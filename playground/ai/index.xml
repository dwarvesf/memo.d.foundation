<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ai on Dwarves Foundation</title><link>https://memo.d.foundation/playground/ai/</link><description>Recent content in Ai on Dwarves Foundation</description><generator>Hugo</generator><language>en-us</language><managingEditor>han@d.foundation (Han Ngo)</managingEditor><webMaster>han@d.foundation (Han Ngo)</webMaster><copyright>© 2024 Dwarves Foundation.</copyright><lastBuildDate>Thu, 27 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://memo.d.foundation/playground/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Securing your remote MCP servers</title><link>https://memo.d.foundation/playground/ai/securing-your-remote-mcp-servers/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/securing-your-remote-mcp-servers/</guid><description>The AI ecosystem is rapidly evolving beyond isolated systems toward integrated networks of AI models and tools. At the core of this evolution lies the Model Context Protocol (MCP), a standardized communication framework that enables AI systems to interact with external tools and services.</description></item><item><title>Tool-Level Security for Remote MCP Servers</title><link>https://memo.d.foundation/playground/ai/tool-level-security-for-remote-mcp-servers/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/tool-level-security-for-remote-mcp-servers/</guid><description>The Model Context Protocol (MCP) has emerged as a powerful standardized framework for AI-to-tool communication, enabling more sophisticated interactions between LLMs and external systems.</description></item><item><title>Intro to Model Context Protocol</title><link>https://memo.d.foundation/playground/ai/model-context-protocol/</link><pubDate>Fri, 29 Nov 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/model-context-protocol/</guid><description>By making a new protocol known as the Model Context Protocol (MCP) open-source, Anthropic made a major change in AI. By overcoming the limitations of traditional data integration techniques and addressing the recurrent problem of data isolation, this protocol aims to enhance the connections between data hubs and AI systems.</description></item><item><title>Natural Language to Database Queries: Text-to-MongoDB</title><link>https://memo.d.foundation/playground/ai/text-to-mongodb/</link><pubDate>Wed, 13 Nov 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/text-to-mongodb/</guid><description>graph TD A[Natural Language Interface] --&amp;gt; B{Data Access} B --&amp;gt; C[Non-Technical Users] B --&amp;gt; D[Data Scientists] B --&amp;gt; E[Business Analysts] A --&amp;gt; F{Analytics} F --&amp;gt; G[Real-Time Insights] F --&amp;gt; H[Interactive Exploration] F --&amp;gt; I[Agentic Workflows] A --&amp;gt; J{Data Integration} J --&amp;gt; K[Cross-Database Queries] J --&amp;gt; L[Cross-Domain Analysis] There are a lot of external efforts in creating text2sql LLMs and workflows to facilitate in Retrieval Augmented Generation and agentic workflows.</description></item><item><title>Evaluate Chatbot Agent by User Simulation</title><link>https://memo.d.foundation/playground/ai/evaluate-chatbot-agent-by-simulated-user/</link><pubDate>Thu, 12 Sep 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/evaluate-chatbot-agent-by-simulated-user/</guid><description>When building a chatbot agent, it&amp;rsquo;s important to evaluate its performance and user satisfaction. One effective method is user simulation, which involves creating virtual users to interact with the chatbot and assess its responses.</description></item><item><title>Journey of Thought Prompting: Harnessing AI to Craft Better Prompts</title><link>https://memo.d.foundation/playground/ai/journey-of-thought-prompting/</link><pubDate>Wed, 11 Sep 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/journey-of-thought-prompting/</guid><description>The Problem with Prompt Engineering Let&amp;rsquo;s face it: prompt engineering is hard. We&amp;rsquo;re all fumbling in the dark, trying to coax these large language models into doing what we want.</description></item><item><title>LLM tracing in AI system</title><link>https://memo.d.foundation/playground/ai/llm-tracing-in-ai-system/</link><pubDate>Wed, 11 Sep 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/llm-tracing-in-ai-system/</guid><description>When Building software with Large Language Models (LLMs) involves several steps, from planning to deployment. LLM tracing emerges as a final step in this process, providing ongoing insights and enabling continuous improvement of LLM-powered applications.</description></item><item><title>Evaluating caching in RAG systems</title><link>https://memo.d.foundation/playground/ai/caching-with-rag-system/</link><pubDate>Fri, 09 Aug 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/caching-with-rag-system/</guid><description>Introduction In the rapidly evolving landscape of artificial intelligence, Retrieval-Augmented Generation (RAG) systems have emerged as a powerful paradigm for combining the strengths of retrieval-based and generative models.</description></item><item><title>What is Generative UI?</title><link>https://memo.d.foundation/playground/ai/generative-ui/</link><pubDate>Thu, 08 Aug 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/generative-ui/</guid><description>What is Generative UI? A generative UI (genUI) is a user interface that responds to the user with AI-generated elements instead of just text messages.</description></item><item><title>Re-ranking in RAG</title><link>https://memo.d.foundation/playground/ai/re-ranking-in-rag/</link><pubDate>Fri, 26 Jul 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/re-ranking-in-rag/</guid><description>One of the primary problems in RAG systems is the retrieval of a heterogeneous set of documents or pieces of information.</description></item><item><title>Function calling in AI agents</title><link>https://memo.d.foundation/playground/ai/function-calling/</link><pubDate>Thu, 18 Jul 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/function-calling/</guid><description>Introduction Function calling is a critical component in the architecture of AI agents, facilitating the integration of external functionalities and resources.</description></item><item><title>Streamlining Internal Tool Development with Managed LLMOps: A Dify Case Study</title><link>https://memo.d.foundation/playground/ai/building-llm-powered-tools-with-dify/</link><pubDate>Fri, 12 Jul 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/building-llm-powered-tools-with-dify/</guid><description>Organizations are always looking for ways to improve efficiency and productivity. Large Language Models (LLMs) are a powerful technology that can help create smart internal tools.</description></item><item><title>Thumbs up and Thumbs down pattern</title><link>https://memo.d.foundation/playground/ai/thumbs-up-and-thumbs-down-pattern/</link><pubDate>Fri, 12 Jul 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/thumbs-up-and-thumbs-down-pattern/</guid><description>Collecting user feedback is importance for improving the accuracy and relevance of responses. One simple yet powerful feedback mechanism is the thumbs up and thumbs down system.</description></item><item><title>Building Agent Supervisors to Generate Insights</title><link>https://memo.d.foundation/playground/ai/supervisor-ai-agents/</link><pubDate>Thu, 11 Jul 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/supervisor-ai-agents/</guid><description>Introduction In the rapidly evolving field of artificial intelligence, the concept of agent supervisors has emerged as a powerful approach to orchestrating multiple AI agents for complex tasks.</description></item><item><title>RAPTOR: Tree-based Retrieval for Language Models</title><link>https://memo.d.foundation/playground/ai/raptor-llm-retrieval/</link><pubDate>Wed, 10 Jul 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/raptor-llm-retrieval/</guid><description>What is it? RAPTOR (Recursive Abstractive Processing for Tree-Organized Retrieval) is a new technique for improving retrieval-augmented language models, particularly for long documents: https://arxiv.</description></item><item><title>Proximal Policy Optimization</title><link>https://memo.d.foundation/playground/ai/proximal-policy-optimization/</link><pubDate>Wed, 03 Jul 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/proximal-policy-optimization/</guid><description>Introduction Proximal Policy Optimization (PPO) is an algorithm that aims to improve the stability of training by avoiding overly large policy updates.</description></item><item><title>A Grand Unified Theory of the AI Hype Cycle</title><link>https://memo.d.foundation/playground/ai/a-grand-unified-theory-of-the-ai-hype-cycle/</link><pubDate>Thu, 13 Jun 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/a-grand-unified-theory-of-the-ai-hype-cycle/</guid><description>The Cycle The history of AI goes in cycles, each of which looks at least a little bit like this:</description></item><item><title>Developing rapidly with Generative AI</title><link>https://memo.d.foundation/playground/ai/developing-rapidly-with-generative-ai/</link><pubDate>Thu, 02 May 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/developing-rapidly-with-generative-ai/</guid><description>Generative AI Generative AI is a subset of artificial intelligence that focuses on creating new content, such as images, text, or audio, based on patterns learned from existing data.</description></item><item><title>RLHF with Open Assistant</title><link>https://memo.d.foundation/playground/ai/rlhf-with-open-assistant/</link><pubDate>Thu, 10 Aug 2023 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/rlhf-with-open-assistant/</guid><description>What is Open Assistant? Open Assistant (abbreviated as OA) is a chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU.</description></item><item><title>Story map for LLMs</title><link>https://memo.d.foundation/playground/ai/story-map-for-llms/</link><pubDate>Wed, 09 Aug 2023 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/story-map-for-llms/</guid><description>Story Map: Journey for Engineers Developing Applications on top of Large Language Models (LLMs) Below is a story map of a kind of simplified learning and execution path for engineers starting out in developing AI.</description></item><item><title>Adversarial Prompting in Prompt Engineering</title><link>https://memo.d.foundation/playground/ai/adversarial-prompting/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/adversarial-prompting/</guid><description>Adversarial prompting is a crucial aspect of prompt engineering, as it aids in understanding the risks and safety concerns associated with Large Language Models (LLMs).</description></item><item><title>Chunking strategies to overcome context limitation in LLM</title><link>https://memo.d.foundation/playground/ai/chunking-strategies-to-overcome-context-limitation-in-llm/</link><pubDate>Sat, 08 Jul 2023 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/chunking-strategies-to-overcome-context-limitation-in-llm/</guid><description>When it comes to Large Language Models (LLMs) like GPT, managing context size - the number of tokens per prompt - is a unique challenge.</description></item><item><title>LLM's Accuracy - Self Refinement</title><link>https://memo.d.foundation/playground/ai/llms-accuracy-self-refinement/</link><pubDate>Thu, 29 Jun 2023 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/llms-accuracy-self-refinement/</guid><description>Self-refinement is a technique where the model evaluates and refines its own output. Normally, when using an LLM, you provide a prompt and the model generates a completion.</description></item><item><title>Query Caching for Large Language Models</title><link>https://memo.d.foundation/playground/ai/llm-query-caching/</link><pubDate>Fri, 09 Jun 2023 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/llm-query-caching/</guid><description>It&amp;rsquo;s quite fascinating to see the increasingly pivotal role that Large Language Models (LLMs) are playing in various applications, covering the spectrum from natural language processing tasks to predictive typing, and more.</description></item><item><title>Introduction to Reinforcement Learning and Its Application with LLMs</title><link>https://memo.d.foundation/playground/ai/reinforcement-learning/</link><pubDate>Mon, 05 Jun 2023 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/reinforcement-learning/</guid><description>Introduction Reinforcement Learning (RL) is a machine learning method in which an automated system, known as an agent, interacts with a dynamic environment to learn and improve its action strategy.</description></item><item><title>Foundation Models: The Latest Advancement in AI</title><link>https://memo.d.foundation/playground/ai/foundation-model/</link><pubDate>Thu, 18 May 2023 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/foundation-model/</guid><description>Foundation models are the latest advancement in the AI realm, proposed by Stanford researchers. Unlike conventional AI systems, they aren&amp;rsquo;t limited to specific tasks, making them a game-changer for a variety of applications.</description></item><item><title>Select Vector Database for LLM</title><link>https://memo.d.foundation/playground/ai/select-vector-database-for-llm/</link><pubDate>Thu, 18 May 2023 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/select-vector-database-for-llm/</guid><description>During our research on applying LLM to real-world applications, we have observed the widespread usage and increasing popularity of Vector databases in various fields.</description></item><item><title>Build your chatbot with open source Large Language Models</title><link>https://memo.d.foundation/playground/ai/build-your-chatbot-with-open-source-large-language-models/</link><pubDate>Thu, 27 Apr 2023 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/build-your-chatbot-with-open-source-large-language-models/</guid><description>Currently, AI chatbot services like ChatGPT are being widely used, but these services are restricted in many countries and also prohibited by many schools due to the high quality of results they produce compared to the level of students’ knowledge.</description></item><item><title>Workaround with OpenAI's token limit with Langchain</title><link>https://memo.d.foundation/playground/ai/workaround-with-openais-token-limit-with-langchain/</link><pubDate>Fri, 21 Apr 2023 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/workaround-with-openais-token-limit-with-langchain/</guid><description>Problem Tuning OpenAI&amp;rsquo;s ChatGPT comes as a very finicky problem as we don&amp;rsquo;t have access to the model and other forms of tuning GPT are very limited.</description></item><item><title>Working with langchain document loaders</title><link>https://memo.d.foundation/playground/ai/working-with-langchain-document-loaders/</link><pubDate>Fri, 21 Apr 2023 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/working-with-langchain-document-loaders/</guid><description>Langchain is a framework that enables the development of applications that utilize language models. It provides support for various main modules, including Models, Prompts, Memory, Indexes, Chains, and Agents.</description></item></channel></rss>