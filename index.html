<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><title data-next-head="">Dwarves Memo - Home</title><meta property="title" content="Dwarves Memo - Home" data-next-head=""/><meta property="og:title" content="Dwarves Memo - Home" data-next-head=""/><meta name="description" content="Knowledge sharing platform for Dwarves Foundation" data-next-head=""/><meta property="og:description" content="Knowledge sharing platform for Dwarves Foundation" data-next-head=""/><meta property="og:type" content="article" data-next-head=""/><meta property="og:site_name" content="Dwarves Memo" data-next-head=""/><link rel="icon" type="image/x-icon" href="{{ $favicon.Permalink }}" data-next-head=""/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" data-next-head=""/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" data-next-head=""/><link rel="apple-touch-icon" href="/apple-touch-icon.png" data-next-head=""/><link rel="icon" href="/favicon.ico" data-next-head=""/><link rel="alternate" type="application/rss+xml" title="Dwarves Memo - Home - RSS Feed" href="/feed.xml" data-next-head=""/><link rel="alternate" type="application/atom+xml" title="Dwarves Memo - Home - Atom Feed" href="/atom.xml" data-next-head=""/><link rel="preconnect" href="https://fonts.googleapis.com" data-next-head=""/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous" data-next-head=""/><link rel="apple-touch-icon" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><link data-next-font="" rel="preconnect" href="/" crossorigin="anonymous"/><link rel="preload" href="/_next/static/css/e8529fa281a1010f.css" as="style"/><link href="https://fonts.googleapis.com/css2?family=Public+Sans:ital,wght@0,100..900;1,100..900&amp;family=IBM+Plex+Sans:ital,wght@0,100..700;1,100..700&amp;display=swap" rel="stylesheet" data-next-head=""/><link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;display=swap" rel="stylesheet" data-next-head=""/><link rel="stylesheet" href="/_next/static/css/e8529fa281a1010f.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-fbb920bddf9bf0a6.js" defer=""></script><script src="/_next/static/chunks/framework-e252e7e8cb4283ef.js" defer=""></script><script src="/_next/static/chunks/main-b572048b704c71d9.js" defer=""></script><script src="/_next/static/chunks/pages/_app-001c12c5c94f1fd6.js" defer=""></script><script src="/_next/static/chunks/09244f9f-f6998eb65789973d.js" defer=""></script><script src="/_next/static/chunks/496-cbd4dbb3f0d35a5c.js" defer=""></script><script src="/_next/static/chunks/743-10ce7259ea790993.js" defer=""></script><script src="/_next/static/chunks/pages/index-5754fc0d2eb3f837.js" defer=""></script><script src="/_next/static/YEl9dMUxleKjDbVxqv2Hg/_buildManifest.js" defer=""></script><script src="/_next/static/YEl9dMUxleKjDbVxqv2Hg/_ssgManifest.js" defer=""></script></head><body class="min-h-screen antialiased"><script>
              (function() {
                // Get saved theme or default to system preference
                const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
                const savedTheme = localStorage.getItem('theme');
                
                // Default to system preference if no saved preference
                const theme = (savedTheme === 'light' || savedTheme === 'dark') 
                  ? savedTheme 
                  : (prefersDark ? 'dark' : 'light');
                
                // Apply theme
                if (theme === 'dark') {
                  document.documentElement.classList.add('dark');
                  document.documentElement.setAttribute('data-theme', 'dark');
                } else {
                  document.documentElement.classList.remove('dark');
                  document.documentElement.setAttribute('data-theme', 'light');
                }
              })();
            </script><link rel="preload" as="image" href="/assets/home_cover.webp"/><div id="__next"><div class="bg-background border-border w-sidebar-mobile xl:w-sidebar fixed top-0 left-0 z-40 flex h-full flex-col border-r pt-4 pb-12 font-sans transition-transform duration-300 ease-in-out translate-x-[-100%] xl:translate-x-0 "><a class="mx-4 flex h-10 items-center gap-2 px-2 xl:mx-0 xl:justify-center" href="/"><svg width="24" height="24" viewBox="0 0 19 20" fill="none" xmlns="http://www.w3.org/2000/svg" class="h-6.25 w-6 min-w-6"><path d="M2.41664 20C1.08113 20 0 18.8812 0 17.4991V2.50091C0 1.11883 1.08113 0 2.41664 0L8.46529 0.00731261C13.8427 0.00731261 18.1954 4.55576 18.1248 10.1353C18.0541 15.6271 13.6307 20 8.32397 20H2.41664Z" fill="#E13F5E"></path><path d="M3.63209 15.6271H3.32118C3.15159 15.6271 3.01733 15.4881 3.01733 15.3126V12.8044C3.01733 12.6289 3.15159 12.49 3.32118 12.49H5.74488C5.91447 12.49 6.04873 12.6289 6.04873 12.8044V13.1262C6.04873 14.5082 4.9676 15.6271 3.63209 15.6271Z" fill="white"></path><path d="M3.32119 8.11701H10.8749C12.2105 8.11701 13.2916 6.99818 13.2916 5.6161V5.31628C13.2916 5.13347 13.1503 4.98721 12.9736 4.98721H5.44105C4.10554 4.98721 3.02441 6.10604 3.02441 7.48813V7.80257C3.02441 7.97807 3.15867 8.11701 3.32119 8.11701Z" fill="white"></path><path d="M3.32118 11.8684H7.24998C8.58549 11.8684 9.66661 10.7496 9.66661 9.36747V9.05303C9.66661 8.87753 9.53236 8.73859 9.36277 8.73859H3.32118C3.15159 8.73859 3.01733 8.87753 3.01733 9.05303V11.5539C3.0244 11.7294 3.15866 11.8684 3.32118 11.8684Z" fill="white"></path></svg><span class="inline-block font-sans text-xs leading-tight font-bold tracking-tight uppercase xl:hidden">Dwarves<br/>Memo</span></a><nav class="flex flex-1 flex-col p-4 xl:items-center xl:px-2"><a class="hover:bg-muted dark:hover:bg-muted flex items-center rounded-lg text-sm font-medium transition-colors md:justify-start text-primary" id="sidebar-item-0" data-state="closed" data-slot="tooltip-trigger" href="/"><div class="p-2"><div class="h-6 w-6" style="mask-image:url(&#x27;/assets/img/home.svg&#x27;);-webkit-mask-image:url(&#x27;/assets/img/home.svg&#x27;);background-color:currentColor;mask-repeat:no-repeat;-webkit-mask-repeat:no-repeat;mask-size:contain;-webkit-mask-size:contain;mask-position:center;-webkit-mask-position:center"></div></div><span class="ml-3 inline-block xl:hidden">Home</span></a><a class="hover:bg-muted dark:hover:bg-muted flex items-center rounded-lg text-sm font-medium transition-colors md:justify-start" id="sidebar-item-1" data-state="closed" data-slot="tooltip-trigger" href="/consulting"><div class="p-2"><div class="h-6 w-6" style="mask-image:url(&#x27;/assets/img/consulting.svg&#x27;);-webkit-mask-image:url(&#x27;/assets/img/consulting.svg&#x27;);background-color:currentColor;mask-repeat:no-repeat;-webkit-mask-repeat:no-repeat;mask-size:contain;-webkit-mask-size:contain;mask-position:center;-webkit-mask-position:center"></div></div><span class="ml-3 inline-block xl:hidden">Consulting</span></a><a class="hover:bg-muted dark:hover:bg-muted flex items-center rounded-lg text-sm font-medium transition-colors md:justify-start" id="sidebar-item-2" data-state="closed" data-slot="tooltip-trigger" href="/earn"><div class="p-2"><div class="h-6 w-6" style="mask-image:url(&#x27;/assets/img/earn.svg&#x27;);-webkit-mask-image:url(&#x27;/assets/img/earn.svg&#x27;);background-color:currentColor;mask-repeat:no-repeat;-webkit-mask-repeat:no-repeat;mask-size:contain;-webkit-mask-size:contain;mask-position:center;-webkit-mask-position:center"></div></div><span class="ml-3 inline-block xl:hidden">Earn</span></a><a class="hover:bg-muted dark:hover:bg-muted flex items-center rounded-lg text-sm font-medium transition-colors md:justify-start" id="sidebar-item-3" data-state="closed" data-slot="tooltip-trigger" href="/careers/hiring"><div class="p-2"><div class="h-6 w-6" style="mask-image:url(&#x27;/assets/img/hiring.svg&#x27;);-webkit-mask-image:url(&#x27;/assets/img/hiring.svg&#x27;);background-color:currentColor;mask-repeat:no-repeat;-webkit-mask-repeat:no-repeat;mask-size:contain;-webkit-mask-size:contain;mask-position:center;-webkit-mask-position:center"></div></div><span class="ml-3 inline-block xl:hidden">Hiring</span></a><a class="hover:bg-muted dark:hover:bg-muted flex items-center rounded-lg text-sm font-medium transition-colors md:justify-start" id="sidebar-item-4" data-state="closed" data-slot="tooltip-trigger" href="/updates/digest"><div class="p-2"><div class="h-6 w-6" style="mask-image:url(&#x27;/assets/img/digest.svg&#x27;);-webkit-mask-image:url(&#x27;/assets/img/digest.svg&#x27;);background-color:currentColor;mask-repeat:no-repeat;-webkit-mask-repeat:no-repeat;mask-size:contain;-webkit-mask-size:contain;mask-position:center;-webkit-mask-position:center"></div></div><span class="ml-3 inline-block xl:hidden">Digest</span></a><a class="hover:bg-muted dark:hover:bg-muted flex items-center rounded-lg text-sm font-medium transition-colors md:justify-start" id="sidebar-item-5" data-state="closed" data-slot="tooltip-trigger" href="/updates/ogif"><div class="p-2"><div class="h-6 w-6" style="mask-image:url(&#x27;/assets/img/ogifs.svg&#x27;);-webkit-mask-image:url(&#x27;/assets/img/ogifs.svg&#x27;);background-color:currentColor;mask-repeat:no-repeat;-webkit-mask-repeat:no-repeat;mask-size:contain;-webkit-mask-size:contain;mask-position:center;-webkit-mask-position:center"></div></div><span class="ml-3 inline-block xl:hidden">OGIFs</span></a></nav><div class="mx-4 border-t pt-1 xl:mx-2"><div class="flex items-center justify-between gap-3 p-2 xl:justify-center"><button class="flex cursor-pointer items-center justify-center hover:opacity-80"><svg viewBox="0 0 20 20" width="24" height="24"><path d="M16.667 12.3249L17.3564 12.6202C17.4795 12.3329 17.4115 11.9994 17.1857 11.7832C16.96 11.567 16.6239 11.5135 16.3421 11.6489L16.667 12.3249ZM8.19804 2.3999L8.79449 2.85459C8.9845 2.60535 8.99949 2.26424 8.83208 1.99928C8.66467 1.73433 8.35016 1.60141 8.04348 1.666L8.19804 2.3999ZM13.6635 12.2548C10.3006 12.2548 7.60587 9.59905 7.60587 6.36135L6.10587 6.36135C6.10587 10.4618 9.50689 13.7548 13.6635 13.7548L13.6635 12.2548ZM16.3421 11.6489C15.5358 12.0364 14.6271 12.2548 13.6635 12.2548L13.6635 13.7548C14.8559 13.7548 15.9863 13.4841 16.9918 13.0009L16.3421 11.6489ZM15.9776 12.0295C14.9688 14.384 12.579 16.0499 9.77963 16.0499L9.77963 17.5499C13.1836 17.5499 16.1131 15.5222 17.3564 12.6202L15.9776 12.0295ZM9.77963 16.0499C6.05539 16.0499 3.06774 13.1083 3.06774 9.51796L1.56774 9.51796C1.56774 13.971 5.26169 17.5499 9.77963 17.5499L9.77963 16.0499ZM3.06774 9.51796C3.06774 6.3999 5.31884 3.77274 8.3526 3.1338L8.04348 1.666C4.35439 2.44295 1.56774 5.65176 1.56774 9.51796L3.06774 9.51796ZM7.60587 6.36135C7.60587 5.04819 8.0465 3.83578 8.79449 2.85459L7.60159 1.94521C6.66318 3.17619 6.10587 4.70542 6.10587 6.36135L7.60587 6.36135Z" fill="currentColor"></path><path d="M13.9357 2.46517C13.5852 2.2404 13.1672 2.64169 13.4007 2.97822L13.8173 3.57826C13.9864 3.82156 14.0766 4.10745 14.0766 4.3999C14.0766 4.69235 13.9864 4.97825 13.8173 5.22154L13.4007 5.82158C13.1672 6.15811 13.5858 6.55941 13.9364 6.33463L14.5607 5.93461C14.8141 5.77233 15.1119 5.68573 15.4165 5.68573C15.7211 5.68573 16.0189 5.77233 16.2723 5.93461L16.8973 6.33463C17.2478 6.55941 17.6658 6.15811 17.4317 5.82158L17.015 5.22154C16.846 4.97825 16.7558 4.69235 16.7558 4.3999C16.7558 4.10745 16.846 3.82156 17.015 3.57826L17.4317 2.97822C17.6658 2.64169 17.2478 2.2404 16.8966 2.46517L16.2723 2.8652C16.0189 3.02747 15.7211 3.11407 15.4165 3.11407C15.1119 3.11407 14.8141 3.02747 14.5607 2.8652L13.9357 2.46517Z" fill="currentColor" fill-opacity="0.25"></path></svg></button><span class="inline-block flex-1 shrink-0 text-sm leading-6 font-medium xl:hidden">Night mode</span><button class="bg-border flex h-5 w-9 cursor-pointer items-center justify-center rounded-full py-0.5 pr-4.5 pl-0.5 hover:opacity-95 xl:hidden"><div class="text-foreground-light rounded-full bg-white p-0.5"><svg viewBox="0 0 20 20" width="12" height="12"><path d="M16.667 12.3249L17.3564 12.6202C17.4795 12.3329 17.4115 11.9994 17.1857 11.7832C16.96 11.567 16.6239 11.5135 16.3421 11.6489L16.667 12.3249ZM8.19804 2.3999L8.79449 2.85459C8.9845 2.60535 8.99949 2.26424 8.83208 1.99928C8.66467 1.73433 8.35016 1.60141 8.04348 1.666L8.19804 2.3999ZM13.6635 12.2548C10.3006 12.2548 7.60587 9.59905 7.60587 6.36135L6.10587 6.36135C6.10587 10.4618 9.50689 13.7548 13.6635 13.7548L13.6635 12.2548ZM16.3421 11.6489C15.5358 12.0364 14.6271 12.2548 13.6635 12.2548L13.6635 13.7548C14.8559 13.7548 15.9863 13.4841 16.9918 13.0009L16.3421 11.6489ZM15.9776 12.0295C14.9688 14.384 12.579 16.0499 9.77963 16.0499L9.77963 17.5499C13.1836 17.5499 16.1131 15.5222 17.3564 12.6202L15.9776 12.0295ZM9.77963 16.0499C6.05539 16.0499 3.06774 13.1083 3.06774 9.51796L1.56774 9.51796C1.56774 13.971 5.26169 17.5499 9.77963 17.5499L9.77963 16.0499ZM3.06774 9.51796C3.06774 6.3999 5.31884 3.77274 8.3526 3.1338L8.04348 1.666C4.35439 2.44295 1.56774 5.65176 1.56774 9.51796L3.06774 9.51796ZM7.60587 6.36135C7.60587 5.04819 8.0465 3.83578 8.79449 2.85459L7.60159 1.94521C6.66318 3.17619 6.10587 4.70542 6.10587 6.36135L7.60587 6.36135Z" fill="currentColor"></path><path d="M13.9357 2.46517C13.5852 2.2404 13.1672 2.64169 13.4007 2.97822L13.8173 3.57826C13.9864 3.82156 14.0766 4.10745 14.0766 4.3999C14.0766 4.69235 13.9864 4.97825 13.8173 5.22154L13.4007 5.82158C13.1672 6.15811 13.5858 6.55941 13.9364 6.33463L14.5607 5.93461C14.8141 5.77233 15.1119 5.68573 15.4165 5.68573C15.7211 5.68573 16.0189 5.77233 16.2723 5.93461L16.8973 6.33463C17.2478 6.55941 17.6658 6.15811 17.4317 5.82158L17.015 5.22154C16.846 4.97825 16.7558 4.69235 16.7558 4.3999C16.7558 4.10745 16.846 3.82156 17.015 3.57826L17.4317 2.97822C17.6658 2.64169 17.2478 2.2404 16.8966 2.46517L16.2723 2.8652C16.0189 3.02747 15.7211 3.11407 15.4165 3.11407C15.1119 3.11407 14.8141 3.02747 14.5607 2.8652L13.9357 2.46517Z" fill="currentColor" fill-opacity="0.25"></path></svg></div></button></div></div></div><div class="bg-background text-foreground relative flex h-screen font-sans transition-colors "><div id="sidebar" class="bg-background-secondary xl:w-directory-width h-[calc(100svh-32px)] w-0 flex-col pt-10 pb-2 text-sm leading-normal xl:pr-3 xl:ml-sidebar translate-0 transition duration-100 ease-in-out z-2 overflow-y-auto reading:opacity-0 reading:translate-x-[-10%] reading:pr-0 reading:w-0 reading:ml-0"><div class=""><div class="relative flex flex-col"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/pinned"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out"><path d="m6 9 6 6 6-6"></path></svg><span>Pinned Notes</span></a><div class="m-0 w-full pl-1"><div class="relative flex flex-col before:bg-border before:absolute before:top-0 before:left-[7px] before:h-full before:w-[1px] before:content-[&#x27;&#x27;] after:bg-border pl-3 after:absolute after:top-1/2 after:left-[7px] after:h-full after:w-[1px] after:origin-center after:-translate-y-1/2 after:scale-y-0 after:transition-transform after:duration-300 after:ease-in-out after:content-[&#x27;&#x27;]"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium text-muted-foreground pl-2" href="/playbook/operations/ogif"><span>OGIF - Oh God It&#x27;s Friday</span></a></div></div></div><div class="relative flex flex-col"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out"><path d="m6 9 6 6 6-6"></path></svg><span>Home</span></a><div class="m-0 w-full pl-1"><div class="relative flex flex-col before:bg-border before:absolute before:top-0 before:left-[7px] before:h-full before:w-[1px] before:content-[&#x27;&#x27;] after:bg-border pl-3 after:absolute after:top-1/2 after:left-[7px] after:h-full after:w-[1px] after:origin-center after:-translate-y-1/2 after:scale-y-0 after:transition-transform after:duration-300 after:ease-in-out after:content-[&#x27;&#x27;]"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/careers"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out -rotate-90"><path d="m6 9 6 6 6-6"></path></svg><span>Careers</span></a></div><div class="relative flex flex-col before:bg-border before:absolute before:top-0 before:left-[7px] before:h-full before:w-[1px] before:content-[&#x27;&#x27;] after:bg-border pl-3 after:absolute after:top-1/2 after:left-[7px] after:h-full after:w-[1px] after:origin-center after:-translate-y-1/2 after:scale-y-0 after:transition-transform after:duration-300 after:ease-in-out after:content-[&#x27;&#x27;]"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/consulting"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out -rotate-90"><path d="m6 9 6 6 6-6"></path></svg><span>Consulting</span></a></div><div class="relative flex flex-col before:bg-border before:absolute before:top-0 before:left-[7px] before:h-full before:w-[1px] before:content-[&#x27;&#x27;] after:bg-border pl-3 after:absolute after:top-1/2 after:left-[7px] after:h-full after:w-[1px] after:origin-center after:-translate-y-1/2 after:scale-y-0 after:transition-transform after:duration-300 after:ease-in-out after:content-[&#x27;&#x27;]"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/earn"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out -rotate-90"><path d="m6 9 6 6 6-6"></path></svg><span>Earn</span></a></div><div class="relative flex flex-col before:bg-border before:absolute before:top-0 before:left-[7px] before:h-full before:w-[1px] before:content-[&#x27;&#x27;] after:bg-border pl-3 after:absolute after:top-1/2 after:left-[7px] after:h-full after:w-[1px] after:origin-center after:-translate-y-1/2 after:scale-y-0 after:transition-transform after:duration-300 after:ease-in-out after:content-[&#x27;&#x27;]"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/handbook"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out -rotate-90"><path d="m6 9 6 6 6-6"></path></svg><span>Handbook</span></a></div><div class="relative flex flex-col before:bg-border before:absolute before:top-0 before:left-[7px] before:h-full before:w-[1px] before:content-[&#x27;&#x27;] after:bg-border pl-3 after:absolute after:top-1/2 after:left-[7px] after:h-full after:w-[1px] after:origin-center after:-translate-y-1/2 after:scale-y-0 after:transition-transform after:duration-300 after:ease-in-out after:content-[&#x27;&#x27;]"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/opensource"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out -rotate-90"><path d="m6 9 6 6 6-6"></path></svg><span>Opensource</span></a></div><div class="relative flex flex-col before:bg-border before:absolute before:top-0 before:left-[7px] before:h-full before:w-[1px] before:content-[&#x27;&#x27;] after:bg-border pl-3 after:absolute after:top-1/2 after:left-[7px] after:h-full after:w-[1px] after:origin-center after:-translate-y-1/2 after:scale-y-0 after:transition-transform after:duration-300 after:ease-in-out after:content-[&#x27;&#x27;]"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/playbook"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out -rotate-90"><path d="m6 9 6 6 6-6"></path></svg><span>Playbook</span></a></div><div class="relative flex flex-col before:bg-border before:absolute before:top-0 before:left-[7px] before:h-full before:w-[1px] before:content-[&#x27;&#x27;] after:bg-border pl-3 after:absolute after:top-1/2 after:left-[7px] after:h-full after:w-[1px] after:origin-center after:-translate-y-1/2 after:scale-y-0 after:transition-transform after:duration-300 after:ease-in-out after:content-[&#x27;&#x27;]"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/playground"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out -rotate-90"><path d="m6 9 6 6 6-6"></path></svg><span>Playground</span></a></div><div class="relative flex flex-col before:bg-border before:absolute before:top-0 before:left-[7px] before:h-full before:w-[1px] before:content-[&#x27;&#x27;] after:bg-border pl-3 after:absolute after:top-1/2 after:left-[7px] after:h-full after:w-[1px] after:origin-center after:-translate-y-1/2 after:scale-y-0 after:transition-transform after:duration-300 after:ease-in-out after:content-[&#x27;&#x27;]"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/updates"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out -rotate-90"><path d="m6 9 6 6 6-6"></path></svg><span>Updates</span></a></div></div></div><div class="relative flex flex-col"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/tags"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out -rotate-90"><path d="m6 9 6 6 6-6"></path></svg><span>Popular Tags</span></a></div></div></div><div class="relative flex flex-1 flex-col overflow-y-auto"><header class="bg-background/95 supports-[backdrop-filter]:bg-background/60 top-0 w-full shrink-0 font-sans backdrop-blur"><div class="mx-auto flex h-full items-center justify-between border-b p-2 xl:border-none xl:px-5"><div class="flex items-center gap-2.5"><button id="sidebar-toggle" aria-label="Toggle sidebar" class="flex h-10 w-10 cursor-pointer items-center justify-center focus:outline-none xl:hidden"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="text-current"><path d="M4 6H20M4 12H20M4 18H20" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg></button><a class="flex items-center gap-2 xl:hidden" href="/"><svg width="24" height="24" viewBox="0 0 19 20" fill="none" xmlns="http://www.w3.org/2000/svg" class="h-[32px] w-[29px] min-w-6 shrink-0"><path d="M2.41664 20C1.08113 20 0 18.8812 0 17.4991V2.50091C0 1.11883 1.08113 0 2.41664 0L8.46529 0.00731261C13.8427 0.00731261 18.1954 4.55576 18.1248 10.1353C18.0541 15.6271 13.6307 20 8.32397 20H2.41664Z" fill="#E13F5E"></path><path d="M3.63209 15.6271H3.32118C3.15159 15.6271 3.01733 15.4881 3.01733 15.3126V12.8044C3.01733 12.6289 3.15159 12.49 3.32118 12.49H5.74488C5.91447 12.49 6.04873 12.6289 6.04873 12.8044V13.1262C6.04873 14.5082 4.9676 15.6271 3.63209 15.6271Z" fill="white"></path><path d="M3.32119 8.11701H10.8749C12.2105 8.11701 13.2916 6.99818 13.2916 5.6161V5.31628C13.2916 5.13347 13.1503 4.98721 12.9736 4.98721H5.44105C4.10554 4.98721 3.02441 6.10604 3.02441 7.48813V7.80257C3.02441 7.97807 3.15867 8.11701 3.32119 8.11701Z" fill="white"></path><path d="M3.32118 11.8684H7.24998C8.58549 11.8684 9.66661 10.7496 9.66661 9.36747V9.05303C9.66661 8.87753 9.53236 8.73859 9.36277 8.73859H3.32118C3.15159 8.73859 3.01733 8.87753 3.01733 9.05303V11.5539C3.0244 11.7294 3.15866 11.8684 3.32118 11.8684Z" fill="white"></path></svg><span class="font-ibm-sans text-xs text-[11px] leading-[14.849px] font-bold -tracking-[0.157px] uppercase">Dwarves<br/>Memo</span></a></div><div class="ml-auto flex items-center gap-3.5"><div class="command-palette relative z-50"><button class="hidden w-50 cursor-pointer justify-between rounded-md border bg-transparent px-3 py-1.5 transition-all duration-100 ease-in-out hover:shadow-md md:flex" aria-label="Open command palette"><div class="flex items-center gap-0.5"><span class="text-muted-foreground text-sm filter-[opacity(50%)]">🔍 Search...</span></div><div class="text-muted-foreground flex items-center gap-0.5 text-xs"><kbd class="dark:bg-border rounded bg-[#f9fafb] px-1.5 py-0.5">⌘</kbd><kbd class="dark:bg-border rounded bg-[#f9fafb] px-1.5 py-0.5">K</kbd></div></button><button class="text-foreground flex h-10 w-10 items-center justify-center border-none bg-transparent p-0 md:hidden" aria-label="Open search"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 16 16" fill="none" class="text-foreground" aria-hidden="true"><circle cx="6.88881" cy="6.8889" r="5.55556" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></circle><path d="M11.3333 11.3333L14.6666 14.6667" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></button></div><button class="hidden cursor-pointer items-center justify-center border-0 bg-transparent px-1.5 outline-none hover:opacity-95 active:opacity-100 xl:flex" aria-label="Toggle reading mode" data-reading-mode="false" data-state="closed" data-slot="tooltip-trigger"><svg width="48" height="28" viewBox="0 0 62 34" fill="none" xmlns="http://www.w3.org/2000/svg" class="h-7 w-12 xl:w-14"><g><rect width="62" height="34" rx="17" class="fill-border dark:fill-border"></rect><g class="transition-transform duration-150 ease-in-out translate-x-0"><circle cx="17" cy="17" r="14" class="fill-white"></circle><path d="M17 23.898V18.3265C17 17.9747 17.1398 17.6373 17.3885 17.3885C17.6373 17.1398 17.9747 17 18.3265 17C18.6783 17 19.0158 17.1398 19.2645 17.3885C19.5133 17.6373 19.6531 17.9747 19.6531 18.3265V21.2449H21.7755C22.3384 21.2449 22.8782 21.4685 23.2763 21.8666C23.6744 22.2646 23.898 22.8045 23.898 23.3673V23.898" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="stroke-[#333639]"></path><path d="M16.2119 12.8561C14.8891 11.4004 13.114 10.4334 11.1736 10.1113C11.0416 10.0926 10.9071 10.1022 10.7791 10.1395C10.6511 10.1768 10.5324 10.2409 10.4311 10.3275C10.3279 10.4158 10.245 10.5253 10.1883 10.6487C10.1315 10.772 10.1021 10.9062 10.1021 11.0419V18.6088C10.1007 18.8411 10.1854 19.0658 10.3399 19.2394C10.4944 19.413 10.7077 19.5232 10.9386 19.5487C12.4542 19.7543 13.8794 20.354 15.0774 21.276" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="stroke-[#333639]"></path><path d="M16.2124 15.7885V12.8561" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="stroke-[#333639]"></path><path d="M21.4852 19.5487C21.7161 19.5232 21.9295 19.413 22.084 19.2394C22.2385 19.0658 22.3232 18.8411 22.3218 18.6088V11.0419C22.3218 10.9062 22.2924 10.772 22.2356 10.6487C22.1788 10.5253 22.096 10.4158 21.9928 10.3275C21.8915 10.2409 21.7728 10.1768 21.6447 10.1395C21.5167 10.1022 21.3823 10.0926 21.2502 10.1113C19.3098 10.4334 17.5347 11.4004 16.2119 12.8561" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="stroke-[#333639]"></path></g></g></svg></button></div></div></header><div class="main-grid relative w-full flex-1 flex-col"><div class="right-sidebar leading-[140% xl:w-right-sidebar-width hidden font-sans text-sm font-medium xl:flex transition-[transform,opacity,visibility] duration-100 ease-in-out visible w-0 translate-x-0 transform opacity-100 reading:opacity-0 reading:xl:translate-x-[50px] reading:invisible reading:fixed reading:right-[calc((100vw-var(--max-container-width)-var(--nav-sidebar-width))/2)]"><div class="sticky top-[60px] right-0 flex flex-col gap-y-8 pt-4 pb-10 transition-[top] duration-200 ease-in-out"></div></div><main class="main-content mx-auto max-w-[var(--container-max-width)] min-w-0 flex-1 p-[var(--main-padding-mobile)] font-serif xl:p-[var(--main-padding)]"><img alt="" loading="lazy" width="1920" height="1080" decoding="async" data-nimg="1" class="yggdrasil-tree no-zoom pointer-events-none object-contain opacity-[0.03] md:w-[20vw] xl:w-[20vw] dark:opacity-100 absolute bottom-8 left-1/2 w-[50vw] max-w-xs -translate-x-1/2 xl:translate-x-[80%]" style="color:transparent" src="/assets/img/footer-bg.svg"/><div class="memo-content pb-8"><div class="font-serif"><img src="/assets/home_cover.webp" class="no-zoom max-h-[500px] rounded-sm"/><p class="mt-[var(--element-margin)]">Welcome to the Dwarves Memo.</p><p class="mt-[var(--element-margin)]">This site is a part of our continuous learning engine, where we want to build up the 1% improvement habit, learning in public.</p><p class="mt-[var(--element-margin)]">Written by Dwarves for product craftsmen.</p><p class="mt-[var(--element-margin)]">Learned by engineers. Experimented by engineers.</p><h2 class="-track-[0.0125] mt-8 mb-2.5 text-[26px] leading-[140%] font-semibold">💡 OGIFs</h2><div id="changelog" class="link-v-list mt-2.5 flex flex-col gap-1.5" data-placement="vertical"><div id="memo-1" class="link-v-list-item"><a class="link-v-list-item-title hover:text-primary hover:decoration-primary inline text-[17px] underline decoration-neutral-100" href="/updates/ogif/41-20250314">#41 ICY-BTC, GitHub Bot, MCP-DB, Pocket Turing</a></div><div id="memo-2" class="link-v-list-item"><a class="link-v-list-item-title hover:text-primary hover:decoration-primary inline text-[17px] underline decoration-neutral-100" href="/updates/ogif/28-20241018">#28 Go sync.Map, AI UX, Yelp AI, LLM Patterns, Git Analysis</a></div><div id="memo-3" class="link-v-list-item"><a class="link-v-list-item-title hover:text-primary hover:decoration-primary inline text-[17px] underline decoration-neutral-100" href="/updates/ogif/27-20241011">#27 Go weekly, Frontend, AI UX, Finite Automata</a></div><div id="memo-4" class="link-v-list-item"><a class="link-v-list-item-title hover:text-primary hover:decoration-primary inline text-[17px] underline decoration-neutral-100" href="/updates/ogif/26-20241004">#26 Design insights, Go tools, Trading app, Chatbots, Essays</a></div><div id="memo-5" class="link-v-list-item"><a class="link-v-list-item-title hover:text-primary hover:decoration-primary inline text-[17px] underline decoration-neutral-100" href="/updates/ogif/25-20240927">#25 Team updates, Hybrid work, AI insights, Go weekly</a></div></div><h2 class="-track-[0.0125] mt-8 mb-2.5 text-[26px] leading-[140%] font-semibold">✨ New memos</h2><div class="v-list" data-placement="vertical"><div id="memo-1" class="v-list-item xs:flex-row flex w-full flex-col not-last:border-b"><div class="v-list-item-image xs:w-3/10 xs:pb-3 xs:pr-6 pt-3 pb-0"><img class="no-zoom h-[130px] w-full rounded-sm object-cover" src="/assets/home_cover.webp" alt="Cover image for New Brainery" height="130" loading="lazy"/></div><div class="flex flex-1 flex-col gap-1 py-3"><a class="hover:text-primary hover:decoration-primary mt-0 text-[17px] font-semibold underline decoration-neutral-100" href="/earn/open-source">New Brainery</a><div class="text-foreground line-clamp-2 text-sm font-normal"></div></div></div><div id="memo-2" class="v-list-item xs:flex-row flex w-full flex-col not-last:border-b"><div class="v-list-item-image xs:w-3/10 xs:pb-3 xs:pr-6 pt-3 pb-0"><img class="no-zoom h-[130px] w-full rounded-sm object-cover" src="/assets/home_cover.webp" alt="Cover image for New Brainery" height="130" loading="lazy"/></div><div class="flex flex-1 flex-col gap-1 py-3"><a class="hover:text-primary hover:decoration-primary mt-0 text-[17px] font-semibold underline decoration-neutral-100" href="/earn/productivity">New Brainery</a><div class="text-foreground line-clamp-2 text-sm font-normal"></div></div></div><div id="memo-3" class="v-list-item xs:flex-row flex w-full flex-col not-last:border-b"><div class="v-list-item-image xs:w-3/10 xs:pb-3 xs:pr-6 pt-3 pb-0"><img class="no-zoom h-[130px] w-full rounded-sm object-cover" src="/assets/home_cover.webp" alt="Cover image for New Brainery" height="130" loading="lazy"/></div><div class="flex flex-1 flex-col gap-1 py-3"><a class="hover:text-primary hover:decoration-primary mt-0 text-[17px] font-semibold underline decoration-neutral-100" href="/earn/quality">New Brainery</a><div class="text-foreground line-clamp-2 text-sm font-normal"></div></div></div></div><h2 class="-track-[0.0125] mt-8 mb-2.5 text-[26px] leading-[140%] font-semibold">🧑‍💻 Life at Dwarves</h2><div class="v-list" data-placement="vertical"><div id="memo-1" class="v-list-item xs:flex-row flex w-full flex-col not-last:border-b no-image first:*:pt-0"><div class="flex flex-1 flex-col gap-1 py-3"><a class="hover:text-primary hover:decoration-primary mt-0 text-[17px] font-semibold underline decoration-neutral-100" href="/playground/01_literature/record-reward-sharing-culture">Record and reward sharing at Dwarves</a><div class="text-foreground line-clamp-2 text-sm font-normal">Discover how the Dwarves community fosters a culture of continuous learning and knowledge sharing. With a monthly reward pool of up to 2500 ICY, contributors are recognized for sharing valuable insights, especially in areas like AI/LLM, Golang, and more. Get involved and grow with us.</div><div class="text-secondary-foreground dark:text-secondary-light font-ibm-sans text-sm font-normal">September 05, 2024</div></div></div><div id="memo-2" class="v-list-item xs:flex-row flex w-full flex-col not-last:border-b no-image first:*:pt-0"><div class="flex flex-1 flex-col gap-1 py-3"><a class="hover:text-primary hover:decoration-primary mt-0 text-[17px] font-semibold underline decoration-neutral-100" href="/careers/culture">Culture Handbook</a><div class="text-foreground line-clamp-2 text-sm font-normal">Keep learning and growing. We started this team out of software practice advancement.</div><div class="text-secondary-foreground dark:text-secondary-light font-ibm-sans text-sm font-normal">December 15, 2023</div></div></div><div id="memo-3" class="v-list-item xs:flex-row flex w-full flex-col not-last:border-b no-image first:*:pt-0"><div class="flex flex-1 flex-col gap-1 py-3"><a class="hover:text-primary hover:decoration-primary mt-0 text-[17px] font-semibold underline decoration-neutral-100" href="/playbook/operations/red-flags">Red Flags</a><div class="text-foreground line-clamp-2 text-sm font-normal">These red flags are things we don’t want to see in our peeps. Even when you think they are improper, don’t waste your time with a wrong group of people.</div><div class="text-secondary-foreground dark:text-secondary-light font-ibm-sans text-sm font-normal">February 16, 2023</div></div></div></div><h2 class="-track-[0.0125] mt-8 mb-2.5 text-[26px] leading-[140%] font-semibold">📝 Changelog</h2><div id="changelog" class="link-v-list mt-2.5 flex flex-col gap-1.5" data-placement="vertical"><div id="memo-1" class="link-v-list-item"><a class="link-v-list-item-title hover:text-primary hover:decoration-primary inline text-[17px] underline text-primary decoration-primary" href="/updates/digest/15-new-year-gathering">#15 New year gathering</a><span class="link-v-list-item-time text-secondary-foreground dark:text-secondary-light font-ibm-sans ml-1 inline text-sm font-normal"> - <!-- -->February 04, 2025</span></div><div id="memo-2" class="link-v-list-item"><a class="link-v-list-item-title hover:text-primary hover:decoration-primary inline text-[17px] underline text-primary decoration-primary" href="/updates/digest/14-back-to-the-office">#14 Hybrid work harmony</a><span class="link-v-list-item-time text-secondary-foreground dark:text-secondary-light font-ibm-sans ml-1 inline text-sm font-normal"> - <!-- -->September 25, 2024</span></div><div id="memo-3" class="link-v-list-item"><a class="link-v-list-item-title hover:text-primary hover:decoration-primary inline text-[17px] underline text-primary decoration-primary" href="/updates/digest/13-more-than-lines-of-code">#13 More than lines of code</a><span class="link-v-list-item-time text-secondary-foreground dark:text-secondary-light font-ibm-sans ml-1 inline text-sm font-normal"> - <!-- -->July 20, 2024</span></div></div><h2 class="-track-[0.0125] mt-8 mb-2.5 text-[26px] leading-[140%] font-semibold">🤝 Open positions</h2><div class="v-list" data-placement="vertical"><div id="memo-1" class="v-list-item xs:flex-row flex w-full flex-col not-last:border-b no-image first:*:pt-0"><div class="flex flex-1 flex-col gap-1 py-3"><a class="hover:text-primary hover:decoration-primary mt-0 text-[17px] font-semibold underline decoration-neutral-100" href="/careers/archived/full-stack-engineer">Full-Stack Engineer</a><div class="text-foreground line-clamp-2 text-sm font-normal">We are looking for a Full-Stack Engineer who is passionate about building scalable, secure, and efficient web applications. The ideal candidate will have a strong understanding of both frontend and backend technologies, and the ability to work across the entire stack.</div></div></div></div><div class="font-sans"><h2 class="mt-6 text-[10px] font-medium uppercase">Love what we are doing?</h2><ul class="xs:grid-cols-2 mt-2.5 grid list-none gap-2.5 pl-0"><li><a href="https://discord.gg/dwarvesv" class="text-primary text-sm">🩷 Join our Discord Network →</a></li><li><a href="https://github.com/dwarvesf/playground" class="text-primary text-sm">🔥 Contribute to our Memo →</a></li><li><a href="https://careers.d.foundation/" class="text-primary text-sm">🤝 Join us, we are hiring →</a></li><li><a href="http://memo.d.foundation/earn/" class="text-primary text-sm">🙋 Give us a helping hand →</a></li></ul></div></div></div></main><div class="toc-space"></div></div></div><footer class="border-t-border bg-background fixed right-0 bottom-0 left-0 z-40 flex h-8 items-stretch overflow-hidden border-t px-3 py-0 text-[0.875rem] leading-[140%] font-normal tracking-[-0.0125rem]"><div class="socials flex items-center gap-x-[10px] pr-3"><a href="https://github.com/dwarvesf" target="_blank" rel="noreferrer" class="aspect-square cursor-pointer"><svg width="18" height="18" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="Plus/Github"><path id="Vector" d="M9 1.5C8.01509 1.5 7.03982 1.69399 6.12987 2.0709C5.21993 2.44781 4.39314 3.00026 3.6967 3.6967C2.29018 5.10322 1.5 7.01088 1.5 9C1.5 12.315 3.6525 15.1275 6.63 16.125C7.005 16.185 7.125 15.9525 7.125 15.75V14.4825C5.0475 14.9325 4.605 13.4775 4.605 13.4775C4.26 12.6075 3.7725 12.375 3.7725 12.375C3.09 11.91 3.825 11.925 3.825 11.925C4.575 11.9775 4.9725 12.6975 4.9725 12.6975C5.625 13.8375 6.7275 13.5 7.155 13.32C7.2225 12.8325 7.4175 12.5025 7.6275 12.315C5.9625 12.1275 4.215 11.4825 4.215 8.625C4.215 7.7925 4.5 7.125 4.9875 6.5925C4.9125 6.405 4.65 5.625 5.0625 4.6125C5.0625 4.6125 5.6925 4.41 7.125 5.3775C7.7175 5.2125 8.3625 5.13 9 5.13C9.6375 5.13 10.2825 5.2125 10.875 5.3775C12.3075 4.41 12.9375 4.6125 12.9375 4.6125C13.35 5.625 13.0875 6.405 13.0125 6.5925C13.5 7.125 13.785 7.7925 13.785 8.625C13.785 11.49 12.03 12.12 10.3575 12.3075C10.6275 12.54 10.875 12.9975 10.875 13.695V15.75C10.875 15.9525 10.995 16.1925 11.3775 16.125C14.355 15.12 16.5 12.315 16.5 9C16.5 8.01509 16.306 7.03982 15.9291 6.12987C15.5522 5.21993 14.9997 4.39314 14.3033 3.6967C13.6069 3.00026 12.7801 2.44781 11.8701 2.0709C10.9602 1.69399 9.98491 1.5 9 1.5Z" fill="#9B9B9B"></path></g></svg></a><a href="https://discord.gg/dwarvesv" target="_blank" rel="noreferrer" class="aspect-square cursor-pointer"><svg width="18" height="18" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="Discord"><path id="Union" d="M14.1919 3.95003C13.2419 3.50716 12.2133 3.18572 11.1418 3C11.1324 2.9997 11.1231 3.00146 11.1144 3.00517C11.1058 3.00887 11.0981 3.01442 11.0918 3.02143C10.9632 3.25715 10.8132 3.5643 10.7132 3.80002C9.57677 3.62859 8.42102 3.62859 7.28456 3.80002C7.18456 3.55716 7.03455 3.25715 6.89884 3.02143C6.89169 3.00715 6.87026 3 6.84883 3C5.77738 3.18572 4.75592 3.50716 3.79875 3.95003C3.79161 3.95003 3.78447 3.95717 3.77732 3.96431C1.83441 6.87154 1.29868 9.70019 1.56298 12.5003C1.56298 12.5145 1.57012 12.5288 1.58441 12.536C2.87015 13.4789 4.1059 14.0503 5.32737 14.4289C5.34879 14.436 5.37022 14.4289 5.37737 14.4146C5.66309 14.0217 5.92024 13.6074 6.14167 13.1717C6.15596 13.1431 6.14167 13.1146 6.1131 13.1074C5.70595 12.9503 5.32022 12.7646 4.94164 12.5503C4.91307 12.536 4.91307 12.4931 4.9345 12.4717C5.01307 12.4145 5.09164 12.3503 5.17022 12.2931C5.1845 12.2788 5.20593 12.2788 5.22022 12.286C7.67743 13.4074 10.3275 13.4074 12.7561 12.286C12.7704 12.2788 12.7919 12.2788 12.8061 12.2931C12.8847 12.3574 12.9633 12.4145 13.0419 12.4788C13.0704 12.5003 13.0704 12.5431 13.0347 12.5574C12.6633 12.7788 12.2704 12.9574 11.8633 13.1146C11.8347 13.1217 11.8275 13.1574 11.8347 13.1789C12.0633 13.6146 12.3204 14.0289 12.599 14.4217C12.6204 14.4289 12.6419 14.436 12.6633 14.4289C13.8919 14.0503 15.1276 13.4789 16.4134 12.536C16.4277 12.5288 16.4348 12.5145 16.4348 12.5003C16.7491 9.26446 15.9134 6.45724 14.2205 3.96431C14.2133 3.95717 14.2062 3.95003 14.1919 3.95003ZM6.51311 10.7931C5.77738 10.7931 5.16307 10.1145 5.16307 9.27875C5.16307 8.44301 5.76309 7.76442 6.51311 7.76442C7.27028 7.76442 7.87029 8.45015 7.86315 9.27875C7.86315 10.1145 7.26313 10.7931 6.51311 10.7931ZM11.4918 10.7931C10.7561 10.7931 10.1418 10.1145 10.1418 9.27875C10.1418 8.44301 10.7418 7.76442 11.4918 7.76442C12.249 7.76442 12.849 8.45015 12.8419 9.27875C12.8419 10.1145 12.249 10.7931 11.4918 10.7931Z" fill="#9B9B9B"></path></g></svg></a><a href="https://www.facebook.com/dwarvesf" target="_blank" rel="noreferrer" class="aspect-square cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24"><path fill="#9b9b9b" d="M22 12c0-5.52-4.48-10-10-10S2 6.48 2 12c0 4.84 3.44 8.87 8 9.8V15H8v-3h2V9.5C10 7.57 11.57 6 13.5 6H16v3h-2c-.55 0-1 .45-1 1v2h3v3h-3v6.95c5.05-.5 9-4.76 9-9.95"></path></svg></a><a href="https://dwarves.foundation/" target="_blank" rel="noreferrer" class="aspect-square cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24"><path fill="#9b9b9b" d="M17.9 17.39c-.26-.8-1.01-1.39-1.9-1.39h-1v-3a1 1 0 0 0-1-1H8v-2h2a1 1 0 0 0 1-1V7h2a2 2 0 0 0 2-2v-.41a7.984 7.984 0 0 1 2.9 12.8M11 19.93c-3.95-.49-7-3.85-7-7.93c0-.62.08-1.22.21-1.79L9 15v1a2 2 0 0 0 2 2m1-16A10 10 0 0 0 2 12a10 10 0 0 0 10 10a10 10 0 0 0 10-10A10 10 0 0 0 12 2"></path></svg></a><a href="mailto:team@dwarves.foundation" target="_blank" rel="noreferrer" class="aspect-square cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 36 36"><path fill="#9b9b9b" d="M32.33 6a2 2 0 0 0-.41 0h-28a2 2 0 0 0-.53.08l14.45 14.39Z" class="clr-i-solid clr-i-solid-path-1"></path><path fill="#9b9b9b" d="m33.81 7.39l-14.56 14.5a2 2 0 0 1-2.82 0L2 7.5a2 2 0 0 0-.07.5v20a2 2 0 0 0 2 2h28a2 2 0 0 0 2-2V8a2 2 0 0 0-.12-.61M5.3 28H3.91v-1.43l7.27-7.21l1.41 1.41Zm26.61 0h-1.4l-7.29-7.23l1.41-1.41l7.27 7.21Z" class="clr-i-solid clr-i-solid-path-2"></path><path fill="none" d="M0 0h36v36H0z"></path></svg></a></div><div class="authors !hidden items-center border-r border-r-[var(--border-color-light)] px-3 text-[#9b9b9b] md:flex dark:border-r-[var(--border-color)]"><span class="text-[var(--secondary-font-color-light-2)]">Dwarves Foundation</span></div><div class="filename !hidden items-center border-r border-r-[var(--border-color-light)] px-3 text-[#9b9b9b] md:flex dark:border-r-[var(--border-color)]"><span class="text-[var(--secondary-font-color-light-2)]">Memo</span></div><div class="last-updated hidden items-center px-3 text-[#9b9b9b]"><span class="text-[var(--secondary-font-color-light-2)]">© 2025</span></div></footer></div><section aria-label="Notifications alt+T" tabindex="-1" aria-live="polite" aria-relevant="additions text" aria-atomic="false"></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"directoryTree":{"/pinned":{"label":"Pinned Notes","children":{"/playbook/operations/ogif":{"label":"OGIF - Oh God It's Friday","children":{}}}},"/":{"label":"Home","children":{"/earn":{"label":"Earn","children":{"/earn/open-source":{"label":"New Brainery","children":{}},"/earn/productivity":{"label":"New Brainery","children":{}},"/earn/quality":{"label":"New Brainery","children":{}},"/earn/readme":{"label":"Open Bounties","children":{}}}},"/consulting":{"label":"Consulting","children":{"/consulting/case-study":{"label":"Case Study","children":{"/consulting/case-study/screenz-ai":{"label":"Screenz.ai","children":{}},"/consulting/case-study/kafi":{"label":"Kafi","children":{}},"/consulting/case-study/droppii":{"label":"Droppii","children":{}},"/consulting/case-study/konvoy":{"label":"Konvoy","children":{}},"/consulting/case-study/cimb":{"label":"CIMB","children":{}},"/consulting/case-study/swift":{"label":"Swift","children":{}},"/consulting/case-study/startupvn":{"label":"StartupVN","children":{}},"/consulting/case-study/open-fabric":{"label":"Open Fabric","children":{}},"/consulting/case-study/icrosschain":{"label":"iCrosschain","children":{}},"/consulting/case-study/hedge-foundation":{"label":"Hedge Foundation","children":{}},"/consulting/case-study/searchio":{"label":"Search.io","children":{}},"/consulting/case-study/tokenomy":{"label":"Tokenomy","children":{}},"/consulting/case-study/basehq":{"label":"BaseHQ","children":{}},"/consulting/case-study/momos":{"label":"Momos","children":{}},"/consulting/case-study/attrace":{"label":"Attrace","children":{}},"/consulting/case-study/setel":{"label":"Setel","children":{}},"/consulting/case-study/joinpara":{"label":"JoinPara","children":{}},"/consulting/case-study/relay":{"label":"Relay","children":{}},"/consulting/case-study/naru":{"label":"Naru","children":{}},"/consulting/case-study/mudah":{"label":"Mudah","children":{}},"/consulting/case-study/reapit":{"label":"Reapit","children":{}},"/consulting/case-study/aharooms":{"label":"Aharooms","children":{}},"/consulting/case-study/begroup":{"label":"beGroup","children":{}},"/consulting/case-study/airwatt":{"label":"AirWatt","children":{}},"/consulting/case-study/voconic":{"label":"Voconic","children":{}},"/consulting/case-study/sol":{"label":"Sol","children":{}},"/consulting/case-study/dental-marketplace":{"label":"Dental Marketplace","children":{}},"/consulting/case-study/bhd":{"label":"BHD Cinema","children":{}}}},"/consulting/market-report":{"label":"Market Report","children":{"/consulting/market-report/event-takeaways-2nd":{"label":"2nd Talks and Takeaways","children":{}},"/consulting/market-report/event-takeaways-1st":{"label":"1st Talks and Takeaways","children":{}},"/consulting/market-report/2025-28th-feb":{"label":"#9: Bybit Loses $1.5B in Hack, Claude 3.7 Sonnet Drops, and OpenArt Designs Characters","children":{}},"/consulting/market-report/2025-21th-feb":{"label":"#8: R1 1776 Goes Open-Source, Cardex Gets Hacked, and Grok-3 Debuts","children":{}},"/consulting/market-report/2025-14th-feb":{"label":"#7: 10x AI Cost Reduction, Lyft’s 2026 Robotaxi Milestone, and Solana ETF Buzz","children":{}},"/consulting/market-report/2025-7th-feb":{"label":"#6 Trending Products, DeepSeek Wave, and Ethereum Predictions","children":{}},"/consulting/market-report/2025-17th-jan":{"label":"#5 VC Trends, Blockchain Breakthroughs, and AI Innovations","children":{}},"/consulting/market-report/2025-10th-jan":{"label":"#4 AI Supercomputers, Mini AI PCs, SEA VC","children":{}},"/consulting/market-report/2025-3rd-jan":{"label":"#3 AI at CES, Wall Street Boom, Blockchain Trends","children":{}},"/consulting/market-report/2024-27th-dec":{"label":"#2 AI Talent Wars, OpenAI’s New Models, Hyperliquid","children":{}},"/consulting/market-report/2024-13th-dec":{"label":"#1 Gemini 2.0, OpenAI’s Sora,  a16z’s Predictions","children":{}}}},"/consulting/wala":{"label":"WALA","children":{"/consulting/wala/43-factory":{"label":"43 Factory","children":{}},"/consulting/wala/dzs-media":{"label":"DZS Media","children":{}},"/consulting/wala/sp-group":{"label":"SP Group","children":{}}}},"/consulting/partners-network":{"label":"Partners Network","children":{}},"/consulting/readme":{"label":"Consulting Team","children":{}}}},"/handbook":{"label":"Handbook","children":{"/handbook/navigate-changes":{"label":"Navigate changes","children":{}},"/handbook/community":{"label":"Community","children":{"/handbook/community/icy-worth":{"label":"How much is your ICY worth","children":{}},"/handbook/community/icy-swap":{"label":"How to swap ICY to BTC","children":{}},"/handbook/community/icy":{"label":"ICY","children":{}},"/handbook/community/discord":{"label":"Discord","children":{}},"/handbook/community/earn":{"label":"Earn","children":{}},"/handbook/community/radar":{"label":"Radar","children":{}},"/handbook/community/sharing":{"label":"Sharing knowledge","children":{}},"/handbook/community/showcase":{"label":"Showcase","children":{}},"/handbook/community/memo":{"label":"Memo","children":{}}}},"/handbook/guides":{"label":"Guides","children":{"/handbook/guides/check-in-at-office":{"label":"Office check-in process for earning ICY","children":{}},"/handbook/guides/leave-request":{"label":"Leave request","children":{}},"/handbook/guides/nda":{"label":"NDA \u0026 Agreements","children":{}},"/handbook/guides/configure-the-company-email":{"label":"Configure your company email","children":{}},"/handbook/guides/one-on-one-meeting":{"label":"1-on-1 meetings","children":{}},"/handbook/guides/continuing-education-allowance":{"label":"Continuing education allowance","children":{}},"/handbook/guides/reimbursement":{"label":"Reimbursement","children":{}},"/handbook/guides/email-communication-and-use":{"label":"Email use","children":{}},"/handbook/guides/password-sharing":{"label":"Password Sharing","children":{}},"/handbook/guides/asset-request":{"label":"Request an asset","children":{}},"/handbook/guides/effective-meeting":{"label":"Effective meetings","children":{}},"/handbook/guides/conduct-a-meeting":{"label":"How to conduct a meeting","children":{}}}},"/handbook/making-a-career":{"label":"Making a career","children":{}},"/handbook/as-a-community":{"label":"As a community","children":{}},"/handbook/knowledge-base":{"label":"Knowledge base","children":{}},"/handbook/stock-option-plan":{"label":"Stock option plan","children":{}},"/handbook/readme":{"label":"📔 Handbook","children":{}},"/handbook/compliance":{"label":"Compliance","children":{}},"/handbook/mma":{"label":"MMA","children":{}},"/handbook/hybrid-working":{"label":"Hybrid Working","children":{}},"/handbook/routine":{"label":"Work routine","children":{}},"/handbook/ventures":{"label":"Ventures arm","children":{}},"/handbook/purpose":{"label":"Purpose","children":{}},"/handbook/benefits-and-perks":{"label":"Benefits \u0026 perks","children":{}},"/handbook/dwarves-foundation-is-you":{"label":"You are Dwarves Foundation","children":{}},"/handbook/getting-started":{"label":"💎 Getting started","children":{}},"/handbook/how-we-hire":{"label":"How we hire","children":{}},"/handbook/how-we-spend-money":{"label":"How we spend money","children":{}},"/handbook/misc":{"label":"Misc","children":{"/handbook/misc/marketing-assets":{"label":"Marketing assets","children":{}}}},"/handbook/moonlighting":{"label":"Moonlighting","children":{}},"/handbook/places-to-work":{"label":"Places to work","children":{}},"/handbook/security-rules":{"label":"Security rules","children":{}},"/handbook/tools-and-systems":{"label":"Tools and systems","children":{}},"/handbook/what-we-stand-for":{"label":"What we stand for","children":{}},"/handbook/what-we-value":{"label":"What we value","children":{}},"/handbook/where-we-work":{"label":"Where we work","children":{}},"/handbook/who-does-what":{"label":"Who does what","children":{}},"/handbook/faq":{"label":"FAQ","children":{}},"/handbook/how-we-work":{"label":"How we work","children":{}}}},"/playground":{"label":"Playground","children":{"/playground/01_literature":{"label":"01_literature","children":{"/playground/01_literature/evolutionary-database-design":{"label":"Evolutionary Database Design: Managing Change and Scaling with the System","children":{}},"/playground/01_literature/design":{"label":"Design","children":{"/playground/01_literature/design/product-design-commentary-20241122":{"label":"Product Design Commentary #7: Hyper-personalization - How AI improves user experience personalization","children":{}},"/playground/01_literature/design/product-design-commentary-20241115":{"label":"Product Design Commentary #6: AI in Design - Cool ideas and how to make them happen","children":{}},"/playground/01_literature/design/product-design-commentary-20241101":{"label":"Product Design Commentary #5: Figma to SwiftUI (functional code) with Claude AI","children":{}},"/playground/01_literature/design/product-design-commentary-20241018":{"label":"Product Design Commentary #4: Generative AI UX design patterns","children":{}},"/playground/01_literature/design/product-design-commentary-20241011":{"label":"Product Design Commentary #3: The art of prompting in AI-human interaction","children":{}},"/playground/01_literature/design/product-design-commentary-20241004":{"label":"Product Design Commentary #2: Unpacking the sparkles icon and AI onboarding challenges","children":{}},"/playground/01_literature/design/product-design-commentary-20240927":{"label":"Product Design Commentary #1: New technologies changing UX/UI and product design","children":{}}}},"/playground/01_literature/giving-a-talk-checklist":{"label":"Giving a talk","children":{}},"/playground/01_literature/database-design-circular":{"label":"Database design Circular","children":{}},"/playground/01_literature/a-lens-to-modern-data-engineering":{"label":"A Lens to Modern Data Engineering","children":{}},"/playground/01_literature/security":{"label":"Security","children":{"/playground/01_literature/security/a-holistic-guide-to-security":{"label":"A Holistic Guide to Security","children":{}},"/playground/01_literature/security/how-i-came-up-with-our-security-standard":{"label":"How I came up with our Security Standard","children":{}}}},"/playground/01_literature/record-reward-sharing-culture":{"label":"Record and reward sharing at Dwarves","children":{}},"/playground/01_literature/designing-for-forgiveness":{"label":"Designing for Forgiveness: Creating Error-Tolerant Interfaces","children":{}},"/playground/01_literature/design-file-sharing-system-part-2-permission-and-password":{"label":"Design file-sharing system - Part 2: Permission \u0026 Password","children":{}},"/playground/01_literature/designing-a-model-with-dynamic-properties":{"label":"Designing a model with dynamic properties","children":{}},"/playground/01_literature/hybrid-search":{"label":"Evaluating search engine in RAG systems","children":{}},"/playground/01_literature/design-file-sharing-system-part-1-directory-structure":{"label":"Design file-sharing system - Part 1: Directory Structure","children":{}},"/playground/01_literature/using-foundry-for-evm-smart-contract-developement":{"label":"Using Foundry for EVM smart contract development","children":{}},"/playground/01_literature/creating-a-fully-local-search-engine-on-memo":{"label":"Building a Local Search Engine for Our Memo Website","children":{}},"/playground/01_literature/observer-pattern":{"label":"Introduce the Observer pattern and its use cases","children":{}},"/playground/01_literature/visitor-design-pattern":{"label":"Visitor design pattern, the concept, problem solution and use cases","children":{}},"/playground/01_literature/strategy-design-pattern":{"label":"Strategy design pattern, the concept, use cases and difference with the state design pattern","children":{}},"/playground/01_literature/vietnam-tech-ecosystem-report":{"label":"Vietnam Tech Ecosystem 2024 Report","children":{}},"/playground/01_literature/how-we-crafted-the-ogif-summarizer-bot-to-streamline-weekly-knowledge-sharing":{"label":"How we crafted the OGIF summarizer bot to streamline weekly knowledge-sharing","children":{}},"/playground/01_literature/feedback-mechanism":{"label":"Design feedback mechanism for LLM applications","children":{}},"/playground/01_literature/local-first-software":{"label":"Local-first Software","children":{}},"/playground/01_literature/error-handling-in-rust":{"label":"Error handling on Rust","children":{}},"/playground/01_literature/engineering":{"label":"Engineering","children":{"/playground/01_literature/engineering/backend":{"label":"Backend","children":{"/playground/01_literature/engineering/backend/bloom-filter":{"label":"Bloom Filter","children":{}},"/playground/01_literature/engineering/backend/introduction-to-crdt":{"label":"Introduction to CRDT","children":{}},"/playground/01_literature/engineering/backend/sql-sargable-queries-and-their-impact-on-database-performance":{"label":"SQL Saragable Queries and Their Impact on Database Performance","children":{}},"/playground/01_literature/engineering/backend/the-removal-of-apache-kafkas-dependency-on-zookeeper":{"label":"The removal of Apache Kafka's dependency on Zookeeper","children":{}},"/playground/01_literature/engineering/backend/sql-and-how-it-relates-to-disk-reads-and-writes":{"label":"SQL and how it relates to Disk Reads and Writes","children":{}}}},"/playground/01_literature/engineering/data":{"label":"Data","children":{"/playground/01_literature/engineering/data/data-pipeline-design-framework":{"label":"Data Pipeline Design Framework","children":{}},"/playground/01_literature/engineering/data/quick-learning-vector-database":{"label":"Quick Learning Vector Database","children":{}},"/playground/01_literature/engineering/data/mapreduce":{"label":"MapReduce","children":{}}}},"/playground/01_literature/engineering/google-data-fusion":{"label":"Google Data Fusion","children":{}},"/playground/01_literature/engineering/google-dataproc":{"label":"Google Dataproc","children":{}},"/playground/01_literature/engineering/introducing-htmx-navigating-the-advantages-and-concerns":{"label":"Introducing HTMX - Navigating the Advantages and Concerns","children":{}},"/playground/01_literature/engineering/typesafe-client-server":{"label":"Typesafe Client Server","children":{}},"/playground/01_literature/engineering/url-redirect-vs-rewrite":{"label":"URL Redirect vs. Rewrite; What’s the difference?","children":{}}}},"/playground/01_literature/template-method-design-pattern":{"label":"A Tour of Template method pattern with Golang","children":{}},"/playground/01_literature/command-pattern":{"label":"Command Pattern","children":{}},"/playground/01_literature/radix-sort":{"label":"Radix Sort","children":{}},"/playground/01_literature/state-pattern":{"label":"State Pattern","children":{}},"/playground/01_literature/dynamic-liquidity-market-a-new-form-of-concentrated-liquidity-amm-on-solana":{"label":"Dynamic Liquidity Market Maker - a new form of concentrated liquidity AMM on Solana","children":{}},"/playground/01_literature/memo-knowledge-base-meeting":{"label":"Memo Knowledge Base Meeting","children":{}},"/playground/01_literature/peep-nft":{"label":"Claim your Peeps NFT","children":{}},"/playground/01_literature/recording-flow":{"label":"How We Set Up a Recording Workflow for Dwarves Office Hours","children":{}},"/playground/01_literature/memo-publication-workflow":{"label":"Memo Publication Workflow","children":{}},"/playground/01_literature/history-of-structured-output-for-llms":{"label":"History of Structured Outputs for LLMs","children":{}},"/playground/01_literature/builder-design-pattern":{"label":"Introduce the Builder pattern and its use cases","children":{}},"/playground/01_literature/how-to-make-a-moc":{"label":"How to make a MOC","children":{}},"/playground/01_literature/prototype-design-pattern":{"label":"Going Through use cases of the prototype design pattern and it place among the creational patterns","children":{}},"/playground/01_literature/singleton-design-pattern":{"label":"A tour of Singleton design pattern with Golang","children":{}},"/playground/01_literature/echelon-x-singapore-2024-where-innovations-meet-inspiration":{"label":"Echelon X Singapore 2024: Where Innovations Meet Inspiration","children":{}},"/playground/01_literature/c4-modelling":{"label":"Breaking Down Complexity: The Role of Abstractions and UML in C4 Modelling","children":{}},"/playground/01_literature/dollar-cost-averaging":{"label":"Dollar Cost Averaging (DCA)","children":{}},"/playground/01_literature/how-i-create-content-for-multiple-platforms-at-dwarves":{"label":"How I Create Content for Multiple Platforms at Dwarves","children":{}},"/playground/01_literature/understanding-saving-investing-and-speculating-key-differences-and-strategies":{"label":"Understanding Saving, Investing, and Speculating: Key Differences and Strategies","children":{}},"/playground/01_literature/writing-content-for-multimedia-guidelines":{"label":"Writing Content for Multimedia Guidelines","children":{}},"/playground/01_literature/how-to-earn-reward-from-staking-dfg":{"label":"How to earn reward from staking DFG","children":{}},"/playground/01_literature/how-to-transfer-dfg-from-eth-to-base-for-staking":{"label":"How to bridge $DFG from Ethereum Mainnet to Base Network for staking","children":{}},"/playground/01_literature/design-less-present-more-with-deckset":{"label":"Design less, present more with Deckset","children":{}},"/playground/01_literature/level-up-your-markdown-memos":{"label":"Level Up Your Markdown Memos: Avoiding Common Pitfalls","children":{}},"/playground/01_literature/tech-canvas":{"label":"Tech Canvas","children":{}},"/playground/01_literature/how-to-recap-a-publication":{"label":"Recapping A publication","children":{}},"/playground/01_literature/lifecycle-of-a-publication":{"label":"Life cycle of a publication","children":{}},"/playground/01_literature/how-to-set-up-environment-for-editing-memo":{"label":"How to set up environment to edit memo","children":{}},"/playground/01_literature/_how-to-setup-crypto-wallet-to-withdraw-icy":{"label":"How to set up crypto wallet to withdraw ICY","children":{}},"/playground/01_literature/_how-to-withdraw-icy":{"label":"How to withdraw ICY","children":{}},"/playground/01_literature/how-to-take-better-screenshots-on-mac":{"label":"How To Take Better Screenshots On Mac","children":{}},"/playground/01_literature/how-to-push-content-on-note-d":{"label":"How to push content on memo.d.foundation","children":{}},"/playground/01_literature/labs-weekly-catchup-5":{"label":"Labs Weekly Catchup #5","children":{}},"/playground/01_literature/labs-weekly-catchup-4":{"label":"Labs Weekly Catchup #4","children":{}},"/playground/01_literature/labs-weekly-catchup-3":{"label":"Labs Weekly Catchup #3","children":{}},"/playground/01_literature/labs-weekly-catchup-2":{"label":"Labs Weekly Catchup #2","children":{}},"/playground/01_literature/labs-weekly-catchup-1":{"label":"Labs Weekly Catchup #1","children":{}},"/playground/01_literature/labs-who-we-are":{"label":"Labs - Who we are","children":{}},"/playground/01_literature/readme":{"label":"Dwarves Memo","children":{}},"/playground/01_literature/duckdb-demo-and-showcase":{"label":"DuckDB demo and showcase","children":{}},"/playground/01_literature/salary-advance":{"label":"$icy Salary Advance","children":{}},"/playground/01_literature/how-rd-contributes-to-performance-review":{"label":"How R\u0026D contributes to Performance Review","children":{}},"/playground/01_literature/knowledge-journey":{"label":"Knowledge Journey","children":{}},"/playground/01_literature/labs-new-member-onboarding":{"label":"Labs - New Member Onboarding","children":{}},"/playground/01_literature/labs-roadmap-nov-23-update":{"label":"Labs Roadmap (Nov 23 update)","children":{}},"/playground/01_literature/labs-topic-proposal-progress-tracking":{"label":"Labs - Topic proposal \u0026 progress tracking","children":{}},"/playground/01_literature/labs-x-consulting-workflow":{"label":"Labs x Consulting Workflow","children":{}},"/playground/01_literature/reward-model-nomination":{"label":"Reward Model \u0026 Nomination","children":{}},"/playground/01_literature/our-view-on-fullstack-engineering":{"label":"Our View On Fullstack Engineering","children":{}},"/playground/01_literature/adoption-of-pnpm":{"label":"Adoption Of Pnpm","children":{}},"/playground/01_literature/working-on-a-project-interview-assessment-at-dwarves":{"label":"Working On A Project Interview Assessment At Dwarves","children":{}},"/playground/01_literature/how-we-created-an-ai-powered-interview-system-using-openais-chatgpt":{"label":"How We Created An AI Powered Interview System Using Openais Chatgpt","children":{}},"/playground/01_literature/easy-prompt-engineering-for-business-use-and-mitigating-risks-in-llms":{"label":"Easy Prompt Engineering For Business Use And Mitigating Risks In Llms","children":{}},"/playground/01_literature/exploring-machine-learning-approaches-for-fine-tuning-llama-models":{"label":"Exploring Machine Learning Approaches For Fine Tuning Llama Models","children":{}},"/playground/01_literature/managing-dataflow-and-sql-database-with-concurrency-control":{"label":"Managing Dataflow And Sql Database With Concurrency Control","children":{}},"/playground/01_literature/choosing-the-right-javascript-framework-a-deep-dive-into-react-vs-angular-vs-vue":{"label":"Choosing The Right Javascript Framework A Deep Dive Into React Vs Angular Vs Vue","children":{}},"/playground/01_literature/design-system-for-layer-2-using-zk-rollup":{"label":"Design System For Layer 2 Using Zk Rollup","children":{}},"/playground/01_literature/lessons-learned-from-being-a-part-of-corporate-micro-frontend-implementation":{"label":"Lessons Learned From Being A Part Of Corporate Micro Frontend Implementation","children":{}},"/playground/01_literature/cost-of-react-native":{"label":"Cost Of React Native","children":{}},"/playground/01_literature/lessons-learned-from-concurrency-practices-in-blockchain-projects":{"label":"Lessons Learned From Concurrency Practices In Blockchain Projects","children":{}},"/playground/01_literature/database-designs-for-multilingual-apps":{"label":"Database Designs For Multilingual Apps","children":{}},"/playground/01_literature/accelerate-project-initiation-with-advanced-nextjs-boilerplate-react-toolkit":{"label":"Accelerate Project Initiation With Advanced Nextjs Boilerplate React Toolkit","children":{}},"/playground/01_literature/how-blue-green-deployment-helped-mochi":{"label":"How Blue Green Deployment Helped Mochi","children":{}},"/playground/01_literature/i18n-frontend-guideline":{"label":"I18n Frontend Guideline","children":{}},"/playground/01_literature/radio-talk-61-monorepo":{"label":"Radio Talk 61 Monorepo","children":{}},"/playground/01_literature/from-multi-repo-to-monorepo-a-case-study-with-nghenhan-turbo-monorepo":{"label":"From Multi Repo To Monorepo A Case Study With Nghenhan Turbo Monorepo","children":{}},"/playground/01_literature/radio-talk-60-blue-green-deployment":{"label":"Radio Talk 60 Blue Green Deployment","children":{}},"/playground/01_literature/growth-is-our-universal-language":{"label":"Growth Is Our Universal Language","children":{}},"/playground/01_literature/the-key-of-security-mechanisms-in-tackling-cyber-threats":{"label":"The Key Of Security Mechanisms In Tackling Cyber Threats","children":{}},"/playground/01_literature/responsibility":{"label":"Responsibility","children":{}},"/playground/01_literature/configure-the-company-email":{"label":"Configure The Company Email","children":{}},"/playground/01_literature/tech-event-in-the-latest-transforming-healthcare-with-technology":{"label":"Tech Event In The Latest Transforming Healthcare With Technology","children":{}},"/playground/01_literature/from-data-to-backend-an-apprentice-sharing":{"label":"From Data To Backend An Apprentice Sharing","children":{}},"/playground/01_literature/data-analyst-in-retail-trading":{"label":"Data Analyst In Retail Trading","children":{}},"/playground/01_literature/passing-the-probation-get-3-upvotes":{"label":"Passing The Probation Get 3 Upvotes","children":{}},"/playground/01_literature/react-native-new-architecture":{"label":"React Native New Architecture","children":{}},"/playground/01_literature/writing":{"label":"Writing","children":{"/playground/01_literature/writing/state-explain-link":{"label":"State, Explain, Link - An all-purpose writing technique","children":{}}}},"/playground/01_literature/dwarves-radio-talk-17-conduct-a-1-1-session":{"label":"Dwarves Radio Talk 17 Conduct A 1 1 Session","children":{}},"/playground/01_literature/dwarves-radio-talk-16-run-an-effective-performance-review":{"label":"Dwarves Radio Talk 16 Run An Effective Performance Review","children":{}},"/playground/01_literature/understanding-an-application-design":{"label":"Understanding An Application Design","children":{}},"/playground/01_literature/sql-practices-orm-vs-plain-sql":{"label":"Sql Practices Orm Vs Plain Sql","children":{}},"/playground/01_literature/what-i-learned-on-design-thinking-and-software-development":{"label":"What I Learned On Design Thinking And Software Development","children":{}},"/playground/01_literature/six-things-i-extracted-from-design-thinking":{"label":"Six Things I Extracted From Design Thinking","children":{}},"/playground/01_literature/gitflow-pull-request":{"label":"Gitflow Pull Request","children":{}},"/playground/01_literature/git-commit-message-convention":{"label":"Git Commit Message Convention","children":{}},"/playground/01_literature/are-we-really-engineers":{"label":"Are We Really Engineers","children":{}},"/playground/01_literature/how-we-setup-cicd":{"label":"How We Setup Cicd","children":{}},"/playground/01_literature/getting-started-with-webflow":{"label":"Getting Started With Webflow","children":{}},"/playground/01_literature/ui-design-best-practices-dwarves":{"label":"Ui Design Best Practices Dwarves","children":{}},"/playground/01_literature/xpc-services-on-macos-app-using-swift":{"label":"Xpc Services On Macos App Using Swift","children":{}},"/playground/01_literature/the-correct-way-to-build-kpi":{"label":"The Correct Way To Build Kpi","children":{}},"/playground/01_literature/domain-insight-research-framework":{"label":"Domain Insight Research Framework","children":{}},"/playground/01_literature/asking-as-a-junior":{"label":"Asking As A Junior","children":{}},"/playground/01_literature/infinite-image-gallery-with-r3f-an-approach":{"label":"Infinite Image Gallery With R3f An Approach","children":{}},"/playground/01_literature/market":{"label":"Market","children":{"/playground/01_literature/market/an-overview-of-micro-investment-in-real-estate":{"label":"An Overview Of Micro Investment In Real Estate","children":{}}}},"/playground/01_literature/grid-and-layout":{"label":"Grid And Layout","children":{}},"/playground/01_literature/startups-vs-junior-designers":{"label":"Startups Vs Junior Designers","children":{}},"/playground/01_literature/gestalt-principles-in-ui-design":{"label":"Gestalt Principles In Ui Design","children":{}},"/playground/01_literature/aarrr-framework-in-a-nutshell":{"label":"AARRR Framework In A Nutshell","children":{}},"/playground/01_literature/a-quick-intro-to-webassembly":{"label":"A Quick Intro To Webassembly","children":{}},"/playground/01_literature/sdk-event-sourcing":{"label":"Sdk Event Sourcing","children":{}},"/playground/01_literature/software-development-life-cycle-101":{"label":"Software Development Life Cycle 101","children":{}},"/playground/01_literature/introduce-to-dwarves-memo":{"label":"Introduce To Dwarves Memo","children":{}},"/playground/01_literature/daemons-and-services-programming-guide":{"label":"Daemons And Services Programming Guide","children":{}},"/playground/01_literature/remote-moderated-usability-testing":{"label":"Remote Moderated Usability Testing","children":{}},"/playground/01_literature/an-alternative-to-tm":{"label":"An Alternative To Tm","children":{}},"/playground/01_literature/how-a-design-system-work":{"label":"How A Design System Work","children":{}},"/playground/01_literature/software-modeling":{"label":"Software Modeling","children":{}},"/playground/01_literature/reusability-in-software-development":{"label":"Reusability In Software Development","children":{}},"/playground/01_literature/blockchain-for-designers":{"label":"Blockchain For Designers","children":{}},"/playground/01_literature/design-better-mobile-application":{"label":"Design Better Mobile Application","children":{}},"/playground/01_literature/introduction-to-software-craftsmanship":{"label":"Introduction To Software Craftsmanship","children":{}},"/playground/01_literature/domain-glossary":{"label":"Domain Glossary","children":{}},"/playground/01_literature/architecture-decision-record":{"label":"Architecture Decision Record","children":{}},"/playground/01_literature/build-an-assistant-on-the-terminal":{"label":"Build An Assistant On The Terminal","children":{}},"/playground/01_literature/create-circular-text-using-swiftui":{"label":"Create Circular Text Using Swiftui","children":{}},"/playground/01_literature/draw-watch-face-using-swiftui":{"label":"Draw Watch Face Using Swiftui","children":{}},"/playground/01_literature/applied-security-basis":{"label":"Applied Security Basis","children":{}},"/playground/01_literature/swiftui":{"label":"Swiftui","children":{}},"/playground/01_literature/bunk-license-check":{"label":"Bunk License Check","children":{}},"/playground/01_literature/well-crafted-software":{"label":"Well Crafted Software","children":{}},"/playground/01_literature/objective":{"label":"Objective","children":{}},"/playground/01_literature/project-management":{"label":"Project Management","children":{}},"/playground/01_literature/kubernetes-helm-101":{"label":"Kubernetes Helm 101","children":{}},"/playground/01_literature/what-is-kubernetes":{"label":"What Is Kubernetes","children":{}},"/playground/01_literature/traits-to-assess-during-an-interview":{"label":"Traits To Assess During An Interview","children":{}},"/playground/01_literature/recursively-export-file-pattern-in-javascript-es6-application":{"label":"Recursively Export File Pattern In Javascript Es6 Application","children":{}},"/playground/01_literature/playaround-with-clojure":{"label":"Playaround With Clojure","children":{}},"/playground/01_literature/playaround-with-rust":{"label":"Playaround With Rust","children":{}},"/playground/01_literature/overview-on-broker-pattern-in-distributed-system":{"label":"Overview On Broker Pattern In Distributed System","children":{}},"/playground/01_literature/fundamental-end-to-end-frontend-testing-with-cypress":{"label":"Fundamental End To End Frontend Testing With Cypress","children":{}},"/playground/01_literature/uidynamicanimator":{"label":"Uidynamicanimator","children":{}},"/playground/01_literature/reproduce-apple-find-me-bottom-menu-view":{"label":"Reproduce Apple Find Me Bottom Menu View","children":{}},"/playground/01_literature/build-a-passcode-view-with-swift":{"label":"Build A Passcode View With Swift","children":{}},"/playground/01_literature/istio":{"label":"Istio","children":{}},"/playground/01_literature/different-ways-to-test-react-application":{"label":"Different Ways To Test React Application","children":{}},"/playground/01_literature/federated-byzantine":{"label":"Federated Byzantine","children":{}},"/playground/01_literature/fabric-hyperledger-architecture-explanation":{"label":"Fabric Hyperledger Architecture Explanation","children":{}},"/playground/01_literature/setup-react-project-with-webpack-and-babel":{"label":"Setup React Project With Webpack And Babel","children":{}},"/playground/01_literature/split-and-reuse-code-in-react-application":{"label":"Split And Reuse Code In React Application","children":{}},"/playground/01_literature/hoc-renderprops-and-hook-in-reactjs":{"label":"Hoc Renderprops And Hook In Reactjs","children":{}},"/playground/01_literature/resource-assignment":{"label":"Resource Assignment","children":{}},"/playground/01_literature/the-principle-of-spacing-in-ui-design-part-2":{"label":"The Principle Of Spacing In Ui Design Part 2","children":{}},"/playground/01_literature/finite-state-machine":{"label":"Finite State Machine","children":{}},"/playground/01_literature/card-sorting-and-a-glimpse-at-experimental-sorting-session":{"label":"Card Sorting And A Glimpse At Experimental Sorting Session","children":{}},"/playground/01_literature/about-devops":{"label":"About Devops","children":{}},"/playground/01_literature/our-daily-standup-format":{"label":"Our Daily Standup Format","children":{}},"/playground/01_literature/good-design-understanding":{"label":"Good Design Understanding","children":{}},"/playground/01_literature/competency-mapping":{"label":"Competency Mapping","children":{}},"/playground/01_literature/design-resourcestools":{"label":"Design Resourcestools","children":{}},"/playground/01_literature/design-tips-tricks":{"label":"Design Tips Tricks","children":{}},"/playground/01_literature/design-system":{"label":"Design System","children":{}},"/playground/01_literature/design-workflow":{"label":"Design Workflow","children":{}},"/playground/01_literature/three-levels-of-design":{"label":"Three Levels Of Design","children":{}},"/playground/01_literature/ui-design-fundamental":{"label":"Ui Design Fundamental","children":{}},"/playground/01_literature/ux-model":{"label":"Ux Model","children":{}},"/playground/01_literature/the-principle-of-spacing-in-ui-design-part-1":{"label":"The Principle Of Spacing In Ui Design Part 1","children":{}},"/playground/01_literature/be-careful-with-your-code-splitting-setup":{"label":"Be Careful With Your Code Splitting Setup","children":{}},"/playground/01_literature/qc-onboarding":{"label":"Qc Onboarding","children":{}},"/playground/01_literature/dcos-series-part-5-gitlab":{"label":"Dcos Series Part 5 Gitlab","children":{}},"/playground/01_literature/dcos-series-part-4-deploy-simple-application-with-backend-database":{"label":"Dcos Series Part 4 Deploy Simple Application With Backend Database","children":{}},"/playground/01_literature/dcos-series-part-3-service-discovery-and-load-balancing":{"label":"Dcos Series Part 3 Service Discovery And Load Balancing","children":{}},"/playground/01_literature/dcos-series-part-2-deploy-simple-applications":{"label":"Dcos Series Part 2 Deploy Simple Applications","children":{}},"/playground/01_literature/dcos-series-part-1-quick-look-installation":{"label":"Dcos Series Part 1 Quick Look Installation","children":{}},"/playground/01_literature/skill-of-software-engineer":{"label":"Skill Of Software Engineer","children":{}},"/playground/01_literature/docker-registry":{"label":"Docker Registry","children":{}},"/playground/01_literature/agile-using-clickup-as-agile-management-tool":{"label":"Agile Using Clickup As Agile Management Tool","children":{}},"/playground/01_literature/agile-how-to-create-clickup-tickets":{"label":"Agile How To Create Clickup Tickets","children":{}},"/playground/01_literature/considering-factors-for-performance-evaluating":{"label":"Considering Factors For Performance Evaluating","children":{}},"/playground/01_literature/how-we-contribute-to-homebrew":{"label":"How We Contribute To Homebrew","children":{}},"/playground/01_literature/the-10x-engineer":{"label":"The 10x Engineer","children":{}},"/playground/01_literature/definition-of-done":{"label":"Definition Of Done","children":{}},"/playground/01_literature/estimation-in-agile":{"label":"Estimation In Agile","children":{}},"/playground/01_literature/sprint-lifecycle":{"label":"Sprint Lifecycle","children":{}},"/playground/01_literature/remote-prepare-and-get-going":{"label":"Remote Prepare And Get Going","children":{}},"/playground/01_literature/docker-microcontainers":{"label":"Docker Microcontainers","children":{}}}},"/playground/00_fleeting":{"label":"00_fleeting","children":{"/playground/00_fleeting/automata":{"label":"Automata","children":{}},"/playground/00_fleeting/error-handling-patterns":{"label":"Error Handling Patterns","children":{}},"/playground/00_fleeting/founder-liquidity":{"label":"Founder Liquidity","children":{}},"/playground/00_fleeting/why-hollywood-and-gaming-struggle-with-ai":{"label":"Why Hollywood and gaming struggle with AI","children":{}},"/playground/00_fleeting/subscription-pricing-models":{"label":"Subscription Pricing Models","children":{}},"/playground/00_fleeting/erlang-fsm":{"label":"Erlang Finite State Machine","children":{}},"/playground/00_fleeting/rust-trait":{"label":"Rust Trait","children":{}},"/playground/00_fleeting/explaining-gradient-descent-in-machine-learning-with-a-simple-analogy":{"label":"Explaining Gradient Descent in Machine Learning with a simple analogy","children":{}},"/playground/00_fleeting/organize-team-know-how-with-zettelkasten-method":{"label":"Organize team know-how with Zettelkasten Method","children":{}},"/playground/00_fleeting/how-to-talk-to-chatgpt-effectively":{"label":"How to talk to ChatGPT effectively","children":{}},"/playground/00_fleeting/icy-in-2024":{"label":"$icy in 2024","children":{}},"/playground/00_fleeting/icy-dfg":{"label":"💠 df protocol, $icy and $dfg","children":{}},"/playground/00_fleeting/202302281019-case-study-write-heavy-scalable-and-reliable-inventory-platform":{"label":"Case study: Write-heavy scalable and reliable inventory platform","children":{}},"/playground/00_fleeting/202301191192-multi-column-index-in-db":{"label":"Multi-column index in DB","children":{}},"/playground/00_fleeting/202301091379-invoking-component-functions-in-react":{"label":"Invoking component functions in React","children":{}},"/playground/00_fleeting/202212131609-how-to-deal-with-technical-debt-in-scrum":{"label":"How to deal with technical debt in Scrum","children":{}},"/playground/00_fleeting/202211141287-go-json-parsing":{"label":"Go JSON parser: number \u003c-\u003e interface","children":{}},"/playground/00_fleeting/202211141513-materialized-view-pattern":{"label":"Materialized View Pattern","children":{}},"/playground/00_fleeting/202211081111-error-messaging":{"label":"Error Messaging","children":{}},"/playground/00_fleeting/202210172128-sign-in-form-best-practices":{"label":"Sign-in Form Best Practices","children":{}},"/playground/00_fleeting/202210162154-the-best-of-css-tldr":{"label":"The Best of CSS TLDR","children":{}},"/playground/00_fleeting/202210150019-migration-planning":{"label":"Migration Planning","children":{}},"/playground/00_fleeting/202210131000-behavior-driven-development":{"label":"Behavior Driven Development","children":{}},"/playground/00_fleeting/202210131516-react-fiber":{"label":"React Fiber","children":{}},"/playground/00_fleeting/202210122014-forward-proxy":{"label":"Forward Proxy","children":{}}}},"/playground/_radar":{"label":"_radar","children":{"/playground/_radar/readme":{"label":"Tech Radar","children":{}},"/playground/_radar/apache-spark":{"label":"Apache Spark","children":{}},"/playground/_radar/ant-design":{"label":"Ant Design","children":{}},"/playground/_radar/apache-kafka":{"label":"Apache Kafka","children":{}},"/playground/_radar/argocd":{"label":"Argocd","children":{}},"/playground/_radar/astro":{"label":"Astro","children":{}},"/playground/_radar/backstage":{"label":"Backstage","children":{}},"/playground/_radar/blue-green-deployment":{"label":"Blue Green Deployment","children":{}},"/playground/_radar/browserstack":{"label":"Browserstack","children":{}},"/playground/_radar/carbon":{"label":"Carbon","children":{}},"/playground/_radar/chatgpt-assistance":{"label":"Chatgpt Assistance","children":{}},"/playground/_radar/chromatic":{"label":"Chromatic","children":{}},"/playground/_radar/clickhouse":{"label":"Clickhouse","children":{}},"/playground/_radar/cloudflare-workers":{"label":"Cloudflare Workers","children":{}},"/playground/_radar/codecept":{"label":"Codecept","children":{}},"/playground/_radar/commitlint":{"label":"Commitlint","children":{}},"/playground/_radar/copilot":{"label":"Copilot","children":{}},"/playground/_radar/cucumber":{"label":"Cucumber","children":{}},"/playground/_radar/cypress":{"label":"Cypress","children":{}},"/playground/_radar/dapr":{"label":"Dapr","children":{}},"/playground/_radar/deno":{"label":"Deno","children":{}},"/playground/_radar/detox":{"label":"Detox","children":{}},"/playground/_radar/devcontainers":{"label":"Devcontainers","children":{}},"/playground/_radar/devpod":{"label":"Devpod","children":{}},"/playground/_radar/dora-metrics":{"label":"Dora Metrics","children":{}},"/playground/_radar/duckdb":{"label":"Duckdb","children":{}},"/playground/_radar/earthly":{"label":"Earthly","children":{}},"/playground/_radar/elixir-umbrella-project":{"label":"Elixir Umbrella Project","children":{}},"/playground/_radar/elixir":{"label":"Elixir","children":{}},"/playground/_radar/erlang":{"label":"Erlang","children":{}},"/playground/_radar/error-logging-convention":{"label":"Error Logging Convention","children":{}},"/playground/_radar/eslint":{"label":"Eslint","children":{}},"/playground/_radar/event-sourcing":{"label":"Event Sourcing","children":{}},"/playground/_radar/excalidraw":{"label":"Excalidraw","children":{}},"/playground/_radar/expo":{"label":"Expo","children":{}},"/playground/_radar/figma":{"label":"Figma","children":{}},"/playground/_radar/formal-verification":{"label":"Formal Verification","children":{}},"/playground/_radar/fullstack-tracing":{"label":"Fullstack Tracing","children":{}},"/playground/_radar/gestalt-principle":{"label":"Gestalt Principle","children":{}},"/playground/_radar/github-actions":{"label":"Github Actions","children":{}},"/playground/_radar/golang":{"label":"Golang","children":{}},"/playground/_radar/grafana":{"label":"Grafana","children":{}},"/playground/_radar/graylog":{"label":"Graylog","children":{}},"/playground/_radar/headless-ui":{"label":"Headless Ui","children":{}},"/playground/_radar/hoppscotch":{"label":"Hoppscotch","children":{}},"/playground/_radar/ipfs":{"label":"Ipfs","children":{}},"/playground/_radar/jotai":{"label":"Jotai","children":{}},"/playground/_radar/k6":{"label":"K6","children":{}},"/playground/_radar/k9s":{"label":"K9s","children":{}},"/playground/_radar/kaniko":{"label":"Kaniko","children":{}},"/playground/_radar/kotlin":{"label":"Kotlin","children":{}},"/playground/_radar/kubeseal-sops":{"label":"Kubeseal Sops","children":{}},"/playground/_radar/ladle":{"label":"Ladle","children":{}},"/playground/_radar/langchain":{"label":"Langchain","children":{}},"/playground/_radar/large-language-model-llm":{"label":"Large Language Model LLM","children":{}},"/playground/_radar/loki":{"label":"Loki","children":{}},"/playground/_radar/makefile":{"label":"Makefile","children":{}},"/playground/_radar/micro-frontend":{"label":"Micro Frontend","children":{}},"/playground/_radar/monorepo":{"label":"Monorepo","children":{}},"/playground/_radar/msw":{"label":"Msw","children":{}},"/playground/_radar/n6n":{"label":"N6n","children":{}},"/playground/_radar/nestjs":{"label":"Nestjs","children":{}},"/playground/_radar/netlify":{"label":"Netlify","children":{}},"/playground/_radar/newrelic":{"label":"Newrelic","children":{}},"/playground/_radar/nextjs":{"label":"Nextjs","children":{}},"/playground/_radar/nodejs":{"label":"Nodejs","children":{}},"/playground/_radar/nostrum":{"label":"Nostrum","children":{}},"/playground/_radar/nx":{"label":"Nx","children":{}},"/playground/_radar/orval":{"label":"Orval","children":{}},"/playground/_radar/page-object-model":{"label":"Page Object Model","children":{}},"/playground/_radar/partytown":{"label":"Partytown","children":{}},"/playground/_radar/phaser":{"label":"Phaser","children":{}},"/playground/_radar/phoenix":{"label":"Phoenix","children":{}},"/playground/_radar/playwright":{"label":"Playwright","children":{}},"/playground/_radar/pnpm":{"label":"Pnpm","children":{}},"/playground/_radar/progressive-delivery":{"label":"Progressive Delivery","children":{}},"/playground/_radar/prometheus":{"label":"Prometheus","children":{}},"/playground/_radar/prompt-engineering":{"label":"Prompt Engineering","children":{}},"/playground/_radar/qwik":{"label":"Qwik","children":{}},"/playground/_radar/radix-ui":{"label":"Radix Ui","children":{}},"/playground/_radar/react-hook-form":{"label":"React Hook Form","children":{}},"/playground/_radar/react-llm":{"label":"React LLM","children":{}},"/playground/_radar/react-native":{"label":"React Native","children":{}},"/playground/_radar/react-query":{"label":"React Query","children":{}},"/playground/_radar/react-server-component":{"label":"React Server Component","children":{}},"/playground/_radar/react-testing-library":{"label":"React Testing Library","children":{}},"/playground/_radar/react":{"label":"React","children":{}},"/playground/_radar/reinforcement-learning-from-human-feedback":{"label":"Reinforcement Learning From Human Feedback","children":{}},"/playground/_radar/remix":{"label":"Remix","children":{}},"/playground/_radar/replayio":{"label":"Replayio","children":{}},"/playground/_radar/reverse-engineering":{"label":"Reverse Engineering","children":{}},"/playground/_radar/rust":{"label":"Rust","children":{}},"/playground/_radar/selenium":{"label":"Selenium","children":{}},"/playground/_radar/semantic-release-auto-release":{"label":"Semantic Release Auto Release","children":{}},"/playground/_radar/sentry":{"label":"Sentry","children":{}},"/playground/_radar/serverlessq":{"label":"Serverlessq","children":{}},"/playground/_radar/solidity":{"label":"Solidity","children":{}},"/playground/_radar/solidjs":{"label":"Solidjs","children":{}},"/playground/_radar/stern":{"label":"Stern","children":{}},"/playground/_radar/svelte":{"label":"Svelte","children":{}},"/playground/_radar/swagger":{"label":"Swagger","children":{}},"/playground/_radar/swift-ui":{"label":"Swift Ui","children":{}},"/playground/_radar/swift":{"label":"Swift","children":{}},"/playground/_radar/swr":{"label":"Swr","children":{}},"/playground/_radar/tailwindcss":{"label":"Tailwindcss","children":{}},"/playground/_radar/tauri":{"label":"Tauri","children":{}},"/playground/_radar/team-topologies":{"label":"Team Topologies","children":{}},"/playground/_radar/timeline":{"label":"Timeline","children":{"/playground/_radar/timeline/create-working-devcontainer-for-nextjs-boilerplate":{"label":"Create Working Devcontainer For Nextjs Boilerplate","children":{}},"/playground/_radar/timeline/open-source-devpod-paperspace-provider":{"label":"Open Source Devpod Paperspace Provider","children":{}},"/playground/_radar/timeline/create-working-devcontainer-for-go-api":{"label":"Create Working Devcontainer For Go Api","children":{}},"/playground/_radar/timeline/fe-23-training-type-safe-client-server":{"label":"Fe 23 Training Type Safe Client Server","children":{}},"/playground/_radar/timeline/first-introduced-use-of-duckdb-in-consolelabs-logconsoleso":{"label":"First Introduced Use Of Duckdb In Consolelabs Logconsoleso","children":{}},"/playground/_radar/timeline/add-type-safe-client-server-support-for-next-boilerplate":{"label":"Add Type Safe Client Server Support For Next Boilerplate","children":{}},"/playground/_radar/timeline/building-reliable-apps-sentry-and-distributed-tracing-for-effective-monitoring":{"label":"Building Reliable Apps Sentry And Distributed Tracing For Effective Monitoring","children":{}},"/playground/_radar/timeline/an-engineering-story-map-for-llms":{"label":"An Engineering Story Map For Llms","children":{}},"/playground/_radar/timeline/exploring-resumable-server-side-rendering-with-qwik":{"label":"Exploring Resumable Server Side Rendering With Qwik","children":{}},"/playground/_radar/timeline/challenge-faced-when-researching-rlhf-with-open-assistant":{"label":"Challenge Faced When Researching Rlhf With Open Assistant","children":{}},"/playground/_radar/timeline/embracing-go-1210s-slog-a-unified-logging-interface-with-benchmarks-against-zerolog-and-zap":{"label":"Embracing Go 1210s Slog A Unified Logging Interface With Benchmarks Against Zerolog And Zap","children":{}},"/playground/_radar/timeline/adoption-of-pnpm":{"label":"Adoption Of Pnpm","children":{}},"/playground/_radar/timeline/diagnosing-and-resolving-performance-issues-with-pprof-and-trace-in-go":{"label":"Diagnosing And Resolving Performance Issues With Pprof And Trace In Go","children":{}},"/playground/_radar/timeline/migrate-yarn-to-pnpm-in-fortress":{"label":"Migrate Yarn To Pnpm In Fortress","children":{}},"/playground/_radar/timeline/level-up-your-testing-game-harnessing-gomock-for-unbeatable-unit-testing-in-go":{"label":"Level Up Your Testing Game Harnessing Gomock For Unbeatable Unit Testing In Go","children":{}},"/playground/_radar/timeline/migrate-yarn-to-pnpm-in-nghe-nhan-droppii":{"label":"Migrate Yarn To Pnpm In Nghe Nhan Droppii","children":{}},"/playground/_radar/timeline/common-design-patterns-in-golang-part-1":{"label":"Common Design Patterns In Golang Part 1","children":{}},"/playground/_radar/timeline/go-training-2023-from-basic-to-advanced":{"label":"Go Training 2023 From Basic To Advanced","children":{}},"/playground/_radar/timeline/llms-accuracy-self-refinement":{"label":"Llms Accuracy Self Refinement","children":{}},"/playground/_radar/timeline/adversarial-prompting":{"label":"Adversarial Prompting","children":{}},"/playground/_radar/timeline/chunking-strategies-to-overcome-context-limitation-in-llm":{"label":"Chunking Strategies To Overcome Context Limitation In LLM","children":{}},"/playground/_radar/timeline/dealing-with-long-term-memory-of-chatbot":{"label":"Dealing With Long Term Memory Of Chatbot","children":{}},"/playground/_radar/timeline/error-handling-and-failure-management-in-a-go-system":{"label":"Error Handling And Failure Management In A Go System","children":{}},"/playground/_radar/timeline/migrate-yarn-to-pnpm-in-nextjs-boilerplate":{"label":"Migrate Yarn To Pnpm In Nextjs Boilerplate","children":{}},"/playground/_radar/timeline/lessons-learned-building-an-llm-chatbot-a-case-study":{"label":"Lessons Learned Building An LLM Chatbot A Case Study","children":{}},"/playground/_radar/timeline/foundation-model":{"label":"Foundation Model","children":{}},"/playground/_radar/timeline/integrate-zod-to-nextjs-boilerplate":{"label":"Integrate Zod To Nextjs Boilerplate","children":{}},"/playground/_radar/timeline/llm-query-caching":{"label":"LLM Query Caching","children":{}},"/playground/_radar/timeline/build-your-chatbot-with-open-source-large-language-models":{"label":"Build Your Chatbot With Open Source Large Language Models","children":{}},"/playground/_radar/timeline/integrate-playwright-x-codecept-with-discord":{"label":"Integrate Playwright X Codecept With Discord","children":{}},"/playground/_radar/timeline/overcoming-distributed-system-challenges-using-golang":{"label":"Overcoming Distributed System Challenges Using Golang","children":{}},"/playground/_radar/timeline/easy-prompt-engineering-for-business-use-and-mitigating-risks-in-llms":{"label":"Easy Prompt Engineering For Business Use And Mitigating Risks In Llms","children":{}},"/playground/_radar/timeline/migrate-headlessui-to-radixui":{"label":"Migrate Headlessui To Radixui","children":{}},"/playground/_radar/timeline/llm-101-enhance-developer-productivity":{"label":"LLM 101 Enhance Developer Productivity","children":{}},"/playground/_radar/timeline/approaches-to-manage-concurrent-workloads-like-worker-pools-and-pipelines":{"label":"Approaches To Manage Concurrent Workloads Like Worker Pools And Pipelines","children":{}},"/playground/_radar/timeline/lessons-learned-from-being-a-part-of-corporate-microfrontend-implementation":{"label":"Lessons Learned From Being A Part Of Corporate Microfrontend Implementation","children":{}},"/playground/_radar/timeline/migrate-yarn-to-pnpm-in-react-toolkit":{"label":"Migrate Yarn To Pnpm In React Toolkit","children":{}},"/playground/_radar/timeline/lessons-learned-from-concurrency-practices-in-blockchain-projects":{"label":"Lessons Learned From Concurrency Practices In Blockchain Projects","children":{}},"/playground/_radar/timeline/applying-mock-service-worker-msw-for-seamless-web-development":{"label":"Applying Mock Service Worker Msw For Seamless Web Development","children":{}},"/playground/_radar/timeline/integrate-playwright-to-run-e2e-test-with-fortress":{"label":"Integrate Playwright To Run E2e Test With Fortress","children":{}},"/playground/_radar/timeline/from-multi-repo-to-monorepo-a-case-study-with-nghenhan":{"label":"From Multi Repo To Monorepo A Case Study With Nghenhan","children":{}},"/playground/_radar/timeline/case-study-how-blue-green-deployment-help-mochi":{"label":"Case Study How Blue Green Deployment Help Mochi","children":{}},"/playground/_radar/timeline/develop-codecept-to-integrate-with-fortress":{"label":"Develop Codecept To Integrate With Fortress","children":{}},"/playground/_radar/timeline/case-study-from-multiple-repo-to-monorepo-at-nghe-nhan":{"label":"Case Study From Multiple Repo To Monorepo At Nghe Nhan","children":{}},"/playground/_radar/timeline/apply-blue-green-deployment-to-mochi":{"label":"Apply Blue Green Deployment To Mochi","children":{}},"/playground/_radar/timeline/memo-blue-green-deployment":{"label":"Memo Blue Green Deployment","children":{}},"/playground/_radar/timeline/brainery-blue-green-deployment":{"label":"Brainery Blue Green Deployment","children":{}},"/playground/_radar/timeline/brainery-validation-with-zod":{"label":"Brainery Validation With Zod","children":{}},"/playground/_radar/timeline/brainery-progressive-delivery":{"label":"Brainery Progressive Delivery","children":{}},"/playground/_radar/timeline/memo-react-native-new-architecture":{"label":"Memo React Native New Architecture","children":{}},"/playground/_radar/timeline/backend-for-call-requests-to-binance-and-get-data-from-multiple-platforms":{"label":"Backend For Call Requests To Binance And Get Data From Multiple Platforms","children":{}},"/playground/_radar/timeline/create-backend-monorepo-to-share-code-and-manage-multiple-services-in-one-repo":{"label":"Create Backend Monorepo To Share Code And Manage Multiple Services In One Repo","children":{}},"/playground/_radar/timeline/nextjs-boilerplate":{"label":"Nextjs Boilerplate","children":{}},"/playground/_radar/timeline/apply-page-object-model-structure-to-wego":{"label":"Apply Page Object Model Structure To Wego","children":{}},"/playground/_radar/timeline/apply-page-object-model-structure-to-aharooms":{"label":"Apply Page Object Model Structure To Aharooms","children":{}},"/playground/_radar/timeline/apply-page-object-model-structure-to-artzy":{"label":"Apply Page Object Model Structure To Artzy","children":{}},"/playground/_radar/timeline/apply-page-object-model-structure-to-sci":{"label":"Apply Page Object Model Structure To Sci","children":{}},"/playground/_radar/timeline/build-automation-for-sci":{"label":"Build Automation For Sci","children":{}},"/playground/_radar/timeline/apply-page-object-model-structure-to-basehq":{"label":"Apply Page Object Model Structure To Basehq","children":{}},"/playground/_radar/timeline/mdx-document-for":{"label":"Mdx Document For","children":{}},"/playground/_radar/timeline/develop":{"label":"Develop","children":{}},"/playground/_radar/timeline/apply-monorepos-to-repit-to-resolve-the-problem-of-consistency":{"label":"Apply Monorepos To Repit To Resolve The Problem Of Consistency","children":{}},"/playground/_radar/timeline/learn-typescript-as-a-mandatory-to-develop-reapit-foundation":{"label":"Learn Typescript As A Mandatory To Develop Reapit Foundation","children":{}},"/playground/_radar/timeline/develop-sdk-integration-demo-for-sajari":{"label":"Develop Sdk Integration Demo For Sajari","children":{}},"/playground/_radar/timeline/live-view":{"label":"Live View","children":{}},"/playground/_radar/timeline/migrate-aharooms-pms-to-typescript":{"label":"Migrate Aharooms Pms To Typescript","children":{}},"/playground/_radar/timeline/create-api-service-for-urbox-to-sync-orders-from-3rd-parties-and-manage-shipment":{"label":"Create Api Service For Urbox To Sync Orders From 3rd Parties And Manage Shipment","children":{}},"/playground/_radar/timeline/nghenhan-microservices":{"label":"Nghenhan Microservices","children":{}},"/playground/_radar/timeline/radio-talk-65-fullstack-type-safe-with-trpc":{"label":"Radio Talk 65 Fullstack Type Safe With Trpc","children":{}},"/playground/_radar/timeline/understanding-test-doubles-an-in-depth-look":{"label":"Understanding Test Doubles An In Depth Look","children":{}},"/playground/_radar/timeline/radio-talk-64-coding-best-practice-that-optimizing-go-compiler":{"label":"Radio Talk 64 Coding Best Practice That Optimizing Go Compiler","children":{}},"/playground/_radar/timeline/reward-model":{"label":"Reward Model","children":{}},"/playground/_radar/timeline/q-learning":{"label":"Q Learning","children":{}},"/playground/_radar/timeline/sum-command":{"label":"Sum Command","children":{}},"/playground/_radar/timeline/reinforcement-learning":{"label":"Reinforcement Learning","children":{}},"/playground/_radar/timeline/react-server-component":{"label":"React Server Component","children":{}},"/playground/_radar/timeline/select-vector-database-for-llm":{"label":"Select Vector Database For LLM","children":{}},"/playground/_radar/timeline/workaround-with-openais-token-limit-with-langchain":{"label":"Workaround With Openais Token Limit With Langchain","children":{}},"/playground/_radar/timeline/working-with-langchain-document-loaders":{"label":"Working With Langchain Document Loaders","children":{}},"/playground/_radar/timeline/the-cost-of-react-native":{"label":"The Cost Of React Native","children":{}},"/playground/_radar/timeline/state-of-frontend-2023-react-vs-angular-vs-vue":{"label":"State Of Frontend 2023 React Vs Angular Vs Vue","children":{}},"/playground/_radar/timeline/unit-testing-best-practices-in-golang":{"label":"Unit Testing Best Practices In Golang","children":{}},"/playground/_radar/timeline/what-is-pnpm":{"label":"What Is Pnpm","children":{}},"/playground/_radar/timeline/tackling-server-state-complexity-in-frontend-development":{"label":"Tackling Server State Complexity In Frontend Development","children":{}},"/playground/_radar/timeline/why-we-chose-our-tech-stack":{"label":"Why We Chose Our Tech Stack","children":{}},"/playground/_radar/timeline/why-micro-frontend":{"label":"Why Micro Frontend","children":{}},"/playground/_radar/timeline/radio-talk-monorepo":{"label":"Radio Talk Monorepo","children":{}},"/playground/_radar/timeline/radio-talk-blue-green-deployment":{"label":"Radio Talk Blue Green Deployment","children":{}},"/playground/_radar/timeline/radio-talk-a-demo-of-query-engine-postgresql-vs-apache-spark":{"label":"Radio Talk A Demo Of Query Engine Postgresql Vs Apache Spark","children":{}},"/playground/_radar/timeline/rnd-team-mentioned-apache-spark-as-a-solution-to-handle-query-big-data":{"label":"Rnd Team Mentioned Apache Spark As A Solution To Handle Query Big Data","children":{}},"/playground/_radar/timeline/radio-talk-engineering-health-metrics":{"label":"Radio Talk Engineering Health Metrics","children":{}},"/playground/_radar/timeline/radio-talk-nextjs-13":{"label":"Radio Talk Nextjs 13","children":{}},"/playground/_radar/timeline/radio-talk-using-nextjs-as-a-fullstack-framework":{"label":"Radio Talk Using Nextjs As A Fullstack Framework","children":{}},"/playground/_radar/timeline/use-yup-to-validate-form-values-in-droppii":{"label":"Use Yup To Validate Form Values In Droppii","children":{}},"/playground/_radar/timeline/vitejs-native-modules":{"label":"Vitejs Native Modules","children":{}},"/playground/_radar/timeline/radio-talk-introduction-to-apache-spark":{"label":"Radio Talk Introduction To Apache Spark","children":{}},"/playground/_radar/timeline/vercel-switching-their-packages-from-yarn-to-pnpm-caught-our-attention":{"label":"Vercel Switching Their Packages From Yarn To Pnpm Caught Our Attention","children":{}},"/playground/_radar/timeline/radio-talk-remix-vs-nextjs":{"label":"Radio Talk Remix Vs Nextjs","children":{}},"/playground/_radar/timeline/radio-talk-turborepo":{"label":"Radio Talk Turborepo","children":{}},"/playground/_radar/timeline/react-toolkit-migrate-from-lerna-to-turporepo":{"label":"React Toolkit Migrate From Lerna To Turporepo","children":{}},"/playground/_radar/timeline/use-monorepos-to-build-v3-of-react-sdk-for-searchio":{"label":"Use Monorepos To Build V3 Of React Sdk For Searchio","children":{}},"/playground/_radar/timeline/react-toolkit":{"label":"React Toolkit","children":{}},"/playground/_radar/timeline/use-nx-for-managing-basehq-frontend-monorepos":{"label":"Use Nx For Managing Basehq Frontend Monorepos","children":{}},"/playground/_radar/timeline/practice-and-using-selenium-in-setel-project":{"label":"Practice And Using Selenium In Setel Project","children":{}},"/playground/_radar/timeline/urbox-backend-api":{"label":"Urbox Backend Api","children":{}},"/playground/_radar/timeline/using-k6-in-setel":{"label":"Using K6 In Setel","children":{}},"/playground/_radar/timeline/use-monorepos-to-resolve-the-problem-of-sharing-ui-components-in-aharoom":{"label":"Use Monorepos To Resolve The Problem Of Sharing Ui Components In Aharoom","children":{}},"/playground/_radar/timeline/a-case-study-interview-into-micro-frontends-building-design-system-for-e-commerce-platform":{"label":"A Case Study Interview Into Micro Frontends Building Design System For E Commerce Platform","children":{}},"/playground/_radar/timeline/accelerate-project-initiation-with-advanced-nextjs-boilerplate-react-toolkit":{"label":"Accelerate Project Initiation With Advanced Nextjs Boilerplate React Toolkit","children":{}},"/playground/_radar/timeline/adapt-cucumber-as-a-bdd-for-wego":{"label":"Adapt Cucumber As A Bdd For Wego","children":{}}}},"/playground/_radar/timescaledb":{"label":"Timescaledb","children":{}},"/playground/_radar/tla":{"label":"Tla","children":{}},"/playground/_radar/trunk-based-development":{"label":"Trunk Based Development","children":{}},"/playground/_radar/turborepo":{"label":"Turborepo","children":{}},"/playground/_radar/type-safe-client-server":{"label":"Type Safe Client Server","children":{}},"/playground/_radar/typescript":{"label":"Typescript","children":{}},"/playground/_radar/ui-documentation":{"label":"Ui Documentation","children":{}},"/playground/_radar/uno-css":{"label":"Uno Css","children":{}},"/playground/_radar/upptime":{"label":"Upptime","children":{}},"/playground/_radar/v-model":{"label":"V Model","children":{}},"/playground/_radar/vector-database":{"label":"Vector Database","children":{}},"/playground/_radar/vercel":{"label":"Vercel","children":{}},"/playground/_radar/vitejs":{"label":"Vitejs","children":{}},"/playground/_radar/volta":{"label":"Volta","children":{}},"/playground/_radar/wasm":{"label":"Wasm","children":{}},"/playground/_radar/webdriverio":{"label":"Webdriverio","children":{}},"/playground/_radar/webflow":{"label":"Webflow","children":{}},"/playground/_radar/yup":{"label":"Yup","children":{}},"/playground/_radar/zod":{"label":"Zod","children":{}},"/playground/_radar/zustand":{"label":"Zustand","children":{}}}},"/playground/blockchain":{"label":"Blockchain","children":{"/playground/blockchain/build-custom-ai-agent-with-elizaos":{"label":"Build custom AI Agent with ElizaOS","children":{}},"/playground/blockchain/web3-development-with-foundry":{"label":"Web3 Development with Foundry","children":{}},"/playground/blockchain/cross-chain-transfers-implementing-a-token-swap-from-base-chain-to-bitcoin":{"label":"Implement a Token Swap from the Base chain to Bitcoin for cross-chain transactions","children":{}},"/playground/blockchain/ton_core_concept":{"label":"Ton's base concepts","children":{}},"/playground/blockchain/ton_blockchain_of_blockchains":{"label":"Ton: Blockchain of blockchains","children":{}},"/playground/blockchain/introduce-to-solana-token-2022-new-standard-to-create-a-token-in-solana":{"label":"Introduce to Solana Token 2022 - new standard to create a token in solana","children":{}},"/playground/blockchain/solana-core-concept":{"label":"Solana core concepts","children":{}},"/playground/blockchain/metaplex-nft-compression":{"label":"Metaplex NFT Compression","children":{}},"/playground/blockchain/plonky2":{"label":"Plonky2","children":{}},"/playground/blockchain/polygon-zkevm-architecture":{"label":"Polygon zkEVM architecture","children":{}},"/playground/blockchain/starknet-architecture":{"label":"StarkNet architecture","children":{}},"/playground/blockchain/zk-snarks":{"label":"zk-SNARKs","children":{}},"/playground/blockchain/layer-2":{"label":"Layer 2: Scaling Solutions for Ethereum","children":{}},"/playground/blockchain/solana-account":{"label":"Solana Account","children":{}},"/playground/blockchain/foundational-topics":{"label":"Foundational Topics","children":{"/playground/blockchain/foundational-topics/zero-knowledge-proofs":{"label":"Zero-knowledge Proofs","children":{}},"/playground/blockchain/foundational-topics/blocks":{"label":"Blocks","children":{}},"/playground/blockchain/foundational-topics/distributed-systems":{"label":"Distributed systems","children":{}},"/playground/blockchain/foundational-topics/pos":{"label":"PoS","children":{}},"/playground/blockchain/foundational-topics/smart-contract":{"label":"Smart Contract","children":{}},"/playground/blockchain/foundational-topics/topics":{"label":"Topics","children":{}}}},"/playground/blockchain/multisign-wallet":{"label":"Multisign wallet","children":{}},"/playground/blockchain/anchor-framework":{"label":"Anchor framework","children":{}},"/playground/blockchain/blockchain-bridge":{"label":"Blockchain Bridge","children":{}},"/playground/blockchain/nft-fractionalization":{"label":"NFT Fractionalization","children":{}},"/playground/blockchain/how-tokens-work-on-solana":{"label":"How Tokens Work on Solana","children":{}},"/playground/blockchain/liquidity-pool":{"label":"Liquidity pool","children":{}}}},"/playground/frontend":{"label":"Frontend","children":{"/playground/frontend/report":{"label":"Report","children":{"/playground/frontend/report/frontend-report-march-2025":{"label":"March 2025","children":{}},"/playground/frontend/report/frontend-report-february-2025":{"label":"February 2025","children":{}},"/playground/frontend/report/frontend-report-january-2025":{"label":"January 2025","children":{}},"/playground/frontend/report/frontend-report-second-half-of-november-2024":{"label":"Nov 2024 (Second Half)","children":{}},"/playground/frontend/report/frontend-report-first-half-of-november-2024":{"label":"Nov 2024 (First Half)","children":{}},"/playground/frontend/report/frontend-report-october-2024":{"label":"October 2024","children":{}},"/playground/frontend/report/frontend-report-september-2024":{"label":"September 2024","children":{}},"/playground/frontend/report/frontend-report-august-2024":{"label":"August 2024","children":{}},"/playground/frontend/report/frontend-report-july-2024":{"label":"July 2024","children":{}}}},"/playground/frontend/react":{"label":"React","children":{"/playground/frontend/react/code-splitting":{"label":"Code splitting","children":{}},"/playground/frontend/react/component-composition-patterns":{"label":"Component composition patterns","children":{}},"/playground/frontend/react/design-system-integration":{"label":"Design system integration","children":{}},"/playground/frontend/react/hook-architecture":{"label":"Hook architecture","children":{}},"/playground/frontend/react/rendering-strategies":{"label":"Rendering strategies","children":{}},"/playground/frontend/react/state-management-strategy":{"label":"State management strategy","children":{}},"/playground/frontend/react/testing-strategies":{"label":"Testing strategies","children":{}}}},"/playground/frontend/websockets":{"label":"WebSockets","children":{}},"/playground/frontend/from-markup-to-pixels-a-look-inside-the-dom-cssom-and-render-tree":{"label":"From Markup to Pixels - A look inside the DOM, CSSOM, and Render Tree","children":{}},"/playground/frontend/window-and-iframe-communication":{"label":"Window and iframe communication","children":{}},"/playground/frontend/applying-mock-service-worker-msw-for-seamless-web-development":{"label":"Applying Mock Service Worker (MSW) for Seamless Web Development","children":{}},"/playground/frontend/render-optimization-in-data-fetching-libraries":{"label":"Render optimization in data-fetching libraries","children":{}},"/playground/frontend/a-fragment-colocation-pattern-with-react-apollo-graphql":{"label":"A Fragment Colocation Pattern with React \u0026 Apollo GraphQL","children":{}},"/playground/frontend/scroll-driven-animations":{"label":"Scroll-driven animations","children":{}},"/playground/frontend/react-server-component":{"label":"React Server Components, NextJs Route and Data Fetching","children":{}},"/playground/frontend/url-formats-for-sharing-via-social-networks":{"label":"URL formats for sharing via social networks","children":{}},"/playground/frontend/shadow-dom":{"label":"Shadow DOM","children":{}},"/playground/frontend/retain-scroll-position-in-infinite-scroll":{"label":"Retain scroll position in infinite scroll","children":{}},"/playground/frontend/continuous-translation":{"label":"Continuous Translation","children":{}},"/playground/frontend/what-is-pnpm-compare-to-npmyarn":{"label":"What is PNPM Compare To NPM/Yarn","children":{}},"/playground/frontend/why-micro-frontend":{"label":"Why Micro Frontend","children":{}},"/playground/frontend/why-we-chose-our-tech-stack-accelerating-development-with-a-robust-frontend-solution":{"label":"Why We Chose Our Tech Stack Accelerating Development With A Robust Frontend Solution","children":{}},"/playground/frontend/tackling-server-state-complexity-in-frontend-development":{"label":"Tackling Server State complexity in Frontend Development","children":{}},"/playground/frontend/variable-fonts":{"label":"Variable Fonts","children":{}},"/playground/frontend/when-should-we-use-usereducer-instead-of-usestate":{"label":"When should we use useReducer instead of useState?","children":{}},"/playground/frontend/preserving-and-resetting-state-in-react":{"label":"Preserving and Resetting state in React","children":{}},"/playground/frontend/mixpanel":{"label":"Mixpanel","children":{}},"/playground/frontend/validation-with-zod":{"label":"Validation with Zod","children":{}},"/playground/frontend/parse-dont-validate-in-typescript":{"label":"Parse, don't validate in TypeScript","children":{}},"/playground/frontend/webassembly":{"label":"Webassembly","children":{}},"/playground/frontend/singleton-design-pattern-in-javascript":{"label":"Singleton Design Pattern in Javascript","children":{}},"/playground/frontend/an-introduction-to-atomic-css":{"label":"An Introduction to Atomic CSS","children":{}},"/playground/frontend/intro-to-indexeddb":{"label":"Intro to IndexedDB","children":{}},"/playground/frontend/the-fundamental-of-web-performance":{"label":"The fundamental of web performance","children":{}},"/playground/frontend/wai-aria":{"label":"WAI-ARIA","children":{}},"/playground/frontend/build-polymorphic-react-components-with-typescript":{"label":"Build polymorphic React components with Typescript","children":{}},"/playground/frontend/threejs":{"label":"Threejs","children":{"/playground/frontend/threejs/cameras-in-threejs":{"label":"Cameras in ThreeJS","children":{}}}},"/playground/frontend/prevent-layout-thrashing":{"label":"Prevent Layout Thrashing","children":{}},"/playground/frontend/pure-css-parallax":{"label":"Pure CSS Parallax","children":{}},"/playground/frontend/css-container-queries":{"label":"CSS Container Queries","children":{}},"/playground/frontend/hsl-color":{"label":"HSL Color","children":{}},"/playground/frontend/mitigate-blocking-the-main-thread":{"label":"Mitigate blocking the main thread","children":{}},"/playground/frontend/css-in-js":{"label":"CSS in JS","children":{}},"/playground/frontend/dark-mode-flickers-a-white-background-for-a-fraction-of-a-second":{"label":"Dark mode flickers a white background for a fraction of a second","children":{}},"/playground/frontend/why-dom-manipulation-is-slow":{"label":"Why DOM manipulation is slow?","children":{}},"/playground/frontend/why-virtual-dom-is-fast":{"label":"Why Virtual DOM is fast?","children":{}},"/playground/frontend/vitejs-native-modules":{"label":"ViteJS native modules","children":{}},"/playground/frontend/javascript-modules":{"label":"JavaScript modules","children":{}},"/playground/frontend/atomic-design-pattern":{"label":"Atomic Design Pattern","children":{}},"/playground/frontend/focus-trap":{"label":"Focus trap","children":{}},"/playground/frontend/html-inert":{"label":"HTML inert","children":{}},"/playground/frontend/useeffect-double-calls-in-react-18":{"label":"useEffect double calls in React 18","children":{}},"/playground/frontend/react-18":{"label":"React 18","children":{}},"/playground/frontend/remix-versus-nextjs":{"label":"Remix Versus Nextjs","children":{}},"/playground/frontend/zaplib-post-mortem":{"label":"Zaplib post-mortem","children":{}},"/playground/frontend/parallelism-in-javascript":{"label":"Parallelism in JavaScript","children":{}},"/playground/frontend/mpa-spa-and-partial-hydration":{"label":"MPA, SPA and Partial Hydration","children":{}},"/playground/frontend/micro-frontends-microservices-for-frontend-development":{"label":"Micro Frontends Microservices For Frontend Development","children":{}},"/playground/frontend/using-correct-html-element-to-increase-website-accessibility":{"label":"Using Correct Html Element To Increase Website Accessibility","children":{}},"/playground/frontend/remove-unused-css-styles-from-bootstrap-using-purgecss":{"label":"Remove Unused CSS Styles From Bootstrap Using Purgecss","children":{}}}},"/playground/use-cases":{"label":"Use Cases","children":{"/playground/use-cases/service_monitoring_with_upptime":{"label":"Secure and transparent uptime monitoring with Upptime and GitHub secrets","children":{}},"/playground/use-cases/create-slides-with-overleaf":{"label":"Create slides with Overleaf and ChatGPT","children":{}},"/playground/use-cases/optimize-init-load-time-for-trading-platform":{"label":"Optimizing initial load time for a Trading Platform","children":{}},"/playground/use-cases/ai-interview-platform-mvp":{"label":"Building MVP for AI-driven interview platform","children":{}},"/playground/use-cases/optimizing-ui-for-effective-investment-experience":{"label":"Hedge Foundation - Optimizing UI for effective investment experience","children":{}},"/playground/use-cases/implement-binance-future-pnl-analysis-page":{"label":"Implement Binance Futures PNL analysis page by Phoenix LiveView","children":{}},"/playground/use-cases/migrate-normal-table-to-timescale-table":{"label":"Migrate regular tables into TimescaleDB hypertables to improve query performance","children":{}},"/playground/use-cases/bitcoin-alt-performance-tracking":{"label":"Tracking Bitcoin-Altcoin Performance Indicators in BTC Hedging Strategy","children":{}},"/playground/use-cases/database-hardening-for-trading-platform":{"label":"Database hardening for a trading platform","children":{}},"/playground/use-cases/data-archive-and-recovery":{"label":"Building a data archive and recovery strategy for high-volume trading system","children":{}},"/playground/use-cases/persist-history-using-data-snapshot-pattern":{"label":"Implementing data snapshot pattern to persist historical data","children":{}},"/playground/use-cases/ai-ruby-travel-assistant-chatbot":{"label":"AI-powered Ruby travel assistant","children":{}},"/playground/use-cases/building-chatbot-agent-for-project-management-tool":{"label":"Building chatbot agent to streamline project management","children":{}},"/playground/use-cases/building-data-pipeline-ogif-transcriber":{"label":"Building data pipeline for OGIF transcriber","children":{}},"/playground/use-cases/centralized-monitoring-setup-for-trading-platform":{"label":"Setup centralized monitoring system for Hedge Foundation trading platform","children":{}},"/playground/use-cases/binance-transfer-matching":{"label":"Building better Binance transfer tracking","children":{}},"/playground/use-cases/crypto-market-outperform-chart-rendering":{"label":"Visualizing crypto market performance: BTC-Alt dynamic indicators in Golang","children":{}},"/playground/use-cases/enhancing-cryptocurrency-transfer-logger":{"label":"Transfer mapping: enhancing loggers for better transparency","children":{}},"/playground/use-cases/reconstructing_trading_pnl_data_pipeline_approach":{"label":"Reconstructing historical trading PnL: a data pipeline approach","children":{}},"/playground/use-cases/ai-powered-monthly-project-reports":{"label":"Project reports system: a case study","children":{}}}},"/playground/ai":{"label":"AI","children":{"/playground/ai/securing-your-remote-mcp-servers":{"label":"Securing your remote MCP servers","children":{}},"/playground/ai/tool-level-security-for-remote-mcp-servers":{"label":"Tool-Level Security for Remote MCP Servers","children":{}},"/playground/ai/model-context-protocol":{"label":"Intro to Model Context Protocol","children":{}},"/playground/ai/building-llm-system":{"label":"Building LLM System","children":{"/playground/ai/building-llm-system/quantization-in-llm":{"label":"Quantization for large language models","children":{}},"/playground/ai/building-llm-system/graphrag":{"label":"GraphRAG - Building a knowledge graph for RAG system","children":{}},"/playground/ai/building-llm-system/guardrails-in-llm":{"label":"Guardrails in LLM","children":{}},"/playground/ai/building-llm-system/react-in-llm":{"label":"ReAct(Reason + Act) in LLM","children":{}},"/playground/ai/building-llm-system/rewoo-in-llm":{"label":"ReWOO: Reasoning without observation - A deeper look","children":{}},"/playground/ai/building-llm-system/model-selection":{"label":"Model selection","children":{}},"/playground/ai/building-llm-system/logs-pillar":{"label":"Logging","children":{}},"/playground/ai/building-llm-system/metric-pillar":{"label":"Metrics","children":{}},"/playground/ai/building-llm-system/observability-in-ai-platforms":{"label":"Observability in AI platforms","children":{}},"/playground/ai/building-llm-system/trace-pillar":{"label":"Tracing","children":{}},"/playground/ai/building-llm-system/intent-classification-by-llm":{"label":"Intent classification by LLM","children":{}},"/playground/ai/building-llm-system/llm-as-a-judge":{"label":"LLM as a judge","children":{}},"/playground/ai/building-llm-system/use-cases-for-llm-applications":{"label":"Use cases for LLM applications","children":{}},"/playground/ai/building-llm-system/the-rise-of-ai-applications-with-llm":{"label":"The rise of AI applications with LLM","children":{}},"/playground/ai/building-llm-system/evaluation-guideline-for-llm-application":{"label":"Evaluation guidelines for LLM applications","children":{}},"/playground/ai/building-llm-system/prevent-prompt-injection":{"label":"Prevent prompt injection","children":{}},"/playground/ai/building-llm-system/building-llm-system":{"label":"§ Building LLM system","children":{}},"/playground/ai/building-llm-system/multi-agent-collaboration-for-task-completion":{"label":"Multi-agent collaboration for task completion","children":{}},"/playground/ai/building-llm-system/multimodal-in-rag":{"label":"Multimodal in rag","children":{}}}},"/playground/ai/digest":{"label":"Digest","children":{"/playground/ai/digest/ai-digest-02":{"label":"AI digest #2 New command Aider, OpenHands, Qwen2.5 Coder 32B, Predicted Output","children":{}},"/playground/ai/digest/ai-digest-01":{"label":"AI digest #1 Aider reasoning, OpenAI Realtime API, Cline - pre Claude-dev ","children":{}}}},"/playground/ai/copilots":{"label":"Copilots","children":{"/playground/ai/copilots/projects-operations":{"label":"Project Operations Copilots","children":{}},"/playground/ai/copilots/team-copilots":{"label":"Team Copilots","children":{}}}},"/playground/ai/text-to-mongodb":{"label":"Natural Language to Database Queries: Text-to-MongoDB","children":{}},"/playground/ai/use-cases":{"label":"Use Cases","children":{"/playground/ai/use-cases/salesforce":{"label":"Salesforce use cases","children":{}},"/playground/ai/use-cases/yelp":{"label":"Yelp use cases","children":{}}}},"/playground/ai/evaluate-chatbot-agent-by-simulated-user":{"label":"Evaluate Chatbot Agent by User Simulation","children":{}},"/playground/ai/journey-of-thought-prompting":{"label":"Journey of Thought Prompting: Harnessing AI to Craft Better Prompts","children":{}},"/playground/ai/llm-tracing-in-ai-system":{"label":"LLM tracing in AI system","children":{}},"/playground/ai/caching-with-rag-system":{"label":"Evaluating caching in RAG systems","children":{}},"/playground/ai/generative-ui":{"label":"What is Generative UI?","children":{}},"/playground/ai/re-ranking-in-rag":{"label":"Re-ranking in RAG","children":{}},"/playground/ai/function-calling":{"label":"Function calling in AI agents","children":{}},"/playground/ai/building-llm-powered-tools-with-dify":{"label":"Streamlining Internal Tool Development with Managed LLMOps: A Dify Case Study","children":{}},"/playground/ai/thumbs-up-and-thumbs-down-pattern":{"label":"Thumbs up and Thumbs down pattern","children":{}},"/playground/ai/supervisor-ai-agents":{"label":"Building Agent Supervisors to Generate Insights","children":{}},"/playground/ai/raptor-llm-retrieval":{"label":"RAPTOR: Tree-based Retrieval for Language Models","children":{}},"/playground/ai/proximal-policy-optimization":{"label":"Proximal Policy Optimization","children":{}},"/playground/ai/a-grand-unified-theory-of-the-ai-hype-cycle":{"label":"A Grand Unified Theory of the AI Hype Cycle","children":{}},"/playground/ai/developing-rapidly-with-generative-ai":{"label":"Developing rapidly with Generative AI","children":{}},"/playground/ai/rlhf-with-open-assistant":{"label":"RLHF with Open Assistant","children":{}},"/playground/ai/story-map-for-llms":{"label":"Story map for LLMs","children":{}},"/playground/ai/adversarial-prompting":{"label":"Adversarial Prompting in Prompt Engineering","children":{}},"/playground/ai/chunking-strategies-to-overcome-context-limitation-in-llm":{"label":"Chunking strategies to overcome context limitation in LLM","children":{}},"/playground/ai/llms-accuracy-self-refinement":{"label":"LLM's Accuracy - Self Refinement","children":{}},"/playground/ai/llm-query-caching":{"label":"Query Caching for Large Language Models","children":{}},"/playground/ai/reinforcement-learning":{"label":"Introduction to Reinforcement Learning and Its Application with LLMs","children":{}},"/playground/ai/foundation-model":{"label":"Foundation Models: The Latest Advancement in AI","children":{}},"/playground/ai/select-vector-database-for-llm":{"label":"Select Vector Database for LLM","children":{}},"/playground/ai/build-your-chatbot-with-open-source-large-language-models":{"label":"Build your chatbot with open source Large Language Models","children":{}},"/playground/ai/workaround-with-openais-token-limit-with-langchain":{"label":"Workaround with OpenAI's token limit with Langchain","children":{}},"/playground/ai/working-with-langchain-document-loaders":{"label":"Working with langchain document loaders","children":{}}}},"/playground/go":{"label":"Go","children":{"/playground/go/weekly":{"label":"Weekly","children":{"/playground/go/weekly/dec-13":{"label":"#24 Go 1.24 testing/synctest experiment for time and concurrency testing","children":{}},"/playground/go/weekly/dec-06":{"label":"#23 Draft Release Notes for Go 1.24 and weak pointers in Go","children":{}},"/playground/go/weekly/nov-29":{"label":"#22 GoMLX: ML in Go without Python","children":{}},"/playground/go/weekly/nov-22":{"label":"#21 Go sync.Once is Simple","children":{}},"/playground/go/weekly/nov-15":{"label":"#20 Go Turns 15","children":{}},"/playground/go/weekly/nov-08":{"label":"#19 Writing secure Go code","children":{}},"/playground/go/weekly/nov-01":{"label":"#18 Fuzz Testing Go HTTP Services","children":{}},"/playground/go/weekly/oct-25":{"label":"#17 Leveraging benchstat Projects in Go benchmark and Go Plan9 memo on 450% speeding up calculations","children":{}},"/playground/go/weekly/oct-18":{"label":"#16 Understand sync.Map","children":{}},"/playground/go/weekly/oct-11":{"label":"#15 Go embed and Reflect","children":{}},"/playground/go/weekly/oct-04":{"label":"#14 Compile-time eval \u0026 SQLite with wazero","children":{}},"/playground/go/weekly/sep-27":{"label":"#13 Compiler Quests and Vector Vexations","children":{}},"/playground/go/weekly/sep-20":{"label":"#12 CLI Tools for K8s, REST, and Terminals","children":{}},"/playground/go/weekly/sep-13":{"label":"#11 Actors, Frameworks, and the Future of Go","children":{}},"/playground/go/weekly/sep-06":{"label":"#10 Script, Telemetry","children":{}},"/playground/go/weekly/aug-30":{"label":"#9 TinyGo, SQLite vector search, and Permify","children":{}},"/playground/go/weekly/aug-23":{"label":"#8 GoNB, kubetrim, and GopherCon UK 2024","children":{}},"/playground/go/weekly/aug-16":{"label":"#7 Go 1.23, Websockets, and Structs","children":{}},"/playground/go/weekly/aug-09":{"label":"#6 Cogent Core, Russ Cox stepping down","children":{}},"/playground/go/weekly/aug-02":{"label":"#5 Go 1.23 features, Memory, Minecraft, and More","children":{}},"/playground/go/weekly/jul-26":{"label":"#4 Ethical Hacking, HTTP Requests, Mac App Development","children":{}},"/playground/go/weekly/jul-12":{"label":"#3 Generic Collections, Generics Constraints, AI Bot","children":{}},"/playground/go/weekly/jul-05":{"label":"#2 Go 1.23 Iterators","children":{}},"/playground/go/weekly/june-27":{"label":"#1 eBPF and PGO Optimization Techniques","children":{}}}},"/playground/go/extension-interface-pattern":{"label":"Go extension interface pattern","children":{}},"/playground/go/go-import":{"label":"Go import design: using git repo path","children":{}},"/playground/go/go-package":{"label":"Package first design","children":{}},"/playground/go/go-generics-type-safety":{"label":"How does Go achieve type safety when it enables generics?","children":{}},"/playground/go/go-for-enterprise":{"label":"Go For Enterprise","children":{"/playground/go/go-for-enterprise/who-using-golang-in-enterprise":{"label":"Who is using Go in enterprise?","children":{}},"/playground/go/go-for-enterprise/enterprise-standard-language":{"label":"Go as an Enterprise Standard Language","children":{}},"/playground/go/go-for-enterprise/how-to-use-go-in-enterprise":{"label":"How to use Go in the Enterprise","children":{}},"/playground/go/go-for-enterprise/when-to-use-golang-in-enterprise":{"label":"When to use Go in the Enterprise","children":{}},"/playground/go/go-for-enterprise/why-enterprise-chose-java":{"label":"Why Enterprise Chose Java","children":{}},"/playground/go/go-for-enterprise/why-go":{"label":"Why Go?","children":{}}}},"/playground/go/compute-union-2-finite-automata":{"label":"Efficient Union of Finite Automata in Golang: A Practical Approach","children":{}},"/playground/go/approaches-to-manage-concurrent-workloads-like-worker-pools-and-pipelines":{"label":"Approaches To Manage Concurrent Workloads Like Worker Pools And Pipelines","children":{}},"/playground/go/message-queues-and-streaming-platforms-eg-kafka-nats-rabbitmq":{"label":"Message Queues And Streaming Platforms Eg Kafka Nats Rabbitmq","children":{}},"/playground/go/unit-testing-best-practices-in-golang":{"label":"Unit Testing Best Practices In Golang","children":{}},"/playground/go/profiling-in-go":{"label":"Profiling in Go","children":{}},"/playground/go/go-in-software-engineering":{"label":"Go In Software Engineering","children":{}},"/playground/go/go-concurrency":{"label":"Go Concurrency","children":{}},"/playground/go/slice-and-array-in-golang":{"label":"Slice And Array In Golang","children":{}},"/playground/go/use-go-selenium-to-crawl-data":{"label":"Use Go Selenium To Crawl Data","children":{}},"/playground/go/connecting-vim-with-golang":{"label":"Connecting Vim With Golang","children":{}}}},"/playground/market-report":{"label":"Market Report","children":{"/playground/market-report/2024-october":{"label":"October 2024","children":{}},"/playground/market-report/2024-september":{"label":"September 2024","children":{}},"/playground/market-report/2024-august":{"label":"August 2024","children":{}},"/playground/market-report/2024-july":{"label":"July 2024","children":{}},"/playground/market-report/2024-may":{"label":"May 2024","children":{}},"/playground/market-report/2024-april":{"label":"April 2024","children":{}},"/playground/market-report/2024-march":{"label":"March 2024","children":{}},"/playground/market-report/2024-february":{"label":"February 2024","children":{}},"/playground/market-report/2024-january":{"label":"January 2024","children":{}},"/playground/market-report/2023-december":{"label":"December 2023","children":{}}}},"/playground/devbox":{"label":"Devbox","children":{"/playground/devbox/devbox":{"label":"§ Devbox","children":{}},"/playground/devbox/story":{"label":"Story","children":{"/playground/devbox/story/devbox-production-success-story":{"label":"Devbox in Production: Our Success Story","children":{}},"/playground/devbox/story/devbox-local-development-env":{"label":"Using Devbox to setup local development environment","children":{}},"/playground/devbox/story/devbox-nix-and-our-devbox-adoption":{"label":"The overview into Nix \u0026 how we use Devbox @ Dwarves","children":{}},"/playground/devbox/story/devbox-docker-adoption-and-challenges":{"label":"Our Docker adoption and its challenges","children":{}},"/playground/devbox/story/devbox-a-world-before-docker":{"label":"The world before Docker","children":{}}}},"/playground/devbox/guide":{"label":"Guide","children":{"/playground/devbox/guide/containerless":{"label":"Ditch the Containers: Go Containerless with Devbox","children":{}},"/playground/devbox/guide/devboxjson":{"label":"Devbox.json: Your Project's DNA","children":{}},"/playground/devbox/guide/run-your-own-shell":{"label":"Devbox Shell: Your Dev Environment, Your Rules","children":{}}}},"/playground/devbox/introduction":{"label":"Introduction","children":{"/playground/devbox/introduction/the-reason-for-being":{"label":"The reason for being","children":{}},"/playground/devbox/introduction/why-devbox-but-not-nix":{"label":"Devbox vs Nix: Why We Chose Simplicity","children":{}}}},"/playground/devbox/research":{"label":"Research","children":{"/playground/devbox/research/content-addressable-storage-in-docker":{"label":"Devbox vs Nix: Why We Chose Simplicity","children":{}},"/playground/devbox/research/fixed-output-derivation":{"label":"Fixed-output Derivation in Nix","children":{}},"/playground/devbox/research/nix-is-faster-than-docker-build":{"label":"Nix is Faster Than Docker Build","children":{}},"/playground/devbox/research/pinning-nixpkgs":{"label":"Pinning nixpkgs in Nix","children":{}},"/playground/devbox/research/shadow-copies":{"label":"Shadow Copies in Docker Builds","children":{}},"/playground/devbox/research/unstable-package-installation":{"label":"Unstable Package Installation in Docker","children":{}}}}}}}},"/careers":{"label":"Careers","children":{"/careers/archived":{"label":"Archived","children":{"/careers/archived/full-stack-engineer":{"label":"Full-Stack Engineer","children":{}},"/careers/archived/executive-assistant":{"label":"Executive Assistant","children":{}},"/careers/archived/technical-recruiter":{"label":"Technical Recruiter","children":{}},"/careers/archived/backend-engineer-go-elixir-rust":{"label":"Backend Engineer, Go/Elixir/Rust","children":{}},"/careers/archived/react-native-developer":{"label":"React Native Developer","children":{}},"/careers/archived/android-developer":{"label":"Mobile Engineer, Android","children":{}},"/careers/archived/community-executive":{"label":"Community Executive","children":{}},"/careers/archived/data-engineering":{"label":"Energy - Data Engineering","children":{}},"/careers/archived/devops":{"label":"DevOps Engineer - FinTech","children":{}},"/careers/archived/frontend-developer-junior":{"label":"Junior Frontend Developer","children":{}},"/careers/archived/frontend":{"label":"Frontend","children":{}},"/careers/archived/ios-developer":{"label":"iOS Developer - EnergyTech","children":{}},"/careers/archived/macos-developer":{"label":"Software Engineer, macOS","children":{}},"/careers/archived/product-designer-new-grad":{"label":"Product Designer, New Grad","children":{}},"/careers/archived/product-designer":{"label":"Product Designer","children":{}},"/careers/archived/qc-automation":{"label":"QC Engineer, Automation - Logistics","children":{}},"/careers/archived/qc-manual":{"label":"Fintech - QC Engineer, Manual","children":{}},"/careers/archived/reactjs-web-engineer":{"label":"Web Engineer, React.js","children":{}},"/careers/archived/visual-designer":{"label":"Visual Designer","children":{}},"/careers/archived/android":{"label":"Android","children":{}},"/careers/archived/golang":{"label":"Golang","children":{}},"/careers/archived/intern":{"label":"Intern","children":{}},"/careers/archived/ios":{"label":"iOS Developer","children":{}},"/careers/archived/qa":{"label":"QA Engineer","children":{}}}},"/careers/open-positions":{"label":"Open Positions","children":{"/careers/open-positions/business-manager":{"label":"Business Development","children":{}},"/careers/open-positions/growth":{"label":"Growth","children":{}}}},"/careers/culture":{"label":"Culture Handbook","children":{}},"/careers/manifesto":{"label":"The Manifesto","children":{}},"/careers/life":{"label":"Life at Dwarves","children":{}},"/careers/apprentice":{"label":"Apprentice","children":{"/careers/apprentice/2022":{"label":"2022","children":{"/careers/apprentice/2022/batch-of-2022":{"label":"Batch of 2022","children":{}},"/careers/apprentice/2022/2022-meet-ngoc-thanh-pham":{"label":"Thanh Pham","children":{}},"/careers/apprentice/2022/2022-meet-tuan-dao":{"label":"Tuan Dao","children":{}}}},"/careers/apprentice/apprentice":{"label":"Apprentice program","children":{}}}},"/careers/readme":{"label":"Join the Dwarves","children":{}}}},"/opensource":{"label":"Opensource","children":{"/opensource/readme":{"label":"Open Source","children":{}}}},"/playbook":{"label":"Playbook","children":{"/playbook/operations":{"label":"Operations","children":{"/playbook/operations/checklists":{"label":"Checklists","children":{"/playbook/operations/checklists/leave-and-request-checklist":{"label":"Leave Request","children":{}},"/playbook/operations/checklists/offboarding-checklist":{"label":"Offboarding","children":{}},"/playbook/operations/checklists/artifact-checklist":{"label":"Back up Artifact","children":{}},"/playbook/operations/checklists/project-archive":{"label":"Project Archive","children":{}},"/playbook/operations/checklists/project-case-study":{"label":"Project Case Study","children":{}},"/playbook/operations/checklists/project-communication":{"label":"Project Communication","children":{}},"/playbook/operations/checklists/project-handover":{"label":"Project Handover","children":{}},"/playbook/operations/checklists/project-initialization":{"label":"Project Initialization","children":{}},"/playbook/operations/checklists/assets-checklist":{"label":"Assets","children":{}},"/playbook/operations/checklists/billing-checklist":{"label":"Billing","children":{}},"/playbook/operations/checklists/candidate-checklist":{"label":"Candidate","children":{}},"/playbook/operations/checklists/consulting-contract-checklist":{"label":"Consulting Contract","children":{}},"/playbook/operations/checklists/hiring-checklist":{"label":"Hiring","children":{}},"/playbook/operations/checklists/onboarding-checklist":{"label":"Onboarding","children":{}},"/playbook/operations/checklists/unemployment-social-health-insurance":{"label":"Unemployment, Social, Health Insurance","children":{}},"/playbook/operations/checklists/vietnam-invoice-checklist":{"label":"Vietnam Invoice","children":{}}}},"/playbook/operations/how-to-conduct-delivery-reports":{"label":"How to conduct delivery reports","children":{}},"/playbook/operations/how-we-do-effective-planning-and-reporting":{"label":"How we do effective planning and reporting","children":{}},"/playbook/operations/project-schedule-delivery-guidelines":{"label":"Project Delivery Schedule and Guidelines","children":{}},"/playbook/operations/ogif":{"label":"OGIF - Oh God It's Friday","children":{}},"/playbook/operations/red-flags":{"label":"Red Flags","children":{}},"/playbook/operations/focus-on-software-delivery":{"label":"Focus On Software Delivery","children":{}},"/playbook/operations/are-you-helping":{"label":"Are You Helping","children":{}},"/playbook/operations/the-inner-circle":{"label":"The Inner Circle","children":{}},"/playbook/operations/mbti-type-intj":{"label":"MBTI Type INTJ","children":{}},"/playbook/operations/mbti-type-istp":{"label":"MBTI Type ISTP","children":{}},"/playbook/operations/mbti-type-estj":{"label":"MBTI Type ESTJ","children":{}},"/playbook/operations/mbti-type-istj":{"label":"MBTI Type ISTJ","children":{}},"/playbook/operations/applying-myersbriggs-type-indicator-in-hr":{"label":"Applying Myersbriggs Type Indicator In Hiring","children":{}},"/playbook/operations/the-four-preferences":{"label":"The Four Preferences","children":{}},"/playbook/operations/making-decision-as-a-team-member":{"label":"Making Decision As A Team Member","children":{}},"/playbook/operations/adjust-the-way-we-work-in-basecamp-style":{"label":"Adjust The Way We Work In Basecamp Style","children":{}},"/playbook/operations/beyond-the-title":{"label":"Beyond The Title","children":{}},"/playbook/operations/go-the-extra-mile":{"label":"Go The Extra Mile","children":{}},"/playbook/operations/the-dwarves-runs-by-ideas":{"label":"The Dwarves Runs By Ideas","children":{}},"/playbook/operations/a-tips-of-hiring-dont":{"label":"A Tips Of Hiring - Do \u0026 Don't","children":{}},"/playbook/operations/the-dwarves-culture-handbook":{"label":"The Dwarves Culture Handbook","children":{}},"/playbook/operations/how-people-matter-should-work":{"label":"How People Matter Should Work","children":{}},"/playbook/operations/delegation-and-believe-it-will-work":{"label":"Delegation And Believe It Will Work","children":{}},"/playbook/operations/constructive-feedback":{"label":"Constructive Feedback","children":{}},"/playbook/operations/transparency":{"label":"Transparency","children":{}},"/playbook/operations/bric-a-brac":{"label":"Bric A Brac","children":{}},"/playbook/operations/account":{"label":"Account","children":{}},"/playbook/operations/avoid-burn-out":{"label":"Avoid Burn Out","children":{}},"/playbook/operations/writing-management-objectives-in-smart":{"label":"Writing Management Objectives In Smart","children":{}},"/playbook/operations/building-a-solid-high-performing-team":{"label":"Building A Solid High Performing Team","children":{}},"/playbook/operations/hiring-for-operations-team":{"label":"Hiring For Operations Team","children":{}},"/playbook/operations/annual-bonus-for-sales":{"label":"Annual bonus for sales","children":{}},"/playbook/operations/bunk-license-check":{"label":"Bunk license check","children":{}},"/playbook/operations/collaboration-guidelines":{"label":"Collaboration Guidelines","children":{}},"/playbook/operations/compliance-check-process":{"label":"Compliance Check Process","children":{}},"/playbook/operations/email-template":{"label":"Email Template","children":{"/playbook/operations/email-template/assignment-invitation-2":{"label":"Assignment Inviation (Skip pre-assessment)","children":{}},"/playbook/operations/email-template/assignment-invitation":{"label":"Assignment Inviation","children":{}},"/playbook/operations/email-template/confirm-resume-date":{"label":"Confirm Employee's Resume Date Day","children":{}},"/playbook/operations/email-template/farewell":{"label":"Farewell Letter","children":{}},"/playbook/operations/email-template/follow-up-onboarding-items":{"label":"Follow-up Onboarding Items","children":{}},"/playbook/operations/email-template/hung-king-commemoration-day":{"label":"Hung King Commemoration Day","children":{}},"/playbook/operations/email-template/information-about-resource-change":{"label":"Inform about resource change","children":{}},"/playbook/operations/email-template/international-labour-day":{"label":"International Labour Day","children":{}},"/playbook/operations/email-template/interview-invitation":{"label":"Interview Invitation","children":{}},"/playbook/operations/email-template/milestone-sign-off":{"label":"Milestone sign-off","children":{}},"/playbook/operations/email-template/national-day":{"label":"National Day","children":{}},"/playbook/operations/email-template/new-year-day":{"label":"New Year Day","children":{}},"/playbook/operations/email-template/offer-letter":{"label":"Offer Letter","children":{}},"/playbook/operations/email-template/referral-bonus-confirmation-note":{"label":"Referral Bonus Confirmation Note","children":{}},"/playbook/operations/email-template/rejection-email":{"label":"Rejection","children":{}},"/playbook/operations/email-template/salary-increment":{"label":"Salary Increment Announcement","children":{}},"/playbook/operations/email-template/tet-holiday":{"label":"Tet Holiday","children":{}},"/playbook/operations/email-template/thank-you-letter":{"label":"Thank you letter","children":{}},"/playbook/operations/email-template/welcome-onboard":{"label":"Welcome Onboard","children":{}},"/playbook/operations/email-template/welcome-to-dwarves-update":{"label":"Welcome to Dwarves Updates","children":{}}}},"/playbook/operations/naming-convention":{"label":"Naming convention","children":{}},"/playbook/operations/setup-email-template":{"label":"Setup email template in Gmail","children":{}},"/playbook/operations/delegate-work-not-responsibility":{"label":"Delegate Work Not Responsibility","children":{}},"/playbook/operations/types-of-employees":{"label":"Types Of Employees","children":{}},"/playbook/operations/hiring-approach":{"label":"Hiring Approach","children":{}},"/playbook/operations/the-okr":{"label":"The OKR","children":{}},"/playbook/operations/our-metrics-for-performance-review":{"label":"Our Metrics For Performance Review","children":{}},"/playbook/operations/make-remote-working-works":{"label":"Make Remote Working Works","children":{}},"/playbook/operations/blocking-distraction":{"label":"Blocking Distraction","children":{}},"/playbook/operations/effective-meeting":{"label":"Effective Meeting","children":{}},"/playbook/operations/our-policy-for-remote-working":{"label":"Our Policy For Remote Working","children":{}}}},"/playbook/business":{"label":"Business","children":{"/playbook/business/pricing-model-bill-by-hours":{"label":"Pricing model: Bill by hours","children":{}},"/playbook/business/invoice":{"label":"Invoice","children":{}},"/playbook/business/nda":{"label":"NDA","children":{}},"/playbook/business/collaboration-guideline":{"label":"Collaboration Guideline","children":{}},"/playbook/business/df-workflow":{"label":"Dwarves Workflow","children":{}},"/playbook/business/fbsc":{"label":"FBSC","children":{}},"/playbook/business/how-to-work-with-clients":{"label":"How to work with clients","children":{}},"/playbook/business/service-feedbacks":{"label":"Service Feedbacks","children":{}},"/playbook/business/setting-the-budget":{"label":"Setting The Budget","children":{}},"/playbook/business/fixed-budget-scope-controlled":{"label":"Fixed Budget Scope Controlled","children":{}},"/playbook/business/the-adjacent-possible":{"label":"The Adjacent Possible","children":{}}}},"/playbook/engineering":{"label":"Engineering","children":{"/playbook/engineering/estimation-guidelines":{"label":"Estimation Guidelines","children":{}},"/playbook/engineering/presentation":{"label":"monitoring","children":{}},"/playbook/engineering/repo-icon":{"label":"release","children":{}}}},"/playbook/design":{"label":"Design","children":{"/playbook/design/design-system":{"label":"lean-canvas","children":{}},"/playbook/design/ia":{"label":"NDA","children":{}},"/playbook/design/ix":{"label":"IA","children":{}},"/playbook/design/aarrr":{"label":"AARRR","children":{}},"/playbook/design/design-sprint":{"label":"Design Sprint","children":{}},"/playbook/design/lean-canvas":{"label":"Lean Canvas","children":{}},"/playbook/design/prototype":{"label":"Low-fidelity prototype: UI Design","children":{}},"/playbook/design/ui":{"label":"UI","children":{}},"/playbook/design/ux":{"label":"UX","children":{}},"/playbook/design/wireframe":{"label":"wireframe","children":{}}}}}},"/updates":{"label":"Updates","children":{"/updates/changelog":{"label":"Changelog","children":{"/updates/changelog/2025-whats-new-march":{"label":"What's New in March 2025","children":{}},"/updates/changelog/2025-whats-new-february":{"label":"What's New in February 2025","children":{}},"/updates/changelog/2024-in-review":{"label":"2024 In Review","children":{}},"/updates/changelog/2024-whats-new-december":{"label":"What's New in December 2024","children":{}},"/updates/changelog/2024-summit-building-bonds-our-way":{"label":"Summit 2024: Building bonds our way","children":{}},"/updates/changelog/2024-whats-new-november":{"label":"What's New in November 2024","children":{}},"/updates/changelog/2024-whats-new-oct":{"label":"What's New in October 2024","children":{}},"/updates/changelog/2024-whats-new-september":{"label":"What's New in September 2024","children":{}},"/updates/changelog/2024-navigating-changes":{"label":"Navigating changes","children":{}},"/updates/changelog/2024-whats-new-august":{"label":"What's New in August 2024","children":{}},"/updates/changelog/2024-whats-new-july":{"label":"What's New in July 2024","children":{}},"/updates/changelog/2024-semi-annual-review":{"label":"State of Dwarves: 2024 Semi-annual Review","children":{}},"/updates/changelog/2024-whats-new-june":{"label":"What's New in June 2024","children":{}},"/updates/changelog/2024-whats-new-may":{"label":"What's New in May 2024","children":{}},"/updates/changelog/2024-community-meet-up":{"label":"Dwarves’ 2nd community offline meet-up","children":{}},"/updates/changelog/2024-whats-new-april":{"label":"What's New in April 2024","children":{}},"/updates/changelog/2024-whats-new-march":{"label":"What's New in March 2024","children":{}},"/updates/changelog/2024-whats-new-february":{"label":"What's New in February 2024","children":{}},"/updates/changelog/2024-whats-new-january":{"label":"What's New in January 2024","children":{}},"/updates/changelog/2023-whats-new-december":{"label":"What's New in December 2023","children":{}},"/updates/changelog/readme":{"label":"Changelog","children":{}},"/updates/changelog/2023-whats-new-november":{"label":"What's New in November 2023","children":{}},"/updates/changelog/2023-whats-new-october":{"label":"What's New in October 2023","children":{}},"/updates/changelog/2023-happy":{"label":"Happy 2023","children":{}},"/updates/changelog/2022-dwarves-of-the-year":{"label":"Dwarves Of The Year 2022","children":{}},"/updates/changelog/2022-in-review":{"label":"2022 In Review","children":{}},"/updates/changelog/2022-summit-engineering-a-good-time":{"label":"Summit 2022: Engineering A Good Time","children":{}},"/updates/changelog/road-to-100":{"label":"Road To 100","children":{}},"/updates/changelog/2022-whats-new-may":{"label":"What's New in May 2022","children":{}},"/updates/changelog/2022-whats-new-january":{"label":"What's New in January 2022","children":{}},"/updates/changelog/2021-whats-new-december":{"label":"What's New in December 2021","children":{}},"/updates/changelog/2021-dwarves-of-the-year":{"label":"Dwarves Of The Year 2021","children":{}},"/updates/changelog/2021-whats-new-july":{"label":"What's New in July 2021","children":{}},"/updates/changelog/2020-in-review":{"label":"2020 In Review","children":{}},"/updates/changelog/2021-in-review":{"label":"2021 In Review","children":{}},"/updates/changelog/2019-in-review":{"label":"2019 In Review","children":{}},"/updates/changelog/2018-in-review":{"label":"2018 In Review","children":{}}}},"/updates/ogif":{"label":"OGIF","children":{"/updates/ogif/41-20250314":{"label":"#41 ICY-BTC, GitHub Bot, MCP-DB, Pocket Turing","children":{}},"/updates/ogif/28-20241018":{"label":"#28 Go sync.Map, AI UX, Yelp AI, LLM Patterns, Git Analysis","children":{}},"/updates/ogif/27-20241011":{"label":"#27 Go weekly, Frontend, AI UX, Finite Automata","children":{}},"/updates/ogif/26-20241004":{"label":"#26 Design insights, Go tools, Trading app, Chatbots, Essays","children":{}},"/updates/ogif/25-20240927":{"label":"#25 Team updates, Hybrid work, AI insights, Go weekly","children":{}},"/updates/ogif/24-20240920":{"label":"#24 Go weekly, AI workflows, Team AI demo, Figma-UI with Claude","children":{}},"/updates/ogif/23-20240913":{"label":"#23 Go weekly, FE report, Hybrid work, AI agents","children":{}},"/updates/ogif/22-20240906":{"label":"#22 Hybrid work, Tech report, Go weekly, AI demo","children":{}},"/updates/ogif/21-20240830":{"label":"#21 Community engagement, Go weekly, Journey of thought for prompt engineering","children":{}},"/updates/ogif/20-20240823":{"label":"#20 Go weekly, Dynamic objects, Devbox, LLM tracing, Cursor AI","children":{}},"/updates/ogif/19-20240821":{"label":"#19 Go weekly, UI design, File sharing, Dify AI","children":{}},"/updates/ogif/18-20240809":{"label":"#18 Go weekly, RAG, UI, FE updates","children":{}},"/updates/ogif/17-20240802":{"label":"#17 Community Call July, C4 Model, Interview Life in the US","children":{}},"/updates/ogif/16-20240726":{"label":"#16 Go weekly, Dune query, AI voice clone, RAG re-ranking","children":{}},"/updates/ogif/15-20240719":{"label":"#15 AI Supervisors, Local-first Software, Code Completion, Bot Commands","children":{}},"/updates/ogif/14-20240712":{"label":"#14 Generic Collections, Pricing Models, and OGIF Summarizer","children":{}},"/updates/ogif/13-20240705":{"label":"#13 Go Weekly updates, Radix Sort, Human Feedback Mechanism, and effective ChatGPT usage","children":{}},"/updates/ogif/12-20240628":{"label":"#12 June updates, Go Performance, eBPF, PGO, Multimodal RAG","children":{}},"/updates/ogif/11-20240621":{"label":"#11 Design patterns: template method \u0026 visitor, Radix sort, and weekly tech commentary","children":{}},"/updates/ogif/10-20240614":{"label":"#10 Behavioral Patterns and Map Content Organization","children":{}},"/updates/ogif/9-20240607":{"label":"#9 What's next for June and Behavior Design Patterns","children":{}},"/updates/ogif/7-20240517":{"label":"#7 Echelon EXPO, Programming patterns, and Moonlighting","children":{}},"/updates/ogif/6-20240510":{"label":"#6 Factory Pattern, Erlang State Machines, and Trading Process","children":{}},"/updates/ogif/5-20240503":{"label":"#5 Singapore Market Report, C4 Modelling, Memo's Nested Sidebar","children":{}},"/updates/ogif/4-20240426":{"label":"#4 DCA, Devbox","children":{}},"/updates/ogif/3-20240419":{"label":"#3 Generative AI, Tokenomics, and Finance Talks","children":{}},"/updates/ogif/2-20240412":{"label":"#2 Devbox as the new Docker, Security Standards, and Understanding Liquidity","children":{}},"/updates/ogif/1-20240405":{"label":"#1 Markdown Presentations, Research Pipeline, Screenshots How-to","children":{}},"/updates/ogif/readme":{"label":"OGIF - Oh God It's Friday","children":{}}}},"/updates/forward-engineering":{"label":"Forward Engineering","children":{"/updates/forward-engineering/2024-2025":{"label":"20242025","children":{}},"/updates/forward-engineering/2024-quarter-3":{"label":"Quarter 3 2024","children":{}},"/updates/forward-engineering/2023-november":{"label":"November 2023","children":{}},"/updates/forward-engineering/2023-october":{"label":"October 2023","children":{}},"/updates/forward-engineering/2023-august":{"label":"August 2023","children":{}},"/updates/forward-engineering/2023-june":{"label":"June 2023","children":{}},"/updates/forward-engineering/2023-may":{"label":"May 2023","children":{}},"/updates/forward-engineering/2023-march":{"label":"March 2023","children":{}},"/updates/forward-engineering/2023-december":{"label":"December 2023","children":{}},"/updates/forward-engineering/2022":{"label":"2022","children":{}},"/updates/forward-engineering/tech-radar-volume-03":{"label":"Tech Radar Volume 03","children":{}},"/updates/forward-engineering/tech-radar-volume-02":{"label":"Tech Radar Volume 02","children":{}},"/updates/forward-engineering/tech-radar-volume-01":{"label":"Tech Radar Volume 01","children":{}},"/updates/forward-engineering/tech-radar-the-introduction":{"label":"Tech Radar Introduction","children":{}}}},"/updates/digest":{"label":"Digest","children":{"/updates/digest/15-new-year-gathering":{"label":"#15 New year gathering","children":{}},"/updates/digest/14-back-to-the-office":{"label":"#14 Hybrid work harmony","children":{}},"/updates/digest/13-more-than-lines-of-code":{"label":"#13 More than lines of code","children":{}},"/updates/digest/12-summer-moments":{"label":"#12 Summer moments","children":{}},"/updates/digest/11-come-grow-with-us":{"label":"#11 Come grow with us","children":{}},"/updates/digest/10-from-lean-to-learner":{"label":"#10 From lean to learner","children":{}},"/updates/digest/9-a-little-more-speed-for-summer":{"label":"#9 A little more speed for summer","children":{}},"/updates/digest/8-then-came-the-last-days-of-may":{"label":"#8 Then came the last days of May","children":{}},"/updates/digest/7-a-journey-through-time":{"label":"#7 A journey through time","children":{}},"/updates/digest/6-stay-for-the-culture":{"label":"#6 Come for the conversation, stay for the culture","children":{}},"/updates/digest/5-delay-the-gratification":{"label":"#5 Endure the hardship, delay the gratification","children":{}},"/updates/digest/4-finding-your-authentic-tribe":{"label":"#4 Finding your authentic tribe","children":{}},"/updates/digest/3-we-all-start-somewhere":{"label":"#3 We all start somewhere","children":{}},"/updates/digest/2-walk-around-learn-around":{"label":"#2 Walk around learn around","children":{}},"/updates/digest/1-what-do-you-stand-for":{"label":"#1 What do you stand for?","children":{}},"/updates/digest/readme":{"label":"Digest","children":{}}}},"/updates/newsletter":{"label":"Newsletter","children":{"/updates/newsletter/knowledge-base":{"label":"Build your knowledge base","children":{}},"/updates/newsletter/dwarve-updates-ai-llm":{"label":"The Stage of AI and LLM at Dwarves","children":{}},"/updates/newsletter/readme":{"label":"_base","children":{}},"/updates/newsletter/growth-stages":{"label":"The Stage of Growth at Dwarves","children":{}},"/updates/newsletter/the-next-leading-chairs":{"label":"The Next Leading Chairs","children":{}},"/updates/newsletter/blockchain-and-data":{"label":"The future is blockchain and data","children":{}},"/updates/newsletter/hiring-stages":{"label":"The stages of hiring at Dwarves","children":{}},"/updates/newsletter/2021-in-review":{"label":"It's a wrap: 2021 in Review","children":{}},"/updates/newsletter/engineering-org-structure":{"label":"Engineering Organizational Structure","children":{}},"/updates/newsletter/path-to-growth":{"label":"The Path To Growth at Dwarves","children":{}},"/updates/newsletter/engineer-performance-review":{"label":"Engineer Performance Review","children":{}},"/updates/newsletter/project-compliance":{"label":"Project Compliance","children":{}},"/updates/newsletter/dalat-office":{"label":"Da Lat Office","children":{}},"/updates/newsletter/dwarves-updates":{"label":"Dwarves Updates","children":{}}}},"/updates/life":{"label":"Life","children":{"/updates/life/dat-nguyen":{"label":"Dat Nguyen","children":{}},"/updates/life/software-design-group":{"label":"Software Design Group","children":{}},"/updates/life/hieu-vu":{"label":"Hieu Vu","children":{}},"/updates/life/nam-nguyen":{"label":"Nam Nguyen","children":{}},"/updates/life/an-tran":{"label":"An Tran","children":{}},"/updates/life/tom-nguyen":{"label":"Tom Nguyen","children":{}},"/updates/life/anh-tran":{"label":"Anh Tran","children":{}},"/updates/life/thanh-pham":{"label":"Thanh Pham","children":{}}}},"/updates/culture-test":{"label":"Culture Test","children":{}},"/updates/fund":{"label":"Fund","children":{"/updates/fund/dwarves-ventures-fund-1":{"label":"Dwarves Ventures Fund 1","children":{}},"/updates/fund/dwarves-ventures-fund-0":{"label":"Dwarves Ventures Fund 0","children":{}}}}}}}},"/tags":{"label":"Popular Tags","children":{"/tags/earn":{"label":"#earn","children":{},"count":5},"/tags/ai":{"label":"#ai","children":{},"count":58},"/tags/hiring":{"label":"#hiring","children":{},"count":51},"/tags/case-study":{"label":"#case-study","children":{},"count":29},"/tags/handbook":{"label":"#handbook","children":{},"count":47},"/tags/business":{"label":"#business","children":{},"count":10},"/tags/growth":{"label":"#growth","children":{},"count":2},"/tags/consulting":{"label":"#consulting","children":{},"count":24},"/tags/market-report":{"label":"#market-report","children":{},"count":34},"/tags/tech-report":{"label":"#tech-report","children":{},"count":15},"/tags/software-development":{"label":"#software-development","children":{},"count":1},"/tags/database-management":{"label":"#database-management","children":{},"count":1},"/tags/icy":{"label":"#icy","children":{},"count":14},"/tags/career":{"label":"#career","children":{},"count":45},"/tags/full-stack":{"label":"#full-stack","children":{},"count":1},"/tags/engineer":{"label":"#engineer","children":{},"count":3},"/tags/ux-ui":{"label":"#ux-ui","children":{},"count":13},"/tags/product-design":{"label":"#product-design","children":{},"count":7},"/tags/report":{"label":"#report","children":{},"count":8},"/tags/checklist":{"label":"#checklist","children":{},"count":17},"/tags/presentation":{"label":"#presentation","children":{},"count":1},"/tags/business-development":{"label":"#business-development","children":{},"count":1},"/tags/database":{"label":"#database","children":{},"count":8},"/tags/sql":{"label":"#sql","children":{},"count":4},"/tags/data-modeling":{"label":"#data-modeling","children":{},"count":1},"/tags/data-engineering":{"label":"#data-engineering","children":{},"count":4},"/tags/system-design":{"label":"#system-design","children":{},"count":2},"/tags/architecture":{"label":"#architecture","children":{},"count":4},"/tags/etl":{"label":"#etl","children":{},"count":3},"/tags/automata":{"label":"#automata","children":{},"count":1},"/tags/fintech":{"label":"#fintech","children":{},"count":16},"/tags/mobile":{"label":"#mobile","children":{},"count":1},"/tags/wala":{"label":"#wala","children":{},"count":3},"/tags/fnb":{"label":"#fnb","children":{},"count":2},"/tags/film":{"label":"#film","children":{},"count":1},"/tags/go":{"label":"#go","children":{},"count":5},"/tags/error":{"label":"#error","children":{},"count":1},"/tags/open-source":{"label":"#open-source","children":{},"count":3},"/tags/community":{"label":"#community","children":{},"count":42},"/tags/startup":{"label":"#startup","children":{},"count":9},"/tags/shares":{"label":"#shares","children":{},"count":1},"/tags/founder":{"label":"#founder","children":{},"count":1},"/tags/entertainment":{"label":"#entertainment","children":{},"count":1},"/tags/hybrid-working":{"label":"#hybrid-working","children":{},"count":3},"/tags/guide":{"label":"#guide","children":{},"count":11},"/tags/security":{"label":"#security","children":{},"count":10},"/tags/reward":{"label":"#reward","children":{},"count":3},"/tags/team":{"label":"#team","children":{},"count":39},"/tags/design":{"label":"#design","children":{},"count":31},"/tags/ux":{"label":"#ux","children":{},"count":2},"/tags/directory-structure":{"label":"#directory-structure","children":{},"count":2},"/tags/file-management":{"label":"#file-management","children":{},"count":2},"/tags/file-system":{"label":"#file-system","children":{},"count":2},"/tags/permissions":{"label":"#permissions","children":{},"count":1},"/tags/database-modelling":{"label":"#database-modelling","children":{},"count":1},"/tags/nda":{"label":"#nda","children":{},"count":1},"/tags/compliance":{"label":"#compliance","children":{},"count":2},"/tags/people":{"label":"#people","children":{},"count":27},"/tags/operations":{"label":"#operations","children":{},"count":73},"/tags/llm":{"label":"#llm","children":{},"count":76},"/tags/rag":{"label":"#rag","children":{},"count":5},"/tags/search":{"label":"#search","children":{},"count":1},"/tags/evaluation":{"label":"#evaluation","children":{},"count":3},"/tags/delivery":{"label":"#delivery","children":{},"count":3},"/tags/reporting":{"label":"#reporting","children":{},"count":1},"/tags/project":{"label":"#project","children":{},"count":16},"/tags/billbyhours":{"label":"#billbyhours","children":{},"count":1},"/tags/engineering":{"label":"#engineering","children":{},"count":64},"/tags/subscription":{"label":"#subscription","children":{},"count":1},"/tags/pricing":{"label":"#pricing","children":{},"count":1},"/tags/product":{"label":"#product","children":{},"count":1},"/tags/blockchain":{"label":"#blockchain","children":{},"count":50},"/tags/evm":{"label":"#evm","children":{},"count":5},"/tags/foundry":{"label":"#foundry","children":{},"count":2},"/tags/search-engine":{"label":"#search-engine","children":{},"count":1},"/tags/duckdb":{"label":"#duckdb","children":{},"count":3},"/tags/transformers.js":{"label":"#transformers.js","children":{},"count":1},"/tags/hybrid-search":{"label":"#hybrid-search","children":{},"count":1},"/tags/erlang":{"label":"#erlang","children":{},"count":1},"/tags/elixir":{"label":"#elixir","children":{},"count":5},"/tags/fsm":{"label":"#fsm","children":{},"count":1},"/tags/design-pattern":{"label":"#design-pattern","children":{},"count":9},"/tags/gang-of-four":{"label":"#gang-of-four","children":{},"count":9},"/tags/observer-pattern":{"label":"#observer-pattern","children":{},"count":1},"/tags/behavior-pattern":{"label":"#behavior-pattern","children":{},"count":2},"/tags/visitor-design-pattern":{"label":"#visitor-design-pattern","children":{},"count":1},"/tags/strategy-design-pattern":{"label":"#strategy-design-pattern","children":{},"count":1},"/tags/ogif":{"label":"#ogif","children":{},"count":29},"/tags/guidelines":{"label":"#guidelines","children":{},"count":3},"/tags/feedback":{"label":"#feedback","children":{},"count":2},"/tags/mechanism":{"label":"#mechanism","children":{},"count":1},"/tags/local-first":{"label":"#local-first","children":{},"count":1},"/tags/crdt":{"label":"#crdt","children":{},"count":2},"/tags/data-synchronization":{"label":"#data-synchronization","children":{},"count":1},"/tags/data-ownership":{"label":"#data-ownership","children":{},"count":1},"/tags/real-time-collaboration":{"label":"#real-time-collaboration","children":{},"count":1},"/tags/rust":{"label":"#rust","children":{},"count":10},"/tags/trait":{"label":"#trait","children":{},"count":1},"/tags/error-handling":{"label":"#error-handling","children":{},"count":1},"/tags/data-structure":{"label":"#data-structure","children":{},"count":1},"/tags/bloom-filter":{"label":"#bloom-filter","children":{},"count":1},"/tags/big-o":{"label":"#big-o","children":{},"count":1},"/tags/behavioral-pattern":{"label":"#behavioral-pattern","children":{},"count":1},"/tags/golang":{"label":"#golang","children":{},"count":44},"/tags/behavior-patterns":{"label":"#behavior-patterns","children":{},"count":2},"/tags/algorithms":{"label":"#algorithms","children":{},"count":1},"/tags/sorting":{"label":"#sorting","children":{},"count":1},"/tags/network":{"label":"#network","children":{},"count":2},"/tags/machine-learning":{"label":"#machine-learning","children":{},"count":2},"/tags/zettelkasten":{"label":"#zettelkasten","children":{},"count":1},"/tags/prompt":{"label":"#prompt","children":{},"count":1},"/tags/chatgpt":{"label":"#chatgpt","children":{},"count":1},"/tags/solana":{"label":"#solana","children":{},"count":7},"/tags/amm":{"label":"#amm","children":{},"count":1},"/tags/memo":{"label":"#memo","children":{},"count":14},"/tags/instructions":{"label":"#instructions","children":{},"count":10},"/tags/guideline":{"label":"#guideline","children":{},"count":15},"/tags/ops":{"label":"#ops","children":{},"count":2},"/tags/nft":{"label":"#nft","children":{},"count":3},"/tags/workflow":{"label":"#workflow","children":{},"count":5},"/tags/recording":{"label":"#recording","children":{},"count":1},"/tags/history":{"label":"#history","children":{},"count":1},"/tags/creational-design-pattern":{"label":"#creational-design-pattern","children":{},"count":1},"/tags/moc":{"label":"#moc","children":{},"count":3},"/tags/software-design":{"label":"#software-design","children":{},"count":2},"/tags/software-architecture":{"label":"#software-architecture","children":{},"count":3},"/tags/graphical-notation":{"label":"#graphical-notation","children":{},"count":2},"/tags/energy":{"label":"#energy","children":{},"count":1},"/tags/techecosystem":{"label":"#techecosystem","children":{},"count":1},"/tags/summit":{"label":"#summit","children":{},"count":4},"/tags/crypto":{"label":"#crypto","children":{},"count":1},"/tags/content":{"label":"#content","children":{},"count":6},"/tags/investment":{"label":"#investment","children":{},"count":1},"/tags/personal-finance":{"label":"#personal-finance","children":{},"count":1},"/tags/dfg":{"label":"#dfg","children":{},"count":6},"/tags/tutorial":{"label":"#tutorial","children":{},"count":7},"/tags/standardization":{"label":"#standardization","children":{},"count":1},"/tags/work-adoption":{"label":"#work-adoption","children":{},"count":1},"/tags/code of conduct":{"label":"#code of conduct","children":{},"count":1},"/tags/research":{"label":"#research","children":{},"count":3},"/tags/field-notes":{"label":"#field-notes","children":{},"count":1},"/tags/innovation":{"label":"#innovation","children":{},"count":2},"/tags/radar":{"label":"#radar","children":{},"count":10},"/tags/bounty":{"label":"#bounty","children":{},"count":4},"/tags/communications":{"label":"#communications","children":{},"count":3},"/tags/token":{"label":"#token","children":{},"count":2},"/tags/brain":{"label":"#brain","children":{},"count":1},"/tags/knowledge-base":{"label":"#knowledge-base","children":{},"count":1},"/tags/engineering/data":{"label":"#engineering/data","children":{},"count":5},"/tags/data-pipeline":{"label":"#data-pipeline","children":{},"count":1},"/tags/vector-database":{"label":"#vector-database","children":{},"count":4},"/tags/payment":{"label":"#payment","children":{},"count":2},"/tags/partners":{"label":"#partners","children":{},"count":1},"/tags/brainery":{"label":"#brainery","children":{},"count":2},"/tags/devops":{"label":"#devops","children":{},"count":5},"/tags/google-cloud":{"label":"#google-cloud","children":{},"count":1},"/tags/google-data-studio":{"label":"#google-data-studio","children":{},"count":1},"/tags/google-data-fusion":{"label":"#google-data-fusion","children":{},"count":1},"/tags/reliability":{"label":"#reliability","children":{},"count":2},"/tags/cdap":{"label":"#cdap","children":{},"count":1},"/tags/data":{"label":"#data","children":{},"count":14},"/tags/google-dataproc":{"label":"#google-dataproc","children":{},"count":1},"/tags/hadoop":{"label":"#hadoop","children":{},"count":2},"/tags/streaming":{"label":"#streaming","children":{},"count":1},"/tags/ecommerce":{"label":"#ecommerce","children":{},"count":2},"/tags/dropshipping":{"label":"#dropshipping","children":{},"count":1},"/tags/dwarves":{"label":"#dwarves","children":{},"count":23},"/tags/work":{"label":"#work","children":{},"count":18},"/tags/internal":{"label":"#internal","children":{},"count":11},"/tags/discussion":{"label":"#discussion","children":{},"count":6},"/tags/event":{"label":"#event","children":{},"count":7},"/tags/labs":{"label":"#labs","children":{},"count":28},"/tags/catchup":{"label":"#catchup","children":{},"count":5},"/tags/home":{"label":"#home","children":{},"count":2},"/tags/tauri":{"label":"#tauri","children":{},"count":1},"/tags/htmx":{"label":"#htmx","children":{},"count":2},"/tags/frontend":{"label":"#frontend","children":{},"count":68},"/tags/culture":{"label":"#culture","children":{},"count":10},"/tags/estimation":{"label":"#estimation","children":{},"count":1},"/tags/code-generation":{"label":"#code-generation","children":{},"count":1},"/tags/typesafe":{"label":"#typesafe","children":{},"count":1},"/tags/fullstack":{"label":"#fullstack","children":{},"count":2},"/tags/discord":{"label":"#discord","children":{},"count":36},"/tags/workshop":{"label":"#workshop","children":{},"count":1},"/tags/demo":{"label":"#demo","children":{},"count":1},"/tags/protocol":{"label":"#protocol","children":{},"count":2},"/tags/performance-review":{"label":"#performance-review","children":{},"count":2},"/tags/assessment":{"label":"#assessment","children":{},"count":1},"/tags/knowledge":{"label":"#knowledge","children":{},"count":2},"/tags/tech-radar":{"label":"#tech-radar","children":{},"count":1},"/tags/evaluating-tech":{"label":"#evaluating-tech","children":{},"count":1},"/tags/process":{"label":"#process","children":{},"count":9},"/tags/updates":{"label":"#updates","children":{},"count":41},"/tags/distributed-system":{"label":"#distributed-system","children":{},"count":1},"/tags/data-types":{"label":"#data-types","children":{},"count":1},"/tags/data-structures":{"label":"#data-structures","children":{},"count":2},"/tags/client":{"label":"#client","children":{},"count":6},"/tags/guidline":{"label":"#guidline","children":{},"count":1},"/tags/performance":{"label":"#performance","children":{},"count":36},"/tags/playbook":{"label":"#playbook","children":{},"count":3},"/tags/software":{"label":"#software","children":{},"count":11},"/tags/framework":{"label":"#framework","children":{},"count":6},"/tags/productivity":{"label":"#productivity","children":{},"count":7},"/tags/learning":{"label":"#learning","children":{},"count":4},"/tags/system design":{"label":"#system design","children":{},"count":1},"/tags/enterprise":{"label":"#enterprise","children":{},"count":10},"/tags/australia":{"label":"#australia","children":{},"count":1},"/tags/sargable-queries":{"label":"#sargable-queries","children":{},"count":1},"/tags/zookeeper":{"label":"#zookeeper","children":{},"count":1},"/tags/kafka":{"label":"#kafka","children":{},"count":1},"/tags/sequential-reads":{"label":"#sequential-reads","children":{},"count":1},"/tags/sequential-writes":{"label":"#sequential-writes","children":{},"count":1},"/tags/random-reads":{"label":"#random-reads","children":{},"count":1},"/tags/random-writes":{"label":"#random-writes","children":{},"count":1},"/tags/url-redirect":{"label":"#url-redirect","children":{},"count":1},"/tags/url-rewrite":{"label":"#url-rewrite","children":{},"count":1},"/tags/http":{"label":"#http","children":{},"count":1},"/tags/seo":{"label":"#seo","children":{},"count":1},"/tags/dx":{"label":"#dx","children":{},"count":1},"/tags/machine learning":{"label":"#machine learning","children":{},"count":1},"/tags/r\u0026d":{"label":"#r\u0026d","children":{},"count":1},"/tags/web":{"label":"#web","children":{},"count":9},"/tags/micro-frontend":{"label":"#micro-frontend","children":{},"count":3},"/tags/backend":{"label":"#backend","children":{},"count":4},"/tags/tool":{"label":"#tool","children":{},"count":3},"/tags/technique":{"label":"#technique","children":{},"count":9},"/tags/vietnam":{"label":"#vietnam","children":{},"count":1},"/tags/write-heavy":{"label":"#write-heavy","children":{},"count":1},"/tags/inventory-platform":{"label":"#inventory-platform","children":{},"count":1},"/tags/scalability":{"label":"#scalability","children":{},"count":1},"/tags/doordash":{"label":"#doordash","children":{},"count":1},"/tags/low-latency":{"label":"#low-latency","children":{},"count":1},"/tags/observability":{"label":"#observability","children":{},"count":5},"/tags/teamwork":{"label":"#teamwork","children":{},"count":2},"/tags/leadership":{"label":"#leadership","children":{},"count":4},"/tags/multi-column-index":{"label":"#multi-column-index","children":{},"count":1},"/tags/index":{"label":"#index","children":{},"count":1},"/tags/composite-index":{"label":"#composite-index","children":{},"count":1},"/tags/react":{"label":"#react","children":{},"count":15},"/tags/hooks":{"label":"#hooks","children":{},"count":2},"/tags/components":{"label":"#components","children":{},"count":1},"/tags/scrum":{"label":"#scrum","children":{},"count":2},"/tags/technicaldebt":{"label":"#technicaldebt","children":{},"count":1},"/tags/projectmanagement":{"label":"#projectmanagement","children":{},"count":1},"/tags/email":{"label":"#email","children":{},"count":22},"/tags/decoder":{"label":"#decoder","children":{},"count":1},"/tags/json":{"label":"#json","children":{},"count":1},"/tags/materialized-view":{"label":"#materialized-view","children":{},"count":1},"/tags/data-warehouse":{"label":"#data-warehouse","children":{},"count":1},"/tags/mapreduce":{"label":"#mapreduce","children":{},"count":1},"/tags/distributed":{"label":"#distributed","children":{},"count":3},"/tags/form":{"label":"#form","children":{},"count":1},"/tags/uilibraries":{"label":"#uilibraries","children":{},"count":1},"/tags/migrations":{"label":"#migrations","children":{},"count":1},"/tags/agile":{"label":"#agile","children":{},"count":6},"/tags/behavior-driven-development":{"label":"#behavior-driven-development","children":{},"count":1},"/tags/testing":{"label":"#testing","children":{},"count":4},"/tags/ubiquitous-language":{"label":"#ubiquitous-language","children":{},"count":1},"/tags/forward-proxy":{"label":"#forward-proxy","children":{},"count":1},"/tags/apprenticeship":{"label":"#apprenticeship","children":{},"count":4},"/tags/remote":{"label":"#remote","children":{},"count":12},"/tags/showcase":{"label":"#showcase","children":{},"count":1},"/tags/practice":{"label":"#practice","children":{},"count":7},"/tags/internship":{"label":"#internship","children":{},"count":2},"/tags/swap":{"label":"#swap","children":{},"count":2},"/tags/quant":{"label":"#quant","children":{},"count":1},"/tags/radio":{"label":"#radio","children":{},"count":3},"/tags/writing":{"label":"#writing","children":{},"count":1},"/tags/english":{"label":"#english","children":{},"count":1},"/tags/apprentice":{"label":"#apprentice","children":{},"count":1},"/tags/meeting":{"label":"#meeting","children":{},"count":4},"/tags/us":{"label":"#us","children":{},"count":4},"/tags/mbti":{"label":"#mbti","children":{},"count":6},"/tags/intj":{"label":"#intj","children":{},"count":1},"/tags/istp":{"label":"#istp","children":{},"count":1},"/tags/estj":{"label":"#estj","children":{},"count":1},"/tags/istj":{"label":"#istj","children":{},"count":1},"/tags/personalities":{"label":"#personalities","children":{},"count":1},"/tags/management":{"label":"#management","children":{},"count":4},"/tags/early-stage":{"label":"#early-stage","children":{},"count":3},"/tags/design-thinking":{"label":"#design-thinking","children":{},"count":2},"/tags/healthcare":{"label":"#healthcare","children":{},"count":1},"/tags/browser-extension":{"label":"#browser-extension","children":{},"count":2},"/tags/git":{"label":"#git","children":{},"count":2},"/tags/marketplace":{"label":"#marketplace","children":{},"count":2},"/tags/tips":{"label":"#tips","children":{},"count":10},"/tags/real-estate":{"label":"#real-estate","children":{},"count":1},"/tags/nocode":{"label":"#nocode","children":{},"count":1},"/tags/hospitality":{"label":"#hospitality","children":{},"count":1},"/tags/ride-hailing":{"label":"#ride-hailing","children":{},"count":1},"/tags/iot":{"label":"#iot","children":{},"count":1},"/tags/macos":{"label":"#macos","children":{},"count":3},"/tags/swift":{"label":"#swift","children":{},"count":7},"/tags/partnership":{"label":"#partnership","children":{},"count":1},"/tags/pm":{"label":"#pm","children":{},"count":4},"/tags/travel":{"label":"#travel","children":{},"count":1},"/tags/operation":{"label":"#operation","children":{},"count":7},"/tags/idea":{"label":"#idea","children":{},"count":1},"/tags/ventures":{"label":"#ventures","children":{},"count":3},"/tags/purpose":{"label":"#purpose","children":{},"count":2},"/tags/wasm":{"label":"#wasm","children":{},"count":2},"/tags/transparency":{"label":"#transparency","children":{},"count":1},"/tags/event-sourcing":{"label":"#event-sourcing","children":{},"count":1},"/tags/sdlc":{"label":"#sdlc","children":{},"count":1},"/tags/modeling":{"label":"#modeling","children":{},"count":2},"/tags/goal":{"label":"#goal","children":{},"count":2},"/tags/license":{"label":"#license","children":{},"count":1},"/tags/template":{"label":"#template","children":{},"count":20},"/tags/k8s":{"label":"#k8s","children":{},"count":1},"/tags/js":{"label":"#js","children":{},"count":2},"/tags/clojure":{"label":"#clojure","children":{},"count":1},"/tags/react.js":{"label":"#react.js","children":{},"count":2},"/tags/employee":{"label":"#employee","children":{},"count":2},"/tags/onboarding":{"label":"#onboarding","children":{},"count":1},"/tags/assets":{"label":"#assets","children":{},"count":1},"/tags/company":{"label":"#company","children":{},"count":1},"/tags/tooling":{"label":"#tooling","children":{},"count":9},"/tags/human-resource":{"label":"#human-resource","children":{},"count":1},"/tags/dcos":{"label":"#dcos","children":{},"count":5},"/tags/docker":{"label":"#docker","children":{},"count":11},"/tags/okr":{"label":"#okr","children":{},"count":1},"/tags/oss":{"label":"#oss","children":{},"count":1},"/tags/newsletter":{"label":"#newsletter","children":{},"count":45},"/tags/web3":{"label":"#web3","children":{},"count":4},"/tags/monitoring":{"label":"#monitoring","children":{},"count":2},"/tags/upptime":{"label":"#upptime","children":{},"count":1},"/tags/mcp":{"label":"#mcp","children":{},"count":3},"/tags/overleaf":{"label":"#overleaf","children":{},"count":1},"/tags/slide":{"label":"#slide","children":{},"count":1},"/tags/office-hours":{"label":"#office-hours","children":{},"count":28},"/tags/btc":{"label":"#btc","children":{},"count":1},"/tags/forward-engineering":{"label":"#forward-engineering","children":{},"count":14},"/tags/tech-community":{"label":"#tech-community","children":{},"count":1},"/tags/weekly-digest":{"label":"#weekly-digest","children":{},"count":15},"/tags/wrap-up":{"label":"#wrap-up","children":{},"count":7},"/tags/real-time":{"label":"#real-time","children":{},"count":1},"/tags/phoenix-live-view":{"label":"#phoenix-live-view","children":{},"count":1},"/tags/timescaledb":{"label":"#timescaledb","children":{},"count":1},"/tags/go-weekly":{"label":"#go-weekly","children":{},"count":24},"/tags/finance":{"label":"#finance","children":{},"count":1},"/tags/agents":{"label":"#agents","children":{},"count":4},"/tags/defi":{"label":"#defi","children":{},"count":2},"/tags/aider":{"label":"#aider","children":{},"count":2},"/tags/qwen2.5":{"label":"#qwen2.5","children":{},"count":1},"/tags/openhand":{"label":"#openhand","children":{},"count":1},"/tags/predicted output":{"label":"#predicted output","children":{},"count":1},"/tags/project-management":{"label":"#project-management","children":{},"count":1},"/tags/copilots":{"label":"#copilots","children":{},"count":2},"/tags/team-management":{"label":"#team-management","children":{},"count":1},"/tags/mongodb":{"label":"#mongodb","children":{},"count":1},"/tags/salesforce":{"label":"#salesforce","children":{},"count":1},"/tags/use cases":{"label":"#use cases","children":{},"count":2},"/tags/design-system":{"label":"#design-system","children":{},"count":1},"/tags/storybook":{"label":"#storybook","children":{},"count":1},"/tags/hook":{"label":"#hook","children":{},"count":1},"/tags/cline":{"label":"#cline","children":{},"count":1},"/tags/realtime api":{"label":"#realtime api","children":{},"count":1},"/tags/interface":{"label":"#interface","children":{},"count":1},"/tags/import":{"label":"#import","children":{},"count":1},"/tags/package":{"label":"#package","children":{},"count":1},"/tags/yelp":{"label":"#yelp","children":{},"count":1},"/tags/generics":{"label":"#generics","children":{},"count":2},"/tags/log":{"label":"#log","children":{},"count":1},"/tags/pillar":{"label":"#pillar","children":{},"count":3},"/tags/metric":{"label":"#metric","children":{},"count":1},"/tags/tracing":{"label":"#tracing","children":{},"count":1},"/tags/intent-classification":{"label":"#intent-classification","children":{},"count":1},"/tags/prompting":{"label":"#prompting","children":{},"count":1},"/tags/life-at-dwarves":{"label":"#life-at-dwarves","children":{},"count":8},"/tags/changelog":{"label":"#changelog","children":{},"count":1},"/tags/test":{"label":"#test","children":{},"count":1},"/tags/language":{"label":"#language","children":{},"count":5},"/tags/ai-agents":{"label":"#ai-agents","children":{},"count":2},"/tags/ai-evaluation":{"label":"#ai-evaluation","children":{},"count":1},"/tags/prompt-engineering":{"label":"#prompt-engineering","children":{},"count":4},"/tags/ai-integration":{"label":"#ai-integration","children":{},"count":1},"/tags/networking":{"label":"#networking","children":{},"count":7},"/tags/finite-automata":{"label":"#finite-automata","children":{},"count":1},"/tags/pattern-matching":{"label":"#pattern-matching","children":{},"count":1},"/tags/state-machines":{"label":"#state-machines","children":{},"count":1},"/tags/java":{"label":"#java","children":{},"count":1},"/tags/programming":{"label":"#programming","children":{},"count":1},"/tags/caching":{"label":"#caching","children":{},"count":1},"/tags/devbox":{"label":"#devbox","children":{},"count":17},"/tags/nix":{"label":"#nix","children":{},"count":9},"/tags/generative-ui":{"label":"#generative-ui","children":{},"count":1},"/tags/function-calling":{"label":"#function-calling","children":{},"count":1},"/tags/ton":{"label":"#ton","children":{},"count":2},"/tags/ai-powered":{"label":"#ai-powered","children":{},"count":1},"/tags/pattern":{"label":"#pattern","children":{},"count":1},"/tags/supervisor-architecture":{"label":"#supervisor-architecture","children":{},"count":1},"/tags/document-processing":{"label":"#document-processing","children":{},"count":1},"/tags/information-retrieval":{"label":"#information-retrieval","children":{},"count":1},"/tags/iterators":{"label":"#iterators","children":{},"count":1},"/tags/reinforcement-learning":{"label":"#reinforcement-learning","children":{},"count":3},"/tags/kernel-programing":{"label":"#kernel-programing","children":{},"count":1},"/tags/anchor":{"label":"#anchor","children":{},"count":2},"/tags/containerization":{"label":"#containerization","children":{},"count":4},"/tags/virtualization":{"label":"#virtualization","children":{},"count":4},"/tags/meet-up":{"label":"#meet-up","children":{},"count":4},"/tags/meetup":{"label":"#meetup","children":{},"count":2},"/tags/motivation":{"label":"#motivation","children":{},"count":1},"/tags/cybersecurity":{"label":"#cybersecurity","children":{},"count":2},"/tags/serverless":{"label":"#serverless","children":{},"count":1},"/tags/doty":{"label":"#doty","children":{},"count":5},"/tags/websocket":{"label":"#websocket","children":{},"count":1},"/tags/protocols":{"label":"#protocols","children":{},"count":1},"/tags/nextjs":{"label":"#nextjs","children":{},"count":2},"/tags/rendering":{"label":"#rendering","children":{},"count":1},"/tags/dom":{"label":"#dom","children":{},"count":3},"/tags/cssom":{"label":"#cssom","children":{},"count":1},"/tags/render-tree":{"label":"#render-tree","children":{},"count":1},"/tags/iframe":{"label":"#iframe","children":{},"count":1},"/tags/postmessage":{"label":"#postmessage","children":{},"count":1},"/tags/mock-service-worker":{"label":"#mock-service-worker","children":{},"count":1},"/tags/api-mocking":{"label":"#api-mocking","children":{},"count":1},"/tags/web-development-tool":{"label":"#web-development-tool","children":{},"count":1},"/tags/data-fetching":{"label":"#data-fetching","children":{},"count":1},"/tags/frontend,":{"label":"#frontend,","children":{},"count":1},"/tags/graphql":{"label":"#graphql","children":{},"count":1},"/tags/reactjs":{"label":"#reactjs","children":{},"count":2},"/tags/scroll-driven-animations":{"label":"#scroll-driven-animations","children":{},"count":1},"/tags/animations":{"label":"#animations","children":{},"count":1},"/tags/intersection-observer":{"label":"#intersection-observer","children":{},"count":1},"/tags/server-component":{"label":"#server-component","children":{},"count":1},"/tags/caching-data":{"label":"#caching-data","children":{},"count":1},"/tags/social-networks":{"label":"#social-networks","children":{},"count":1},"/tags/foundation-model":{"label":"#foundation-model","children":{},"count":1},"/tags/fine-tuning":{"label":"#fine-tuning","children":{},"count":1},"/tags/vector database":{"label":"#vector database","children":{},"count":1},"/tags/shadow-dom":{"label":"#shadow-dom","children":{},"count":1},"/tags/web-api":{"label":"#web-api","children":{},"count":1},"/tags/swr-infinite":{"label":"#swr-infinite","children":{},"count":1},"/tags/web-design":{"label":"#web-design","children":{},"count":1},"/tags/tuning-llm":{"label":"#tuning-llm","children":{},"count":2},"/tags/langchain":{"label":"#langchain","children":{},"count":1},"/tags/translation":{"label":"#translation","children":{},"count":1},"/tags/profiling":{"label":"#profiling","children":{},"count":1},"/tags/state-mangement":{"label":"#state-mangement","children":{},"count":1},"/tags/global-state-management":{"label":"#global-state-management","children":{},"count":1},"/tags/css":{"label":"#css","children":{},"count":5},"/tags/fonts":{"label":"#fonts","children":{},"count":1},"/tags/variable-fonts":{"label":"#variable-fonts","children":{},"count":1},"/tags/state-management":{"label":"#state-management","children":{},"count":2},"/tags/component":{"label":"#component","children":{},"count":1},"/tags/proof-of-knowledge":{"label":"#proof-of-knowledge","children":{},"count":1},"/tags/fronten":{"label":"#fronten","children":{},"count":1},"/tags/typescript":{"label":"#typescript","children":{},"count":4},"/tags/analytics-tools":{"label":"#analytics-tools","children":{},"count":1},"/tags/analytics-platform":{"label":"#analytics-platform","children":{},"count":1},"/tags/software engineer":{"label":"#software engineer","children":{},"count":1},"/tags/parsing":{"label":"#parsing","children":{},"count":1},"/tags/technology":{"label":"#technology","children":{},"count":5},"/tags/validation":{"label":"#validation","children":{},"count":1},"/tags/webassembly":{"label":"#webassembly","children":{},"count":1},"/tags/sandbox":{"label":"#sandbox","children":{},"count":1},"/tags/zk-rollup":{"label":"#zk-rollup","children":{},"count":2},"/tags/polygon":{"label":"#polygon","children":{},"count":1},"/tags/starknet":{"label":"#starknet","children":{},"count":1},"/tags/ethereum":{"label":"#ethereum","children":{},"count":2},"/tags/zero-knowledge":{"label":"#zero-knowledge","children":{},"count":1},"/tags/atomic-css":{"label":"#atomic-css","children":{},"count":1},"/tags/client-side":{"label":"#client-side","children":{},"count":1},"/tags/storage":{"label":"#storage","children":{},"count":1},"/tags/frontend/performance":{"label":"#frontend/performance","children":{},"count":2},"/tags/wai-aria":{"label":"#wai-aria","children":{},"count":1},"/tags/accessibility":{"label":"#accessibility","children":{},"count":4},"/tags/polymorphic-component":{"label":"#polymorphic-component","children":{},"count":1},"/tags/threejs":{"label":"#threejs","children":{},"count":1},"/tags/web-performance":{"label":"#web-performance","children":{},"count":2},"/tags/html":{"label":"#html","children":{},"count":4},"/tags/animation":{"label":"#animation","children":{},"count":1},"/tags/zk-proof":{"label":"#zk-proof","children":{},"count":1},"/tags/guides":{"label":"#guides","children":{},"count":1},"/tags/responsive-design":{"label":"#responsive-design","children":{},"count":1},"/tags/hsl":{"label":"#hsl","children":{},"count":1},"/tags/javascript":{"label":"#javascript","children":{},"count":4},"/tags/css-in-js":{"label":"#css-in-js","children":{},"count":1},"/tags/tip":{"label":"#tip","children":{},"count":1},"/tags/dark-mode":{"label":"#dark-mode","children":{},"count":1},"/tags/multisign-wallet":{"label":"#multisign-wallet","children":{},"count":1},"/tags/virtual-dom":{"label":"#virtual-dom","children":{},"count":1},"/tags/senior":{"label":"#senior","children":{},"count":1},"/tags/native-modules":{"label":"#native-modules","children":{},"count":1},"/tags/vitejs":{"label":"#vitejs","children":{},"count":1},"/tags/esm":{"label":"#esm","children":{},"count":1},"/tags/modules":{"label":"#modules","children":{},"count":1},"/tags/blockchain-bridge":{"label":"#blockchain-bridge","children":{},"count":1},"/tags/foundational-topics":{"label":"#foundational-topics","children":{},"count":5},"/tags/distributed-systems":{"label":"#distributed-systems","children":{},"count":1},"/tags/pos":{"label":"#pos","children":{},"count":1},"/tags/smart-contract":{"label":"#smart-contract","children":{},"count":1},"/tags/atomic-design":{"label":"#atomic-design","children":{},"count":1},"/tags/a11y":{"label":"#a11y","children":{},"count":1},"/tags/useeffect":{"label":"#useeffect","children":{},"count":1},"/tags/concurrency":{"label":"#concurrency","children":{},"count":2},"/tags/parallelism":{"label":"#parallelism","children":{},"count":1},"/tags/liquidity":{"label":"#liquidity","children":{},"count":1},"/tags/engineering/frontend":{"label":"#engineering/frontend","children":{},"count":1},"/tags/designer":{"label":"#designer","children":{},"count":1},"/tags/funding":{"label":"#funding","children":{},"count":2},"/tags/wfh":{"label":"#wfh","children":{},"count":1},"/tags/tech radar":{"label":"#tech radar","children":{},"count":1},"/tags/policy":{"label":"#policy","children":{},"count":1},"/tags/vim":{"label":"#vim","children":{},"count":1}}}},"ogifMemos":[{"content":"\n### Topics and Highlights\n\n- **Swap ICY-BTC:** Huy shared updates on the ICY-BTC swap mechanism, explaining the current state and adjustments needed to ensure accurate ICY valuation during swaps.\n- **GitHub BotL:** Thanh introduced a GitHub bot to automate PR reviews, aiming to improve processing speed and consistency in code management.\n- **Memo UI:** The team presented improvements to the Memo user interface, focusing on better data access and user experience.\n- **Agentic: MCP-DB:** Huy discussed the MCP-DB system, highlighting how it handles data storage and retrieval to support agents in automated workflows.\n- **Pocket Turning, Recapable:** Vincent shared progress on the Pocket Turning and Recapable, outlining the completion of core gameplay and next steps.\n- **Funding Rate Arbitrage:**  Antran presented a strategy for funding rate arbitrage across multiple exchanges, addressing technical challenges and execution strategies.\n\n### Vietnamese Transcript\n\n**[05:30]** Hôm nay chắc mình bắt đầu sớm nha. Buổi hôm nay chắc kết hợp với lại anh trong buổi meeting một xíu. Một phần là sẽ làm showcase, cái thứ hai là anh tổng kết một số việc mà bữa trước có trao đổi với mấy anh em á. Cái số hai, cái số ba là mình sẽ bắt đầu cho mấy anh em đăng ký công việc. Hiện tại để mà dễ trước, chắc là mình sẽ để cho Huy Nguyễn đi show mấy cái phần bên Huy trước, liên quan tới ICY một tí, xong rồi show một số cái về tech mà team mình đang làm nè. Để mình có một cái snapshot về chuyện là team tech thì hiện nay như thế nào nhé. Rồi sắp tới thì team mình cần gì, với lại mấy anh em xem contribute được gì vào đó ha.\n\n**[06:35]** Huy, Thành đâu? Nhường sân khấu này nè. Rồi ok, nội dung đầu tiên, chắc là bên ICY Swap trước đi. Mình announce đó, hồi tuần trước, tuần này deploy lên rồi thì giờ những cái khác biệt như thế nào, chắc nhờ Huy đi lại hết mấy series đó.\n\n**[07:29]** Alo, rồi rồi, đã xem màn hình rồi. Thì bây giờ mọi người có thể vào trang ICY Swap để mà swap được rồi. Đây, mình chỉ số liệu nha. Nhưng mà ở trên đây thì nó đang ready hết tất cả mọi thứ rồi. Việc làm duy nhất bây giờ là đang ngồi soát lại mấy cái số ICY á. Tại vì lúc trước vận hành á, thì mình vận hành theo kiểu là mình neo cái giá ICY, nên mình cũng không quan tâm cái lượng lưu thông (circulated) lắm. Nên có mấy trường hợp là mình để vô mấy cái ví của team, hoặc là chuyển qua mấy cái Mochi Balance của em hoặc là của anh Bảo. Thì mấy cái đó đang cần rà soát lại để mà nó ra cái số lưu thông đúng. Tại vì giờ mình sẽ ngồi, cái giá của mình nó sẽ dynamic theo cái pool nên cần ngồi check lại cái đó thì cũng gần xong hết rồi.\n\n**[09:09]** Giờ còn mỗi cái account của anh Bảo là cần kiểm tra lại thôi. Nhớ có đợt là chuyển cho anh Bảo, giờ đang ngồi xem lại cái phần đó rồi cộng trừ lại rồi cắt cái phần đó ra khỏi cái circulated thì số này nó sẽ ra đúng. Còn lại hiện tại muốn swap ủng hộ thì cũng có thể swap được ở trên trang này. Lịch là đang vậy. Em show thử cái list Holder của mình hiện tại cho mấy anh em xem chắc cần biết nhiều hơn xíu. Trước giờ mọi người tham gia không quan tâm nhiều lắm nhưng mà chắc lần này thì mình cần để ý hơn.\n\n**[09:51]** ICY của mình mình deploy ở trên Base, đúng không? Nên khi anh em vào trong cái list Holder, mọi người sẽ thấy được một cái list khoảng tất cả những cái ví nào đang được giữ ICY của team mình, thì là CCK Holder ha. Là một. Rồi thì cái link để mà vô đây chắc Huy share nha. Chứ mọi người lên mà search thì chắc không biết được đâu.\n\nĐầu tiên là anh em cần nắm cái này. Quay qua đoạn này rồi. Anh nghĩ mấy anh em cần quan tâm phần này nhiều hơn xíu. Nó trở thành cái norm của thế giới tech luôn rồi, không cần làm gì mới nữa. Nên anh em nắm được thì sẽ ok hơn.\n\n**[10:33]** ICY của mình hiện đã được list. Trong danh sách này có các ví minter, ví dùng để lập ngân sách cho các hoạt động, và một số ví đang nắm giữ lượng ICY lớn. Các hoạt động liên quan đến staking ICY sẽ được triển khai dần dần trong thời gian tới. Đây là thông tin đầu tiên anh em cần nắm rõ.\n\n**[11:15]** Huy, demo thử luồng swap đi. Có ai có địa chỉ Bitcoin với một ít ICY không? Vincent có ở đây không? Ok, giờ thử swap từ ICY sang Bitcoin. Giá hiện tại được tính theo cơ chế động dựa trên lượng ICY đang lưu hành và pool. Chức năng swap rất đơn giản, chỉ cần điền số lượng, bấm swap là xong.\n\n**[12:27]** Khoan đã, đừng nhập địa chỉ ảo. Ok, vậy là ổn rồi. Khung đầu tiên là ICY như bình thường. Ở dưới thì đang hiển thị đơn vị là satoshi, tức là đơn vị nhỏ nhất của Bitcoin. Khi nhập số lượng vào, nó sẽ tự động chuyển đổi. Tuy nhiên, tỷ giá hiện tại đang bị lệch một chút, khoảng 1.2 thay vì 1.5. Đây chắc là lỗi tính toán nhỏ, chỉnh lại là được.\n\n**[13:28]** Cần có số ICY tối thiểu để swap. Thử nhập 30 ICY xem sao. Refresh lại thử xem có được không.\n\n**[14:43]** Hình như không đủ tiền trong ví rồi. Bạn có ETH trên Base không? Chuyển qua Base và kiểm tra lại xem.\n\n**[15:51]** Không phải lỗi đó đâu. Vấn đề là account chưa được đăng ký nên không thể thực hiện giao dịch. Sẽ fix phần đó sau. Mục tiêu ở đây là giúp mọi người hiểu rõ hơn về cơ chế swap và cách định giá token. Nếu nắm rõ thì sau này sẽ dễ dàng hơn trong việc quản lý tokenomics.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pj13pwqkVdQ?si=0LryX12wLbTu3i1m\u0026amp;start=806\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**[16:47]** Huy, giải thích nhanh lại cơ chế tính giá đi. Lần trước Quan demo chưa nói kỹ phần đó. Giá của ICY được xác định theo cơ chế minting, nghĩa là giá sẽ không thay đổi mạnh nếu có ai đó swap số lượng lớn. Nó không hoạt động theo kiểu cơ chế tạo lập thị trường tự động (AMM) mà giá sẽ được kiểm soát theo cơ chế minting. Cơ chế này giúp giá duy trì ổn định ngay cả khi có giao dịch lớn.\n\n**[17:43]** Hoàn toàn là nó phụ thuộc vào Bitcoin. Nên nếu giá Bitcoin tăng thì lượng ICY mà anh em đang cầm sẽ tăng về giá trị USD. Còn về cơ chế minting, nhờ Huy giải thích thêm một chút. Nói chung là cơ chế chung của mình trước giờ là mình sẽ cố định giá trị của ICY theo USDC. Anh em không cần quan tâm nhiều, cứ hiểu đơn giản là một ICY tương đương với 1.5 USD.\n\n**[18:37]**Phần đảm bảo này là để giúp team vận hành có thể đảm bảo là tới ngày thì sẽ đổi USDC vào trong contract để mọi người swap. Tỷ giá swap trong contract cũ là cố định ở mức 1.5 ICY, nhưng đó là model cũ. Model mới của mình thì linh hoạt hơn. Nếu anh em đã dùng Uniswap hay các AMM (Automatic Market Maker) khác thì nó cũng tương tự một chút. Ở đây, cơ chế hoạt động là bên dưới có một pool thanh khoản (liquidity pool), trong đó chứa cả ETH và USDC. Tùy vào tình hình của pool lúc đó, tỷ giá sẽ được điều chỉnh dựa trên lượng ETH và USDC trong pool.\n\n**[19:18]** Cơ chế của mình cũng tương tự như vậy. Giá ICY sẽ được quyết định bởi lượng Bitcoin trong pool và lượng ICY đang được lưu hành. Công thức đơn giản thôi: mình có lượng ICY (X), có lượng BTC (Y) trong pool, thì X/Y sẽ ra được giá trị của một ICY tính theo BTC. Công thức này là công thức toán học cơ bản, không có gì phức tạp.\n\n**[19:55]** Do cơ chế hoạt động của mình, sẽ có hai thời điểm làm thay đổi thanh khoản:\n\n1. **Thời điểm đầu tiên** là vào mỗi tháng, team vận hành sẽ đổ thêm BTC vào pool để làm chi phí cho các hoạt động của team. Lúc này giá ICY sẽ tăng lên một chút vì lượng BTC trong pool tăng lên.\n2. **Thời điểm thứ hai** là khi team đẩy thêm ICY vào pool (minting thêm). Khi mint thêm ICY, giá ICY trên thị trường sẽ giảm xuống do lượng ICY trong pool tăng lên.\n\n**[20:35]** Hai trường hợp trên sẽ ảnh hưởng trực tiếp đến giá ICY. Còn nếu giá Bitcoin thay đổi thì giá trị USD của ICY có thể thay đổi, nhưng giá ICY tính theo BTC thì không thay đổi. Market impact từ Bitcoin là yếu tố bên ngoài, không ảnh hưởng trực tiếp đến việc minting hoặc giá trị ICY trong pool.\n\n**[21:12]** Anh em có câu hỏi gì thêm thì đặt câu hỏi, tí nữa sẽ trả lời sau. À, có câu hỏi về việc swap ngược từ BTC về ICY đúng không? Hiện tại thì chưa có chức năng đó. Hiện tại chỉ hỗ trợ swap từ ICY sang BTC thôi, không có chức năng swap ngược lại. Tức là mua vào thì được, nhưng bán ra thì chưa hỗ trợ.\n\n**[21:40]** Cảm ơn Huy. Có gì cần lưu ý thêm không? Cần lưu ý là hiện tại vẫn đang trong giai đoạn thử nghiệm nên có thể có một số trường hợp ngoại lệ. Ví dụ như một số tình huống có thể phát sinh khi swap hoặc thanh khoản chưa đủ. Về cơ bản thì luồng hiện tại vẫn đang hoạt động ổn định.\n\n**[22:00]** Như là số lượng ICY tối thiểu để swap. Vì bản chất là team mình đang cover cái phần phí mà để mà làm gas trên ETH, trên Base và cả trên BTC luôn thì nên đang kiểu đang giới hạn cái số ICY nó swap nhiều tí để mà hạn chế với cái việc mà mọi người swap tầm 1-2 ICY để test á thì nó tốn cái chi phí gas nên đang để tầm trên 20 ICY mới cho mọi người swap trên web.\n\nCái thứ hai là ở cái do cái việc mà mình mint thêm ICY thì nó sẽ làm thay đổi giá thị trường, thì nên em đang disable luôn cái phần mà cơ chế cái ứng lương trước của mình.\n\n**[22:37]** Tức là đồng loạt ứng lương thì nó sẽ ảnh hưởng giá đúng không? Vậy cái lesson learn trong cái này đó là sau đợt này làm thì có vài điểm mà anh đang thấy là bắt đầu team mình đang tập trung vô build những cái tool nó hỗ trợ mình hoạt động. Cũng là một số cái thử nghiệm mới, cũng là một số cái mà hỗ trợ hoạt động thiệt sự. Nhưng mà sau khi xong mấy cái bài này thì nó sẽ ra được một số mấy cái article liên quan thì mấy anh em nếu mà trước đó không có tham gia những cái dự án đó có thể tìm lại những cái bài đó để mà coi được cái game, cái knowledge game từ cái đợt đó là cái gì của mấy anh em làm dự án đó ha.\n\n**[23:24]** Rồi thì trong cái vụ ICY Swap đợt này chắc là được hai ba bài phải không? Dạ, như được ba bài. Còn kiểu viết nhiều thêm thì vẫn có nhiều cái để viết. Ừ, thôi đó cứ thong thả từ từ đi.\n\n**[24:02]** Sau phần của Huy, anh cảm ơn Huy rồi chuyển sang nội dung thứ hai liên quan đến những gì team mình đang làm. Anh Bảo ai nói trước cũng được, nhưng chắc là để Thành nói trước. Thành bảo là em nói trước cũng được, em sẽ gom lại hết để anh cho mọi người biết team đang ở giai đoạn nào. Nhưng anh bảo là để Thành nói trước đi, tại vì đang có người bấm chuông. Rồi anh mời Thành bắt đầu.\n\n**[25:00]** Mọi người, Memo của mình là một trong những cái đợt lớn đợt này, có upgrade format lại cho nhìn nó ok hơn tí. Mình luôn muốn mình tạo những cái map content, những cái thứ mà mình đọc được cái mình up lên đây. Nhưng mà hiện tại cái mô hình đó thật ra nó cũng không có còn quá hiệu quả với chuyện là mấy cái model ra đời nó nén dữ liệu lại, rồi mình query trực tiếp từ đó ra thì nó sẽ hiệu quả hơn.\n\nThì cái point của chuyện là đưa những cái kiến thức mà nó bình thường lên trên Memo thì nó cũng không phù hợp lắm ha. Nên đợt này lúc mà làm lại thì có một cái ý chính để mà muốn nói với anh em đó là Memo hiện tại sẽ được dùng chỉ cho mục đích duy nhất thôi ,  đó là cái knowledge gain mà từ dự án.\n\nCái đó là gần như là những cái mới mà nó xuất phát từ chính cái hoạt động của cái team mình. Gần như trên đây sau này nó sẽ gồm là liên quan tới lĩnh vực gì đó, mình đã làm gì đó trong đó. Nó có nhiều hơn, maybe là sau một giai đoạn thì khi tụi nó train lại cái model thì những cái dữ liệu của mình á thì nó sẽ trở thành một phần của kiến thức chung cho cả cộng đồng.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pj13pwqkVdQ?si=MhsFuFFQ5NFKTlYS\u0026amp;start=1556\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**[25:39]** Và cái phần này anh nghĩ là nó sẽ giúp ích rất nhiều cho cái chuyện mà mọi người làm kiểu training lại cho AI model sau này, hoặc là mấy cái chuyện mà mình muốn nó có cái việc mà suggestion kiểu tự động ấy.\n\n**[26:24]** Nội dung sẽ trở thành một phần trong mô hình đó hoặc nếu có mấy công cụ tìm kiếm trên internet, thì có thể bài của mình chỉ là một phần nhỏ trong nguồn tài liệu được tham khảo vào thôi, giống như là một phần nhỏ trong citation. Điều này cũng không có vấn đề gì lớn. Nhưng nhìn chung, toàn bộ những nội dung này sẽ gần như trở thành spirit của team.\n\nTrong lần nâng cấp lớn này, có một điểm chính mà Tuấn đã hoàn thành chưa nhỉ? Tuấn ơi, phần liên quan đến việc đồng bộ toàn bộ dữ liệu của team, nhất là về phần nội dung, hiện đang được định hướng như vậy để các thành viên nắm rõ hơn.\n\n**[27:00]** Tức là sau đợt này, các thành viên đang tham gia vào các dự án sẽ có xu hướng ngồi lại với nhau để xem xét kỹ hơn từ những dự án đó, và xác định rõ phần **knowledge gain** (kiến thức thu được) từ chính các dự án đó là gì. Sau đó, team sẽ đưa lên Memo làm nguồn tài liệu nội bộ cho team.\n\nPhần thứ hai là ở cuối mỗi bài sẽ có một phần liên quan đến **group of reading**. Hiện tại phần này vẫn chưa hoàn chỉnh, nhưng ý tưởng là sau khi hoàn thiện, sẽ có thêm phần thông tin tổng hợp về bài viết để người đọc có thể tra cứu và học thêm từ bài viết đó.\n\n**[27:47]** Ngoài ra, tất cả dữ liệu của team được viết ra sẽ được gán định danh ví dụ như **GitHub**, **Discord**, hoặc những kênh nội bộ khác. Dữ liệu này sẽ được upload lên dạng **blockchain storage** trên nền tảng **Arweave (AV)** – một nền tảng lưu trữ phi tập trung. Điều này giúp cho nội dung của team có một định danh rõ ràng và minh bạch.\n\nThêm vào đó, người đọc sẽ có thể xem lại bài viết, đánh giá hoặc để lại phản hồi trực tiếp trên bài viết. Đây là một phần của ý tưởng nâng cấp mới cho trang **Memo** của team.\n\n**[28:39]** Trước đây, team đã có ý định sử dụng Obsidian để quản lý nội dung, nhưng có vẻ như một số thành viên gặp khó khăn trong việc làm quen với công cụ đó. Vì vậy, hiện tại để làm cho mọi thứ đơn giản hơn, team sẽ chuyển sang cơ chế trực tiếp hơn. Cụ thể là thay vì phải làm qua Obsidian, các thành viên có thể submit nội dung trực tiếp vào repository của thư viện chung của team.\n\nCác thành viên chỉ cần đưa nội dung vào và submit trực tiếp qua nền tảng này, không cần phải tuân theo workflow bắt buộc của Obsidian nữa. Nếu ai vẫn muốn dùng Obsidian thì không sao, nhưng nếu không dùng thì cũng không ảnh hưởng gì cả. Đây là thay đổi cơ bản nhất trong hệ thống Memo của team.\n\n**[29:24]** Hiện tại team đang làm một số dự án chính, bao gồm:\n\n1. Bitcoin Swap – đã nhắc tới ở phần trước.\n2. Memo – vừa mới trình bày xong.\n3. Hai dự án nhỏ khác:\n\n- **agentic** – nhóm của Quang và Huy đang phát triển.\n- **github bot** – nhóm của Thành đang thực hiện, hiện đang test thử.\n\nGiờ chắc nhường lại cho Thành để chia sẻ thêm về những nội dung này.\n\n**[30:32]** Dự án này đã được khởi động hơn một tuần và đã chính thức chạy code được hơn một tuần. Mục đích chính của nó là tạo ra một hệ thống nhắc nhở (reminder). Trước đây, team thường gặp tình huống khi tạo pull request (PR), mọi người hay để đó và chờ chạy xong rồi quên luôn việc cần review. Tool này sẽ phục vụ cho việc theo dõi và cập nhật thông tin về các hoạt động hàng ngày trên github hoặc hàng tuần trên các kênh giao tiếp nội bộ của team.\n\n**[31:18]** Hệ thống này được thiết kế dưới dạng một tích hợp đơn giản. Luồng hoạt động cơ bản bao gồm một số use case như: thông báo cho người được assign để review, tương tác với GitHub API, và post thông tin vào các kênh nội bộ như Discord hoặc Slack. Hiện tại, team đang test thử trên Discord. Ngoài ra, team cũng đang thử nghiệm với agentic và một framework mới gọi là **Mastra AI**.\n\nFramework này khác với các tool Python thông thường. Một số thành viên trong team không quen làm việc với Python, nên team muốn thử nghiệm xem liệu sử dụng framework mới này có hiệu quả hơn các giải pháp hiện tại hay không. Framework này hỗ trợ các tính năng như setup môi trường, define các trạng thái để quản lý dữ liệu, và cho phép cấu hình lại tùy theo nhu cầu của team.\n\n**[32:19]** Cấu trúc của hệ thống này có hai phần chính:\n\n1. **Agentic App** – Đây là ứng dụng chính để xử lý các hoạt động của hệ thống.\n2. **Discord App** – Hỗ trợ việc gửi thông báo vào Discord.\n\nNgoài ra, hệ thống còn có một vài component phụ, như workflow để xử lý công việc theo lịch trình, kiểm tra và thông báo cho developer nếu có bất kỳ pull request nào đang chờ được review. Nếu pull request vượt quá một khoảng thời gian nhất định, hệ thống sẽ gửi thông báo để nhắc người thực hiện review.\n\n**[33:12]** Agentic App sẽ expose một vài API cho phép chat và theo dõi trạng thái của các pull request. Khi có một pull request được tạo ra, hệ thống sẽ tự động xác định các điều kiện như trạng thái của pull request (work in progress hay chưa), thời gian tạo pull request, và sẽ gửi thông báo cho người review sau khoảng 30 phút kể từ lúc tạo. Ví dụ: nếu có một pull request cần được review nhưng không có ai assigned hoặc đã quá thời gian xử lý, hệ thống sẽ tự động ping lại người phụ trách.\n\n**[35:02]** Thay vì phải theo dõi thủ công, hệ thống sẽ gắn con agent vào để tự động theo dõi và thông báo thông qua endpoint của hệ thống. Trong phần logic, hệ thống sẽ định nghĩa các điều kiện cụ thể, chẳng hạn như chỉ gửi thông báo nếu pull request được tạo trong vòng 30 phút hoặc đang trong trạng thái work in progress. Nếu pull request được cập nhật hoặc chuyển trạng thái, hệ thống sẽ tự động theo dõi và gửi thông báo cho developer để đảm bảo không bị sót.\n\n**[35:39]** Hệ thống sẽ hoạt động dựa trên code filter thông thường. Ngoài ra, nó sẽ có một số workflow khác như việc gửi thông báo vào cuối ngày để tổng hợp tình trạng của các pull request trên Discord. Hệ thống sẽ tự động gửi thông báo về số lượng pull request đang mở, tình trạng của chúng và trạng thái review hiện tại. Đây là chức năng chính của tool này ,  đóng vai trò như một công cụ reminder.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pj13pwqkVdQ?si=Zduog0abeAWXIIM4\u0026amp;start=2107\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**[36:24]** Hệ thống cũng có thể tích hợp với các công cụ chat khác. Đơn giản là có thể tạo thêm một command và gửi request tới endpoint của hệ thống. Các request này sẽ được định nghĩa dựa trên schema cụ thể, ví dụ như input là **review ID** hoặc các thông tin khác liên quan đến trạng thái của pull request. Hệ thống sẽ lấy dữ liệu này và hiển thị trên giao diện mà người dùng thường xuyên sử dụng.\n\n**[37:04]** Phần xử lý backend của hệ thống được thực hiện thông qua tool Lippia, một công cụ định dạng dữ liệu JSON thành dạng bảng Markdown table hoặc dạng data binding. Hiện tại team đang test thử hai luồng xử lý này trước khi mở rộng thêm các tính năng khác. Khi hệ thống hoạt động ổn định, các workflow này sẽ được mở cho tất cả các thành viên trong team thử nghiệm và phát triển thêm.\n\n**[38:08]** Hệ thống được thiết kế để mở rộng một cách linh hoạt. Các thành viên trong team có thể tự phát triển và đóng góp các workflow khác nhau. Hệ thống này cho phép xây dựng các tool dưới dạng một đơn vị độc lập (**packaging unit**), sau đó kết hợp các đơn vị này lại để tạo ra các workflow phức tạp hơn. Khi muốn phát hành một workflow mới, các thành viên chỉ cần định nghĩa lại đơn vị cơ bản và tích hợp nó vào hệ thống.\n\nViệc mở rộng các workflow sẽ giúp hệ thống phát triển theo chiều ngang (mở rộng số lượng tính năng), thay vì theo chiều dọc (phát triển tính năng hiện tại). Khi số lượng các workflow tăng lên, hệ thống sẽ càng trở nên linh hoạt và mạnh mẽ hơn.\n\n**[38:54]** Về cơ bản, workflow được coi là lớp ứng dụng (application layer) tương tự như các API data trước đây. Hệ thống này sẽ hoạt động ở cấp độ tool, nhưng người dùng cuối sẽ tương tác với nó qua giao diện của workflow. Hiện tại, vẫn chưa có đơn vị nào triển khai thành công mô hình này ở quy mô lớn. Tuy nhiên, GitHub hiện đã mở rộng API cho các developer tạo các extension và tích hợp chúng trực tiếp vào GitHub.\n\n**[39:40]** Dify đang xây dựng một nền tảng để hỗ trợ các developer phát triển và triển khai các tool và workflow này một cách dễ dàng hơn. Mục tiêu là tạo ra một marketplace để các tool và workflow có thể được phân phối và sử dụng bởi nhiều người dùng khác nhau. Hệ thống này tương tự như một nền tảng mở, cho phép các developer bên thứ ba triển khai các tool và workflow của riêng họ.\n\nTrên nền tảng của Dify đã có khoảng 50 tool khác nhau. Một số tool đã từng được phát hành dưới dạng thử nghiệm, nhưng do chưa có định hướng rõ ràng và thiếu sự hỗ trợ từ cộng đồng, nên chúng chưa đạt được thành công như mong đợi.\n\n**[40:17]** Một số nền tảng trước đây đã thử xây dựng mô hình tương tự nhưng chưa đạt được thành công. Lý do là vì các tool này chỉ được xây dựng dưới dạng form, thiếu khả năng tương tác với dữ liệu bên ngoài và chưa có khả năng kết hợp các workflow phức tạp. Tuy nhiên, Dify đang tập trung vào việc giải quyết các vấn đề này để tạo ra một hệ sinh thái hoàn chỉnh cho các workflow và tool.\n\n**[40:59]** Các công cụ này cũng cho phép người dùng đẩy dữ liệu từ các nguồn bên ngoài vào hệ thống. Người dùng có thể gửi dữ liệu từ các ứng dụng bên ngoài qua các Open Form hoặc API. Dify sẽ tự động xử lý và định dạng dữ liệu để sử dụng trong các workflow của hệ thống.\n\n**[41:56]** Team đang tập trung vào hai hướng phát triển chính:\n\n1. Tiếp tục mở rộng và phát triển các workflow hiện có.\n2. Cải tiến và tối ưu hóa các công cụ hiện tại để hỗ trợ việc triển khai và sử dụng dễ dàng hơn.\n\nHệ thống được xây dựng dựa trên các tiêu chuẩn chung về thiết kế tool và workflow. Công cụ Smithery hiện tại đang đóng vai trò như một Agent để quản lý các workflow. Smithery cũng có thể được sử dụng như một Package Manager để cài đặt và quản lý các tool trong hệ thống.\n\n**[42:53]** Workflow sẽ hoạt động theo cơ chế, nếu một workflow nào đó trở nên phổ biến, mọi người có thể lấy nó về và sử dụng dưới dạng tool. Bản chất của các công cụ này là được thiết kế để phục vụ các domain cụ thể. Ví dụ như một công cụ để tạo file, tìm kiếm hoặc lấy file code chẳng hạn. Nó hoạt động giống như một SDK, tức là một bộ thư viện mà bạn chỉ cần import vào để sử dụng.\n\n**[43:37]** Khi đã tích hợp vào SDK, bạn có thể sử dụng các method sẵn có để thao tác với dữ liệu. Điều này cho phép tích hợp dễ dàng vào các công cụ AI. Hiện tại, chỉ có Cross là hỗ trợ trực tiếp cho các thao tác này. Tuy nhiên, trong tương lai, nó sẽ được chuẩn hóa để các công cụ khác cũng có thể dễ dàng tích hợp. Trường hợp của Manus là một ví dụ. Manus sử dụng rất nhiều tool khác nhau, tuy nhiên khi so sánh với hệ thống agent trong Smithery, về cơ bản chúng là hai lớp hoàn toàn khác nhau.\n\n**[44:15]** Trong hệ thống của Manus, các công cụ được kết hợp lại để tạo ra các workflow tổng quát hơn. Các công cụ này hoạt động ở các lớp khác nhau, trong khi các agent trong Smithery được thiết kế để hoạt động độc lập. Câu hỏi đặt ra là làm thế nào để phân biệt rõ ràng sự khác nhau giữa hệ thống của Manus và hệ thống agent trong Smithery. Có một bài tóm tắt về điều này đã được đăng trong kênh AI Club ,  nội dung chính nói về khả năng suy nghĩ (thinking) và khả năng sử dụng máy tính (computer use).\n\n**[45:09]** Cơ chế của hệ thống Manus là một hệ thống service-oriented. Để kết hợp nhiều tool với nhau trong cùng một workflow, cần phải định nghĩa rõ các bước thực hiện. Ví dụ như bước 1 cần sử dụng tool nào, bước 2 cần sử dụng tool nào, v.v. Điều này đòi hỏi các bước phải được cấu hình cụ thể. Tuy nhiên, hệ thống mới có khả năng suy luận để tự động xác định xem cần sử dụng những công cụ nào để hoàn thành tác vụ. Đây chính là điểm khác biệt giữa hệ thống mới và các hệ thống cũ.\n\n**[45:59]** Cụ thể, hệ thống mới có thể nhận biết được một tác vụ cần sử dụng bao nhiêu công cụ, thực hiện qua các bước nào, và có thể điều chỉnh thứ tự thực hiện một cách thông minh. Đây là một cơ chế đặc biệt và khác biệt so với các hệ thống cũ. Nói cách khác, nó hoạt động như một Supervisor ,  có khả năng suy luận và đưa ra quyết định về thứ tự và phương pháp thực hiện các bước trong workflow.\n\n**[46:35]** Hệ thống Supervisor hoạt động ở lớp cao hơn so với các agent trong  Smithery. Các agent trong  Smithery chỉ đơn giản là các công cụ thực thi một tác vụ cụ thể, trong khi Supervisor có khả năng quản lý và điều phối toàn bộ quá trình thực hiện tác vụ. Việc tích hợp Supervisor cho phép hệ thống hoạt động một cách linh hoạt hơn, đồng thời dễ dàng mở rộng và bổ sung thêm các công cụ mới.\n\n**[47:33]** Mục tiêu của team là hiểu rõ cách hoạt động của hệ thống và nắm được cơ chế điều hành của các workflow. Nếu có thể xác định được cách thức triển khai và quản lý các workflow, thì sẽ có thể chọn lọc và sử dụng các công cụ hiệu quả hơn. Đây là điều mà team đang hướng tới ,  xây dựng một hệ thống có khả năng mở rộng và tối ưu hóa quy trình làm việc.\n\n**[48:24]** Tiếp theo, team sẽ tập trung vào việc xây dựng hệ thống **MCP**. Đây là một hệ thống mới được thiết kế để quản lý dữ liệu và workflow. Team đã tiến hành demo hệ thống này cách đây khoảng hai tuần. Bản chất của hệ thống MCP là xây dựng một agent hoạt động trên nền tảng có sẵn. Người dùng có thể nhanh chóng triển khai và kiểm tra hệ thống thông qua MCP.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pj13pwqkVdQ?si=KGQZ4rVPmrc9nMq9\u0026amp;start=2935\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**[49:10]** MCP sẽ là một hệ thống hoàn chỉnh, bao gồm một cơ sở dữ liệu (**database**) và một máy chủ (**server**). Điều này cho phép hệ thống hoạt động một cách độc lập và có khả năng xử lý dữ liệu lớn. Khác với các hệ thống cũ, MCP sẽ cho phép người dùng điều chỉnh cấu hình và quản lý dữ liệu dễ dàng hơn.\n\n**[49:58]** Bản chất của MCP là một agent, được định nghĩa theo một cấu trúc input và output cụ thể. Điều này cho phép các hệ thống khác nhau có thể kết nối và tương tác với MCP thông qua các giao thức tiêu chuẩn. Nói cách khác, MCP có thể được tích hợp vào bất kỳ hệ thống nào thông qua các giao thức được định nghĩa sẵn.\n\n**[50:35]** MCP cũng cho phép người dùng quản lý dữ liệu thông qua Knowledge Database, bản chất nó là timescale database, dump hết mọi data về hoạt động của team vào trong đó. Đây là một cơ sở dữ liệu dạng time-series, cho phép ghi nhận các sự kiện theo thời gian thực, ai làm backend sẽ quen dạng event sourcing, event log. Ví dụ: ghi nhận thông tin về các thành viên của team, trạng thái hoạt động của hệ thống, hoặc các sự kiện quan trọng khác.\n\n**[51:13]** Knowledge Database sẽ lưu trữ toàn bộ dữ liệu hoạt động của team, bao gồm các thông tin như ai đã thực hiện tác vụ gì, trạng thái của hệ thống vào từng thời điểm cụ thể, và các thông tin khác liên quan đến hoạt động nội bộ của team. Điều này cho phép team theo dõi và phân tích hiệu suất làm việc, từ đó đưa ra các quyết định điều chỉnh hợp lý.\n\n**[51:51]** Concept của hệ thống sẽ có một thành phần gọi là Landing Zone. Landing Zone có nghĩa là mọi dữ liệu mà mình đang có ,  khoảng mười mấy đến hàng chục bộ dữ liệu (database) ,  sẽ được tập kết vào đây. Trước đây, khoảng ba đến năm năm trước, nếu muốn xây dựng một hệ thống lưu trữ dữ liệu mình sẽ tạo một con bot để thu thập mọi hoạt động của team và đưa vào trong cơ sở dữ liệu của mình.\n\nVới mô hình Meta mới, tất cả các dữ liệu lớn (Big Data) sẽ được dump vào một kho lưu trữ tạm thời dưới dạng file .dat trên S3 hoặc GCS (Google Cloud Storage). Con MCP này sẽ có khả năng đọc trực tiếp từ Landing Zone. Nếu hệ thống thấy rằng dữ liệu trong Landing Zone có giá trị và cần thiết, nó có thể tự động chuyển đổi dữ liệu đó sang dạng Time Series Database (TSDB) để sử dụng lâu dài. Đây chính là end game (kết quả cuối cùng) của hệ thống này.\n\nCòn lại, vấn đề sẽ là xây dựng các Use Case (trường hợp sử dụng) dựa trên các dữ liệu đã được tổ chức trong hệ thống ,  theo hướng mà team mong muốn. Đây là định hướng phát triển quan trọng của hệ thống MCP trong thời gian tới.\n\n**[52:25]** Vậy là hiện tại team sẽ có một hệ thống cơ sở dữ liệu cũ ,  đó là cơ sở dữ liệu dạng table kiểu cũ, nằm ở phần bên dưới của hệ thống (có thể thấy trên diagram với các khối màu xanh dương). Giờ đây, team đang bổ sung thêm hai thành phần mới:\n\n- Thành phần **Landing Zone** ,  nằm trong khối màu vàng phía trên của hệ thống.\n- Thành phần **Time Series Database (TSDB)** ,  được kết nối trực tiếp với các thành phần trong hệ thống cũ để phân tích và khai thác dữ liệu.\n\nTeam đang lưu trữ các dữ liệu thô trong Landing Zone. Về bản chất, việc tập kết dữ liệu trong Landing Zone giống như việc gom quân ,  tập trung tất cả dữ liệu về một chỗ, sau đó mới quyết định cách phân tích và xử lý. Đây là cơ chế giúp hệ thống vận hành linh hoạt hơn và dễ dàng mở rộng khi có thêm dữ liệu mới.\n\n**[53:11]** Điểm đặc biệt của hệ thống này là khả năng tự động chuyển đổi dữ liệu từ Landing Zone sang Time Series Database. Cơ chế này xuất phát từ nhu cầu ngày càng tăng về phân tích dữ liệu cục bộ (local analytics). Đây là xu hướng đang nổi lên trong bối cảnh sự phát triển của AI (Trí tuệ nhân tạo).\n\nSự trỗi dậy của AI đã làm gia tăng nhu cầu về các hệ thống phân tích dữ liệu theo thời gian thực. Khi các dữ liệu thô được tập kết vào Landing Zone, hệ thống sẽ tự động nhận diện dữ liệu có giá trị và chuyển chúng sang TSDB để phân tích chi tiết hơn. Đây là một bước tiến quan trọng trong việc xây dựng hệ thống phân tích dữ liệu hiệu quả và có khả năng thích ứng với những thay đổi của thị trường.\n\n**[53:45]** Hiện tại team đã có thể chạy analytic trực tiếp cho phần dữ liệu được lưu trữ trên local. Hệ thống này cho phép chạy analytic ngay trên dữ liệu Data Lake mà không cần phải chuyển dữ liệu đi xa. Đối với phần dữ liệu trong Landing Zone ,  tức là phần file packet mà Huy đang show trên màn hình ,  đây là phần mà team cần tập trung nghiên cứu thêm. Vấn đề này có liên quan đến text processing, nên mấy anh em cần phải pick up (nắm bắt) chủ đề này. Cái này cũng không khó lắm, chắc học trong vòng nửa ngày là có thể nắm được cơ bản.\n\nPhần Prompt để tìm kiếm và khai thác dữ liệu cũng khá nhanh và đơn giản, không phức tạp. Đây là phần rất đáng để thử nghiệm vì nó liên quan đến cơ chế knowledge discovery (khám phá tri thức) trong hệ thống. Đây là một trong những phần nâng cấp mới mà Huy vừa nhắc tới.\n\n**[54:22]**  Điểm nổi bật nhất của hệ thống trong đợt nâng cấp này chính là **Knowledge Hub**. Đây là nơi mà team sẽ tập trung toàn bộ dữ liệu để phục vụ cho việc phân tích và khai thác tri thức. Knowledge Hub sẽ trở thành một dạng **data pool** chung của toàn team. Bất kỳ ai cũng có thể thêm dữ liệu vào đây, và hệ thống sẽ xử lý, chuyển đổi dữ liệu theo format tiêu chuẩn.\n\nĐiều quan trọng là khi hệ thống đã được thiết lập xong, mọi người trong team sẽ có chung một **protocol** để sử dụng. Các module hoặc component khác nhau sẽ có thể **share (chia sẻ)** chung một cấu trúc dữ liệu và truy cập trực tiếp vào Knowledge Hub. Đây sẽ là nền tảng chung để đồng bộ dữ liệu và xử lý dữ liệu trong nội bộ team.\n\n**[54:58]** Về phần cơ sở dữ liệu (DB), hệ thống sẽ có hai lớp:\n\n- **DB cũ:** Dùng để hỗ trợ các nghiệp vụ hiện có và xử lý các dữ liệu có cấu trúc sẵn.\n- **DB mới:** Được thiết kế để kết nối trực tiếp với **Knowledge Hub** và hỗ trợ phân tích dữ liệu theo thời gian thực.\n\nĐiểm đặc biệt là phần **MCP** sẽ đóng vai trò như một **protocol** để các module khác nhau có thể giao tiếp với nhau. Điều này có nghĩa là bất kỳ dữ liệu nào cần được truy cập hoặc xử lý, chỉ cần đưa vào đúng đường dẫn của hệ thống thì nó sẽ tự động được xử lý theo cấu trúc tiêu chuẩn. Đây là cách để hệ thống đồng nhất dữ liệu và tránh xung đột khi có nhiều nguồn dữ liệu cùng được xử lý.\n\n**[55:43]** Từ giờ, team sẽ cần làm quen với các cơ chế xử lý dữ liệu mới. Mọi người nên dành thời gian để tìm hiểu thêm về các thành phần trong hệ thống mới. Khi các thành phần này hoạt động ổn định, các dự án mới của team sẽ tận dụng các công cụ này để triển khai nhanh hơn và hiệu quả hơn. Đây sẽ là bộ công cụ chính để phục vụ cho các dự án trong tương lai.\n\nHệ thống này có tiềm năng trở thành **requirement** bắt buộc trong các dự án tiếp theo. Nếu bạn muốn bắt kịp với hệ thống mới, hãy bắt đầu từ việc tìm hiểu các nguyên lý cơ bản về MCB và các protocol liên quan.\n\n**[56:40]** Trước đây, khi team triển khai hệ thống trên S3 hoặc GCS (Google Cloud Storage), việc xử lý dữ liệu khá mất thời gian. Tuy nhiên, với cơ chế mới, dữ liệu từ Landing Zone sẽ được xử lý nhanh hơn và dễ dàng hơn.\n\nHệ thống đã được thử nghiệm trên nhiều nền tảng khác nhau, bao gồm **S3** và **GCS**. Tuy nhiên, vì hạ tầng hiện tại của team đang chạy trên **GCS**, nên các dữ liệu từ Landing Zone sẽ được xử lý trên GCS trước. Mặc dù vậy, về mặt kỹ thuật, hệ thống này có thể mở rộng sang các nền tảng khác mà không gặp trở ngại lớn.\n\n**[57:45]** Cơ chế hoạt động của Landing Zone khá đơn giản:\n\n- Các dữ liệu từ nhiều nguồn khác nhau sẽ được tập trung vào Landing Zone.\n- Các dữ liệu này sẽ được lưu dưới dạng **file Parquet** theo từng ngày.\n- Hệ thống có khả năng đọc lại các file này thông qua cơ chế **Time Series Database** (TSDB).\n\nHiện tại, một số file **Parquet** mẫu đã được tạo và đang trong quá trình kiểm tra. Nếu cần, team có thể chạy thử demo trên các dữ liệu mẫu này để kiểm tra tính nhất quán của hệ thống.\n\n**[58:24]** Những hoạt động của team giống như kiểu **AI sub** hoặc **Memo** thì nó cũng được đẩy hết lên đây. Nhiệm vụ của **Landing Zone** là lưu trữ mọi dữ liệu mà team muốn, ai muốn lưu trữ gì thì cứ đẩy hết vào đây rồi sau đó hệ thống sẽ quyết định xử lý dữ liệu đó như thế nào. Hệ thống cũng đã cung cấp một số công cụ để mọi người có thể đẩy dữ liệu lên, ví dụ như là các **API proxy** để forward các sự kiện. Mọi người muốn push thông tin lên Landing Zone thì chỉ cần gọi API là được.\n\nMemo hiện tại đang sử dụng cơ chế này để lấy dữ liệu từ các **nền tảng xã hội** và đồng bộ vào hệ thống. Cơ chế này cũng đã được thử nghiệm thành công. Còn đối với những loại dữ liệu có tính đặc thù như là **Discord messages** hoặc **data từ Basecamp**, team cần phải xây dựng các **crawler** hoặc các **connector** để thu thập dữ liệu. Hiện tại, team đã có một số template sẵn cho những loại dữ liệu này.\n\n**[58:59]** Về hướng phát triển tiếp theo, team sẽ tập trung vào việc khai thác dữ liệu từ Landing Zone. Nếu bạn muốn tham gia vào dự án này, lời khuyên là hãy bắt đầu từ một **vertical cụ thể**. Ví dụ:\n\n- Xác định một **use case** rõ ràng.\n- Tìm hiểu xem **dữ liệu nào** cần cho use case đó.\n- Định nghĩa lại cơ chế khai thác dữ liệu theo hướng **từ trên xuống dưới**.\n\nThay vì kiểu thấy dữ liệu nào hay thì lưu lại, team nên nghĩ theo hướng là **xác định use case trước** rồi mới quyết định lưu trữ dữ liệu. Điều này giúp hệ thống hoạt động một cách có tổ chức và dễ dàng quản lý hơn.\n\nVí dụ cụ thể là nếu có một use case về **Project Nghệ Nhân** thì team sẽ cần tạo một **Git Agent** để thu thập dữ liệu từ Git, sau đó đẩy dữ liệu đó vào **Knowledge Hub** thông qua MCP. Từ đó, hệ thống sẽ định nghĩa các công cụ khai thác dữ liệu cho use case này.\n\n**[1:00:16]** Ngoài ra, team đang phát triển một MCP Server nhỏ. MCP Server này thực chất là một server cơ bản, sử dụng các thành phần kỹ thuật thông thường của hệ thống internet hiện tại. Nó định nghĩa các input và output rõ ràng, cho phép kết nối với nhiều loại giao diện khác nhau.\n\nVí dụ:\n\n- Nếu có một MCP để xử lý dữ liệu từ Slack, team sẽ định nghĩa các API cho từng loại dữ liệu.\n- Nếu cần có các công cụ để đọc dữ liệu từ Google Sheets hoặc phân tích dữ liệu về tình trạng check-in trong tuần, team có thể tạo các MCP tool để xử lý những dữ liệu đó.\n\nMCP sẽ là một thành phần trung gian để đồng bộ và xử lý dữ liệu từ nhiều nguồn khác nhau. Mọi người có thể truy cập các công cụ này từ Editor, Command Line, hoặc bất kỳ giao diện nào khác.\n\n**[1:01:07]** Bản chất của MCP là nó sẽ đóng vai trò như một **API Gateway** để kết nối các công cụ. Nếu bạn cần theo dõi việc check-in hàng tuần của mọi người trong team, bạn có thể tạo một MCP để thu thập dữ liệu từ **Knowledge Hub** và Google Sheets, sau đó so sánh dữ liệu để xem ai đã check-in và ai chưa check-in.\n\nHệ thống hiện tại đang dừng ở mức độ triển khai MCP Server cơ bản. Giao diện hiện tại sử dụng **Command Line** để gọi MCP, nhưng về cơ bản team có thể mở rộng để kết nối với các công cụ khác nhau.\n\n**[1:01:43]** Hệ thống đang tập trung vào việc triển khai cơ chế xác thực (authentication) và phân quyền (authorization).\n\n- Authentication – Xác thực người dùng để truy cập vào hệ thống.\n- Authorization – Phân quyền cho các hoạt động xử lý dữ liệu.\n\nHệ thống đang được sử dụng nội bộ trong team, chưa công khai ra bên ngoài. Nếu bạn muốn sử dụng MCP, bạn sẽ cần nhập vào **private key** để xác thực quyền truy cập.\n\n**[1:02:23]** Về mặt kỹ thuật, MCP có thể mở rộng ra các thành phần khác nhau trong hệ thống. Mọi người có thể tích hợp MCP vào các ứng dụng hiện tại hoặc các công cụ hiện có mà không cần phải viết lại quá nhiều code.\n\nTeam vẫn đang thử nghiệm tính năng này và tập trung vào việc hoàn thiện các phần về bảo mật và quản lý quyền truy cập. Khi hệ thống đã ổn định, mọi người có thể tích hợp MCBP vào các quy trình xử lý dữ liệu hiện có.\n\n**[1:03:00]** Chỉ là đang dừng lại ở đây thôi, chưa xử lý được các bài toán phức tạp về authorization. Sau khi hoàn thành các bước hiện tại thì mới đến việc xử lý các bài toán phức tạp hơn liên quan đến authorization và quyền sử dụng hệ thống. Mọi người có thể tập trung vào các vấn đề cơ bản trước đã.\n\nRồi, cảm ơn Huy nhé. Đây là một trong những phần phát triển kỹ thuật quan trọng của team. Nếu theo dõi các hoạt động trên tech và AI Club, mọi người sẽ nhận ra team đang tiến tới các bước tiếp theo trong quá trình phát triển. Về mặt kỹ thuật, mọi người nên chú ý vào các từ khóa quan trọng mà Huy vừa đề cập. Nếu chưa hiểu rõ thì có thể xem lại bản ghi để nắm được đầy đủ thông tin.\n\n**[1:03:45]** Team core vẫn đang tiếp tục phát triển hệ thống. Yêu cầu tất cả các thành viên tham gia vào dự án để có thể **transfer knowledge** hiệu quả hơn. Dự án này là môi trường để mọi người học hỏi và thực hành.\n\nĐây là cơ hội để các thành viên mới trong team tiếp cận và nắm bắt các khía cạnh kỹ thuật quan trọng. Nếu cảm thấy chưa sẵn sàng thì có thể tham khảo các phần hướng dẫn và tài liệu nội bộ để bắt kịp. Việc training sẽ được thực hiện trong quá trình làm việc chứ không có các buổi training riêng. Đây là môi trường thực hành trực tiếp để vừa làm vừa học.\n\n**[1:04:29]** Bên cạnh việc phát triển hệ thống, team cũng đang thực hiện knowledge transfer từ các dự án đã hoàn thành. Dự kiến cuối tháng sẽ có một buổi tổng hợp lại các bài học rút ra từ các dự án này. Nếu ai chưa thực sự hiểu rõ thì có thể tham khảo hoặc hỏi các thành viên đã làm qua để nắm thêm thông tin.\n\nNếu cảm thấy chưa sẵn sàng hoặc cần thêm thông tin thì có thể hỏi trực tiếp các thành viên trong team. Mọi người có thể ping các thành viên có kinh nghiệm hơn để nhận được sự hỗ trợ.\n\n**[1:05:07]** Team có hai nhóm khác nhau đang hoạt động song song:\n\n- **Team của Tuấn** đang phát triển một số game và ứng dụng nhỏ.\n- **Team build** đang làm việc trên các ứng dụng thử nghiệm để kiểm tra tính khả thi của hệ thống.\n\nCác hoạt động này tương tự với các nhóm **Build Club** và **AI Club** trong team Foundation. Một số sản phẩm đã bắt đầu có **output** tốt. Tuấn và team đang phát triển một trò chơi dựa trên **Turing Machine**.\n\n**[1:06:38]** Trò chơi **Turing Machine** mà team Tuấn phát triển được chuyển thể từ phiên bản board game thành phiên bản trên thiết bị di động. Mục tiêu của trò chơi là đoán một chuỗi gồm **ba số**. Để đoán đúng chuỗi số này, người chơi sẽ nhận được các **clue** (gợi ý).\n\nVí dụ:\n\n- Nếu gợi ý nói rằng “một trong ba số phải lớn hơn 1” → Người chơi có thể nhập số vào và hệ thống sẽ xác định xem đáp án có đúng hay không.\n- Nếu hai số sai nhưng một số đúng thì hệ thống sẽ phản hồi ngay để người chơi có thể tiếp tục điều chỉnh.\n\nLuật chơi khá phức tạp nên có thể gây khó khăn cho người chơi mới. Tuấn và team đang tiếp tục điều chỉnh để trò chơi trở nên dễ tiếp cận hơn mà không mất đi tính thử thách.\n\n**[1:07:23]** Tên trò chơi là [**Pocket Turing**](https://pocket-turing.vercel.app/) bởi vì phiên bản board game gốc của nó liên quan đến các thẻ đục lỗ – giống như cơ chế hoạt động của Turing Machine trong lập trình máy tính. Tuy nhiên, mình đã điều chỉnh và phát triển thêm các yếu tố mới để phù hợp hơn với phiên bản di động.\n\nMÌnh có kế hoạch tinh chỉnh và mở rộng trò chơi trong các phiên bản tiếp theo. Ngoài ra, cũng đang kiểm tra xem có thể triển khai thêm các tính năng thu phí hoặc các tùy chọn nâng cao để tăng khả năng monetize.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pj13pwqkVdQ?si=bP3ZjI3af1fVijle\u0026amp;start=3997\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**[1:08:16]** Mình đang thử nghiệm phiên bản beta của trò chơi. Trò chơi đã hoàn thiện về mặt gameplay và người chơi có thể trải nghiệm trọn vẹn các tính năng. Bước tiếp theo là thử nghiệm với nhóm người dùng rộng hơn để thu thập phản hồi và cải thiện sản phẩm.\n\n**[1:09:15]** Mục tiêu tiếp theo là đưa trò chơi vào App Store và Google Play để tiếp cận nhiều người dùng hơn. Trước mắt, team muốn đảm bảo trò chơi hoạt động ổn định và không phát sinh lỗi nghiêm trọng.\n\nTuấn kỳ vọng trò chơi sẽ thu hút được ít nhất **100 người dùng** trả phí trong giai đoạn thử nghiệm đầu tiên. Nếu nhận được phản hồi tích cực  sẽ mở rộng thêm các tính năng mới và cải thiện trải nghiệm người chơi. Mong nhận được phản hồi từ các thành viên khác để có thể điều chỉnh và hoàn thiện sản phẩm tốt hơn. Tuấn đã chia sẻ link tải trò chơi cho các thành viên trong team để mọi người có thể trải nghiệm và đóng góp ý kiến.\n\n**[1:10:13]** Nếu anh em hứng thú với việc build sản phẩm thì giai đoạn này là thời điểm phù hợp để bắt đầu. Trước đây team đã thử nghiệm nhiều lần nhưng lần này là cơ hội tốt để làm bài bản hơn. Việc phát triển các sản phẩm nội bộ không chỉ giúp cải thiện năng lực kỹ thuật mà còn mở ra cơ hội thương mại hóa trong tương lai.\n\nNgoài game của Tuấn, team đang phát triển thêm các công cụ khác. Nếu có ý tưởng hay, anh em có thể đóng góp để cùng xây dựng và thử nghiệm. Cách bán hoặc thương mại hóa sản phẩm thì tính sau, quan trọng là hoàn thiện các tính năng cốt lõi trước.\n\n**[1:10:58]** Tiếp theo là phần của An. An từng làm một tool gọi là **Rec** để tổng hợp thông tin theo dạng giống với hệ thống của **Apple**. Phiên bản 1 của Rec yêu cầu người dùng tự sắp xếp thông tin, còn phiên bản 2 hiện tại đã được tích hợp AI để hỗ trợ sắp xếp tự động.\n\nTuy nhiên, AI vẫn có một số hạn chế trong việc nhận diện nội dung đầy đủ. Đôi khi AI không thể xác định được toàn bộ ngữ cảnh nên kết quả trả về chưa thực sự hoàn hảo. Tuy nhiên, các nội dung quan trọng vẫn được sắp xếp và hiển thị đầy đủ.\n\n**[1:11:56]** Tool này đang trong giai đoạn hoàn thiện, nhưng các chức năng cốt lõi đã ổn định. Hiện tại, team đang tập trung vào việc cải thiện phần giao diện và tối ưu trải nghiệm người dùng. An dự kiến sẽ tiếp tục phát triển thêm các tính năng bổ sung để hỗ trợ người dùng tốt hơn.\n\n**[1:12:51]** Các dự án của team hiện đang ở giai đoạn thử nghiệm và cải tiến. Nếu ai có thắc mắc hoặc góp ý, có thể trực tiếp trao đổi với An hoặc các thành viên khác trong team. Hiện tại, các dự án đã showcase gần hết. Các phần chi tiết hơn sẽ được đề cập vào buổi sau.\n\n**[1:13:57]** Bên đội mình, anh luôn nói về chuyện kiến thức liên quan tới liquidity và game in general, thì anh em thật sự muốn team mình đẩy theo hướng đó một chút. Vì nó có lợi cho gần như là cái life skill luôn, đúng không? Nên anh muốn team mình đi theo hướng đấy trong đợt này. Mấy anh em, đặc biệt là những người hứng thú với trading, tức là lấy data về để tìm kiếm cái Alpha trên đó, Intel trên đó, để ra được những cái market-making dựa trên điều kiện nào đó.\n\n**[1:14:43]** Nó là một cái, hoặc có thể đi xa hơn để làm một luồng rất tuyệt vời. Hình như hiện tại chỉ là ước mơ của anh thôi. An đã làm được một version, anh thấy khá ok. Đây là cơ hội để cho anh em biết trong team đang có những tiến triển như vậy. Đang chạy ha, mời An. Nói chung là game kiếm tiền thôi. Coi tụi nó kiếm tiền sao thì mình làm vậy. Mấy cái thường thường thì có biết một cái gì để thử, nó cũng là dạng **Delta neutral**, đúng không? Thì mình cũng research những thứ đó. Rồi đi build và research xong để có kiến thức ship.\n\n**[1:15:30]** Chơi cái cột này hết thôi, không nhìn tới đâu nữa. Mọi người thấy màn hình terminal chưa? Có thấy chưa? Có thấy rồi, ok, chạy để chạy thử. Chắc phải zoom lên, zoom lên một hai level, hơi nhỏ, rồi ok rồi. Đây là arbitrage để ăn funding free, thì có nhiều thể loại arbitrage. Cái này chỉ là một trong những loại đó thôi, ăn trên chênh lệch phantom giữa các sàn. Đang tập trung vào ba sàn: Binance, OKX ,  thằng OKX này sàn của nó không có nhiều dữ liệu lắm ,  nên em có cái diagram cho cái đó không, An?\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pj13pwqkVdQ?si=IevTgfLbxwcu6MOh\u0026amp;start=4506\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**[1:16:26]** Nghĩ mọi người sẽ hơi khó hình dung. Nhìn cái này chắc không hiểu nó là gì. Có diagram không? Ok, không có vẽ à? Có cái này, to, nhưng là lý thuyết, không cụ thể ra được high level. Không thấy, chắc phải ngồi vẽ lại sơ sơ. Thấy chưa? Chắc nhìn hình của anh đi, hình của anh, biết ngay là cái này luôn. PRL à? Ủa, nó đang chạy lộn, quên, nó đang vào mấy cái socket của…\n\n**[1:17:47]** Tụi nó để lấy real-time data về. Đang lấy dữ liệu từ bao nhiêu account? Ba cái: Binance, Bybit, với cái gì nữa? Ok rồi, init để lấy giá về, đúng không? Lấy giá, lấy funding, lấy phí chưa? Lấy mấy cái data như phí thì đang code theo calculation, chưa xài để lấy về. OKX chắc không có. Mấy cái trade này thì thường chỉ nằm ở hai cái chính: Binance, Bybit. Ừ, setup ok rồi, nó sẽ có mảng thể hiện cái vị nào đang có chênh lệch funding, thì có profit. Em tính được nếu mình vào thì nó sẽ bao nhiêu. PH là số lần thu funding để hòa vốn phí, monitoring cái cao nhất giữa hai sàn. Bước một là lấy chênh lệch funding giữa hai bên, đúng không? Không, em nói là lấy trên ba exchange, so với góc của nó vẫn là exchange net, đúng không? Ừ, exchange net tính sau thôi.\n\n**[1:19:49]** Funding thì giả sử tụi nó thường, trên lập giá thì không có nhiều, kiểu một thằng dương, hai thằng đều dương, hoặc hai thằng đều âm, thì chênh lệch ít hơn. Thật ra mình đặt counter trên cái chênh khác, chỉ là offset giá di chuyển, để không lỗ bởi giá. Trên exchange net, không có chênh lệch đó, mình làm funding lúc nào cũng bằng 0. Vì không có phí swap, thay vì counter trên sàn khác bằng cái đó, mình counter lúc funding bằng 0. Hiện tại chấp nhận ít lợi hơn, nhưng version đầu tiên vậy.\n\n**[1:20:33]** Lấy giá, lấy **funding**, rồi coi có deploy capital thôi, đúng không? Chạy thử chưa? Chưa đổ tiền vô. Ừ, cái này kiểu game scale, cần nhiều tiền mới ăn, vài trăm ngàn thì vô không thấy gì. Hiểu, ok. Về kỹ thuật thì em làm gì? Từ lúc price crash, em làm những gì?\n\n**[1:21:25]** Đầu tiên em research chart trước, coi nó thế nào, có chênh lệch gì không. Xong rồi ship, code hết bằng Cloud 3.7. Phải lấy data sàn trước qua socket, từ API dock của sàn, quăng lên WebSocket client. Sàn nào cũng có dock, lấy về ship lên, tự view được.\n\n**[1:22:15]** Web cho ba sàn xong, có form đầy đủ. Sau đó build chart, giải thích cho nó, build từ từ. Check data, sai thì tự build sample để đảm bảo data đúng. Vì format giữa các sàn khác nhau.\n\n**[1:23:01]** Khác hết, nên cần test data valid mới compare được. Tiếp theo build con để vào lệnh, khi phát hiện thì có thằng đứng ra vào lệnh, watch bot xem lỗ không, làm từ từ, hợp lý. Quá trình hết bao lâu? Một tuần.\n\n**[1:23:58]** Bước tiếp theo của tool này là gì? Em sẽ check data trước, xem sàn nào dễ kiếm tiền, có lời. Quản lý rủi ro, lấy phí structure của sàn. Vì phí ảnh hưởng lớn, phải tính chính xác, đảm bảo lời mới vào lệnh. Có back system không? Có history để backtest không? Có, nhưng không chính xác.\n\n**[1:25:38]** Đây là showcase kỹ thuật, hướng này team tự lập, ok. Anh em showcase game trading, có bước đẩy tiếp, đang trên đường làm cái muốn làm, rất good. Công nghệ, techno house, xài thế nào thôi. Quan trọng nhất là…\n\n**[1:26:19]** Hoạt động team hiện tại vậy nhé. Productivity gần đây bắt đầu sync. Tom comment trước, productivity team giờ bao nhiêu? 2/10 hay 4/10? So với 6-7/10 cần, anh thấy setup tốt rồi.\n\n**[1:27:01]** Bước tiếp theo về mặt catch up cái công nghệ tool link để hỗ trợ mình vận hành đội theo mô hình này, nó đang được improve từ từ lên. Bên thị trường, thị trường **funding** nói chung và những sản phẩm bắt đầu cũng rục rịch quay trở lại. Người ta thấy công nghệ ổn định hơn. Bên **crypto** thì do macro ảnh hưởng nhiều, nhưng cứ có trend nào về tech là sẽ vô cắn thôi, là vậy ha. Anh đang thấy sắp tới tín hiệu để nó resume lại thì đâu đó khoảng 50/50. Trước đó anh nhìn thì cái market rất tệ, kiểu mọi thứ chưa sẵn sàng. Dù có học nhiều, làm nhiều thì cũng không ra kết quả liền.\n\n**[1:27:40]** Nhưng đợt này anh nghĩ mấy anh em sẽ phải có sự yêu cầu về chuyện tham gia mấy cái này ha. Tuần sau chắc nhờ Huy, Tom với Thành thống kê lại, xem ngoại trừ dự án anh em đang làm thì hoạt động tham gia những dự án side project như vậy, anh em nào đang làm gì ha. Đó là thần sau nội dung, thì cũng trao đổi gần hết rồi. Tuần sau còn một số cái core flow tiếp, nhưng chắc cũng không ảnh hưởng quá nhiều tới mọi thứ.\n\n**[1:28:22]** Hôm nay là ngày 14, hy vọng đến cuối tháng này, buổi họp team tiếp theo sẽ show được nhiều progress hơn. Tất cả những thứ mình đang làm rất quan trọng ha. Toàn bộ này đều đang được đưa lên Memo, tụi anh đang sử dụng Memo đó không chỉ để share trên đó không ăn thua.\n\n**[1:29:01]** Shill khắp nơi mấy công ty khác mình biết, bắt đầu mở rộng network ra để xem tìm kiếm user cần thiết. Chuyện là mình biết những thứ này rồi thì làm sao mình mound được khả năng mình profit từ kiến thức của mình, ý là vậy. Ok ha, đó là cái skin mà team đang chạy theo. Tóm lại, thị trường nhận định đang như vậy. Tuần sau mấy anh em sẽ phải đăng ký làm cái registration vô cho những cái phần, với lại Huy, Tom và Thành là những bên mạng bắt buộc.\n\n**[1:29:45]** Còn bên mấy cái hobby club, như kiểu Build hay gì đó, thì anh không yêu cầu cao vào bên đó, ra cái kỹ thuật để apply, nó cũng không quan trọng lắm. Quan trọng là output nhiều hơn. Hai nhóm khác nhau: một nhóm là những phần mà core project mình sẽ làm, tập trung vào làm sao tăng activity, tăng cái **knowledge base** của mọi người; còn cụm kia tập trung vào cái **skill set**, chuyện develop product sao launch, làm sao làm onboarding tốt hơn, user các kiểu. Là một cái nhóm skill set khác.\n\n**[1:30:27]** Đặc biệt là Huy, Huy đang co cho cái việc quay trở lại office để bắt đầu làm shadowing cho chuyện **knowledge transfer**, thì nếu được thì cứ tiếp tục để nó diễn ra. Rồi xem số liệu như thế nào thì report lại cho anh ha. Hopefully khi nào có con số đây thì mấy anh em xem thảo luận tiếp, làm sao setup cái vụ shadowing đó trên mấy cái dự án mà mình, mấy cái site mà mình tham gia, để có cái case share với nhau ha.\n\n**1:31:05** Toàn bộ là vậy. Nếu bây giờ không có gì khác thì chắc mình kết thúc ở đây. Đây có bao nhiêu bạn nhờ? 28 bạn hả? Không, đang bao nhiêu bạn trong con này nhờ? Chuẩn bị spam ICY, có vấn đề để transfer ICY chưa? Để cái này mai mốt lấy acc anh, hoài căng quá. Có vấn đề trên ICY nhờ. Mọi người ra random nha, giật cô hồn nha. Amount 28 thì mình sẽ drop 14 token ICY, entry là 14 rồi. Xin mời, duration là 5 giây. Ok, let’s go. Một ICY hồi nãy là tương đương khoảng 100 Satoshi rồi đó.\n\n**[1:32:09]** Tuần sau lịch vậy nha, mọi người xem phối hợp với nhau để làm việc cho hiệu quả rồi. Bye bye.\n\n---\n\n### English Transcript\n\n**[05:30]** Hello, can you hear me? Oh, okay, it’s fine now. Today, I think we’ll start a bit early. Today’s session will probably combine with the brother in the meeting for a little bit. One part will be to do a showcase, the second part is that the brother will summarize some things that were discussed with the guys previously. The second and third parts are that we’ll start letting the guys register for tasks. For now, to make it easier, I’ll probably let Huy Nguyễn go first to show the parts related to Huy, which involve ICY a little, and then show some tech stuff that our team is currently working on. This will give me a snapshot of how the tech team is doing right now. Then, moving forward, what our team needs and what the guys can contribute to it. Alright, let’s get started.\n\n**[06:35]** Huy, where’s Thành? Let’s give them the stage now. Okay, for the first content, let’s start with ICY Swap. We announced it, last week or this week it was deployed, so now how are the differences, I’ll probably ask Huy to go over that whole series again.\n\n**[07:29]** Hello, alright, I’ve seen the screen already. So now everyone can go to the ICY Swap page to swap. Here, I’ll show the data. But up here, everything is fully ready now. The only thing left to do is that we’re currently reviewing the ICY numbers. Because previously, when we were operating, we operated by pegging the ICY price, so we didn’t really care much about the circulating supply. So there were some cases where we put it into the team’s wallets or transferred it to Mochi Balances for me or for brother Bảo. Those things need to be reviewed again to get the correct circulating supply number. Because now we’ll sit down, and the price will be dynamic based on the pool, so we need to check that again, and it’s almost done.\n\n**[09:09]** Now, the only thing left is brother Bảo’s account that needs to be checked again. I remember there was a time we transferred to brother Bảo, so now we’re reviewing that part, doing the addition and subtraction, and cutting that part out of the circulating supply, then this number will come out correct. For now, if anyone wants to swap to support, they can swap on this page. That’s the current schedule. I’ll show the list of our current Holders so the guys can see, probably need to know a bit more. Up until now, people participated without paying much attention, but this time we need to be more mindful.\n\n**[09:51]** Our ICY is deployed on Base, right? So when the guys go into the Holder list, everyone will see a list of all the wallets currently holding our team’s ICY, which are the CCK Holders. That’s one thing. And then the link to access this, Huy will share it, I guess. Because if people go search for it, they probably won’t find it.\n\nFirst, the guys need to understand this. Moving on to this part now. I think the guys need to pay more attention to this part. It’s become the norm in the tech world already, no need to do anything new anymore. So if the guys grasp this, it’ll be better.\n\n**[10:33]** Our ICY is now listed. In this list, there are minter wallets, wallets used to budget for activities, and some wallets holding large amounts of ICY. Activities related to staking ICY will be rolled out gradually in the coming time. This is the first piece of information the guys need to understand clearly.\n\n**[11:15]** Huy, demo the swap process for us. Does anyone have a Bitcoin address with some ICY? Is Vincent here? Okay, now let’s try swapping from ICY to Bitcoin. The current price is calculated dynamically based on the circulating ICY amount and the pool. The swap function is very simple, just enter the amount, press swap, and it’s done.\n\n**[12:27]** Wait, don’t enter a fake address. Okay, it’s good now. The first frame is ICY as usual. Below it, it’s displaying the unit in satoshi, which is the smallest unit of Bitcoin. When you enter the amount, it will automatically convert. However, the current exchange rate is slightly off, around 1.2 instead of 1.5. This is probably a small calculation error, we can fix it.\n\n**[13:28]** You need a minimum amount of ICY to swap. Try entering 30 ICY and see how it goes. Refresh it and check if it works.\n\n**[14:43]** It seems like there’s not enough money in the wallet. Do you have ETH on Base? Transfer it to Base and check again.\n\n**[15:51]** It’s not that error. The issue is that the account hasn’t been registered, so it can’t perform the transaction. We’ll fix that part later. The goal here is to help everyone understand the swap mechanism and how token pricing works better. If you understand it well, it’ll be easier to manage tokenomics later on.\n\n**[16:47]** Huy, quickly explain the pricing mechanism again. Last time Quan demoed it but didn’t go into detail about that part. The price of ICY is determined by the minting mechanism, meaning the price won’t fluctuate heavily if someone swaps a large amount. It doesn’t operate like an automated market maker (AMM) mechanism; the price will be controlled through the minting mechanism. This mechanism helps keep the price stable even with large transactions.\n\n**[17:43]** It completely depends on Bitcoin. So if Bitcoin’s price goes up, the amount of ICY you guys are holding will increase in USD value. As for the minting mechanism, Huy, explain a bit more. Generally, our overall mechanism so far is that we fix ICY’s value to USDC. You guys don’t need to worry too much, just understand simply that one ICY is equivalent to 1.5 USD.\n\n**[18:37]** This assurance part is to help the operating team ensure that by the deadline, USDC will be added into the contract for everyone to swap. The swap rate in the old contract was fixed at 1.5 ICY, but that was the old model. Our new model is more flexible. If you guys have used Uniswap or other AMMs (Automated Market Makers), it’s somewhat similar. Here, the mechanism works with a liquidity pool underneath, which contains both ETH and USDC. Depending on the pool’s situation at that time, the exchange rate will be adjusted based on the amount of ETH and USDC in the pool.\n\n**[19:18]** Our mechanism works similarly. The price of ICY will be determined by the amount of Bitcoin in the pool and the amount of ICY currently in circulation. The formula is simple: we have the amount of ICY (X), we have the amount of BTC (Y) in the pool, then X/Y will give us the value of one ICY in terms of BTC. This formula is basic mathematics, nothing complicated.\n\n**[19:55]** Due to our operating mechanism, there will be two moments that change liquidity:\n\n1. **The first moment** is every month when the operating team adds more BTC into the pool to cover the costs of the team’s activities. At this point, the price of ICY will increase slightly because the amount of BTC in the pool increases.\n2. **The second moment** is when the team adds more ICY into the pool (minting more). When more ICY is minted, the market price of ICY will decrease because the amount of ICY in the pool increases.\n\n**[20:35]** The two cases above will directly affect the price of ICY. However, if the price of Bitcoin changes, the USD value of ICY might change, but the price of ICY in terms of BTC will not change. The market impact from Bitcoin is an external factor and does not directly affect the minting or the value of ICY in the pool.\n\n**[21:12]** If you guys have any more questions, feel free to ask, and we’ll answer them later. Oh, there’s a question about swapping back from BTC to ICY, right? Currently, that function isn’t available. Right now, we only support swapping from ICY to BTC, not the reverse swap. Meaning you can buy in, but selling out isn’t supported yet.\n\n**[21:40]** Thank you, Huy. Anything else to note? One thing to note is that we’re still in the testing phase, so there might be some exceptional cases. For example, some situations might arise during swaps or when liquidity isn’t sufficient. Fundamentally, though, the current flow is still operating stably.\n\n**[22:00]** Like the minimum ICY amount required to swap. Because essentially, our team is covering the gas fees for transactions on ETH, on Base, and even on BTC, we’re kind of limiting it so that the ICY amount swapped needs to be a bit higher. This is to avoid situations where people swap just 1-2 ICY to test, which would cost gas fees, so we’ve set it at around above 20 ICY to allow swapping on the web.\n\nThe second thing is that since minting more ICY will change the market price, I’ve disabled the part about our previous salary advance mechanism.\n\n**[22:37]** Meaning if everyone advances salaries at the same time, it would affect the price, right? So the lesson learned from this is that after this round, there are a few points I’m noticing. Our team is starting to focus on building tools to support our operations. These are also some new experiments and some things that genuinely support our activities. But after finishing these tasks, we’ll produce some articles related to them. So if any of you didn’t participate in those projects earlier, you can look back at those articles to understand the game, the knowledge gained from that round, and what the guys working on those projects achieved.\n\n**[23:24]** So with this ICY Swap round, we’ll probably get two or three articles, right? Yes, like three articles. And if we want to write more, there’s still plenty to write about. Yeah, alright, take it slow and steady.\n\n**[24:02]** After Huy’s part, I thank Huy and move on to the second topic related to what our team is currently doing. Brother Bảo, whoever wants to go first is fine, but I’ll probably let Thành speak first. Thành said it’s okay for him to go first, he’ll gather everything to let everyone know what stage the team is at. But I said let Thành go first because someone’s ringing the bell. Alright, I invite Thành to start.\n\n**[25:00]** Everyone, our Memo is one of the big things this round, and we’ve upgraded its format to make it look a bit better. We always want to create content maps, things that we can read and upload here. But currently, that model isn’t really that effective anymore because new models compress data, and querying directly from there would be more efficient.\n\nSo the point is that putting ordinary knowledge onto Memo isn’t very suitable anymore. For this round, when reworking it, there’s one main idea I want to tell you all: Memo will now be used for one sole purpose ,  the knowledge gained from projects.\n\nThat’s almost like the new things that come directly from our team’s activities. In the future, it’ll mostly consist of what field it’s related to and what we’ve done in that field. There’s more to it ,  maybe after a period when they retrain the model, our data will become part of the shared knowledge for the whole community.\n\n**[25:39]** And I think this part will be very helpful for things like retraining AI models later or for cases where we want it to provide automatic suggestions.\n\n**[26:24]** The content will become part of that model, or if there are internet search tools, our articles might just be a small part of the referenced materials, like a small piece in a citation. That’s not a big issue. But overall, all this content will pretty much become the spirit of the team.\n\nIn this major upgrade, there’s one key point that Tuấn has completed, right? Tuấn, the part about syncing all the team’s data, especially the content, is currently being directed this way so the members can understand it better.\n\n**[27:00]** Meaning after this round, the members participating in projects will tend to sit down together to review those projects more closely and determine exactly what the **knowledge gain** from those projects is. After that, the team will upload it to Memo as internal reference material for the team.\n\nThe second part is that at the end of each article, there will be a section related to a **group of reading**. This part isn’t fully complete yet, but the idea is that once it’s finished, there will be an additional section summarizing information about the article so readers can look up and learn more from it.\n\n**[27:47]** In addition, all the data written by the team will be tagged with identifiers such as **GitHub**, **Discord**, or other internal channels. This data will be uploaded to a **blockchain storage** form on the **Arweave (AV)** platform ,  a decentralized storage platform. This ensures that the team’s content has a clear and transparent identifier.\n\nOn top of that, readers will be able to review the articles, rate them, or leave feedback directly on the articles. This is part of the new upgrade idea for the team’s **Memo** page.\n\n**[28:39]** Previously, the team intended to use Obsidian to manage content, but it seems some members had difficulty getting familiar with that tool. Therefore, to make things simpler now, the team will switch to a more direct mechanism. Specifically, instead of having to go through Obsidian, members can submit content directly to the repository of the team’s shared library.\n\nMembers just need to input the content and submit it directly through this platform, without having to follow Obsidian’s mandatory workflow anymore. If someone still wants to use Obsidian, that’s fine, but if they don’t, it won’t affect anything. This is the most fundamental change in the team’s Memo system.\n\n**[29:24]** Currently, the team is working on several main projects, including:\n\n1. Bitcoin Swap ,  already mentioned in the previous section.\n2. Memo ,  just presented.\n3. Two smaller projects:\n    - **Agentic** ,  being developed by Quang and Huy’s group.\n    - **GitHub Bot** ,  being worked on by Thành’s group, currently in testing.\n\nNow, I’ll probably hand it over to Thành to share more about these contents.\n\n**[30:32]** This project was started over a week ago and has officially been running code for more than a week. Its main purpose is to create a reminder system. Previously, the team often encountered situations where, after creating a pull request (PR), people would leave it there, wait for it to finish running, and then forget about the need to review it. This tool will serve to track and update information about daily activities on GitHub or weekly activities on the team’s internal communication channels.\n\n**[31:18]** This system is designed as a simple integration. The basic workflow includes several use cases, such as notifying the person assigned to review, interacting with the GitHub API, and posting information to internal channels like Discord or Slack. Currently, the team is testing it on Discord. Additionally, the team is experimenting with Agentic and a new framework called **Mastra AI**.\n\nThis framework is different from typical Python tools. Some team members aren’t familiar with working in Python, so the team wants to test whether using this new framework is more effective than current solutions. The framework supports features like setting up the environment, defining states to manage data, and allowing reconfiguration based on the team’s needs.\n\n**[32:19]** The system’s structure has two main parts:\n\n1. **Agentic App** ,  This is the main application for handling the system’s activities.\n2. **Discord App** ,  This supports sending notifications to Discord.\n\nAdditionally, the system has a few auxiliary components, such as workflows to handle scheduled tasks, check, and notify developers if there are any pull requests waiting for review. If a pull request exceeds a certain amount of time, the system will send a notification to remind the person responsible for reviewing it.\n\n**[33:12]** The Agentic App will expose a few APIs that allow chatting and tracking the status of pull requests. When a pull request is created, the system will automatically identify conditions like the pull request’s status (work in progress or not), the time it was created, and will notify the reviewer after about 30 minutes from the creation time. For example, if a pull request needs review but no one is assigned or it has exceeded the processing time, the system will automatically ping the responsible person again.\n\n**[35:02]** Instead of having to track manually, the system will attach an agent to automatically monitor and notify through the system’s endpoint. In the logic part, the system will define specific conditions, such as only sending notifications if the pull request was created within 30 minutes or is in a work-in-progress state. If the pull request is updated or changes status, the system will automatically track and notify the developer to ensure nothing is missed.\n\n**[35:39]** The system will operate based on standard code filters. Additionally, it will have some other workflows, like sending notifications at the end of the day to summarize the status of pull requests on Discord. The system will automatically send notifications about the number of open pull requests, their statuses, and the current review status. This is the main function of this tool ,  acting as a reminder tool.\n\n**[36:24]** The system can also integrate with other chat tools. It’s simple ,  you can create an additional command and send a request to the system’s endpoint. These requests will be defined based on a specific schema, such as the input being a **review ID** or other information related to the pull request’s status. The system will take this data and display it on the interface that users frequently use.\n\n**[37:04]** The backend processing of the system is handled through the Lippia tool, which formats JSON data into Markdown tables or data-binding formats. Currently, the team is testing these two processing flows before expanding to additional features. Once the system is stable, these workflows will be opened up for all team members to test and further develop.\n\n**[38:08]** The system is designed to scale flexibly. Team members can independently develop and contribute different workflows. This system allows the creation of tools as standalone **packaging units**, which can then be combined to create more complex workflows. When wanting to release a new workflow, members just need to redefine the basic unit and integrate it into the system.\n\nExpanding workflows will help the system grow horizontally (increasing the number of features) rather than vertically (developing existing features). As the number of workflows increases, the system will become more flexible and powerful.\n\n**[38:54]** Fundamentally, workflows are considered the application layer, similar to previous data APIs. This system will operate at the tool level, but end users will interact with it through the workflow interface. Currently, no entity has successfully implemented this model on a large scale. However, GitHub has now expanded its API for developers to create extensions and integrate them directly into GitHub.\n\n**[39:40]** Dify is building a platform to support developers in developing and deploying these tools and workflows more easily. The goal is to create a marketplace where tools and workflows can be distributed and used by various users. This system is similar to an open platform, allowing third-party developers to deploy their own tools and workflows.\n\nOn Dify’s platform, there are already about 50 different tools. Some tools were previously released as experiments, but due to a lack of clear direction and community support, they didn’t achieve the expected success.\n\n**[40:17]** Some platforms in the past tried building similar models but didn’t succeed. The reason is that those tools were only built as forms, lacking the ability to interact with external data and unable to combine complex workflows. However, Dify is focusing on solving these issues to create a complete ecosystem for workflows and tools.\n\n**[40:59]** These tools also allow users to push data from external sources into the system. Users can send data from external applications via Open Forms or APIs. Dify will automatically process and format the data for use in the system’s workflows.\n\n**[41:56]** The team is focusing on two main development directions:\n\n1. Continuing to expand and develop existing workflows.\n2. Improving and optimizing current tools to support easier deployment and use.\n\nThe system is built based on common standards for tool and workflow design. The Smithery tool is currently acting as an Agent to manage workflows. Smithery can also be used as a Package Manager to install and manage tools within the system.\n\n**[42:53]** Workflows will operate on the mechanism that if a workflow becomes popular, people can take it and use it as a tool. The nature of these tools is that they are designed to serve specific domains. For example, a tool for creating files, searching, or retrieving code files. It works like an SDK, meaning a library that you just need to import to use.\n\n**[43:37]** Once integrated into the SDK, you can use the available methods to manipulate data. This allows easy integration into AI tools. Currently, only Cross directly supports these operations. However, in the future, it will be standardized so other tools can also integrate easily. The case of Manus is an example. Manus uses many different tools, but when compared to the agent system in Smithery, they are fundamentally two completely different layers.\n\n**[44:15]** In Manus’s system, tools are combined to create more general workflows. These tools operate at different layers, while agents in Smithery are designed to work independently. The question is how to clearly distinguish the difference between Manus’s system and the agent system in Smithery. There’s a summary article about this posted in the AI Club channel ,  the main content discusses the ability to think (thinking) and the ability to use computers (computer use).\n\n**[45:09]** The mechanism of the Manus system is a service-oriented system. To combine multiple tools into a single workflow, the execution steps need to be clearly defined. For example, step 1 uses which tool, step 2 uses which tool, and so on. This requires the steps to be specifically configured. However, the new system has the ability to reason and automatically determine which tools are needed to complete a task. This is the key difference between the new system and older systems.\n\n**[45:59]** Specifically, the new system can recognize how many tools a task requires, which steps to go through, and can intelligently adjust the execution order. This is a special mechanism and a difference compared to older systems. In other words, it operates like a Supervisor ,  capable of reasoning and making decisions about the order and method of executing steps in a workflow.\n\n**[46:35]** The Supervisor system operates at a higher layer than the agents in Smithery. Agents in Smithery are simply tools that execute a specific task, while the Supervisor has the ability to manage and coordinate the entire task execution process. Integrating the Supervisor allows the system to operate more flexibly while making it easy to expand and add new tools.\n\n**[47:33]** The team’s goal is to understand how the system works and grasp the mechanics of managing workflows. If we can determine how to deploy and manage workflows, we’ll be able to select and use tools more effectively. This is what the team is aiming for ,  building a system capable of scaling and optimizing workflows.\n\n**[48:24]** Next, the team will focus on building the **MCP** system. This is a new system designed to manage data and workflows. The team conducted a demo of this system about two weeks ago. The essence of the MCP system is to build an agent that operates on an existing platform. Users can quickly deploy and test the system through MCP.\n\n**[49:10]** MCP will be a complete system, including a **database** and a **server**. This allows the system to operate independently and handle large amounts of data. Unlike older systems, MCP will allow users to adjust configurations and manage data more easily.\n\n**[49:58]** The essence of MCP is an agent, defined with a specific input and output structure. This allows different systems to connect and interact with MCP through standard protocols. In other words, MCP can be integrated into any system via predefined protocols.\n\n**[50:35]** MCP also allows users to manage data through the Knowledge Database, which is essentially a timescale database where all the team’s activity data is dumped. This is a time-series database that enables recording events in real-time, something backend developers will recognize as event sourcing or event logs. For example, it records information about team members, the system’s operational status, or other significant events.\n\n**[51:13]** The Knowledge Database will store all the team’s activity data, including details like who performed which task, the system’s status at specific times, and other information related to the team’s internal operations. This allows the team to track and analyze work performance, thereby making reasonable adjustment decisions.\n\n**[51:51]** The system’s concept includes a component called the Landing Zone. The Landing Zone means that all the data we currently have ,  about a dozen to tens of datasets (databases) ,  will be centralized here. Three to five years ago, if we wanted to build a data storage system, we’d create a bot to collect all the team’s activities and input them into our database.\n\nWith the new Meta model, all large data (Big Data) will be dumped into a temporary storage in the form of .dat files on S3 or GCS (Google Cloud Storage). The MCP will have the ability to read directly from the Landing Zone. If the system determines that the data in the Landing Zone is valuable and necessary, it can automatically convert that data into a Time Series Database (TSDB) for long-term use. This is the end game (final outcome) of this system.\n\nThe remaining issue will be building Use Cases based on the organized data in the system ,  in the direction the team desires. This is a key development direction for the MCP system in the near future.\n\n**[52:25]** So currently, the team will have an old database system ,  a traditional table-based database located at the bottom of the system (visible in the diagram with blue blocks). Now, the team is adding two new components:\n\n- The **Landing Zone** component ,  located in the yellow block at the top of the system.\n- The **Time Series Database (TSDB)** component ,  directly connected to the old system’s components for data analysis and exploitation.\n\nThe team is storing raw data in the Landing Zone. Essentially, centralizing data in the Landing Zone is like rallying troops ,  gathering all the data in one place before deciding how to analyze and process it. This mechanism makes the system more flexible and easily scalable when new data is added.\n\n**[53:11]** The special feature of this system is its ability to automatically convert data from the Landing Zone to the Time Series Database. This mechanism stems from the growing need for local data analytics. This is an emerging trend in the context of AI (Artificial Intelligence) development.\n\nThe rise of AI has increased the demand for real-time data analysis systems. When raw data is centralized in the Landing Zone, the system will automatically identify valuable data and transfer it to the TSDB for more detailed analysis. This is a significant step forward in building an efficient and adaptable data analysis system to market changes.\n\n**[53:45]** Currently, the team can already run analytics directly on the data stored locally. This system allows running analytics right on the Data Lake without needing to transfer data elsewhere. For the data in the Landing Zone ,  the file packets that Huy is showing on the screen ,  this is the part the team needs to focus on researching further. This issue relates to text processing, so the guys need to pick up this topic. It’s not too difficult; it’ll probably take about half a day to grasp the basics.\n\nThe Prompt for searching and exploiting data is also quite fast and simple, not complicated. This is a part very worth experimenting with because it relates to the knowledge discovery mechanism in the system. This is one of the new upgrades Huy just mentioned.\n\n**[54:22]** The most standout feature of the system in this upgrade is the **Knowledge Hub**. This is where the team will centralize all data to serve analysis and knowledge exploitation. The Knowledge Hub will become a common **data pool** for the entire team. Anyone can add data here, and the system will process and convert the data into a standard format.\n\nThe important thing is that once the system is fully set up, everyone in the team will have a common **protocol** to use. Different modules or components will be able to **share** a common data structure and access the Knowledge Hub directly. This will be the common foundation for syncing and processing data within the team.\n\n**[54:58]** Regarding the database (DB), the system will have two layers:\n\n- **Old DB:** Used to support existing operations and process pre-structured data.\n- **New DB:** Designed to connect directly with the **Knowledge Hub** and support real-time data analysis.\n\nThe special thing is that the **MCP** will act as a **protocol** for different modules to communicate with each other. This means that any data needing access or processing just needs to be fed into the system’s correct pathway, and it will be automatically processed according to the standard structure. This is how the system unifies data and avoids conflicts when multiple data sources are processed simultaneously.\n\n**[55:43]** From now on, the team will need to get familiar with the new data processing mechanisms. Everyone should take the time to learn more about the components in the new system. Once these components are stable, the team’s new projects will leverage these tools to deploy faster and more efficiently. This will be the main toolkit to serve future projects.\n\nThis system has the potential to become a **requirement** for upcoming projects. If you want to keep up with the new system, start by learning the basic principles of MCP and related protocols.\n\n**[56:40]** Previously, when the team deployed systems on S3 or GCS (Google Cloud Storage), data processing took quite a bit of time. However, with the new mechanism, data from the Landing Zone will be processed faster and more easily.\n\nThe system has been tested on various platforms, including **S3** and **GCS**. However, since the team’s current infrastructure runs on **GCS**, the data from the Landing Zone will be processed on GCS first. That said, technically, the system can expand to other platforms without major obstacles.\n\n**[57:45]** The Landing Zone’s operating mechanism is quite simple:\n\n- Data from various sources will be centralized in the Landing Zone.\n- This data will be stored as **Parquet files** by day.\n- The system can read these files back through the **Time Series Database (TSDB)** mechanism.\n\nCurrently, some sample **Parquet** files have been created and are being tested. If needed, the team can run a demo on these sample data sets to check the system’s consistency.\n\n**[58:24]** The team’s activities, like **AI sub** or **Memo**, are also fully pushed up here. The task of the **Landing Zone** is to store all the data the team wants ,  anyone who wants to store something can push it all here, and then the system will decide how to process that data. The system has also provided some tools for people to push data up, such as **API proxies** to forward events. If anyone wants to push information to the Landing Zone, they just need to call the API.\n\nMemo is currently using this mechanism to pull data from **social platforms** and sync it into the system. This mechanism has been successfully tested. For more specific data types like **Discord messages** or **data from Basecamp**, the team needs to build **crawlers** or **connectors** to collect the data. Currently, the team already has some ready-made templates for these data types.\n\n**[58:59]** For the next development direction, the team will focus on exploiting data from the Landing Zone. If you want to join this project, the advice is to start with a specific **vertical**. For example:\n\n- Identify a clear **use case**.\n- Find out **which data** is needed for that use case.\n- Redefine the data exploitation mechanism in a **top-down** approach.\n\nInstead of storing whatever data seems interesting, the team should think in terms of **defining the use case first** and then deciding what data to store. This helps the system operate in an organized and easily manageable way.\n\nA specific example is if there’s a use case about **Project Nghệ Nhân**, the team would need to create a **Git Agent** to collect data from Git, then push that data into the **Knowledge Hub** via MCP. From there, the system would define data exploitation tools for this use case.\n\n**[1:00:16]** Additionally, the team is developing a small MCP Server. This MCP Server is essentially a basic server, using standard technical components of the current internet system. It defines clear inputs and outputs, allowing connection to various interfaces.\n\nFor example:\n\n- If there’s an MCP to process data from Slack, the team will define APIs for each data type.\n- If tools are needed to read data from Google Sheets or analyze weekly check-in status data, the team can create MCP tools to handle that data.\n\nMCP will act as an intermediary component to sync and process data from various sources. Everyone can access these tools from the Editor, Command Line, or any other interface.\n\n**[1:01:07]** The essence of MCP is that it will serve as an **API Gateway** to connect tools. If you need to track everyone’s weekly check-ins in the team, you can create an MCP to collect data from the **Knowledge Hub** and Google Sheets, then compare the data to see who has checked in and who hasn’t.\n\nThe current system is at the stage of deploying a basic MCP Server. The current interface uses the **Command Line** to call MCP, but fundamentally, the team can expand it to connect with various other tools.\n\n**[1:01:43]** The system is focusing on implementing authentication and authorization mechanisms.\n\n- **Authentication** – Verifying users to access the system.\n- **Authorization** – Assigning permissions for data processing activities.\n\nThe system is currently being used internally within the team and has not been made public externally. If you want to use MCP, you’ll need to input a **private key** to authenticate your access rights.\n\n**[1:02:23]** Technically, MCP can expand to different components within the system. Everyone can integrate MCP into existing applications or tools without needing to rewrite too much code.\n\nThe team is still testing this feature and focusing on completing the security and access management parts. Once the system is stable, everyone can integrate MCP into their existing data processing workflows.\n\n**[1:03:00]** It’s just paused here for now; we haven’t tackled the complex authorization problems yet. After completing the current steps, we’ll move on to addressing more complex issues related to authorization and system usage rights. For now, everyone can focus on the basic issues first.\n\nAlright, thank you, Huy. This is one of the important technical development parts for the team. If you follow the activities on the tech and AI Club, you’ll notice the team is moving toward the next steps in the development process. Technically, everyone should pay attention to the key terms Huy just mentioned. If you’re not clear on them, you can review the transcript to get the full information.\n\n**[1:03:45]** The core team is still continuing to develop the system. We request all members to participate in the project so we can **transfer knowledge** more effectively. This project is an environment for everyone to learn and practice.\n\nThis is an opportunity for new team members to get acquainted with and grasp important technical aspects. If you feel unprepared, you can refer to the internal guides and documents to catch up. Training will happen during the work process rather than in separate sessions. This is a hands-on environment where you learn while doing.\n\n**[1:04:29]** Alongside system development, the team is also conducting knowledge transfer from completed projects. We expect to have a session at the end of the month to summarize the lessons learned from these projects. If anyone doesn’t fully understand yet, they can refer to or ask members who’ve worked on them for more information.\n\nIf you feel unprepared or need more details, you can directly ask team members. Everyone can ping more experienced members to get support.\n\n**[1:05:07]** The team has two different groups working in parallel:\n\n- **Tuấn’s team** is developing some games and small applications.\n- **The build team** is working on experimental applications to test the system’s feasibility.\n\nThese activities are similar to the **Build Club** and **AI Club** groups within the Foundation team. Some products have started showing good **output**. Tuấn and his team are developing a game based on the **Turing Machine**.\n\n**[1:06:38]** The **Turing Machine** game that Tuấn’s team is developing is adapted from the board game version into a mobile version. The game’s goal is to guess a sequence of **three numbers**. To guess the correct sequence, players receive **clues**.\n\nFor example:\n\n- If the clue says “one of the three numbers must be greater than 1” → Players can input numbers, and the system will determine if the answer is correct.\n- If two numbers are wrong but one is correct, the system will respond immediately so players can continue adjusting.\n\nThe rules are quite complex, which might be challenging for new players. Tuấn and the team are continuing to tweak it to make the game more accessible without losing its challenge.\n\n**[1:07:23]** The game is called [**Pocket Turing**](https://pocket-turing.vercel.app/) because the original board game version involves punched cards ,  similar to how the Turing Machine works in computer programming. However, I’ve adjusted and added new elements to make it more suitable for the mobile version.\n\nI plan to refine and expand the game in future versions. Additionally, I’m checking if we can implement premium features or advanced options to increase monetization potential.\n\n**[1:08:16]** I’m testing the beta version of the game. The gameplay is complete, and players can fully experience the features. The next step is to test it with a broader user group to gather feedback and improve the product.\n\n**[1:09:15]** The next goal is to bring the game to the App Store and Google Play to reach more users. For now, the team wants to ensure the game runs stably without serious bugs.\n\nTuấn hopes the game will attract at least **100 paying users** in the initial testing phase. If we get positive feedback, we’ll expand with new features and improve the player experience. I’d love to hear feedback from other team members to adjust and perfect the product further. Tuấn has shared the game download link with team members so everyone can try it and provide input.\n\n**[1:10:13]** If you guys are excited about building products, this is a good time to start. The team has experimented many times before, but this is a chance to do it more systematically. Developing internal products not only improves technical skills but also opens up future commercialization opportunities.\n\nBesides Tuấn’s game, the team is working on other tools. If you have any good ideas, feel free to contribute so we can build and test together. How to sell or monetize the products can be figured out later; the priority is completing the core features first.\n\n**[1:10:58]** Next is An’s part. An once made a tool called **Rec** to aggregate information in a format similar to **Apple**’s system. Version 1 of Rec required users to manually organize information, while the current Version 2 has integrated AI to support automatic organization.\n\nHowever, the AI still has some limitations in fully recognizing content. Sometimes it can’t grasp the entire context, so the results aren’t completely perfect. Still, the important content is organized and displayed fully.\n\n**[1:11:56]** This tool is in the refinement stage, but the core functions are stable. Currently, the team is focusing on improving the interface and optimizing the user experience. An plans to continue developing additional features to better support users.\n\n**[1:12:51]** The team’s projects are currently in the testing and improvement phase. If anyone has questions or suggestions, they can directly discuss with An or other team members. For now, we’ve showcased almost all the projects. More detailed parts will be covered in the next session.\n\n**[1:13:57]** On our team’s side, I always talk about the knowledge related to **liquidity** and **game in general**, right? We really want the team to push a little in that direction because it’s beneficial for almost like a **life skill**, you know? So I want our team to head in that direction this time. Especially those of you who are really interested in **trading**, meaning getting data to find the **Alpha** on it, the **Intel** on it, to come up with some **market-making** strategies based on certain conditions or something like that.\n\n**[1:14:43]** It’s one thing, or it could even go further to create a really awesome flow. It feels like it’s just my dream for now. An has already made a version that I think is pretty okay. Just taking this chance to let you guys know that the team has this kind of progress going on. It’s running, right? Let’s invite An. Okay, okay, generally it’s just a money-making game. See how they make money, and we’ll do the same. The usual stuff has a bit of something to test, a bit of it is also in the form of **Delta neutral**, right? So we also research those things there. Then go build and research to have the knowledge to ship it.\n\n**[1:15:30]** Play this column until it’s all used up, that’s it, no looking over there. Do you all see the terminal screen? Do you see it? Yes, okay, let’s run it. Let’s run it. I think we need to zoom in, zoom in one or two levels, it’s still a bit small, okay now. Yeah, this is the arbitrage to eat the **funding free frost**, right? There are many, many types of arbitrage like that. This is just one of those types, which is eating off the difference, the **phantom bin**, between the exchanges. We’re focusing on three exchanges: **Binance**, **OKX** ,  that devil OKX, their exchange doesn’t have too much stuff ,  so, do you have a diagram for that, An?\n\n**[1:16:26]** I think it’ll be a bit hard for everyone to visualize. Looking at this, they won’t understand what it is. Is there one? Okay, no diagram? Oh, there’s this, big one, just theory, nothing concrete comes up at a high level? I guess we’ll have to sketch it roughly again. Do you see it yet? Maybe look at my diagram, yeah, my diagram, so you know it’s this right away. The PRL? Wait, it’s messed up, running wrong, forgot, it’s going into the sockets of…\n\n**[1:17:47]** Those guys to pull **real-time data** back, and it’s currently pulling data from how many accounts? Three accounts ,  **Binance**, **Bybit**, and what? Okay, initialized to get the price back, right? Getting the price, getting the **funding** back, getting the price yet? Getting some data like fees and fee-related data, it’s kind of coded according to that calculation, but it hasn’t been used to fetch yet. OKX probably doesn’t have it. Those trades, okay, don’t have it, so usually it’s just on the two main ones, which are **Binance** and **Bybit**. Yeah, setup is okay, and then it’ll have an array to show which pair has the difference, the difference in **funding**, then it’ll have profit, and I calculate that if we enter, how much it would be. PH is the number, the number of times we collect the **funding** to break even with the fees. It’s monitoring, monitoring the highest between the two exchanges, that’s it. Step one is getting the difference, the difference in **funding** between the two sides, right? Between the two sides that I’m talking about, no. Because I said this is getting from three exchanges, so compared to its angle, it’s still on the exchange net, right? Yeah, exchange net is something calculated later because…\n\n**[1:19:49] Funding**, let’s say normally, on the price setup, they usually don’t have much, like one is positive, two are positive, or two are negative, so the difference is smaller. Actually, we place a counter on the other difference, it’s just the offset, the price movement offset, so it doesn’t lose due to the price. On the exchange net, there won’t be that difference, we make the **funding** always equal to zero, right? Because there’s no swap fee there, and instead of countering on another exchange with that thing, we counter at the moment when the **funding** is also zero. Currently, we accept that it won’t be as profitable, but that’s how the first version is.\n\n**[1:20:33] b**So we get the price, get the top, get the **funding**, then see if it’s just about deploying capital, right? Have you tried running it yet? Not yet, haven’t poured money in. Yeah, this is like a scale game, you need a lot of money to profit, but with just a few hundred or a few thousand, it goes in, and it doesn’t look like much. Got it, got it, okay, understood. But on the technical side, technically, for me to do this, what did I apply from start to finish? From when it crashed, what did I do? Yeah…\n\n**[1:21:25]** First, I researched that chart beforehand, checked how it was, whether it had this or that, all those things. Yeah, got those dots sorted. We’ll ship it for that, yeah, that guy will code everything with code, okay? Using this **Cloud 3.7**, right? First, you have to get the exchange’s data before calculating anything. The main exchanges will pull from sockets, and the setup is, first, on the API docks of the exchanges, right? This one, yeah, then pull their docks back, throw it to this guy, it ships up to the **WebSocket client**. Every exchange has docks, all of them, pull them back, ship them up, and it’ll auto-view.\n\n**[1:22:15]** The web for all three exchanges is done, with forms and everything. After that, we start building it up, yeah, this part, this chart. The first step is probably explaining it to it and stuff, kind of it builds slowly up. Then check the data and all, if it’s wrong, it auto-builds itself. I built it, and it auto, every time there’s something new, it’ll auto-build a sample to check the data before finding it again for us. Cool, to ensure the data is correct or not. Because the thing between the exchanges, the format is different, the data format is…\n\n**[1:23:01]** Different, everything is different, right? So to compare it all into one final form for it to compare, it needs a section to test pulling the data back, ensuring the data is valid, then it starts comparing. That’s the step. Next, it’ll be building things like, next is, yeah, building the guy to place orders. When it detects these, there’ll be a guy standing by to place orders, watching our bot to see if it’s losing or whatever, slowly, reasonably. The whole process took how long? About a week, yeah, cool, huh? So now the next step…\n\n**[1:23:58]** The next step of this tool I’m working on, what’s the next step? I’ll check the data first, check the data to see which one makes money easily, which one is profitable, which one you put money into and it’s all profitable. There’ll be data to check those profits, then manage more of our stuff, like risks and all that, then, yeah, pull all the data back about the fee structure of the exchanges. Because if you use those trusts or whatever, the exchange fees affect the thing a lot, so you need the exact fees, then calculate…\n\n**[1:24:51]** How to ensure it’s profitable in the end before placing orders, right? Next will probably be those steps. Okay, that’s the step, the step of when to place orders, that’s the final thing, right? The rest needs to filter the data first. Is there a back system built? Because I think this data, does it have history or not? Does it? Or is it just at that moment? It does, if you can get the history, it’s backtest history, but I think it’s not accurate, huh? Yeah, not accurate, not there. I don’t think so. The other stuff might have it, but this arbitrage is a bit hard to get accurate.\n\n**[1:25:38]** This is a technical showcase. I think with this direction in the team, independently, our team, regarding this direction, it’s okay. You guys showcasing the trading game have started having steps that the team is pushing forward to do. I think fundamentally, fundamentally, you guys are all on a path, on the way to getting to what you want to do, which is very good. The thing is, with technology, with that tech know-how, how we bring it out and use it, right?\n\n**[1:26:19]** The team’s activities in general are like this, okay? Regarding productivity, it feels like recently everyone has started syncing with each other to a certain degree. But with Tom, Tom is probably out, but Tom had a comment from before when you guys were sitting and chatting. We were thinking, what’s the team’s productivity level right now? How much would Tom rate it? 2/10 or 4/10, huh? If compared to the level we need, you guys at like 6-7/10, the general average, I think we’re in a very good setup right now.\n\n**[1:27:01]** The next step regarding the quality, the technology tool link to support us in operating the team according to this model, it’s being improved slowly but surely. On the market side, the **funding** market in general and the products are starting to stir and come back. People see the technology becoming more stable. In **crypto**, it’s heavily influenced by macro factors, but whenever there’s a tech trend, they’ll jump in and bite, that’s how it is, right? I’m seeing signals for it to resume soon, about 50/50 right now. Before this, I looked at the market, and it was really bad, like everything wasn’t ready yet. Even if you studied a lot and worked a lot, results wouldn’t come immediately.\n\n**[1:27:40]** But this time, I think you guys will need to have some requirements about participating in these things, okay? Next week, I’ll probably ask Huy,Tom and Thành to compile some stats, to see besides the projects you’re working on, what’s the participation in side projects like that, who’s doing what, alright? That’s the follow-up after the content, we’ve discussed almost everything. Next week, there are still some core flow parts left, but they probably won’t affect things too much.\n\n**[1:28:22]** Today is the 14th, I hope by the end of this month, the next team meeting will show more progress. Everything we’re doing is very important, right? Another important thing is we have Sister Minh here, Nicki. Probably past the out time already. All of this is being uploaded to **Memo**, and we’re using that **Memo** not just to share on it ,  that’s not enough ,  but the channels we’re working on are being sent out…\n\n**[1:29:01]** To everywhere, to other companies we know, starting to expand the network to look for necessary users. The thing is, we know these things already, so how do we mound our ability to profit from our knowledge? That’s the idea, okay? That’s the skin the team is following. In summary, the market assessment is like this. Next week, you guys will need to register for those parts, and Huy, Tom, and Thành are the mandatory segments.\n\n**[1:29:45]** As for the hobby clubs, like Build or something, I don’t have high demands there, producing technical stuff to apply, it’s not that important. The output matters more. Two different groups: one group is the core project parts we’ll work on, focusing on how to increase activity, increase everyone’s **knowledge base**; the other group focuses on the **skill set**, how to develop products for launch, how to do onboarding better, users and all that. It’s a different skill set group. You guys next week jump in and start thinking, especially…\n\n**[1:30:27]** Especially Huy, Huy is co-handling the return to the office to start shadowing for **knowledge transfer**. If it works, just keep it going, then see how the numbers look and report back to me, okay? Hopefully, when we have the numbers, you guys discuss further, figure out how to set up that shadowing on the projects, the sites we’re involved in, to have cases to share with each other, right? Like Sister An, finishing this in a week is super solid, doing everything herself, using new workflows and all, it’s great…\n\n**[1:31:05]** Alright, you guys, that’s the whole thing. If there’s nothing else now, we’ll probably end here. How many people are here? 28 people, huh? No, how many in this call right now? Preparing to spam ICY, is there an issue with transferring ICY yet? Everyone go random, grab it like ghosts, okay? Amount is 28, so we’ll drop 14 ICY tokens, entry is 14 already. Go ahead, duration is 5 seconds. Okay, let’s go. One ICY earlier was about 100 Satoshi already.\n\n**[1:32:09]** Now starting, don’t know when the boss updates the multiplier price, just estimate it for now. Today’s early, next time seeing Bitcoin, it looks cool. Happy Weekend, bye bye everyone.\n","title":"OGIF Office Hours #41 - ICY-BTC Swap, GitHub Bot, MCP-DB, Pocket Turing, Recapable, and Arbitrage Strategy","short_title":"#41 ICY-BTC, GitHub Bot, MCP-DB, Pocket Turing","description":"In OGIF 41, the team covered key updates on the ICY-BTC swap, GitHub bot automation, MCP-DB system for agent workflows, and progress on the Pocket Turning and Recapable projects and we also shared insights into funding rate arbitrage strategies.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Thu Mar 20 2025 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/41-20250314.md","slugArray":["updates","ogif","41-20250314"]},{"content":"\n**Topic Highlights**\n\n- **Go Weekly #16**: Phat discussed concurrent data structures in Go, focusing on `sync.Map`. He explored its structure, use cases, and performance trade-offs in high-read, low-write scenarios. He also touched on garbage collection issues reported by the Go team.\n- **Generative AI UX Design Patterns**: Nam presented on UX design patterns for AI integration, covering System Scope Relationship, Spatial Relationship, and Functional Relationship. He explained how AI can be incorporated at various levels in digital products and discussed different ways to present AI features in user interfaces.\n- **Yelp Usecase AI**: Dat presented real-world AI use cases from Yelp, explaining how AI is used for recommendation systems, text editing, and image summarization. He explored AI applications in generating datasets, spam detection, and auto-generating short video reviews for restaurants.\n- **LLM Pattern**: Hoang introduced design patterns for integrating LLMs (Large Language Models) into applications. Key patterns included in-context learning, data preprocessing, and multi-agent collaboration, highlighting their practical use in AI-powered systems.\n- **Dify Git Analyze**: Cat demonstrated a Git repository analysis tool built using Dify. The tool scrapes content from repositories and supports diagram generation for code structure analysis, with a focus on optimizing the knowledge retrieval process in large datasets\n\n---\n\n**Vietnamese Transcript**\n\n**0:28** Chủ đề hôm nay vẫn có Go Weekly, và Nam đang thử nghiệm phần commentary về thiết kế hàng tuần. Chúng ta sẽ theo dõi trong vài tuần tới xem nội dung như thế nào.\n\n**11:19** Nam sẽ trình bày tiếp cho anh em, và sau đó sẽ có một vài bài của Hoàng, Cát, Đạt. Chúng ta đang nghiên cứu về các trường hợp sử dụng mà các công ty khác đang áp dụng, hoặc các công cụ mà dev đang sử dụng, và có thể sẽ mở một bài chia sẻ trong tuần này hoặc tuần sau. Bài hôm nay sẽ xoay quanh việc tạo một nút thiết kế UX. Trước đây, có rất nhiều câu hỏi về phạm vi mà AI đang áp dụng và vai trò của nó sẽ như thế nào – liệu nó chỉ đóng góp như một thành phần nhỏ riêng lẻ hay là cả một ứng dụng trong các sản phẩm số. Hôm nay, em sẽ giải đáp thắc mắc đó, tức là AI đang đóng vai trò như thế nào và cách thức hoạt động của nó ra sao.\n\n**12:11** Đầu tiên, em sẽ nói về \"System Scope Relationship.\" Hình ảnh này sẽ mô tả AI được tích hợp vào các hệ thống ở nhiều cấp độ khác nhau, từ một thành phần nhỏ lẻ đến một hệ sinh thái toàn diện hơn. AI có thể chỉ là một phần nhỏ trong một thành phần hoặc có thể phát triển thành các tính năng lớn hơn, giúp tự động hóa nhiều chức năng. Điều này sẽ giúp người dùng trải nghiệm ứng dụng dễ dàng hơn. AI có thể đóng vai trò trong bất kỳ phần nào của sản phẩm số – từ thành phần, luồng xử lý, tính năng cho đến toàn bộ ứng dụng, hoặc thậm chí là một nền tảng hoặc hệ sinh thái.\n\n**12:53** Ví dụ, trong một ứng dụng, AI có thể đóng vai trò một tính năng nhỏ, giúp người dùng thao tác nhanh hơn thay vì phải làm thủ công. Hoặc AI có thể là toàn bộ một ứng dụng như ChatGPT, nơi toàn bộ ứng dụng được xây dựng trên nền tảng AI, phục vụ cho một mục đích nhất định. Hoặc AI có thể là một nền tảng như Rewind AI, với nhiều tính năng hỗ trợ AI cho nhiều công việc khác nhau trong cùng một ứng dụng. Đây là phạm vi của AI trong các sản phẩm hiện nay.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/s7doIOUDGgA?si=nx8a1rNN4wSuuPBo\u0026amp;start=688\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**13:39** Tiếp theo, về \"Spatial Relationship,\" phần này giúp chúng ta hiểu về cách tính năng AI được bố trí và sắp xếp trong giao diện người dùng (UI). Có nhiều cách để tích hợp AI vào thiết kế, và quan trọng là làm sao để bố trí chúng sao cho hợp lý, tối ưu trải nghiệm người dùng mà không gây rối mắt hay phức tạp giao diện. Spatial Relationship ảnh hưởng trực tiếp đến trải nghiệm người dùng. Ví dụ, AI có thể hoạt động độc lập hoặc song song với các tính năng khác, nhưng vẫn giữ không gian riêng của mình. Khi hiểu được các mối quan hệ này, chúng ta có thể chọn cách sử dụng và sắp xếp tính năng AI một cách tối ưu, không gây phân tâm cho người dùng.\n\n**15:11** Có sáu cách để trình bày tính năng AI, bao gồm:\n\n1. **Separate**: AI hoạt động độc lập.\n2. **Alongside**: AI được đặt bên cạnh các tính năng khác.\n3. **Layer**: AI hoạt động dưới dạng lớp phủ.\n4. **Integrated Parent**: AI đóng vai trò chính trong điều hướng hoặc quản lý nội dung chính.\n5. **Integrated Child**: AI đóng vai trò nhỏ hơn, bổ trợ cho tính năng chính.\n6. **Point**: AI chỉ xuất hiện như một biểu tượng nhỏ, giúp người dùng hiểu thêm về cách nó hoạt động.\n\n**16:41** Tiếp theo là \"Functional Relationship,\" phần này mô tả các mối quan hệ chức năng giữa AI và các tính năng khác trong hệ thống. AI có thể tồn tại độc lập nhưng vẫn adapt (thích nghi) với các nội dung và tính năng của hệ thống ở mức cao hơn. AI có thể tích hợp với các tính năng hiện có để cải thiện hiệu suất, thay vì người dùng phải thao tác thủ công. Khi hiểu rõ cách hoạt động chức năng của AI, chúng ta sẽ xác định rõ vai trò của nó trong ứng dụng và thiết kế để các hành động chức năng của nó không bị xung đột, cũng như không làm gián đoạn luồng sử dụng của người dùng.\n\n**17:28** Có sáu cách để mô tả mối quan hệ chức năng của AI:\n\n1. **Separate**: AI hoạt động riêng biệt.\n2. **Aware Of**: AI tách biệt nhưng có khả năng nhận biết các thay đổi trong tính năng chính.\n3. **Acting Up**: AI tương tác qua lại giữa các tính năng.\n4. **Feature Incorporate**: AI được tích hợp như một phần của một tính năng hiện có.\n5. **Usage**: AI được sử dụng theo cách mà nó tương tác với các phần khác trong ứng dụng.\n6. **Usage Conventionally**: AI tương tác hai chiều với các tính năng khác một cách trực tiếp.\n\n**18:14** Nó sẽ không ảnh hưởng trực tiếp đến tính năng chính, nhưng nó sẽ có tác động qua lại với AI và từ đó giúp cải thiện tính năng chính. Đây là một ví dụ cụ thể hơn về cách sử dụng của nó, chẳng hạn như trong code này có thể generate một panel bên phải.\n\nTiếp theo là **Acting Up**, nghĩa là hai bên sẽ có tác động qua lại, có thể trao đổi dữ liệu qua lại với nhau. Ví dụ, tính năng A có thể hiểu được dữ liệu từ tính năng B và ngược lại. Các dữ liệu này sẽ được trao đổi qua lại liên tục để cải thiện sự tương tác.\n\nTiếp theo là **Feature Incorporate**, nghĩa là AI được tích hợp trực tiếp vào các tính năng hiện có của ứng dụng. Cuối cùng là **Usage Conventionally**, nghĩa là AI sẽ tương tác theo cách thông thường với các tính năng khác, giống như cách các ứng dụng truyền thống hoạt động.\n\nVí dụ như khi bạn dùng một ứng dụng và có nhiều tính năng khác nhau, AI sẽ đóng vai trò trong các phần như feature, nhưng không phải lúc nào cũng là phần chính, mà sẽ đóng vai trò bổ trợ.\n\n**19:06** Ví dụ khác là ứng dụng Quora hay các ứng dụng khác, AI sẽ có nhiều tính năng nhỏ được tích hợp vào, như kiểu gợi ý trả lời câu hỏi, giúp người dùng thực hiện các tác vụ dễ dàng hơn. Vậy là nãy giờ em đã đi qua ba phần chính:\n\n1. **System Scope**: Giới thiệu cách AI tích hợp vào sản phẩm.\n2. **Spatial Relationship**: Giới thiệu cách sắp xếp AI trong giao diện người dùng.\n3. **Functional Relationship**: Giới thiệu các mối quan hệ chức năng giữa AI và các tính năng khác.\n\nNhững phần này giúp tối ưu hóa sản phẩm, cải thiện trải nghiệm người dùng và nâng cao hiệu quả cho ứng dụng AI.\n\n**19:57** Điều này rất quan trọng bởi vì nếu mình hiểu rõ cách áp dụng AI, tính năng mình làm sẽ mang lại nhiều giá trị hơn cho người dùng. Ví dụ mà em quên chưa nhắc đến là phần \"separate.\" Em đã đưa ra một số ví dụ, nhưng để quay lại một chút về \"separate\" – tính năng AI hoạt động độc lập. Mình có thể xem xét trường hợp Microsoft có một cái slider để generate hình ảnh song song với tính năng khác. Hoặc với một ứng dụng như Shopee, AI sẽ đóng vai trò hỗ trợ bên cạnh tính năng chính của ứng dụng.\n\n**20:53** Đó là những ví dụ minh họa cho việc sắp xếp và bố trí AI trong giao diện và sản phẩm. Anh Thành có thấy phần này như thế nào? Em thấy nó giống với các patterns thông thường trong thiết kế.\n\n**22:01** Anh Thành: Đúng rồi, những cái này là các mẫu patterns mình hay dùng trong việc thiết kế ứng dụng AI, hoặc khi tích hợp AI vào một ứng dụng hoặc sản phẩm riêng biệt. Về cơ bản, nó là những cấu trúc quen thuộc để mình hiểu rõ hơn về cách áp dụng AI. Em có thể phân loại, chia nhỏ chúng ra thành những tính năng nhỏ hơn. Phần này rất rõ ràng.\n\n**23:31** Cảm ơn Nam. Ok, tiếp theo là bài của Hoàng và Đạt nhé.\n\nHôm nay, em sẽ giới thiệu một bài gọi là \"AI Button trong các ứng dụng LLM.\" Trước khi vào bài, em sẽ nói qua về nội dung và agenda. Đầu tiên là chúng ta sẽ tìm hiểu về các design patterns liên quan đến AI Button. Những cái pattern này được áp dụng trong nhiều ứng dụng khác nhau. Em sẽ lấy ra những cái phổ biến và dễ hiểu nhất để giới thiệu cho mọi người.\n\n**24:35** Bài này sẽ xoay quanh việc sử dụng ứng dụng AI trong các sản phẩm số. Ứng dụng này tận dụng sức mạnh của các mô hình AI để giải quyết các bài toán cụ thể hoặc hỗ trợ người dùng trong các tác vụ. Khi sử dụng LLM, nhiều người có thể gặp vấn đề là mô hình không đưa ra đúng kết quả như mong đợi. Điều này là do bản chất của các mô hình này chỉ dựa trên khả năng phản hồi dựa trên chuỗi dữ liệu. Có nhiều cách để giải quyết vấn đề này. Một trong những cách tốn kém nhất là phải điều chỉnh lại toàn bộ mô hình từ đầu. Điều này có thể mất nhiều thời gian và nguồn lực.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/s7doIOUDGgA?si=Jrnm_7QXsbImTctp\u0026amp;start=1435\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**25:15** Mình có một cách gọi là **in-context learning**, có nghĩa là AI có thể học trực tiếp ngay trong ngữ cảnh hiện tại khi bạn đang sử dụng nó. Đây là một kỹ thuật như là few-shot learning hoặc zero-shot learning, giúp AI tự học mà không cần phải được huấn luyện lại từ đầu. Ví dụ, bạn chỉ cần cho AI một vài ví dụ nhỏ trong ngữ cảnh và nó sẽ tự điều chỉnh cách hoạt động của mình dựa trên những gì được cung cấp. Thay vì phải retrain toàn bộ mô hình, cách này giúp tiết kiệm thời gian và tài nguyên rất nhiều, và nó vẫn đảm bảo AI có thể học từ ngữ cảnh cụ thể mà bạn cung cấp.\n\n**25:52** Với trường hợp này, **in-context learning** được sử dụng rất nhiều trong **prompt engineering**. Mọi người sẽ cung cấp các ví dụ có sẵn trực tiếp vào prompt và mô hình sẽ học từ những ví dụ đó để tạo ra các kết quả tiếp theo. Đó là ý tưởng chính của in-context learning. Về cơ bản, thiết kế sẽ hoạt động như thế này: bạn có một truy vấn, sau đó bạn xây dựng prompt với các ví dụ cần thiết và dữ liệu few-shot learning, rồi bạn đưa nó qua mô hình, mô hình sẽ trả về kết quả dựa trên các ví dụ đó. Tuy nhiên, nó không chỉ dừng lại ở các ví dụ, mà còn bao gồm rất nhiều yếu tố khác.\n\n**26:37** Nhìn rộng hơn, in-context learning liên quan đến việc cung cấp ngữ cảnh vào prompt bằng cách truyền vào các thông tin mà mô hình không có sẵn. Vì đây là một mô hình được huấn luyện trước, kiến thức của nó bị giới hạn, vì vậy bạn truyền thêm thông tin vào ngữ cảnh và prompt để mô hình học trong quá trình tạo ra kết quả. Ví dụ, trong chẩn đoán hình ảnh y khoa, mô hình có thể không có đủ kiến thức chuyên môn. Vì vậy, bạn cung cấp kiến thức đó vào ngữ cảnh và prompt để mô hình học trong quá trình tạo ra kết quả. Đó là cốt lõi của in-context learning.\n\nTiếp theo là nút thiết kế thứ hai quan trọng, được gọi là **data preprocessing/ editing**.\n\n**27:54** Phần này miêu tả quy trình chuẩn bị dữ liệu cho mô hình ngôn ngữ (LM). Như mọi người biết, LM hoạt động dựa trên các cơ sở dữ liệu vector, sử dụng so sánh vector để tìm các điểm dữ liệu tương tự. Quy trình này thường liên quan đến việc xử lý dữ liệu đa phương tiện và các loại thông tin khác nhau. Để đảm bảo đầu ra là tối ưu, việc áp dụng các bước xử lý trước dữ liệu là rất quan trọng. Ví dụ, bạn có thể xử lý trước văn bản bằng cách lọc ra các chi tiết không cần thiết để làm ngắn lại, hoặc với hình ảnh và âm thanh, bạn có thể loại bỏ nhiễu hoặc nén dữ liệu để giảm kích thước trước khi đưa qua mô hình ngôn ngữ.\n\n**29:19** Việc xử lý trước hoặc chỉnh sửa dữ liệu giúp mô hình hoạt động hiệu quả hơn. Có nhiều cách để xử lý trước, tuỳ thuộc vào loại dữ liệu hoặc ngữ cảnh. Bạn sẽ thực hiện điều này dựa trên các yêu cầu cụ thể. Nút thiết kế tiếp theo mà tôi muốn đề cập đến là một thiết kế thường được sử dụng, mặc dù có nhiều tên gọi khác nhau. Tôi gọi nó là **example agent**. Đây là một thiết kế thường thấy khi bạn muốn truy vấn của mình đi qua nhiều ngữ cảnh khác nhau. Ví dụ, nếu bạn có một ứng dụng đánh giá bài viết, bạn có thể cho bài viết đó đi qua một đường ống nơi mỗi agent đánh giá bài viết từ một góc độ khác nhau.\n\n**30:11** Một agent có thể đánh giá bài viết từ góc nhìn của một nhà văn, một agent khác có thể từ một góc nhìn khác. Sau khi đi qua tất cả các agent này, sẽ có một lớp tổng hợp cuối cùng để kết hợp hoặc xử lý các kết quả đó, và cuối cùng cung cấp cho người dùng một kết quả tổng hợp. Thiết kế này thường thấy trong các hệ thống đánh giá, nơi bạn đánh giá kết quả từ các mô hình khác nhau và chọn ra kết quả tốt nhất dựa trên các điều kiện đã được thiết lập trước.\n\n**30:55** Nút thiết kế tiếp theo, gọi là **agentic button**. Vậy agentic có nghĩa là gì? Trong ngữ cảnh của các mô hình ngôn ngữ (LMs), **agentic LMs** ám chỉ việc nâng cấp khả năng của mô hình. Vì mô hình chỉ biết những gì nằm trong dữ liệu huấn luyện của nó, chúng ta sẽ nâng cấp nó để tăng cường sức mạnh của nó và giảm thiểu sự can thiệp của con người. Thiết kế này giúp hệ thống tự động hoá nhiều hơn, cho phép nó hoạt động với ít sự can thiệp của con người hơn.\n\n**32:24** Thiết kế này có một số thành phần chính giúp bạn đạt được mức độ tự động hóa này. Có bốn thành phần chính: **reflection**, **planning**, **execution**, và **multi-collaboration**. Mỗi thành phần này đều giúp hệ thống của bạn trở nên tự động hóa hơn. Đầu tiên, chúng ta hãy nói về **reflection**. Reflection liên quan đến việc đánh giá kết quả ban đầu của mô hình dựa trên một tiêu chí hoặc một chỉ số cụ thể để xác định xem kết quả đó đã được tối ưu hóa chưa. Nếu chưa, hệ thống sẽ điều chỉnh và lặp lại quá trình này, tiếp tục tạo ra kết quả cho đến khi đạt được kết quả tối ưu.\n\n**33:06** Reflection giúp giảm thiểu sự can thiệp của con người vì thay vì tạo ra một kết quả ban đầu không đáp ứng mong đợi của bạn, hệ thống sẽ tinh chỉnh dựa trên các tiêu chí đã được thiết lập trước, cuối cùng đưa ra một kết quả chính xác hơn mà không cần điều chỉnh thủ công.\n\nReflection button này có nghĩa là nó sẽ đánh giá cái output ban đầu của một con AI, rồi nó sẽ đánh giá dựa theo một tiêu chuẩn nào đó hoặc là một cái chỉ số nào đó để xem là cái kết quả này đã tối ưu chưa. Nếu chưa tối ưu nó sẽ thêm thắt một chút và nó sẽ chạy vòng lại con AI đó để nó tạo ra kết quả khác cho tới khi nào đạt được kết quả tối ưu nó sẽ trả cho mình cái kết quả cuối cùng. cái này nó sẽ giúp giảm thiểu việc con người phải can thiệp vào quá trình làm việc, bởi vì nếu mà output đầu tiên không đúng ý mình, mình không cần phải tự chỉnh lại nữa mà nó sẽ tự tối ưu.\n\n**33:42** Button thứ hai là tool. Tool có thể là external, nó có thể là external API hoặc là những cái function mà mọi người code. Những cái tool này được sử dụng để cho model có thể lấy được những knowledge từ thế giới bên ngoài, những real-time knowledge, những external resource mà nó không được train sẵn. Như OpenAI hay là Claude đều có hỗ trợ. Khi đó, con model có thể tự biết khi nào cần gọi tool dựa vào cái description mà mọi người viết trên cái tool đó. Model sẽ tự biết cách lấy và extract thông tin từ tool, rồi trả về cho con LM để nó generate ra output.\n\n**34:30** Kế tiếp là planning. Planning button có nghĩa là mọi người cho con LM có khả năng lập kế hoạch, để tránh việc phải prompt đi prompt lại nhiều lần. Ví dụ, nếu có một task phức tạp, mình sẽ có một cái prompt lớn cho nó plan ra tất cả các step mà nó cần làm theo kiểu step by step. Cách này sẽ cho nó làm những việc nhỏ trước, rồi cuối cùng kết hợp lại thành một cái task lớn. Cái kiểu planning design này có nhiều biến thể, và đây là biến thể đơn giản nhất: lập kế hoạch xong rồi làm từng bước một.\n\n**35:10 C**uối cùng là multi-collaboration. Cái này em đã present cách đây một tháng rồi. Nói chung, nó giống như kiểu là AI giỏi việc nào làm việc đó. Mình có một cái context đúng không? mình chia nó ra, rồi đưa qua từng người. Người nào giỏi việc đó nó sẽ giải quyết việc đó, xong rồi pass qua con agent tiếp theo. Cứ thế, cuối cùng nó sẽ complete được cái requirement. Cái design này sử dụng tính chất divide and conquer khá nhiều. Chia việc lớn thành việc nhỏ, rồi đưa việc nhỏ cho người giỏi chuyên môn. Đây là một cái design button mà em thấy khá nhiều nơi bên ngoài sử dụng.\n\n**36:24** Đó là những design button mà em thấy nhiều nơi sử dụng và hiểu nhất. Em đã trình bày xong. Mọi người có câu hỏi gì không?\n\n**37:10** Hoàng, em nói lại cái phần planning, để confirm lại cái comment của anh Bảo. Nó giống như là kiểu đọc cái prompt đúng không? Nó sẽ hiểu cái prompt của anh trước, xong rồi nó sẽ chia cái prompt ra thành những cái nhỏ hơn, xong rồi nó sẽ có những con worker, có thể là những IDE worker hoặc là những cái prompt nhỏ để nó hoàn thành task đó. Đúng không?\n\n**37:40** Đúng rồi, anh có thể hiểu như vậy. Mình có thể chia prompt ra, ví dụ như là một task phức tạp, nó sẽ chia ra nhiều cái plan nhỏ. Những cái plan nhỏ này sẽ làm step by step. Ví dụ nó làm plan 1 trước, rồi làm plan 2, rồi làm plan 3. Sau khi hoàn thành tất cả các plan, nó sẽ tổng hợp lại ở một cái chỗ nào đó, hoặc là một cái component cuối cùng để nó ra được câu trả lời cuối cùng.\n\n**38:06** Ý là nó giống như cái con Zero mà hôm trước anh Tom present ấy. Con worker sẽ có thể làm một số task như đọc file, xóa file, sửa file, hay là talk với Internet, gửi email các thể loại. basically, agent các thứ như vậy.\n\n**38:52** Đúng rồi, bản chất của nó là thay vì làm một cục rất lớn để giải quyết hết cái task đó, mình phải đi prompt đi prompt lại nhiều lần để nó cho ra kết quả. Mình có một cái prompt trước, để chia nhỏ thành các task nhỏ, rồi sau đó có một cái pipeline để nó đi qua từng con worker, làm những việc nhỏ nhỏ cho mình.\n\n**39:23** Ok, kéo lên slide 14 đi Hoàng, slide 14. Anh cũng thấy là kiểu con này giống giống con Mule Automation mà Tom setup đúng không? Con Mule button mà Tom setup ấy. Em đã code xong rồi nhưng nhìn cái design này với cả cái button giống hệ nhau này.\n\n**39:46** Ừ, cái này là thằng Tpm nó chạy loop rồi, nhìn ra giống giống một tí. Nó giống planning mà anh Tom vừa nói, là nó break task ra từng phần, rồi xử lý từng phần một. Nó có iteration trong đó, giống như là nó có một list các step mà em đã mô tả ở trên. Back lại cái của em, chính là chỗ mà agent đang thấy. Cái của anh thấy nó giống planning hơn, là nó chia plan ra trước, rồi làm step by step từng plan một, đi qua mỗi vòng làm từng cái một. Còn cái này nó giống như là làm song song với nhau, nó parallel với nhau, để ra output xong rồi đánh giá lại output đó, rồi đưa ra kết quả cuối cùng. Chắc anh nhầm cái work rồi, đã correct lại.\n\n**42:28** Đúng rồi, thử đi. Nó là kiểu như vậy đó, nó chia ra thành nhiều việc khác nhau. Nó giống như là classify, nó chạy qua từng cái. Cái này giống multi-collaboration hơn, vì nó giống như question classifier, chỉ chạy một trong mấy cái này thôi. Mỗi agent làm việc đúng chuyên môn của nó, rồi combine lại.\n\n**43:33** Nhưng mà anh thấy mấy phần như reason với input analysis có đúng không? Của Tom, phần expert ấy. Riêng vụ pick domain ấy, nó có classifier ở đó, nhưng mà mấy phần reason với input analyzer là những agent khác nhau. Bên group đó là expert thôi, mình consider nó như là một group expert đúng không? Và nó combine với năm cái agent mình phía dưới.\n\n**45:33** Nếu mà làm tất cả mọi thứ trong cùng một cái prompt, em chắc chắn nó sẽ không ra được kết quả mình mong muốn đâu. Vì context quá nhiều và không có example cụ thể. Đầu tiên là accuracy chắc chắn sẽ giảm vì quá nhiều dữ liệu cùng lúc. Cái chính là phải chia ra nhiều layer, từng bước một. Thực tế mình cần output từ con LM, chứ không thể hardcode từ trước được. Mình chỉ muốn một cái prompt đơn giản nhất, để nó làm ra các câu trả lời nhỏ, rồi từ đó có một câu trả lời lớn.\n\n**46:59** Đúng rồi, khi làm nhỏ ra, mình sẽ biết vấn đề nằm ở đâu để debug. Như anh đã nói, specify kỹ, chia ra từng layer, nếu thấy sai ở đâu mình sửa ở đó. Còn nếu quăng một cục, mình sẽ không biết nó sai chỗ nào, rồi phải sửa rất nhiều lần.\n\n**48:43** Đúng rồi anh. Ví dụ như tạo một cái event trong calendar vào ngày mai, nếu không có sự kiện trong giờ đó tạo event, còn nếu có rồi thông báo. Nếu mình quăng một cục request đảm bảo nó sẽ rối ngay, vì nó phải thực hiện theo step by step. Nếu chia thành từng layer, test từng bước sẽ ổn hơn.\n\n**49:23** Nó sẽ em chắc là 99% là nó sẽ mù luôn á. Nếu mà còn nếu mình chia cái thành layer cơ, thành nhiều lớp layer á, làm test bài test nó sẽ ok hơn. Rồi, hô nào nên nữ, nên văn phòng là có Tôm ở đấy người chửi nhau. Anh không có hỏi nào chắc là cảm ơn Hoàng trước. À, đến Đạt nhé. Đạt nhờ. À, em không thị xem màn hình. Ok rồi, mọi người thấy màn hình của em chưa? Ừ, thấy rồi.\n\n**50:38** Hôm nay em nói về Yelp use cases. Từ từ Đạt, để anh giới thiệu context một chút. đợt này team mấy bạn sẽ focus vô đâu đó và đi search thử mấy cái phần use case ấy. Use case ở đây có nhiều dạng. Cái dạng mà Đạt đang sharing nó sẽ là mình xem thử các bên startup hay enterprise nó đang apply vào để giải quyết vấn đề gì. Là có thể là những cái green field, tức là những cái hoàn toàn mới. Hoặc là những cái mà nó optimize cho cái phần current workflow của chúng đó, kiểu vậy. Nó sẽ viết những use case và report lại hàng tháng, những cái phần update. Ngoài ra có một cái phần dạng use case khác nữa đó là những cái phần tuning mà để boost phần development của bên phía bên phía là tech các thứ. nó sẽ có những cái technique hay là có những cái phần editor mới, hay là mấy cái tool mới các thứ. đ cũng sẽ report cái phần đấy đâu đó trong tech. Đang testing thử trong khoảng hai tuần một đấy. đây là một cái bài đầu tiên chắc con Yelp này, nó đang dạng là con start-up phải không, chắc là. tiếp tục giới thiệu cho anh em một tí về cách mà bọn này đang apply AI là như thế nào?\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/s7doIOUDGgA?si=l1ZUsZApjB78hPcD\u0026amp;start=3018\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**52:01** Yelp là cái đơn vị nó đưa ra cái software, nó cung cấp cái software cho các store, các bên mà doanh nghiệp muốn làm các đơn vị nhỏ lẻ như kiểu là giao hàng nhanh, hay là nhà hàng, rồi các bánh dụng cụ cơ bản, kiểu như vậy. Yelp này nó bán cái software cho mọi người làm việc đó. em sẽ chia sẻ chút về thằng này, nó sử dụng AI vào trong cái tooling của nó như thế nào.\n\n**53:00** trước đó chúng nó có một cái machine learning system rồi, bây giờ nó app thêm AI vào để giúp cho cái việc recommendation nó đúng hơn. bọn Yelp này nó có trên hệ thống của chúng nó, nó có nhiều cái thể loại đánh giá như kiểu đánh giá nhà hàng nó không bị tốt chẳng hạn. dựa trên những cái review đó, chúng nó có làm cái trò là text editing để so sánh được những cái kết quả mà spam hay không á. nó sẽ sử dụng AI vào trong cái việc gì. Thứ nhất là chúng nó sẽ tạo, chúng nó sử dụng AI để làm cái việc làm dataset, để train được cái model đánh giá là nó đang spam hay nó đang review tốt hay xấu như thế nào á. nó sẽ sử dụng AI để tạo ra cái dataset dựa trên LinkedIn. ở trong đây, em đọc có thấy bảo là chúng có sử dụng số tính như Zero-shot và Few-shot để làm dataset. chúng nó chỉ sử dụng một số cái model ở trên Hugging Face, rồi xong chúng nó làm classify để đánh giá được là review tốt hay xấu. đây là một cái use case cho cái việc AI dùng để làm text editing.\n\n**54:18** À, sang cái use case thứ hai của chúng nó, là chúng nó có sử dụng Clip Model. Clip Model bản chất của nó là xử lý hình ảnh. Xử lý hình ảnh có nghĩa là sao? Có nghĩa là dựa trên review, dựa trên review... đợi em chút để em kiếm nè. À, Clip á, nó sẽ xử lý hai thứ. Một là cái caption của cái ảnh, và cái ảnh nó như thế nào. qua Clip này á, nó sẽ hiểu được cái context của cái ảnh là cái gì. chúng nó sử dụng Clip vào trong những cái công việc như là những cái người ta đi vào trong một quán ăn hay một cái quán nhậu á, chúng nó sẽ review, chụp ảnh để capture lại những cái thứ này. Và ví dụ như hình ảnh của một cái món sản phẩm đi, trước khi apply Clip nó không đánh giá được, nó không đánh giá được là nó có bánh quế không, nó chỉ đánh giá được mỗi gà rán thôi chẳng hạn. Sau khi apply Clip vào á, nó sẽ biết được là có gà rán và có bánh quế. bản chất, nó sử dụng cái Clip này là một phần của AI, là nó xử lý ảnh, xử lý ảnh và caption của ảnh, và hình ảnh thành vector để nó so sánh với nhau. đây là hai use case của nó. những cái use case này được áp dụng cho cái gì?\n\n**55:38** Hai cái use case trên nó sẽ áp dụng trong cái tình huống là khi mà mình có nhiều review á, mình có thể summarize nó lại thành một cái highlight review ở trên đây. dựa trên những cái thứ mà nó chuyển thành vector được á, nó có thể annotation được cái việc là những cái hình ảnh đang nói cái gì, nó support cho mình được cái gì ở trong đây. Đợi một chút, nó sẽ highlight cho mình luôn. nó sẽ biết được cho mình cái context của cái ảnh là gì, nó có thể annotation được cái việc này. đó là cái use case của cái việc mà AI dùng để làm image summarization.\n\n**56:15** Đầu năm nay nó có release thêm cái là Yelp Assistant. Dựa trên những cái nền tảng cũ của chúng nó, chúng nó có thể tạo ra chatbot rồi, xong nó có thể review lại cái highlight như thế này, mình cứ hỏi nó xong nó recommendation cho mình cái gì thôi. Đơn giản là như vậy. Ngoài ra em có thấy một cái use case cũng khá đặc biệt, có nghĩa là trong cái giai đoạn từ 2020 á, nó nổ ra cái câu chuyện là làm clip ngắn review các thứ á. chúng nó có một cái nguồn dataset nhất định cho cái việc đó. em thấy chúng nó bảo chúng nó sắp release một cái như anh Tom có đề cập, cái bọn đó có thể chuyển văn bản thành giọng nói á. dựa trên cái nguồn dataset review này á, có lẽ chúng nó support review thêm cái việc mà làm video clip ngắn để mô tả cái nhà hàng.\n\n**57:45** Dựa trên những cái review, những cái video mà người ta tới người ta review á, mình có thể tạo ra được một cái đoạn script, xong cho nó chạy qua AI, nó tự động làm ra một cái video về một cái nhà hàng như mình. đây là use case của bọn này, đơn giản nó có thế thôi. Ok, quay lại cái câu hỏi đầu tiên, cái này nó sẽ dạng là dùng AI để label data, đúng không?\n\n**58:35** Ok, vậy là check xem là cái comment là negative hay positive, đúng không? Kể kiểu đấy là một ví dụ. Cái thứ hai nữa là nó sử dụng cái clip model, đúng không? Chắc là sẽ dạng giống như Vision, nhưng mà live hơn, cũng để dán nhãn, đúng không? Để dán nhãn giống như cái của bên phía Plot, dán nhãn cho ảnh. hai cái use case đó, nó sẽ được ứng dụng trong cái việc gì?\n\n**59:18** Em nghĩ có một cái ý khá hay mà nó chưa nói tới, là câu chuyện là nó có nguồn dataset sẵn. Như là ai tới review, ai tới đánh giá các thứ, dựa trên những cái clip ngắn như thế này, nó có thể tạo ra được một cái video intro về cái nhà hàng đó. Nó sử dụng AI. Em nghĩ là nó sử dụng AI để viết kịch bản, rồi sau đó đưa kịch bản đó cho một con AI voice để nói. Nhưng mà hình ảnh nó lấy ở đâu? Như kiểu là video nó sẽ lấy từ đâu ra?\n\n**59:57** Từ trong cái review, ai tới review họ sẽ có một cái video để review. Ok, tự động tạo advertisement, đúng không? Dạ vâng, cho TikTok hay những nền tảng như TikTok các thứ, kiểu summarize từ review của user. Nghe cũng có vẻ sáng tạo đấy. Ừ, chắc anh em confirm mấy cái của anh bảo làm rồi đúng không?\n\n**01:00:07** Đang vậy, cái này ok là cái caption. Ok, đúng hầu như là đúng anh. Bạn nói đúng, là chúng nó sẽ, em nghĩ em nghĩ cái use case này bọn này ban đầu á, cái mục đích ban đầu của bọn này là làm recommendation. trước đó, trước khi có AI chúng nó đã có một cái hybrid recommendation model trước. Căn bản là nó sẽ... Em nghĩ là khi mà có cái này á, nó dẹp gần hết cái model cũ này luôn. Em nghĩ có một cái khá hay là cái business messaging mà chúng nó không có đề cập nhiều. Có nghĩa là em nghĩ là nó sẽ dựa trên là có review top 50 review chẳng hạn. Xong top 50 cái interaction, kiểu như rating như thế nào. Thứ nhất là review tốt, n rating tốt, cái business messaging của nó sẽ tốt. Mà Yelp không đề cập vấn đề này, mình không trách nó được.\n\n**01:00:51** Ok, anh em có câu hỏi cho Đạt không? Bài đầu tiên đấy. Đạt bảo đang thêm mấy cái, mình phải enterprise nữa, nhưng mà thầy thấy đang Viettel với cả FPT, với cả VNG các thứ, đang chưa biết thấy chúng nó thế nào. Đạt kêu mấy cái tool, cái tool gì coding của bên phía FPT hả, đang kêu cùi.\n\n**01:01:41** Hì, một bản for, một bản for của của continue à? Nó thế, nó thế không tốt. Nó hơi cùi, thô. Hai, chị hết rồi à? Chắc vậy. Đạt nhé. Hôm nay mấy bài về Yelp và Tech Linh chắc tuần sau, tuần sau, tuần sau nữa, nếu kịp.\n\n**01:02:01** Tí demo luôn đi, Đạt luôn. Để Đạt demo một tí cái gì nhỉ? Cá đang là một con bot, để có thể question với cả question một cái short code dưới dạng kiểu developer mà hiểu rõ hơn về code, hay là test kiểu như là một vai trò auditor đi kiểm tra chất lượng của code. Đạt đang demo dev cái workflow hay con bot dựa trên diff đó cho anh em xem thử nào. Mình bật hình rồi Đạt ơi.\n\n**01:03:01** đây là một cái project để em xin vào club ai nha. Trình em gọi là hơi 'newb' nên project này mà có lem quá mọi người thông cảm. Workflow cơ bản là em sẽ lấy query, rồi trích xuất ra được cái URL của repo. Ở đây em có dùng lại cái scrapper của anh Tom, nhưng mà nó chưa đúng ý em, nên em có tạo một con scrapper ở local nó sẽ lấy được tất cả content của repo luôn. Nhưng mà cái đó nó quá lâu với quá lớn. Ờ, default hiện tại em chưa thấy làm cách nào mà bỏ vào con context được, trừ khi dùng cái knowledge retrieval, mà dùng knowledge retrieval em không có gọi là trực tiếp được mà phải bỏ vào trước. Mình không có chọn, không có chọn repo được.\n\n**01:05:45** Cái scraper này của anh Tom nó không có lấy content của file, cho nên em chưa vẽ diagram được. Vẽ diagram có thể em dùng, tí nữa em test thử. Cái này là em lấy được content của những file nè, ở root, ở những file doc. Những file đó không chắc câu hỏi của Huy vừa đưa ra chắc là cũng không trả lời được. Để em thử, em có sẵn cái full của em vô đây rồi, offline nhỉ. Bên phía in sẵn content rồi, chứ không online. Cái này em generate bằng luôn, cũng không có.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/s7doIOUDGgA?si=DGxSbJrTJjDCyUp5\u0026amp;start=3798\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**01:07:07** Cái này nó sẽ scrap full content, nó sẽ đầy đủ hơn. Để em thử đặt câu hỏi của bên Huy hay của Hoàng các em thử nào. Mình thử BC chat lên rồi đặt câu hỏi xem. Anh có không? À không. Maybe là cái context này quá lớn, cái phần knowledge retrieval này em chưa tìm được cách mà cho nó vào context tốt được.\n\n**01:09:19** Retrieve tối ưu lắm. Cái file text này cũng mấy chục ngàn dòng, mấy chục ngàn dòng á. Mở lên xem thử nà, đ đang dùng mini hả, đổi sang máy đ xịn hơn xem có ok hơn không. Đồ mini hơi cùi. 2 triệu từ như thế, từ làm sao mà nó còn xong được ta? Em nghĩ là phải có một cái server, cái dedicated server luôn nó mới ok. Anh đang tò mò tại sao nó chạy được ấy, bởi vì 29U word à, như vừa thấy à. Nhân với cả 4 này là số to. Kích cỡ đấy, Follow up xem thử. Ok, tức là em vẫn là từ cái context thôi đúng không, là mình cũng chỉ dạng là query kiểu query vb đúng không, chứ không phải mình nhập hết tất cả cái đấy vào context.\n\n**01:10:57** Ok, đúng rồi anh. em chưa nắm được là cái retrieval của thằng dify nó sẽ chạy như thế nào. Không biết nó chạy có đúng không, nó retrieve có đúng không. Em chưa tracing được nó mà em có cái tool tracing ở phía trước nữa, có thể test lại thử xem như thế nào. Nhưng mà ý là nếu mà kiểu retrieval như này chắc là kết quả nó sẽ không đúng được đâu anh. Anh cũng đang chưa biết là nó sẽ run bao nhiêu data ấy. Kiểu nó chỉ prefer 2-300 thôi, kiểu data không thể nào đủ mà để làm mấy cái task kiểu này. Cái này ít nhất cũng phải vài trăm tương đối data ấy. Dạ cái này còn work in progress.\n\n**01:11:35** Đùa đấy, cứ lên công ty là có AI Club rồi. À, là của full version hay là fix được cái vụ này demo với bọn anh ở trên office nhé, mà try em để lại cho anh. OK, để em xem nó vẫn không build ra chắc mọi người coi đỡ. Cái chắc build bị gì đó, mọi người thấy màn hình không ạ?\n\n**01:13:08** Dạ tuần này như em nói tuần trước em sẽ up cái bài sync.Map này. Em thấy nó hay với chi tiết để mọi người mà xài Go có cái nhìn tổng quan hơn về map nói chung. Và cái thằng sync map này đi qua trước là phần context. khi mọi người viết map đúng không, mà mình nếu mà mình viết concurrent map hay operation đó, mình làm concurrent á, về bản 1.16 trước nó sẽ không báo đâu, nhưng mà nó vẫn không safe nha. Còn bản từ 1.16 trở đi á nó sẽ error như thế này đó. Cho nên là để mà solve được problem này bình thường mọi người có thể viết map kèm với tại package sync, viết manual đó được.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/s7doIOUDGgA?si=0nH3Rjv-OZ5FAoAP\u0026amp;start=4394\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**01:13:56** Bên cạnh đó nó có một cái option khác đó là thằng sync.Map này. chút nữa đến cuối mình sẽ sẽ nói tại sao nó lại được đề ra xài và cái usecase của nó như thế nào. thằng này nó được đề ra để mà mình không cần quan tâm lắm về cái việc mà mình phải xài mutex để lock lại cho việc synchronize. Tức là mình chỉ có việc xài thôi. Xài nó trông đơn giản như thế này nha, nó friendly như là mình viết map kiểm tra value vậy. Ví dụ như mình load một cái key lên có value ok nó sẽ giống như là việc map value bình thường thôi. Trong như này, nếu có là ok true, còn nếu không có false của y chang.\n\n**01:14:38** Còn có một số cái function mà mình có thể xài rất handy. Đây là bảng 12.23 sẽ có clear, clear hết. Ví dụ như load là để lấy value, store là để update hoặc store cái key. Update vậy. Delete các thứ. ngoài cái việc mà mình viết concurrent đó đi đó, bên cạnh đó khi mà mình range, tức là mình loop một cái map nó cũng bị race condition nữa. thằng sync map này nó có cái hàm range này, mình xài mình sẽ không quan tâm nó là ấy, nó sẽ không bị nhưng mà như hàm range bình thường thôi. nó sẽ không cho mình cái cái snapshot mà gọi là consistent nhất, là khi mà mình vừa mới vô cái snapshot nó không được update là.\n\n**01:15:28** Mà mình range, tức là mình loop một cái map, nó cũng bị race condition nữa. thằng `sync.Map` này nó có cái hàm `Range`, mình xài, mình sẽ không quan tâm nó là cái gì, nó sẽ không bị như bình thường đâu. Nhưng mà như hàm `Range` bình thường thôi, nó sẽ không cho mình cái snapshot mà gọi là consistent nhất, là khi mà mình vừa mới vào cái snapshot nó không được update. trong lúc đó mình sẽ phải thay đổi cách viết, nhưng ít nhất là nó sẽ không bị phải error như thế này.\n\n**01:16:06** Đến cái phần bên dưới nó work như thế nào á. mọi người, nếu mà mọi người viết khi mà xem `CH` và `definition` cái `map` nó được cấu trúc như thế này: nó sẽ bao gồm hai cái `map`. Đó, nghe đến đây là mọi người sẽ thấy hơi kinh, nghe hơi thốn `RAM` với `memory`. Nó có một cái `Read Only map` và một cái `Dirty map`. nghe như thế mọi người có thể đoán được là nó sẽ làm việc theo kiểu là những cái value mà nếu mà được `write` nó sẽ được viết vào cái thằng `Dirty map` này hết. Cứ viết `update` vào đây, `update` vào đây, con này nó sẽ giống như là.\n\n**01:16:46** Cái `Read Only map` này nó sẽ là những cái khi mà mình đọc vào á, mình sẽ luôn đọc ở đây. Còn `write` sẽ luôn `write` mới vào thằng `Dirty map`. Còn cái flow bên dưới nó làm việc như thế nào chút xíu nữa mình sẽ nhìn cái chart flow mình sẽ thấy. À, cả hai cái `map` này có một điểm chung: nó đều có một cái con trỏ `entry` nha mọi người, để ý để dễ hiểu cái flow. Ví dụ, ở đây mình thêm một cái `entry` mới, đúng không? nó sẽ thêm vào `Dirty map` và nó đều trỏ đến `entry` này. Cái này nó sẽ giống như là một cái `flag` để đánh dấu rằng là cái `map` này đã được thay đổi rồi. Tức là cái thằng `Read Only map` này nó không phải là mới nhất nữa. Khi này bên dưới nó sẽ nhìn và hiểu rằng là thằng `Dirty map` mới là cái nên đọc vào.\n\n**01:17:27** Hình này thể hiện rằng là ví dụ như mình `update` một cái value nào đó, do bên dưới nó là con trỏ đúng không, mình chỉ việc `update` cái con trỏ đó thôi, không cần phải `update` từng cái value như là mình làm với `map` truyền thống. để làm được điều này á, bên dưới nó để ra một cơ chế là ba cái trạng thái (`state`) cho cái con trỏ `entry` này. `State` thứ nhất là `normal state`, đúng không? `Normal state` tức là những cái value cũ của `map`, nó đang có đủ và có thể xài được, không có bị gì hết. Còn trạng thái `amended` là khi mà `entry` đã bị sửa lại. Còn `delete state` là khi một `entry` nào đó đã được `delete` khỏi `map`, nhưng nó chưa được remove hoàn toàn nha. Tức là nó sẽ được...\n\n**01:18:59** ...assign cái con trỏ `entry` vào `new entry`, chứ chưa remove ra. Còn cái `expired state` là xóa hoàn toàn, giống như là `hard delete` là mất khỏi `map` luôn. Để hình dung rõ hơn, mọi người có thể nhìn cái flow như thế này nha: ví dụ ban đầu cái `map` của mình đang có một cái `key1` và `value1` đúng không? bên `Dirty map` chưa có gì cả, tức là chưa được thêm bớt gì. Sau đó, mình thêm một cái `key2` nào đó, đúng không? nó sẽ được thêm vào `Dirty map`, và khúc này là thằng `map` đã `amended` rồi, nó đã có một cái `flag` `amended` ở đây.\n\n**01:19:40** Sau đó, khi mình xóa (`delete`) một cái `key`, `map` này sẽ bị gán `new entry`, đúng không? Bên này cũng sẽ được tương tự gán `new entry`, giống như cái hình trước. Tức là mình chỉ cần cập nhật con trỏ thôi, không cần phải cập nhật value. Rồi, sau khi `delete` xong, đúng không, để `promote` được cái `Dirty map` này, mình phải cập nhật lại qua bên `Read Only map`, để `Dirty map` trở về `new state`, giống như đưa về trạng thái ban đầu.\n\n**01:20:18** Tương tự, thêm một `key3` nữa, khi thêm cái `key3` này á, cái `state` này nè, sau khi nó đã trở về `new state` rồi đúng không, mình thêm `key3` vào á, nó xác định rằng thằng này đã được `delete` rồi, nó sẽ là `delete` hoàn toàn. Điều này có nghĩa là lần sau, khi nó so sánh với `Dirty map`, nó biết rằng bên này cái `value1` đã bị xóa rồi, không còn nữa. cái `Read Only map` lúc này chỉ còn lại `key2` và `key3`.\n\n**01:20:51** Cho nên chính vì lý do này, `sync.Map` không có hàm `len` cho mọi người xài. Tại vì nếu như mọi người dùng hàm `len` ở đây, sẽ không biết được `value` của nó, tại vì lúc đó nó sẽ đếm cả những cái `value` đã `expired` hay `deleted`. Mọi người có thể thấy, chính vì cái cấu trúc của `sync.Map` được build như thế này, use case của nó được recommended là nên dùng cho những use case mà đọc (`read`) nhiều hơn ghi (`write`). Tức là nếu mà `write` hoặc `delete` nhiều, mọi người tưởng tượng chỗ này nó xài con trỏ liên tục, và có một cái issue bên Go team đã report là thằng này không bao giờ được garbage collected.\n\n**01:21:36** Sau đó Go team họ confirm rằng cái `sync.Map` này được sinh ra chủ yếu để support mấy cái bên trong Go Library thôi. Nếu mọi người thấy nó `handy` vì có những function dễ xài có thể xài, nhưng nếu use case của mọi người mà cần lưu trữ (`store`), hoặc là `update`, `delete` nhiều không nên xài, vì nó sẽ làm chậm hệ thống.\n\n**01:22:24** Dạ chắc chỉ vậy thôi ạ. Em có code lại cái bài bên này là cái bác này hay share mấy bài cũng khá chi tiết, mọi người có thể follow theo dõi. Ủa, cái này là topic gì Phát? Cho anh coi lại cái bài kịch bản đúp đầu r. À, cái sync map à? Ừ, sync map á. Ủa, nó có khác gì với lại cái anh vừa pass vô không vậy? Khác ở cái gì? Hình như là khác á anh. Ý là cái này em nhớ không nhầm là kiểu như cộng đồng tùy. Anh ví dụ use case họ muốn viết một cái gì đó mà họ thấy. Đó, anh nhìn thấy, họ ghi cái trong cái bên đấy, link mà nhìn thấy cách nó chạy mà lý do tụi nó làm thêm cái gì ấy nhỉ?\n\n**01:23:30** Anh nhìn thấy nè, họ thêm một cái lớp nữa để họ xài. Ví dụ như là họ sẽ có những cái use case đúng không? Ví dụ như họ muốn implement generic trên `sync.Map` đó. Cái này cũng có ảnh hưởng do cái vụ link nãy em nói, do thằng này nó không được garbage collected nè. Đó, kiểu vậy. ví dụ như bên này Go team ở dưới, họ đã confirm chốt xong cái này là cái `sync.Map` này họ kêu là cái này là `intended`, intentional choice rồi, cho nên họ sẽ không sửa. Họ sẽ không đổi đúng không? Bây giờ cộng đồng làm gì mình chỉ biết là họ tự xài thôi. Ý là họ thích cái việc `sync.Map` này được để ra dễ xài, có mấy cái function ngon lành, họ ráng thêm một tầng nữa, rồi chế những cái mà họ cảm thấy là ok, mình có thể xài được. Kiểu vậy.\n\n**01:24:07** Ủa mà sao cái clip này cũng lâu mà bữa nay lại chọn à? Ờ, thế kiểu insight thôi, insight cho mọi người xài. Ý là cái use case này cũng có thể được apply cho bên mình. Ví dụ như bên enterprise đúng không? ví dụ mình xài `map`, mà mình xài concurrency đúng không? mọi người sẽ tự viết một cái `struct`, xong rồi mọi người sẽ nhét một cái `mutex` vào, rồi tùy người sẽ ngồi bắt đầu viết lại. Đủ các kiểu. Trong khi đó thằng `sync.Map` rất handy, như nãy em show anh, là mấy cái function này là nó luôn follow cái chuẩn, là anh muốn `load` anh phải gọi hàm này. Kiểu vậy, nó chuẩn hơn.\n\n**01:24:50 M**ọi người sẽ tự viết một cái `struct` như thế, xong rồi mọi người sẽ nhét một cái mutex vào, tùy người sẽ ngồi bắt đầu viết rồi đú các kiểu. Trong khi đó `sync.Map` rất là handy. `Sync.Map` này như em show anh nãy đó, những cái function của nó, nó luôn follow cái chuẩn này hết. Anh muốn load anh phải gọi hàm này, kiểu vậy nó sẽ chuẩn hơn. Nhưng mà như cái bài này là mình phải để ý những cái trade-off của nó, xài cho đúng quy. Ok, hiểu rồi, tức là quy chuẩn cái cách mà sử dụng `map` hả? Với lại workflow hả?\n\n**01:25:26 C**ảm ơn Phát. Rồi để tranh thủ, mấy cái Thành ơi, nhất là xin anh em thêm 10 phút nữa nhé. Nó sẽ hơi tốn thời gian thêm xíu. Nhất là anh nhận được tổng cộng 11 cái submission cho cái bài test của mình. Có ít bài hình ở trên, mấy anh em nhìn ở trên tí. Deadline của mình là đến ngày 20, tức là tuần sau nhé. Bữa trước anh thông báo như là 27 ha, phải không? 26, 27 gì đó là deadline, mấy anh em coi tranh thủ còn một tuần nhìn bài đó rồi làm ha. Cái bài đó nó sẽ quan trọng, có một số cái mà chi tiết của từng bài đó anh chưa có nhìn kỹ. Chỉ có bài của Tôm bữa trước, Tôm nó quăng nhanh lên trên lobby quá, thành ra là có nhìn sơ qua xíu. Nhưng mà còn của mấy anh em chưa nhìn rồi. Nhưng mà cái ý chính là mọi người xem thử nha, cái chất lượng bài của mình á, tập trung ở chuyện là đợt này khi mà market nó thay đổi nhiều vậy, cái demand của thị trường cho cái nghề làm software nó có sự thay đổi lớn á.\n\n**01:26:15** Tất nhiên những cái nhu cầu nó vẫn sẽ còn ở đó thôi, nhưng mà cái số lượng đó nó giảm xuống. Thành ra đó anh gọi là cái sự thay đổi về cái nhu cầu thị trường gần như với góc nhìn của anh trải qua nó là giống như 2014, nhưng mà on-over-again, vậy là sự thay đổi công nghệ mới ra, mọi thứ mới ra, thị trường mới rồi những cái tiềm năng mới nó sẽ xuất hiện trên đó. cái bài test nó sẽ quan trọng với việc là giúp cho mình, nhất là test về văn hóa, nhìn lại trong cái lúc mà tụi anh muốn check lại cái team á, muốn là hai cái đội: đội làm research study với cả đội làm consulting nó có một cái sự phân hóa rõ ràng.\n\n**01:27:36** Nó có một cái sự phân hóa rõ ràng. Như trong cái bài viết anh post lên notion cách đây khoảng hai tuần hả, sẽ có sự phân hóa rõ ràng. Tương lai nó sẽ có thêm một số những cái policy mới cho chính sách về lợi ích khác nhau giữa hai đội nữa. Nhưng mà hiện nay là, như mình thấy đó, mọi người thấy OGIF dần dần nó được chuyển qua gần như thành cái buổi là report lại tất cả những cái study. Cái phần mà anh em đang coi mới và report lại trên này. Có thể những bài đó do được add, có thể những bài đó là do mọi người bắt đầu anh nhìn thấy, có một vài thành viên trong team mình thật sự là thấy cái kiến thức mới đó, xong rồi pick up những kiến thức mới đó để mà coi.\n\nTừ từ thấy rõ ràng là tụi anh muốn cái sự phân hóa đó nó diễn ra càng ngày càng rõ hơn. Và cũng có chính sách rõ ràng cho cái chuyện đó. Tức là ai mà thích coi mấy cái phần topic nhiều hơn, xong rồi ra ứng dụng ở tới mức là MVP, hay là ứng dụng vô những cái dự án nếu có, hoặc là đi deep dive thêm về kiến thức á, sẽ có một cái benefit khác. Những anh em nào mà không nhất thiết để phải ngồi coi những cái phần liên quan tới phần study như vậy, cứ ngồi làm dự án bình thường thôi. Nhưng mà nó sẽ có một số vấn đề khác đi kèm mà anh cũng có list ra trong cái link notion cách đây hai tuần. mọi người xem nhìn lại cái link đó một tí, để biết là vì cái định hướng như vậy nên là cái bài test này nó mang ý nghĩa là xem thử coi là cái mức độ của mọi người trong chuyện bắt kịp kiến thức mới, hoặc là cái độ tương thích với lại văn hóa trong cái giai đoạn mà tất cả mọi thứ nó thay đổi như vậy tới mức nào ha.\n\n**01:29:20** Để hiểu vì cái mục tiêu là như vậy, nên là cái lúc mà chấm cái bài á, anh sẽ là người duy nhất chấm cái bài đó. Team mấy anh chị khác không có chấm đâu. Tất cả mọi người sẽ phải làm mà, nên là anh nghĩ rằng anh set cái standard cho chuyện đó. Nên là mấy bạn chịu khó làm bài đó tự làm là một chuyện. Thứ hai nữa là bài nào mà chất lượng thấp thật ra cũng không có vấn đề gì hết, chấm điểm thấp một xíu thôi, nhưng mà vừa làm hết vẫn sẽ được đủ điểm để mà coi như là pass cái đó. Chỉ là sau đó cái kết quả trước mắt thể hiện được á, là anh sẽ phân cụm thành hai cụm khác nhau.\n\nĐội Foundation hay là đội Lab á, vẫn là đội core của mình từ năm nay, ha. Đó là cái thông báo chính. Nên là trên 11 cái bài này, nếu bạn nào làm xong rồi mà cảm thấy là mình có thể làm tốt hơn được cho cái chuyện mà anh vừa mới nói đó, đội mình thật ra là cái team Foundation và cái team Lab á vẫn sẽ được ưu tiên nhiều hơn trong những vấn đề khác nhau. Được ha. Nên là nếu mà anh em cái bài đó mà đang kiểu làm qua loa á, tập trung ngồi làm kỹ lại tí. Check hai thứ ha: văn hóa trên đó là một, thứ hai nữa là kiến thức.\n\n**01:29:56** Sau đó cái kết quả trước mắt thể thấy được á, là anh sẽ ân cụm thành hai cụm khác nhau, cái đội Foundation hay là đội Lab á vẫn là sẽ đội core của mình từ từ từ 8-9 năm nay ha. đó là vậy, đó là cái thông báo chính. Nên là trên 11 cái bài này, nếu bạn nào làm xong rồi mà cảm thấy là mình có thể làm tốt hơn được cho cái chuyện là anh vừa mới stay ra, là đội mình thiệt ra là cái team Foundation, cái team Lab á vẫn sẽ được ưu tiên nhiều hơn trong những vấn đề khác nhau. Được ha. Nên là nếu mà anh em cái bài đó mà đang kiểu làm qua loa á, tập trung ngồi làm kỹ lại tí, check hai thứ ha: văn hóa trên đó là một, thứ hai nữa là kiến thức cho cái cụm thông tin cái cụm gần nhất mà nó đang có vẻ hot nhất là LLM thôi.\n\nNhưng thực ra team mình vẫn cover rất là nhiều mảng khác nhau, vẫn đang có xem về design, mấy bạn cũng đang xem đúng không. Vẫn có đội đang xem đúng không. Go vẫn đang xem. Blockchain có vẻ nó qua trend tí rồi, thị trường nó đang sideways thôi, nhưng mà về demand của consulting nó vẫn yêu cầu những cái đó rất là nhiều.\n\n**01:31:46** Mấy cái mini app cho telegram, họ mua về rồi clone nhanh lên, thấy góc nhìn của mấy bạn làm business logic (BL) và tech (TCH) bây giờ nó khác một xíu rồi, không còn như ngày đầu nữa. Nhưng mà với consulting mình vẫn có thể sử dụng thôi, bình thường. Hoặc là mình có thể nhìn theo một góc nhìn khác, theo dạng là nó như một cái asset class mới xuất hiện. Với vai trò là developer, mình phải nhìn nó theo góc nhìn làm sao để nó ảnh hưởng đến cái workflow của mình như thế nào, quản lý tài sản ra sao.\n\n**01:32:29** Đó là vấn đề về bài test nhé. Mấy anh em chú ý cái đó. Thứ hai, nãy có nhắc tới cái định hướng về team và số lượng nhân sự. Trong đó có nhắc lại cái link notion hôm trước anh có gửi nhé. Đội Foundation, đội chính khi start lại lần nữa như vậy. Lúc trước team tụi anh bắt đầu chỉ có ba người thôi, sau đó dần dần tăng lên bốn người, rồi lên năm người. Có thêm Quan, có thêm Hiếu, có thêm mấy bạn khác. Nhưng mà ban đầu start với ba người, giờ đội hình xịn hơn rồi. Bây giờ 40 người toàn là thứ dữ, chắc chắn sẽ đi nhanh hơn. Câu chuyện chung là vậy, đánh giá chung cũng là như thế, nên mấy anh em nắm tình hình nha.\n\n**01:33:12** Cái thứ ba nữa có liên quan là Huy Nguyễn, nếu mà xong rồi, chắc tuần sau xem lại thống kê con số về ICY giùm anh nha. Hôm trước em cũng báo là số lượng bắt đầu chạy hơi nhiều, nên mình phải xem lại, cân lại con số cho nó hợp lý. Riêng phần này nhờ Huy và Thành chủ động làm giùm, xử lý giùm anh, xem lại cân số cho nó hợp lý. Thành có một công việc phụ là phần benefit cho thành viên team Lab, xem thử đề xuất như thế nào. Nó có thể được coi là một cái payon, nhưng mình sẽ không trả qua kênh bình thường, mà sẽ có cái cơ chế khác.\n\n**01:33:52** Nhưng mà mấy thành viên team Lab sẽ có cái đó, mọi người quen với cái đó rồi. Cuối cùng là, riêng phần về LLM hiện tại, trong cái list câu hỏi có một câu hỏi quan trọng là làm sao để sử dụng, tìm hiểu bên ngoài sử dụng LLM như thế nào và adapt ra sao. Nhấn mạnh lại câu đó, vì nó là một câu mang ý nghĩa trong việc làm knowledge discovery. Câu hỏi này liên quan đến việc test là không chỉ đơn thuần là dùng, mà là tất cả các công cụ mà mấy anh em thấy được trong team hiện tại. Khi có người sử dụng hiệu quả, có người sử dụng kém hiệu quả hơn, RT (retrieval technology) nó thành một spectrum rất rõ ràng, những người thấp là thấp, những người cao rất cao.\n\n**01:34:38** Tụi anh muốn nâng cái standard đó lên. Spectrum đó tụi anh muốn rút ngắn lại, càng cô động lại càng tốt. Bây giờ nó đang rất dài. Câu này ngoài việc dùng tool để làm discovery, nó còn mang ý nghĩa xem ngành nghề của mình sẽ như thế nào trong việc ứng dụng đó để nâng cao competency của mình, làm việc có năng suất hơn. Đó là toàn bộ vấn đề, và mọi người xác nhận lại xem cái mình làm có đúng chưa, nó có tầng ý nghĩa sâu xa hơn vậy.\n\n**01:35:20** Cuối cùng để kết thúc buổi này, Thành ơi, mấy buổi OGIF sau, những phần mà Tom đã làm liên quan đến việc xây dựng structure của một cái LLM app, có thể lấy cái đó ra phân tích thử nhé. Phân tích lấy cái đó để làm sâu hơn luôn nhé.\n\n**01:35:56**Toàn bộ mọi người hy vọng là tất cả anh em đều pass hết để đi chơi cho nó vui vẻ. Tuần sau sẽ có một cái bài khác. Tuần sau request là bên chỗ của Minh L. Minh ơi, chắc là lên làm một cái demo nha, tiếp tục về cái finite state machine, FSM á. Vì trong định hướng những công nghệ nền tảng như blockchain, AI, nhưng phần chính vẫn sẽ là các anh em làm engineer sẽ có một ngách khác để đi, đó là hiểu rõ các hệ thống lớn vận hành thế nào. Tương lai, nếu mình không phải là người sinh ra để làm data manipulation AI sẽ làm giùm mình, mình không cần tự thiết kế hay làm mấy việc của junior nữa.\n\n**01:37:35** Cách duy nhất để lên senior là hiểu rõ vấn đề và làm kiến trúc thôi. Phần finite state machine đóng vai trò tương đối quan trọng, liên quan đến chuyện scale mà trước giờ tụi mình đã nói nhiều. Trước đó Minh có đọc và hiểu đúng góc nhìn mà anh đang muốn hướng tới. Nên là xem thử làm bài phân biệt các loại general server của nó nhé. Server state machine và event-based server. Rồi làm một cái sample để biểu diễn và implement nó luôn bằng Erlang nha. Erlang có sẵn hết các framework rồi.\n\n**01:39:01** Bài này chắc là khi nào Minh Lưu. ready, nếu tuần sau không kịp có thể là hai tuần. Đề nghị mấy bạn backend và mấy bạn sen team mình gom lại, có gì confirm trước nhé. Vì bài này rất quan trọng trong chuyện phân tích thiết kế phần mềm. Bài này rất quan trọng. Trước giờ mọi người chỉ nói tới modeling và làm C4 thôi, nhưng Erlang là ngôn ngữ đi sát cái này nhất rồi, thường mọi người sẽ không biết hết. Chúng ta không nhất thiết phải học Erlang nhưng có thể nhìn cách thiết kế và build của họ để làm phần đó rất chuẩn, giống như là họ có framework sẵn, mình chỉ cần gắn vào để sử dụng thôi.\n\n**01:39:37 T**ranh thủ, ngày 20 tháng 10 là chủ nhật, Mỹ với Ngọc và Giang có post rồi. Hôm đó là các chị em đi chơi, còn không ở Sài Gòn đại diện team sẽ chúc mọi người phát tài. Chúc mọi người phát tài chắc hợp lý nhất trong trường hợp này. Một chút chúc khác có vẻ không liên quan lắm. Rồi vậy nha, anh em tham gia được đăng ký với Mỹ để book bàn và đi cho hợp lý.\n\n**01:41:19 N**hờ Thành những buổi sau cấu trúc lại thành mấy cái talk nhé. Rồi làm goal đó, team mình có thêm Builder-club nữa, đội đó chắc để xem mấy anh em lúc trước làm Super Bit ổn định lại hoặc làm console ổn định lại anh sẽ cấu trúc lại sau nhé. Đợt này chắc là nghỉ ngơi đầy đủ rồi. Rồi ok, anh em có câu hỏi gì cho bài test không kết thúc ở đây nhé. Rồi tạm biệt mấy anh em, hẹn gặp lại tuần sau. Cảm ơn Thành, cảm ơn tất cả mọi người.\n\n---\n\n**English Transcript**\n\n**0:28** The topic still includes Go Weekly, and Nam is currently testing the weekly design commentary. Let's see how it goes over the next few weeks.\n\n**11:19** Nam will continue to present to the team, and there are a few topics from Hoang, Cat, and Dat. We’re currently researching various use cases that other companies are applying and some of the tools being used by developers. There will likely be a presentation this week or next about these findings. The focus will be on generating a UX design button. In the past, there have been questions about where AI is applied and how it plays a role, whether it serves as a small, standalone component or as part of a broader application for digital products. Today, I will address how AI contributes and how it functions.\n\n**12:11** First, I will talk about system scope relationships. This diagram illustrates how AI is integrated into systems at different levels, from a small component to a comprehensive ecosystem. AI can be a small part of a component or evolve into a larger function, automating features to improve user experience (UX). Here, AI plays a crucial role in digital products, and when integrated, it can fit into various parts, from components to flows, to features, or even as an entire application. It can be part of a platform or ecosystem.\n\n**12:53** For example, as a feature within an app, AI can help users interact with the app more easily, saving time by automating tasks that would otherwise be done manually. As a standalone application, there are many examples like ChatGPT, which serves a specific purpose, or as a platform like Rewind AI, which offers multiple features supporting AI in different tasks within the same app. These are examples of the scope of AI's current operations.\n\n**13:39** Next, regarding the spatial relationship, this helps us understand how AI features are placed and organized within the user interface (UI). There are several ways to integrate AI into design, and it's important to know how to position them in the app so that they optimize user experience without causing confusion or making the interface too complex. Spatial relationships directly affect user experience. For example, AI can operate independently or alongside other features while still maintaining its own space. When you understand these relationships, you can choose how to place and use AI features in a way that enhances usability without overwhelming the user.\n\n**15:11** There are six different methods for presenting AI: it can be entirely separate, alongside other features, layered, integrated with the parent feature, or in small points such as icons. These methods include:\n\n- Separate: AI operates as a separate feature.\n- Alongside: AI is placed next to other features.\n- Layer: AI overlays with another feature.\n- Integrated Parent: AI serves a major role in navigating and managing core content.\n- Integrated Child: AI operates as a secondary, smaller feature.\n- Point: AI is a small icon or widget that helps the user understand its function.\n\n**16:41** Moving on to the functional relationship, this describes the functional interactions between AI and other features in the system. AI can exist separately but still adapt to the overall content and functionality of the app at a higher level. AI can integrate with existing features to improve performance, replacing manual tasks. Understanding how AI works functionally allows us to define its role clearly in the app and design in a way that ensures the functional actions don’t conflict with one another and don't disrupt the user flow.\n\n**17:28** There are six methods to describe this functional relationship, which are similar to the spatial relationships I mentioned earlier:\n\n1. Separate: AI operates independently.\n2. Aware Of: AI exists separately but is aware of how it affects the main feature.\n3. Acting Up: AI interacts back and forth with other features, adapting data between them.\n4. Feature Incorporate: AI is incorporated as a part of an existing feature.\n5. Usage: AI adapts based on how it's used within the app.\n6. Usage Conventionally: AI communicates directly with other features in a two-way interaction.\n\nI will provide an example of this functional relationship in the code I am about to show, where AI generates a panel on the right side of the screen.\n\n**19:06** For example, the acting-up relationship means AI can be aware of and react to changes made by other features, like data syncing between two systems. In contrast, feature incorporation would mean AI is integrated as part of the overall functionality of a specific feature.\n\n**19:57** That covers the main aspects I’ve discussed so far, with three key elements for integrating AI into product design: optimizing product features, improving user functionality, and enhancing the overall effectiveness of the AI-powered system. It’s important to understand how to apply AI properly to provide clear value to the user. If we understand how to apply AI effectively, it becomes easier to design a system that brings value to the user by integrating AI in a meaningful way.\n\n**20:53** I realized I missed an example earlier, so let me go back and explain. I’ll share a few examples that I think will clarify the functional relationships we discussed. For instance, in Microsoft, there’s a tool that generates images, this operates alongside other features in a parallel fashion. There’s also a feature that sits beside the main functions of the app but doesn’t serve as a core part of the experience.\n\n**22:01** Yes, that's a good example. The functional actions and spatial relationships you presented seem to be similar to common patterns. These are just standard patterns for AI design, how to integrate an AI feature into an app or design an AI-driven app, depending on how it’s categorized.\n\n**22:31** Yes, these are patterns we often use when designing AI applications or integrating AI into a separate application or product. Essentially, they are familiar structures to help us better understand how to apply AI. You can categorize and break them down into smaller features. This part is very clear.\n\n**23:31** Thank you, Nam. Ok, next will be Hoàng and Đạt’s presentation.\n\nToday, I will introduce a topic called \"AI Button in LLM Applications.\" Before diving in, let me briefly cover the content and agenda. First, we will explore design patterns related to the AI Button. These patterns are applied in various applications. I’ll pick out the most common and understandable ones to introduce to everyone.\n\n**24:35** This presentation will revolve around using AI in digital products. These applications leverage the power of AI models to solve specific problems or assist users in tasks. When using LLMs, many may encounter the issue where the model does not provide the expected result. This happens because the model operates based on its ability to respond using the data it has been trained on. There are multiple ways to address this issue. One of the most expensive ways is to retrain the entire model from scratch, which can take a lot of time and resources.\n\n**25:15** We have a technique called **in-context learning**, which means AI can learn directly within the current context while you are using it. This technique includes few-shot learning or zero-shot learning, allowing the AI to learn without needing to be retrained from scratch. For example, you only need to provide the AI with a few small examples in the context, and it will adjust its behavior based on what is provided. Instead of retraining the entire model, this method saves a lot of time and resources while still ensuring the AI can learn from the specific context you give it.\n\n**25:52** In this case, **in-context learning** is widely used in **prompt engineering**. People provide available examples directly into the prompt, and the model learns from those examples to generate subsequent results. That's the main idea of in-context learning. Essentially, the design works like this: you have a query, then you build a prompt with the necessary examples and few-shot learning data, and you pass it through the model, which returns a result based on those examples. However, it doesn’t stop at just examples; many other factors are involved as well.\n\n**26:37** Broadly speaking, in-context learning involves feeding the context into the prompt by providing information that the model doesn’t inherently have. Since this is a pre-trained model, its knowledge is limited, so you provide additional information in the context and prompt for the model to learn during the result generation process. For instance, in medical image diagnosis, the model may not have enough specialized knowledge. Therefore, you provide that expertise into the context and prompt so the model can learn during the result generation process. That’s the core of in-context learning.\n\nNext, we have another important design button, which is **data preprocessing/editing**.\n\n**27:54** This section describes the process of preparing data for the language model (LM). As you know, LMs operate based on vector databases, using vector comparisons to find similar data points. This process often involves handling multimedia data and various types of information. To ensure optimal output, applying data preprocessing steps is crucial. For example, you can preprocess text by filtering out unnecessary details to shorten it, or with images and audio, you can remove noise or compress the data to reduce size before passing it through the language model.\n\n**29:19** Data preprocessing or editing helps the model operate more efficiently. There are many ways to preprocess, depending on the type of data or context. You perform this based on specific requirements. The next design button I want to mention is a commonly used one, though it goes by different names. I call it the **example agent**. This design is commonly seen when you want your query to pass through multiple contexts. For example, if you have a content review application, you can let that content pass through a pipeline where each agent evaluates the content from a different perspective.\n\n**30:11** One agent might evaluate the content from a writer's perspective, and another agent might do so from a different angle. After going through all these agents, there will be a final synthesis layer to combine or process those results, ultimately providing the user with a comprehensive output. This design is often seen in evaluation systems where results from different models are evaluated, and the best outcome is chosen based on predefined conditions.\n\n**30:55** The next design button is called **agentic button**. So, what does agentic mean? In the context of language models (LMs), **agentic LMs** refer to enhancing the model's capabilities. Since the model only knows what’s in its training data, we upgrade it to increase its power and minimize human intervention. This design helps the system become more automated, allowing it to operate with less human interference.\n\n**32:24** This design has several key components that help you achieve this level of automation. There are four main components: **reflection**, **planning**, **execution**, and **multi-collaboration**. Each of these components helps make your system more automated. First, let’s talk about **reflection**. Reflection involves evaluating the initial results of the model based on a specific criterion or metric to determine if the result has been optimized. If it hasn’t, the system adjusts and repeats the process, continuing to generate results until it reaches an optimal outcome.\n\n**33:06** Reflection helps reduce human intervention because, instead of producing an initial result that doesn’t meet your expectations, the system refines itself based on pre-established criteria, eventually delivering a more accurate result without manual adjustment.\n\nThe Reflection button means that it will evaluate the initial output of an AI, then assess it according to a certain standard or metric to see if the result has been optimized. If not, it will adjust slightly and run the AI again to generate another result until the optimal result is achieved. This helps reduce the need for human intervention, as if the first output is not what you expected, you don’t need to manually adjust it, the system will optimize itself.\n\n**33:42** The second button is the tool. Tools can be external, such as external APIs or functions that people code. These tools are used to allow the model to access knowledge from the outside world, real-time knowledge, or external resources that it hasn’t been pre-trained on. For example, OpenAI or Claude both support this. The model can know when to call the tool based on the description you write for the tool. The model will know how to retrieve and extract information from the tool and then return it to the LM to generate an output.\n\n**34:30** Next is planning. The planning button means that you give the LM the ability to plan, preventing the need to prompt multiple times. For example, if you have a complex task, you provide a large prompt for the LM to plan out all the steps it needs to take in a step-by-step manner. This allows it to perform smaller tasks first, which are eventually combined into a larger task. This planning design has many variations, and this is the simplest version: planning and then executing step by step.\n\n**35:10** Finally, multi-collaboration. I presented this about a month ago. Essentially, it's like having the AI excel at a particular task. You have a context, right? You divide it and pass it through to different agents. Each agent is good at its specific task, and after they complete their tasks, it passes on to the next agent. In this way, it can complete the requirement. This design heavily utilizes the divide-and-conquer principle, breaking a large task into smaller tasks and assigning each to a specialized agent. This is a design button I’ve seen being used in many places.\n\n**36:24** Those are the design buttons that I’ve seen used in many places and understand the most. I’ve finished my presentation. Does anyone have any questions?\n\n**37:10** Hoàng, can you repeat the part about planning to confirm Bảo’s comment? It’s like it reads the prompt, right? It understands your prompt first, then breaks it down into smaller tasks, and then there are workers, perhaps IDE workers or smaller prompts, to complete the task. Is that correct?\n\n**37:40** Yes, you can think of it that way. You can split the prompt, for example, in a complex task, into several smaller plans. These smaller plans will be done step by step. For instance, it executes plan 1 first, then plan 2, then plan 3. Once all the plans are completed, they are compiled somewhere or in a final component to produce the final answer.\n\n**38:06** It’s like the Zero you presented last time, right? The worker can do tasks like reading files, deleting files, modifying files, or interacting with the Internet, sending emails, and so on. So basically, agents work in this way.\n\n**38:52** Exactly. Instead of handling a massive task all at once, which requires repeated prompting, you start with a prompt that breaks the task into smaller tasks, and then a pipeline runs through each worker, handling small tasks for you.\n\n**39:23** Ok, pull up slide 14, Hoàng. Slide 14. I also see this is kind of like the Mule Automation setup that Tom created, right? The Mule button that Tom set up. I’ve finished the code, but this design and the button look exactly the same.\n\n**39:46** Yes, this is a looping process with Tom, which looks somewhat similar. It’s like planning, as Tom mentioned, where it breaks down the task into parts and handles each part. It has iterations within it, like a list of steps you described earlier. Referring back to yours, the agents can see that. What I’m seeing looks more like planning: it splits the plan upfront and then works step by step on each plan, moving through each round one by one. This one, though, works more in parallel, where they run simultaneously, produce the output, evaluate it, and then return the final result. I think I got the workflow mixed up; it’s now corrected.\n\n**42:28** Exactly, give it a try. It works like that, breaking down into different tasks. It’s more like a classification, running through each one. This is closer to multi-collaboration because it’s like a question classifier, where only one agent runs for each task. Each agent works on its specific expertise, then combines everything.\n\n**43:33** But do you think the parts like reasoning and input analysis are correct? Tom’s expert part. Specifically, for picking domains, there’s a classifier, but reasoning and input analyzers are separate agents. In that group, they’re experts, right? We consider them a group of experts, and they combine with the five agents underneath.\n\n**45:33** If we try to do everything within a single prompt, I’m certain it won’t give us the desired result. The context is too large and lacks specific examples. The main issue is that accuracy will definitely decrease because there’s too much data at once. The key is to split it into multiple layers, step by step. In reality, we need the output from the LM; we can’t hardcode it all in advance. We just want the simplest prompt so it can generate small answers that ultimately lead to a large answer.\n\n**46:59** Exactly, by breaking it down, we can identify where the problem lies and debug it. Like you mentioned, specify clearly and break it down into layers. If something goes wrong, we can fix that part. If you throw everything in at once, you won’t know where the error is, and you’ll have to fix it repeatedly.\n\n**48:43** Exactly. For example, creating an event in the calendar for tomorrow, if there’s no event at that time, it creates the event, but if there is already one, it sends a notification. If we throw in a large request at once, it will get confusing because it has to execute step by step. Breaking it into layers and testing each step will make it work better.\n\n**49:23** I'm almost certain that 99% of the time, it will get lost if it’s done in one go. However, if we split it into layers, into multiple layers, and do the tests, it will work much better. Ok, let's go. If anyone's at the office, Tom’s probably there to argue with. If no one has any more questions, thanks to Hoàng first. Now, Đạt, you’re up. Đạt, are you sharing your screen? Ok, can everyone see my screen? Yes, we can.\n\n**50:38** Today, I’m going to talk about Yelp use cases. Wait a second, Đạt, let me introduce some context first. So this time, the team will focus somewhere and search for some use cases. There are different types of use cases. The type Đạt is sharing is where we look at how startups or enterprises are applying AI to solve specific problems. It could be something completely new, like a greenfield, or it could be optimizing the current workflow of their system. They will write use cases and report updates monthly. In addition, there’s another type of use case, which involves tuning to boost the development on the tech side. They will also report that part somewhere in tech. We’re testing this for about two weeks. This is the first report, and it’s about Yelp. Yelp is a startup, right? Now, Đạt, introduce how they are applying AI.\n\n**52:01** Yelp is a company that provides software to stores and businesses that want to offer services like fast delivery, restaurants, or basic utilities. Yelp sells the software for those tasks. I’ll share a bit about how they use AI in their tools.\n\n**53:00** Before this, they had a machine learning system, but now they’ve added AI to improve the accuracy of their recommendations. Yelp has many types of reviews on its system, like restaurant reviews, which may not always be good. Based on those reviews, they do some text editing to compare whether the results are spam or legitimate. AI is used here in several ways. First, they use AI to create datasets to train a model to assess whether a review is spam or a good/bad review. They use AI to generate datasets based on LinkedIn. From what I’ve read, they use techniques like Zero-shot and Few-shot learning to create these datasets. They use some models from Hugging Face and then classify the reviews as good or bad. This is one use case where AI is applied in text editing.\n\n**54:18** Now onto the second use case, they use the Clip Model. The Clip Model primarily processes images. What does that mean? It means that based on reviews... wait a minute, let me find the reference... Ah, Clip processes two things: one is the caption of the image, and the other is the image itself. Through Clip, it can understand the context of the image. Yelp uses Clip for tasks such as when someone goes into a restaurant or pub and posts reviews or captures images of the place. For example, before applying Clip, it couldn’t identify if there were waffles in a dish; it could only identify fried chicken. After applying Clip, it can now recognize both fried chicken and waffles. Essentially, it uses Clip as part of AI to process images, captions, and convert images into vectors to compare them. So, these are the two use cases for Yelp.\n\n**55:38** These two use cases are applied in situations where you have many reviews, and you can summarize them into a highlight review. Based on the information converted into vectors, it can annotate what the images are conveying, and what they are supporting. Just give it a moment, it will highlight it for you. It understands the context of the image and can annotate it accordingly. This is the use case for how AI is used in image summarization.\n\n**56:15** Earlier this year, Yelp released the Yelp Assistant. Based on their existing platform, they were able to create a chatbot that reviews highlights like this. You simply ask, and it recommends something for you. It's as simple as that. Additionally, I noticed a use case from 2020 when the trend of short review clips started becoming popular. Yelp had a dataset specifically for that purpose. They mentioned that they are about to release something, as Tom referred to, that can convert text to speech. Based on the review dataset, they might support creating short video clips to describe a restaurant.\n\n**57:45** Based on reviews or videos posted by people, Yelp could generate a script and run it through AI to automatically create a video about a restaurant. That’s the use case. It’s simple as that. Ok, going back to the first question, this use case is essentially using AI to label data, right?\n\n**58:35** Ok, so it checks whether the comment is negative or positive, right? That’s one example. The second one is using the Clip Model, correct? It’s similar to Vision but more live, also for labeling, right? Like with Plot, labeling for images. So, these two use cases are applied for what?\n\n**59:18** I think there's an interesting point that hasn't been mentioned yet, which is the story about having a ready-made dataset. For instance, when someone leaves a review or gives a rating, based on these short clips, Yelp could generate an intro video for the restaurant. It uses AI for that. I think they use AI to write the script and then pass that script to an AI voice to narrate. But where do they get the images from? How do they get the video content?\n\n**59:57** From the review, when someone comes to review, they will have a video to review. Ok, so it's automatically generating an advertisement, right? Yes, for TikTok or similar platforms, summarizing user reviews. Sounds pretty creative. Yeah, I guess you guys have confirmed what Bảo mentioned, right?\n\n**01:00:07** Yeah, this one is about the caption, and it's mostly correct. You're right, I think the initial purpose of this use case was for recommendation. Before they had AI, they already had a hybrid recommendation model in place. Basically... I think with this new AI, they will likely replace the old model. One interesting point that wasn't mentioned much is business messaging. I think it’s based on, say, the top 50 reviews or top 50 interactions, how are the ratings, and if the reviews are good and the ratings are good, then the business messaging will also be good. But Yelp didn’t bring up this topic, and we can’t blame them for that.\n\n**01:00:51** Does anyone have any questions for Đạt? This is his first presentation. Đạt mentioned he’s working on adding more, probably for enterprise too. But I’ve seen Viettel, FPT, and VNG, and I’m still not sure how they are doing things. Đạt said some of FPT's coding tools are kind of lame.\n\n**01:01:41** Haha, is it just a continuation of a previous version? Yeah, it’s not great. It’s a bit rough and underdeveloped. Are we done with that? I guess so. Ok, Đạt. Today we’ve covered Yelp and Tech Linh, so maybe next week or the week after that, if time permits.\n\n**01:02:01** Let's do a demo real quick, Đạt. Could you demo something for us? What about a bot that can handle questions or understand short code from a developer’s perspective? Or something like an auditor checking the code quality? Could you demo the workflow or the bot you’re working on with that diff you mentioned? Please turn on the screen, Đạt.\n\n**01:03:01** So this is a project I’m working on for joining the AI Club. I’m pretty new at this, so if the project looks rough, please bear with me. The basic workflow is that I take a query and extract the URL of a repository. Here, I reused Tom’s scraper, but it didn’t fully meet my needs, so I created my own local scraper to fetch all the content from the repo. However, that takes too long and generates too much data. As of now, I haven't found a way to add it to the context unless I use knowledge retrieval. But to use knowledge retrieval, I have to prepare it in advance; I can’t select the repo directly.\n\n**01:05:45** Tom’s scraper doesn’t capture the content of the files, so I haven’t been able to draw a diagram yet. I might use it for the diagram later, I’ll test it out. This scraper only fetches the content from the root directory and some doc files. Those files might not answer Huy’s question accurately. Let me try it; I have my full setup ready offline. The content is already prepared, not online. This was generated directly, so it doesn’t have it either.\n\n**01:07:07** This scraper fetches the full content, so it’s more complete. Let me try asking questions like Huy’s or Hoàng’s. Let’s try BC chat and ask a question there. Do you have it? Ah no. Maybe the context is too large, and I haven’t figured out how to integrate it properly into the knowledge retrieval part.\n\n**01:09:19** The retrieval process is very optimized. This text file has tens of thousands of lines, tens of thousands! Let’s open it and see. Are you using a mini machine? Try switching to a more powerful machine to see if it runs better. The mini machine is a bit weak. Two million words... how is it even handling that? I think you’d need a dedicated server to run it efficiently. I’m curious how it's even running; we’re talking about 29U words, as we saw. Multiply that by 4, and the number is huge. The size... Let's follow up and see. Ok, so you’re working directly from the context, right? You’re querying like a typical query vb, rather than feeding all the data into the context.\n\n**01:10:57** Right, exactly. I’m not sure how the retrieval in this diffy system works. I don’t know if it’s retrieving the correct data or if it’s retrieving at all. I haven’t been able to trace it, but I have a tracing tool that I can test later to see how it works. But the idea is that if the retrieval works like this, it probably won’t give accurate results. You’re unsure about how much data it's running, right? It seems to only prefer 2-300 items, and that’s not enough data for these kinds of tasks. This requires at least several hundred data points. So yeah, this is still a work in progress.\n\n**01:11:35** Just joking, there’s always the AI Club at the company! Oh, so is this the full version, or is it the fixed one? If it’s fixed, demo it for us in the office, and try to leave it for me. OK, let me see. It still hasn’t built, so people are just watching for now. The build seems to have some issues, can everyone see the screen?\n\n**01:13:08** So, this week, as I mentioned last week, I will upload the sync.Map article. I think it's really useful, with details that give people using Go a general overview of maps. Regarding sync.Map, let's first go over the context. When writing maps, especially concurrent maps or concurrent operations, before version 1.16, it wouldn’t show any errors, but it wasn’t safe either. From version 1.16 onward, it throws an error like this. So to solve this issue, people usually write maps with a sync package, like using manual sync.RWMutex.\n\n**01:13:56** Besides that, there’s another option called sync.Map. Later, I’ll explain why this option exists and what its use case is. This sync.Map was created so that you don’t have to worry much about using mutexes to lock data for synchronization. You just use it. It’s as simple as this, and it’s friendly, just like using a map to check values. For example, when you load a key with a value, if it's available, it returns true; otherwise, it returns false, just like a regular map.\n\n**01:14:38** Additionally, it has several handy functions. For example, version 12.23 has `clear` to clear everything, `load` to get a value, `store` to update or store a key, and so on. Besides writing concurrently, when you range (loop) over a map, race conditions can also occur. However, with sync.Map’s range function, it handles that, so you don’t have to worry about it. It doesn’t behave like a typical range function. However, it doesn’t give you a fully consistent snapshot. When you first enter, the snapshot may not be updated. So, during this, you have to change your writing method, but at least it won’t error like this.\n\n**01:16:06** Now, let’s go over how it works. When you write and define the map, it’s structured with two maps. At this point, you might be thinking, “Wow, this sounds like it’s heavy on RAM and memory!” There’s a Read-Only map and a Dirty map. From this, you can infer that values, when written, will be updated in the Dirty map. It just keeps updating there, while the Read-Only map.\n\n**01:16:46** The Read-Only map will always be used when you're reading. Meanwhile, the writes will always be made to the Dirty map. As for the underlying flow, we’ll look at the chart in a moment to better understand it. Both of these maps have a common point: they both use a pointer called an entry. Pay attention to this part to make the flow easier to follow. For example, when you add a new entry, it will be added to the Dirty map, and both will point to this entry. This works as a flag that indicates the map has been changed. So, at this point, the Read-Only map is no longer the most up-to-date version. The system will know that the Dirty map is the one to read from.\n\n**01:17:27** This diagram shows that, for example, when you update a value, since it’s using a pointer underneath, you only need to update the pointer itself, not each value as you would in a traditional map. To achieve this, the system implements a mechanism that defines three states for the entry pointer. The first state is the **normal state**, meaning that the old values in the map are still intact and can be used, without any issues. The second state is **amended**, meaning that the entry has been modified. And the third state is the **delete state**, where an entry has been deleted from the map, but it hasn’t been completely removed. It’s still held in a transitional state, and the entry pointer is moved to a new position, but it hasn’t been fully removed yet.\n\n**01:18:59** The pointer `entry` is assigned to the `new entry`, but it hasn’t been removed yet. The `expired state` refers to complete deletion, like a hard delete, meaning the entry is completely removed from the map. To help visualize this, you can refer to this flow: for example, at the beginning, the map has a `key1` and `value1`, and at this point, the `Dirty map` has nothing, meaning nothing has been added or changed yet. Then, if you add a `key2`, it will be added to the `Dirty map`, and at this point, the map is marked as `amended` because a `flag` indicating `amended` is set here.\n\n**01:19:40** Afterward, when you delete a `key`, the map will be assigned a `new entry`, right? The same thing happens on the other side, as it is also assigned a `new entry`, similar to the previous diagram. In essence, you’re only updating the pointer without having to update the values themselves. Then, after completing the deletion, to promote the `Dirty map`, you must update it through the `Read Only map` so that the `Dirty map` returns to a `new state`, like resetting it to the original state.\n\n**01:20:18** Similarly, when adding a new `key3`, after the state has returned to the `new state`, and you add `key3`, the system identifies that the previous entry has been deleted entirely. This means that next time when it compares with the `Dirty map`, it knows that the `value1` has been deleted and no longer exists. At this point, the `Read Only map` will only contain `key2` and `key3`.\n\n**01:20:51** Due to this, `sync.Map` does not have a `len` function for users to utilize. This is because, if you used the `len` function here, it would not account for the actual values, as it would count even those that have been expired or deleted. As you can see, because `sync.Map` is structured this way, its use case is recommended for scenarios that require more reading (`read`) than writing (`write`). If you perform a lot of `write` or `delete` operations, just imagine the pointer being used continuously, and there’s even an issue reported by the Go team that this map is never garbage collected.\n\n**01:21:36** Later, the Go team confirmed that this `sync.Map` was designed primarily to support some of the internal Go Library processes. If you find it handy because of its user-friendly functions, you can use it, but for use cases that involve storing (`store`), updating, or deleting often, it’s not recommended, as it may slow down the system.\n\n**01:22:24** That’s about it. I’ve written some code based on this topic, and there’s a blogger who shares detailed posts on this subject, so you might want to follow them. Oh, what’s the topic, Phát? Show me the post again. Ah, `sync.Map`, right? `Sync.Map`. Does it differ from what you just passed in? What’s different? I think it does. The point is that I remember, depending on the community, people might have different use cases. For instance, if someone wants to implement something specific, they can adapt it as needed.\n\n**01:23:30** You can see that some people add an extra layer on top for their own use cases. For example, some want to implement generics on `sync.Map`. This is partly because of the linking issue I mentioned earlier, where the map isn’t garbage collected. That’s the problem. The Go team has already confirmed that this behavior is intentional, and they won’t fix it. They’re not going to change it, right? So now, what the community does is figure out how to work around it. They like how easy `sync.Map` is to use, with those nice functions, so they just add another layer to customize it further, making it usable for their specific needs.\n\n**01:24:07** Why are we discussing this old clip now? Oh, it’s just an insight for people to use. This use case can be applied to enterprise environments too. For example, in enterprise projects, if we use `map` and need concurrency, typically, people would write a custom `struct`, add a `mutex`, and then write everything themselves. But `sync.Map` is handy, as I showed earlier, with functions that follow certain standards. If you want to `load`, you have to call a specific function, and everything is structured that way, making it more reliable.\n\n**01:24:50** People usually write a custom `struct`, then add a `mutex`, and start writing all the necessary logic themselves. Meanwhile, `sync.Map` is really handy. As I showed you earlier, it has several functions that adhere to a specific standard. If you want to `load`, you must call a specific function. This structure ensures consistency. However, you still need to be aware of the trade-offs when using `sync.Map`, making sure to apply it correctly in the right context. Right, so you have to understand the proper workflow and `map` usage.\n\n**01:25:26** Phát: Yes, about `Map`. Ok, thanks, Phát. Now, let’s quickly get through a few things. Thành, I need about 10 more minutes from the team. It’ll take a bit more time because I’ve received a total of 11 submissions for the test. Not many have attached images, so some of you can review them. Our deadline is set for the 20th, which is next week. I think earlier, I mentioned the 27th, or was it 26th or 27th? Anyway, that's the deadline. So, please review everything this week and get the submissions ready. This test is important because the market is shifting significantly, and there’s a big change in the demand for software roles.\n\n**01:26:15** Of course, the demand is still there, but the volume has decreased. That's why I refer to it as a shift in the market demand, similar to what happened around 2014, where it’s like things are changing all over again. New technology is coming out, new opportunities, new markets, and emerging potentials. So, this test will be essential in helping us assess, especially when it comes to team culture. We’re taking this opportunity to evaluate the team, particularly to see how the research study team and the consulting team are becoming more distinct.\n\n**01:27:36** There’s a clear distinction between the two teams now. Like I mentioned in the post on Notion about two weeks ago, this distinction is becoming more pronounced. In the future, there will be more specific policies related to different benefits between these two teams. But for now, as you can see, OGIF is gradually becoming a session where we report on all the studies that the team has been reviewing and reporting back on. Some of those reports might be added later, and you can see that some team members have been picking up new knowledge and sharing it.\n\n**01:27:36** Gradually, it's becoming clearer that we want this differentiation to become more distinct over time. And there will be clear policies around this. So, those who enjoy diving deep into topics and taking them to the level of MVP, or applying them in actual projects, or going deeper into knowledge, they will get different benefits. Those who don't necessarily want to focus on study-related topics can continue working on projects as usual, but there will be other issues involved, which I've listed in the Notion link from two weeks ago. Everyone should review that link to understand the direction we're going in. This test is designed to assess how well you can keep up with new knowledge and how aligned you are with the culture during this time of significant changes.\n\n**01:29:20** Because of these goals, I’ll be the only one grading this test. None of the other team members will be grading. Everyone has to do it, and I’ve set the standard for this. So, the important thing is that everyone does the test themselves. Even if the quality isn’t the best, it’s fine. I’ll just give it a lower score, but as long as it’s completed, you’ll pass. The immediate outcome I see from this is that I’ll group the results into two clusters.\n\nThe Foundation team and the Lab team, they’re still the core teams we’ve had for the past eight or nine years. This is the main announcement. If you’ve finished your test and feel like you can improve based on what I’ve just said, the Foundation team and the Lab team will still be prioritized in various aspects. So, if you feel like you did the test carelessly, please take some time to do it thoroughly. Focus on two things: the culture aspect and the knowledge.\n\n**01:29:56** The immediate result you’ll see is that I’ll group the results into two clusters. The Foundation team and the Lab team will remain the core of our team from now until the next eight or nine years. That’s the main announcement. Out of these 11 submissions, if anyone feels they can improve after hearing what I’ve said, please focus on making it better, especially since the Foundation and Lab teams will be prioritized more in different areas. So, if you feel like you’ve done it hastily, take the time to refine it. Check two things: the culture aspect and the latest, hottest topic cluster, which right now is LLM.\n\nBut in reality, our team still covers many different areas. We still have people focusing on design, and others still working on Go, right? Blockchain might have moved a bit out of the spotlight, and the market is going sideways, but consulting still demands a lot of expertise in those areas.\n\n**01:31:46** Regarding mini apps for Telegram, they quickly clone them, and now the business logic (BL) and tech (TCH) approaches have shifted a bit from the early days. But for consulting, we can still use them as usual, or we can view them from a different angle, where they become a new asset class. As developers, we should look at how these affect our workflow and how we manage assets.\n\n**01:32:29** That’s the matter concerning the test. Pay attention to that. Second, as mentioned earlier, regarding team direction and numbers, I mentioned the Notion link I sent earlier. The Foundation team, which started over again, initially had just three people, and then gradually it grew to four, then five. We added Quan, Hiếu, and others. Initially, it was just three of us, but now the team is much stronger. With 40 people, all highly skilled, we’ll certainly move faster. That’s the general overview, so everyone should be aware of the current situation.\n\n**01:33:12** Third, Huy Nguyễn, once you’re done, next week please take a look at the ICY numbers. Earlier, you mentioned the numbers were starting to grow, so we’ll need to review and balance those out. For this task, Huy and Thành, please take charge and ensure it’s handled properly. Thành also has an additional task, which is to review benefits for the Lab team members and propose something. It could be considered as a payon, but it won’t go through the normal channels, as there will be a different mechanism for this.\n\n**01:33:52** But the Lab team members will have that, and everyone’s familiar with it. Lastly, regarding the LLM, in the current question list, there’s an important question about how to use LLM externally and how to adapt it. Emphasize that question, as it’s about knowledge discovery. The test question is not only about using it but about all the tools our team currently uses. When some people use them effectively and others less so, it creates a very clear spectrum, those who are weaker remain weaker, and those who are stronger stand out much more.\n\n**01:34:38** We want to raise the standard. We want to shorten that spectrum, to make it as compact as possible. Right now, the gap is too wide. Beyond using tools for discovery, this question also asks us to look at how our field of work can apply these tools to elevate our competencies and make us more productive. That’s the whole issue, so everyone should confirm whether what they’ve done is correct or not. It has a deeper meaning than it seems.\n\n**01:35:20** Lastly, to wrap up today’s session, Thành, for the next OGIF meetings, apart from diving deeper into use cases, there are things Tom has done related to building the structure of an LLM app. We could take that and analyze it. Let’s break it down and dive deeper into it.\n\n**01:35:56** Hopefully, everyone passes the test so we can all have a good time. Next week, there will be another test. Next week, Minh L., can you do a demo? Continue with the finite state machine, FSM. As part of our focus on foundational technologies like blockchain and AI, the key point is that engineers will have a different path forward. The goal is to understand how large systems operate. In the future, if you’re not the one handling data manipulation, AI will do that for us, we won’t need to design things ourselves or do junior-level tasks anymore.\n\n**01:37:35** The only way to become senior is to understand the issues and work on architecture. The finite state machine plays an important role, especially in scaling, something we’ve talked about a lot. Minh has read through it and understood the direction we’re aiming for. So, we need to do a comparison between the types of general servers it covers. State machine-based servers versus event-based servers. Then create a sample to show how it’s modeled, implemented using Erlang. Erlang already has the frameworks for it.\n\n**01:39:01** This topic will proceed when Minh Lưu is ready. If it’s not next week, it could be in two weeks. I suggest that the backend team and the senior team gather together, and if there’s anything, confirm it beforehand. This topic is critical for software analysis and design. It’s a very important session. Up until now, we’ve only talked about modeling and doing C4 diagrams, but Erlang is the language that goes deepest into this area. Most people don’t know it entirely. We don’t necessarily need to learn Erlang, but we can look at how they design and build systems to handle this area properly, as they already have frameworks available. We just need to plug them in and use them.\n\n**01:39:37** Speaking of which, October 20th is a Sunday, and Mỹ, Ngọc, and Giang have already posted about it. The ladies are going out on that day, and for those not in Saigon, the team representatives will wish everyone prosperity. It seems like wishing prosperity is the most appropriate thing to say in this situation. Any other wishes might not fit as well. Alright, so if anyone wants to join, register with Mỹ to book a table and plan accordingly.\n\n**01:41:19** Thành, in the upcoming meetings, structure things into talks. Then set the goal for that. Our team now has a Builder Club as well. I’ll look into how the team members who used to work on Super Bit and console are stabilizing things, and I’ll restructure afterward. This time, it seems like we’ve had a good rest. Alright, does anyone have any questions about the test? If not, we’ll wrap up here. Alright, goodbye everyone, see you next week. Thanks, Thành, and thanks to everyone.\n\n---\n","title":"OGIF Office Hours #28 - Golang sync.Map, Generative AI UX design patterns, Yelp's AI use cases, Design patterns in LLM application, and Dify github analyzer","short_title":"#28 Go sync.Map, AI UX, Yelp AI, LLM Patterns, Git Analysis","description":"OGIF Office Hours #28 covered Go Weekly #16 by Phat on sync.Map concurrency, Nam's Product Commentary #4 on Generative AI UX design patterns, Dat Nguyen's presentation on Yelp's AI use cases including recommendation systems, Hoang's discussion on LLM application design patterns, and Cat's demonstration of a Dify-based Git repository analysis tool.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Mon Oct 21 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/28-20241018.md","slugArray":["updates","ogif","28-20241018"]},{"content":"\n### Topic highlights\n\n1. Nam's presentation on \"UX Guide to Prompt with AI\"\n   - Overview of current AI-human interaction trends\n   - Introduction to the \"Race\" (Role, Action, Context, Expectation) concept in AI prompting\n   - Discussion of new methods to improve AI UX:\n     - Context Through Rephrasing\n     - Implicit Referencing\n     - Continue Conversation\n     - Racing and AI Scoring\n     - System Prompting\n   - Focus on designing AI tools for better user experience beyond speed and accuracy\n\n2. Minh's presentation on computing the union of two finite automata\n   - Applications of finite state machines in programming\n   - Use of automata in input validation (e.g., regex for email, phone number checks)\n   - Application in event-driven systems and event buttons\n   - Demonstration using Go source code\n\n3. Phat's presentation on Go Weekly commentary\n   - Overview of recent developments in the Go programming language\n   - Discussion of notable changes and updates\n   - Insights into the Go community and ecosystem\n\n4. Lap's presentation on Frontend Report for September\n   - Overview of recent trends and developments in frontend technologies\n   - Discussion of notable frameworks, libraries, and tools\n   - Insights into the frontend community and ecosystem\n\n---\n\n**Vietnamese Transcript**\n\n**08:02** Có thông tin gì cần phổ biến không? Không thì chắc để phát lên trước, nay thấy nhiều bài quá, để ưu tiên cho mấy bạn mới. Ok, nay có tới năm bài.\n\n**09:13**  Xin mời anh em.  Anh em nào có topic thì lên sớm nhờ. Dạ, pha start trước rồi, chưa đến phần Thành, mời Nam.  Dạ, bài của em là \"User Experience AI.\" Cái bài này chị team làm đi, rồi Thành bạn đã chuẩn bị chưa? Hôm nay, Nam sẽ chia sẻ về đề tài có tên là \"UX Guide to  Prompt with AI.\"\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hq_u9GQdNMg?si=FdFGv418n1MC5Apq\u0026amp;start=608\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**10:20**\nThì em nói overview trước về tình hình hiện tại. Giao tiếp giữa con người và AI là chủ đề rất phổ biến hiện nay, và sự xuất hiện của LLM (Large Language Models) là công cụ hữu ích mà team mình đang muốn tìm hiểu. Bài hôm nay em sẽ dành cho ai quan tâm đến User Experience (UX) của AI, cụ thể hơn là cách các tool hiện đang thiết kế cho sự tương tác giữa người dùng và AI tốt hơn. Hiện nay có khá nhiều tool và platform ra đời, nhưng họ thường tập trung vào việc cải thiện tốc độ prompt và độ chính xác, thay vì chú trọng đến trải nghiệm người dùng.\n\n**11:08** Cái khái niệm \"Race\" (Role, Action, Context, Expectation) rất phổ biến trong việc prompt AI. Người dùng cần prompt theo cấu trúc này để AI có thể tạo ra output chính xác nhất. Tuy nhiên, không phải trường hợp nào cũng áp dụng được \"Race.\" Có nhiều công ty đã phát triển những phương pháp mới để cải thiện UX của AI, giúp tương tác giữa người dùng và AI mượt mà hơn.\n\n**12:04** Phương pháp đầu tiên là \"Context Through Rephrasing.\" Phương pháp này giúp AI truy vấn lại ngữ cảnh của câu hỏi trước, để trả lời câu hỏi tiếp theo một cách liên mạch, không cần từ đầu phải có cấu trúc prom chuẩn chỉnh. Ví dụ: Câu hỏi đầu tiên là “Who is the wife of Superman?” Tiếp theo, câu hỏi “When did they get married?” AI sẽ hiểu ngữ cảnh và liên kết đúng. Nhưng nếu không có ngữ cảnh phù hợp, như câu “What day did Titanic sink?”, AI sẽ không thể đưa ra kết quả đúng.\n\n**12:50** Tiếp theo là \"Implicit Referencing,\" ví dụ khi hỏi về số tầng của một building, AI sẽ tự động assume đó là một tòa nhà nổi tiếng như \"Willis Tower in Chicago.\" Nếu hỏi “What day?” mà không có ngữ cảnh liên quan, AI không thể trả lời chính xác. Các câu hỏi cần có sự liên kết chặt chẽ với nhau để AI có thể trả lời tốt hơn, và điều này cũng áp dụng cho \"Context Through Rephrasing.\"\n\n**14:19** Một khái niệm tương tự là \"Continue Conversation,\" như trong Google Assistant. Các câu hỏi được nối tiếp một cách tự nhiên, và mỗi câu hỏi mới sẽ liên quan đến những câu hỏi trước đó để tạo ra một chuỗi hội thoại liên tục.\n\n**15:03** Phương pháp tiếp theo là \"Racing and AI Scoring.\" Google Assistant cũng áp dụng phương pháp này. Nó cung cấp nhiều tùy chọn dựa trên các ngữ cảnh khác nhau, giúp người dùng có kết quả tốt hơn. AI cũng có thể tự động học từ những lựa chọn của người dùng để cải thiện khả năng tương tác. Ví dụ, khi AI không rõ ngữ cảnh, nó sẽ đưa ra các tùy chọn cho người dùng chọn.\n\n**16:03** Cuối cùng là \"System Prompting.\" Lý thuyết này định hướng cho AI hoạt động theo ngữ cảnh và mục tiêu người dùng đặt ra. Nó giúp AI tạo ra output chính xác mà không cần tuân theo một chuẩn prompt cố định. Ví dụ, cùng một câu hỏi “Plan for releasing a software product,” Chat GPT có thể đưa ra các khái niệm chung chung, trong khi GPT mini sẽ đưa ra các câu hỏi chi tiết hơn để giúp người dùng prompt tiếp và đạt kết quả chính xác hơn.\n\n**17:45** Bài hôm nay sẽ tập trung vào việc thiết kế tool AI sao cho user experience tốt hơn, không chỉ dựa vào tốc độ hay độ chính xác, mà còn chú trọng đến sự tương tác và trải nghiệm tổng thể của người dùng.\n\n**18:50** Tóm tắt lại bài này cho các bạn, đặc biệt là các bạn designer, bài của Nam có hai khía cạnh chính. Thứ nhất, nó giải thích cấu trúc của \"Race\" và cách áp dụng nó. Thứ hai, nó đưa ra một framework thiết kế tool AI tập trung vào việc prompt sao cho tương tác giữa AI và người dùng tốt hơn. Cấu trúc \"Race\" này gồm Role, Action, Context, và Expectation, và nó giúp cải thiện UX của AI.\n\n**19:20** Giải thích cái cấu trúc sơ qua của chuyện là cái Race nó như thế nào, có những thể loại Race như thế nào là những phần nãy giờ Nam nói. Cái thứ hai đó là cái layer về chuyện xây dựng (build) một ứng dụng tập trung vào chuyện prompting, thì cấu trúc đó gắn vào ra làm sao. Khi viết một cái Race, bạn sẽ phải nói rõ Role, Action, Context, và Expectation.\n\n**20:03** Race được mô tả rất rõ ràng: Role là gì, Action là gì, mọi thứ được mô tả theo cái Expect là gì, Task là gì. Tóm lại, chữ R thì cơ bản nhất là các designer sẽ nhìn và hiểu cấu trúc của một câu Race. Nó sẽ có cấu trúc nhất định, dựa trên đó mà đưa ra kết quả tiêu chuẩn. Input là như vậy, và output sẽ nhận được kết quả tương ứng.\n\n**20:47** Phần thứ hai, phần cuối của bài này, sẽ nói về chuyện khi mình đã hiểu cấu trúc của một cái prompt rồi, và hiểu luôn cách để prompt sao cho chuẩn xác. Khi thiết kế, cần phải chú ý những gì? Phần này sẽ là phần mở vì bài này giống như là bài 101 cho các bạn designer để nhìn qua và hiểu cơ bản.\n\n**21:30** Nam đã nói khá nhiều về cái chữ R, nên đôi lúc có thể mọi người sẽ hiểu lầm là bài này đang giải thích chi tiết lại cái đó. Nhưng thực ra bài này là giới thiệu về prompting cho UX designer. Ok, câu hỏi sẽ là, có ai có thắc mắc gì không? Bài này khá cơ bản, team mình xài nhiều rồi, demo cũng nhiều rồi. Có một phần cần lưu ý, bài này đặc biệt hơn ở chỗ giới thiệu về system prompting, mà các bài khác không có.\n\n**22:31** Bài này giới thiệu cái system prompting mà các bài hướng dẫn khác thường không nhắc tới. Các bài viết cho người dùng cuối (end user) thường không đề cập đến điều này nhiều. Bài này nhắc tới system prompting vì nó viết dưới góc nhìn của designer – một người trong đội build. System prompting sẽ khác so với prompting thông thường, vì nó điều khiển cách AI hoạt động theo mục tiêu cụ thể của hệ thống.\n\n**23:06** Cấu trúc của system prompting khác so với các loại R thông thường mà mọi người thường thấy khi đọc research. Thường thì các bạn chỉ thấy nói về 200 kiểu R khác nhau, nhưng không có góc độ là viết cho người build app. Bài này dành cho designer, không phải là end user, mà là người đứng giữa, để kết nối các phần lại với nhau.\n\n**23:48** Bài này khác với những bài viết dành cho engineer vì nó không chỉ giới thiệu về tooling để xây dựng prompts, mà còn nói về việc kết hợp các kiểu R lại với nhau. Đây là bài ở mức độ trung gian, phù hợp cho các bạn làm designer, có vai trò đứng giữa, không trực tiếp build nhưng cũng không phải người dùng cuối. Nó giúp kết nối hai phần này với nhau.\n\n**24:33** Ok, cảm ơn Nam. Tuần sau chắc sẽ scope lại bài theo content cho mọi người dễ hiểu hơn. Còn đi sâu vào chi tiết thì sẽ hơi khó để mọi người nắm bắt hết nội dung. Cảm ơn em nhé. Mời bạn tiếp theo. Để xem thử, không xem màn hình được, à vào lại rồi.\n\n**25:41** Bài của em hôm nay là về một vấn đề nhỏ trong kỹ thuật lập trình, đó là cách compute một tổ hợp (Union) của hai cái finite automata hay còn gọi là finite state machine. Em sẽ demo nó trên một cái source code Go. Chủ đề này hôm nay sẽ có một số mục chính. Trước tiên sẽ giải thích các ứng dụng của automata để mọi người dễ hình dung trước, rồi sẽ đi vào chi tiết.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hq_u9GQdNMg?si=nEFRO7pOhdBxjouy\u0026amp;start=1617\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**26:41** Ứng dụng mà của finite state machine mà mọi người thường thấy nhất là nó sẽ dùng trong việc có một cái button và một cái input, thì mình sẽ muốn kiểm tra xem input này đưa vào cái button đó nó sẽ match hay là nó fail. Nó đơn giản chỉ là như vậy thôi. Cái dễ thấy nhất thường sẽ là dùng regex để kiểm tra xem một đoạn text có phải là một email hoặc là số điện thoại, hoặc là số nhà hay không. Mình sẽ có một cái button giống như vậy, và mình sẽ đưa một đoạn text vào cho nó kiểm tra xem nó có match với điều kiện đó không.\n\nNgoài regex, dễ thấy nhất, thì ở trong những cái hệ thống event-driven nó sẽ có cái gọi là event button. Mọi người sẽ define một cái button dưới dạng một cái state machine, sau đó, mỗi event sẽ là một state, nó sẽ đi qua event button này và sẽ được filter qua xem nó có match với cái event đó hay không. Nếu match thì nó sẽ đi qua và tới cái state tiếp theo để nó làm tiếp, còn nếu không thì nó sẽ fail và không đi qua được.\n\n**27:27** Đây là một ví dụ của nó: Ví dụ, mình có một cái event bus, tất cả các event sẽ đi qua cái event bus này và sẽ được filter qua các rule. Nếu một event thỏa mãn điều kiện của rule thì nó sẽ đi qua để tiếp tục xử lý. Điều này thường thấy nhất trong các hệ thống cloud hiện tại, họ dùng rất nhiều cái hệ thống này để quản lý các event và filter chúng qua những cái rule như vậy. Mọi người có thể thấy trong những cái hệ thống lớn như của Amazon chẳng hạn, event của họ sẽ đi qua một chuỗi các rule như thế.\n\n**28:05** Ví dụ là mình có một cái button, và tất cả những cái item nào có cái field image, trong cái field image đó có một cái object là width với giá trị là 800, thì nó sẽ được pass qua hết. Và ở dưới thì nó cũng sẽ thêm một vài cái rule nữa, chẳng hạn như những cái field khác nhau mà mình thêm vào cho cái button đó. Đó là một ví dụ về việc finite state machine và event button hoạt động như thế nào. Khi một event được đưa vào hệ thống, nó sẽ đi qua các rule, và nếu thỏa mãn các điều kiện thì nó sẽ được pass qua để tiếp tục các bước xử lý tiếp theo.\n\n**28:56** Đây là một ví dụ cụ thể về hệ thống event của Amazon, nơi mà các event của họ sẽ đi qua một chuỗi các rule để được filter và xử lý. Hầu hết các hệ thống cloud hiện nay đều sử dụng những mẫu button tương tự để quản lý và xử lý các event một cách có tổ chức và hiệu quả.\n\n**29:37** Trong thực tế, bây giờ mình sẽ đi ngược lại một chút về finite automata (f automata) dưới góc độ toán học, nó là cái gì. Thực chất, nó đơn giản là một cái machine trong đó có một tập hợp những states. Để đi từ một state này tới một state tiếp theo, nó cần phải đi qua một transition. Ví dụ, để từ start state tới một end state, nó sẽ luôn cần phải có một điểm bắt đầu gọi là start state và một điểm kết thúc gọi là end state. Vì vậy, nó được gọi là finite state machine bởi vì nó luôn có điểm bắt đầu và điểm kết thúc.\n\n**30:21** Ở giữa, sẽ có một tập hợp các transitions và states để di chuyển từ điểm bắt đầu tới điểm kết thúc. Một input symbol là cái để đưa vào một state để nó di chuyển tới một state khác, và trong thực tế, input symbol thường sẽ là một ký tự. Tí nữa mình sẽ bàn chi tiết về vấn đề này. Accepting state là trạng thái mà khi input của nó được chấp nhận, thì nó sẽ được di chuyển tới một state khác thông qua một transition. Nếu như không chấp nhận thì nó sẽ không di chuyển tới đâu cả, coi như transition đó không dẫn tới một state nào.\n\n**31:04** Có hai loại finite automata, đó là deterministic finite automata (DFA) và nondeterministic finite automata (NFA). Điểm khác biệt duy nhất ở đây là với DFA, mỗi state sẽ có một input symbol duy nhất dẫn tới một transition tới một state khác. Còn với NFA, nó có thể có nhiều transitions cho cùng một state, thậm chí có thể không có transition nào hết. Điều này chỉ khác nhau về cách thể hiện con đường từ điểm bắt đầu tới điểm kết thúc, chứ thật ra một cái finite state machine đều có thể được biểu diễn dưới dạng DFA hoặc NFA, chỉ khác nhau cách biểu diễn thôi.\n\n**31:51** Về phần Union của hai cái finite automata, thì nó sẽ là tổ hợp của tất cả các states và transitions của hai cái finite automata cộng lại. Đặc điểm của nó là nếu ví dụ cái event A pass qua được cái finite automaton FA1 và event B pass qua cái finite automaton FA2, thì tổ hợp của hai cái này, Union của hai cái này, nó phải đảm bảo là cả event A và event B đều pass qua được.\n\n**32:45** Tại sao chúng ta cần phải tính toán Union của hai cái finite automata? Trong thực tế, ví dụ như khi dùng một cái event button, ta sẽ không dùng một cái button mà sẽ dùng nhiều button kết hợp lại với nhau. Ví dụ ở trong hình, chúng ta có thể define rất nhiều button, và trong event của mình có thể chứa nhiều đoạn thông tin match với những button này. Khi muốn kết hợp những button đó lại với nhau, chúng ta sẽ cần tính toán tổ hợp của tất cả chúng lại.\n\n**33:24** Nhưng mình sẽ không tính tất cả một lần, mà sẽ tính từng cái một, từng cặp một, ví dụ như cặp A và cặp B trước, sau đó lấy tổ hợp của A và B, rồi lại tính với cặp C. Chỉ cần tính toán hai button một lúc thôi, đây là mức cơ bản nhất để tính ra được tổ hợp của tất cả các button này.\n\nĐể tính toán Union của hai cái finite automata, theo lý thuyết thì chúng ta sẽ phải tính hết tất cả các states và transitions của hai automata đó. Ví dụ mình có hai cái button A và B, trong mỗi button sẽ có rất nhiều states, ví dụ như từ A1 đến Ax và từ B1 đến Bx. Khi tính toán theo kiểu lý thuyết, mình sẽ phải tính toán tất cả các trường hợp kết hợp giữa hai button này, ví dụ A1-B1, A2-B2, A1-B2, A2-B1, có rất nhiều trường hợp.\n\n**34:07** Trong thực tế mình chỉ quan tâm đến việc khi đưa event vào button thì mình muốn biết nó có match hay không thôi. Mình chỉ cần quan tâm xem event đó sau khi đưa vào button, nó có thể đi đến state cuối hay không. Việc tính toán tất cả các states trong Union sẽ rất lãng phí và không cần thiết. Do đó, cách tiếp cận thực tế là mình sẽ có hai finite automata với các states từ A1 tới Ax và từ B1 tới Bx. Khi tính tổ hợp của chúng, mình sẽ kiểm tra xem state đó có dẫn tới một transition nào trong A hoặc B hay không. Nếu không, mình sẽ bỏ qua.\n\n**35:40** Ví dụ như nếu state chỉ dẫn tới A1 và không có transition nào dẫn tới B, thì mình sẽ chỉ tính toán cho nhánh của A, bỏ qua nhánh của B. Ngược lại, cũng tương tự với B. Trường hợp cuối cùng là nếu A1 di chuyển tới Ax và B1 cũng di chuyển tới Bx, thì chúng ta sẽ tạo ra một state mới là Ax-Bx. Lúc này, mình sẽ bắt đầu đệ quy lại và tiếp tục tính toán từ bước đầu tiên này. Ví dụ, mình có A1-B1, và sau đó có A2-B2, thì mình sẽ lặp lại bốn bước này để tính toán tiếp.\n\n**36:15** Khi đó, số lượng states mà mình có thể bỏ qua và không cần tính hoặc không cần lưu trữ sẽ giảm đi rất nhiều so với phương pháp lý thuyết ở trên.\n\nVề input symbol, như trong ví dụ về event button hoặc regex, trong thực tế, các button và input mà chúng ta truyền vào chương trình đều sẽ ở dạng ký tự. Ký tự ở đây thường sẽ là những cái.\n\n**37:04** Ký tự dưới dạng UTF-8, tức là những ký tự đơn giản ví dụ như từ a tới z hoặc từ 0 đến 9. Nó sẽ nằm gọn trong UTF-8, bao gồm 244 ký tự. Mặc dù UTF-8 xài 8 bits (2^8 - 1 = 256), nhưng những bits từ 245 đến 255 thì dư ra, nên mình không xài, chỉ có 244 bits đầu tiên thôi. Rồi, đây là phần detail implementation trong code. Đây là cái workflow cơ bản mà mình sẽ thực hiện. Không biết có zoom được không? Zoom hình hồi nãy thử xem, không thấy chữ gì hết. Từ từ, để xem lại.\n\n**38:21** Rồi, cái FA là gì? Finite automata hả? Đúng rồi, automata. Cái hàm này sẽ merge hai cái automata lại với nhau. Đầu tiên nó sẽ tạo ra một cái key để mình đánh dấu lại, để không phải đi lại những cái state mà mình đã xử lý rồi. Sau đó, nó sẽ check thử cái key này, nếu không trùng, thì nó bắt đầu làm việc. Nó sẽ tạo một cái combined state rỗng, bao gồm tất cả các transitions của hai cái finite automata đó. Rồi nó sẽ tiếp tục merge từng cái finite automata lại với nhau, từng cái một. Kéo lên, mình đọc chưa kịp cái đó.\n\n**39:33** Trong quá trình implementation, sẽ có một số điểm cần chỉnh sửa trong cấu trúc dữ liệu để lưu lại những states đó. Đề tài này của em là em đang chạy cho cái example nào vậy? Hình này đang chạy sample nào? Đây chắc để em show code thì dễ nhìn hơn, phải nhìn vào đề bài mới biết đang code cho bài nào. Rồi, sau cái ví dụ này, sẽ có nhiều câu hỏi cho mình. Nhưng bài này chỉ cần Phúc và Tuấn hiểu là được, mọi người hiểu code rõ không?\n\nVí dụ hồi nãy về bài toán event button, ở đây mình sẽ define một cái button chẳng hạn. Cái button em define ra dưới dạng T, và đây là cái event. Khi mình chạy đoạn code này, nó chỉ là một phần logic thôi, ngoài ra còn nhiều đoạn code khác nữa. Nhưng khi chạy cái đó, kết quả mình mong đợi là nó sẽ kiểm tra xem event này có match với button này không. Nó sẽ trả về kết quả là đúng hay không đúng, event có match với button không.\n\n**41:13** Đúng rồi, đó là bài toán mà vấn đề này đang giải quyết. Đây là đoạn code đơn giản, em sẽ chạy ra kết quả, chỉ kiểm tra xem nó có match với button này hay không thôi. Ví dụ ở đây, button này có transition với từ \"user_register,\" chẳng hạn. Nếu em sửa lại điều gì đó khác, thì nó sẽ không match. Còn nếu event thỏa mãn điều kiện thì nó sẽ match, kiểu như vậy.\n\n**42:09** Em sẽ đi thẳng tới phần logic chính. Nó sẽ là cái hàm để merge hai cái finite state machine lại với nhau. Mỗi cái finite automata này đại diện cho một cái button. Cứ tưởng tượng mình có nhiều cái button. Ở đây mới chỉ có một cái button thôi, ví dụ em tách cái này thành hai button. Hàm của mình có nhiệm vụ merge hai cái button đó lại để tạo ra một cái button tổng.\n\n**43:31** Như đã nói, để tránh tính toán quá nhiều, trước tiên mình sẽ giải thích các tham số truyền vào hàm. Hai cái FAState là hai cái structure đại diện cho hai cái button hồi nãy của mình. Mỗi cái structure này bao gồm một small table để đại diện cho một dãy những input symbols và những transitions tương ứng. Epsilon là state mà tự đưa lại chính vị trí của nó, mình sẽ bỏ qua nó tạm thời. Ở đây mình chỉ quan tâm tới hai cái states này thôi. Đơn vị nhỏ nhất ở đây mà mình muốn làm input là file, bởi vì một ký tự sẽ được thể hiện dưới dạng UTF-8 và bao gồm 244 bits. Bây giờ mình sẽ loop qua từng bit trong từng ký tự này để so sánh.\n\n**44:20** Ví dụ như trong ví dụ này, mình đưa một cái event vào, sau khi mình compute xong hai cái button này, nó sẽ bắt đầu từ từng ký tự. Ví dụ nó sẽ đi từ ký tự dấu ngoặc, rồi sẽ kiểm tra xem có transition nào tới cái \"user\" không. Nếu không có, nó sẽ skip phần ID, vì nó không match. Bạn này đang đi vào chi tiết cách so sánh từng ký tự.\n\n**45:02** Skip đoạn này đi. Chỉ cần xem lợi ích và ý tưởng của việc cài đặt thôi, còn so sánh chi tiết thì không cần thiết ở đây. Lợi ích của phương pháp này đơn giản là nó giúp thuật toán không phải tính toán lại nhiều lần. Thuật toán khá đơn giản, chỉ là compare, như mình đã phân tích. Nếu một ký tự không có dẫn tới một transition nào, mình sẽ bỏ qua. Hoặc nếu nó chỉ dẫn tới một nhánh, mà nhánh đó không có transition nào, thì mình cũng bỏ qua luôn.\n\n**46:34** Ví dụ nếu state A1 của mình đi đến state B, mà state B không tồn tại, thì mình sẽ bỏ qua nhánh đó. Ngược lại, nếu state này đã tồn tại trong map rồi, mình cũng sẽ bỏ qua. Chỉ khi nào thỏa hết các điều kiện thì mình mới bắt đầu tính toán và loop qua từng state trong finite automata. Sau khi loop qua từng bước với mỗi state tương ứng trong B, mình sẽ ra được cái state tổng và gán nó vào, sau đó return ra kết quả.\n\n**47:17** Mọi người có hiểu không? Hỏi Minh xem. Minh đi coi cái này, anh kêu Minh quăng cái link lên. Bữa anh em nghe có hiểu không? Quan trọng là coi lại cái diagram đầu tiên, vì mình sợ mọi người không hiểu. Diagram này lâu lắm rồi, hơn cả tháng rồi đúng không? Đúng rồi, diagram này, mọi người có hiểu không?\n\n**49:11** Hệ thống như event bus của Amazon cần phải merge có khi lên đến hàng triệu cái button, nên sẽ có một số chi tiết trong phần implementation để làm những việc này nhanh hơn. Rồi qua một hình khác nữa đi, hình kế tiếp, hình mà nó rẽ hai nhánh, dùng hình đó để nói dễ hơn. Hình rẽ hai nhánh, đúng rồi. Cái hình rẽ hai nhánh, cái nào mà nên? Ừ chắc dùng giữ hình này đi, mấy anh kia có hiểu không?\n\n**50:11** Nói luôn cho rõ, lỡ nói bài này, mọi người nắm thì nó sẽ ok hơn. Hoàng có hiểu không? Em có hiểu cái này làm gì không? À, Phúc hỏi là có dùng bit operator không? Này thì chưa, chưa đến mức đó, chỉ là chi tiết so sánh rồi, không liên quan tới phần đó đâu. Tuấn, Minh ơi, Vincent đâu rồi, mọi người có hiểu bài này không? Không hiểu hả? Bài này nó ẩn tới ba lớp trong đó của phần Minh nói nha. Để mình clear vài thứ cho anh em đỡ lẫn lộn.\n\n**51:03** Đầu tiên là finite automata, tức là cái machine trạng thái, giống như cái state transition diagram mà mấy anh em hay vẽ. Nhớ không? Nó có những trạng thái (states) và các nút (nodes) đại diện cho trạng thái đó. Cái thứ hai là các điều kiện (input symbols) để di chuyển từ trạng thái này qua trạng thái khác, gọi là transition. Đọc cho dễ hiểu, dễ nhớ nhé. Nó giống như cái state transition diagram, đó là cái đầu tiên.\n\n**51:47** Cái thứ hai, cái mà Minh vừa show ra, là hai loại finite automata này. Tại sao lại show ra hai loại này? Vì có những trạng thái rất đơn giản, nó chỉ đi một chiều và không quay ngược lại được. Ví dụ, giờ ăn trưa chẳng hạn. Khi mình đi ra Hà Đô để ăn trưa, mình có thể đi ăn phở, đi bộ ra quán phở, ăn xong rồi đi về. Đó là hoàn thành một cái finite state trạng thái hũ hạn. Nó không có quay đầu lại được, đó là finite automata.\n\n**53:10** Một ví dụ khác, có một trạng thái finite automata mới là đi ăn trưa, nhưng lần này đi xuống siêu thị mua cơm, trả tiền rồi đi về. Vẫn là một cái finite automata, nhưng nó có các states khác với cái trước.\n\n**53:57** Câu chuyện là làm sao tính toán tổ hợp (union) của hai cái finite automata này. Giả sử có hai trạng thái tổ hợp, một là đi ăn phở, hai là đi mua cơm siêu thị. Ta cần build một cái union cho hai trạng thái đó, giống như Minh đã nói về việc merge hai cái state machines lại. Ở đây, chúng ta sẽ có hai lựa chọn: một là đi ăn phở, hai là đi siêu thị mua cơm. Ý tưởng là làm sao tổ hợp tất cả các lựa chọn có thể có giữa hai hệ thống states khác nhau.\n\n**54:30** Mình tính tổ hợp của nó thì mình gộp lại thôi. Trong cái trường hợp hồi nãy, ví dụ đó, mình sẽ có bao nhiêu options? Một người đi ăn phở, người kia đi siêu thị, đúng không? Ví dụ cũng là tính tổ hợp, nhưng đây là tổ hợp khác nha. Bài toán là có hai cái hệ thống finite automata (FA), và mình yêu cầu là tính union của chúng lại. Sau đó, mình kiểm tra như thế nào? Sẽ có hai phần: phần thứ nhất là đi theo luồng ban đầu – đi ăn phở, và phần thứ hai là đi theo luồng siêu thị. Một trường hợp khác là khi chập hai hệ điều kiện lại với nhau, nó sẽ sinh ra một hệ phụ nữa. Khi đó, mình lại phải tiếp tục tính toán và compute thêm.\n\n**55:17** Rồi, idea cơ bản của việc làm union của nhiều finite automata là vậy. Nó giống như phần mà Minh đã show lúc nãy, Minh có show cái source code. Rồi, coi lại cái hàm lúc nãy đi. Được rồi, ở đây, hàm của Minh có cái hàm để merge tất cả các states lại. Tức là, như đây, mình giả lập là có hai cái hệ states thôi đúng không, của hai cái finite automata khác nhau. Sau đó mình gộp lại thành một hệ chung, rồi ra được cái bảng lớn. Trên cái bảng lớn đó, mình mới tiếp tục tính toán với từng điều kiện.\n\n**56:04** Giờ mình đã build xong cái bảng lớn, một cái array lớn là danh sách tổng các điều kiện nằm ngay đó. Bây giờ mình sẽ bắt đầu tính toán. Khi có một điều kiện mới đưa vào, nó sẽ bắt đầu bằng cách kiểm tra tất cả các điều kiện của hệ đầu tiên. Nếu không được, thì nó kiểm tra các điều kiện của hệ thứ hai. Nếu vẫn không match, thì nó sẽ kiểm tra tiếp điều kiện của hệ tổ hợp giữa hai hệ trước đó. Logic tính toán cơ bản là như vậy.\n\n**57:02** Cái khó của bài này, nếu anh em cảm thấy hơi lẫn lộn, là do quá trình mô hình hóa từ toán học sang lập trình. Cho xem lại cái hàm và cái hình lúc nãy. Hình này là để giải thích tại sao trong bài regular expressions, người ta lại mention điều đó. Khi mình check trong cái dấu ngoặc vuông trong regular expressions, mình phải đi qua bao nhiêu điều kiện trong đó. Vì có nhiều options như vậy, mỗi option lại được mô hình hóa thành toán để dễ xử lý. Mỗi điều kiện là một cái finite automata, và chúng ta tính union của các điều kiện này.\n\n**58:38** Mô hình hóa toán logic thành lập trình là quá trình tính toán với nhiều hệ khác nhau. Mình phải tính toán xem điều kiện union của các hệ 1, 2, 3, 4... Nếu không có điều kiện nào, thì mình phải tính tiếp hệ giao của từng cặp điều kiện. Bài toán này là như vậy. Nếu anh em muốn tìm hiểu thêm, đây là một bài quan trọng vì nó giúp cho hiểu cách mà mình làm trong các hệ thống logic lớn.\n\n**59:21** Chắc bữa trước đưa cho Minh coi rồi. Tại vì điều này quan trọng, bởi nó liên quan tới việc làm hàm cộng trong logic. So sánh phổ biến nhất là login authentication, như bài log in, nó sẽ dính tới bài này. Trong quá trình log in, sẽ có nhiều điều kiện, ví dụ như nó pass bằng 2FA, hoặc email, hoặc SMS, hoặc password. Mỗi thứ này có thể mô hình hóa thành một cái finite automata riêng, và khi mình compute, mình gom tất cả lại.\n\n**01:00:00** Ví dụ như có yêu cầu là người dùng phải có vừa face scan vừa có QR code trên app để đăng nhập. Đó là một điều kiện tổ hợp (giao), chứ không đơn giản là một điều kiện if như bình thường. Trong mô hình toán học, ta sẽ dễ dàng xử lý hơn vì nó sẽ có tính chất đệ quy để tính toán các tổ hợp logic phức tạp. Cái quan trọng nhất là làm sao để tính được tổ hợp này mà không phải tính lại nhiều lần. Output sẽ là success hoặc failure. Nhưng đối với các bạn junior, khi thêm một case mới mà không có tư duy mô hình hóa, họ sẽ làm rất nhiều if statements lộn xộn, gây khó khăn khi bảo trì code.\n\n**01:01:29** Khi thêm một feature mới mà không có tư duy về mô hình hóa, code sẽ trở nên rối rắm và không hiệu quả. Họ sẽ phải sửa lại nhiều lần, gây ra nhiều lỗi và mất nhiều thời gian hơn để kiểm thử và sửa lỗi. Đó là lý do tại sao bài toán này quan trọng, vì nó ảnh hưởng tới việc thiết kế hệ thống, đặc biệt là các hệ thống như login authentication, nơi mà việc tổ hợp nhiều điều kiện là rất phổ biến.\n\n**01:02:23** Còn câu hỏi nào không? Không có hả? Minh, em có hiểu hết không? Ok, chắc hết giờ rồi. Thành ơi, còn bài nào nữa không? Chắc còn hai bài nữa, tranh thủ làm nốt thôi. Để em xem nào. Mọi người thấy màn hình không? Ok, tuần này em chỉ biết được hai bài, còn một bài nữa nhưng nó dài quá, chắc hẹn tuần sau. Bài đó cần chi tiết hơn về cách sử dụng.\n\n**01:03:36** Bài tiếp theo là về Go và cách embed file. Go embed là gì? Nó cho phép mình embed một cái file trực tiếp vào trong binary. Điều này giúp mình giảm thiểu việc handle các external files. Cách sử dụng là khi mình embed một file vào binary, quá trình handle sẽ trở nên đơn giản hơn. Nhưng có một hạn chế, đó là nếu file quá lớn, thì binary của mình sẽ phình to ra. Nên cần phải cẩn thận khi sử dụng.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hq_u9GQdNMg?si=Jiktpv6YYMbiOzp8\u0026amp;start=3793\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**01:04:15** Cách sử dụng như thế này: mình chỉ việc import rồi sử dụng như bình thường. Ví dụ, mình có một cái file message, mình embed file đó vào, rồi có thể truy cập file đó trực tiếp trong binary. Đối với nhiều file, mình có thể thêm ký tự sau như thế này. Sau đó, mình dùng biến đã embed để read file hoặc access như một file bình thường. Hoặc mình có thể embed nguyên một thư mục Directory luôn.\n\n**01:04:57** Thường thì chúng ta muốn embed cái static file như file ảnh, HTML, hoặc cái gì đó kiểu vậy. Về cái limitation mình nói trước đó, cái thứ hai là về reflect một cái package. Bài này thì nội dung cũng không mới. Thật ra cũng không mới nếu như mà em xài Go và có đọc trước bài của bác R rồi. Em sẽ nói qua luôn. Context của ông tác giả này cũng giống như mình thôi. Ví dụ như ổng đang xài một cái tool, một cái codebase nào đó, xong ổng gặp vấn đề về reflect và viết lại bài này. Thì nhìn chung, reflect có ba phần cần chú ý.\n\n**01:05:49** Ba phần quan trọng là: từ interface value cho đến reflection object, và ngược lại. Phần cuối cùng là khi muốn modify thì những cái value đó phải settable – nghĩa là phải được export, tức là phải viết trên capitalized value. Interface value là gì? Reflection object là gì? Interface value là mỗi hàm mà mình xài trong package reflect, nó luôn được hiểu là một interface{} rộng, cho nên nó là giá trị interface. Còn cái giá trị này là reflection object, và ngược lại.\n\n**01:06:36** Về chiều đi: ValueOf sẽ trả về một reflection object. Còn chiều ngược lại: từ đây, mình có thể dùng method là .Interface() để trả ngược lại giá trị ban đầu. Bên Go thì hiện tại nó đã mặc định sẵn rồi. Nếu muốn cập nhật (update) cái gì đó, mình cần tìm cái settable. Reflect có method này để mình có thể dùng và cập nhật được.\n\n**01:07:12** Còn một ý nữa là bên bài viết đó cũng đã nói rồi – nên tránh dùng reflect trừ trường hợp bất khả kháng. Vì nếu mình dùng các hàm như FieldByName, nếu input không được kiểm soát tốt, nó có thể dẫn đến panic hoặc crash ngay lập tức. Nên chỉ dùng khi thực sự cần thiết thôi, trong những trường hợp bí bách.\n\n**01:07:53** Còn một bài khác nữa mà em nói là dài, nói về map. Bài này so sánh giữa việc xài map bình thường với khi cần hỗ trợ concurrency, thì mình cần dùng locking strategy. Có thể xài mutex hay cái gì đó, hoặc lock khác. Bên package sync có hỗ trợ một cái sync.Map. Bài đó sẽ so sánh giữa hai cách tiếp cận này. Thực sự thì không có cái nào hơn cái nào, mà tuỳ vào use case mà xài.\n\n**01:08:35** Rồi chắc tới phần sau. Phát dạ, đơn giản thôi. Minh Trần đang hỏi về logic của ba automata, rồi yêu cầu thêm hai automata nữa. Thì Minh Trần đang hiểu sai thứ tự rồi. Thứ tự sẽ là theo logic khác. Tại sao anh Huy lại nói về các automata của hệ thống Việt Nam? Là bởi vì trước đây họ tiếp cận từ góc độ máy công nghiệp, những hệ máy tự động hoá. Không thể build tụi nó để chúng tương tác với nhau, chạy với nhau tự động, vì chi phí thử và sai rất cao.\n\n**01:09:31** Vì thế, để đảm bảo hiệu quả, họ phải tính toán về mặt logic trước, xem có bao phủ hết các trường hợp không. Ví dụ, khi có ba hệ thống, thêm hai hệ thống nữa là thành năm hệ thống. Trước tiên, phải xem thiết kế logic có chồng chéo gì không. Sau đó, mình mới list out các cây logic ra và tính toán. Đó là bước đầu tiên, sau đó mới tiến hành cài đặt.\n\n**01:10:09** Còn phần lập trình thực hiện sau đó tuỳ vào cách bạn muốn làm: có thể là union các hệ thống hoặc làm hàm cộng. Quan trọng là trước khi làm gì, mình phải đảm bảo phần logic đã cover được hết các trường hợp. Logic ở đây không chỉ là chuyển từ A sang B, mà là hệ logic tổng quát, bao gồm việc tính toán trên cây logic.\n\n**01:10:50** Union trong bài này nói về logic toán học một chút thôi. Còn khi implementation, nếu anh em đã làm thì chắc cũng dễ dàng làm được hàm cộng. Chỉ cần hiểu là trong union logic, chúng ta gom các điều kiện lại và tính toán. Sau khi gom các điều kiện đó, câu hỏi sẽ là trong hàm cộng, nó thực hiện như thế nào. Thường thì mọi người sẽ cố gắng explicitly từng bước một.\n\n**01:11:53** Ok, chắc ổn rồi. Thành còn gì nữa không? Ok, được rồi, để bên DevOps xử lý tiếp. Vào thử lại xem có vấn đề gì không. Mọi người tranh thủ làm bài test sớm nhé. Đợt này có deal về tài chính và AI, nên hãy chú ý.\n\n**01:13:04** Rồi, em sẽ nói qua luôn. Trong tháng 9 này thì không có nhiều tin nổi bật. Em sẽ nói nhanh thôi. Đầu tiên là về React, với những keywords như server actions, server functions, và React compiler. Có một bài viết trên freeCodeCamp về kiến trúc của React 19, nói rõ về cách tối ưu hoá hiệu suất. Nếu mọi người có thời gian thì nên đọc bài này.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hq_u9GQdNMg?si=2kaVp-rYPWxf3Rup\u0026amp;start=4446\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**01:15:12** Về Next.js, không có gì mới. Chỉ có một cái lùm xùm hồi đầu tháng khi OpenAI chuyển từ Next.js sang Remix. Tóm lại, OpenAI muốn trang của họ nhẹ hơn vì Next.js hơi nặng đối với kiểu trang SPA của chatbox. Vì vậy, họ quyết định quay về dùng Remix. Điều này liên quan đến một xu hướng mà em cảm thấy đang xuất hiện trong cộng đồng engineer: các framework như Next.js dần không được ưa chuộng như trước nữa.\n\n**01:15:51**\nCòn về Next.js, không có gì nhiều, chỉ vậy thôi. Ngoài ra, có một cái OpenNext, nó đang hướng tới hỗ trợ việc host Next.js trên tất cả các runtime. Hiện tại, Next.js chỉ chính thức hỗ trợ hosting trên các môi trường cụ thể, còn nếu muốn host ở những môi trường khác thì rất khó khăn.\n\n**01:16:28** Thằng OpenNext này thì mục tiêu của tụi nó là muốn hướng tới một cách mà mọi người có thể host Next.js trên tất cả các môi trường, kiểu không còn bị Versel độc quyền nữa. Vậy nên, có thằng này làm để giải quyết vấn đề đó. Qua cái mục này thì em thấy có hai cái thú vị đang được feature ở đây. Có một thanh niên đang implement một hệ thống real-time đơn giản dùng TypeScript và React. Nói chung, nó khá đơn giản, nhưng mà khi đọc thì thấy nó vui vui, kiểu như là JavaScript làm được mọi thứ vậy.\n\n**01:17:14** Next là một bài về chủ đề này. Nó hơi giống như commentary, nhưng mà em để bên này vì thấy nó cũng khá liên quan. Bài này bàn về trạng thái của ES5 trên web. ES5 giống như đợt trước em có nói, kiểu như CSS3 vậy, mấy cái công nghệ này tồn tại quá lâu rồi. Bài này khảo sát xem các thư viện, trang web trên internet liệu còn bao nhiêu trang web đang còn dùng ES5 hay đã move qua ES6 hết rồi. Tóm lại, kết luận là 89% của top 10.000 trang web hiện tại đã shift sang ES6 rồi.\n\n**01:17:55** Cho nên, kết luận ở đây là ES5 vẫn xài, nhưng mà khi làm một cái gì đó mới, nhất là khi làm thư viện mới, thì nói chung là không nên hướng tới ES5 nữa, vì nó cũng sắp lỗi thời rồi, nó đã quá lâu rồi. State of ES5 vẫn khá là liên quan.\n\n**01:18:44** Về phía trending, không có gì nhiều, nhưng có một bài này em thấy khá vui. Người ta đang có một cái open letter để kêu gọi thằng Oracle bỏ cái trademark của JavaScript. Em mới biết là JavaScript thuộc về trademark của Oracle. Khi nhắc tới Oracle, mọi người chỉ biết về Java thôi, gần như không có sản phẩm nào liên quan tới JavaScript, nhưng mà trademark của JavaScript lại thuộc về Oracle. Nên cái open letter này là kiểu mấy ông lớn trong giới developer yêu cầu Oracle thả cái trademark của JavaScript ra đi, đừng giữ nữa, vì Oracle không có đóng góp gì cho cộng đồng JavaScript.\n\n**01:19:22** Có rất nhiều người nổi tiếng đã ký vào bức thư này, những người creator của Node.js và JavaScript, kiểu rất nhiều người họ đã ký. Em cũng mới biết tới, nhưng mà thấy cũng hay hay.\n\n**01:20:16** Rồi tiếp theo, quay lại mấy cái framework và library mới, nhưng chắc phần này em sẽ skip vì không có gì đặc biệt. Có một cái bài commentary mà anh Thành gửi cho em, nó liên quan về cái sentiment của cộng đồng về React và JavaScript, đặc biệt là Next.js. Bài này khá dài, nhưng tóm lại ý chính của họ là các framework như Next.js càng ngày càng nặng.\n\n**01:20:55** Họ chỉ trích xu hướng hiện tại của cộng đồng engineer React là các front-end developers đang chạy theo các framework và library lạm dụng quá nhiều JavaScript. Điều này có lợi cho trải nghiệm của developer (DX), nhưng lại làm giảm trải nghiệm của người dùng (UX) vì phải ship quá nhiều JavaScript về phía client. Tóm lại là code thì sướng, nhưng sản phẩm cuối cùng thì người dùng lại không thích. Đặc biệt là họ chỉ đích danh thằng Next.js, nói rằng cần đẩy ngược các phần nặng về lại server để cải thiện trải nghiệm người dùng.\n\n**01:21:28** Cái sentiment này khá rõ ràng, họ đang kêu gọi mọi người chuyển ngược về server-side nhiều hơn. Em thấy bên front-end cứ đi vòng quanh vậy thôi, từ server chuyển xuống client, rồi từ client nặng quá lại kêu chuyển về server.\n\n**01:22:19** Nói chung là đó là mấy bài em thấy thú vị trong đợt tháng 9 vừa rồi. Drama thì cũng có chút thú vị, lôi kéo sự chú ý. Bên Go thì ổn định quá nên không có drama, thành ra không ai nói gì nhiều. Còn bên JavaScript thì cứ có drama suốt, từ server-side script, JavaScript modules, kiểu như drama quanh đi quẩn lại. Cộng đồng này lúc nào cũng vậy, không có biên chuẩn rõ ràng thì lúc nào cũng cãi nhau về chuyện đó.\n\nCảm ơn mọi người. Về phần reminder, các anh em tranh thủ làm bài test sớm nhé, để có thời gian xử lý kịp. Còn một số phần team lab cần xem lại, đặc biệt là báo cáo kết quả sau khi chuyển hết phần này, xem còn gì cần report không. Thành, chắc tụi mình sẽ wrap up ở đây và tập trung vào các case đã nói trước rồi, nhé.\n\n**01:23:30** Rồi, cảm ơn mọi người! Về phần reminder, các anh em tranh thủ làm bài test sớm nhé, để có thời gian xử lý kịp. Còn một số phần team lab cần xem lại, đặc biệt là báo cáo kết quả sau khi chuyển hết phần này, xem còn gì cần report không. Thành, chắc tụi mình sẽ wrap up ở đây và tập trung vào các case đã nói trước rồi, nhé.\n\n**01:24:04** Lập, xem lại giúp nhé. Cát có share một bài bên ngoài, bài đó mới post lên, dễ hiểu, mọi người thử xem nhé. Xu hướng hiện tại của mình sẽ kết thúc chu kỳ của mấy cái software không cần suy nghĩ nhiều, mà tập trung vào phần tooling nhiều hơn. Giờ mấy cái kỹ thuật cơ bản về toán và logic đang quay lại. Sắp tới, team lab sẽ report các chủ đề theo hướng logic nhiều hơn, để anh em nghe quen dần.\n\n**01:24:50** Tom hồi giữa tuần có dựng lại một cái library mới tên là WebUI sau khi cái library cũ bị shut down. Mọi người thử xem. Thằng này khá là legit, khi mình hỏi về chủ đề compile union của hai cái finite automata, nó trả lời toàn bộ theo công thức toán hết, nhìn rất dễ hiểu. Nó giải thích rõ ràng từng bước làm thế nào để tính union của hai hệ thống finite automata.\n\n**01:26:15** Đây, hai hệ rời, hệ chập lại điều kiện để tính toán điều kiện của hai cái dưới đây. Nó nói về chuyện state transitions, anh đang thử nghiệm một vài khái niệm về toán trên đây, và thấy khá là legit. Nếu được, khuyến khích anh em xài con này nhiều hơn. Con này, Tôm đã ngồi mod lại cái system của nó rồi. Ban đầu có thể sẽ nhìn hơi khó chịu một chút, vì mình đã quen nói chuyện bằng ngôn ngữ bình thường khi giải đề toán rất bình thường. Giờ mình phải step back lại một chút, để thấy rằng mấy kiến thức về khối A (toán học) giờ nó có giá trị. Full logic luôn. Rồi, advance như thế nào, practical implications là như thế nào, kỹ thuật làm như thế nào, đều có hết.\n\n**01:26:57** Thành thử ra, với những gì đang diễn ra, với các inquiry và commentary, anh ngồi dò, chắc chắn là thị trường sẽ chuyển qua hướng tài chính. Từ năm ngoái đến giờ, sau đợt blockchain và crypto, team mình hiện tại, đội của Huy Nguyễn vẫn đang tiếp tục, và đội đó vẫn rất ổn. Một số kỹ thuật mới hơn bên blockchain, như Monas hay gì đó, thì mình chưa xem, nhưng chắc cũng tương tự thôi, không có kỹ thuật nào khác biệt quá.\n\n**01:28:29** Về mảng tài chính, mình đang tích cực gần với các cycles về tài chính. Domain đó đang build up theo hướng này, và có vẻ như đây là một cửa rất sáng. Hướng này team mình cũng đang dần làm gần hết rồi, giờ chỉ còn lại là số lượng case study nhiều hay ít nữa thôi. Anh nghĩ vậy là hợp lý. Chất lượng đội ngũ cũng đang được cải thiện dần. Như bài lúc nãy đưa cho Minh, không nhớ là đã đưa cho Minh Lư chưa, nhưng Minh có xem được thì chắc cũng đã hiểu được tầm 6/10. Nhưng anh tin rằng nó vẫn hơn rất nhiều so với nhiều người khác. Mặc dù có sợ, nhưng không report lại được. Minh đã mở hai phần của finite state ra và giải thích rất legit.\n\n**01:29:12** Định hướng của team là theo hướng đó. Nếu khéo, thì chắc là hết tháng này, mình có thể đẩy thêm được nội dung về toán logic nhiều hơn một chút, cố gắng so sánh giữa những khái niệm cũ và những khái niệm mới mà mình đang biết, tương đương với nhau thôi. Biên lại, chỉnh lại cho phù hợp. Ok, không yêu cầu tất cả mọi người phải đi theo hướng đó, nhưng theo quan sát cơ bản, anh thấy thị trường đang dịch chuyển theo hướng đó. Để giữ giá trị khác biệt, mình chơi game theo cách khác chút. Đó là message để anh em aware.\n\n**01:29:58** Nếu không có gì khác thì còn một bài của anh Thành, chắc để sau. Còn lại, mọi thứ, thằng vừa rồi nếu mọi người chưa có access, thì xin chỗ Tom nhé. Hẹn gặp lại anh em tuần sau. Thứ Tư tuần sau sẽ không có buổi họp giữa tuần, mọi người ngồi và làm tiếp theo hướng mình vừa nói nhé. Content làm sao để anh em hiểu.\n\n**01:30:57** Ok, chắc là vậy nhé. Bye bye anh em, hẹn gặp lại anh em vào Thứ Sáu tuần sau. Thứ Tư tuần sau sẽ không có buổi nào ở giữa nữa. Mọi người dành thời gian xem thêm nội dung liên quan tới những gì cần để hoàn thành bài test nhé. Cảm ơn tất cả anh em. Bye bye, hẹn gặp lại.\n\n---\n\n**English transcript**\n\n**08:02** Is there any information that needs to be shared? If not, let's have Phát go first, I see a lot of topics today, so let's prioritize the new members. Ok, there are five topics today.\n\n**09:13** Please come forward. Whoever has a topic, please go early. Yes, Phát will start first, and then Thành’s part will follow. Nam, are you ready? Today, Nam will share a topic called \"UX Guide to Prompt with AI.\"\n\n**10:20** I’ll give an overview of the current situation first. Interaction between humans and AI is a popular topic today, and the emergence of Large Language Models (LLM) is a useful tool that our team is looking into. Today’s topic is for anyone interested in the User Experience (UX) of AI, specifically how tools are currently designed to improve the interaction between users and AI. Many tools and platforms are being developed today, but they mostly focus on improving prompt speed and accuracy instead of focusing on the user experience.\n\n**11:08** The concept of \"RACE\" (Role, Action, Context, Expectation) is quite common in prompting AI. Users need to prompt in this structure for AI to generate the most accurate output. However, not every case applies to \"RACE.\" Many companies have developed new methods to improve AI UX, helping make the interaction between users and AI smoother.\n\n**12:04** The first method is \"Context Through Rephrasing.\" This method helps AI query the context of the previous question to answer the next question coherently, without needing a perfectly structured prompt from the start. For example, if the first question is \"Who is the wife of Superman?\" and then you ask, \"When did they get married?\" AI will understand the context and connect the dots. But if there is no relevant context, such as asking, \"What day did the Titanic sink?\" AI won’t be able to provide the right answer.\n\n**12:50** Next is \"Implicit Referencing,\" for example, when asking about the number of floors in a building, AI might assume it's a famous building like the \"Willis Tower in Chicago.\" If you ask, \"What day?\" without proper context, AI cannot give an accurate answer. Questions must be tightly connected for AI to answer better, and this also applies to \"Context Through Rephrasing.\"\n\n**14:19** A similar concept is \"Continue Conversation,\" like in Google Assistant. Questions are naturally linked, and each new question relates to the previous ones to create a continuous conversation.\n\n**15:03** The next method is \"Racing and AI Scoring.\" Google Assistant also applies this method. It provides multiple options based on different contexts, helping users get better results. AI can also learn from user choices to improve interaction. For example, when AI is unclear about the context, it will give users options to choose from.\n\n**16:03** Lastly, there is \"System Prompting.\" This theory directs AI to operate based on the context and user-defined goals. It helps AI generate accurate output without following a fixed prompt standard. For example, when asking, \"Plan for releasing a software product\". ChatGPT may provide general concepts, while GPT mini will ask more detailed questions to help users continue prompting for more precise results.\n\n**17:45** Today’s discussion focuses on designing AI tools to improve user experience, not just in terms of speed or accuracy but also in terms of user interaction and overall experience.\n\n**18:50** To summarize this for everyone, especially designers, Nam's topic has two main aspects. First, it explains the structure of \"RACE\" and how to apply it. Second, it presents a framework for designing AI tools, focusing on how to prompt effectively to improve the interaction between AI and users. The RACE structure includes Role, Action, Context, and Expectation, and it helps enhance AI UX.\n\n**19:20** To explain briefly, R stands for Role, and there are different types of R’s that Nam mentioned earlier. For designers to understand the R structure, it's important to look at how to build an app focused on prompting and how this structure ties in. It involves introducing the R technique, a common technique Nam mentioned earlier, called RACE. When writing a RACE, you need to clearly state the Role, Action, Context, and Expectation.\n\n**20:03** RACE is described very clearly: what is Role, what is Action, everything is explained, including what Expectation is and what Task is. In summary, the most basic thing for designers is to understand the structure of a RACE prompt. It follows a specific structure, which produces standard results. The input follows that structure, and the output will provide corresponding results.\n\n**20:47** The second and final part of this presentation will discuss what to pay attention to when designing once you understand the structure of a prompt and how to prompt accurately. This part is open-ended because this is like a 101 guide for designers to look at and understand the basics.\n\n**21:30** Nam has talked quite a bit about the letter R, so some people might misunderstand that this topic is just explaining that concept in detail. But in fact, this presentation is introducing prompting to UX designers. Ok, any questions? This topic is quite basic; our team has used it a lot, and we’ve demoed it many times. There’s one point to note: this topic is special because it introduces system prompting, which other guides don’t cover.\n\n**22:31** This presentation introduces system prompting, which is usually not mentioned in other guides. Guides for end-users (end users) rarely mention this. This topic covers system prompting because it’s written from a designer’s perspective – someone who is part of the team building it. System prompting differs from regular prompting because it controls how AI operates based on the system's specific goals.\n\n**23:06** The structure of system prompting differs from the usual R's that people often see when reading research. Typically, you see discussions about 200 different types of R’s, but there is no perspective from someone building the app. This topic is for designers, not for end-users, but for those in-between to connect the different parts.\n\n**23:48** This is different from articles for engineers because it not only introduces the tools to build prompts but also discusses how to combine different R types. This is an intermediate-level topic, suitable for designers who play the intermediary role, not directly building but also not the end-users. It helps bridge these two parts together.\n\n**24:33** Ok, thanks, Nam. Next week, we will scope this topic again to make the content easier to understand for everyone. Going into detail might be a bit difficult for everyone to grasp. Thank you, Nam. Now, on to the next speaker. Let’s see if we can view the screen. Ah, it’s back.\n\n**25:41** My topic today is a small problem in programming techniques, which is how to compute the union of two finite automata, also known as finite state machines. I will demo it using Go source code. Today’s topic will have a few key points. First, I’ll explain the applications of automata for everyone to get an idea, then we’ll go into the details.\n\n**26:41** The most common application of finite state machines is that when you have a button and an input, you want to check whether the input matches or fails. It’s as simple as that. The most common example is using regex to check whether a piece of text is an email, a phone number, or a street number. We have a button like that, and we feed in a piece of text to check if it matches the condition.\n\nAside from regex, another common case is in event-driven systems, where we have event buttons. You define a button in the form of a state machine, and each event is a state. The event will go through the event button and get filtered to see if it matches that event. If it matches, it moves on to the next state for further processing; otherwise, it fails and doesn’t go through.\n\n**27:27** Here’s an example: Suppose we have an event bus, and all the events pass through this event bus and get filtered through the rules. If an event satisfies the rule, it proceeds for further processing. This is most commonly seen in modern cloud systems, where they use a lot of these systems to manage events and filter them through rules like this. You can see this in large systems like Amazon, where their events pass through a series of rules.\n\n**28:05** For example, suppose we have a button, and all items with a field \"image\" that contains an object with a width of 800 will pass through. And we can also add a few more rules for different fields that we add to that button. This is an example of how finite state machines and event buttons work. When an event enters the system, it passes through rules, and if the conditions are met, it will pass through to the next processing steps.\n\n**28:56** This is a specific example of Amazon’s event system, where their events pass through a series of rules to be filtered and processed. Most cloud systems today use similar button patterns to manage and process events in an organized and efficient way.\n\n**29:37** In practice, let's go back a bit to finite automata (f automata) in mathematical terms, what it is. In essence, it's simply a machine with a set of states. To move from one state to the next, it needs to go through a transition. For example, to go from the start state to the end state, there will always need to be a start point called the start state and an endpoint called the end state. That’s why it’s called a finite state machine because it always has a start and an end.\n\n**30:21** In between, there will be a set of transitions and states to move from the start point to the end point. An input symbol is what you feed into a state to move it to another state, and in practice, the input symbol is often a character. We’ll talk more about this in detail later. The accepting state is the state where if the input is accepted, it moves to another state through a transition. If it’s not accepted, it doesn’t go anywhere, as if the transition doesn’t lead to any state.\n\n**31:04** There are two types of finite automata, deterministic finite automata (DFA) and nondeterministic finite automata (NFA). The only difference is that with DFA, each state has a single input symbol leading to a transition to another state. With NFA, there can be multiple transitions for the same state, and there may even be no transitions at all. This difference is just about how the path from the start to the end is represented, but both finite state machines can be expressed as either DFA or NFA. It’s just a matter of representation.\n\n**31:51** Regarding the union of two finite automata, it’s the combination of all the states and transitions of the two finite automata. Its feature is that if event A passes through finite automaton FA1 and event B passes through finite automaton FA2, the union of these two must ensure that both event A and event B pass through.\n\n**32:45** Why do we need to compute the union of two finite automata? In practice, for example, when using an event button, we don’t use just one button, we use multiple buttons combined. For example, in the diagram, we can define many buttons, and in our event, we may have multiple pieces of information that match these buttons. When we want to combine these buttons, we need to compute the union of all of them.\n\n**33:24** But we don’t compute them all at once; we compute them one at a time, for example, first with pairs A and B, then take the union of A and B and compute it with pair C. We just need to compute two buttons at a time, this is the most basic level of calculating the union of all these buttons.\n\n**34:07** To compute the union of two finite automata, theoretically, we would have to calculate all the states and transitions of both automata. For example, if we have two buttons, A and B, and each button has many states, such as from A1 to Ax and from B1 to Bx. Theoretically, we would have to calculate all combinations of these two buttons, like A1-B1, A2-B2, A1-B2, A2-B1, there are many combinations.\n\n34:07 In practice, we only care about whether, when feeding an event into the button, we want to know if it matches or not. We only care if, after feeding the event into the button, it can reach the final state or not. Calculating all the states in the union would be wasteful and unnecessary. Therefore, the practical approach is to have two finite automata with states from A1 to Ax and from B1 to Bx. When calculating their union, we check if the state leads to any transition in A or B. If not, we skip it.\n\n**35:40** For example, if the state only leads to A1 and there’s no transition leading to B, then we only calculate the branch for A and skip B. Similarly, we do the same for B. The last case is if A1 moves to Ax and B1 also moves to Bx, then we create a new state, Ax-Bx. At this point, we recursively start again and continue calculating from this first step. For example, we have A1-B1, and then we have A2-B2, so we repeat these four steps to continue calculating.\n\n**36:15** This way, the number of states we can skip and not calculate or store is significantly reduced compared to the theoretical method mentioned earlier.\n\nRegarding input symbols, like in the event button or regex examples, in practice, the buttons and inputs we feed into the program are always in the form of characters. Characters here are often those.\n\n**37:04** Characters in UTF-8, which are simple characters like from a to z or from 0 to 9. They fit into UTF-8, which includes 244 characters. Although UTF-8 uses 8 bits (2^8 - 1 = 256), the bits from 245 to 255 are left over, so we don’t use them, just the first 244 bits. Now, here’s the implementation detail in the code. This is the basic workflow we’ll follow. Not sure if it can be zoomed in? Try zooming in on the diagram from earlier, the text isn't visible. Wait a moment, let’s check again.\n\n**38:21** Alright, what is FA? Finite automata? Yes, automata. This function will merge two automata together. First, it creates a key to mark the states that have already been processed so that we don’t have to revisit them. Then, it checks this key, and if it’s not a duplicate, it starts working. It creates an empty combined state that includes all the transitions of the two finite automata. Then it continues merging each finite automaton, one by one. Scroll up, I couldn’t read that part in time.\n\n**39:33** During implementation, there will be some points where we need to modify the data structure to store those states. Which example is your topic based on? Which sample is this diagram running? Let me show the code; it’ll be easier to see. You have to look at the problem to know which code we're dealing with. After this example, we’ll have more questions. But this topic only needs Phúc and Tuấn to understand, does everyone understand the code clearly?\n\n**40:13** The earlier example about the event button, here we define a button, for example. The button I defined is in the form of T, and here’s the event. When we run this code, it’s just part of the logic; there are more parts of the code. But when running that, the expected result is that it will check if this event matches this button. It will return whether the event matches the button or not.\n\n**41:13** That’s right, that’s the problem this code is solving. This is simple code; it will run and return results, just checking if it matches this button or not. For example, here, this button has a transition with \"user_register,\" for instance. If I change something else, it won’t match. But if the event meets the condition, it will match, something like that.\n\n**42:09** I’ll go straight to the main logic. It’s the function to merge two finite state machines together. Each of these finite automata represents a button. Imagine we have multiple buttons. Here we only have one button, but imagine I split this into two buttons. My function is responsible for merging those two buttons into one total button.\n\n**43:31** As mentioned earlier, to avoid too much calculation, I’ll first explain the parameters passed into the function. The two FAState are two structures representing the two buttons we had earlier. Each structure includes a small table to represent a series of input symbols and their corresponding transitions. Epsilon is the state that returns to its own position, we’ll skip that for now. Here, we only care about these two states. The smallest unit we want to use as input is the file because a character is represented in UTF-8 and includes 244 bits. Now, we’ll loop through each bit in these characters to compare.\n\n**44:20** For example, in this case, when I input an event, after computing these two buttons, it starts from each character. For example, it starts with a bracket and checks if there’s any transition to \"user.\" If there isn’t, it skips the ID part because it doesn’t match. This part goes into the details of comparing each character.\n\n**45:02** Skip this part. Just look at the benefits and the idea behind the implementation; there’s no need to compare in detail here. The benefit of this method is simple: it helps the algorithm avoid recalculating too many times. The algorithm is quite simple, it’s just comparing, as we analyzed earlier. If a character doesn’t lead to a transition, we skip it. Or if it only leads to one branch, and that branch doesn’t have any transitions, we skip it as well.\n\n**46:34** For example, if state A1 moves to state B, but state B doesn’t exist, we skip that branch. Conversely, if that state already exists in the map, we skip it. Only when all conditions are met do we start calculating and loop through each state in the finite automata. After looping through each step with the corresponding state in B, we get the final state and assign it, then return the result.\n\n**47:17** Does everyone understand? Ask Minh. Minh, check this out. I told Minh to send the link. Did you all understand this? The important thing is to review the first diagram because I’m afraid people don’t understand it. This diagram was a long time ago, more than a month ago, right? Yes, this diagram, does everyone understand?\n\n**49:11** Systems like Amazon’s event bus need to merge sometimes up to millions of buttons, so there will be some details in the implementation to speed up these tasks. Switch to another diagram, the next one, the one that branches into two; use that to explain better. The branching diagram, which one should we use? Let’s stick with this diagram, do the others understand?\n\n**50:11** Let’s explain it clearly so that everyone gets it. Hoàng, do you understand? Do you get what this is doing? Ah, Phúc asked if it uses a bit operator. Not yet, it hasn’t reached that level, it’s just detailed comparisons, unrelated to that part. Tuấn, Minh, where’s Vincent? Does everyone understand this topic? No? This topic is nested in three layers from what Minh discussed earlier. Let’s clear a few things to make it less confusing for everyone.\n\n**51:03** First, finite automata, or state machines, are like state transition diagrams that you often draw. Remember? They have states and nodes representing those states. Second, there are conditions (input symbols) that allow you to move from one state to another, called transitions. Read it carefully to understand and remember it better. It’s like a state transition diagram; that’s the first point.\n\n**51:47** The second point is the two types of finite automata that Minh just showed. Why show these two types? Because some states are simple, they only move in one direction and can’t reverse. For example, lunchtime. When you walk out to Hà Đô to eat pho, you can walk to the pho restaurant, eat, and return. That completes a finite state; it doesn’t reverse, that’s a finite automaton.\n\n**53:10** Another example is a new finite automaton where you go to the supermarket to buy lunch, pay, and return. It’s still a finite automaton, but it has different states than the previous one.\n\n**53:57** The issue is how to calculate the union of these two finite automata. Let’s say there are two states: one where you eat pho, and the other where you go to the supermarket to buy lunch. We need to build a union of these two states, like how Minh talked about merging two state machines. Here, we have two choices: one is to eat pho, and the other is to go to the supermarket. The idea is to compute all possible combinations of these two state systems.\n\n**54:30** We calculate their union by simply combining them. In the earlier example, how many options do we have? One person goes to eat pho, and the other goes to the supermarket, right? This example is also calculating the union, but it’s a different kind of union. The problem is that there are two finite automata (FA), and we need to compute their union. Then we check how to combine them. There are two parts: one part follows the original flow, eating pho, and the other part follows the supermarket flow. Another case is when you combine two sets of conditions, which will generate a new set. At that point, we have to continue calculating and computing more.\n\n**55:17** The basic idea of creating a union of multiple finite automata is like that. It’s similar to what Minh showed earlier, Minh showed the source code. Now, let’s go back to that function. Alright, here, Minh’s function has a method to merge all the states. This means we simulate having two state systems only, right? From two different finite automata. Then we merge them into a unified system, which gives us a big table. From that big table, we continue to calculate based on each condition.\n\n**56:04** Now, we’ve built the big table, a large array that contains the complete list of conditions. Now, we’ll start calculating. When a new condition is input, it begins by checking all the conditions of the first system. If it doesn’t match, it checks all the conditions of the second system. If it still doesn’t match, it checks the conditions of the union of the two systems. The basic calculation logic is just like that.\n\n**57:02** The difficulty of this problem, if you feel a bit confused, lies in the process of modeling from mathematics into programming. Do you get it, Tư? Lucky, did you grasp it? Ok, follow the problem. Show the function and the diagram from earlier. This diagram explains why regular expressions mention this. When you check in square brackets in regular expressions, you need to go through all the conditions inside. Because there are so many options, each option is modeled mathematically to make it easier to handle. Each condition is a finite automaton, and we compute the union of these conditions.\n\n**58:38** Modeling mathematical logic into programming is the process of calculating with different systems. We need to calculate the union condition of systems 1, 2, 3, 4... If none of the conditions are met, we have to calculate the intersection of each pair of conditions. This problem is like that. If you want to learn more, this is an important topic because it helps you understand how we operate in large logic systems.\n\n**59:21** I think I gave this to Minh earlier. This is important because it relates to creating logic addition functions. A common comparison is login authentication, like in the login process, which relates to this problem. During the login process, there are many conditions, for example, passing 2FA, email, SMS, or password. Each of these can be modeled into its own finite automaton, and when we compute them, we combine them all.\n\n**0 1:00:00** For example, there might be a requirement for the user to have both face scan and QR code to log in. That’s a combined condition (intersection), not just a simple if statement. In mathematical modeling, we can handle this easily because it has recursive properties to compute complex logic combinations. The most important thing is how to calculate this combination without recalculating many times. The output will either be success or failure. But for junior developers, when adding a new case without the modeling mindset, they’ll end up creating many messy if statements, making it hard to maintain the code.\n\n**01:01:29** When adding a new feature without a modeling mindset, the code becomes messy and inefficient. They’ll have to rewrite it many times, causing many bugs and wasting time fixing and testing. That’s why this problem is important, as it impacts system design, especially in systems like login authentication, where combining multiple conditions is common.\n\n**01:02:23** Any more questions? No? Minh, do you understand it all? Ok, looks like we’re out of time. Thành, are there any more topics? There are two more, but let’s try to wrap them up quickly. Let me check. Can everyone see the screen? Ok, this week, I only have two topics, there’s another one, but it’s too long, we’ll do it next week. That one requires more detail in terms of usage.\n\n**01:03:36** The next topic is about Go and how to embed files. What is Go embed? It allows us to embed a file directly into the binary. This helps reduce the need to handle external files. The way it works is that when we embed a file into the binary, the handling process becomes simpler. But there’s a limitation: if the file is too large, the binary will expand. So, be careful when using this.\n\n**01:04:15** The usage is like this: we just import it and use it as usual. For example, we have a message file, we embed that file into the binary, and then we can access that file directly. For multiple files, we can add additional characters like this. Then, we use the embedded variable to read or access it like a normal file. Or we can even embed an entire directory.\n\n**01:04:57** Usually, we want to embed static files like images, HTML, or something like that. As for the limitation I mentioned earlier, the second topic is about reflecting a package. This topic is not new. It’s not really new if you’ve used Go and read the article by Dr. R. I’ll go over it quickly. The context is that the author encountered a problem with reflection while using a tool or codebase and wrote this article. In general, reflection has three key points to note.\n\n**01:05:49** The three important points are: from interface value to reflection object, and vice versa. The final point is when you want to modify the values, they need to be settable, meaning they need to be exported, or written with a capitalized value. What is an interface value? What is a reflection object? The interface value is, in every function we use in the reflect package, it’s always understood as a wide interface{}, so it’s an interface value. And this value is a reflection object, and vice versa.\n\n**01:06:36** As for the direction: ValueOf returns a reflection object. In the opposite direction, from here, we can use the method .Interface() to return the original value. In Go, this is now default. If you want to update something, you need to find something settable. Reflect has this method for you to use and update.\n\n**01:07:12** Another point mentioned in that article is to avoid using reflect unless absolutely necessary. If you use functions like FieldByName, if the input is not well-controlled, it can lead to panic or crashes immediately. So, only use it when absolutely necessary, in cases where there’s no other option.\n\n**01:07:53** There’s another article that I mentioned that’s quite long, about map. It compares using regular maps with the need to support concurrency, where you’ll need a locking strategy. You can use mutex or something else, or some other lock. The sync package provides a sync.Map. The article compares these two approaches. There’s no better option; it depends on the use case.\n\n**01:08:35** Now, let’s move on to the next part. Phát, simple stuff. Minh Trần is asking about the logic of three automata and then adding two more automata. But Minh Trần is misunderstanding the order. The order will follow different logic. Why did Huy mention automata systems in Vietnam? Because previously, they approached it from the perspective of industrial machines, automated systems. They couldn’t build them to interact with each other or run automatically because the cost of trial and error was too high.\n\n**01:09:31** So, to ensure effectiveness, they had to calculate the logic first to see if it covered all cases. For example, when there are three systems, and you add two more, making five systems. First, you have to see if the logic design overlaps. Then, we list out the logic trees and calculate. That’s the first step, then we proceed with implementation.\n\n**01:10:09** As for implementation, it depends on how you want to do it: you can union the systems or create an addition function. The important thing is that before you do anything, you must ensure the logic covers all the cases. Logic here is not just about going from A to B; it’s a general logic system, including calculations on logic trees.\n\n**01:10:50** Union in this article talks about mathematical logic a bit. When it comes to implementation, if you’ve done it before, you’ll find it easy to create an addition function. Just understand that in union logic, we combine conditions and calculate. After combining those conditions, the question is how the addition function performs. Usually, people try to explicitly go step by step.\n\n**01:11:53** Ok, seems good now. Thành, is there anything else? Ok, got it, DevOps team will handle the rest. Try it again and see if there’s any issue. Everyone, please do your tests early. We’ve got a financial and AI deal this time, so pay attention.\n\n**01:13:04** Now, I’ll move on. In September, there weren’t many notable updates. I’ll go over it quickly. First, about React, with keywords like server actions, server functions, and React compiler. There’s an article on freeCodeCamp about React 19’s architecture, detailing how to optimize performance. If you have time, you should read that article.\n\n**01:15:12** Regarding Next.js, nothing much new. There was some noise at the beginning of the month when OpenAI switched from Next.js to Remix. In short, OpenAI wanted their page to be lighter because Next.js was a bit heavy for a chatbox SPA (Single Page Application). So, they decided to switch back to Remix. This relates to a trend I’m noticing in the engineer community: frameworks like Next.js are becoming less favored.\n\n**01:16:28** The goal of OpenNext is to make it so that people can host Next.js on any environment, no longer being restricted by Vercel’s exclusivity. So, this project is here to solve that problem. Moving on, I see two interesting things being featured. There’s someone implementing a simple real-time system using TypeScript and React. It’s pretty simple, but reading it makes you smile, like JavaScript can do everything.\n\n**01:17:14** Next is a piece about this topic, which is kind of like commentary, but I’m putting it here because it’s still relevant. This article discusses the state of ES5 on the web. ES5 is like what I mentioned before, like CSS3, technologies that have been around for too long. This article surveys how many websites on the internet are still using ES5 or if they’ve moved on to ES6. In short, the conclusion is that 89% of the top 10,000 websites have already shifted to ES6.\n\n**01:17:55** So, the takeaway here is that ES5 is still in use, but when building something new, especially when building a new library, generally, you shouldn’t aim for ES5 anymore because it’s almost outdated; it’s been around for too long. The state of ES5 is still somewhat relevant.\n\n**01:18:44** Regarding trending topics, there’s not much, but there is an amusing one. There’s an open letter asking Oracle to give up the JavaScript trademark. I just found out that JavaScript belongs to Oracle's trademark. When people think of Oracle, they only know Java, and almost no product relates to JavaScript. But the trademark for JavaScript is owned by Oracle. So this open letter is basically developers asking Oracle to release the JavaScript trademark, not hold onto it anymore, because Oracle hasn’t contributed anything to the JavaScript community.\n\n**01:19:22** Many big names have signed the letter, including the creators of Node.js and JavaScript, many well-known people have signed it. I just found out, but it seems interesting.\n\n**01:20:16** Moving on to new frameworks and libraries, but I’ll probably skip this part because there’s nothing special. There’s a commentary from Thành, relating to the sentiment in the React and JavaScript community, especially around Next.js. The article is quite long, but to sum it up, the main point is that frameworks like Next.js are getting heavier.\n\n**01:20:55** They criticize the current trend in the React engineer community: front-end developers are chasing after frameworks and libraries that overuse JavaScript. This benefits the developer experience (DX), but it reduces the user experience (UX) because too much JavaScript is being shipped to the client. In short, writing code is fun, but the final product doesn’t make the user happy. They specifically mention Next.js, saying that the heavy parts need to be pushed back to the server to improve the user experience.\n\n**01:21:28** This sentiment is quite clear; they’re calling for a shift back to more server-side solutions. I feel like the front-end community keeps going in circles: moving from the server to the client, and now the client is too heavy, so they’re calling to move back to the server.\n\n**01:22:19** In general, those are the interesting topics I found in September. Drama is always interesting; it grabs attention. In Go, everything is stable, so there’s no drama, which is why no one talks much. But in JavaScript, there’s always drama, from server-side scripts to JavaScript modules, the drama just keeps coming back around. The community is always like this; without clear standards, people are always arguing.\n\n**01:23:30** Thanks, everyone. Regarding the reminder, please do your tests early so there’s time to handle everything. The team lab still has some work to review, especially the reports after everything is transferred over. Thành, I think we’ll wrap up here and focus on the cases we mentioned earlier.\n\n**01:24:04** Lập, please review. Cát shared an article outside, it’s new, easy to understand, everyone take a look. The current trend seems to be ending the cycle of software that doesn’t require much thought, focusing more on tooling. Now, basic techniques in math and logic are making a return. In the future, the lab team will report more on topics in logic, so everyone gets used to it.\n\n**01:24:50** Tom rebuilt a new library called WebUI after the old one was shut down. Everyone take a look. This one is quite legit. When you ask it about the union of two finite automata, it responds with everything in mathematical formulas, very easy to understand. It explains clearly how to compute the union of two finite automata systems.\n\n**01:26:15** Here, the two systems combine conditions to calculate. It talks about state transitions, I’m testing a few mathematical concepts on it, and it seems quite legit. If possible, I encourage everyone to use this more. Tom has already modified its system. Initially, it might seem a bit uncomfortable because we’ve been used to using normal language to talk about these problems for so long. Now, we have to step back a little, and see that knowledge in math is valuable now. Full logic. Then, how to advance, practical implications, how to implement it, everything is there.\n\n**01:26:57** Given what’s happening with the inquiries and commentary, I’ve been checking, and I’m certain the market is shifting toward finance. Since last year, after the blockchain and crypto wave, our team, Huy Nguyễn’s team, is still moving forward, and that team is still doing well. Some newer techniques in blockchain, like Monas or something, we haven’t looked at yet, but it’s probably similar, no major technical differences.\n\n**01:28:29** In finance, we’re actively working with the financial cycles. That domain is building up this way, and it seems like a bright opportunity. Our team is also almost done with this, now it’s just a matter of how many case studies there are. I think this direction is reasonable. The team’s quality is gradually improving. Like the material I gave to Minh earlier, I can’t remember if I gave it to Minh Lư yet, but if Minh has seen it, he should understand about 6/10. But I believe it’s still much better than many others. Even though there might be fear, he didn’t report back. Minh opened two parts of the finite state machine and explained them very well.\n\n**01:29:12** The team’s direction is to follow this path. If done skillfully, by the end of this month, we could push more content about math and logic. We’ll try to compare old concepts with new ones we already know. Let’s refine and adjust. Ok, it’s not required that everyone follow this path, but based on basic observation, I see the market is shifting in that direction. To keep our value distinct, we have to play a different game. Consider this as a message for everyone to be aware.\n\n**01:29:58** If there’s nothing else, there’s one more article from Thành, but we’ll leave it for later. As for the rest, if anyone doesn’t have access to the thing from earlier, ask Tom. See you next week. Next Wednesday, there won’t be a mid-week meeting, everyone sit and continue along the direction we just discussed. Let’s work on the content so that everyone can understand.\n\n**01:30:57** Ok, I think that’s it. Bye-bye, everyone, see you next Friday. Next Wednesday, there won’t be a mid-week meeting. Everyone take time to review the content related to what needs to be done for the test. Thanks, everyone. Bye-bye, see you.\n","title":"OGIF Office Hours #27 - Go Weekly, Frontend Report Sep, UX Guide to Prompt with AI, Computing the Union of Two Finite Automata","short_title":"#27 Go weekly, Frontend, AI UX, Finite Automata","description":"In OGIF office hour 27, covering presentations on UX Guide to Prompt with AI, computing the union of finite automata, and other topics including Go Weekly and Frontend Report for September.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Mon Oct 14 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/27-20241011.md","slugArray":["updates","ogif","27-20241011"]},{"content":"\n### Topic highlights\n\n1. Nam Bui's presentation on product design:\n    - Introduction to the Sparkle icon and its use in AI applications.\n    - Sharing insights on onboarding new users for AI applications.\n2. Phat's share on Go weekly commentary:\n    - Introduction to \"Prep\", a tool for compile-time evaluation in Go.\n    - Overview of \"War Zero\", a database-compatible web assembly runtime.\n    - Discussion on the advantages and limitations of these tools.\n3. Hoang's presentation on chatbot evaluation:\n    - Introduction to a method for evaluating chatbots using simulated users and evaluators.\n    - Description of the setup and implementation of the evaluation process.\n4. Anh's case study on a stock trading application:\n    - Introduction to the research and redesign project for the Kafi stock trading app.\n    - Sharing the process of user research, problem analysis, and proposed solutions.\n    - Discussion on applying AI in the user research process.\n5. Important announcements from management:\n    - Request for everyone to write 2 essays and 1 practical assignment on AI:\n        - Essay 1: About company culture\n        - Essay 2: About AI applications in each person's field of work\n        - Assignment 3: Practical task (topic yet to be determined)\n    - These are conditions for the year-end trip and performance review.\n    - Submission deadline is before the 4th week of November.\n    - Emphasis on controlled use of AI in work processes.\n6. Updates on ongoing projects and research topics in the team:\n    - Discussion on topics such as multi-agent systems, knowledge routing, semantic projection, etc.\n    - Emphasis on the importance of understanding and applying new architectures in software development.\n7. Highlighting the importance of applying AI in work and the need for proactive learning to keep up with trends.\n8. Discussion about changes in the job market, especially for junior and mid-level positions.\n\n---\n\n**Vietnamese Transcript**\n\n**00:00** Hôm nay có một vài topic về Go commentary, ngoài ra thì sẽ có bài của Nam về phần product design commentary. Sau đấy thì sẽ có một vài phần liên quan đến evaluate chatbot và kỹ thuật để làm chatbot của Hoàng và Tom. Chắc là sẽ share anh em một tí về cái kiến trúc microservices, nếu còn thời gian thì có một bài case study về một cái project crypto finance của Anna.\n\n**08:47** Nam Bùi lên được, em chưa thấy Nam Bùi xong bài… Xong rồi thì em share màn hình nhé.\n\n**10:31** Rồi mọi người thấy màn hình chưa? Ok, chắc mọi người thấy rồi. Tiếp nối bài product design của tuần trước, tuần này em sẽ nói về hai bài, đầu tiên sẽ là về icon Sparkle. Đầu tiên thì icon Sparkle này thì chắc là cũng phổ biến, không biết mọi người có thấy icon này bao giờ chưa? Nếu có thì mọi người bấm phím 1 cho em với. Thì icon này nó sẽ thuộc dạng là… Ừ thì icon này thì hiện tại nó đang sử dụng cho tất cả các app, và hiện tại em sẽ muốn giới thiệu một vài cái app.\n\n**11:30** Đầu tiên là cái app Plane Finder này thì nó sẽ dùng icon này để hiện thị cho các bài viết mới của Plane Finder. Cái app thứ hai là app e-commerce chuyên bán quần áo mỹ phẩm Ulta, thì nó sẽ có một cái tính năng là discover, sử dụng icon Sparkle để show tính năng này. Tiếp theo thì chắc mọi người cũng quen thuộc hơn, đó là Google Meet, nó có tính năng remove background và thêm background khác vào, thì nó cũng sử dụng icon Sparkle này.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/AhehaT_PK84?si=QfcJA-sP6X9_eIL6\u0026amp;start=659\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**12:14** Như vậy là mình có ba cái app đã sử dụng icon Sparkle, ngoài ra thì còn nhiều app khác nữa cũng đang sử dụng icon này. Sp icon này không chỉ sử dụng cho một tính năng nhất định mà nó rất phổ biến. Đến khi AI bắt đầu xuất hiện thì AI hiện tại cũng đang dùng icon này rất nhiều, ví dụ như Figma dùng cho icon generator.  Ngoài Figma thì còn có Miro, một app để vẽ diagram hay wireframe.\n\n**12:59** Một cái app nữa đó là Dovetail app, nó sử dụng icon này để generate lại các buổi họp. Hầu hết các app AI hiện tại đều đang sử dụng icon này. Và cuối cùng là ứng dụng Nylas, hiện tại Nylas sử dụng icon này làm giao diện chính của họ. Việc này làm cho người dùng khi thấy icon Sparkle sẽ liên tưởng đến các tính năng liên quan đến AI, vì icon Sparkle này đang trở thành biểu tượng của AI.\n\n**13:45** Trước khi em show các giao diện về AI, em có show một số ví dụ về việc sử dụng icon này cho những tính năng khác của các app khác, để chứng minh rằng icon Sparkle này không bị giới hạn chỉ cho một tính năng duy nhất mà nó có thể dùng cho nhiều tính năng khác nhau. Để sử dụng icon này hiệu quả, em nghĩ khi mình hover lên icon thì sẽ có tooltip để hiển thị tính năng cụ thể là gì, hoặc là show ra tên tính năng ở dưới icon luôn. Nhìn chung thì việc sử dụng icon Sparkle hay các icon dạng generic khác sẽ cần tooltip hoặc tên tính năng để user tránh bị nhầm lẫn.\n\n**14:31** Bây giờ em sẽ chuyển sang bài thứ hai, bài này sẽ nói về việc onboarding người dùng mới cho AI. Em sẽ tập trung so sánh các app với nhau để đưa ra những best practices cho việc onboarding người mới sử dụng AI hay vừa đăng nhập vào và khám phá một tool AI mới.\n\n**15:26** Ở đây thì có một app khá nổi tiếng ở Trung Quốc tên là SparekDesk. Khi người dùng vừa vào app, họ sẽ có một danh sách các câu hỏi và hướng dẫn để tìm hiểu về app này. Ngược lại thì ChatGPT không cần phải có danh sách câu hỏi này, mà người dùng có thể bắt đầu ngay bằng cách gõ câu hỏi của mình vào để kiểm tra khả năng của nó.\n\n**16:10** Thay vì cung cấp list câu hỏi hướng dẫn, người dùng thường bắt đầu với ChatGPT bằng cách hỏi ngay một câu như ‘Can you…’ để kiểm tra khả năng của AI này có thể làm được hay không. Cách này giúp việc onboarding với ChatGPT hiệu quả hơn so với các tài liệu hướng dẫn dài dòng.\n\n**17:09** Ví dụ tiếp theo là khi người dùng lên App Store, họ có thể thấy các danh mục như Productivity để hiển thị tính năng của app. Ví dụ ở bên trái là Productivity, bên phải là kết quả tìm kiếm và các tính năng của app. Điều này giúp người dùng dễ hiểu hơn về app trước khi họ tải về.\n\n**18:02** Nên là em nghĩ rằng với từng character thì nó sẽ tạo ra một câu hỏi khác nhau cho từng character, nên là người dùng sẽ bị khó hiểu và phải cân nhắc việc nên chọn cái nào. Còn phần mềm này thì nó chỉ có những hướng dẫn tool-tip ngắn gọn cho user, và không có những bước onboarding rườm rà như vậy. Thì cái ý ở đây là mình nên loại bỏ những cái step không cần thiết cho user, thay vì đưa quá nhiều bước hoặc quá nhiều thứ làm người dùng bị confused. Đây là ý cuối cùng.\n\n**18:58** Ví dụ như cái app bên trái đưa ra những câu hỏi chi tiết cụ thể cho người dùng, còn app bên phải thì lại đưa ra các câu hỏi chung chung, không liên quan đến một tình huống cụ thể nào. Theo em thì việc đưa ra câu hỏi chung chung sẽ hiệu quả hơn, vì những câu hỏi chi tiết quá sẽ không hữu ích cho người dùng, và thường thì những câu hỏi chi tiết quá sẽ không match với những gì người dùng mong muốn. Vì vậy em nghĩ là nó sẽ dư thừa trong quá trình onboarding user. Ngược lại, ChatGPT thì đưa ra những câu hỏi chung chung, và điều này sẽ có phần trăm cao hơn là nó phù hợp với mong muốn của người dùng.\n\n**19:44** Từ bốn cái ví dụ so sánh này, em rút ra: Thứ nhất, mình nên hạn chế đưa ra quá nhiều câu hỏi chi tiết cho user, thay vào đó, để họ tự do hỏi trực tiếp cái gì họ muốn. Thứ hai, mình nên đưa ra phạm vi tính năng rõ ràng ngay từ đầu, như dạng để set expectation cho user, thay vì để họ vào rồi không dùng được thì họ sẽ xóa ứng dụng. Thứ ba, mình cần bỏ đi những bước onboarding rườm rà không cần thiết và tối ưu hoá thời gian cho user. Cuối cùng, mình nên đưa ra những câu hỏi chung chung, thay vì những câu hỏi quá chi tiết.\n\n**20:33** Dạ rồi, em xong. Anh em có câu hỏi gì không thì comment lại phía dưới nhé. Nhưng mà anh thấy ở đây, thực ra việc so sánh như vậy thì anh có cảm giác những cái app này nó có target đến cùng một tác vụ không em? Tại vì thực ra kiểu cái case này, những câu hỏi mang tính specific có thể vẫn useful trong một số hoàn cảnh khác nhau. Chứ không phải lúc nào câu hỏi random cũng hợp lý, vì như kiểu ChatGPT là một tool chat general có thể làm nhiều thứ. Còn một số giao diện chat khác thì nó lại specific cho một tác vụ cụ thể thôi.\n\n**21:26** Nhưng cái mà em nói thì nó cũng thuộc dạng generic tool chat như ChatGPT, chứ không phải cho một tác vụ cụ thể. Đúng rồi, nên là em so sánh hai cái dạng generic tool chat với nhau thôi.\n\n**22:09** Dạ, thì đúng như anh nói, ví dụ như là một cái app cụ thể thì nó cần có những câu hỏi cụ thể hơn. Nhưng mà ở đây em chỉ so sánh hai cái dạng tool chat chung chung thôi.\n\n**23:07** Dạ. Đúng rồi, thắc mắc thêm không? Có gì hỏi tiếp nhé. Bây giờ thì chuyển qua topic tiếp theo. Topic lần này là hai bài viết về AI: một cái là sự hiểu lầm về Sparkle icon, và một cái là các best practice để onboarding user mới dùng AI. Anh em có câu hỏi gì về Sparkle icon không?\n\n**23:58** Thực ra thì bây giờ đa phần những cái app có AI thì đều có những kiểu như mic icon, các thứ tương tự. Nhìn vào là biết ngay là có AI chứ không nhầm lẫn được. Đồng ý. Còn phần onboarding thì anh thấy hơi cấn. Mục đích của việc onboarding là để giúp user bắt đầu với app và có điểm tựa để họ khám phá thêm, chứ không phải cho long-term user dùng. Onboarding này sẽ chỉ dùng cho user mới bắt đầu thôi.\n\n**25:10** Em có gửi một cái link để mọi người có thể đọc thêm sau. Bài đó em tóm tắt dựa trên các giao diện mới đang support AI hiện tại. Tháng này có nhiều app chat ra mắt với những feature và UI khá ngầu. Sáng nay, em thấy ChatGPT có thêm tính năng Canvas, mở ra pop-up để scroll artifact bên phía CR. Nếu mọi người hứng thú thì có thể tham khảo thêm. Ok, cảm ơn em. Được rồi, phát biểu tiếp nhé. Ok rồi anh, bye mọi người.\n\n**26:42** Dạ, thì tuần này em có được hai bài, thấy cũng ok, không có gì phức tạp lắm. Chủ yếu là những cái tool mới thôi. Bài đầu tiên đó là về thằng Prep. Thì Prep này nó là một cái tool để giúp compile-time evaluation. Nó là một cái tool để enable compile-time evaluation, giúp cho quá trình này xảy ra ngay tại compile-time thay vì tại runtime.\n\n**29:11** Thì mọi người hiểu compile-time evaluation là gì không nhỉ? Kiểu như bình thường khi mình viết code, những giá trị mà mình gán cho biến hoặc hàm thì nó sẽ được tính toán tại runtime, nhưng với thằng tool này, nó sẽ giúp chuyển những đoạn tính toán ở runtime thành compile-time. Việc này sẽ giúp boost performance lên một chút, đặc biệt trong các trường hợp cần tính toán nặng. Ví dụ, với những bài toán phức tạp như tính Fibonacci số lớn, nếu làm tại compile-time thì sẽ nhanh hơn nhiều so với tính tại runtime.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/AhehaT_PK84?si=1TdsiNLvEgAImu-g\u0026amp;start=1751\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**29:42** Cách dùng cũng đơn giản thôi. Prep này, mình chỉ cần nhét những đoạn code cần evaluate tại compile-time vào trong hàm prep là được. Như mọi người thấy ở đây, ví dụ như tính toán Fibonacci. Đối với những con số nhỏ thì đơn giản, nhưng khi con số lớn lên thì tính toán sẽ lâu hơn. Nhưng khi dùng `prep`, những con số lớn sẽ được tính toán nhanh hơn nhiều. Ngoài ra, khi build, mình sẽ cần dùng một cái lệnh như thế này (chỉ vào màn hình), lệnh này là để run cái tool `prep` luôn tại compile-time.\n\n**30:25** Tuy nhiên, có một số giới hạn của thằng tool này. Thứ nhất, nó chỉ hỗ trợ các giá trị mà mình có thể xác định được tại compile-time, và những giá trị đó phải nằm trong cùng scope với hàm prep. Ngoài ra, không thể sử dụng tool này cho các thao tác IO vì nó là compile-time, không hợp lý để xử lý IO operations trong compile-time.\n\n**31:15** Zero này nó là một cái runtime library. Nó claim là nó database compatible, xài nó cũng đơn giản thôi. Mọi người cứ import vào rồi xài thôi. Ví dụ như đây là một cái ví dụ mà nó compatible với thằng database relational cơ bản, thì nó claim là nó sẽ free cho. Ok, mọi người cũng ngại import những cái thằng mà xài kiểu SD. Dạ chắc vậy. Mọi người có câu hỏi gì không? Ok, không có thì tiếp tục nhé.\n\n**32:18** Dạ đúng rồi, bài này em check là nó nằm khoảng 4 ngày trước đúng không ta? Anh thấy cái Go với lại kia khoảng 4 ngày trước. Dạ đúng rồi, trong tuần đó anh. Dạ, có thêm cái này hôm bữa nữa. Cái bài về lm power Go này mình chưa có điểm qua phải không? Phép có rồi mà anh, nhưng không nhớ rõ nó nằm ở kỳ mấy nữa. Để em search lại cái. Rồi trên đây nó có một số bài mà chắc team mình sẽ quan tâm, không biết nó như thế nào. Cái bài là bài này nè, trong nguyên cái dàn list á, có một cái list được thả up rất là nhiều. Khứa này nó dùng Go mà nó dev web, thì nó ra được khoảng đâu 22 cái note của nó về việc dùng Go để code web.\n\n**33:07** Thì bài này không biết em check chưa, nhưng cộng đồng nó up vote cái này rất là nhiều. Dạ chắc là anh. Nó kiểu như là mấy cái nốt mà thông qua mấy cái release version, nó thấy cái nào technote hữu ích thì nó up lên. Em nghĩ nhiều người sẽ nhìn thấy và quan tâm. Ok, giống như là anh thấy mấy cái bạn điểm qua version rất là cũ của Google luôn.\n\n**33:49** Dạ, đúng rồi. Sau đó nó check out mấy cái win, mấy cái gì đó hay ho của những cái version đó của Go. Ok, bài tổng hợp này là mới đúng không ta? Dạ đúng rồi, bài tổng hợp này mới. Ông này tự tổng hợp lại theo cái list của ổng thay vì lên awesome Go, ổng tự làm list. Xong rồi bên dưới thì bán khoá học. Ok, chắc là bài này cũng uy tín. Chắc lấy bài này track lại, hôm qua mới lấy cái bài cũ đăng lên lại. Anh thấy cộng đồng đang pick up dần, nếu khéo chắc sẽ track thêm.\n\n**34:32** Dạ, đúng rồi. Với lại anh Hiếu có xem cái bài này, vô tình em cũng đọc được. Ảnh bảo là bên Go có một cái repo để mọi người tham khảo, kiểu microservice cũng ok lắm, tên gì đó luôn. Để em search lại cái link rồi gửi cho mọi người nhé.\n\n**36:32 H**ôm nay em sẽ giới thiệu về một cái dự án em làm cách đây gần hai tháng. Đó là một bài liên kết với system AI. Khi mà cái task nó quá lớn, quá nhiều subtask, mọi người phải chia ra thành từng module riêng lẻ, thì sẽ có một con router ở giữa. Nó sẽ nhận request từ user, rồi phân chia tới từng module con. Bài này sẽ giới thiệu cách mà em evaluate cái system này.\n\n**37:10** Có một phương pháp mà team em đang làm là sẽ dùng một simulation con, gọi là simulated user, để tương tác với các module. Sau đó, sẽ có một con evaluator đánh giá thông qua cuộc hội thoại này dựa trên các tiêu chí mà mình tự định nghĩa. Ví dụ như em test thử một simulation cho một công ty hàng không, khách hàng muốn refund lại vé, thì mình tạo simulation cho khách hàng đó. Cuộc hội thoại hoàn toàn giữa các con AI với nhau, có thể thấy là mới vào sẽ có các lời chào hỏi, giới thiệu, request từ khách hàng, và AI sẽ gọi qua các module worker, làm việc với các module khác nhau. Sau đó, nó sẽ trả về kết quả cuối cùng và con evaluator sẽ đánh giá xem cuộc hội thoại này có đạt yêu cầu hay không.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/AhehaT_PK84?si=rIMEVKw521g2rZ_B\u0026amp;start=2196\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**37:56** Ví dụ như em dùng một metric là binary thôi, 0 hoặc 1. 0 là user không được refund, 1 là user được refund. Sau đó, evaluator sẽ đánh giá dựa trên các tiêu chí mà mình đã đặt ra. Em có test thử một bộ sinh thái của Langchain để chạy thử, dùng OpenAI để chạy qua. Khi kết thúc, kết quả sẽ được đưa ra, và mình sẽ đánh giá xem các bước có đúng với mục tiêu hay không.\n\n**38:41** Đây là một ví dụ thành công. Simulation chạy qua, module ticket office xử lý và trả kết quả về cho user. Từ đó, mình có thể xem và đánh giá các bước trong quá trình này. Nếu cần, mình có thể optimize lại luồng hoặc workflow. Đây là một phương pháp để mọi người evaluate một chatbot hoặc một agent.\n\n**39:33** Mọi người có câu hỏi gì không? Đại loại là mình sẽ dùng một con agent hoặc multi-agent để simulate conversation với một con chatbot. Sau đó, evaluator sẽ đánh giá kết quả của toàn bộ cuộc hội thoại. Ví dụ như trong một test case, mọi người sẽ có những input mong muốn. Simulation user sẽ đưa những input đó vào cuộc hội thoại với chatbot, và khi hoàn tất, evaluator sẽ đánh giá xem kết quả có đạt yêu cầu không.\n\n**40:35** Ví dụ là mình dùng ba con agent tổng cộng. Một con simulation user, một con chatbot, và một con evaluator để đánh giá. Langchain hỗ trợ luôn cả việc xây dựng một graph để tổ chức các cuộc hội thoại. Ví dụ user tương tác với chatbot, và khi kết thúc, evaluator sẽ kiểm tra lại toàn bộ quá trình hội thoại. Mọi thứ đều có thể define trong evaluator, ví dụ như check số lượng tool đã sử dụng, hoặc xem có công cụ nào bị gọi hai lần hay không.\n\n**42:07** Giống như automation test case đúng không? Đúng rồi, mình define những test case, rồi assign các tag cho từng con agent. Ví dụ test này để pass, test kia để fail, có những tag khác nhau tuỳ vào từng tình huống. Đạt có nói về việc define expected output cuối cùng, và quá trình thì tự generate. Khi chạy qua các tool, nó sẽ kiểm tra xem tool có sử dụng đúng cách hay không, có chạy đúng số lượng tool đã định trước không.\n\n**43:25** Mọi thứ đều có thể define trong evaluator ở cuối cùng để kiểm tra. Giả sử mình muốn hard-code một bộ test case thì cũng được. Ý là mình define conversation để book một cái ticket chẳng hạn, rồi kiểm tra xem có đủ step để đến thành công không, có step nào dẫn đến fail không. Tất cả đều có thể định nghĩa sẵn.\n\n**44:05** Khi mình hard-code nguyên một luồng như vậy, mình có thể theo dõi từng bước. Nhưng với approach này, mọi thứ đều có thể tự chạy và kiểm tra theo quá trình. Mọi người có thể define những metric để đánh giá conversation, như correctness hay accuracy, để biết agent có hoạt động đúng không. Đây là một cách để chạy test toàn diện cho agent.\n\n**45:31** Còn một bài nữa mà em kết hợp chung với bài này. Mọi người thấy con agent sẽ xử lý như thế này, qua nhiều bước khác nhau trong quá trình hội thoại. Cái này lấy từ hai ví dụ collaboration trước, nhưng nó specific cho case của tụi mình. Cả quá trình sẽ được đánh giá qua ba architecture nhỏ kết hợp lại, với một con router đứng giữa. Router sẽ route request tới những con nhỏ hơn dựa vào yêu cầu của user, rồi sẽ trả về kết quả.\n\n**46:40** Đó là một cách để xử lý, mọi người có thể nhìn vào đây để thấy cách nó vận hành. Cả quá trình đều có thể được đánh giá qua từng bước. Nếu cần build một bộ test trong app thực tế, thì approach này vẫn có thể áp dụng.\n\n**47:50** Ok, tiếp theo Hoàng trả lại diễn đàn cho Tom. Hình như mấy cái bài của Tom đều đã đại khái xong hết rồi, đúng không Tom? Mới form một chút thôi, nhưng tôi phải chạy script để update lại mấy cái link ảnh ấy. Nó có vẻ hơi nhiều ảnh nhỉ. Ok, share tiếp về case study nhé.\n\n**49:39** Mọi người vào link Figma này để nhìn cho rõ nhé, xem màn hình thì nó bị bể. Được rồi, trước khi share, mình có cần phải sensor cái gì không ta? Có dính NDA gì không? Hay là bài này bình thường thôi? Không dính vấn đề gì cả, đây là một case study về dự án đầu tiên mà team designer bắt đầu áp dụng AI, chủ yếu hỗ trợ trong quá trình nghiên cứu UX.\n\n**50:36** Kafi thì Kafi là công ty hồi xưa. Trước đây nó có một tên khác, nhưng mà trước đây thì nó mờ nhạt trên thị trường. Sau cái năm 2022 thì nó có một cái chuyển đổi về nhân sự nên là nó đổi tên thành Kafi. Từ đó,  bắt đầu tái cơ cấu, và sau năm 2024 thì Kafi ghi nhận được một số lợi nhuận cao, kinh doanh vô cùng ấn tượng. Họ đã sử dụng nguồn lợi nhuận này để bắt đầu phát triển và nâng cấp hai ứng dụng là Kafi Trade và Kafi Wealth, với mục tiêu phát triển và mở rộng chiến lược kinh doanh và thị trường. Họ đã tìm đến bên Dwarves Foundation để đầu tư vào việc nghiên cứu người dùng và các công nghệ.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/AhehaT_PK84?si=d4w1jusl537bKAU5\u0026amp;start=3015\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**51:30** Về thách thức chính của ứng dụng Kafi hiện tại, đó là trải nghiệm người dùng chưa đáp ứng được nhu cầu của một nhóm người dùng đa dạng. Tưởng tượng như một ứng dụng đầu tư, nhưng khi người dùng tiếp cận thì lại không đáp ứng đúng nhu cầu của họ. Điều này đặt ra một thách thức, từ đó Kafi bắt đầu nghiên cứu về trải nghiệm người dùng để đáp ứng nhiều nhu cầu khác nhau của khách hàng. Vì vậy, nhóm đã đặt ra câu hỏi là: \"Chúng ta phải làm gì tiếp theo?\" Mục tiêu chính là tạo ra một ứng dụng đáp ứng kỳ vọng và mang lại giá trị thực sự cho các nhà đầu tư.\n\n**52:19** Quá trình này không hề dễ dàng bởi vì nhóm không chỉ cải thiện một ứng dụng mà còn mang đến một triết lý, đó là xây dựng một công cụ có thể thay đổi cách mọi người tiếp cận với việc đầu tư. Ở đây, em chia quá trình nghiên cứu để hiểu người dùng thành ba giai đoạn: empathize (đồng cảm và hiểu nhu cầu người dùng), lập kế hoạch và thiết kế. Đầu tiên là empathize, trong giai đoạn này nhóm bắt đầu thực sự hiểu được những gì mà khách hàng mong muốn và kỳ vọng.\n\n**53:07** Ba câu hỏi chính mà nhóm muốn trả lời trong giai đoạn đầu của dự án là: Những khó khăn và pain point hiện tại của người dùng là gì? Họ thực sự muốn gì? Và họ cần gì? Sau đó nhóm tiến hành nghiên cứu chuyên sâu để bóc tách những vấn đề này. Trong đó có phương pháp kiểm tra khả năng sử dụng (usability testing). Ở đây, nhóm trực tiếp sử dụng ứng dụng để hiểu sâu và nắm bắt các chi tiết mà phương pháp khác khó phát hiện được, ví dụ như cảm xúc và suy nghĩ của người dùng khi tương tác với ứng dụng.\n\n**53:54** Ngoài ra, nhóm cũng điều tra các diễn đàn và cộng đồng như Reddit hoặc Facebook để nắm bắt hành vi và những yếu tố tiềm ẩn trong thị trường chứng khoán mà Kafi chưa kịp nắm bắt. Trong quá trình nghiên cứu, nhóm cũng sử dụng AI để nghiên cứu thị trường và phân tích đối thủ, sử dụng SWOT để hiểu rõ về sản phẩm hiện có trên thị trường, ví dụ như nghiên cứu điểm mạnh và điểm yếu của các sản phẩm đó.\n\n**55:29** Sau khi hoàn thành tất cả các nghiên cứu sơ cấp và thu thập dữ liệu, nhóm chuyển sang giai đoạn khái niệm hóa dự án. Giai đoạn này bao gồm việc phân tích thông tin đã thu thập và thực sự hiểu sâu về nó. Tiếp theo là giai đoạn lập kế hoạch dự án. Sau khi thu thập tất cả các dữ liệu sơ cấp từ đối thủ cạnh tranh, AI, và khảo sát, nhóm ưu tiên hình thành các chiến lược cho trải nghiệm người dùng thực tế.\n\n**56:18** Nhóm bắt đầu hiểu rõ về mong muốn và nhu cầu của khách hàng. Sau đó, nhóm phân loại thông tin thu thập được và sắp xếp chúng theo thứ tự ưu tiên. Nhóm trình bày các phát hiện này cho team Kafi để cùng hình thành các chiến lược dựa trên dữ liệu thực tế và đồng ý với các vấn đề đã được phát hiện. Tiếp theo là giai đoạn nghiên cứu thứ cấp, một giai đoạn nghiên cứu sâu hơn về chiến lược sản phẩm.\n\n**57:08** Có ba giai đoạn chính: xây dựng personas, mapping ưu tiên và pain point. Từ đó, nhóm sẽ hiểu rõ hơn về lộ trình sản phẩm và xác định các tính năng cần có trong phiên bản thứ hai. Sau đó, nhóm sẽ trình bày các insight này cho khách hàng. Bước đầu tiên là xây dựng personas, tức là tạo ra đại diện cho phân khúc khách hàng dựa trên các yếu tố như độ tuổi, kinh nghiệm đầu tư, mục tiêu tài chính và mức độ chấp nhận rủi ro của họ.\n\n**57:57** Sau khi xác định được personas, nhóm sẽ tiến hành phân tích sâu hơn về hành vi bằng cách xây dựng một journey map để hiểu rõ hành vi của người dùng. Điều này bao gồm các điểm chính như nghiên cứu cách họ tương tác với các tính năng, tần suất sử dụng, và các yếu tố ảnh hưởng đến quyết định đầu tư của họ. Tiếp theo, nhóm tập trung vào việc xác định nhu cầu ưu tiên của từng đối tượng khách hàng.\n\n**58:49** Ví dụ, nhà đầu tư mới cần nhiều hướng dẫn và công cụ học tập hơn, trong khi các nhà giao dịch chuyên nghiệp có thể ưu tiên các công cụ phân tích để nâng cao khả năng thực hiện giao dịch thành công. Cuối cùng, dựa trên kết quả phân tích dữ liệu và triết lý của Kafi – xây dựng ước mơ tài chính – nhóm quyết định tập trung vào hai đối tượng chính: new trader và professional trader (hay còn gọi là newbie trader và day trader).\n\n**59:31** Từ đó, nhóm rút ra kết luận quan trọng là cần định hình lại cách tiếp cận giao dịch chứng khoán. Các kết luận bao gồm việc giúp nhà đầu tư mới vượt qua các rào cản kiến thức, đáp ứng nhu cầu về tốc độ và chính xác cho các nhà giao dịch chuyên nghiệp, và giải quyết các vấn đề liên quan đến bảo mật và quản lý rủi ro. Cuộc nghiên cứu này cũng chỉ ra rằng các nhà giao dịch có xu hướng sử dụng ứng dụng di động như một công cụ hỗ trợ, để theo dõi biến động thị trường, cập nhật tin tức nhanh chóng, và kiểm tra số dư tài sản.\n\n**01:00:15** Sau khi hoàn thành quá trình nghiên cứu, nhóm và Kafi đã thống nhất được một số giải pháp chính. Ba vấn đề chính mà nhóm xác định được là sự phức tạp đối với nhà đầu tư mới, quy trình onboarding khó khăn, và nhu cầu đa dạng của các nhóm đối tượng khác nhau.\n\n**01:01:10** Để giải quyết từng vấn đề này, nhóm phát triển ba giải pháp chính. Các giải pháp này được thiết kế dựa trên những hiểu biết sâu sắc từ nghiên cứu người dùng và phân tích thị trường. Giải pháp đầu tiên là giúp đỡ các nhà đầu tư mới, vì đầu tư là một lĩnh vực phức tạp, đặc biệt là đối với người mới bắt đầu. Cafi được thiết kế trở thành một người hướng dẫn đáng tin cậy, sử dụng công cụ hỗ trợ Contextual Help (trợ giúp ngữ cảnh).\n\n**01:01:49** Ví dụ, trong một biểu đồ giá phức tạp, sẽ có một biểu tượng nhỏ xuất hiện ở góc màn hình. Khi người dùng chạm vào biểu tượng này, một trợ giúp tương tác sẽ xuất hiện, giải thích các khái niệm như khối lượng giao dịch là gì, giá đóng cửa là gì. Nó cũng cung cấp các mẹo để đọc biểu đồ, chẳng hạn như biểu đồ nến.\n\n**01:02:36** Phép tìm hiểu sâu về các kỹ thuật và các chỉ số kỹ thuật. Tất cả đều sẽ hiển thị trong một màn hình. Cuối cùng là việc cải thiện giao diện người dùng bằng cách áp dụng nguyên tắc \"Less is More\" bằng cách tạo ra một giao diện tối giản, hiện đại và khoa học. Mỗi yếu tố trên màn hình đều có một mục đích cụ thể để giúp người dùng thực hiện giao dịch nhanh chóng và hiệu quả, làm cho các nhà giao dịch mới không cảm thấy choáng ngợp trước khối lượng thông tin lớn.\n\n**01:03:21** Với giải pháp thứ hai, nhóm tập trung vào việc cải thiện từng bước trong quy trình onboarding, giúp người dùng dễ dàng hơn. Trước đây, nhóm nhận thấy ứng dụng Cafi gặp khó khăn với tỷ lệ người dùng bỏ cuộc trong quá trình đăng ký. Nguyên nhân chính là do quy trình đăng ký và xác minh danh tính điện tử (eKYC) phức tạp, khiến người dùng nản lòng vì phải cung cấp quá nhiều thông tin. Để khắc phục vấn đề này, nhóm đã tối ưu hóa quy trình onboarding bằng cách chia nhỏ quá trình đăng ký thành các bước ngắn gọn, chỉ yêu cầu đủ thông tin ở mỗi bước.\n\n**01:04:06** Ngoài ra, nhóm còn cho phép người dùng khám phá ứng dụng trước khi hoàn tất đăng ký để tạo cảm giác thoải mái, không bị áp lực phải cung cấp quá nhiều thông tin ngay lập tức. Khi người dùng đã tạo tài khoản xong, nhóm cũng hướng dẫn từng bước về xác minh, theo dõi danh mục và đặt lệnh một cách trực quan, tích hợp thanh tiến độ để giúp người dùng dễ dàng theo dõi quá trình. Cách tiếp cận này không chỉ đơn giản hóa quy trình mà còn tạo ra trải nghiệm phù hợp với nhu cầu cá nhân của từng đối tượng khách hàng.\n\n**01:04:48** Giải pháp thứ ba là thiết kế công cụ tùy theo từng đối tượng người dùng. Các nhà đầu tư có nhu cầu sử dụng công cụ hỗ trợ khác nhau tùy theo mức độ kinh nghiệm. Khi nền tảng web có thể linh hoạt trong việc bố trí các tính năng, thì thiết kế giao diện trên điện thoại lại bị hạn chế hơn. Vấn đề đặt ra là làm sao để cung cấp đủ công cụ cho các nhà đầu tư chuyên nghiệp mà không làm khó khăn cho người dùng mới. Giải pháp của nhóm là áp dụng hệ thống phân loại người dùng. Sau khi hoàn tất đăng ký, người dùng sẽ được chia thành các nhóm như mới bắt đầu, trung cấp và chuyên nghiệp. Mỗi nhóm sẽ nhận được trải nghiệm phù hợp với mức độ hiểu biết và mục tiêu đầu tư của họ.\n\n**01:05:24** Ví dụ, người mới có thể tiếp cận các bài học cơ bản, trong khi nhà đầu tư chuyên nghiệp sẽ được cung cấp các công cụ phân tích chuyên sâu. Cách tiếp cận này không chỉ cải thiện trải nghiệm người dùng mà còn thúc đẩy sự phát triển của nền tảng Kafi bằng cách cung cấp nội dung và công cụ phù hợp với từng giai đoạn phát triển của người dùng. Kafi sẽ trở thành một môi trường học tập và đầu tư năng động, phục vụ cho cả người mới và những nhà đầu tư dày dặn kinh nghiệm.\n\n**01:06:00** Kết quả sau case study của Kafi cho thấy rằng, có rất nhiều cách để giải quyết những vấn đề mà các ứng dụng chứng khoán đang đối mặt. Tuy nhiên, quan trọng nhất vẫn là hiểu rõ nhu cầu của khách hàng. Nếu một công ty đang phục vụ nhiều nhóm đối tượng người dùng khác nhau, thì việc thu thập và phân tích nhu cầu đa dạng của họ là rất quan trọng. Sau đó, cần sắp xếp thứ tự ưu tiên để đáp ứng nhu cầu phù hợp với từng đối tượng.\n\n**01:06:43** Ở đây có một số phương pháp hiệu quả để khám phá và hiểu nhu cầu khách hàng, bao gồm khảo sát bằng câu hỏi đóng mở để thu thập thông tin, xây dựng personas để tạo các đại diện người dùng, xác định mục tiêu, hành vi và khó khăn của họ. Phân tích đối thủ cạnh tranh cũng là một phương pháp, sử dụng các công cụ phân tích để đánh giá sản phẩm của đối thủ, từ đó nhìn ra điểm mạnh và yếu của họ.\n\n**01:07:26** Ngoài ra, AI có thể được kết hợp vào quá trình nghiên cứu người dùng, giúp xử lý một khối lượng thông tin lớn từ các đối thủ cạnh tranh hoặc từ dữ liệu thu thập được trong quá trình khảo sát và phỏng vấn người dùng. AI có thể phân tích tất cả các dữ liệu đó và tạo ra những personas cho từng nhóm người dùng. Từ đó, chúng ta có thể tìm ra các giải pháp phù hợp với nhu cầu của từng tập khách hàng.\n\n**01:08:08** Em xin hết. Mọi người có câu hỏi gì không? Thật ra mấy cái này cũng không rút gọn được vì áp dụng hết luôn. Không có rút gọn được. Đúng rồi, cực lắm. Ai không có giọng rung rung sợ sợ vậy đâu. Personal của em là gì, của một designer là gì?\n\n**01:09:52** Personal hả? Thì đó, giống như em nói, từ khi có AI thì việc nghiên cứu user trở nên nhẹ nhàng hơn. Không còn phải đi khảo sát, đi hỏi, đi phỏng vấn quá nhiều user. Có nhiều người bên ngoài mỗi ngày phải gọi điện phỏng vấn mười mấy người. Chị có xài cafe để làm research không? Em có xài cafe để làm research là sao? Mình phải bớt lại chị, phỏng vấn personas của bên mình, thì em chat với cả ChatGPT.\n\n**01:11:08** Ừ, personas thật ra khi hỏi AI về personas nó sẽ cho anh một nùi luôn. Rất nhiều thứ. Vấn đề chính là AI không giúp lên kế hoạch ưu tiên các vấn đề, mà chỉ giúp mình tìm ra những personas ban đầu thôi. Từ đó mình phải dựa vào kinh nghiệm và những cuộc phỏng vấn người dùng thực tế, rồi mới phân tích và nhóm lại các personas cho đúng. Nếu không thì AI sẽ đưa ra quá nhiều personas.\n\n**01:11:56** Kafi chỉ là tham khảo mấy cái của đối thủ cạnh tranh thôi. Ok, anh không có câu hỏi gì nữa. Không biết có thu được giọng anh chưa. Nếu có phần nào thiếu thì gửi slide để xem sau.\n\n**01:13:25** Theo kịch bản là Tom sẽ có một cái bài cho anh em tên là *mixture of agents*, tức là cụm mấy cái agents nó ngồi lại với nhau xong rồi nó chạy multi-agent để ra kết quả, mà tạm thời bài đó có vẻ dễ, mọi người sẽ chưa đến lúc để nghe bài đó đâu. Anh đang nghĩ vậy nên skip bài đó nhé. Giờ có một thông báo quan trọng hơn về chuyện đi chơi và bài test.\n\n**01:14:09** Bài test sẽ có nội dung như sau: mấy anh em xem chuẩn bị trước là vừa. Thứ nhất là anh em sẽ viết hai bài luận. Tự viết, nào viết dở là sẽ bị chém ha. Hai bài luận, một bài luận đầu tiên là về văn hóa. Anh sẽ pick ra một trong bốn cụm văn hóa mà team mình đang theo đuổi, chắc xoay quanh hybrid working xong rồi các kiểu thôi nha. Mấy anh em sẽ viết một bài về cái đó. Câu hỏi thì anh sẽ đưa sau, nhưng giờ phổ biến trước, chắc cuối tuần sẽ release một cái về văn hóa, để mọi người đặt tay vào làm.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/AhehaT_PK84?si=jh0lgTRFw1oWMfgk\u0026amp;start=4462\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**01:14:52** Lý do để làm bài này là vì giai đoạn hiện tại, anh nghĩ mọi người cần cố gắng, phải tự set motivation cho mình để thích nghi với giai đoạn mới. Giai đoạn mới là giai đoạn của thị trường. Giai đoạn của công ty mình thì bình thường, không có gì hết, nhưng thị trường nó thay đổi, nên để phù hợp thì mọi người cần có lý do để refresh lại động lực của mình trong ngành này. Được ha. Sẽ có một bài luận cho mấy anh em về văn hóa.\n\n**01:15:36** Bài thứ hai, câu hỏi sẽ xoay quanh chuyện này. Anh chưa chốt câu hỏi chính xác là gì, nhưng nó sẽ nằm trong chuyện mà ứng dụng của lĩnh vực mà mấy anh em đang làm, nó đang được ứng dụng tới đâu rồi. Có thể gom lại thành một bài giống như *state of the app* của lĩnh vực mấy anh em đang làm, ở bên ngoài người ta đang triển khai như thế nào, thì đó là bài thứ hai.\n\n**01:16:18** Sample cho bài đó có thể nhìn như sau: không biết đây có không, nhưng sample thôi. Bên dev thì chắc dễ, nhưng bên kiểu làm sale, làm design, làm tester, làm PM, tất cả các roles liên quan. Mà Tom đang tính là nó sẽ cut hết mấy cái đó thành agents hết. Thật ra là mình sẽ biết nó sẽ cover được đâu đó 70-80% công việc, nhưng vẫn cần người đứng đằng sau để lái agents đó, thành ra là cũng sẽ tùy ý.\n\n**01:17:04** Ví dụ như bài này phải không? Để coi lại nha. Đúng rồi, thử coi, phải không? Có một số bài anh đang coi cách sử dụng AI như thế này. Có một số bài như vậy. Bên vật dev nó cũng cover một số, cũng không có nhiều lắm, nhưng đại ý là vậy nhé. Bài số hai sẽ là với mỗi role của mấy anh em trong công ty, mấy anh em đang cầm một cái role nhất định, thì cái role của mình, hiện tại là làm sao, chuyện sử dụng AI người ta đang xài như thế nào, đó là bài số hai nhé. Được ha.\n\n**01:17:42** Bài số ba sẽ liên quan tới chuyện thực hành. Đề thì chưa biết, tại vì nếu đưa chủ đề linh tinh quá thì mấy anh em lên ngồi chat với GPT nó cũng không có tác dụng gì lắm. Nên sẽ liên quan đến chuyện chạy thực tế, làm nghề, build software thôi, nên chuyện thực tế áp dụng cho mình sao để hiệu quả thì chắc anh sẽ nghĩ ra một cái đề. Có thể là một đề để submit, rồi mọi người dùng AI để assessment. Anh không có cổ súy hoàn toàn cho chuyện AI cover mọi thứ nhá. Tại vì thấy cách mọi người sử dụng rồi. Ví dụ như anh dùng mấy cái tool kia để ra cái script, thì nó cũng rất chung chung, không có thực tiễn và không có bài học rút ra.\n\n**01:18:16**Comment nhanh vậy thôi để mọi người thấy rằng chuyện sử dụng máy móc, làm rập khuôn thì nó rất là gà. Gà, mà biết dùng chữ gì cho đúng nữa? Nhưng nhìn nó chán, chán đời lắm. Rồi ha, bài số ba là ứng dụng nhé. Là chuyện của mình sau khi tìm hiểu rồi, thì bài thứ ba sẽ là ứng dụng.\n\n**01:18:58** Tiếp, hiện tại mọi người sẽ có lịch đi chơi, nếu mà đúng thì khoảng đầu tháng 12 mình sẽ có khoảng hai tháng để chuẩn bị. Mình sẽ cần chốt trước đó một tháng là ít nhất, nên mọi người có một tháng để làm thôi. Được ha. Nên những thứ mọi người cần submit là đây. Đây là gần như điều kiện cần cho chuyện mấy bạn đi chơi, và nó cũng là điều kiện đủ cho performance review cuối năm vào tháng 12 và tháng 1.\n\n**01:19:39** Hiện tại, anh đang expect những hoạt động của team mình sẽ được assess với AI ở mức độ mà mình kiểm soát được, đảm bảo cái đầu ra vẫn là cái mà mình mong muốn như trước giờ, chứ không phải là \"tại vì em dùng cái này, nên giờ kết quả nó ra như vậy, là tại anh bảo em dùng\". Được ha? Như đương dao tự đâm chân mình rồi đổ lỗi cho người khác, thì không được. Ok, đó là điều kiện cần để đi chơi, và điều kiện đủ để làm bài review.\n\n**01:20:14** Điều này quan trọng, vì lần này, bài review vào tháng 12, nếu bạn nào đi một vòng mà không làm được, thì khả năng cao là junior với fresher sẽ bay màu hết. Hôm qua có xem một cái bài rất buồn cười. Nó không được tuyển vào đâu hết, nên nó làm một cái game multiplayer, firm crash, sử dụng Go và TP. Nó đăng lên và sử dụng toán để làm animation. Comment rất là vui.\n\n**01:21:04** Review đợt tháng 12 sẽ là cái đó nhé. Đó là thông báo cuối cùng để anh em nắm. Message sẽ được release vào cuối tuần để mọi người chuẩn bị deadline để nộp, và chấm điểm cho Huy vào trước tuần thứ tư của tháng 11. Chắc tuần thứ tư của tháng 10 là mấy bạn còn ba tuần đó, đúng không? Đúng rồi, ha. Đây là thông báo. Mấy anh em không tham gia con thì cũng không quan trọng lắm.\n\n**01:21:55** Tiếp nữa, đó là cái list mà Tom đang làm một số phần ở đây. Anh chưa check hết, nhưng anh bắt đầu check từ từ xem là assess những gì. List pilot sao chậm quá nè. List khác, list khác, khác list bữa trước nói. Review nhanh qua cho mấy anh em thấy một chút. List này ha, Tôm đang làm. Anh thấy có một số bạn tham gia nè. Đây là tín hiệu rất tốt, cho thấy mọi người đã bắt đầu aware được sự thay đổi concept trong chuyện làm software.\n\n**01:22:42** Giờ nó xuất hiện thêm server, rồi cách làm data manipulation khác nhau, data collection khác nhau. Mọi thứ đều khác hết, nên là sẽ khác. Những phần reward đã gửi rồi xong. Còn phần Tom đang làm, để review. Đợi anh review, anh review của mấy bạn. Rồi Tom sẽ review tiếp những phần khác. Một số cái như Hiếu Vũ nữa. Hiếu Vũ có đây không? Nhưng mà chưa thấy update gì hết. Bắt đầu xin việc kiểu này là toang rồi.\n\n**01:23:15** Các bạn ơi, phải chủ động đi tìm đề tài để làm rồi ha. Đây là một cái list. Còn cái list khác đợi Tom finish, thì mình sẽ đi qua một cái list khác. Cái chủ đề *multi-agent*, khi nào mấy chủ đề kia thông qua hết? *Knowledge sharing*, grouping, *specific projection.*\n\n**01:24:07** Mấy cái *MapReduce*, team đang làm nè, collect data, build gom data lại rồi chạy cho nó. Thành đang làm con này nè, bữa trước đang kiến trúc, đang hơi quay. Tiếp theo là những chủ đề khác liên quan đến hệ thống cũ. Trước chỉ có server thôi, mà giờ có thêm agent, nên phải đưa dữ liệu qua cho tụi nó. Cấu trúc kiến trúc sẽ khác đi một tí. Khi nhận một cái đề bài, cấu trúc agent ra sao vẫn là chủ đề chưa bao giờ thảo luận kỹ với nhau.\n\n**01:25:12** Một số bạn đang setup dify, thấy có liên quan, nhưng mà nhiều câu hỏi về kiến trúc, về cấu trúc một hệ thống không chỉ có server mà có nhiều agent đứng dọc trong đó. Giống như bài Hoàng làm hồi nãy. Đó là một sample dễ, nhưng bài toán cụ thể thì cấu trúc server sẽ như thế nào? Đó là chủ đề thực tế thôi, phải làm. Nhắc lại vậy thôi, hiện tại nếu không quan tâm thì phần Tom đang viết chẳng có ý nghĩa gì lắm. Chúng ta đang bị tụt lại rất xa trong kiến thức này.\n\n**01:25:39** Anh nghĩ cụm kiến thức này sẽ thành foundation cho software engineer. Không phải là kiến thức blockchain, không cần ai cũng phải biết. Nhưng phần này phải biết. Quan trọng là phải biết cách chia bài toán ra sao, để có logic chart trong đầu. Nếu không chia được thì đang gà. Nhẹ nhàng vậy ha.\n\n**01:26:17** Đó là toàn bộ message. Muốn tranh thủ cho anh em biết định hướng và expectation đang di chuyển theo hướng đó nha. Cuối tuần này sẽ có đề bài để viết hai bài luận, một bài report và một bài case study nhé. Nếu không còn gì thêm thì chắc là gg.\n\n**01:26:53** Tạm biệt anh em, hẹn gặp lại. Hy vọng hôm nay mấy chủ đề recap lại vẫn có giá trị. Sau khi có kiến thức đầy đủ hơn thì sẽ tiếp tục chủ đề hệ thống mới. Còn hiện tại, tất cả hệ thống mọi người đang build vẫn còn trong cái group cũ. Nghĩa là cũ với bên ngoài, chưa đến đó. Nhưng đi trước biết trước thì tốt hơn ha. Rồi ok, vậy ha. Mọi người xem thử còn câu hỏi gì không?\n\n**01:27:44** Chắc không có gì thêm, kết thúc nhé. Đúng rồi, cái này phải chat với team mình. Hôm qua thằng Đạt nó một cái clip lên này. Mình cảm thấy mình đi sau xã hội rất nhiều luôn. Đạt đâu nhỉ? Nó là clip của mấy anh Việt Nam ngồi automate với cái gì đó. Tiêu rồi. Biết kênh nào không?\n\n**01:28:42** Rồi, chắc vậy. Kênh đó random nhỉ? Hiện tại mọi người còn upset về việc học sâu như cũ. Học kiến trúc này kiến trúc nọ. Nhưng automate ở mức độ này thì phải ứng dụng nhiều hơn. Tất cả các app doanh nghiệp hay app bình thường sẽ nằm trong scope như vậy. Nếu build up dễ thì nó cover hết các trường hợp và làm rất nhanh. Nếu build up khó thì mấy anh em còn chưa biết mấy cái dễ nữa thì khó.\n\n**01:29:22** Hy vọng mỗi buổi thứ sáu mình học thêm được một cái gì mới. Hẹn gặp mọi người ở OGIF tuần sau.\n\n---\n\n**English Transcript**\n\n**00:00** Today we have a few topics on Go commentary, and there will be a product design commentary from Nam. After that, there will be some sections related to evaluating chatbots and technical details on how to build a chatbot by Hoang and Tom. They will probably share a bit about microservices architecture. If we have time, there will be a case study on a crypto finance project by Anna.\n\n**08:47** Nam Bui is up, but I haven’t seen his work completed yet... Okay, share your screen when you're ready.\n\n**10:31** Can everyone see the screen? Great, let's continue from last week's product design presentation. This week, I will discuss two topics, starting with the Sparkle icon. The Sparkle icon is probably quite familiar to everyone. If you’ve seen this icon before, press 1 for me. This icon is used across multiple apps, and today I’ll introduce a few of those apps.\n\n**11:30** First is the Plane Finder app, which uses this icon to show new blog posts. The second app is Ulta, an e-commerce app specializing in clothing and cosmetics. It uses the Sparkle icon for the Discover feature. You’re probably more familiar with the third app, Google Meet, which uses this icon for removing the background and adding a new one.\n\n**12:14** So we have three apps using the Sparkle icon, and there are more apps utilizing it. The Sparkle icon isn’t just for one specific feature; it’s becoming quite common. As AI technology emerged, it started incorporating this icon heavily. For example, Figma uses the icon for the AI generator. Other apps, like Miro (for drawing diagrams or wireframes), also use it.\n\n**12:59** Another example is Dovetail, which uses the icon to generate meeting summaries. Most AI apps are now adopting this icon. Finally, the Nylas app has integrated the Sparkle icon as its primary interface symbol. This has made users associate the Sparkle icon with AI features, making it a symbol for AI.\n\n**13:45** Before showing AI interfaces, I shared some examples of how this icon is used in other apps for various features, demonstrating that the Sparkle icon isn’t limited to just one function but can support multiple ones. To use the icon effectively, I think we should display a tooltip when hovering over it to explain the feature, or show the feature name underneath the icon. Generally, using the Sparkle icon or other generic icons requires tooltips or feature names to avoid user confusion.\n\n**14:31** Now, I’ll move on to the second topic, which discusses onboarding new users for AI. I’ll compare different apps and share best practices for onboarding new users who are just logging in or exploring a new AI tool.\n\n**15:26** Here we have a famous app from China called SparekDesk. When users first enter the app, they are presented with a list of questions and tutorials to help them explore the app. On the other hand, ChatGPT doesn’t need such a list, as users can immediately start by typing a question to test its capabilities.\n\n**16:10** Instead of providing a list of guiding questions, users often begin with ChatGPT by asking something like “Can you...?” to test what it can do. This makes onboarding with ChatGPT more effective than going through lengthy documentation.\n\n**17:09** Another example is the App Store, where users can see categories like Productivity to display app features. On the left side, it shows Productivity, while on the right side, it displays search results and the app’s key features. This makes it easier for users to understand the app before downloading it.\n\n**18:02** I think each character creates a different set of questions, which can confuse users as they have to decide which one to choose. Meanwhile, this software offers concise tooltips for users without lengthy onboarding steps. The key takeaway here is that we should eliminate unnecessary steps for users instead of overwhelming them with too many.\n\n**18:58** For example, the app on the left gives users very specific, detailed questions, while the one on the right offers general questions without relating to any specific situation. In my opinion, general questions are more effective because overly specific questions often don’t match users’ actual needs. Thus, I think detailed questions are redundant in the onboarding process. In contrast, ChatGPT’s general questions have a higher chance of aligning with users’ expectations.\n\n**19:44** From these four examples, I conclude: First, we should limit giving users too many detailed questions and instead let them ask directly what they want. Second, we should clearly define the scope of features right from the start, to set user expectations. Otherwise, they might get frustrated and delete the app if it doesn’t meet their needs. Third, we need to remove unnecessary onboarding steps to optimize user time. Lastly, we should present general questions rather than overly specific ones.\n\n**20:33** That’s it for me. If you have any questions, feel free to leave comments. But I think the comparison here raises a point: Do these apps target the same task? Because in some cases, specific questions might still be useful depending on the situation. It’s not always ideal to present random questions, as ChatGPT is more of a general-purpose chat tool, whereas other chat interfaces are more specific to certain tasks.\n\n**21:26** But what I was talking about here is also a generic chat tool like ChatGPT, not for any specific task. Yes, that’s why I compared two generic chat tools side by side.\n\n**22:09** Yes, exactly as you said. A specific app might need more specific questions, but in this case, I’m only comparing two general-purpose chat tools.\n\n**23:07** Got it. Any more questions? Feel free to ask. Now let's move to the next topic. This time we have two articles about AI: one about the misunderstanding of the Sparkle icon and the other about best practices for onboarding new AI users. Does anyone have questions about the Sparkle icon?\n\n**23:58** Actually, now most AI apps have mic-like icons and other symbols that make it easy to recognize AI features. Agreed. As for onboarding, I feel like it’s a bit tricky. The goal of onboarding is to give users a starting point to explore the app, not something for long-term use. This type of onboarding is specifically for new users only.\n\n**25:10** I’ve sent a link for further reading. This article summarizes new AI-supported interfaces. Recently, there have been many cool new chat apps with great features and UI. This morning, I noticed ChatGPT added a Canvas feature, with a pop-up to scroll through artifacts from CR. If you’re interested, feel free to check it out. Okay, thanks. Alright, let’s continue. Ok, I’m done. Bye, everyone.\n\n**26:42** This week, I’ve got two articles to share, nothing too complicated. The first one is about Prep, which is a tool for compile-time evaluation. It enables compile-time evaluation, allowing the process to happen during compile-time instead of runtime.\n\n**29:11** So, does everyone know what compile-time evaluation is? Normally, the values we assign to variables or functions are evaluated at runtime, but this tool helps convert those calculations to compile-time. This boosts performance, especially for computationally heavy tasks. For example, calculating large Fibonacci numbers at compile-time is much faster than doing it at runtime.\n\n**29:42** It’s simple to use. You just place the code that needs compile-time evaluation inside the `prep` function. As you can see here (pointing to the screen), Fibonacci calculations for small numbers are straightforward, but as the numbers grow, it gets slower. By using `prep`, larger numbers are calculated much faster. When building the code, you need to use a command like this to execute the `prep` tool during compile-time.\n\n**30:25** However, there are some limitations. First, it only supports values that can be determined at compile-time, and those values must be in the same scope as the `prep` function. Additionally, you cannot use it for IO operations because they don’t make sense at compile-time.\n\n**31:15** Zero is a runtime library. It claims to be database compatible. It’s also simple to use. You just import it and start using it, like in this example here, which shows compatibility with a basic relational database. It claims to be free. Ok, any questions? If not, let’s move on.\n\n**32:18** Right, this article I checked was posted about four days ago, correct? I saw that Go thing was also from about four days ago. Yes, that’s right, during that week. And I also have something else from the other day. The article on lm power Go, did we go over that yet? I’m not sure, but I think we did. Let me search for it. Anyway, there are some articles here that I think the team will be interested in. This one here, for example, got a lot of upvotes. The guy used Go to develop a web app, and it produced around 22 notes on how to use Go for web development.\n\n**33:07** I’m not sure if you’ve checked it, but the community has upvoted this a lot. Yes, I think I did. It’s like these notes came from various release versions. It highlights useful technical notes, which is why it’s getting attention. Ok, it’s like they pointed out old versions from Google, right?\n\n**33:49** Yes, exactly. Then they check out the wins and cool features of those older Go versions. Ok, is this summary new? Yes, it’s a new one. Instead of relying on Awesome Go, this guy made his own list. Underneath, there’s a link to his paid course. Ok, seems legit. We’ll track this article again. I picked up an older article yesterday, reposted it, and saw the community is slowly picking up on it. If we’re smart about it, we’ll track more.\n\n**34:32** Yes, and I read the article Hiếu pointed out too. He mentioned a Go repo where people can find microservice examples, and it looks pretty good. I’ll search for the link and send it to everyone.\n\n**36:32** Today I’ll introduce a project I worked on about two months ago. It’s a system AI project. When the task becomes too large with too many subtasks, you need to break it into individual modules with a router in the middle. This router receives user requests and forwards them to the relevant submodules. Today’s article will explain how I evaluated this system.\n\n**37:10** One method we used was a simulated user to interact with the modules. Then, an evaluator would assess the conversation based on criteria we defined. For example, I simulated a scenario with an airline customer wanting a refund for their ticket. The entire conversation happens between AI agents, and you can see from the chat that it starts with greetings and introductions, followed by the refund request. The AI then calls different modules to handle each part of the process. After the final response, the evaluator checks whether the process met the refund criteria.\n\n**37:56** In this case, I used a binary metric, 0 for no refund, 1 for successful refund. Then, the evaluator reasons through the conversation and provides the result. I used Langchain’s ecosystem to test this. Everything worked smoothly with OpenAI. The evaluator looks at whether the necessary steps were taken to meet the goal.\n\n**38:41** Here’s an example of a successful simulation. The ticket office module processed the request and returned the result to the user. This way, we can assess and optimize the workflow if needed. It’s a method for evaluating chatbot agents.\n\n**39:33** Any questions? Basically, you simulate a user-agent conversation, and the evaluator assesses the final result. For instance, in a test case, you input what you want the simulated user to say. Then, it interacts with the chatbot, and the evaluator reviews the result to see if it meets the expected outcome.\n\n**40:35** For example, we’re using three agents here: one simulated user, one chatbot, and one evaluator. Langchain supports building a graph to organize the conversations. For instance, the user interacts with the chatbot, and at the end, the evaluator checks the conversation. The evaluator can define things like checking the number of tools used, ensuring no tool was called twice, etc.\n\n**42:07** It’s like an automation test case, right? Exactly. You define the test cases and assign tags to each agent. Some tests are set to pass, others to fail, depending on the situation. Last time Đạt talked about defining the expected output, but the workflow is generated automatically. This way, when a tool is used, it checks whether the tool is used correctly and how many times the tool was called.\n\n**43:25** Everything can be defined in the final evaluator to check. Suppose we want to hard-code a test case, we can do that. Meaning we can define a conversation, like booking a ticket, and check if all the steps for success are there or if any steps lead to failure. Everything can be predefined.\n\n**44:05** When we hard-code a full flow like that, we can track each step. But with this approach, everything can run automatically and check as part of the process. You can define metrics to evaluate the conversation, such as correctness or accuracy, to determine if the agent is functioning properly. This is a way to comprehensively test the agent.\n\n**45:31** There’s another part I combined with this one. You can see how the agent handles everything, going through different stages of the conversation. This example was taken from two previous collaboration samples, but it's specific to our case. The whole process is evaluated through three small architectures combined, with a router in the middle. The router routes requests to smaller modules based on the user’s request and returns results.\n\n**46:40** That’s one way to handle it, and you can see how it operates. The entire process can be evaluated step by step. If you need to build a test in a real app, this approach can still be applied.\n\n**47:50** Okay, next, Hoang is handing it back to Tom. Looks like Tom’s topics are almost done, right Tom? I just need to run a script to update some image links. There seem to be a lot of images. Okay, continue sharing about the case study.\n\n**49:39** Please check the Figma link to get a clearer view because the screen sometimes gets distorted. Before sharing, do we need to sensor anything? Is there any NDA involved? Or is this just a normal case study? There’s no issue here; this is the first project where the design team applied AI, mainly to support UX research.\n\n**50:36** Kafi is a company from before, which used to have a different name. It was obscure in the market for a while, but after 2022, there was a personnel restructuring, so they renamed it Kafi. They began re-structuring, and after 2024, Kafi reported impressive profits. They used these profits to start developing and upgrading two applications: Kafi Trade and Kafi Wealth, with the goal of expanding their business strategy and market. They came to Dwarves Foundation to invest in user research and technology.\n\n**51:30** The main challenge for Kafi’s current app is that the user experience doesn’t meet the needs of a diverse group of users. Imagine an investment app that doesn’t align with user needs when they first approach it. This challenge led Kafi to research user experience to meet the varying needs of their customers. So, the team posed the question, “What do we do next?” The main goal was to create an app that met expectations and provided real value to investors.\n\n**52:19** This process wasn’t easy because the team wasn’t just improving an app, they wanted to create a philosophy, building a tool that could change how people approach investing. I’ve broken down the user research process into three phases: empathize (understanding user needs), planning, and design. First is empathize. In this phase, the team began to really understand what customers wanted and expected.\n\n**53:07** The three main questions the team wanted to answer at the start of the project were: What are the current pain points and difficulties? What do users really want? And what do they need? The team then conducted in-depth research to dissect these issues. This included usability testing, where the team directly used the app to gain deep insights and capture details that other methods might miss, such as the emotions and thoughts of users when interacting with the app.\n\n**53:54** Additionally, the team investigated forums and communities like Reddit and Facebook to understand user behavior and hidden factors in the stock market that Kafi hadn’t yet grasped. During the research, the team also used AI to study the market and analyze competitors, using SWOT analysis to understand the current products on the market, including their strengths and weaknesses.\n\n**55:29** After completing all primary research and data collection, the team moved to the concept development phase, where they analyzed the collected information to gain deep insights. Next was the project planning phase. After gathering all primary data from competitors, AI, and surveys, the team prioritized forming strategies for the real user experience.\n\n**56:18** The team first needed to understand what users wanted and needed. Then they classified the collected information and sorted it by priority. The findings were presented to the Kafi team to help them form strategies based on real data and agree on the identified issues. The next phase was secondary research, a more in-depth study of product strategy.\n\n**57:08** There are three main phases: building personas, prioritizing user journeys, and addressing pain points. From this, the team better understood the product roadmap and identified features for the second version of the product. They then presented these insights to the client. The first step was building personas, representing customer segments based on factors such as age, investment experience, financial goals, and risk tolerance.\n\n**57:57** After identifying the personas, the team analyzed user behavior more deeply by mapping out a user journey to understand their actions. This included key points like how they interact with features, the frequency of use, and factors influencing their investment decisions. Next, the team focused on identifying the prioritized needs of each customer segment.\n\n**58:49** For example, new investors need more guidance and learning tools, while professional traders might prioritize analytical tools to enhance their trading success. Finally, based on data analysis and Kafi’s philosophy of building financial dreams, the team decided to focus on two main user groups: new traders and professional traders, also known as newbie traders and day traders.\n\n**59:31** The team drew an important conclusion: we need to reshape how users approach stock trading. These conclusions include helping new investors overcome knowledge barriers, addressing the need for speed and accuracy for professional traders, and solving security and risk management issues. The research also showed that traders tend to use mobile apps as a support tool to track market fluctuations, quickly update news, and check asset balances.\n\n**01:00:15** After completing the research process, the team and Kafi agreed on several key solutions. The three main issues identified were the complexity for new investors, the difficult onboarding process, and the diverse needs of different user groups.\n\n**01:01:10** To address these issues, the team developed three key solutions. These solutions were designed based on deep insights from user research and market analysis. The first solution was to help new investors, as investing is a complex field, especially for beginners. Kafi was designed to become a reliable guide, using a tool called Contextual Help.\n\n**01:01:49** For example, in a complex price chart, a small icon will appear in the corner of the screen. When the user taps on it, interactive help will pop up to explain concepts like what trading volume or closing price means. It also provides tips on reading charts, such as candlestick charts.\n\n**01:02:36** This allows users to dive deeper into techniques and technical indicators, all within a single screen. Finally, to improve the user interface, the team applied the principle of \"Less is More\" by creating a modern, minimalist, and functional interface. Every element on the screen has a specific purpose, helping users trade quickly and efficiently, ensuring new traders don’t feel overwhelmed by the large amount of information.\n\n**01:03:21** The second solution focused on simplifying the onboarding process, making it easier for users. Previously, the team found that Kafi’s app had a high dropout rate during registration, mainly because the electronic identity verification (eKYC) process was too complex, requiring users to provide too much information. To fix this, the team optimized the onboarding process by breaking it down into smaller steps, only requiring essential information at each step.\n\n**01:04:06** Additionally, users were allowed to explore the app before completing registration, helping them feel more comfortable without the pressure of providing too much information upfront. After users created an account, they were guided through steps like verification, tracking portfolios, and placing orders with an integrated progress bar to help them follow the process. This approach not only simplified the process but also created a personalized experience for each customer segment.\n\n**01:04:48** The third solution was designing tools tailored to each user group. Investors have different tool needs depending on their experience level. While the web platform allows flexible feature placement, the mobile interface is more limited. The challenge was providing enough tools for professional traders without making it difficult for new users. The team’s solution was to apply a user segmentation system. After completing registration, users were categorized into groups like beginners, intermediate, and professionals. Each group received an experience tailored to their level of knowledge and investment goals.\n\n**01:05:24** For example, beginners could access basic learning modules, while professional traders would be provided with in-depth analytical tools. This approach not only improved the user experience but also promoted the growth of the Kafi platform by providing relevant content and tools at different stages. Kafi could create a dynamic learning and investment environment, serving both newcomers and experienced investors.\n\n**01:06:00** The results after Kafi’s case study showed that there are many ways to address the issues that stock trading apps face. However, the most important thing is understanding the customers’ needs. If a company serves multiple user segments, it’s crucial to gather and analyze their diverse needs. After that, priorities need to be set to meet the needs of each group.\n\n**01:06:43** Some effective methods for discovering and understanding user needs include surveys with closed and open-ended questions to collect information, building personas to represent users, identifying their goals, behaviors, and pain points, and competitor analysis using tools to assess their products and identify strengths and weaknesses.\n\n**01:07:26** Additionally, AI can be integrated into the user research process, helping process large amounts of data from competitors or from survey and interview data. AI can analyze all that data and create personas for each user group. From there, we can find solutions that match the needs of each customer segment.\n\n**01:08:08** That’s all from me. Any questions? Honestly, these things can't really be shortened, as we applied everything. There’s no way to summarize it further. Exactly, it’s a lot. Nobody’s voice is shaking with nerves here.\n\n**01:09:52** What’s your personal take, as a designer, on AI? Well, as I said, since AI came along, user research has become lighter. No more need to go out and survey or interview too many users. Many people out there still have to call and interview a dozen users every day. Have you used ChatGPT for research? How do you use it for personas?\n\n**01:11:08** When I ask AI about personas, it gives me a lot of results. The main issue is that AI doesn’t help plan the prioritization of issues, it only helps find initial personas. From there, you have to rely on experience and real user interviews, then analyze and group personas correctly. If not, AI will give you too many personas.\n\n**01:11:56** Kafi mostly references competitor benchmarks anyway. Okay, I don’t have any more questions. Not sure if we recorded my voice. If there’s anything missing, just send the slides.\n\n**01:13:25** According to the agenda, Tom has a session called *mixture of agents*, where a group of agents work together, running a multi-agent system to get results. For now, though, that session might be too easy. I don’t think we’re ready for it, so we’ll skip it for now. There’s something more important to discuss about the trip and the test.\n\n**01:14:09** The test content will be as follows. You should start preparing now. First, you’ll write two essays. Write them yourself, if it’s bad, you’ll get criticized! The first essay will be about culture. I’ll pick one of the four core cultural pillars our team is following, likely centered around hybrid working, among other things. You’ll write an essay about that. I’ll share the question later, but I’m letting you know now. We’ll release it by the weekend for you to get started on it.\n\n**01:14:52** The reason for this is that, at this stage, I think everyone needs to set their own motivation to adapt to this new phase. The new phase is shaped by the market. The company phase is still normal, nothing special, but the market is changing. To align with that, everyone needs to refresh their motivation in this industry. That’s the first essay.\n\n**01:15:36** The second essay question will revolve around this: I haven’t decided on the exact wording yet, but it will be about the state of the app in your field. How is AI being applied in the field you work in? You’ll summarize this into an essay, kind of like a state-of-the-app report about how AI is being implemented in the industry outside. That’s the second essay.\n\n**01:16:18** Here’s a sample for that essay. I don’t know if I have it here, just a sample, though. For devs, it’s easier, but for those in sales, design, testing, or PM roles, it applies to all of you. Tom is thinking about cutting out those roles and replacing them with agents entirely. To be honest, we can expect AI to cover about 70–80% of the work, but we’ll still need people to drive those agents. So it’s a mixed approach.\n\n**01:17:04** For example, this article, is this the one? Let me check again. Right, take a look, does it look familiar? Some articles talk about how to use AI in a certain way. There are a few like this. The dev community covers some of this, but not a lot. Anyway, the second essay is about your role in the company. Given your role, how is AI being applied to your work today? That’s the second essay, okay?\n\n**01:17:42**  The third one will be about practical application. I haven’t decided on the prompt yet because if I give you random topics, you’ll just sit and chat with GPT, and it won’t be very useful. So it’ll relate to hands-on tasks, building software and making sure AI is used effectively in your actual work. I’ll think of a submission prompt for that, maybe asking everyone to use AI for assessment. I’m not fully endorsing AI to cover everything because I’ve seen how everyone is using it. For instance, when I use certain tools to generate scripts, it’s very generic and lacks practical insights.\n\n**01:18:16** Just a quick comment on that: the way you’re using AI as a machine, in a formulaic way, shows inexperience. I’m not sure what word to use here, but it’s pretty dull. Very underwhelming. Okay, essay three will be on application, after you’ve researched and understood things, it’ll be about how you practically apply AI.\n\n**01:18:58** Moving on, if the trip goes as planned, we’ll likely go in early December. That gives us about two months to prepare, and we’ll need to finalize everything at least a month in advance. So you’ll have about a month to work on this. Alright? These submissions will be required. This is a necessary condition for the trip, and it’ll also be a condition for the performance review in December and January.\n\n**01:19:39** Currently, I’m expecting that our team’s activities will be assessed using AI to a level where we can control the outcomes and ensure they align with what we want, just like before. It shouldn’t be a case of, “because I used this tool, now the result is like this, because you told me to use it.” Got it? It’s like stabbing yourself with a knife and then blaming someone else, this won’t work. Okay, this is a necessary condition for the trip, and also the sufficient condition for the review.\n\n**01:20:14** This is important because this December’s review, if someone makes it all the way through and doesn’t perform well, then it’s highly likely that the juniors and freshers will be cut. Yesterday, I saw a really funny post. This guy didn’t get hired anywhere, so he made a multiplayer game called *firm crash*, using Go and TP. He posted it and used math to create animations. The comments were pretty amusing.\n\n**01:21:04** So, the December review will focus on that. That’s the final announcement to make sure everyone is aware. The message will be released by the weekend so that everyone can prepare for the deadline to submit, and Huy will grade it before the fourth week of November. Probably, by the fourth week of October, you’ll have about three weeks left, right? Exactly. This is the announcement. If some of you aren’t participating, it doesn’t really matter that much.\n\n**01:21:55** Next, there’s the list that Tom has been working on. I haven’t checked everything yet, but I’m starting to assess things one by one. Why is the pilot list so slow? This is a different list from the one I mentioned before. I’ll quickly go through it to show you all. This list here, Tom is working on it. I see some of you are participating, which is a good sign. It shows that people are starting to become aware of the change in the concept of how we develop software.\n\n**01:22:42** Now, we’ve got the addition of servers, new methods for data manipulation, and different approaches to data collection. Everything is changing, so things will be different. The rewards have already been sent out and are done. As for what Tom is working on, I’ll review it. I’ll review the work that others have done, and Tom will review some other parts. One of the examples is Hieu Vu. Hieu Vu, are you here? I haven’t seen any updates from you. If you’re starting to look for jobs like this, it’s not going to go well.\n\n**01:23:15** You guys need to be proactive in finding topics to work on. Here’s one of the lists. As for the other list, we’ll go through it once Tom finishes it. There’s the *multi-agent* topic, when the other topics are done. *Knowledge sharing*, grouping, *specific projection.*\n\n**01:24:07** The *MapReduce* topic, the team is working on it, collecting data, building it up, and running it. Thanh is working on this one. Last time we were working on the architecture; it’s still a bit rough. Next up are other topics related to the old system. Before, we only had servers, but now we have agents, so we need to send data to them. The architecture will change a bit. When given a problem, how we structure the agents is still a topic we haven’t fully discussed with each other.\n\n**01:25:12** Some of you are setting up Dify and can see it’s related, but there are many questions about architecture and how to structure a system with not just servers but multiple agents distributed throughout. It’s similar to the example Hoang gave earlier, that was just an easy sample. But when it comes to a real problem, how will the server architecture look? This is a real, practical topic that we need to handle. Just reminding you all again: if you’re not paying attention, what Tom is writing might not make much sense to you. We’re falling far behind in this area of knowledge.\n\n**01:25:39** I think this cluster of knowledge will become foundational for software engineers. It’s not blockchain knowledge, I’m not saying everyone needs to know that. But this part, you need to know. What’s important is knowing how to break down a problem and create a logical flowchart in your mind. If you can’t break it down, then you’re still inexperienced. Just a gentle reminder.\n\n**01:26:17** That’s the full message. I just wanted to make sure everyone knows where the direction and expectations are heading. This weekend, there will be an essay prompt: you’ll need to write two essays, one report, and one case study. If there’s nothing else, I think that’s it.\n\n**01:26:53** Goodbye everyone, see you later. Hopefully, today’s recapped topics are still valuable to you. Once you have more knowledge, we’ll move on to discussing the new system. For now, everything you’re building is still within the old framework, meaning it’s old compared to the outside world. But knowing ahead of time is always better. Okay then, let’s wrap up. Does anyone have any questions?\n\n**01:27:44** I guess not. Let’s finish here. Yes, I need to chat with our team. Yesterday, Dat posted a video. I feel like we’re lagging behind society so much. Where’s Dat? He posted a video of some Vietnamese guys automating something. This is crazy. Do you know which channel it’s from?\n\n**01:28:42** Alright, I think so. Is it a random channel? Right now, everyone is still upset about learning architecture the old way. They’re stuck on learning this architecture and that architecture. But at this level of automation, we need to apply it more. Every enterprise app or regular app will fall under this scope. If it’s easy to build up, then it’ll cover everything quickly. If it’s hard to build up, and you don’t even know how to handle the easy stuff yet, then it’s going to be even harder. See you all at OGIF next week.\n\n**01:29:22** I hope that every Friday we learn something new. See you all at OGIF next week.\n","title":"OGIF Office Hours #26 - Product Design Commentary, Go Weekly, Trading App Case Study, Chatbot Evaluations, and Announcement for Essay Assignments","short_title":"#26 Design insights, Go tools, Trading app, Chatbots, Essays","description":"In this Office Hours, Nam Bui shared product design insights on the Sparkle icon in AI and onboarding, Phat covered Go tools Prep and War Zero, and Hoang discussed chatbot evaluations. Anh presented a case study on AI-driven user research for Kafi. Management announced AI essay assignments tied to the year-end trip and performance reviews.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Fri Oct 04 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/26-20241004.md","slugArray":["updates","ogif","26-20241004"]},{"content":"\n85 minutes\n\n**Topics and Highlights**\n\n- **Hybrid Work \u0026 AI Focus**: Encouraging office visits, knowledge sharing, and AI/LLM projects with ICY rewards.\n- **OGIF \u0026 Tutorials**: Regular demos on Golang, AI, product design, and AI tools by Tom.\n- **Company Trip**: Planning a December trip to Penang.\n- **Product Design Insights**: Covered VUI, AR/VR, Modular Design, and AI tools for UX/UI.\n- **Golang \u0026 AI Tech**: Discussed register allocation, BBQV vector index, and GUI libraries.\n- **YouTube Transcription Tool**: Using Whisper API for transcripts.\n- **Newsletter Bot**: Collecting and scoring newsletter content with ChatGPT.\n- **AI Tool Integration**: Summarizing Discord/Twitter content using AI.\n- **Q\u0026A \u0026 Wrap-up**: Technical issues, API use, and future demos.\n\n---\n\n**Vietnamese Transcript**\n\n**00:00** Hello mọi người, Ok chúng ta ổn rồi. Anh Thành đang nói phải không? Không nghe được, thử kiểm tra lại mic nhé.\n\n**00:20** Ok, đã nghe được rồi. Chắc đợi chị Ngọc lên một chút rồi bắt đầu nhé. Chủ yếu là vài vấn đề gần đây, chắc 70% thời gian sẽ dành để trao đổi về các vấn đề nội bộ của chúng ta.\n\n**00:40** Đã có 36 người tham gia, còn đợi ai nữa không? Nếu không, mình bắt đầu luôn nhé. Điểm qua nhanh một số việc trong tháng vừa rồi: Chúng ta đã quay trở lại với văn hóa hybrid, khuyến khích mọi người mỗi tuần sẽ lên văn phòng vài ngày.\n\n**06:47** Mục đích của việc lên văn phòng là để trao đổi kiến thức, học hỏi lẫn nhau một cách nhanh hơn so với làm việc online hoặc chỉ qua các buổi OGIF. Sau vài tuần triển khai chương trình này, thấy mọi người cũng khá hào hứng. Bên cạnh đó, có nhiều chính sách hỗ trợ cho việc lên văn phòng như khi check-in sẽ nhận được ICY, gửi xe cũng được ICY. Bên cạnh đó, phần ăn trưa của mọi người cũng sẽ được hỗ trợ.\n\n**07:20** Như mọi người cũng đã biết, định hướng của chúng ta là học và thực hiện các dự án liên quan đến AI và LLM càng nhiều càng tốt. Mình thấy các bạn khá hứng thú với những series hướng dẫn về prompting từ phía Tom hoặc những kiến thức mới. Thành, em chia sẻ thêm nhé.\n\n**07:58** Em thấy bình thường chúng ta có OGIF vào cuối thứ Sáu, nhưng giờ anh em đã bổ sung thêm buổi demo của Tom vào thứ Tư. Trong thời gian tới, dự kiến sẽ tiếp tục duy trì chu kỳ này trong khoảng 1-2 tháng nữa. Mục đích là để thúc đẩy việc sử dụng những công cụ AI, những automation tools cho công việc và học thêm các kỹ thuật liên quan đến ứng dụng.\n\n**08:40** Mọi người nên theo dõi để biết tình hình và cập nhật các công cụ hiện tại. Chủ yếu chúng ta sẽ học cách xây dựng (build-up), sử dụng các tool, như việc định nghĩa workflow, viết prompts sao cho đúng để áp dụng vào công việc coding hay các task liên quan đến development. Chắc là Tom sẽ phụ trách việc này và cập nhật kiến thức cho mọi người.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/V44ifsSx7k8?si=oBltKeqDthWiYYDK\u0026amp;start=418\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**09:23** Ngoài ra, hiện tại chúng ta có một vài chính sách để khuyến khích mọi người tập trung vào AI/LLM nhiều hơn. Ví dụ, những hoạt động hay demo liên quan đến LLM từ tuần này, lượng reward ICY sẽ nhân 3 hoặc 4 lần, tùy vào chất lượng của bài viết hay output của mọi người. Đây là một sự khích lệ cho những ai quan tâm đến AI.\n\n**10:13** Về các mục tiêu cụ thể hơn, có lẽ đầu tuần sau sẽ có thông báo chi tiết về những thứ cần tập trung và các công cụ nào nên sử dụng. Tóm lại là vậy, tình hình chung là như vậy.\n\n**10:58** Ok, cảm ơn Thành. Như vậy, những hoạt động nghiên cứu liên quan đến AI sẽ được nhân 3 hoặc 4 lần reward. Có ai hỏi nếu spam link liên quan đến AI thì có được thêm ICY không? Chắc là mình sẽ xem xét thêm, mỗi ICY tương đương 1.5$.\n\n**11:56** Để nhắc lại cho mọi người, trong các buổi OGIF của chúng ta, ngoài các phần demo, sẽ luôn có những phần liên quan đến market commentary, cập nhật từ Go Weekly, AI, và sắp tới sẽ có thêm mảng product design.\n\n**12:47** Một thông báo cuối cùng, team ops đang sắp xếp cho chuyến company trip vào tháng 12 tới tại Penang, Malaysia. Thông tin chi tiết sẽ được chia sẻ trên kênh alert hoặc do Inno chia sẻ. Thành, còn gì nữa không hay Bảo muốn chia sẻ thêm gì với mọi người trước khi vào phần tiếp theo?\n\n**13:42** Không có gì thêm, anh chị em nhớ hoàn thành BP sớm nhé. Cung cấp thông tin qua Inno để chuẩn bị cho company trip. Rồi, Thành, mình chuyển tiếp qua phần OGIF thôi.\n\n**14:56** Hôm nay, mình dự định pick-up một vài demo về tool-building mà anh em đã làm trong đợt vừa rồi. Đầu tháng Bảo có phát động, nên hiện đang có một vài demo và commentary.\n\n**15:56** Đầu tiên, nhường diễn đàn cho bên phía design với phần của Nam Bùi. Nam ơi, em lên được chưa?\n\n**16:44** Dạ, em lên rồi. Hôm nay, em sẽ trình bày về chủ đề Product Design Commentary năm 2024 - phần 1. Em sẽ nói về các domain đang nổi, phổ biến và tương lai trong ngành Product Design. Đồng thời, em cũng đề cập đến những vấn đề đau đầu (pain points) mà các domain này gặp phải. Nếu team mình phát triển trong các mảng này, có thể dùng đó làm unique selling point.\n\n**16:56** Em sẽ đề cập đến 4 domain chính:\n\n1. VUI (Voice User Interface)\n2. AR/VR (Augmented/Virtual Reality)\n3. Modular Design Systems\n4. AI tools hỗ trợ quy trình UI/UX workflow.\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/V44ifsSx7k8?si=DRpfCdpelj_z2GBM\u0026amp;start=921\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\n**17:29** Đầu tiên, em nói về VUI. Hiện tại, VUI được ứng dụng nhiều trong ngành Smart Home, như điều khiển các thiết bị nhà thông minh, xe hơi thông minh. Dự đoán vào năm 2026, khoảng 50% dân số Mỹ sẽ sử dụng VUI trên các thiết bị của họ.\n\n**17:44** Ở Việt Nam, hiện FPT.AI đang là đơn vị mạnh nhất trong lĩnh vực này, với các ứng dụng như Kiki App tích hợp trong thiết bị ô tô để chỉ đường. Trên thế giới, các ứng dụng VUI phổ biến như Alexa của Amazon, Google Assistant, và Siri của Apple đang chiếm lĩnh thị trường.\n\n**17:44** Tổng hợp phản hồi từ người dùng, Alexa có ưu thế về NLP nhưng không mạnh về lập trình. Google Assistant tích hợp Google Search nên có kiến thức đa dạng nhưng không sâu. Siri là kém nhất trong ba, chủ yếu dùng Bing, nhưng giọng điệu của nó không được thân thiện lắm.\n\n**17:56** Chuyển qua PP (Predictive Programming), công nghệ này hiện chưa áp dụng nhiều cho tiếng Trung và tiếng Việt. Chủ yếu tập trung vào tiếng Anh và các ngôn ngữ phổ biến khác, do thiếu dữ liệu huấn luyện AI cho ngôn ngữ phức tạp. Nhưng trong tương lai, với sự phát triển về công nghệ và dữ liệu, em tin rằng PP sẽ trở nên phổ biến hơn với các ngôn ngữ này.\n\n**18:13** Về phần Predictive Programming (PP), công nghệ này hiện chưa áp dụng được rộng rãi cho các ngôn ngữ khác ngoài tiếng Anh. Những ngôn ngữ phức tạp như tiếng Trung hoặc tiếng Việt chưa được hỗ trợ tốt. Thường thì người sử dụng cần phải thành thạo tiếng Anh mới tận dụng hiệu quả được PP. Về mặt flexibility, PP hiện vẫn chưa đủ thông minh để hiểu mọi ngữ cảnh mà mình nói; nó chỉ hiểu được khi mình tuân theo đúng những mẫu câu lệnh đã được lập trình sẵn. Đây cũng là một điểm yếu cần được cải thiện trong tương lai.\n\n**19:00** Tiếp theo, em sẽ nói về lĩnh vực AR/VR (Augmented Reality/Virtual Reality). Lĩnh vực này hiện đang tập trung chủ yếu vào các ngành như e-commerce, bất động sản, giúp người dùng có thể trải nghiệm trực tiếp mà không cần phải đến tận nơi. Ví dụ, họ có thể xem trước căn nhà qua ứng dụng VR thay vì phải đến thăm trực tiếp. Năm 2019, giá trị thị trường của AR/VR chỉ khoảng 0,44 triệu tỷ đô, dự đoán đến năm 2024 sẽ đạt 1,73 tỷ đô, và có khả năng chạm mốc 40 tỷ đô vào năm 2027.\n\n**19:46** Tuy nhiên, nhiều doanh nghiệp đã thử ứng dụng AR/VR vào các website của họ, nhưng phần lớn đã rút lại do vấn đề hiệu suất không ổn định. Trong giai đoạn đầu năm 2023 đến cuối năm 2023, AR/VR được áp dụng rộng rãi, nhưng đến đầu năm 2024, nhiều doanh nghiệp bắt đầu rút khỏi website vì trải nghiệm người dùng kém, đặc biệt là khi người dùng truy cập mà gặp phải lag hoặc tốc độ tải chậm.\n\n**20:54** Điều này gây khó chịu cho người dùng, khiến họ nhanh chóng thoát khỏi trang web. Hơn nữa, chi phí để phát triển và duy trì AR/VR là rất cao, nên chỉ có những doanh nghiệp lớn, dư ngân sách mới đầu tư vào công nghệ này. Các doanh nghiệp vừa và nhỏ thường không muốn chi quá nhiều cho việc tích hợp AR/VR vào trang web của họ.\n\n**21:38** Phần tiếp theo là về Modular Data Systems, tập trung vào việc sử dụng các reusable design components giúp phối hợp hiệu quả giữa designer và developer. Hiện nay, trên thị trường có nhiều bộ design system phổ biến, kết hợp cả file UI Figma và các UI components hỗ trợ từ các thư viện.\n\n**22:17** Ví dụ phổ biến nhất là Ant Design System, tuy nhiên UI của Ant Design hiện đã hơi cũ. Ngoài ra, còn có các lựa chọn hiện đại hơn như Tailwind UI và Chakra UI. Cách phối hợp giữa designer và developer là cùng sử dụng một bộ file Figma từ thư viện, designer sẽ thiết kế dựa trên bộ đó, và developer sử dụng các component tương ứng để phát triển.\n\n**23:00** Ví dụ, nếu designer muốn làm một bảng (table), họ sẽ chọn component table trong Figma, còn developer sẽ sử dụng đúng component đó để xây dựng trong code. Điều này đảm bảo sự đồng nhất giữa thiết kế và việc triển khai, giúp giảm thiểu sai lệch giữa thiết kế và sản phẩm cuối cùng. Hiện tại, nhiều thư viện còn hỗ trợ responsive design, giúp developer không cần phải làm lại cho từng thiết bị khác nhau.\n\n**24:09** Đội ngũ của mình cũng có một team tên là Mochi đang phát triển bộ Design System riêng. Một vấn đề khi áp dụng các thư viện này là sản phẩm có thể thiếu đi sự độc đáo, dấu ấn riêng của từng ứng dụng. Ví dụ, 10 ứng dụng cùng sử dụng Ant Design thì giao diện sẽ rất giống nhau, không có sự khác biệt.\n\n**24:56** Do đó, designer và developer cần phải phối hợp rất chặt chẽ. Nếu designer muốn tùy chỉnh bất kỳ component nào trong Figma, họ cần thông báo ngay cho developer để cập nhật lại code tương ứng. Điều này đòi hỏi sự giao tiếp liên tục giữa hai bên để đảm bảo tính nhất quán trong suốt quá trình phát triển.\n\n**25:41** Về các công cụ AI hỗ trợ UX/UI, AI tools giúp chúng ta phân tích hành vi người dùng một cách chính xác và nhanh chóng. Về phần UI, AI có thể hỗ trợ tạo ra các components hoặc styles phù hợp với từng lĩnh vực khác nhau. Các công cụ như ChatGPT, Claude AI, và Midjourney đang làm rất tốt trong việc hỗ trợ nghiên cứu và phát triển UX/UI.\n\n**26:32** Hiện tại, về phần UI thì nó hỗ trợ phần lớn việc tạo ra các hình ảnh (image) nhưng không thể tạo ra được dạng vector hay pixel mà mình có thể chỉnh sửa được. Tuy nhiên, có một số công cụ đang cố gắng cải thiện, ví dụ như khi sử dụng công cụ Midjourney, mình có thể generate ra hình ảnh rồi đưa vào Figma, và hiện tại nó đã có khả năng copy ra thành các layout có auto layout của Figma luôn, giúp việc chỉnh sửa dễ dàng hơn.\n\n**27:24** Nhưng nhìn chung, output của AI về UI hiện tại chủ yếu vẫn chỉ ở dạng hình ảnh (image), rất hiếm khi có thể generate ra vector hoặc những component có thể sử dụng trực tiếp trong thiết kế. Đó là một điểm yếu và hạn chế của công nghệ AI hiện tại trong việc hỗ trợ thiết kế UI.\n\n**28:20** Đối với UX, em nhận thấy AI đang hỗ trợ tốt hơn rất nhiều. Ví dụ, khi mình nhận được một yêu cầu (requirement) ngắn gọn từ phía client, mình có thể thả vào ChatGPT để nó đưa ra một gợi ý về cấu trúc thông tin (info architecture) hoặc các giải pháp UX phù hợp. Thực tế là đôi khi em không nắm rõ hết các yêu cầu nhưng khi thả vào ChatGPT, nó lại cho ra những ý tưởng rất hữu ích, đáp ứng đúng nhu cầu của client.\n\n**28:55** Tuy nhiên, với UI, dù mình có sử dụng AI thì nó vẫn khó có thể tạo ra được những thiết kế đúng ý mình mong muốn. Ngay cả khi nó có thể tạo ra, thì output thường chỉ là dạng image, không phải là những file có thể sử dụng trực tiếp như Figma hay Sketch. Vì vậy, trong mảng UI, AI hiện tại vẫn còn nhiều hạn chế và cần được cải thiện thêm.\n\n**29:20** Anh có đồng ý với em không? Phần UX thì AI có vẻ đang làm tốt hơn UI.\n\n**29:45** Chính xác. Đặc biệt là khi mình làm việc với các yêu cầu dạng info architecture, AI thường cho ra các kết quả khá đúng và phù hợp, giúp tiết kiệm rất nhiều thời gian cho designer. Nhưng với UI, hiện tại vẫn cần có sự can thiệp của con người để đảm bảo tính thẩm mỹ và độ chính xác.\n\n**30:30** Nếu không còn câu hỏi nào khác, em xin phép kết thúc phần chia sẻ của mình. Rất cảm ơn mọi người đã lắng nghe và hy vọng mọi người có thể áp dụng được một vài điểm trong phần trình bày này vào công việc hàng ngày của mình.\n\n**31:00** Cảm ơn Nam Bùi về phần chia sẻ rất chi tiết và đầy đủ về Product Design Commentary 2024. Những insights về việc AI hỗ trợ UX/UI thực sự rất hữu ích và cung cấp cho team những góc nhìn mới về việc ứng dụng AI trong thiết kế. Hy vọng sẽ được nghe thêm nhiều bài chia sẻ thú vị từ bạn trong các buổi OGIF tiếp theo.\n\n**32:51 T**uần rồi em thấy có hai bài như thế này. Thực ra, còn một bài nữa liên quan đến GUI nhưng lát nữa em sẽ nói sau. Đầu tiên là bài về \"register allocation\" của Golang compiler. Bài này hơi phức tạp một chút nên em không thể đưa hết nội dung vào đây được. Chủ yếu là phía Go họ thực hiện việc register allocation thông qua bước SSA (Static Single Assignment).\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/V44ifsSx7k8?si=LMrFIMk9BdRppbOk\u0026amp;start=2226\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\nMọi người có thể đọc tham khảo thêm ở trong link mà em đã bỏ vào đây. Nhưng nhìn chung, bài viết này tập trung vào quá trình tối ưu hóa việc compile bằng cách sử dụng SSA để quản lý register allocation.\n\n**37:43**  Để tổng kết lại, quá trình này giúp cải thiện thời gian compile của chương trình Golang. Cụ thể, nó tập trung vào việc tối ưu hóa hai bước chính là register allocation và stack allocation, từ đó giúp giảm khoảng 20% thời gian compile, đặc biệt hữu ích cho những ứng dụng Go có logic phức tạp hoặc những ứng dụng lớn.\n\nĐây là một bài viết rất chi tiết và kỹ lưỡng, được thực hiện bởi một trong những chuyên gia trong cộng đồng Rust. Bài viết này rất hữu ích cho những ai có quan tâm đến quá trình compiler hoặc muốn tìm hiểu sâu hơn về hiệu suất của Go.\n\n**38:17** Chuyển qua phần thứ hai liên quan đến lĩnh vực AI. Đó là một giải pháp mới có tên gọi BBQV, đây là một Vector Index được phát triển bởi một nhóm gọi là Dexa ở bên Mỹ. BBQV tập trung vào điểm mạnh chính của nó là \"scalable vector search.\" Điểm thú vị là BBQV không phải là giải pháp nhanh nhất, cũng không phải là giải pháp chính xác nhất, nhưng nó lại có khả năng build index cực kỳ nhanh so với các giải pháp khác. Xíu nữa em sẽ cho mọi người thấy biểu đồ mà nhóm tác giả của BBQV đã so sánh với các giải pháp ANN (Approximate Nearest Neighbor) khác.\n\n**39:13** Điều nổi bật của BBQV là khả năng build index với tốc độ rất nhanh, mặc dù carry time của nó chỉ nằm ở mức trung bình so với các giải pháp khác. Để so sánh cụ thể hơn, trên biểu đồ dưới đây, BBQV nằm ở khoảng giữa khi nói về carry time nhưng lại thuộc nhóm nhanh nhất về build time. Điều này là một điểm sáng khi triển khai BBQV trong các hệ thống AI có quy mô lớn, vì thời gian xây dựng index là rất quan trọng.\n\n**39:24** Ngoài ra, còn một bài nữa liên quan đến GUI trong Go. Mặc dù GUI trong Go không phải là một thế mạnh, em vẫn tìm thấy một số giải pháp GUI khá thú vị và muốn giới thiệu cho mọi người. Trong thời gian qua, cộng đồng Go đã cố gắng xây dựng các thư viện GUI có khả năng cạnh tranh với các giải pháp khác như Qt hay Electron. Tuy nhiên, phần lớn các giải pháp GUI này vẫn chưa thực sự hoàn thiện và thiếu tính năng so với những thư viện phổ biến từ các ngôn ngữ lập trình khác.\n\n**39:59** Đó là những gì mà bên team Dex đang dùng, Dex AI này đang xài cái đó, và nó cũng đã open-sourced rồi.\n\nBiểu đồ này cho thấy rằng BBQV có carry time không phải là nhanh nhất nhưng rất ổn định. Tuy nhiên, về mặt build time, BBQV là một trong những giải pháp nhanh nhất. Vì nó là kiểu \"selling point\" của nó, là để build một cái index thì xài thằng này là nhanh nhất.\n\nCòn về một bài nữa là GUI, mình không bỏ vào đây tại vì nhìn chung thì mình thấy bên Go GUI nó cũng hơi hạn chế. Nhưng mà mình kiếm được một thằng gọi là xịn nhất bên Go. Cái accessibility của nó, gallery của nó cũng đẹp, và nhìn chung là khá là mature. Mới đây có một ngôn ngữ mới tên là R, nó cũng viết bằng Go luôn, và nó cũng có một cái extension tích hợp với thằng GUI này. Nhìn chung nó trông như thế này thôi, ví dụ nó trông như thế này.\n\n**40:24** Ngoài ra, còn một bài nữa liên quan đến GUI trong Go. Mặc dù GUI trong Go không phải là một thế mạnh, em vẫn tìm thấy một số giải pháp GUI khá thú vị và muốn giới thiệu cho mọi người. Trong thời gian qua, cộng đồng Go đã cố gắng xây dựng các thư viện GUI có khả năng cạnh tranh với các giải pháp khác như Qt hay Electron. Tuy nhiên, phần lớn các giải pháp GUI này vẫn chưa thực sự hoàn thiện và thiếu tính năng so với những thư viện phổ biến từ các ngôn ngữ lập trình khác.\n\n**40:44** Hiện tại, team DEX AI bên mình đang sử dụng cái này. Nó là mã nguồn mở (open-source) nên rất tiện lợi khi tích hợp vào hệ thống của mình. Còn về mảng GUI, mình cũng tìm hiểu thêm về các thư viện (library) dành cho Go. Phải nói thật là GUI của Go vẫn còn khá hạn chế (tù túng), nhưng mình đã tìm được một thư viện gọi là Fyne. Đây là một trong những thư viện GUI tốt nhất hiện tại dành cho Go. Giao diện của nó (UI gallery) cũng rất đẹp và mature, nghĩa là nó đã khá hoàn thiện so với các thư viện khác.\n\n**41:45** Và gần đây, có một ngôn ngữ mới xuất hiện tên là Gio, cũng được viết bằng Go. Nó cung cấp một số extension có thể tích hợp trực tiếp với Fyne, tạo ra giao diện GUI như bạn thấy ở đây. Dường như xu hướng này đang phát triển khá nhanh trong cộng đồng Go. Về phần này, mình sẽ dừng ở đây để chuyển qua phần của Phát. Không biết Phát có muốn chia sẻ thêm không?\n\n**42:46** Ừm, theo quan sát của tôi thì thấy tên gọi BBQ đã trở nên phổ biến trong lĩnh vực vector database (vector DB). Nhiều dự án mới đều sử dụng BBQ vì tên nghe hay, nhưng thực ra các vector database như này đã vượt qua khái niệm đơn giản chỉ là dimensionality. Việc chọn vector DB nào phù hợp sẽ phụ thuộc nhiều vào yếu tố như hiệu năng và tính năng. BBQ tuy nghe vui, nhưng về tốc độ tìm kiếm (search speed) và hiệu quả tìm kiếm (recall), thì nó có thể không phải là nhanh nhất, nhưng vẫn đạt hiệu suất rất tốt. Nhanh nhất ở đây có lẽ phải kể đến thằng 'HNSW,' tuy nhiên BBQ vẫn là một sự lựa chọn ổn định.\n\n**44:03** Còn về các case study của những công ty lớn đang sử dụng Golang, chúng tôi đã thu thập được một số thông tin rất thú vị. Như đã đề cập, Google – đương nhiên không thể thiếu, vì họ là cha đẻ của Golang. Các doanh nghiệp lớn khác như Meta, Microsoft, và các công ty trong lĩnh vực tài chính như American Express, Monzo, và Paypal đều đã triển khai Go trong hệ thống của họ. Ở mảng streaming, Twitch cũng là một cái tên lớn đang sử dụng Go cho backend của mình. Trong mảng game, Riot Games cũng đã sử dụng Go trong một số dịch vụ. Tôi sẽ tiếp tục cập nhật thêm thông tin chi tiết về những case study này.\n\n**45:51** Đấy, bên bên bên bên Tom cái phần script chắc là thôi nhỉ, hơi basic hả? Ừ, cũng basic. Nếu còn thời gian thì demo nhanh được à. Rồi ok, thì mình nói về cái transcript YouTube. Thật ra là trước đó, trước đó team mình nó có một cái engine để xử lý cái phần này rồi, nhưng mà cái đó hình như bị hạn chế. Nó bị hạn chế bởi thời lượng 50 phút hay sao đó, nên mình mới viết lại một cái backend để process nó bằng cách sử dụng thằng Whisper API.\n\n**46:42** Thằng Whisper API này, nó có một cái gói free để transcribe audio. Một ngày nó cho phép mình transcribe khoảng 600 phút audio miễn phí, nhưng mỗi file chỉ có thể dài tối đa 2 tiếng. Mình tận dụng thằng Whisper API này để chuyển nội dung của video YouTube thành dạng văn bản. Quy trình cơ bản là khi mình đưa một link YouTube vào, hệ thống backend sẽ tự động tải về file video, sau đó chuyển đổi file đó thành định dạng MP3, rồi nén lại để kích thước file phù hợp với giới hạn của Whisper API (25MB mỗi file).\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/V44ifsSx7k8?si=ZHQ9rsOYdGBNBVNC\u0026amp;start=2785\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen\u003e\u003c/iframe\u003e\n\nThời gian nén và xử lý sẽ phụ thuộc vào độ dài của video gốc. Sau khi quá trình xử lý hoàn tất, hệ thống sẽ gửi từng đoạn audio đã nén lên Whisper API để tiến hành việc chuyển đổi từ âm thanh sang văn bản. Kết quả trả về từ API sẽ bao gồm thông tin chi tiết từng đoạn, từ thời gian bắt đầu đến kết thúc, và đoạn text tương ứng. Những đoạn này sau đó sẽ được combine lại và tiếp tục xử lý qua GPT-4 để tinh chỉnh, hiệu chỉnh câu chữ, đảm bảo văn bản đầu ra sát với ngôn ngữ gốc và chính xác hơn.\n\n**48:21** Dựa trên cái segment như vậy, mình combine nó lại rồi sử dụng GPT-4 để thực hiện việc hiệu chỉnh các tiểu tiết (tweak little details) ở đó. Thường thì tiếng Anh nó không bị sai gì hết. Nhưng mà tiếng Việt, nó lại có vấn đề với một số chỗ, ví dụ như ở miền Bắc, cách phát âm chữ dấu ngã thành dấu sắc, phát âm chữ 'r' thành 'd'. Khi mà ra được cái output như vậy, khi đọc thì nó sẽ bị sai về tay vô. Do đó, mình đưa cái content đó cho GPT-4 để nó chỉnh lại (correct) và kết quả là mình sẽ có một đoạn text hoàn chỉnh, đúng với bản gốc của video YouTube.\n\nSau khi ra được content như vậy, mình gửi lên cho D. Nó nhận được D này, cái app này nè, nó sử dụng một công cụ gọi tới cái backend hồi nãy và nó nhận được JSON như vậy. Từ đó, nó bật ra, và tiếp tục sử dụng một thư viện để render cái đoạn transcript như vậy. Nó trả về một đoạn nội dung như thế này, bao gồm full content.\n\n**49:55** Đó là cái mà mình đã làm được. Nếu mà mình sử dụng gói trả phí (subscription plan) của Whisper API luôn thì mình sẽ không bị giới hạn bởi việc cứ mỗi tiếng chỉ convert được khoảng hai tiếng audio. Tuy nhiên, có một giới hạn nữa là khi deploy lên server qua Heroku hay một số server khác, do quá trình xử lý audio này khá tốn thời gian, nên đôi khi gặp vấn đề timeout. Nhưng nếu mình chạy trực tiếp trên local thì mọi thứ sẽ mượt mà hơn rất nhiều.\n\nĐó là lý do tại sao mình sử dụng công cụ này ở bên phía project OIP. Có cái phần chỉnh sửa transcript mà anh em xem lại, không biết là đang dùng con này hay dùng cái gì khác?\n\nHiện tại, mình đang chỉnh lại config để sử dụng công cụ này cho phù hợp hơn. Cái của Tom hình như cũng đang bị đứt rồi hay sao ấy. Vì phần OGIF của mình hiện tại rất là dài, cũng hơn tiếng mấy, cho nên để process hết đoạn đó thì có thể cần phải cải thiện lại performance của công cụ này để nó có thể hoạt động tốt hơn.\n\n**50:40 H**iện tại mình đang dùng free API bên nào? Có ba cái workflow, hai cái là free API, một cái là của em, cái của em bị YouTube chặn rồi. Hình như nó không ổn định đúng không? Ừ, cũng có lúc ổn định lúc không, hai cái đều bị chặn hết rồi. Còn một cái API còn lại là Note GPT bên phía em Mỹ đang dùng, nhưng transcript dài thì cũng có khả năng bị crash thôi.\n\n**52:18** Ok, đúng rồi, lúc ổn định lúc không. Thực ra thì nếu video dưới 10 phút thì luôn work, còn bắt đầu dài hơn chút xíu thì còn tuỳ thuộc. Vấn đề là resources của server miễn phí, không biết là nó có reset được hay không. Còn nếu dài thì cứ đem cái source về local chạy là được hết.\n\n**53:35** Mọi người cũng thấy trên phần AI comment trên Discord, mình đã có một số script từ Twitter rồi. Thì bên phía cái quy trình mình đang làm là làm một cái API từ model Python script. Sau đó mình deploy nó luôn, mô hình này có một cơ chế cho phép mình deploy thẳng như là một cái API.\n\n**54:53** Sau đó mình sử dụng API này để script thông tin từ bên phía mình. Nó sẽ là một cái script chạy như vậy, nó là một cái function nằm trên container, chạy một browser đó, xem trong viewport và lấy các selector và thông tin từ text đó comp từ container của mình. Sau đó mình sẽ expose ra một cái POST request.\n\nPOST request này chỉ cần URL, ví dụ như mình lấy Twitter, hoặc lấy từ sc.com chẳng hạn.\n\n**55:39** Mình muốn script data này thì mình có thể test trực tiếp bên phía Postman request, nhưng với Dify, mình có thể test trực tiếp trên này luôn. Và cái hay nhất là khi mình test xong, mình có thể convert cái workflow từ Dify sang một cái function call, cái này có thể áp dụng trên một cái agent hoặc một cái gì đó riêng cho bên phía Dify nữa.\n\n**56:38 C**ái này có tích hợp bên phía Discord AI, cho nên có bạn nào muốn summarize lại từ Twitter thì chỉ cần post cái link vào, nó sẽ tự summarize. Hình như đang bị lag rồi. Chạy lại tiếp thử xem. Có vẻ như đang bị lag à? Nhưng cứ tưởng tượng là nó sẽ lấy được từ Twitter. Sau này sẽ dùng phương pháp này để script từ bên phía Facebook và bên phía Hoàng đang dùng phương pháp để upload một cái API qua mô hình để script và lấy dữ liệu từ Discord message.\n\n**57:53** Sở dĩ là khi mình gom lại thì Dify auto-convert thành một cái tool luôn. Bình thường mình có thể publish một cái app riêng, tương tác với nó. Hay hơn là mình tạo một cái workflow tool, nó sẽ sắp xếp như là một function call bên phía OpenAI.\n\n**58:37** Đây là cái Discord AI bot mọi người đang AI comment, mọi người đang dùng cho Discord của team mình. Hiện tại, nó có mấy cái tool mình tự làm như là Twitter script nằm ở trong này luôn. Một cái là lấy YouTube transcription của một dịch vụ bên phía tôi làm, một cái là query memo, nó là tooling mình làm để kéo data từ Memo của team mình. Còn lại là mấy cái tool có sẵn trên Dify. Lúc mình muốn add thì nó sẽ nằm ở trên cái list danh sách của workflow. Khi mình tạo workflow xong, sau đó deploy và configure nó, thì nó sẽ nằm hết ra ở trên này.\n\n**59:17** Thì chắc thử xem, \"What are the latest notes added to the doors?\" thì nó sẽ lấy Prompt Token ở trên description của tool và ở trên cái system prompt, nó sẽ biết là dùng tool nào cho phù hợp. Vậy là lấy data dựa vào hai yếu tố đúng không? Thứ nhất là cái system prompt của em, và thứ hai là cái description của tool. Dựa trên câu query ban đầu vào thì nó sẽ detect xem là nên sử dụng cái tool gì để process tiếp đúng không?\n\nDạ đúng rồi, nên ví dụ mình chọn cái này thì nó sẽ switch lại, xem cái nào phù hợp nhất, sau đó chạy cái tool cho mình. Sau đó nó có một cái agent chạy lấy data và gửi lại cho bên phía AI. Ở đây chắc là fail nhưng ý tưởng là như vậy thôi.\n\nOk, chắc phần của em xong rồi, chắc nhường lại cho người tiếp theo.\n\n**01:00:46 D**emo nhanh về itool để hỗ trợ làm memo, cái transcript hiện tại. Hiện tại là nó là dưới dạng một con Discord bot như thế này. Discord như thế này thì em đang host ở trên máy, tại vì server thì tốn tiền. Sẽ có hai cái command chính. Một cái là cái list, thì tính năng của nó đơn giản là nó sẽ có một cái account collect newsletter. Có nghĩa là cái data source của em là những cái newsletter email đó, em dùng một cái email để subscribe khoảng 100 chỗ, nhưng mà tất cả thì nó sẽ về thằng này. Và đơn giản là kiểu có email nào mới mà chưa đọc thì em cào về thôi.\n\nThì backend thì em build bằng Python. Cái app này thì kiểu 90% là xài core standard code.\n\n**01:02:55** Thì cái functionality của nó đơn giản là như thế này. Khi em cào về thì nó sẽ có một cái table article như thế này. Nó sẽ có một cái table article như vậy. Em sẽ lấy title, description cụ thể. Mấy cái này thì em dùng trên BeautifulSoup để lấy. Để sau em sẽ show sau. Nhưng mà về tính năng thì nó đơn giản kiểu vậy thôi.\n\nVí dụ như em muốn lấy bảy cái bài về một kiểu category. Ờ tất cả trong vòng bảy ngày. Em lấy tất cả những bài thuộc tất cả các category trong vòng bảy ngày. Đó thì nó sẽ trả ra vậy, presentation list kiểu như vậy.\n\nThì đây là cái feature đầu tiên là kiểu list ra những cái article mà em collect được từ bên phía email inbox thôi. Cái command thứ hai là \"lend draft cho memo\". Khi mà chạy, nó sẽ load lên kiểu như này.\n\n**01:03:33** Thì đây là cái feature đầu tiên là kiểu list ra những cái article mà em collect được từ bên phía cái email inbox thôi. Ờ một cái comment thứ hai là ờ lên draft cho Memo thì khi mà chạy á thì nó sẽ lên kiểu này. Ờ thì mấy cái như là mấy cái category, cái mấy cái main category mà giống như kiểu nếu mà mọi người có đọc mấy cái PR repo của em á thì mình chỉ có mấy cái kiểu mấy cái main stack của mình như thằng React hay là NestJS này thì nó sẽ wrap lên kiểu cũng giống như cái cấu trúc của bài Memo thôi.\n\n**01:04:14** Kiểu sẽ có 3 bài kiểu có điểm số cao nhất. Ờ rồi đây là sẽ năm bài, những cái bài relevant mà điểm số nó thấp hơn. Thì cái điểm số thì em có đánh theo kiểu nó là relevancy score. Kể vậy thì lúc mà em feed vào cho ChatGPT mini thì em sẽ yêu cầu con ChatGPT mini nó đánh, nó đánh score luôn. Ờ cụ thể cái prompt thì nó nằm ở đây. Đây là cái prompt cho ChatGPT mini kiểu vậy. Là ờ em sẽ cào hết cái email convert sang biotext giữ lại link rồi sau đó feed vô cho con ChatGPT mini với một list mấy cái criteria như thế này để cho\n\n**01:05:01** Nó đọc và nó extract, nó sẽ đánh relevancy score, nó extract article. Kiểu cái format nó giống kiểu ờ nó phải output format, cái format nó output à, dạ đây JSON array có title có description có link và cái danh sách criteria cùng với cái mớ relevancy score của nó thôi đó. Thì thì khi mà cào ra hết thì em bỏ vào cái database như vậy. Ờ cron job khi mà con bot này nó chạy á thì hiện tại em cron job cho nó chạy. Gọi sẽ có một cái job để nó chạy mỗi, nó chạy mỗi ngày thì sẽ vào lấy chỉ lấy những cái email mà chưa đọc thôi.\n\n**01:05:56** Cái thứ hai là kiểu dùng được ChatGPT Mini này là 3.5 Pro thì đang xài cũng miễn phí luôn. Thì thằng ChatGPT mini pro này nó đang cho phép mọi người lên xài miễn phí lấy API access token của nó, mỗi ngày nó sẽ cho 1 triệu token cứ muốn xài sao xài. Thì thấy cái này Ok. Ờ dạ một số cái vấn đề hiện tại với con bot này thì cái thứ nhất là\n\n**01:06:40** Một số vấn đề hiện tại với con bot này thì cái thứ nhất là em chưa có filter ra mấy cái quảng cáo. Em em lúc mà bắt filter ra mấy cái quảng cáo. Cái thứ hai là kiểu như tin rác khá là nhiều ở cái kiểu mấy cái newsletter, đôi khi nó nó include luôn những cái link như những cái description trên GitHub, những cái PR nào được merge. Cái kiểu có nhiều cái newsletter nó nó cũng khá là nhiều tin rác kiểu vậy. Em vẫn đang optimize cái prompt để cho nó relevant hơn cái use case của team mình thôi. Nhưng mà nói chung là về functionality thì hiện tại thì em nghĩ là ok rồi, giờ chỉ có\n\n**01:07:16** Nhưng mà nói chung là về functionality thì hiện tại thì em nghĩ là ok rồi, giờ chỉ có ****optimize cái prompt thôi, chắc là vậy với lại chắc optimize cái relevancy score. Ờ tại vì hiện tại xài free cho nên đang bị thiếu một cái bước là vào từng cái article để cào content đọc rồi mới đánh relevancy. Hiện tại là relevancy score nó đánh là nó đánh dựa trên cái description mà được cung cấp bên bên cái newsletter thôi. Cho nên nói chung nó vẫn củ chuối. Để coi sao để để tìm cái model nào mà nó free hoặc là chạy local đó cho nó chạy nó cào rồi nó đọc. Thế còn hiện tại thì ChatGPT mini 3.5 pro tới cào chừng 15 email là nó hết. Nó nó hết quota.\n\n**01:08:02** Mỗi ngày em chạy vô cào được mấy cái. Dạ thì chắc là game nó vậy thôi. Ok hôm trước anh có comment là cái vụ viết cái commentary về feature thì nó đang thiếu sao ta, mới chỉ đọc link với cả đọc title thì chưa đủ, phải vọc vào content vọc vào parse parse parse bên trong ấy ra. Nói chung là sẽ có thôi anh, chắc là chắc là sau cái này thì em sẽ tìm một cái model free local đó để nó handle cái vụ cào với lại parse content. Kiểu để đánh relevancy lúc đầu thật ra là lúc đầu là em xài vector cộng với similarity để match với lại\n\n**01:08:58** Kiểu để đánh relevancy lúc đầu thật ra là lúc đầu là em xài vector cộng với similarity để match với lại mấy cái category. Nhưng mà kiểu nó đánh đánh kiểu gì á em cũng không biết, do em set up sai hay sao. Tại vì cũng kêu con OpenAI nó generate embedding không à. Xong cái nó đánh cái kiểu gì mà kiểu không có match được cái article nào hết. Xong cái em mệt quá em kêu con ChatGPT làm luôn. Ừ ok rồi thì mấy anh em mấy anh em đang sort mấy cái link từ bên kia mấy cái stack khác ấy xem có tham khảo hay là crawl các thứ thì xem thử. Ừ Ok chắc test thêm. Còn về mặt hosting thì nếu mà cần thì thì nhắn Quang ấy. Hiện tại dừng này lên thôi mình mấy con bot\n\n**01:09:48** Hiện tại dừng này lên thôi mình mấy con bot của mình trên đó là hiện tại bây giờ có đang expose với webhook Discord bot không anh? Bảo em tạo cái có thể expose API ra ấy. Còn em em host một cái function nào đấy để run thì Discord nó hay xài, model còn không bảo bảo Quang host setup service host tự chọn host cho. Dạ à Quảng model cũng ok đấy model Ok free sao ấy. Ý là ở trên Discord phải nó đâu có cho mình host data đúng không anh? Tại vì hiện tại bây giờ là phải đi cào với lại lưu vào database mà. À đúng rồi nhỉ thấy cái tự setup rồi. Ừ anh chắc để em hoàn thiện hơn tí là cái gì em liên hệ anh Quang.\n\n**01:10:39** Nó chỉ là một cái bước nói là cái expose API để access data thôi còn anh em muốn lưu trữ hay là thành index các thứ gì thấy tự set up rồi ok. Ok bây giờ đang hỏi là có đâu rồi ta chạy rồi à. Bây giờ đang hỏi là có handle in-memory được không anh? Ờ nó nó nó nó. Ý là em em đang làm này là kiểu lưu về ý là batch với lại database, batch process ngay cái lúc mà cào á để lưu lại để mình cho requery thì những lần ý là mình chỉ cần cào dưới dưới. Dạ cron job thôi thì khi mà người ta query thì cái trả, cái phản hồi nó sẽ là realtime mình ý là nó trả, hồi nó nó\n\n**01:11:44** Cron job thôi thì khi mà người ta query thì cái trả, cái phản hồi nó sẽ là realtime mình ý là nó trả, hồi nó mình sẽ không cần phải, mình sẽ không cần phải làm mấy cái đó. Nếu như mà có làm in-memory này kia thì em nghĩ chắc chỉ thêm cái runtime inference thôi kiểu cho người ta query bằng ngôn ngữ tự nhiên chứ không có kiểu comment với param. Như hiện tại còn còn cái chuyện mà đi collect article thì em nghĩ em em nghĩ là vẫn nên cào rồi process rồi lưu trong database chứ chứ nếu không mỗi lần chạy đều phải cào mấy trăm article thì chết tiền à. Ủa hiện như thế nào ta? Crawl lại crawl lại được không ta?\n\n**01:12:44** Mình không set lại đâu. Thôi vì đây là một cái engineering solution nên là mình phải có cái gì cho dữ liệu back pressure thì phải cần storage. Nói chung là có cách là mình mình bơm thêm tiền thôi. Ừ trả tiền thì có nó run thôi ok rồi cảm ơn ạ. Ok check xem thử đi. Đang đang lúc này tin đang bảo là tuần sau là những cái buổi thứ tư thì hiện tại đang có cái cái cái này demo các thứ cũng đang còn tương đối đấy chắc là cũng phải 4, 5 bài nữa thì chắc mình schedule sang thứ tư rồi anh em demo sau đấy. Để tôi chấm điểm đánh giá luôn hả? Ok ý còn lại nếu không\n\n**01:13:55** Nếu không ai quất thêm mấy cái copilot còn lại thì mình sẽ làm hết đấy. Ăn hết tiền của mọi người đấy. Okay. Ơ mà chi phí đợt, tò mò tí chi phí đợt vừa rồi anh em chạy vẫn đang xài key của em đúng không hả Tô? Ờ có đúng chắc là mọi người không có tới 1 triệu token đâu vậy. Hả? Chưa tới. Chưa tới. Dạ chưa tới. Bao nhiêu đấy? Vậy hả? Giỏi ta thật! Anh em cũng test hết đấy không bằng không bằng em hoặc là đặt prompt clean deep đâu. Không bằng đâu. Ok nếu mà vẫn thì xài thử đi thôi.\n\n**01:15:08** Hẹn anh em thứ tư tuần sau. Chúc mọi người cuối tuần vui vẻ nhé.\n\n---\n\n**English Transcript**\n\n**00:00** Hello everyone, OK we're good now. Is that Thanh speaking? Can't hear you, please check your mic.\n\n**00:20** OK, we can hear you now. Let's wait for Ngoc to join for a bit before we start. We'll mainly discuss a few recent issues, probably 70% of the time will be spent on our internal matters.\n\n**00:40** We have 36 participants now, are we waiting for anyone else? If not, let's begin. Let's quickly go through some events from last month: We've returned to a hybrid work culture, encouraging everyone to come to the office a few days each week.\n\n**06:47** The purpose of coming to the office is to exchange knowledge and learn from each other more quickly compared to working online or just through OGIF sessions. After a few weeks of implementing this program, people seem quite enthusiastic. Additionally, there are several policies to support coming to the office, such as receiving ICY when checking in, and also for parking. Moreover, lunch for everyone will also be supported.\n\n**07:20** As you all know, our direction is to learn and implement as many AI and LLM-related projects as possible. I see that you're quite interested in the prompting tutorial series from Tom or new knowledge. Thanh, please share more.\n\n**07:58** I noticed that we usually have OGIF at the end of Friday, but now we've added Tom's demo session on Wednesday. In the coming time, we plan to maintain this cycle for about 1-2 more months. The purpose is to promote the use of AI tools, automation tools for work, and to learn more techniques related to applications.\n\n**08:40** Everyone should keep track to know the situation and update on current tools. Mainly, we'll learn how to build up, use tools, such as defining workflows, writing prompts correctly to apply to coding work or development-related tasks. Tom will probably be in charge of this and update knowledge for everyone.\n\n**09:23** In addition, we currently have a few policies to encourage people to focus more on AI/LLM. For example, activities or demos related to LLM from this week, the amount of ICY reward will be multiplied by 3 or 4 times, depending on the quality of the article or output. This is an encouragement for those interested in AI.\n\n**10:13** For more specific goals, perhaps early next week there will be a detailed announcement about what to focus on and which tools to use. That's it in summary, that's the general situation.\n\n**10:58** OK, thank you Thanh. So, AI-related research activities will receive 3 or 4 times the reward. Someone asked if spamming AI-related links would earn more ICY? We'll probably consider that further, each ICY is equivalent to $1.5.\n\n**11:56** To remind everyone, in our OGIF sessions, besides the demo parts, there will always be sections related to market commentary, updates from Go Weekly, AI, and soon we'll add a product design section.\n\n**12:47** One last announcement, the ops team is arranging for a company trip this December in Penang, Malaysia. Detailed information will be shared on the alert channel or by Inno. Thanh, is there anything else, or does Bao want to share anything more with everyone before we move on to the next part?\n\n**13:42** Nothing more, everyone remember to complete the BP early. Provide information through Inno to prepare for the company trip. Alright, Thanh, let's move on to the OGIF section.\n\n**14:56** Today, we plan to pick up a few demos about tool-building that you guys have done recently. Bao initiated it at the beginning of the month, so there are currently a few demos and commentaries.\n\n**15:56** First, let's give the floor to the design side with Nam Bui's part. Nam, are you ready?\n\n**16:44** Yes, I'm ready. Today, I'll present on the topic of Product Design Commentary for 2024 - Part 1. I'll talk about emerging, popular, and future domains in the Product Design industry. At the same time, I'll also mention the pain points that these domains face. If our team develops in these areas, we can use that as a unique selling point.\n\n**16:56** I'll cover 4 main domains:\n\n1. VUI (Voice User Interface)\n2. AR/VR (Augmented/Virtual Reality)\n3. Modular Design Systems\n4. AI tools supporting UI/UX workflow.\n\n**17:29** First, let's talk about VUI. Currently, VUI is widely applied in the Smart Home industry, such as controlling smart home devices, smart cars. It's predicted that by 2026, about 50% of the US population will use VUI on their devices.\n\n**17:44** In Vietnam, FPT.AI is currently the strongest in this field, with applications like Kiki App integrated into car devices for navigation. Worldwide, popular VUI applications like Amazon's Alexa, Google Assistant, and Apple's Siri are dominating the market.\n\n**17:44** Summarizing user feedback, Alexa has an advantage in NLP but is not strong in programming. Google Assistant integrates Google Search, so it has diverse but not deep knowledge. Siri is the weakest of the three, mainly using Bing, but its tone is not very friendly.\n\n**17:56** Moving on to PP (Predictive Programming), this technology is not yet widely applied to Chinese and Vietnamese. It mainly focuses on English and other popular languages, due to the lack of AI training data for complex languages. But in the future, with technological and data developments, I believe PP will become more popular with these languages.\n\n**18:13** Regarding Predictive Programming (PP), this technology is not yet widely applicable to languages other than English. Complex languages like Chinese or Vietnamese are not well supported. Usually, users need to be proficient in English to effectively utilize PP. In terms of flexibility, PP is not yet smart enough to understand every context we speak; it only understands when we follow exactly the pre-programmed command patterns. This is also a weakness that needs to be improved in the future.\n\n**19:00** Next, I'll talk about AR/VR (Augmented Reality/Virtual Reality). This field is currently focusing mainly on industries like e-commerce, real estate, helping users to experience directly without having to be physically present. For example, they can preview a house through a VR application instead of visiting in person. In 2019, the market value of AR/VR was only about $0.44 trillion, predicted to reach $1.73 trillion by 2024, and potentially hit $40 trillion by 2027.\n\n**19:46** However, many businesses have tried to apply AR/VR to their websites, but most have withdrawn due to unstable performance issues. From early 2023 to late 2023, AR/VR was widely applied, but by early 2024, many businesses started to withdraw from websites due to poor user experience, especially when users access and encounter lag or slow loading speeds.\n\n**20:54** This frustrates users, causing them to quickly leave the website. Moreover, the cost to develop and maintain AR/VR is very high, so only large businesses with surplus budgets can invest in this technology. Small and medium-sized businesses often don't want to spend too much on integrating AR/VR into their websites.\n\n**21:38** The next part is about Modular Data Systems, focusing on using reusable design components to help effectively coordinate between designers and developers. Currently, there are many popular design systems on the market, combining both Figma UI files and UI components supported by libraries.\n\n**22:17** The most popular example is the Ant Design System, however, the UI of Ant Design is now a bit outdated. In addition, there are more modern choices like Tailwind UI and Chakra UI. The way designers and developers collaborate is by using the same set of Figma files from the library, the designer will design based on that set, and the developer uses the corresponding components to develop.\n\n**23:00** For example, if a designer wants to create a table, they'll choose the table component in Figma, and the developer will use that exact component to build in code. This ensures consistency between design and implementation, helping to minimize discrepancies between the design and the final product. Currently, many libraries also support responsive design, helping developers avoid having to redo for different devices.\n\n**24:09** Our team also has a team called Mochi that's developing its own Design System. One issue when applying these libraries is that the product may lack uniqueness, the distinctive mark of each application. For example, if 10 applications use Ant Design, their interfaces will look very similar, with no differentiation.\n\n**24:56** Therefore, designers and developers need to coordinate very closely. If a designer wants to customize any component in Figma, they need to immediately notify the developer to update the corresponding code. This requires continuous communication between both sides to ensure consistency throughout the development process.\n\n**25:41** Regarding AI tools supporting UX/UI, AI tools help us analyze user behavior accurately and quickly. For UI, AI can help create components or styles suitable for different fields. Tools like ChatGPT, Claude AI, and Midjourney are doing very well in supporting UX/UI research and development.\n\n**26:32** Currently, for UI, it mostly supports creating images but can't create vector or pixel formats that we can edit. However, some tools are trying to improve this. For example, when using Midjourney, we can generate images and import them into Figma, and now it has the ability to copy them into layouts with Figma's auto layout, making editing easier.\n\n**27:24** But in general, AI's output for UI is still mainly in image format, rarely able to generate vectors or components that can be used directly in design. This is a weakness and limitation of current AI technology in supporting UI design.\n\n**28:20** For UX, I notice AI is supporting much better. For example, when we receive a brief requirement from the client, we can input it into ChatGPT to get a suggestion about information architecture or suitable UX solutions. In fact, sometimes I don't fully grasp all the requirements, but when I input them into ChatGPT, it provides very useful ideas that meet the client's needs.\n\n**28:55** However, with UI, even if we use AI, it's still difficult to create designs exactly as we want. Even if it can create them, the output is usually just in image format, not files that can be used directly like Figma or Sketch. Therefore, in the UI area, current AI still has many limitations and needs further improvement.\n\n**29:20** Do you agree with me? AI seems to be doing better with UX than UI.\n\n**29:45** Exactly. Especially when we work with information architecture requirements, AI often produces quite accurate and appropriate results, saving designers a lot of time. But with UI, human intervention is still needed to ensure aesthetics and accuracy.\n\n**30:30** If there are no other questions, I'd like to conclude my presentation. Thank you all for listening, and I hope you can apply some points from this presentation to your daily work.\n\n**31:00** Thank you, Nam Bui, for the very detailed and comprehensive presentation on Product Design Commentary 2024. The insights about AI supporting UX/UI are really useful and provide the team with new perspectives on applying AI in design. We hope to hear more interesting presentations from you in future OGIF sessions.\n\n**32:51** Last week, I saw two articles like this. Actually, there's another one related to GUI, but I'll talk about that later. First is the article about \"register allocation\" of the Golang compiler. This article is a bit complex, so I can't include all the content here. Mainly, Go implements register allocation through the SSA (Static Single Assignment) step.\n\nYou can read more in the link I've put here. But in general, this article focuses on the process of optimizing compilation using SSA to manage register allocation.\n\n**37:43** To summarize, this process helps improve the compile time of Golang programs. Specifically, it focuses on optimizing two main steps: register allocation and stack allocation, thereby helping to reduce compile time by about 20%, especially useful for Go applications with complex logic or large applications.\n\nThis is a very detailed and thorough article, written by one of the experts in the Rust community. This article is very useful for those interested in the compiler process or wanting to learn more about Go's performance.\n\n**38:17** Moving on to the second part related to AI. It's a new solution called BBQV, a Vector Index developed by a group called Dexa in the US. BBQV focuses on its main strength of \"scalable vector search.\" The interesting point is that BBQV is neither the fastest solution nor the most accurate, but it has the ability to build indexes extremely quickly compared to other solutions. In a moment, I'll show you the chart where the BBQV authors compared it with other ANN (Approximate Nearest Neighbor) solutions.\n\n**39:13** The outstanding feature of BBQV is its ability to build indexes very quickly, although its query time is only average compared to other solutions. To compare more specifically, on the chart below, BBQV is in the middle when it comes to query time but is among the fastest in build time. This is a bright spot when deploying BBQV in large-scale AI systems, as index building time is very important.\n\n**39:24** Additionally, there's another article related to GUI in Go. Although GUI in Go is not a strength, I still found some interesting GUI solutions and want to introduce them to everyone. Recently, the Go community has been trying to build GUI libraries that can compete with other solutions like Qt or Electron. However, most of these GUI solutions are still not really complete and lack features compared to popular libraries from other programming languages.\n\n**39:59** That's what the Dex team is using, Dex AI is using this, and it's also been open-sourced.\n\nThis chart shows that BBQV's query time is not the fastest but very stable. However, in terms of build time, BBQV is one of the fastest solutions. Because it's kind of its \"selling point\", to build an index, using this one is the fastest.\n\nAs for another article about GUI, we didn't include it here because generally, we see that Go GUI is somewhat limited. But we found one that's considered the best in Go. Its accessibility, its gallery is also beautiful, and overall it's quite mature. Recently, there's a new language called R, it's also written in Go, and it also has an extension integrated with this GUI. Overall it looks like this, for example it looks like this.\n\n**40:24** In addition, there's another topic related to GUI in Go. Although GUI is not a strong point in Go, I still found some interesting GUI solutions and want to introduce them to everyone. In recent times, the Go community has been trying to build GUI libraries that can compete with other solutions like Qt or Electron. However, most of these GUI solutions are still not fully developed and lack features compared to popular libraries from other programming languages.\n\n**40:44** Currently, our DEX AI team is using this. It's open-source, so it's very convenient to integrate into our system. As for the GUI aspect, I've also researched more about libraries for Go. To be honest, Go's GUI is still quite limited (constrained), but I found a library called Fyne. This is one of the best GUI libraries currently available for Go. Its interface (UI gallery) is also very beautiful and mature, meaning it's quite well-developed compared to other libraries.\n\n**41:45** And recently, a new language called Gio has emerged, also written in Go. It provides some extensions that can be directly integrated with Fyne, creating GUI interfaces as you see here. It seems this trend is developing quite rapidly in the Go community. For this part, I'll stop here to move on to Phat's section. I don't know if Phat wants to share more?\n\n**42:46** Um, from my observation, I've noticed that the name BBQ has become popular in the field of vector databases (vector DB). Many new projects use BBQ because the name sounds good, but in reality, vector databases like this have gone beyond the simple concept of dimensionality. Choosing which vector DB is suitable will depend a lot on factors like performance and features. Although BBQ sounds fun, in terms of search speed and recall efficiency, it may not be the fastest, but it still achieves very good performance. The fastest here might be 'HNSW,' however, BBQ is still a stable choice.\n\n**44:03** As for case studies of large companies using Golang, we have gathered some very interesting information. As mentioned, Google - of course, can't be missed, because they are the creators of Golang. Other big businesses like Meta, Microsoft, and companies in the financial sector like American Express, Monzo, and Paypal have all implemented Go in their systems. In the streaming sector, Twitch is also a big name using Go for their backend. In the gaming industry, Riot Games has also used Go in some of their services. I will continue to update more detailed information about these case studies.\n\n**45:51** There, on Tom's side, the script part is probably basic, right? Yes, it's quite basic. If there's time, we can quickly demo it. Okay, so let's talk about the YouTube transcript. Actually, before that, our team already had an engine to process this part, but it seemed to be limited. It was limited by a duration of 50 minutes or something, so I rewrote a backend to process it using the Whisper API.\n\n**46:42** This Whisper API has a free package for audio transcription. It allows us to transcribe about 600 minutes of audio for free per day, but each file can only be up to 2 hours long. We utilize this Whisper API to convert YouTube video content into text format. The basic process is when we input a YouTube link, the backend system automatically downloads the video file, then converts that file to MP3 format, and then compresses it to fit the file size limit of the Whisper API (25MB per file).\n\nThe compression and processing time will depend on the length of the original video. After the processing is complete, the system will send each compressed audio segment to the Whisper API to perform the conversion from audio to text. The results returned from the API will include detailed information for each segment, from start time to end time, and the corresponding text. These segments will then be combined and further processed through GPT-4 to refine and adjust the wording, ensuring the output text closely matches the original language and is more accurate.\n\n**48:21** Based on such segments, we combine them and use GPT-4 to tweak little details there. Usually, English doesn't have any errors. But for Vietnamese, it has issues with some parts, for example, in the North, pronouncing the falling tone as rising tone, pronouncing 'r' as 'd'. When we get such output, when reading, it will be incorrect. Therefore, we feed that content to GPT-4 for it to correct, and as a result, we'll have a complete text that matches the original YouTube video.\n\nAfter getting such content, we send it up to D. It receives this D, this app, it uses a tool to call the backend from earlier and it receives JSON like this. From there, it pops up, and continues to use a library to render the transcript like this. It returns a content section like this, including the full content.\n\n**49:55** That's what we've been able to do. If we use the subscription plan of Whisper API, we won't be limited by only being able to convert about two hours of audio every hour. However, there's another limitation when deploying to a server via Heroku or some other servers, because this audio processing is quite time-consuming, so sometimes there are timeout issues. But if we run directly on local, everything will be much smoother.\n\nThat's why we use this tool on the OIP project side. There's a part for editing transcripts that you guys review, I'm not sure if it's using this one or something else?\n\nCurrently, we're adjusting the config to use this tool more appropriately. Tom's part seems to be broken or something. Because our current OGIF part is very long, also over an hour, so to process that entire segment, we may need to improve the performance of this tool to make it work better.\n\n**50:40** Which free API are we currently using? There are three workflows, two are free APIs, one is mine, mine has been blocked by YouTube. It seems unstable, right? Yeah, it's stable sometimes and not at other times, both have been blocked. There's one API left, Note GPT, which My's side is using, but for long transcripts, it's also likely to crash.\n\n**52:18** Ok, that's right, sometimes it's stable, sometimes it's not. Actually, if the video is under 10 minutes, it always works, but once it gets a bit longer, it depends. The issue is with the resources on the free server; it's uncertain whether it can reset or not. But if it's long, you can just bring the source back and run it locally.\n\n**53:35** You all can see on the AI comment section on Discord, we've already got some scripts from Twitter. So, the process we're working on is creating an API from the Python model script. After that, we deploy it directly; this model has a mechanism that allows us to deploy it directly as an API.\n\n**54:53** We then use this API to script information from our side. It acts like a script running like this, a function on a container that runs a browser, looks into the viewport, and takes the selectors and text information from that container of ours. Then, we expose it as a POST request.\n\nThis POST request only needs a URL. For example, if we want to fetch data from Twitter, or take it from sc.com, for instance.\n\n**55:39** If we want to script this data, we can test it directly on the Postman request, but with Dify, we can test it directly on here. And the best part is, after testing, we can convert the workflow from Dify into a function call, which can be applied on an agent or something else specific for Dify.\n\n**56:38** This is integrated with Discord AI, so if anyone wants to summarize from Twitter, they just need to post the link, and it will automatically summarize it. It seems to be lagging now, though. Let's try running it again. It seems to be lagging, but just imagine that it's fetching from Twitter. Later, we'll use this method to script from Facebook, and Hoang is using this method to upload an API through a model to script and pull data from Discord messages.\n\n**57:53** This is when we consolidate it; Dify can auto-convert it into a tool. Normally, you can publish it as a standalone app and interact with it. What's better is that you create a workflow tool, and it will arrange it like a function call on the OpenAI side.\n\n**58:37** This is the Discord AI bot that everyone is using for AI comments within our team Discord. Currently, it has several tools we've made ourselves, like the Twitter script that's integrated here. Another is for obtaining YouTube transcriptions from a service that I made, and another is for querying memos, which is tooling I created to pull data from our team's Memo. The rest are tools available on Diffy. When you want to add a tool, it will be listed in the workflow list. After creating a workflow, deploying, and configuring it, it will all be displayed here.\n\n**59:17** Let’s try, “What are the latest notes added to the doors?” It will take the Prompt Token from the tool’s description and the system prompt to determine the most appropriate tool to use. So, it fetches data based on two factors, right? The first is your system prompt, and the second is the tool’s description. Based on the initial query input, it detects which tool should be used for the next process, right?\n\n**01:00:46** Quick demo of the tool to support memo creation, specifically the current transcript. Right now, it functions as a Discord bot like this. I'm hosting it on my machine because servers cost money. It has two main commands. One is the list command, and its functionality is simple, it has an account that collects newsletters. This means the data source consists of newsletter emails. I use an email to subscribe to about 100 different sources, but everything comes to this one. It's simple: any new email that hasn't been read yet, I scrape it.\n\nFor the backend, I built it using Python. This app is 90% standard core code.\n\n**01:02:55** The functionality is straightforward. When I scrape, it will create a table of articles like this. It creates a table with the title and description in detail. I use BeautifulSoup to extract these, which I'll show later. But in terms of functionality, it's pretty simple.\n\nFor example, if I want to retrieve seven articles from a specific category, all within seven days, I fetch all articles that belong to all categories within seven days. Then it returns in this kind of presentation list.\n\nThis is the first feature, listing the articles I’ve collected from the email inbox. The second command is “lend draft to memo.” When running it, it loads up like this.\n\n**01:03:33** This is the feature that lists the articles collected from the email inbox. Another command is “lend draft to memo,” which, when executed, loads like this. For instance, if you’ve read my GitHub repositories, we have a few main stacks like React or NestJS. It structures it similarly to a Memo article.\n\n**01:04:14** It provides three articles with the highest scores. Then there are five relevant articles with lower scores. The scoring is based on relevancy. When feeding it into ChatGPT mini, I ask it to score as well. The prompt is located here. This is the prompt for ChatGPT mini.\n\nI scrape all the emails, convert them to plain text, keep the link, then feed them to ChatGPT mini with a list of criteria like this.\n\n**01:05:01** It reads, extracts, and assigns a relevancy score, extracting articles. The format resembles a JSON array with the title, description, link, criteria list, and the relevancy score. After scraping everything, I store it in the database like this. A cron job is set to run every day, fetching only unread emails.\n\n**01:05:56** The second feature is using ChatGPT Mini 3.5 Pro, which is currently free. ChatGPT Mini Pro allows free API access tokens, giving 1 million tokens daily for free. So far, it works fine. Some issues with the bot are that I haven't filtered out ads yet, and there's quite a bit of spam in newsletters.\n\n**01:06:40** One of the current issues with this bot is that I haven't filtered out ads. The second issue is spam in newsletters; sometimes, it includes links like GitHub descriptions, merged PRs, etc. Some newsletters contain a lot of spam. I'm still optimizing the prompt to make it more relevant for our team's use case. Functionality-wise, it's okay for now; I just need to optimize the prompt.\n\n**01:07:16** Optimizing the prompt is the main focus, and I need to optimize the relevancy score. Because it's currently free, it lacks the step to scrape content from each article and read it before scoring relevancy. Currently, the relevancy score is based only on the description provided by the newsletter, which is still inadequate. I’ll look for a model that's free or runs locally to handle scraping and reading content. Currently, ChatGPT Mini 3.5 Pro can handle scraping about 15 emails before it reaches its quota.\n\n**01:08:02** Every day, I scrape only a few. As for future enhancements, I’ll try to find a free local model to handle scraping and parsing content. Initially, I used vectors and similarity to match categories, but the scoring setup was somehow wrong. The embeddings generated by OpenAI weren't matching any articles correctly, so I eventually let ChatGPT handle it.\n\n**01:08:58** Then the team can look at links from different stacks, consider references, or run their own tests. If hosting is needed, contact Quang. We have our bots running on our own servers.\n\n**01:09:48** If needed, you can expose APIs to Discord bots. I created one that can expose APIs, and you can host any function you need to run. Dify uses models or Quang hosts setup service; you choose what to host yourself. Dify's model is quite okay and free to use. It doesn't allow hosting data directly, so right now, we're scraping and saving into a database. You might need to set up the system yourself.\n\n**01:10:39** It’s just an extra step for exposing APIs for accessing data. You decide on storage or indexing. Okay, now they’re asking, can it handle in-memory? I’m doing batch processing immediately when scraping, saving for requery purposes later. When someone queries, the response is real-time; you won’t need to run multiple times.\n\n**01:11:44** Cron jobs handle data collection; for querying, in-memory or local runtime inference can be added to enable querying through natural language rather than with parameters. I believe content collection should be processed and stored in a database; otherwise, scraping hundreds of articles every time would be costly.\n\n**01:12:44** You can't avoid setting this up. As this is an engineering solution, storage is needed for data and backpressure. One option is adding more funding for it to run as required. Thanks. Let's check later; Wednesday's demo sessions have quite a lot already, maybe four to five more presentations. We might have to schedule for Wednesday.\n\n**01:13:55** If no one else wants to handle the remaining Copilot tasks, we’ll take them all. Eat up everyone's money! Out of curiosity, the recent expenses, are they still using my API key, Tô? Yes, I believe everyone hasn't reached 1 million tokens yet.\n\n**01:15:08** Anyway, see you all next Wednesday. Have a great weekend.\n","title":"OGIF Office Hours #25 - Team \u0026 Community updates, Hybrid culture, Product design commentary, AI Tooling Insights, Golang weekly","short_title":"#25 Team updates, Hybrid work, AI insights, Go weekly","description":"OGIF Office Hours 25 covers the latest insights on hybrid work culture, AI-driven tooling and workflows, Golang compiler optimizations, and AI-enhanced design strategies. Explore discussions on AR/VR trends, voice user interfaces, AI tools for UI/UX, predictive programming, and team demos showcasing AI integrations and Golang performance tweaks.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Mon Sep 30 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/25-20240927.md","slugArray":["updates","ogif","25-20240927"]}],"newMemos":[{"content":"","title":"New Brainery","short_title":"","description":"","tags":["earn"],"pinned":false,"draft":false,"hiring":false,"authors":[],"date":"Thu Apr 03 2025 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"earn/open-source.md","slugArray":["earn","open-source"]},{"content":"","title":"New Brainery","short_title":"","description":"","tags":["earn"],"pinned":false,"draft":false,"hiring":false,"authors":[],"date":"Thu Apr 03 2025 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"earn/productivity.md","slugArray":["earn","productivity"]},{"content":"","title":"New Brainery","short_title":"","description":"","tags":["earn"],"pinned":false,"draft":false,"hiring":false,"authors":[],"date":"Thu Apr 03 2025 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"earn/quality.md","slugArray":["earn","quality"]}],"teamMemos":[{"content":"\n## Record \u0026 reward sharing at Dwarves\nIf you're part of the Dwarves community, you'll notice our culture of continuous learning and knowledge sharing. This culture isn’t just about individual growth; it’s also about building a strong, connected community.\n\nWe believe learning is key to success and our goal is to create an environment where it’s prioritized, valued, and rewarded, allowing everyone to grow. \n\nTo support this, we’ve organized a variety of engaging events and activities that encourage and recognize knowledge sharing. Additionally, we allocate a portion of our profits to acknowledge these contributions with awards.\n\n## Our approach to learning and growth\nLearning goes hand in hand with a growth mindset. In our fast-moving industry, staying ahead means picking up new knowledge all the time. The more knowledge you share, the more rewards you earn. It’s that simple.\n\n## Monthly pool of up to 2500 ICY for recognized contributions\nWe’ve set aside a monthly pool of **2500 ICY (around $4000)** to reward those who contribute valuable insights. **70%** of this pool is dedicated to those who actively share knowledge across the community. \n\nAdditionally, we place extra value on contributions in key areas like **AI/LLM**, **Golang**, **Software Architecture**, and **Blockchain**. If you’ve got expertise in these fields, your insights will be especially appreciated and may earn you more ICY.\n\nCheck out the [**🧊・earn-icy**](https://discord.com/channels/462663954813157376/1006198672486309908/1239502938918096960) channel to see how we distribute our ICY and get involved.\n\n## How you can participate and make a contribution\nIf you have something worth sharing? Drop useful links in our research channels such as [**💻・tech**](https://discord.com/channels/462663954813157376/810481888619135046/1281086341995565057), [**💡・til**](https://discord.com/channels/462663954813157376/1001883339046797342/1281097209072320615) to get recognized. Got a topic in mind? Present it in our OGIFs or submit a note to our [**memo**](https://memo.d.foundation/). Community members are welcome to participate too.\n\nWe also love open-source work, especially building tools that boost our productivity. If you’re into that, join the force at [**🦄・build**](https://discord.com/channels/462663954813157376/1280726623414390805/1280791483280261161) and start cooking up something great.\n\nWe hope this push will keep our learning culture strong and moving forward.\n\nHappy coding and sharing!","title":"Record and reward sharing at Dwarves","short_title":"","description":"Discover how the Dwarves community fosters a culture of continuous learning and knowledge sharing. With a monthly reward pool of up to 2500 ICY, contributors are recognized for sharing valuable insights, especially in areas like AI/LLM, Golang, and more. Get involved and grow with us.","tags":["reward","team","community"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_","thanh","monotykamary"],"date":"Thu Sep 05 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"playground/01_literature/record-reward-sharing-culture.md","slugArray":["playground","01_literature","record-reward-sharing-culture"]},{"content":"\n## Towards growth\n\nKeep learning and growing. We started this team out of software practice advancement. The continuous study lays the foundation for the future growth. Just like software, knowledge must evolve and be useful. We collect the lesson learned and input into our [**team knowledge base**]().\n\n## Purpose-built\n\nEverything we do comes with [**the purpose behind**](). Good software is software that works and provide actual value. Effort is count when it's placed on things that matter.\n\nThey are apps and systems for mass market. But they can also be a custom script to automate the build pipeline; a website for a non-profit organization, or an open source desktop app.\n\n## Effective \u003e productive\n\nWe try to work on things that create the most value possible in a certain amount of time. Know your priority and do things that matter.\n\nBeing productive is about occupying your time, filling your schedule to the brim and getting as much done as you can.\n\nBeing effective is about finding more of your time unoccupied and open for other things besides work. We don't believe in busyness. We believe in effectiveness.\n\n## Keep it simple\n\nSo everyone could understand. Going simple makes everyone easy to follow.\n\nTake boring solutions and legacy tooling. Use simple words rather than Cambridge-based synonyms.\n\nAfter all, what's important is the problem was solved, not what fancy tool we picked.\n\nShiny toys can cloud our judgement. Sometimes, simple is harder than complex.\n\n![Dwarves team culture principles illustrated diagram](assets/culture-principles.webp)\n\n## Go the extra mile\n\nTry to do more than what required to do. Make the 5% impossible possible.\n\nSpend a bit extra effort. Little things count. How you approach. How you solve or react to it. You'll be amazed by how effective it becomes by [going extra](https://memo.d.foundation/Go-the-extra-mile-4f4051d924444c62bb309cc4864b40df).\n\nSoftware gets updated to bring a better experience. That should applies in everything else. Every time you look back on your work, there should be something to improve.\n\n## Think long-term\n\nMaking any kind of actions, we think about the long-term effects. Every decision we make today can lead to an impact in the future. The technology we endorse, the solution we choose to solve the problem; The founder we backed, the startup we invest into; The people we work with, the way we handle the customers. It also includes how we talk about ourselves, the attitude toward peers.\n\n## Pay it forward\n\nGive before you get. We foster a place for collaboration and productivity, a pay-it-forward chain is vital. It's about passing on wisdom and taking the time to engage in valuable grasp for the less-experienced one.\n\nIt creates a culture of mentoring and ensures we're all moving forward.\n\n## Bond through goals\n\nWe move toward mutual goal. Having a share sense in goal drives us closer to success without distraction.\n\nThough the execution methods might be different, a consensus in goal will synchronize the output and get things done seamlessly.\n\n## Value the difference\n\nHaving multiple authenticity and the will to do right things helps us see differently with fisheye views.\n\nIt gives us more on what we currently know. We trust on that to diversify the team in knowledge base and social experience.\n\n## Making decision as team\n\nThe skillset is essential, but it isn't as important as vision and coordination.\n\nIt's ok to know more, but it's better to learn more. Everyone has something that they could improve upon, including yourself.\n\nBe supportive and values every decision as long as it contributes to the team benefit.\n\n## Thoughts on software\n\nSoftware is continuously changing the world. It's the tunnel to the future. One of our bet is on the Web3, the Open Internet and the next gen automation software using AI and Big Data.\n\nThat's happening and will continue to impact the entire world for the next 10 years. And with that believe, we want to be a one that construct the next future of things.\n\n## Engineering discipline\n\nSoftware engineering is about collaboration. It is what happens to programming when you add time and other programmers.\n\n**Discipline is required** to follow the flow. Not applying software engineering methods results in more expensive, less reliable software, and it can be vital in the long term.\n","title":"Culture Handbook","short_title":"","description":"Keep learning and growing. We started this team out of software practice advancement.","tags":["hiring","career","team"],"pinned":false,"draft":false,"hiring":false,"authors":["nikki","duy"],"date":"Fri Dec 15 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"careers/culture.md","slugArray":["careers","culture"]},{"content":"These red flags are things we don’t want to see in our peeps. Even when you think they are improper, don’t waste your time with a wrong group of people.\n\n**Negative attitude**\n\nThe employee may exhibit a negative attitude towards their work, colleagues, or the company. They may also show signs of disengagement, lack of motivation, lack of integrity or unwillingness to learn.\n\n**Incompatibility**\n\nThe employee may **not fit** in with the company culture or may have a personality clash with other team members.\n\n**Lack of professionalism**\n\nThe employee may display **unprofessional** behavior such as ⚠️ being consistently late, no show up during working hours, missing deadlines, or failing to communicate effectively.\n\n**Poor performance**\n\nThe employee may not be meeting the expected performance standards and may be **struggling to complete tasks on time**.\n\n**Low morale**\n\nThe employee's presence may be **causing low morale** in the team or even leading to a toxic work environment.\n\n**High turnover rate**\n\nIf the employee has a high turnover rate, it could be a sign of a bad hire.\n\n![](assets/red-flags_8e2d26f28c0d107f0b2dba0b99c0da5e_md5.webp)\n","title":"Red Flags","short_title":"","description":"These red flags are things we don’t want to see in our peeps. Even when you think they are improper, don’t waste your time with a wrong group of people.","tags":["people","teamwork","performance"],"pinned":false,"draft":false,"hiring":false,"authors":["tieubao"],"date":"Thu Feb 16 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"playbook/operations/red-flags.md","slugArray":["playbook","operations","red-flags"]}],"changelogMemos":[{"content":"\nWe kicked off our gathering after Tết, bringing the community back together in true Dwarves style - dropping some SOL and ICY tokens into everyone's wallets, bringing the community back together in true Dwarves style. Not a bad way to start the year.\n\n![](assets/15-new-year-gathering-airdrop.png)\n\n![](assets/15-new-year-gathering-airdrop-icy.png)\n\nOn the first day back, the team flooded Discord with Tết stories and updates. Between the usual tech talk and project discussions, conversations shifted to lucky money tales, family gatherings, and the inevitable food coma from too many bánh chưng and bánh tét.\n\nSome bragged about their winning streak (or admitted their losses) in traditional New Year games, both the triumphs and the mishaps. Others shared their first sips of spring wine, late-night card games, and that one cousin who somehow always wins.\n\n![](assets/15-new-year-gathering-convo.png)\n\nPhotos and stories kept rolling in. From pristine beaches and mountain retreats to hometown reunions and family feasts, each snapshot captured a different way the team spent the break. Some took the chance to travel, exploring new places. Others returned to familiar spots, embracing the warmth of home, reconnecting with loved ones over shared meals and old traditions.\n\n![](assets/15-new-year-gathering-moments-1.png)\n\n![](assets/15-new-year-gathering-2.png)\n\nAnd of course, there were those who simply recharged ,  sleeping in, catching up on games, and enjoying the rare quiet before diving back into the grind. Now, we’re back at it, picking up where we left off. The Year of the Snake has just begun.\n","title":"Weekly Digest #15: New year Gathering: Sharing Tết, starting strong","short_title":"#15 New year gathering","description":"Tết break came to an end, and the Dwarves team reunited to share stories, reconnect, and kick off the Year of the Snake in style. We brought it all back to Discord, along with a little SOL \u0026 ICY drop to start the year right.","tags":["weekly-digest","team","community"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Tue Feb 04 2025 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/15-new-year-gathering.md","slugArray":["updates","digest","15-new-year-gathering"]},{"content":"\nSince the start, Dwarves has valued flexibility, allowing our team to work where inspiration strikes. But there's something special about being together, learning, sharing knowledge, and working side by side.\n\nThat's where our hybrid working model steps in.  \n\nWe didn’t aim to fill desks but to create a space where you can learn, connect, and rediscover the energy that comes from working alongside others, even if it’s just for a day or two.\n\n### What makes the Dwarves office different\n\nAs a borderless software team, we know not everyone finds comfort or focus working remotely all the time. Even local cafes have their charm, but let’s be honest, it’s not always smooth sailing. That’s why our engineers have the full support they need to perform at their best.\n\n**1. Work in comfort**\n\nFrom **Apple Studio Displays** to **Herman Miller chairs**, we’ve set up workspaces adapt to you. Whether you need a quiet corner or an open area for brainstorming, you’ll find a spot that suits your style.\n\n**2. Productivity perks**\n\nDistractions? Not here. With high-speed internet, tranquil meeting rooms, subsidized meals, and 24/7 access, you have everything you need to stay in the zone.\n\n**3. A supportive environment that fuels growth**\n\nEvery interaction, every conversation, is a chance to pick up something new or share what you know.\n\n![](assets/14-back-to-the-office-team.png)\n\n### Why our office check-in is worth it\n\nWe’ve added a little extra motivation to make coming into the office more rewarding. Every time you check in at **🏢・lobby**, you’ll earn **5 ICY** tokens as part of our daily team perks. It’s our way of encouraging you to take advantage of everything the office offers and to make every visit count.\n\n- **Simple and quick:** Check in, earn your ICY. Kick-off your day with a little boost.\n- **Earn while you work:** Whether you're here for a focused work or to catch up with teammates. You’re rewarded just for showing up.\n- **Stay connected:** These perks are little a reminder that we’re building something together, day by day.\n\n![](assets/14-back-to-the-office-checkin.png)\n\n### Shaping a place for real learning\n\nWhy leave your home office? What makes this place worth the trip? It’s not about fancy setups. Team members who hadn't visited in a while began dropping by, finding new ways to connect.\n\nWhen @tom picks up a new skill, he shares it with everyone in person. It was him, standing by a desk, showing others in real time. These face-to-face exchanges spread knowledge throughout the team effortlessly. We didn’t force people back; they started coming in because something changed.\n\nYou see, there are things you can’t capture in a digital thread. A quick tip, a shared screen, a face that lights up when they finally get it. That’s learning.\n\nWe didn’t aim for a typical office with rigid desks. Instead, we created a space where reaching out feels natural, and where every conversation might teach you something new, where knowledge isn’t just passed around, it’s lived and experienced.\n\n![](assets/14-back-to-the-office-teamwork.png)\n\n### Real voices: What our team says\n\nDon’t just take our word for it, here’s what some of our team members have to say about coming back to the office:\n\n- “The quick chats turn into real learning moments. In an environment where mentors and seniors are always learning, newbies feel encouraged to do the same. It’s all rooted in Dwarves' mentorship culture.” - @datnguyen\n- \"Working from the office helps me stay focused, and it's easy to reach out when I need a hand. It feels good to have that balance.\" – @vincent\n- \"I appreciate the mix of working remotely and coming in. The face-to-face chats and shared meals make it feel more connected. It truly embodies the spirit of engineers.\" – @nhuthuynh\n- \"It’s not just about working harder; it’s about working smarter. I’ve shared a lot of knowledge by bouncing ideas off my teammates\" – @tom\n- \"Being at the office a couple of days a week has made it easier to separate work and home life. Plus, it's good to see everyone now and then.\" – @nam\n\n### Where work meets growth\n\nThough this is still in the early stages, some of us have already reached the hub and made it their go-to spot for getting into the zone. We’d be glad to have you as one of them.\n\nAlong with everything, we do everything we can to level up our team. In the end, it’s not just about work; it’s about how we grow, together.\n","title":"Weekly Digest #14: Embracing hybrid work - the best of both worlds","short_title":"#14 Hybrid work harmony","description":"Discover how Dwarves embraces hybrid working, blending flexibility with in-person connections. Learn how our office space fosters productivity, learning, and real collaboration, even if it’s just for a day or two a week.","tags":["weekly-digest","team","hybrid-working"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Wed Sep 25 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/14-back-to-the-office.md","slugArray":["updates","digest","14-back-to-the-office"]},{"content":"\nWelcome to this week's edition of our roundup, where we highlight the moments that make us more than just lines of code. This week, we're jet-setting around the world with our team's summer adventures, unveiling new memo features, and cheering for a beloved teammate's new chapter in the US. From beachside workspaces to anime figurine collections, we've got it all.\n\n### Memo submission and boosting team contributions\n\nIn the upcoming phase, the team will focus on streamlining processes and developing tools to make memo submission easier for everyone. Here are two ways we're helping you stay up to speed:\n\n- Use commands like `?memo pr` and `?memo list` to check out the latest memos. (Shoutout to @ohagi for this!)\n- Receive webhook notifications in the Discord server for new PRs, speeding up memo operations.\n\nWe're also introducing tooling for submitting fleet notes directly on Discord and automating the distribution of ICY to everyone. However, the amount of ICY distributed is still below the team's limit, so there's plenty of room for more contributions. Everyone can join hands.\n\n![](assets/13-more-than-lines-of-code-icy-updates.webp)\n\n![](assets/13-more-than-lines-of-code-memo.webp)\n\n### Summer snapshots: where our remote team works\n\nThis summer, our team's \"Summer Times, Where Are You Working From?\" updates took us on a virtual journey around the world. We saw it all: Swiss mountains, Vietnamese beaches, killer nail art, desks so neat they spark joy, anime havens, and even our COO chilling beachside (while \"working,\" of course).\n\nThese snapshots of our team's lives, filled with personal flair, with a mix of personalities and passions that make our team so rad, no matter where we're working from.\n\n[Check out the full recap of our team's summer escapades.](https://memo.d.foundation/updates/digest/12-where-are-you-working-from-this-summer/)\n\n![](assets/13-more-than-lines-of-code-summer.webp)\n\n![](assets/13-more-than-lines-of-code-summer-moments.webp)\n\n### A fond farewell and best wishes to our teammate Hieu Phan\n\nAs you all saw in the lobby last Friday, we had our final team dinner with @hieuthu1 before his move to the US. The memories we made together in Vietnam will always stay with us, even as he embarks on his new journey under American skies.\n\nHe was always a caring presence at Hado, a fantastic cook, and a friend who joined us on afternoon walks after work, always connecting everyone on the team. We wish you all the best on your new adventure and don't forget to call us.\n\n![](assets/13-more-than-lines-of-code-farewell.webp)\n\n![](assets/13-more-than-lines-of-code-farewell.png)\n\n### Celebrating the newborn\n\nCongratulations are in order for @thanh, who recently welcomed a new addition to his family. The whole team is overjoyed for him and his partner as they embark on this exciting new chapter. There's been plenty of well-wishing and baby-related chatter around the team.  \n\nOf course, with such happy news, the playful banter has already begun: who's going to be the next to share a baby announcement? We'll have to wait and see.\n\nIn the meantime, we're sending Thanh and his family all the best as they navigate the joys (and sleepless nights!) of parenthood.\n\n![](assets/13-more-than-lines-of-code_13-more-than-line-code-new-born.webp)\n\nFrom tech tips to tiny toes, this week's digest reminds us that we're more than just a team. So, whether you're sharing a memo, a vacation snapshot, or a life-changing announcement, remember: that we're here to celebrate it with you.  \n","title":"Weekly Digest #13: More than lines of code","short_title":"#13 More than lines of code","description":"Welcome to this week's edition of our roundup, where we highlight the moments that make us more than just lines of code. This week, we're jet-setting around the world with our team's summer adventures, introducing new memo features, cheering for a beloved teammate's new chapter in the US, and celebrating new born. From beachside workspaces to anime figurine collections, we've got it all.","tags":["memo","team","remote","weekly-digest"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Sat Jul 20 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/13-more-than-lines-of-code.md","slugArray":["updates","digest","13-more-than-lines-of-code"]}],"hiringMemos":[{"content":"\n## We are hiring Full-Stack Engineers\n\nThis role offers flexibility, remote work, and the chance to build meaningful solutions alongside a talented team.\n\n\u003e **🤘 \u003ca href=\"mailto:spawn@d.foundation\"\u003eApply now\u003c/a\u003e** (We respond within three days)\n\n## Dwarves is a research-focused technology firm\n\nSince 2015, we have helped companies build \u0026 ship top-notch software, operate tech teams and invest in ambitious people who are after world's next big things.\n\nTechnology is our north star metrics, engineering is our culture. We are a profitable company since day 1 and have been growing steadily.\n\nBy October, we have already achieved our goals set for 2021. Moving to the next goals, we're looking for talented engineers to join our team.\n\n- [Life at Dwarves](https://memo.d.foundation/careers/additional-info/life-at-dwarves/)\n- [The Manifesto](https://memo.d.foundation/careers/additional-info/the-manifesto/)\n- [Culture Handbook](https://memo.d.foundation/careers/additional-info/culture-handbook/)\n\n## Products we recently take part in\n\n### [Ascenda](https://www.ascenda.com/)\n\nAscenda enables financial services companies to grow revenue with world-class rewards.\n\n### [Fornax AI](https://fornax.ai/)\n\nFornax AI helps early-stage startup founders to effectively communicate their ideas to investors.\n\n### [SP Group](https://www.spgroup.com.sg/)\n\nGovernment owned utility distribution enterprise in Singapore, with footprint in most Asian countries and in Australia.\n\n## Our advances into web 3.0\n\n### [Attrace](https://attrace.com/)\n\nNetherland's referral protocol for crypto assets where anyone can sign up to promote.\n\n### [Hedge Foundation](https://www.hedge.foundation/)\n\nHedge Foundation - powerful dashboard to support users in managing crypto account positions, balance, PNL.\n\n### [Tokenomy](https://tokenomy.com/)\n\nTokenomy - decentralized Community VC backed by the largest crypto exchange in Indonesia, Indodax.\n\n\u003e 🤝 **As an engineer at Dwarves, you will be working closely with a team of talented, kind people and working directly with our clients. There is a lot of freedom to contribute to the quality of the project and improve, or prove yourself.**\n\n### What you'll get to do\n\n- Define and shape the fundamentals of engineering at Dwarves Foundation\n- Design and write maintainable code at scale\n- Continuously discuss, debate with other team members to propose optimal solutions for different problems\n- Maintain and monitor the systems to make sure there is no disruption in our services\n\n### What it takes to succeed\n\n- A Linux or Mac user\n- Familiar with Agile development process, esp. Scrum framework\n- 3 years experience with Node JS\n- Proficiency in **Node.js** and **Firebase**\n- Strong understanding of **React**, **Vite**, **TypeScript**, and **Tailwind CSS**\n- Strong interest in **AI/LLM** and **fintech**\n- Experience in shipping web applications to production, **CI/CD with docker centric workflow**\n- Ability to leverage **AI tools** to enhance development and productivity\n- Familiar with running large scale web services\n- Understanding of system performance and scaling\n- Possess excellent communication, sharp analytical abilities with proven design skills, able to think critically of the current system regarding growth and stability\n- Experience in writing good unit tests\n- Good written and verbal English communication, team player with a collaborative work ethics\n\n### What you can look forward to\n\n- You will be working closely with a team of talented, kind people. Your team will have your back. We love helping and uplifting our co-workers.\n- You will be directly with our clients. There is a lot of freedom to contribute to the quality of the project and improve, or prove yourself.\n- You will be working on projects that are impactful and meaningful. We're picky with what we choose to take part in.\n- You will get to be a member of a community where we learn and discuss everything technology.\n\n\u003e 🤘 **\u003ca href=\"mailto:spawn@d.foundation\"\u003eApply now\u003c/a\u003e** (We respond within three days)\n\n**Your dream job not listed? Not a big deal. We hardly ever say no to talented people.**\\\n\u003ca href=\"mailto:spawn@d.foundation\"\u003eShoot us an email\u003c/a\u003e with your LinkedIn / CV\\\n[Join our Discord](https://discord.gg/dfoundation) of +300 other engineers and designers\n","title":"Full-Stack Engineer","short_title":"","description":"We are looking for a Full-Stack Engineer who is passionate about building scalable, secure, and efficient web applications. The ideal candidate will have a strong understanding of both frontend and backend technologies, and the ability to work across the entire stack.","tags":["hiring","career","full-stack","engineer"],"pinned":false,"draft":false,"hiring":true,"authors":["minh"],"date":"Wed Feb 05 2025 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"careers/archived/full-stack-engineer.md","slugArray":["careers","archived","full-stack-engineer"]}]},"__N_SSG":true},"page":"/","query":{},"buildId":"YEl9dMUxleKjDbVxqv2Hg","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>