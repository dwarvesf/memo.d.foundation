<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><title data-next-head="">OGIF Office Hours #28 - Golang sync.Map, Generative AI UX design patterns, Yelp&#x27;s AI use cases, Design patterns in LLM application, and Dify github analyzer</title><meta property="title" content="OGIF Office Hours #28 - Golang sync.Map, Generative AI UX design patterns, Yelp&#x27;s AI use cases, Design patterns in LLM application, and Dify github analyzer" data-next-head=""/><meta property="og:title" content="OGIF Office Hours #28 - Golang sync.Map, Generative AI UX design patterns, Yelp&#x27;s AI use cases, Design patterns in LLM application, and Dify github analyzer" data-next-head=""/><meta name="description" content="OGIF Office Hours #28 covered Go Weekly #16 by Phat on sync.Map concurrency, Nam&#x27;s Product Commentary #4 on Generative AI UX design patterns, Dat Nguyen&#x27;s presentation on Yelp&#x27;s AI use cases including recommendation systems, Hoang&#x27;s discussion on LLM application design patterns, and Cat&#x27;s demonstration of a Dify-based Git repository analysis tool." data-next-head=""/><meta property="og:description" content="OGIF Office Hours #28 covered Go Weekly #16 by Phat on sync.Map concurrency, Nam&#x27;s Product Commentary #4 on Generative AI UX design patterns, Dat Nguyen&#x27;s presentation on Yelp&#x27;s AI use cases including recommendation systems, Hoang&#x27;s discussion on LLM application design patterns, and Cat&#x27;s demonstration of a Dify-based Git repository analysis tool." data-next-head=""/><meta name="keywords" content="office-hours, ogif, discord" data-next-head=""/><meta property="og:type" content="article" data-next-head=""/><meta property="og:site_name" content="Dwarves Memo" data-next-head=""/><link rel="icon" type="image/x-icon" href="{{ $favicon.Permalink }}" data-next-head=""/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" data-next-head=""/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" data-next-head=""/><link rel="apple-touch-icon" href="/apple-touch-icon.png" data-next-head=""/><link rel="icon" href="/favicon.ico" data-next-head=""/><link rel="alternate" type="application/rss+xml" title="OGIF Office Hours #28 - Golang sync.Map, Generative AI UX design patterns, Yelp&#x27;s AI use cases, Design patterns in LLM application, and Dify github analyzer - RSS Feed" href="/feed.xml" data-next-head=""/><link rel="alternate" type="application/atom+xml" title="OGIF Office Hours #28 - Golang sync.Map, Generative AI UX design patterns, Yelp&#x27;s AI use cases, Design patterns in LLM application, and Dify github analyzer - Atom Feed" href="/atom.xml" data-next-head=""/><link rel="preconnect" href="https://fonts.googleapis.com" data-next-head=""/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous" data-next-head=""/><link rel="apple-touch-icon" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><link data-next-font="" rel="preconnect" href="/" crossorigin="anonymous"/><link rel="preload" href="/_next/static/css/63f75362f52c2d1a.css" as="style"/><link href="https://fonts.googleapis.com/css2?family=Public+Sans:ital,wght@0,100..900;1,100..900&amp;family=IBM+Plex+Sans:ital,wght@0,100..700;1,100..700&amp;display=swap" rel="stylesheet" data-next-head=""/><link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;display=swap" rel="stylesheet" data-next-head=""/><link rel="stylesheet" href="/_next/static/css/63f75362f52c2d1a.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-fbb920bddf9bf0a6.js" defer=""></script><script src="/_next/static/chunks/framework-e252e7e8cb4283ef.js" defer=""></script><script src="/_next/static/chunks/main-b572048b704c71d9.js" defer=""></script><script src="/_next/static/chunks/pages/_app-001c12c5c94f1fd6.js" defer=""></script><script src="/_next/static/chunks/09244f9f-f6998eb65789973d.js" defer=""></script><script src="/_next/static/chunks/496-cbd4dbb3f0d35a5c.js" defer=""></script><script src="/_next/static/chunks/743-3dbf50639cfdbb71.js" defer=""></script><script src="/_next/static/chunks/pages/%5B...slug%5D-e21e5d92d493406e.js" defer=""></script><script src="/_next/static/HnnQnlZeGCflQP9U2OWmW/_buildManifest.js" defer=""></script><script src="/_next/static/HnnQnlZeGCflQP9U2OWmW/_ssgManifest.js" defer=""></script></head><body class="min-h-screen antialiased"><script>
              (function() {
                // Get saved theme or default to system preference
                const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
                const savedTheme = localStorage.getItem('theme');
                
                // Default to system preference if no saved preference
                const theme = (savedTheme === 'light' || savedTheme === 'dark') 
                  ? savedTheme 
                  : (prefersDark ? 'dark' : 'light');
                
                // Apply theme
                if (theme === 'dark') {
                  document.documentElement.classList.add('dark');
                  document.documentElement.setAttribute('data-theme', 'dark');
                } else {
                  document.documentElement.classList.remove('dark');
                  document.documentElement.setAttribute('data-theme', 'light');
                }
              })();
            </script><div id="__next"><div class="bg-background border-border fixed top-0 left-0 z-40 flex h-full w-[var(--nav-sidebar-width)] flex-col border-r pt-4 pb-12 font-sans transition-transform duration-300 ease-in-out xl:w-[72px] translate-x-[-100%] xl:translate-x-0 "><a class="mx-4 flex h-10 items-center gap-2 px-2 md:justify-start" href="/"><svg width="24" height="24" viewBox="0 0 19 20" fill="none" xmlns="http://www.w3.org/2000/svg" class="h-6.25 w-6 min-w-6"><path d="M2.41664 20C1.08113 20 0 18.8812 0 17.4991V2.50091C0 1.11883 1.08113 0 2.41664 0L8.46529 0.00731261C13.8427 0.00731261 18.1954 4.55576 18.1248 10.1353C18.0541 15.6271 13.6307 20 8.32397 20H2.41664Z" fill="#E13F5E"></path><path d="M3.63209 15.6271H3.32118C3.15159 15.6271 3.01733 15.4881 3.01733 15.3126V12.8044C3.01733 12.6289 3.15159 12.49 3.32118 12.49H5.74488C5.91447 12.49 6.04873 12.6289 6.04873 12.8044V13.1262C6.04873 14.5082 4.9676 15.6271 3.63209 15.6271Z" fill="white"></path><path d="M3.32119 8.11701H10.8749C12.2105 8.11701 13.2916 6.99818 13.2916 5.6161V5.31628C13.2916 5.13347 13.1503 4.98721 12.9736 4.98721H5.44105C4.10554 4.98721 3.02441 6.10604 3.02441 7.48813V7.80257C3.02441 7.97807 3.15867 8.11701 3.32119 8.11701Z" fill="white"></path><path d="M3.32118 11.8684H7.24998C8.58549 11.8684 9.66661 10.7496 9.66661 9.36747V9.05303C9.66661 8.87753 9.53236 8.73859 9.36277 8.73859H3.32118C3.15159 8.73859 3.01733 8.87753 3.01733 9.05303V11.5539C3.0244 11.7294 3.15866 11.8684 3.32118 11.8684Z" fill="white"></path></svg><span class="inline-block font-sans text-xs leading-tight font-bold tracking-tight uppercase xl:hidden">Dwarves<br/>Memo</span></a><nav class="flex flex-1 flex-col p-4"><a class="hover:bg-muted dark:hover:bg-muted flex items-center rounded-lg text-sm font-medium transition-colors md:justify-start" id="sidebar-item-0" data-state="closed" data-slot="tooltip-trigger" href="/"><div class="p-2"><div class="h-6 w-6" style="mask-image:url(&#x27;/assets/img/home.svg&#x27;);-webkit-mask-image:url(&#x27;/assets/img/home.svg&#x27;);background-color:currentColor;mask-repeat:no-repeat;-webkit-mask-repeat:no-repeat;mask-size:contain;-webkit-mask-size:contain;mask-position:center;-webkit-mask-position:center"></div></div><span class="ml-3 inline-block xl:hidden">Home</span></a><a class="hover:bg-muted dark:hover:bg-muted flex items-center rounded-lg text-sm font-medium transition-colors md:justify-start" id="sidebar-item-1" data-state="closed" data-slot="tooltip-trigger" href="/consulting"><div class="p-2"><div class="h-6 w-6" style="mask-image:url(&#x27;/assets/img/consulting.svg&#x27;);-webkit-mask-image:url(&#x27;/assets/img/consulting.svg&#x27;);background-color:currentColor;mask-repeat:no-repeat;-webkit-mask-repeat:no-repeat;mask-size:contain;-webkit-mask-size:contain;mask-position:center;-webkit-mask-position:center"></div></div><span class="ml-3 inline-block xl:hidden">Consulting</span></a><a class="hover:bg-muted dark:hover:bg-muted flex items-center rounded-lg text-sm font-medium transition-colors md:justify-start" id="sidebar-item-2" data-state="closed" data-slot="tooltip-trigger" href="/earn"><div class="p-2"><div class="h-6 w-6" style="mask-image:url(&#x27;/assets/img/earn.svg&#x27;);-webkit-mask-image:url(&#x27;/assets/img/earn.svg&#x27;);background-color:currentColor;mask-repeat:no-repeat;-webkit-mask-repeat:no-repeat;mask-size:contain;-webkit-mask-size:contain;mask-position:center;-webkit-mask-position:center"></div></div><span class="ml-3 inline-block xl:hidden">Earn</span></a><a class="hover:bg-muted dark:hover:bg-muted flex items-center rounded-lg text-sm font-medium transition-colors md:justify-start" id="sidebar-item-3" data-state="closed" data-slot="tooltip-trigger" href="/careers/hiring"><div class="p-2"><div class="h-6 w-6" style="mask-image:url(&#x27;/assets/img/hiring.svg&#x27;);-webkit-mask-image:url(&#x27;/assets/img/hiring.svg&#x27;);background-color:currentColor;mask-repeat:no-repeat;-webkit-mask-repeat:no-repeat;mask-size:contain;-webkit-mask-size:contain;mask-position:center;-webkit-mask-position:center"></div></div><span class="ml-3 inline-block xl:hidden">Hiring</span></a><a class="hover:bg-muted dark:hover:bg-muted flex items-center rounded-lg text-sm font-medium transition-colors md:justify-start" id="sidebar-item-4" data-state="closed" data-slot="tooltip-trigger" href="/updates/digest"><div class="p-2"><div class="h-6 w-6" style="mask-image:url(&#x27;/assets/img/digest.svg&#x27;);-webkit-mask-image:url(&#x27;/assets/img/digest.svg&#x27;);background-color:currentColor;mask-repeat:no-repeat;-webkit-mask-repeat:no-repeat;mask-size:contain;-webkit-mask-size:contain;mask-position:center;-webkit-mask-position:center"></div></div><span class="ml-3 inline-block xl:hidden">Digest</span></a><a class="hover:bg-muted dark:hover:bg-muted flex items-center rounded-lg text-sm font-medium transition-colors md:justify-start text-primary" id="sidebar-item-5" data-state="closed" data-slot="tooltip-trigger" href="/updates/ogif"><div class="p-2"><div class="h-6 w-6" style="mask-image:url(&#x27;/assets/img/ogifs.svg&#x27;);-webkit-mask-image:url(&#x27;/assets/img/ogifs.svg&#x27;);background-color:currentColor;mask-repeat:no-repeat;-webkit-mask-repeat:no-repeat;mask-size:contain;-webkit-mask-size:contain;mask-position:center;-webkit-mask-position:center"></div></div><span class="ml-3 inline-block xl:hidden">OGIFs</span></a></nav><div class="mx-4 border-t pt-1"><div class="flex items-center justify-between gap-3 p-2"><button class="flex cursor-pointer items-center justify-center hover:opacity-80"><svg viewBox="0 0 20 20" width="24" height="24"><path d="M16.667 12.3249L17.3564 12.6202C17.4795 12.3329 17.4115 11.9994 17.1857 11.7832C16.96 11.567 16.6239 11.5135 16.3421 11.6489L16.667 12.3249ZM8.19804 2.3999L8.79449 2.85459C8.9845 2.60535 8.99949 2.26424 8.83208 1.99928C8.66467 1.73433 8.35016 1.60141 8.04348 1.666L8.19804 2.3999ZM13.6635 12.2548C10.3006 12.2548 7.60587 9.59905 7.60587 6.36135L6.10587 6.36135C6.10587 10.4618 9.50689 13.7548 13.6635 13.7548L13.6635 12.2548ZM16.3421 11.6489C15.5358 12.0364 14.6271 12.2548 13.6635 12.2548L13.6635 13.7548C14.8559 13.7548 15.9863 13.4841 16.9918 13.0009L16.3421 11.6489ZM15.9776 12.0295C14.9688 14.384 12.579 16.0499 9.77963 16.0499L9.77963 17.5499C13.1836 17.5499 16.1131 15.5222 17.3564 12.6202L15.9776 12.0295ZM9.77963 16.0499C6.05539 16.0499 3.06774 13.1083 3.06774 9.51796L1.56774 9.51796C1.56774 13.971 5.26169 17.5499 9.77963 17.5499L9.77963 16.0499ZM3.06774 9.51796C3.06774 6.3999 5.31884 3.77274 8.3526 3.1338L8.04348 1.666C4.35439 2.44295 1.56774 5.65176 1.56774 9.51796L3.06774 9.51796ZM7.60587 6.36135C7.60587 5.04819 8.0465 3.83578 8.79449 2.85459L7.60159 1.94521C6.66318 3.17619 6.10587 4.70542 6.10587 6.36135L7.60587 6.36135Z" fill="currentColor"></path><path d="M13.9357 2.46517C13.5852 2.2404 13.1672 2.64169 13.4007 2.97822L13.8173 3.57826C13.9864 3.82156 14.0766 4.10745 14.0766 4.3999C14.0766 4.69235 13.9864 4.97825 13.8173 5.22154L13.4007 5.82158C13.1672 6.15811 13.5858 6.55941 13.9364 6.33463L14.5607 5.93461C14.8141 5.77233 15.1119 5.68573 15.4165 5.68573C15.7211 5.68573 16.0189 5.77233 16.2723 5.93461L16.8973 6.33463C17.2478 6.55941 17.6658 6.15811 17.4317 5.82158L17.015 5.22154C16.846 4.97825 16.7558 4.69235 16.7558 4.3999C16.7558 4.10745 16.846 3.82156 17.015 3.57826L17.4317 2.97822C17.6658 2.64169 17.2478 2.2404 16.8966 2.46517L16.2723 2.8652C16.0189 3.02747 15.7211 3.11407 15.4165 3.11407C15.1119 3.11407 14.8141 3.02747 14.5607 2.8652L13.9357 2.46517Z" fill="currentColor" fill-opacity="0.25"></path></svg></button><span class="inline-block flex-1 shrink-0 text-sm leading-6 font-medium xl:hidden">Night mode</span><button class="bg-border flex h-5 w-9 cursor-pointer items-center justify-center rounded-full py-0.5 pr-4.5 pl-0.5 hover:opacity-95 xl:hidden"><div class="text-foreground-light rounded-full bg-white p-0.5"><svg viewBox="0 0 20 20" width="12" height="12"><path d="M16.667 12.3249L17.3564 12.6202C17.4795 12.3329 17.4115 11.9994 17.1857 11.7832C16.96 11.567 16.6239 11.5135 16.3421 11.6489L16.667 12.3249ZM8.19804 2.3999L8.79449 2.85459C8.9845 2.60535 8.99949 2.26424 8.83208 1.99928C8.66467 1.73433 8.35016 1.60141 8.04348 1.666L8.19804 2.3999ZM13.6635 12.2548C10.3006 12.2548 7.60587 9.59905 7.60587 6.36135L6.10587 6.36135C6.10587 10.4618 9.50689 13.7548 13.6635 13.7548L13.6635 12.2548ZM16.3421 11.6489C15.5358 12.0364 14.6271 12.2548 13.6635 12.2548L13.6635 13.7548C14.8559 13.7548 15.9863 13.4841 16.9918 13.0009L16.3421 11.6489ZM15.9776 12.0295C14.9688 14.384 12.579 16.0499 9.77963 16.0499L9.77963 17.5499C13.1836 17.5499 16.1131 15.5222 17.3564 12.6202L15.9776 12.0295ZM9.77963 16.0499C6.05539 16.0499 3.06774 13.1083 3.06774 9.51796L1.56774 9.51796C1.56774 13.971 5.26169 17.5499 9.77963 17.5499L9.77963 16.0499ZM3.06774 9.51796C3.06774 6.3999 5.31884 3.77274 8.3526 3.1338L8.04348 1.666C4.35439 2.44295 1.56774 5.65176 1.56774 9.51796L3.06774 9.51796ZM7.60587 6.36135C7.60587 5.04819 8.0465 3.83578 8.79449 2.85459L7.60159 1.94521C6.66318 3.17619 6.10587 4.70542 6.10587 6.36135L7.60587 6.36135Z" fill="currentColor"></path><path d="M13.9357 2.46517C13.5852 2.2404 13.1672 2.64169 13.4007 2.97822L13.8173 3.57826C13.9864 3.82156 14.0766 4.10745 14.0766 4.3999C14.0766 4.69235 13.9864 4.97825 13.8173 5.22154L13.4007 5.82158C13.1672 6.15811 13.5858 6.55941 13.9364 6.33463L14.5607 5.93461C14.8141 5.77233 15.1119 5.68573 15.4165 5.68573C15.7211 5.68573 16.0189 5.77233 16.2723 5.93461L16.8973 6.33463C17.2478 6.55941 17.6658 6.15811 17.4317 5.82158L17.015 5.22154C16.846 4.97825 16.7558 4.69235 16.7558 4.3999C16.7558 4.10745 16.846 3.82156 17.015 3.57826L17.4317 2.97822C17.6658 2.64169 17.2478 2.2404 16.8966 2.46517L16.2723 2.8652C16.0189 3.02747 15.7211 3.11407 15.4165 3.11407C15.1119 3.11407 14.8141 3.02747 14.5607 2.8652L13.9357 2.46517Z" fill="currentColor" fill-opacity="0.25"></path></svg></div></button></div></div></div><div class="bg-background text-foreground relative flex h-screen font-sans transition-colors "><div id="sidebar" class="bg-background-secondary h-[calc(100svh-32px)] w-0 flex-col pt-10 pb-2 pl-0 text-sm leading-normal xl:w-[calc(72px+200px+28px)] xl:pr-3 xl:pl-18 2xl:w-[360px] translate-0 transition duration-100 ease-in-out z-2 overflow-y-auto reading:opacity-0 reading:translate-x-[-10%] xl:reading:w-[72px] reading:pr-0"><div class=""><div class="relative flex flex-col"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/pinned"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out"><path d="m6 9 6 6 6-6"></path></svg><span>Pinned Notes</span></a><div class="m-0 w-full pl-1"><div class="relative flex flex-col before:bg-border pl-3 before:absolute before:top-0 before:left-[7px] before:h-full before:w-[1px] before:content-[&#x27;&#x27;]"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium text-muted-foreground pl-2" href="/playbook/operations/ogif"><span>OGIF - Oh God It&#x27;s Friday</span></a></div></div></div><div class="relative flex flex-col"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out"><path d="m6 9 6 6 6-6"></path></svg><span>Home</span></a><div class="m-0 w-full pl-1"><div class="relative flex flex-col before:bg-border pl-3 before:absolute before:top-0 before:left-[7px] before:h-full before:w-[1px] before:content-[&#x27;&#x27;]"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/careers"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out -rotate-90"><path d="m6 9 6 6 6-6"></path></svg><span>Careers</span></a></div><div class="relative flex flex-col before:bg-border pl-3 before:absolute before:top-0 before:left-[7px] before:h-full before:w-[1px] before:content-[&#x27;&#x27;]"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/consulting"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out -rotate-90"><path d="m6 9 6 6 6-6"></path></svg><span>Consulting</span></a></div><div class="relative flex flex-col before:bg-border pl-3 before:absolute before:top-0 before:left-[7px] before:h-full before:w-[1px] before:content-[&#x27;&#x27;]"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/earn"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out -rotate-90"><path d="m6 9 6 6 6-6"></path></svg><span>Earn</span></a></div><div class="relative flex flex-col before:bg-border pl-3 before:absolute before:top-0 before:left-[7px] before:h-full before:w-[1px] before:content-[&#x27;&#x27;]"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/handbook"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out -rotate-90"><path d="m6 9 6 6 6-6"></path></svg><span>Handbook</span></a></div><div class="relative flex flex-col before:bg-border pl-3 before:absolute before:top-0 before:left-[7px] before:h-full before:w-[1px] before:content-[&#x27;&#x27;]"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/playbook"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out -rotate-90"><path d="m6 9 6 6 6-6"></path></svg><span>Playbook</span></a></div><div class="relative flex flex-col before:bg-border pl-3 before:absolute before:top-0 before:left-[7px] before:h-full before:w-[1px] before:content-[&#x27;&#x27;]"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/playground"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out -rotate-90"><path d="m6 9 6 6 6-6"></path></svg><span>Playground</span></a></div><div class="relative flex flex-col before:bg-border pl-3 before:absolute before:top-0 before:left-[7px] before:h-full before:w-[1px] before:content-[&#x27;&#x27;]"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/updates"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out -rotate-90"><path d="m6 9 6 6 6-6"></path></svg><span>Updates</span></a></div></div></div><div class="relative flex flex-col"><a class="flex cursor-pointer items-center gap-1 p-1.25 text-left text-xs leading-normal font-medium" href="/tags"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down stroke-muted-foreground transition-all duration-300 ease-in-out -rotate-90"><path d="m6 9 6 6 6-6"></path></svg><span>Popular Tags</span></a></div></div></div><div class="relative flex flex-1 flex-col overflow-y-auto"><header class="bg-background/95 supports-[backdrop-filter]:bg-background/60 top-0 w-full shrink-0 font-sans backdrop-blur"><div class="mx-auto flex h-full items-center justify-between px-5 py-2.5"><div class="flex items-center gap-2.5"><button id="sidebar-toggle" aria-label="Toggle sidebar" class="flex h-10 w-10 cursor-pointer items-center justify-center focus:outline-none xl:hidden"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="text-current"><path d="M4 6H20M4 12H20M4 18H20" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg></button><a class="flex items-center gap-2 xl:hidden" href="/"><svg width="24" height="24" viewBox="0 0 19 20" fill="none" xmlns="http://www.w3.org/2000/svg" class="h-7 w-6 min-w-6 shrink-0"><path d="M2.41664 20C1.08113 20 0 18.8812 0 17.4991V2.50091C0 1.11883 1.08113 0 2.41664 0L8.46529 0.00731261C13.8427 0.00731261 18.1954 4.55576 18.1248 10.1353C18.0541 15.6271 13.6307 20 8.32397 20H2.41664Z" fill="#E13F5E"></path><path d="M3.63209 15.6271H3.32118C3.15159 15.6271 3.01733 15.4881 3.01733 15.3126V12.8044C3.01733 12.6289 3.15159 12.49 3.32118 12.49H5.74488C5.91447 12.49 6.04873 12.6289 6.04873 12.8044V13.1262C6.04873 14.5082 4.9676 15.6271 3.63209 15.6271Z" fill="white"></path><path d="M3.32119 8.11701H10.8749C12.2105 8.11701 13.2916 6.99818 13.2916 5.6161V5.31628C13.2916 5.13347 13.1503 4.98721 12.9736 4.98721H5.44105C4.10554 4.98721 3.02441 6.10604 3.02441 7.48813V7.80257C3.02441 7.97807 3.15867 8.11701 3.32119 8.11701Z" fill="white"></path><path d="M3.32118 11.8684H7.24998C8.58549 11.8684 9.66661 10.7496 9.66661 9.36747V9.05303C9.66661 8.87753 9.53236 8.73859 9.36277 8.73859H3.32118C3.15159 8.73859 3.01733 8.87753 3.01733 9.05303V11.5539C3.0244 11.7294 3.15866 11.8684 3.32118 11.8684Z" fill="white"></path></svg><span class="font-sans text-xs leading-tight font-bold tracking-tight uppercase">Dwarves<br/>Memo</span></a></div><div class="ml-auto flex items-center gap-3.5"><div class="command-palette relative z-50"><button class="hidden w-50 cursor-pointer justify-between rounded-md border bg-transparent px-3 py-1.5 transition-all duration-100 ease-in-out hover:shadow-md lg:flex" aria-label="Open command palette"><div class="flex items-center gap-0.5"><span class="text-muted-foreground text-sm filter-[opacity(50%)]">🔍 Search...</span></div><div class="text-muted-foreground flex items-center gap-0.5 text-xs"><kbd class="dark:bg-border rounded bg-[#f9fafb] px-1.5 py-0.5">⌘</kbd><kbd class="dark:bg-border rounded bg-[#f9fafb] px-1.5 py-0.5">K</kbd></div></button><button class="text-foreground flex h-10 w-10 items-center justify-center border-none bg-transparent p-0 lg:hidden" aria-label="Open search"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 16 16" fill="none" class="text-foreground" aria-hidden="true"><circle cx="6.88881" cy="6.8889" r="5.55556" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></circle><path d="M11.3333 11.3333L14.6666 14.6667" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></button></div><button class="hidden cursor-pointer items-center justify-center border-0 bg-transparent px-1.5 outline-none hover:opacity-95 active:opacity-100 xl:flex" aria-label="Toggle reading mode" data-reading-mode="false" data-state="closed" data-slot="tooltip-trigger"><svg width="48" height="28" viewBox="0 0 62 34" fill="none" xmlns="http://www.w3.org/2000/svg" class="h-7 w-12 xl:w-14"><g><rect width="62" height="34" rx="17" class="fill-border dark:fill-border"></rect><g class="transition-transform duration-150 ease-in-out translate-x-0"><circle cx="17" cy="17" r="14" class="fill-white"></circle><path d="M17 23.898V18.3265C17 17.9747 17.1398 17.6373 17.3885 17.3885C17.6373 17.1398 17.9747 17 18.3265 17C18.6783 17 19.0158 17.1398 19.2645 17.3885C19.5133 17.6373 19.6531 17.9747 19.6531 18.3265V21.2449H21.7755C22.3384 21.2449 22.8782 21.4685 23.2763 21.8666C23.6744 22.2646 23.898 22.8045 23.898 23.3673V23.898" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="stroke-[#333639]"></path><path d="M16.2119 12.8561C14.8891 11.4004 13.114 10.4334 11.1736 10.1113C11.0416 10.0926 10.9071 10.1022 10.7791 10.1395C10.6511 10.1768 10.5324 10.2409 10.4311 10.3275C10.3279 10.4158 10.245 10.5253 10.1883 10.6487C10.1315 10.772 10.1021 10.9062 10.1021 11.0419V18.6088C10.1007 18.8411 10.1854 19.0658 10.3399 19.2394C10.4944 19.413 10.7077 19.5232 10.9386 19.5487C12.4542 19.7543 13.8794 20.354 15.0774 21.276" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="stroke-[#333639]"></path><path d="M16.2124 15.7885V12.8561" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="stroke-[#333639]"></path><path d="M21.4852 19.5487C21.7161 19.5232 21.9295 19.413 22.084 19.2394C22.2385 19.0658 22.3232 18.8411 22.3218 18.6088V11.0419C22.3218 10.9062 22.2924 10.772 22.2356 10.6487C22.1788 10.5253 22.096 10.4158 21.9928 10.3275C21.8915 10.2409 21.7728 10.1768 21.6447 10.1395C21.5167 10.1022 21.3823 10.0926 21.2502 10.1113C19.3098 10.4334 17.5347 11.4004 16.2119 12.8561" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="stroke-[#333639]"></path></g></g></svg></button></div></div></header><div class="main-grid relative w-full flex-1 flex-col"><div class="right-sidebar leading-[140% hidden font-sans text-sm font-medium xl:flex 2xl:w-[240px] transition-[transform,opacity,visibility] duration-100 ease-in-out visible w-0 translate-x-0 transform opacity-100 xl:w-[200px] reading:opacity-0 reading:translate-x-[50px] reading:invisible reading:w-0"><div class="sticky top-[60px] right-0 flex flex-col gap-y-8 pt-4 pb-10 transition-[top] duration-200 ease-in-out"><div class="metadata space-y-6"><div class=""><h3 class="text-black-secondary dark:text-foreground text-2xs mb-3 font-sans font-semibold tracking-[0.8px] uppercase">Properties</h3><ul class="space-y-2 text-sm"><li class="text-secondary-foreground dark:text-secondary-light flex items-center gap-1 text-xs leading-[140%]"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" class="h-4 w-4"><g fill="currentColor"><path d="M5.25 12a.75.75 0 0 1 .75-.75h.01a.75.75 0 0 1 .75.75v.01a.75.75 0 0 1-.75.75H6a.75.75 0 0 1-.75-.75zM6 13.25a.75.75 0 0 0-.75.75v.01c0 .414.336.75.75.75h.01a.75.75 0 0 0 .75-.75V14a.75.75 0 0 0-.75-.75zM7.25 12a.75.75 0 0 1 .75-.75h.01a.75.75 0 0 1 .75.75v.01a.75.75 0 0 1-.75.75H8a.75.75 0 0 1-.75-.75zM8 13.25a.75.75 0 0 0-.75.75v.01c0 .414.336.75.75.75h.01a.75.75 0 0 0 .75-.75V14a.75.75 0 0 0-.75-.75zM9.25 10a.75.75 0 0 1 .75-.75h.01a.75.75 0 0 1 .75.75v.01a.75.75 0 0 1-.75.75H10a.75.75 0 0 1-.75-.75zm.75 1.25a.75.75 0 0 0-.75.75v.01c0 .414.336.75.75.75h.01a.75.75 0 0 0 .75-.75V12a.75.75 0 0 0-.75-.75zM9.25 14a.75.75 0 0 1 .75-.75h.01a.75.75 0 0 1 .75.75v.01a.75.75 0 0 1-.75.75H10a.75.75 0 0 1-.75-.75zM12 9.25a.75.75 0 0 0-.75.75v.01c0 .414.336.75.75.75h.01a.75.75 0 0 0 .75-.75V10a.75.75 0 0 0-.75-.75zM11.25 12a.75.75 0 0 1 .75-.75h.01a.75.75 0 0 1 .75.75v.01a.75.75 0 0 1-.75.75H12a.75.75 0 0 1-.75-.75zm.75 1.25a.75.75 0 0 0-.75.75v.01c0 .414.336.75.75.75h.01a.75.75 0 0 0 .75-.75V14a.75.75 0 0 0-.75-.75zM13.25 10a.75.75 0 0 1 .75-.75h.01a.75.75 0 0 1 .75.75v.01a.75.75 0 0 1-.75.75H14a.75.75 0 0 1-.75-.75zm.75 1.25a.75.75 0 0 0-.75.75v.01c0 .414.336.75.75.75h.01a.75.75 0 0 0 .75-.75V12a.75.75 0 0 0-.75-.75z"></path><path fill-rule="evenodd" d="M5.75 2a.75.75 0 0 1 .75.75V4h7V2.75a.75.75 0 0 1 1.5 0V4h.25A2.75 2.75 0 0 1 18 6.75v8.5A2.75 2.75 0 0 1 15.25 18H4.75A2.75 2.75 0 0 1 2 15.25v-8.5A2.75 2.75 0 0 1 4.75 4H5V2.75A.75.75 0 0 1 5.75 2m-1 5.5c-.69 0-1.25.56-1.25 1.25v6.5c0 .69.56 1.25 1.25 1.25h10.5c.69 0 1.25-.56 1.25-1.25v-6.5c0-.69-.56-1.25-1.25-1.25z" clip-rule="evenodd"></path></g></svg><span>Created:</span><span>Oct 21, 2024</span></li><li class="text-secondary-foreground dark:text-secondary-light flex items-center gap-1 text-xs leading-[140%]"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16"><path fill="currentColor" fill-rule="evenodd" d="M18.685 19.097A9.723 9.723 0 0 0 21.75 12c0-5.385-4.365-9.75-9.75-9.75S2.25 6.615 2.25 12a9.723 9.723 0 0 0 3.065 7.097A9.716 9.716 0 0 0 12 21.75a9.716 9.716 0 0 0 6.685-2.653m-12.54-1.285A7.486 7.486 0 0 1 12 15a7.486 7.486 0 0 1 5.855 2.812A8.224 8.224 0 0 1 12 20.25a8.224 8.224 0 0 1-5.855-2.438M15.75 9a3.75 3.75 0 1 1-7.5 0a3.75 3.75 0 0 1 7.5 0" clip-rule="evenodd"></path></svg><span>Author:</span><a class="hover:text-primary hover:underline" href="/contributor/innno_">innno_</a></li><li class="text-secondary-foreground dark:text-secondary-light flex items-start gap-1 text-xs leading-[140%]"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M5.25 2.25a3 3 0 0 0-3 3v4.318a3 3 0 0 0 .879 2.121l9.58 9.581c.92.92 2.39 1.186 3.548.428a18.849 18.849 0 0 0 5.441-5.44c.758-1.16.492-2.629-.428-3.548l-9.58-9.581a3 3 0 0 0-2.122-.879zM6.375 7.5a1.125 1.125 0 1 0 0-2.25a1.125 1.125 0 0 0 0 2.25" clip-rule="evenodd"></path></svg><span>Tags:</span><div class="inline-flex flex-wrap gap-1"><a class="bg-muted hover:bg-muted/80 hover:text-primary dark:bg-border dark:text-foreground dark:hover:text-primary inline-flex items-center rounded-md px-1.5 py-0.5 text-[10px] font-medium text-[#4b4f53]" href="/tags/office-hours">office-hours</a><a class="bg-muted hover:bg-muted/80 hover:text-primary dark:bg-border dark:text-foreground dark:hover:text-primary inline-flex items-center rounded-md px-1.5 py-0.5 text-[10px] font-medium text-[#4b4f53]" href="/tags/ogif">ogif</a><a class="bg-muted hover:bg-muted/80 hover:text-primary dark:bg-border dark:text-foreground dark:hover:text-primary inline-flex items-center rounded-md px-1.5 py-0.5 text-[10px] font-medium text-[#4b4f53]" href="/tags/discord">discord</a></div></li></ul></div><div class=""><h3 class="text-black-secondary dark:text-foreground text-2xs mb-3 font-sans font-semibold tracking-[0.8px] uppercase">Location</h3><ul class="space-y-2 text-sm"><li class="text-secondary-foreground dark:text-secondary-light flex gap-1 text-xs leading-[140%]"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M2.25 12.75V12A2.25 2.25 0 0 1 4.5 9.75h15A2.25 2.25 0 0 1 21.75 12v.75m-8.69-6.44l-2.12-2.12a1.5 1.5 0 0 0-1.061-.44H4.5A2.25 2.25 0 0 0 2.25 6v12a2.25 2.25 0 0 0 2.25 2.25h15A2.25 2.25 0 0 0 21.75 18V9a2.25 2.25 0 0 0-2.25-2.25h-5.379a1.5 1.5 0 0 1-1.06-.44"></path></svg><span>Folder:</span><a class="hover:text-primary break-all hover:underline" href="/updates/ogif">updates/ogif</a></li></ul></div><div class=""><h3 class="text-black-secondary dark:text-foreground text-2xs mb-3 font-sans font-semibold tracking-[0.8px] uppercase">Stats</h3><ul class="space-y-2 text-sm"><li class="text-secondary-foreground dark:text-secondary-light flex items-center justify-between gap-1 text-xs leading-[140%]"><span>Words:</span><span>19,058</span></li><li class="text-secondary-foreground dark:text-secondary-light flex items-center justify-between gap-1 text-xs leading-[140%]"><span>Characters:</span><span>104,707</span></li><li class="text-secondary-foreground dark:text-secondary-light flex items-center justify-between gap-1 text-xs leading-[140%]"><span>Blocks:</span><span>6</span></li><li class="text-secondary-foreground dark:text-secondary-light flex items-center justify-between gap-1 text-xs leading-[140%]"><span>Reading time:</span><span>96m</span></li></ul></div></div></div></div><main class="main-content mx-auto max-w-[var(--container-max-width)] min-w-0 flex-1 p-[var(--main-padding-mobile)] pb-16 font-serif xl:p-[var(--main-padding)]"><img alt="" loading="lazy" width="1920" height="1080" decoding="async" data-nimg="1" class="yggdrasil-tree no-zoom pointer-events-none absolute bottom-8 left-1/2 w-[60vw] max-w-xs -translate-x-1/2 object-contain opacity-[0.03] md:w-[20vw] xl:w-[20vw] dark:opacity-100" style="color:transparent" src="/assets/img/footer-bg.svg"/><div class="memo-content mb-8"><div class="content-wrapper"><div class="content-layout xl:m-h-[400px]"><div class="flex flex-col items-start justify-between md:flex-row"><div class="hidden">OGIF Office Hours #28 - Golang sync.Map, Generative AI UX design patterns, Yelp&#x27;s AI use cases, Design patterns in LLM application, and Dify github analyzer</div><div class="flex-1"><h1 class="mt-0 mb-5 pb-0 font-serif text-[35px] leading-[42px] font-semibold tracking-tight">OGIF Office Hours #28 - Golang sync.Map, Generative AI UX design patterns, Yelp&#x27;s AI use cases, Design patterns in LLM application, and Dify github analyzer</h1></div></div><div class="prose dark:prose-dark prose-headings:font-serif prose-headings:font-semibold prose-headings:tracking-tight prose-headings:leading-[1.24] max-w-none font-serif prose-a:text-foreground prose-a:underline prose-a:decoration-neutral-200 prose-a:hover:text-primary prose-a:hover:decoration-primary prose-a:font-[inherit] prose-table:border prose-img:mt-[var(--element-margin)]"><div class="article-content"><p><strong>Topic Highlights</strong></p>
<ul>
<li><strong>Go Weekly #16</strong>: Phat discussed concurrent data structures in Go, focusing on <code>sync.Map</code>. He explored its structure, use cases, and performance trade-offs in high-read, low-write scenarios. He also touched on garbage collection issues reported by the Go team.</li>
<li><strong>Generative AI UX Design Patterns</strong>: Nam presented on UX design patterns for AI integration, covering System Scope Relationship, Spatial Relationship, and Functional Relationship. He explained how AI can be incorporated at various levels in digital products and discussed different ways to present AI features in user interfaces.</li>
<li><strong>Yelp Usecase AI</strong>: Dat presented real-world AI use cases from Yelp, explaining how AI is used for recommendation systems, text editing, and image summarization. He explored AI applications in generating datasets, spam detection, and auto-generating short video reviews for restaurants.</li>
<li><strong>LLM Pattern</strong>: Hoang introduced design patterns for integrating LLMs (Large Language Models) into applications. Key patterns included in-context learning, data preprocessing, and multi-agent collaboration, highlighting their practical use in AI-powered systems.</li>
<li><strong>Dify Git Analyze</strong>: Cat demonstrated a Git repository analysis tool built using Dify. The tool scrapes content from repositories and supports diagram generation for code structure analysis, with a focus on optimizing the knowledge retrieval process in large datasets</li>
</ul>
<hr>
<p><strong>Vietnamese Transcript</strong></p>
<p><strong>0:28</strong> Chủ đề hôm nay vẫn có Go Weekly, và Nam đang thử nghiệm phần commentary về thiết kế hàng tuần. Chúng ta sẽ theo dõi trong vài tuần tới xem nội dung như thế nào.</p>
<p><strong>11:19</strong> Nam sẽ trình bày tiếp cho anh em, và sau đó sẽ có một vài bài của Hoàng, Cát, Đạt. Chúng ta đang nghiên cứu về các trường hợp sử dụng mà các công ty khác đang áp dụng, hoặc các công cụ mà dev đang sử dụng, và có thể sẽ mở một bài chia sẻ trong tuần này hoặc tuần sau. Bài hôm nay sẽ xoay quanh việc tạo một nút thiết kế UX. Trước đây, có rất nhiều câu hỏi về phạm vi mà AI đang áp dụng và vai trò của nó sẽ như thế nào – liệu nó chỉ đóng góp như một thành phần nhỏ riêng lẻ hay là cả một ứng dụng trong các sản phẩm số. Hôm nay, em sẽ giải đáp thắc mắc đó, tức là AI đang đóng vai trò như thế nào và cách thức hoạt động của nó ra sao.</p>
<p><strong>12:11</strong> Đầu tiên, em sẽ nói về "System Scope Relationship." Hình ảnh này sẽ mô tả AI được tích hợp vào các hệ thống ở nhiều cấp độ khác nhau, từ một thành phần nhỏ lẻ đến một hệ sinh thái toàn diện hơn. AI có thể chỉ là một phần nhỏ trong một thành phần hoặc có thể phát triển thành các tính năng lớn hơn, giúp tự động hóa nhiều chức năng. Điều này sẽ giúp người dùng trải nghiệm ứng dụng dễ dàng hơn. AI có thể đóng vai trò trong bất kỳ phần nào của sản phẩm số – từ thành phần, luồng xử lý, tính năng cho đến toàn bộ ứng dụng, hoặc thậm chí là một nền tảng hoặc hệ sinh thái.</p>
<p><strong>12:53</strong> Ví dụ, trong một ứng dụng, AI có thể đóng vai trò một tính năng nhỏ, giúp người dùng thao tác nhanh hơn thay vì phải làm thủ công. Hoặc AI có thể là toàn bộ một ứng dụng như ChatGPT, nơi toàn bộ ứng dụng được xây dựng trên nền tảng AI, phục vụ cho một mục đích nhất định. Hoặc AI có thể là một nền tảng như Rewind AI, với nhiều tính năng hỗ trợ AI cho nhiều công việc khác nhau trong cùng một ứng dụng. Đây là phạm vi của AI trong các sản phẩm hiện nay.</p>

<p><strong>13:39</strong> Tiếp theo, về "Spatial Relationship," phần này giúp chúng ta hiểu về cách tính năng AI được bố trí và sắp xếp trong giao diện người dùng (UI). Có nhiều cách để tích hợp AI vào thiết kế, và quan trọng là làm sao để bố trí chúng sao cho hợp lý, tối ưu trải nghiệm người dùng mà không gây rối mắt hay phức tạp giao diện. Spatial Relationship ảnh hưởng trực tiếp đến trải nghiệm người dùng. Ví dụ, AI có thể hoạt động độc lập hoặc song song với các tính năng khác, nhưng vẫn giữ không gian riêng của mình. Khi hiểu được các mối quan hệ này, chúng ta có thể chọn cách sử dụng và sắp xếp tính năng AI một cách tối ưu, không gây phân tâm cho người dùng.</p>
<p><strong>15:11</strong> Có sáu cách để trình bày tính năng AI, bao gồm:</p>
<ol>
<li><strong>Separate</strong>: AI hoạt động độc lập.</li>
<li><strong>Alongside</strong>: AI được đặt bên cạnh các tính năng khác.</li>
<li><strong>Layer</strong>: AI hoạt động dưới dạng lớp phủ.</li>
<li><strong>Integrated Parent</strong>: AI đóng vai trò chính trong điều hướng hoặc quản lý nội dung chính.</li>
<li><strong>Integrated Child</strong>: AI đóng vai trò nhỏ hơn, bổ trợ cho tính năng chính.</li>
<li><strong>Point</strong>: AI chỉ xuất hiện như một biểu tượng nhỏ, giúp người dùng hiểu thêm về cách nó hoạt động.</li>
</ol>
<p><strong>16:41</strong> Tiếp theo là "Functional Relationship," phần này mô tả các mối quan hệ chức năng giữa AI và các tính năng khác trong hệ thống. AI có thể tồn tại độc lập nhưng vẫn adapt (thích nghi) với các nội dung và tính năng của hệ thống ở mức cao hơn. AI có thể tích hợp với các tính năng hiện có để cải thiện hiệu suất, thay vì người dùng phải thao tác thủ công. Khi hiểu rõ cách hoạt động chức năng của AI, chúng ta sẽ xác định rõ vai trò của nó trong ứng dụng và thiết kế để các hành động chức năng của nó không bị xung đột, cũng như không làm gián đoạn luồng sử dụng của người dùng.</p>
<p><strong>17:28</strong> Có sáu cách để mô tả mối quan hệ chức năng của AI:</p>
<ol>
<li><strong>Separate</strong>: AI hoạt động riêng biệt.</li>
<li><strong>Aware Of</strong>: AI tách biệt nhưng có khả năng nhận biết các thay đổi trong tính năng chính.</li>
<li><strong>Acting Up</strong>: AI tương tác qua lại giữa các tính năng.</li>
<li><strong>Feature Incorporate</strong>: AI được tích hợp như một phần của một tính năng hiện có.</li>
<li><strong>Usage</strong>: AI được sử dụng theo cách mà nó tương tác với các phần khác trong ứng dụng.</li>
<li><strong>Usage Conventionally</strong>: AI tương tác hai chiều với các tính năng khác một cách trực tiếp.</li>
</ol>
<p><strong>18:14</strong> Nó sẽ không ảnh hưởng trực tiếp đến tính năng chính, nhưng nó sẽ có tác động qua lại với AI và từ đó giúp cải thiện tính năng chính. Đây là một ví dụ cụ thể hơn về cách sử dụng của nó, chẳng hạn như trong code này có thể generate một panel bên phải.</p>
<p>Tiếp theo là <strong>Acting Up</strong>, nghĩa là hai bên sẽ có tác động qua lại, có thể trao đổi dữ liệu qua lại với nhau. Ví dụ, tính năng A có thể hiểu được dữ liệu từ tính năng B và ngược lại. Các dữ liệu này sẽ được trao đổi qua lại liên tục để cải thiện sự tương tác.</p>
<p>Tiếp theo là <strong>Feature Incorporate</strong>, nghĩa là AI được tích hợp trực tiếp vào các tính năng hiện có của ứng dụng. Cuối cùng là <strong>Usage Conventionally</strong>, nghĩa là AI sẽ tương tác theo cách thông thường với các tính năng khác, giống như cách các ứng dụng truyền thống hoạt động.</p>
<p>Ví dụ như khi bạn dùng một ứng dụng và có nhiều tính năng khác nhau, AI sẽ đóng vai trò trong các phần như feature, nhưng không phải lúc nào cũng là phần chính, mà sẽ đóng vai trò bổ trợ.</p>
<p><strong>19:06</strong> Ví dụ khác là ứng dụng Quora hay các ứng dụng khác, AI sẽ có nhiều tính năng nhỏ được tích hợp vào, như kiểu gợi ý trả lời câu hỏi, giúp người dùng thực hiện các tác vụ dễ dàng hơn. Vậy là nãy giờ em đã đi qua ba phần chính:</p>
<ol>
<li><strong>System Scope</strong>: Giới thiệu cách AI tích hợp vào sản phẩm.</li>
<li><strong>Spatial Relationship</strong>: Giới thiệu cách sắp xếp AI trong giao diện người dùng.</li>
<li><strong>Functional Relationship</strong>: Giới thiệu các mối quan hệ chức năng giữa AI và các tính năng khác.</li>
</ol>
<p>Những phần này giúp tối ưu hóa sản phẩm, cải thiện trải nghiệm người dùng và nâng cao hiệu quả cho ứng dụng AI.</p>
<p><strong>19:57</strong> Điều này rất quan trọng bởi vì nếu mình hiểu rõ cách áp dụng AI, tính năng mình làm sẽ mang lại nhiều giá trị hơn cho người dùng. Ví dụ mà em quên chưa nhắc đến là phần "separate." Em đã đưa ra một số ví dụ, nhưng để quay lại một chút về "separate" – tính năng AI hoạt động độc lập. Mình có thể xem xét trường hợp Microsoft có một cái slider để generate hình ảnh song song với tính năng khác. Hoặc với một ứng dụng như Shopee, AI sẽ đóng vai trò hỗ trợ bên cạnh tính năng chính của ứng dụng.</p>
<p><strong>20:53</strong> Đó là những ví dụ minh họa cho việc sắp xếp và bố trí AI trong giao diện và sản phẩm. Anh Thành có thấy phần này như thế nào? Em thấy nó giống với các patterns thông thường trong thiết kế.</p>
<p><strong>22:01</strong> Anh Thành: Đúng rồi, những cái này là các mẫu patterns mình hay dùng trong việc thiết kế ứng dụng AI, hoặc khi tích hợp AI vào một ứng dụng hoặc sản phẩm riêng biệt. Về cơ bản, nó là những cấu trúc quen thuộc để mình hiểu rõ hơn về cách áp dụng AI. Em có thể phân loại, chia nhỏ chúng ra thành những tính năng nhỏ hơn. Phần này rất rõ ràng.</p>
<p><strong>23:31</strong> Cảm ơn Nam. Ok, tiếp theo là bài của Hoàng và Đạt nhé.</p>
<p>Hôm nay, em sẽ giới thiệu một bài gọi là "AI Button trong các ứng dụng LLM." Trước khi vào bài, em sẽ nói qua về nội dung và agenda. Đầu tiên là chúng ta sẽ tìm hiểu về các design patterns liên quan đến AI Button. Những cái pattern này được áp dụng trong nhiều ứng dụng khác nhau. Em sẽ lấy ra những cái phổ biến và dễ hiểu nhất để giới thiệu cho mọi người.</p>
<p><strong>24:35</strong> Bài này sẽ xoay quanh việc sử dụng ứng dụng AI trong các sản phẩm số. Ứng dụng này tận dụng sức mạnh của các mô hình AI để giải quyết các bài toán cụ thể hoặc hỗ trợ người dùng trong các tác vụ. Khi sử dụng LLM, nhiều người có thể gặp vấn đề là mô hình không đưa ra đúng kết quả như mong đợi. Điều này là do bản chất của các mô hình này chỉ dựa trên khả năng phản hồi dựa trên chuỗi dữ liệu. Có nhiều cách để giải quyết vấn đề này. Một trong những cách tốn kém nhất là phải điều chỉnh lại toàn bộ mô hình từ đầu. Điều này có thể mất nhiều thời gian và nguồn lực.</p>

<p><strong>25:15</strong> Mình có một cách gọi là <strong>in-context learning</strong>, có nghĩa là AI có thể học trực tiếp ngay trong ngữ cảnh hiện tại khi bạn đang sử dụng nó. Đây là một kỹ thuật như là few-shot learning hoặc zero-shot learning, giúp AI tự học mà không cần phải được huấn luyện lại từ đầu. Ví dụ, bạn chỉ cần cho AI một vài ví dụ nhỏ trong ngữ cảnh và nó sẽ tự điều chỉnh cách hoạt động của mình dựa trên những gì được cung cấp. Thay vì phải retrain toàn bộ mô hình, cách này giúp tiết kiệm thời gian và tài nguyên rất nhiều, và nó vẫn đảm bảo AI có thể học từ ngữ cảnh cụ thể mà bạn cung cấp.</p>
<p><strong>25:52</strong> Với trường hợp này, <strong>in-context learning</strong> được sử dụng rất nhiều trong <strong>prompt engineering</strong>. Mọi người sẽ cung cấp các ví dụ có sẵn trực tiếp vào prompt và mô hình sẽ học từ những ví dụ đó để tạo ra các kết quả tiếp theo. Đó là ý tưởng chính của in-context learning. Về cơ bản, thiết kế sẽ hoạt động như thế này: bạn có một truy vấn, sau đó bạn xây dựng prompt với các ví dụ cần thiết và dữ liệu few-shot learning, rồi bạn đưa nó qua mô hình, mô hình sẽ trả về kết quả dựa trên các ví dụ đó. Tuy nhiên, nó không chỉ dừng lại ở các ví dụ, mà còn bao gồm rất nhiều yếu tố khác.</p>
<p><strong>26:37</strong> Nhìn rộng hơn, in-context learning liên quan đến việc cung cấp ngữ cảnh vào prompt bằng cách truyền vào các thông tin mà mô hình không có sẵn. Vì đây là một mô hình được huấn luyện trước, kiến thức của nó bị giới hạn, vì vậy bạn truyền thêm thông tin vào ngữ cảnh và prompt để mô hình học trong quá trình tạo ra kết quả. Ví dụ, trong chẩn đoán hình ảnh y khoa, mô hình có thể không có đủ kiến thức chuyên môn. Vì vậy, bạn cung cấp kiến thức đó vào ngữ cảnh và prompt để mô hình học trong quá trình tạo ra kết quả. Đó là cốt lõi của in-context learning.</p>
<p>Tiếp theo là nút thiết kế thứ hai quan trọng, được gọi là <strong>data preprocessing/ editing</strong>.</p>
<p><strong>27:54</strong> Phần này miêu tả quy trình chuẩn bị dữ liệu cho mô hình ngôn ngữ (LM). Như mọi người biết, LM hoạt động dựa trên các cơ sở dữ liệu vector, sử dụng so sánh vector để tìm các điểm dữ liệu tương tự. Quy trình này thường liên quan đến việc xử lý dữ liệu đa phương tiện và các loại thông tin khác nhau. Để đảm bảo đầu ra là tối ưu, việc áp dụng các bước xử lý trước dữ liệu là rất quan trọng. Ví dụ, bạn có thể xử lý trước văn bản bằng cách lọc ra các chi tiết không cần thiết để làm ngắn lại, hoặc với hình ảnh và âm thanh, bạn có thể loại bỏ nhiễu hoặc nén dữ liệu để giảm kích thước trước khi đưa qua mô hình ngôn ngữ.</p>
<p><strong>29:19</strong> Việc xử lý trước hoặc chỉnh sửa dữ liệu giúp mô hình hoạt động hiệu quả hơn. Có nhiều cách để xử lý trước, tuỳ thuộc vào loại dữ liệu hoặc ngữ cảnh. Bạn sẽ thực hiện điều này dựa trên các yêu cầu cụ thể. Nút thiết kế tiếp theo mà tôi muốn đề cập đến là một thiết kế thường được sử dụng, mặc dù có nhiều tên gọi khác nhau. Tôi gọi nó là <strong>example agent</strong>. Đây là một thiết kế thường thấy khi bạn muốn truy vấn của mình đi qua nhiều ngữ cảnh khác nhau. Ví dụ, nếu bạn có một ứng dụng đánh giá bài viết, bạn có thể cho bài viết đó đi qua một đường ống nơi mỗi agent đánh giá bài viết từ một góc độ khác nhau.</p>
<p><strong>30:11</strong> Một agent có thể đánh giá bài viết từ góc nhìn của một nhà văn, một agent khác có thể từ một góc nhìn khác. Sau khi đi qua tất cả các agent này, sẽ có một lớp tổng hợp cuối cùng để kết hợp hoặc xử lý các kết quả đó, và cuối cùng cung cấp cho người dùng một kết quả tổng hợp. Thiết kế này thường thấy trong các hệ thống đánh giá, nơi bạn đánh giá kết quả từ các mô hình khác nhau và chọn ra kết quả tốt nhất dựa trên các điều kiện đã được thiết lập trước.</p>
<p><strong>30:55</strong> Nút thiết kế tiếp theo, gọi là <strong>agentic button</strong>. Vậy agentic có nghĩa là gì? Trong ngữ cảnh của các mô hình ngôn ngữ (LMs), <strong>agentic LMs</strong> ám chỉ việc nâng cấp khả năng của mô hình. Vì mô hình chỉ biết những gì nằm trong dữ liệu huấn luyện của nó, chúng ta sẽ nâng cấp nó để tăng cường sức mạnh của nó và giảm thiểu sự can thiệp của con người. Thiết kế này giúp hệ thống tự động hoá nhiều hơn, cho phép nó hoạt động với ít sự can thiệp của con người hơn.</p>
<p><strong>32:24</strong> Thiết kế này có một số thành phần chính giúp bạn đạt được mức độ tự động hóa này. Có bốn thành phần chính: <strong>reflection</strong>, <strong>planning</strong>, <strong>execution</strong>, và <strong>multi-collaboration</strong>. Mỗi thành phần này đều giúp hệ thống của bạn trở nên tự động hóa hơn. Đầu tiên, chúng ta hãy nói về <strong>reflection</strong>. Reflection liên quan đến việc đánh giá kết quả ban đầu của mô hình dựa trên một tiêu chí hoặc một chỉ số cụ thể để xác định xem kết quả đó đã được tối ưu hóa chưa. Nếu chưa, hệ thống sẽ điều chỉnh và lặp lại quá trình này, tiếp tục tạo ra kết quả cho đến khi đạt được kết quả tối ưu.</p>
<p><strong>33:06</strong> Reflection giúp giảm thiểu sự can thiệp của con người vì thay vì tạo ra một kết quả ban đầu không đáp ứng mong đợi của bạn, hệ thống sẽ tinh chỉnh dựa trên các tiêu chí đã được thiết lập trước, cuối cùng đưa ra một kết quả chính xác hơn mà không cần điều chỉnh thủ công.</p>
<p>Reflection button này có nghĩa là nó sẽ đánh giá cái output ban đầu của một con AI, rồi nó sẽ đánh giá dựa theo một tiêu chuẩn nào đó hoặc là một cái chỉ số nào đó để xem là cái kết quả này đã tối ưu chưa. Nếu chưa tối ưu nó sẽ thêm thắt một chút và nó sẽ chạy vòng lại con AI đó để nó tạo ra kết quả khác cho tới khi nào đạt được kết quả tối ưu nó sẽ trả cho mình cái kết quả cuối cùng. cái này nó sẽ giúp giảm thiểu việc con người phải can thiệp vào quá trình làm việc, bởi vì nếu mà output đầu tiên không đúng ý mình, mình không cần phải tự chỉnh lại nữa mà nó sẽ tự tối ưu.</p>
<p><strong>33:42</strong> Button thứ hai là tool. Tool có thể là external, nó có thể là external API hoặc là những cái function mà mọi người code. Những cái tool này được sử dụng để cho model có thể lấy được những knowledge từ thế giới bên ngoài, những real-time knowledge, những external resource mà nó không được train sẵn. Như OpenAI hay là Claude đều có hỗ trợ. Khi đó, con model có thể tự biết khi nào cần gọi tool dựa vào cái description mà mọi người viết trên cái tool đó. Model sẽ tự biết cách lấy và extract thông tin từ tool, rồi trả về cho con LM để nó generate ra output.</p>
<p><strong>34:30</strong> Kế tiếp là planning. Planning button có nghĩa là mọi người cho con LM có khả năng lập kế hoạch, để tránh việc phải prompt đi prompt lại nhiều lần. Ví dụ, nếu có một task phức tạp, mình sẽ có một cái prompt lớn cho nó plan ra tất cả các step mà nó cần làm theo kiểu step by step. Cách này sẽ cho nó làm những việc nhỏ trước, rồi cuối cùng kết hợp lại thành một cái task lớn. Cái kiểu planning design này có nhiều biến thể, và đây là biến thể đơn giản nhất: lập kế hoạch xong rồi làm từng bước một.</p>
<p><strong>35:10 C</strong>uối cùng là multi-collaboration. Cái này em đã present cách đây một tháng rồi. Nói chung, nó giống như kiểu là AI giỏi việc nào làm việc đó. Mình có một cái context đúng không? mình chia nó ra, rồi đưa qua từng người. Người nào giỏi việc đó nó sẽ giải quyết việc đó, xong rồi pass qua con agent tiếp theo. Cứ thế, cuối cùng nó sẽ complete được cái requirement. Cái design này sử dụng tính chất divide and conquer khá nhiều. Chia việc lớn thành việc nhỏ, rồi đưa việc nhỏ cho người giỏi chuyên môn. Đây là một cái design button mà em thấy khá nhiều nơi bên ngoài sử dụng.</p>
<p><strong>36:24</strong> Đó là những design button mà em thấy nhiều nơi sử dụng và hiểu nhất. Em đã trình bày xong. Mọi người có câu hỏi gì không?</p>
<p><strong>37:10</strong> Hoàng, em nói lại cái phần planning, để confirm lại cái comment của anh Bảo. Nó giống như là kiểu đọc cái prompt đúng không? Nó sẽ hiểu cái prompt của anh trước, xong rồi nó sẽ chia cái prompt ra thành những cái nhỏ hơn, xong rồi nó sẽ có những con worker, có thể là những IDE worker hoặc là những cái prompt nhỏ để nó hoàn thành task đó. Đúng không?</p>
<p><strong>37:40</strong> Đúng rồi, anh có thể hiểu như vậy. Mình có thể chia prompt ra, ví dụ như là một task phức tạp, nó sẽ chia ra nhiều cái plan nhỏ. Những cái plan nhỏ này sẽ làm step by step. Ví dụ nó làm plan 1 trước, rồi làm plan 2, rồi làm plan 3. Sau khi hoàn thành tất cả các plan, nó sẽ tổng hợp lại ở một cái chỗ nào đó, hoặc là một cái component cuối cùng để nó ra được câu trả lời cuối cùng.</p>
<p><strong>38:06</strong> Ý là nó giống như cái con Zero mà hôm trước anh Tom present ấy. Con worker sẽ có thể làm một số task như đọc file, xóa file, sửa file, hay là talk với Internet, gửi email các thể loại. basically, agent các thứ như vậy.</p>
<p><strong>38:52</strong> Đúng rồi, bản chất của nó là thay vì làm một cục rất lớn để giải quyết hết cái task đó, mình phải đi prompt đi prompt lại nhiều lần để nó cho ra kết quả. Mình có một cái prompt trước, để chia nhỏ thành các task nhỏ, rồi sau đó có một cái pipeline để nó đi qua từng con worker, làm những việc nhỏ nhỏ cho mình.</p>
<p><strong>39:23</strong> Ok, kéo lên slide 14 đi Hoàng, slide 14. Anh cũng thấy là kiểu con này giống giống con Mule Automation mà Tom setup đúng không? Con Mule button mà Tom setup ấy. Em đã code xong rồi nhưng nhìn cái design này với cả cái button giống hệ nhau này.</p>
<p><strong>39:46</strong> Ừ, cái này là thằng Tpm nó chạy loop rồi, nhìn ra giống giống một tí. Nó giống planning mà anh Tom vừa nói, là nó break task ra từng phần, rồi xử lý từng phần một. Nó có iteration trong đó, giống như là nó có một list các step mà em đã mô tả ở trên. Back lại cái của em, chính là chỗ mà agent đang thấy. Cái của anh thấy nó giống planning hơn, là nó chia plan ra trước, rồi làm step by step từng plan một, đi qua mỗi vòng làm từng cái một. Còn cái này nó giống như là làm song song với nhau, nó parallel với nhau, để ra output xong rồi đánh giá lại output đó, rồi đưa ra kết quả cuối cùng. Chắc anh nhầm cái work rồi, đã correct lại.</p>
<p><strong>42:28</strong> Đúng rồi, thử đi. Nó là kiểu như vậy đó, nó chia ra thành nhiều việc khác nhau. Nó giống như là classify, nó chạy qua từng cái. Cái này giống multi-collaboration hơn, vì nó giống như question classifier, chỉ chạy một trong mấy cái này thôi. Mỗi agent làm việc đúng chuyên môn của nó, rồi combine lại.</p>
<p><strong>43:33</strong> Nhưng mà anh thấy mấy phần như reason với input analysis có đúng không? Của Tom, phần expert ấy. Riêng vụ pick domain ấy, nó có classifier ở đó, nhưng mà mấy phần reason với input analyzer là những agent khác nhau. Bên group đó là expert thôi, mình consider nó như là một group expert đúng không? Và nó combine với năm cái agent mình phía dưới.</p>
<p><strong>45:33</strong> Nếu mà làm tất cả mọi thứ trong cùng một cái prompt, em chắc chắn nó sẽ không ra được kết quả mình mong muốn đâu. Vì context quá nhiều và không có example cụ thể. Đầu tiên là accuracy chắc chắn sẽ giảm vì quá nhiều dữ liệu cùng lúc. Cái chính là phải chia ra nhiều layer, từng bước một. Thực tế mình cần output từ con LM, chứ không thể hardcode từ trước được. Mình chỉ muốn một cái prompt đơn giản nhất, để nó làm ra các câu trả lời nhỏ, rồi từ đó có một câu trả lời lớn.</p>
<p><strong>46:59</strong> Đúng rồi, khi làm nhỏ ra, mình sẽ biết vấn đề nằm ở đâu để debug. Như anh đã nói, specify kỹ, chia ra từng layer, nếu thấy sai ở đâu mình sửa ở đó. Còn nếu quăng một cục, mình sẽ không biết nó sai chỗ nào, rồi phải sửa rất nhiều lần.</p>
<p><strong>48:43</strong> Đúng rồi anh. Ví dụ như tạo một cái event trong calendar vào ngày mai, nếu không có sự kiện trong giờ đó tạo event, còn nếu có rồi thông báo. Nếu mình quăng một cục request đảm bảo nó sẽ rối ngay, vì nó phải thực hiện theo step by step. Nếu chia thành từng layer, test từng bước sẽ ổn hơn.</p>
<p><strong>49:23</strong> Nó sẽ em chắc là 99% là nó sẽ mù luôn á. Nếu mà còn nếu mình chia cái thành layer cơ, thành nhiều lớp layer á, làm test bài test nó sẽ ok hơn. Rồi, hô nào nên nữ, nên văn phòng là có Tôm ở đấy người chửi nhau. Anh không có hỏi nào chắc là cảm ơn Hoàng trước. À, đến Đạt nhé. Đạt nhờ. À, em không thị xem màn hình. Ok rồi, mọi người thấy màn hình của em chưa? Ừ, thấy rồi.</p>
<p><strong>50:38</strong> Hôm nay em nói về Yelp use cases. Từ từ Đạt, để anh giới thiệu context một chút. đợt này team mấy bạn sẽ focus vô đâu đó và đi search thử mấy cái phần use case ấy. Use case ở đây có nhiều dạng. Cái dạng mà Đạt đang sharing nó sẽ là mình xem thử các bên startup hay enterprise nó đang apply vào để giải quyết vấn đề gì. Là có thể là những cái green field, tức là những cái hoàn toàn mới. Hoặc là những cái mà nó optimize cho cái phần current workflow của chúng đó, kiểu vậy. Nó sẽ viết những use case và report lại hàng tháng, những cái phần update. Ngoài ra có một cái phần dạng use case khác nữa đó là những cái phần tuning mà để boost phần development của bên phía bên phía là tech các thứ. nó sẽ có những cái technique hay là có những cái phần editor mới, hay là mấy cái tool mới các thứ. đ cũng sẽ report cái phần đấy đâu đó trong tech. Đang testing thử trong khoảng hai tuần một đấy. đây là một cái bài đầu tiên chắc con Yelp này, nó đang dạng là con start-up phải không, chắc là. tiếp tục giới thiệu cho anh em một tí về cách mà bọn này đang apply AI là như thế nào?</p>

<p><strong>52:01</strong> Yelp là cái đơn vị nó đưa ra cái software, nó cung cấp cái software cho các store, các bên mà doanh nghiệp muốn làm các đơn vị nhỏ lẻ như kiểu là giao hàng nhanh, hay là nhà hàng, rồi các bánh dụng cụ cơ bản, kiểu như vậy. Yelp này nó bán cái software cho mọi người làm việc đó. em sẽ chia sẻ chút về thằng này, nó sử dụng AI vào trong cái tooling của nó như thế nào.</p>
<p><strong>53:00</strong> trước đó chúng nó có một cái machine learning system rồi, bây giờ nó app thêm AI vào để giúp cho cái việc recommendation nó đúng hơn. bọn Yelp này nó có trên hệ thống của chúng nó, nó có nhiều cái thể loại đánh giá như kiểu đánh giá nhà hàng nó không bị tốt chẳng hạn. dựa trên những cái review đó, chúng nó có làm cái trò là text editing để so sánh được những cái kết quả mà spam hay không á. nó sẽ sử dụng AI vào trong cái việc gì. Thứ nhất là chúng nó sẽ tạo, chúng nó sử dụng AI để làm cái việc làm dataset, để train được cái model đánh giá là nó đang spam hay nó đang review tốt hay xấu như thế nào á. nó sẽ sử dụng AI để tạo ra cái dataset dựa trên LinkedIn. ở trong đây, em đọc có thấy bảo là chúng có sử dụng số tính như Zero-shot và Few-shot để làm dataset. chúng nó chỉ sử dụng một số cái model ở trên Hugging Face, rồi xong chúng nó làm classify để đánh giá được là review tốt hay xấu. đây là một cái use case cho cái việc AI dùng để làm text editing.</p>
<p><strong>54:18</strong> À, sang cái use case thứ hai của chúng nó, là chúng nó có sử dụng Clip Model. Clip Model bản chất của nó là xử lý hình ảnh. Xử lý hình ảnh có nghĩa là sao? Có nghĩa là dựa trên review, dựa trên review... đợi em chút để em kiếm nè. À, Clip á, nó sẽ xử lý hai thứ. Một là cái caption của cái ảnh, và cái ảnh nó như thế nào. qua Clip này á, nó sẽ hiểu được cái context của cái ảnh là cái gì. chúng nó sử dụng Clip vào trong những cái công việc như là những cái người ta đi vào trong một quán ăn hay một cái quán nhậu á, chúng nó sẽ review, chụp ảnh để capture lại những cái thứ này. Và ví dụ như hình ảnh của một cái món sản phẩm đi, trước khi apply Clip nó không đánh giá được, nó không đánh giá được là nó có bánh quế không, nó chỉ đánh giá được mỗi gà rán thôi chẳng hạn. Sau khi apply Clip vào á, nó sẽ biết được là có gà rán và có bánh quế. bản chất, nó sử dụng cái Clip này là một phần của AI, là nó xử lý ảnh, xử lý ảnh và caption của ảnh, và hình ảnh thành vector để nó so sánh với nhau. đây là hai use case của nó. những cái use case này được áp dụng cho cái gì?</p>
<p><strong>55:38</strong> Hai cái use case trên nó sẽ áp dụng trong cái tình huống là khi mà mình có nhiều review á, mình có thể summarize nó lại thành một cái highlight review ở trên đây. dựa trên những cái thứ mà nó chuyển thành vector được á, nó có thể annotation được cái việc là những cái hình ảnh đang nói cái gì, nó support cho mình được cái gì ở trong đây. Đợi một chút, nó sẽ highlight cho mình luôn. nó sẽ biết được cho mình cái context của cái ảnh là gì, nó có thể annotation được cái việc này. đó là cái use case của cái việc mà AI dùng để làm image summarization.</p>
<p><strong>56:15</strong> Đầu năm nay nó có release thêm cái là Yelp Assistant. Dựa trên những cái nền tảng cũ của chúng nó, chúng nó có thể tạo ra chatbot rồi, xong nó có thể review lại cái highlight như thế này, mình cứ hỏi nó xong nó recommendation cho mình cái gì thôi. Đơn giản là như vậy. Ngoài ra em có thấy một cái use case cũng khá đặc biệt, có nghĩa là trong cái giai đoạn từ 2020 á, nó nổ ra cái câu chuyện là làm clip ngắn review các thứ á. chúng nó có một cái nguồn dataset nhất định cho cái việc đó. em thấy chúng nó bảo chúng nó sắp release một cái như anh Tom có đề cập, cái bọn đó có thể chuyển văn bản thành giọng nói á. dựa trên cái nguồn dataset review này á, có lẽ chúng nó support review thêm cái việc mà làm video clip ngắn để mô tả cái nhà hàng.</p>
<p><strong>57:45</strong> Dựa trên những cái review, những cái video mà người ta tới người ta review á, mình có thể tạo ra được một cái đoạn script, xong cho nó chạy qua AI, nó tự động làm ra một cái video về một cái nhà hàng như mình. đây là use case của bọn này, đơn giản nó có thế thôi. Ok, quay lại cái câu hỏi đầu tiên, cái này nó sẽ dạng là dùng AI để label data, đúng không?</p>
<p><strong>58:35</strong> Ok, vậy là check xem là cái comment là negative hay positive, đúng không? Kể kiểu đấy là một ví dụ. Cái thứ hai nữa là nó sử dụng cái clip model, đúng không? Chắc là sẽ dạng giống như Vision, nhưng mà live hơn, cũng để dán nhãn, đúng không? Để dán nhãn giống như cái của bên phía Plot, dán nhãn cho ảnh. hai cái use case đó, nó sẽ được ứng dụng trong cái việc gì?</p>
<p><strong>59:18</strong> Em nghĩ có một cái ý khá hay mà nó chưa nói tới, là câu chuyện là nó có nguồn dataset sẵn. Như là ai tới review, ai tới đánh giá các thứ, dựa trên những cái clip ngắn như thế này, nó có thể tạo ra được một cái video intro về cái nhà hàng đó. Nó sử dụng AI. Em nghĩ là nó sử dụng AI để viết kịch bản, rồi sau đó đưa kịch bản đó cho một con AI voice để nói. Nhưng mà hình ảnh nó lấy ở đâu? Như kiểu là video nó sẽ lấy từ đâu ra?</p>
<p><strong>59:57</strong> Từ trong cái review, ai tới review họ sẽ có một cái video để review. Ok, tự động tạo advertisement, đúng không? Dạ vâng, cho TikTok hay những nền tảng như TikTok các thứ, kiểu summarize từ review của user. Nghe cũng có vẻ sáng tạo đấy. Ừ, chắc anh em confirm mấy cái của anh bảo làm rồi đúng không?</p>
<p><strong>01:00:07</strong> Đang vậy, cái này ok là cái caption. Ok, đúng hầu như là đúng anh. Bạn nói đúng, là chúng nó sẽ, em nghĩ em nghĩ cái use case này bọn này ban đầu á, cái mục đích ban đầu của bọn này là làm recommendation. trước đó, trước khi có AI chúng nó đã có một cái hybrid recommendation model trước. Căn bản là nó sẽ... Em nghĩ là khi mà có cái này á, nó dẹp gần hết cái model cũ này luôn. Em nghĩ có một cái khá hay là cái business messaging mà chúng nó không có đề cập nhiều. Có nghĩa là em nghĩ là nó sẽ dựa trên là có review top 50 review chẳng hạn. Xong top 50 cái interaction, kiểu như rating như thế nào. Thứ nhất là review tốt, n rating tốt, cái business messaging của nó sẽ tốt. Mà Yelp không đề cập vấn đề này, mình không trách nó được.</p>
<p><strong>01:00:51</strong> Ok, anh em có câu hỏi cho Đạt không? Bài đầu tiên đấy. Đạt bảo đang thêm mấy cái, mình phải enterprise nữa, nhưng mà thầy thấy đang Viettel với cả FPT, với cả VNG các thứ, đang chưa biết thấy chúng nó thế nào. Đạt kêu mấy cái tool, cái tool gì coding của bên phía FPT hả, đang kêu cùi.</p>
<p><strong>01:01:41</strong> Hì, một bản for, một bản for của của continue à? Nó thế, nó thế không tốt. Nó hơi cùi, thô. Hai, chị hết rồi à? Chắc vậy. Đạt nhé. Hôm nay mấy bài về Yelp và Tech Linh chắc tuần sau, tuần sau, tuần sau nữa, nếu kịp.</p>
<p><strong>01:02:01</strong> Tí demo luôn đi, Đạt luôn. Để Đạt demo một tí cái gì nhỉ? Cá đang là một con bot, để có thể question với cả question một cái short code dưới dạng kiểu developer mà hiểu rõ hơn về code, hay là test kiểu như là một vai trò auditor đi kiểm tra chất lượng của code. Đạt đang demo dev cái workflow hay con bot dựa trên diff đó cho anh em xem thử nào. Mình bật hình rồi Đạt ơi.</p>
<p><strong>01:03:01</strong> đây là một cái project để em xin vào club ai nha. Trình em gọi là hơi 'newb' nên project này mà có lem quá mọi người thông cảm. Workflow cơ bản là em sẽ lấy query, rồi trích xuất ra được cái URL của repo. Ở đây em có dùng lại cái scrapper của anh Tom, nhưng mà nó chưa đúng ý em, nên em có tạo một con scrapper ở local nó sẽ lấy được tất cả content của repo luôn. Nhưng mà cái đó nó quá lâu với quá lớn. Ờ, default hiện tại em chưa thấy làm cách nào mà bỏ vào con context được, trừ khi dùng cái knowledge retrieval, mà dùng knowledge retrieval em không có gọi là trực tiếp được mà phải bỏ vào trước. Mình không có chọn, không có chọn repo được.</p>
<p><strong>01:05:45</strong> Cái scraper này của anh Tom nó không có lấy content của file, cho nên em chưa vẽ diagram được. Vẽ diagram có thể em dùng, tí nữa em test thử. Cái này là em lấy được content của những file nè, ở root, ở những file doc. Những file đó không chắc câu hỏi của Huy vừa đưa ra chắc là cũng không trả lời được. Để em thử, em có sẵn cái full của em vô đây rồi, offline nhỉ. Bên phía in sẵn content rồi, chứ không online. Cái này em generate bằng luôn, cũng không có.</p>

<p><strong>01:07:07</strong> Cái này nó sẽ scrap full content, nó sẽ đầy đủ hơn. Để em thử đặt câu hỏi của bên Huy hay của Hoàng các em thử nào. Mình thử BC chat lên rồi đặt câu hỏi xem. Anh có không? À không. Maybe là cái context này quá lớn, cái phần knowledge retrieval này em chưa tìm được cách mà cho nó vào context tốt được.</p>
<p><strong>01:09:19</strong> Retrieve tối ưu lắm. Cái file text này cũng mấy chục ngàn dòng, mấy chục ngàn dòng á. Mở lên xem thử nà, đ đang dùng mini hả, đổi sang máy đ xịn hơn xem có ok hơn không. Đồ mini hơi cùi. 2 triệu từ như thế, từ làm sao mà nó còn xong được ta? Em nghĩ là phải có một cái server, cái dedicated server luôn nó mới ok. Anh đang tò mò tại sao nó chạy được ấy, bởi vì 29U word à, như vừa thấy à. Nhân với cả 4 này là số to. Kích cỡ đấy, Follow up xem thử. Ok, tức là em vẫn là từ cái context thôi đúng không, là mình cũng chỉ dạng là query kiểu query vb đúng không, chứ không phải mình nhập hết tất cả cái đấy vào context.</p>
<p><strong>01:10:57</strong> Ok, đúng rồi anh. em chưa nắm được là cái retrieval của thằng dify nó sẽ chạy như thế nào. Không biết nó chạy có đúng không, nó retrieve có đúng không. Em chưa tracing được nó mà em có cái tool tracing ở phía trước nữa, có thể test lại thử xem như thế nào. Nhưng mà ý là nếu mà kiểu retrieval như này chắc là kết quả nó sẽ không đúng được đâu anh. Anh cũng đang chưa biết là nó sẽ run bao nhiêu data ấy. Kiểu nó chỉ prefer 2-300 thôi, kiểu data không thể nào đủ mà để làm mấy cái task kiểu này. Cái này ít nhất cũng phải vài trăm tương đối data ấy. Dạ cái này còn work in progress.</p>
<p><strong>01:11:35</strong> Đùa đấy, cứ lên công ty là có AI Club rồi. À, là của full version hay là fix được cái vụ này demo với bọn anh ở trên office nhé, mà try em để lại cho anh. OK, để em xem nó vẫn không build ra chắc mọi người coi đỡ. Cái chắc build bị gì đó, mọi người thấy màn hình không ạ?</p>
<p><strong>01:13:08</strong> Dạ tuần này như em nói tuần trước em sẽ up cái bài sync.Map này. Em thấy nó hay với chi tiết để mọi người mà xài Go có cái nhìn tổng quan hơn về map nói chung. Và cái thằng sync map này đi qua trước là phần context. khi mọi người viết map đúng không, mà mình nếu mà mình viết concurrent map hay operation đó, mình làm concurrent á, về bản 1.16 trước nó sẽ không báo đâu, nhưng mà nó vẫn không safe nha. Còn bản từ 1.16 trở đi á nó sẽ error như thế này đó. Cho nên là để mà solve được problem này bình thường mọi người có thể viết map kèm với tại package sync, viết manual đó được.</p>

<p><strong>01:13:56</strong> Bên cạnh đó nó có một cái option khác đó là thằng sync.Map này. chút nữa đến cuối mình sẽ sẽ nói tại sao nó lại được đề ra xài và cái usecase của nó như thế nào. thằng này nó được đề ra để mà mình không cần quan tâm lắm về cái việc mà mình phải xài mutex để lock lại cho việc synchronize. Tức là mình chỉ có việc xài thôi. Xài nó trông đơn giản như thế này nha, nó friendly như là mình viết map kiểm tra value vậy. Ví dụ như mình load một cái key lên có value ok nó sẽ giống như là việc map value bình thường thôi. Trong như này, nếu có là ok true, còn nếu không có false của y chang.</p>
<p><strong>01:14:38</strong> Còn có một số cái function mà mình có thể xài rất handy. Đây là bảng 12.23 sẽ có clear, clear hết. Ví dụ như load là để lấy value, store là để update hoặc store cái key. Update vậy. Delete các thứ. ngoài cái việc mà mình viết concurrent đó đi đó, bên cạnh đó khi mà mình range, tức là mình loop một cái map nó cũng bị race condition nữa. thằng sync map này nó có cái hàm range này, mình xài mình sẽ không quan tâm nó là ấy, nó sẽ không bị nhưng mà như hàm range bình thường thôi. nó sẽ không cho mình cái cái snapshot mà gọi là consistent nhất, là khi mà mình vừa mới vô cái snapshot nó không được update là.</p>
<p><strong>01:15:28</strong> Mà mình range, tức là mình loop một cái map, nó cũng bị race condition nữa. thằng <code>sync.Map</code> này nó có cái hàm <code>Range</code>, mình xài, mình sẽ không quan tâm nó là cái gì, nó sẽ không bị như bình thường đâu. Nhưng mà như hàm <code>Range</code> bình thường thôi, nó sẽ không cho mình cái snapshot mà gọi là consistent nhất, là khi mà mình vừa mới vào cái snapshot nó không được update. trong lúc đó mình sẽ phải thay đổi cách viết, nhưng ít nhất là nó sẽ không bị phải error như thế này.</p>
<p><strong>01:16:06</strong> Đến cái phần bên dưới nó work như thế nào á. mọi người, nếu mà mọi người viết khi mà xem <code>CH</code> và <code>definition</code> cái <code>map</code> nó được cấu trúc như thế này: nó sẽ bao gồm hai cái <code>map</code>. Đó, nghe đến đây là mọi người sẽ thấy hơi kinh, nghe hơi thốn <code>RAM</code> với <code>memory</code>. Nó có một cái <code>Read Only map</code> và một cái <code>Dirty map</code>. nghe như thế mọi người có thể đoán được là nó sẽ làm việc theo kiểu là những cái value mà nếu mà được <code>write</code> nó sẽ được viết vào cái thằng <code>Dirty map</code> này hết. Cứ viết <code>update</code> vào đây, <code>update</code> vào đây, con này nó sẽ giống như là.</p>
<p><strong>01:16:46</strong> Cái <code>Read Only map</code> này nó sẽ là những cái khi mà mình đọc vào á, mình sẽ luôn đọc ở đây. Còn <code>write</code> sẽ luôn <code>write</code> mới vào thằng <code>Dirty map</code>. Còn cái flow bên dưới nó làm việc như thế nào chút xíu nữa mình sẽ nhìn cái chart flow mình sẽ thấy. À, cả hai cái <code>map</code> này có một điểm chung: nó đều có một cái con trỏ <code>entry</code> nha mọi người, để ý để dễ hiểu cái flow. Ví dụ, ở đây mình thêm một cái <code>entry</code> mới, đúng không? nó sẽ thêm vào <code>Dirty map</code> và nó đều trỏ đến <code>entry</code> này. Cái này nó sẽ giống như là một cái <code>flag</code> để đánh dấu rằng là cái <code>map</code> này đã được thay đổi rồi. Tức là cái thằng <code>Read Only map</code> này nó không phải là mới nhất nữa. Khi này bên dưới nó sẽ nhìn và hiểu rằng là thằng <code>Dirty map</code> mới là cái nên đọc vào.</p>
<p><strong>01:17:27</strong> Hình này thể hiện rằng là ví dụ như mình <code>update</code> một cái value nào đó, do bên dưới nó là con trỏ đúng không, mình chỉ việc <code>update</code> cái con trỏ đó thôi, không cần phải <code>update</code> từng cái value như là mình làm với <code>map</code> truyền thống. để làm được điều này á, bên dưới nó để ra một cơ chế là ba cái trạng thái (<code>state</code>) cho cái con trỏ <code>entry</code> này. <code>State</code> thứ nhất là <code>normal state</code>, đúng không? <code>Normal state</code> tức là những cái value cũ của <code>map</code>, nó đang có đủ và có thể xài được, không có bị gì hết. Còn trạng thái <code>amended</code> là khi mà <code>entry</code> đã bị sửa lại. Còn <code>delete state</code> là khi một <code>entry</code> nào đó đã được <code>delete</code> khỏi <code>map</code>, nhưng nó chưa được remove hoàn toàn nha. Tức là nó sẽ được...</p>
<p><strong>01:18:59</strong> ...assign cái con trỏ <code>entry</code> vào <code>new entry</code>, chứ chưa remove ra. Còn cái <code>expired state</code> là xóa hoàn toàn, giống như là <code>hard delete</code> là mất khỏi <code>map</code> luôn. Để hình dung rõ hơn, mọi người có thể nhìn cái flow như thế này nha: ví dụ ban đầu cái <code>map</code> của mình đang có một cái <code>key1</code> và <code>value1</code> đúng không? bên <code>Dirty map</code> chưa có gì cả, tức là chưa được thêm bớt gì. Sau đó, mình thêm một cái <code>key2</code> nào đó, đúng không? nó sẽ được thêm vào <code>Dirty map</code>, và khúc này là thằng <code>map</code> đã <code>amended</code> rồi, nó đã có một cái <code>flag</code> <code>amended</code> ở đây.</p>
<p><strong>01:19:40</strong> Sau đó, khi mình xóa (<code>delete</code>) một cái <code>key</code>, <code>map</code> này sẽ bị gán <code>new entry</code>, đúng không? Bên này cũng sẽ được tương tự gán <code>new entry</code>, giống như cái hình trước. Tức là mình chỉ cần cập nhật con trỏ thôi, không cần phải cập nhật value. Rồi, sau khi <code>delete</code> xong, đúng không, để <code>promote</code> được cái <code>Dirty map</code> này, mình phải cập nhật lại qua bên <code>Read Only map</code>, để <code>Dirty map</code> trở về <code>new state</code>, giống như đưa về trạng thái ban đầu.</p>
<p><strong>01:20:18</strong> Tương tự, thêm một <code>key3</code> nữa, khi thêm cái <code>key3</code> này á, cái <code>state</code> này nè, sau khi nó đã trở về <code>new state</code> rồi đúng không, mình thêm <code>key3</code> vào á, nó xác định rằng thằng này đã được <code>delete</code> rồi, nó sẽ là <code>delete</code> hoàn toàn. Điều này có nghĩa là lần sau, khi nó so sánh với <code>Dirty map</code>, nó biết rằng bên này cái <code>value1</code> đã bị xóa rồi, không còn nữa. cái <code>Read Only map</code> lúc này chỉ còn lại <code>key2</code> và <code>key3</code>.</p>
<p><strong>01:20:51</strong> Cho nên chính vì lý do này, <code>sync.Map</code> không có hàm <code>len</code> cho mọi người xài. Tại vì nếu như mọi người dùng hàm <code>len</code> ở đây, sẽ không biết được <code>value</code> của nó, tại vì lúc đó nó sẽ đếm cả những cái <code>value</code> đã <code>expired</code> hay <code>deleted</code>. Mọi người có thể thấy, chính vì cái cấu trúc của <code>sync.Map</code> được build như thế này, use case của nó được recommended là nên dùng cho những use case mà đọc (<code>read</code>) nhiều hơn ghi (<code>write</code>). Tức là nếu mà <code>write</code> hoặc <code>delete</code> nhiều, mọi người tưởng tượng chỗ này nó xài con trỏ liên tục, và có một cái issue bên Go team đã report là thằng này không bao giờ được garbage collected.</p>
<p><strong>01:21:36</strong> Sau đó Go team họ confirm rằng cái <code>sync.Map</code> này được sinh ra chủ yếu để support mấy cái bên trong Go Library thôi. Nếu mọi người thấy nó <code>handy</code> vì có những function dễ xài có thể xài, nhưng nếu use case của mọi người mà cần lưu trữ (<code>store</code>), hoặc là <code>update</code>, <code>delete</code> nhiều không nên xài, vì nó sẽ làm chậm hệ thống.</p>
<p><strong>01:22:24</strong> Dạ chắc chỉ vậy thôi ạ. Em có code lại cái bài bên này là cái bác này hay share mấy bài cũng khá chi tiết, mọi người có thể follow theo dõi. Ủa, cái này là topic gì Phát? Cho anh coi lại cái bài kịch bản đúp đầu r. À, cái sync map à? Ừ, sync map á. Ủa, nó có khác gì với lại cái anh vừa pass vô không vậy? Khác ở cái gì? Hình như là khác á anh. Ý là cái này em nhớ không nhầm là kiểu như cộng đồng tùy. Anh ví dụ use case họ muốn viết một cái gì đó mà họ thấy. Đó, anh nhìn thấy, họ ghi cái trong cái bên đấy, link mà nhìn thấy cách nó chạy mà lý do tụi nó làm thêm cái gì ấy nhỉ?</p>
<p><strong>01:23:30</strong> Anh nhìn thấy nè, họ thêm một cái lớp nữa để họ xài. Ví dụ như là họ sẽ có những cái use case đúng không? Ví dụ như họ muốn implement generic trên <code>sync.Map</code> đó. Cái này cũng có ảnh hưởng do cái vụ link nãy em nói, do thằng này nó không được garbage collected nè. Đó, kiểu vậy. ví dụ như bên này Go team ở dưới, họ đã confirm chốt xong cái này là cái <code>sync.Map</code> này họ kêu là cái này là <code>intended</code>, intentional choice rồi, cho nên họ sẽ không sửa. Họ sẽ không đổi đúng không? Bây giờ cộng đồng làm gì mình chỉ biết là họ tự xài thôi. Ý là họ thích cái việc <code>sync.Map</code> này được để ra dễ xài, có mấy cái function ngon lành, họ ráng thêm một tầng nữa, rồi chế những cái mà họ cảm thấy là ok, mình có thể xài được. Kiểu vậy.</p>
<p><strong>01:24:07</strong> Ủa mà sao cái clip này cũng lâu mà bữa nay lại chọn à? Ờ, thế kiểu insight thôi, insight cho mọi người xài. Ý là cái use case này cũng có thể được apply cho bên mình. Ví dụ như bên enterprise đúng không? ví dụ mình xài <code>map</code>, mà mình xài concurrency đúng không? mọi người sẽ tự viết một cái <code>struct</code>, xong rồi mọi người sẽ nhét một cái <code>mutex</code> vào, rồi tùy người sẽ ngồi bắt đầu viết lại. Đủ các kiểu. Trong khi đó thằng <code>sync.Map</code> rất handy, như nãy em show anh, là mấy cái function này là nó luôn follow cái chuẩn, là anh muốn <code>load</code> anh phải gọi hàm này. Kiểu vậy, nó chuẩn hơn.</p>
<p><strong>01:24:50 M</strong>ọi người sẽ tự viết một cái <code>struct</code> như thế, xong rồi mọi người sẽ nhét một cái mutex vào, tùy người sẽ ngồi bắt đầu viết rồi đú các kiểu. Trong khi đó <code>sync.Map</code> rất là handy. <code>Sync.Map</code> này như em show anh nãy đó, những cái function của nó, nó luôn follow cái chuẩn này hết. Anh muốn load anh phải gọi hàm này, kiểu vậy nó sẽ chuẩn hơn. Nhưng mà như cái bài này là mình phải để ý những cái trade-off của nó, xài cho đúng quy. Ok, hiểu rồi, tức là quy chuẩn cái cách mà sử dụng <code>map</code> hả? Với lại workflow hả?</p>
<p><strong>01:25:26 C</strong>ảm ơn Phát. Rồi để tranh thủ, mấy cái Thành ơi, nhất là xin anh em thêm 10 phút nữa nhé. Nó sẽ hơi tốn thời gian thêm xíu. Nhất là anh nhận được tổng cộng 11 cái submission cho cái bài test của mình. Có ít bài hình ở trên, mấy anh em nhìn ở trên tí. Deadline của mình là đến ngày 20, tức là tuần sau nhé. Bữa trước anh thông báo như là 27 ha, phải không? 26, 27 gì đó là deadline, mấy anh em coi tranh thủ còn một tuần nhìn bài đó rồi làm ha. Cái bài đó nó sẽ quan trọng, có một số cái mà chi tiết của từng bài đó anh chưa có nhìn kỹ. Chỉ có bài của Tôm bữa trước, Tôm nó quăng nhanh lên trên lobby quá, thành ra là có nhìn sơ qua xíu. Nhưng mà còn của mấy anh em chưa nhìn rồi. Nhưng mà cái ý chính là mọi người xem thử nha, cái chất lượng bài của mình á, tập trung ở chuyện là đợt này khi mà market nó thay đổi nhiều vậy, cái demand của thị trường cho cái nghề làm software nó có sự thay đổi lớn á.</p>
<p><strong>01:26:15</strong> Tất nhiên những cái nhu cầu nó vẫn sẽ còn ở đó thôi, nhưng mà cái số lượng đó nó giảm xuống. Thành ra đó anh gọi là cái sự thay đổi về cái nhu cầu thị trường gần như với góc nhìn của anh trải qua nó là giống như 2014, nhưng mà on-over-again, vậy là sự thay đổi công nghệ mới ra, mọi thứ mới ra, thị trường mới rồi những cái tiềm năng mới nó sẽ xuất hiện trên đó. cái bài test nó sẽ quan trọng với việc là giúp cho mình, nhất là test về văn hóa, nhìn lại trong cái lúc mà tụi anh muốn check lại cái team á, muốn là hai cái đội: đội làm research study với cả đội làm consulting nó có một cái sự phân hóa rõ ràng.</p>
<p><strong>01:27:36</strong> Nó có một cái sự phân hóa rõ ràng. Như trong cái bài viết anh post lên notion cách đây khoảng hai tuần hả, sẽ có sự phân hóa rõ ràng. Tương lai nó sẽ có thêm một số những cái policy mới cho chính sách về lợi ích khác nhau giữa hai đội nữa. Nhưng mà hiện nay là, như mình thấy đó, mọi người thấy OGIF dần dần nó được chuyển qua gần như thành cái buổi là report lại tất cả những cái study. Cái phần mà anh em đang coi mới và report lại trên này. Có thể những bài đó do được add, có thể những bài đó là do mọi người bắt đầu anh nhìn thấy, có một vài thành viên trong team mình thật sự là thấy cái kiến thức mới đó, xong rồi pick up những kiến thức mới đó để mà coi.</p>
<p>Từ từ thấy rõ ràng là tụi anh muốn cái sự phân hóa đó nó diễn ra càng ngày càng rõ hơn. Và cũng có chính sách rõ ràng cho cái chuyện đó. Tức là ai mà thích coi mấy cái phần topic nhiều hơn, xong rồi ra ứng dụng ở tới mức là MVP, hay là ứng dụng vô những cái dự án nếu có, hoặc là đi deep dive thêm về kiến thức á, sẽ có một cái benefit khác. Những anh em nào mà không nhất thiết để phải ngồi coi những cái phần liên quan tới phần study như vậy, cứ ngồi làm dự án bình thường thôi. Nhưng mà nó sẽ có một số vấn đề khác đi kèm mà anh cũng có list ra trong cái link notion cách đây hai tuần. mọi người xem nhìn lại cái link đó một tí, để biết là vì cái định hướng như vậy nên là cái bài test này nó mang ý nghĩa là xem thử coi là cái mức độ của mọi người trong chuyện bắt kịp kiến thức mới, hoặc là cái độ tương thích với lại văn hóa trong cái giai đoạn mà tất cả mọi thứ nó thay đổi như vậy tới mức nào ha.</p>
<p><strong>01:29:20</strong> Để hiểu vì cái mục tiêu là như vậy, nên là cái lúc mà chấm cái bài á, anh sẽ là người duy nhất chấm cái bài đó. Team mấy anh chị khác không có chấm đâu. Tất cả mọi người sẽ phải làm mà, nên là anh nghĩ rằng anh set cái standard cho chuyện đó. Nên là mấy bạn chịu khó làm bài đó tự làm là một chuyện. Thứ hai nữa là bài nào mà chất lượng thấp thật ra cũng không có vấn đề gì hết, chấm điểm thấp một xíu thôi, nhưng mà vừa làm hết vẫn sẽ được đủ điểm để mà coi như là pass cái đó. Chỉ là sau đó cái kết quả trước mắt thể hiện được á, là anh sẽ phân cụm thành hai cụm khác nhau.</p>
<p>Đội Foundation hay là đội Lab á, vẫn là đội core của mình từ năm nay, ha. Đó là cái thông báo chính. Nên là trên 11 cái bài này, nếu bạn nào làm xong rồi mà cảm thấy là mình có thể làm tốt hơn được cho cái chuyện mà anh vừa mới nói đó, đội mình thật ra là cái team Foundation và cái team Lab á vẫn sẽ được ưu tiên nhiều hơn trong những vấn đề khác nhau. Được ha. Nên là nếu mà anh em cái bài đó mà đang kiểu làm qua loa á, tập trung ngồi làm kỹ lại tí. Check hai thứ ha: văn hóa trên đó là một, thứ hai nữa là kiến thức.</p>
<p><strong>01:29:56</strong> Sau đó cái kết quả trước mắt thể thấy được á, là anh sẽ ân cụm thành hai cụm khác nhau, cái đội Foundation hay là đội Lab á vẫn là sẽ đội core của mình từ từ từ 8-9 năm nay ha. đó là vậy, đó là cái thông báo chính. Nên là trên 11 cái bài này, nếu bạn nào làm xong rồi mà cảm thấy là mình có thể làm tốt hơn được cho cái chuyện là anh vừa mới stay ra, là đội mình thiệt ra là cái team Foundation, cái team Lab á vẫn sẽ được ưu tiên nhiều hơn trong những vấn đề khác nhau. Được ha. Nên là nếu mà anh em cái bài đó mà đang kiểu làm qua loa á, tập trung ngồi làm kỹ lại tí, check hai thứ ha: văn hóa trên đó là một, thứ hai nữa là kiến thức cho cái cụm thông tin cái cụm gần nhất mà nó đang có vẻ hot nhất là LLM thôi.</p>
<p>Nhưng thực ra team mình vẫn cover rất là nhiều mảng khác nhau, vẫn đang có xem về design, mấy bạn cũng đang xem đúng không. Vẫn có đội đang xem đúng không. Go vẫn đang xem. Blockchain có vẻ nó qua trend tí rồi, thị trường nó đang sideways thôi, nhưng mà về demand của consulting nó vẫn yêu cầu những cái đó rất là nhiều.</p>
<p><strong>01:31:46</strong> Mấy cái mini app cho telegram, họ mua về rồi clone nhanh lên, thấy góc nhìn của mấy bạn làm business logic (BL) và tech (TCH) bây giờ nó khác một xíu rồi, không còn như ngày đầu nữa. Nhưng mà với consulting mình vẫn có thể sử dụng thôi, bình thường. Hoặc là mình có thể nhìn theo một góc nhìn khác, theo dạng là nó như một cái asset class mới xuất hiện. Với vai trò là developer, mình phải nhìn nó theo góc nhìn làm sao để nó ảnh hưởng đến cái workflow của mình như thế nào, quản lý tài sản ra sao.</p>
<p><strong>01:32:29</strong> Đó là vấn đề về bài test nhé. Mấy anh em chú ý cái đó. Thứ hai, nãy có nhắc tới cái định hướng về team và số lượng nhân sự. Trong đó có nhắc lại cái link notion hôm trước anh có gửi nhé. Đội Foundation, đội chính khi start lại lần nữa như vậy. Lúc trước team tụi anh bắt đầu chỉ có ba người thôi, sau đó dần dần tăng lên bốn người, rồi lên năm người. Có thêm Quan, có thêm Hiếu, có thêm mấy bạn khác. Nhưng mà ban đầu start với ba người, giờ đội hình xịn hơn rồi. Bây giờ 40 người toàn là thứ dữ, chắc chắn sẽ đi nhanh hơn. Câu chuyện chung là vậy, đánh giá chung cũng là như thế, nên mấy anh em nắm tình hình nha.</p>
<p><strong>01:33:12</strong> Cái thứ ba nữa có liên quan là Huy Nguyễn, nếu mà xong rồi, chắc tuần sau xem lại thống kê con số về ICY giùm anh nha. Hôm trước em cũng báo là số lượng bắt đầu chạy hơi nhiều, nên mình phải xem lại, cân lại con số cho nó hợp lý. Riêng phần này nhờ Huy và Thành chủ động làm giùm, xử lý giùm anh, xem lại cân số cho nó hợp lý. Thành có một công việc phụ là phần benefit cho thành viên team Lab, xem thử đề xuất như thế nào. Nó có thể được coi là một cái payon, nhưng mình sẽ không trả qua kênh bình thường, mà sẽ có cái cơ chế khác.</p>
<p><strong>01:33:52</strong> Nhưng mà mấy thành viên team Lab sẽ có cái đó, mọi người quen với cái đó rồi. Cuối cùng là, riêng phần về LLM hiện tại, trong cái list câu hỏi có một câu hỏi quan trọng là làm sao để sử dụng, tìm hiểu bên ngoài sử dụng LLM như thế nào và adapt ra sao. Nhấn mạnh lại câu đó, vì nó là một câu mang ý nghĩa trong việc làm knowledge discovery. Câu hỏi này liên quan đến việc test là không chỉ đơn thuần là dùng, mà là tất cả các công cụ mà mấy anh em thấy được trong team hiện tại. Khi có người sử dụng hiệu quả, có người sử dụng kém hiệu quả hơn, RT (retrieval technology) nó thành một spectrum rất rõ ràng, những người thấp là thấp, những người cao rất cao.</p>
<p><strong>01:34:38</strong> Tụi anh muốn nâng cái standard đó lên. Spectrum đó tụi anh muốn rút ngắn lại, càng cô động lại càng tốt. Bây giờ nó đang rất dài. Câu này ngoài việc dùng tool để làm discovery, nó còn mang ý nghĩa xem ngành nghề của mình sẽ như thế nào trong việc ứng dụng đó để nâng cao competency của mình, làm việc có năng suất hơn. Đó là toàn bộ vấn đề, và mọi người xác nhận lại xem cái mình làm có đúng chưa, nó có tầng ý nghĩa sâu xa hơn vậy.</p>
<p><strong>01:35:20</strong> Cuối cùng để kết thúc buổi này, Thành ơi, mấy buổi OGIF sau, những phần mà Tom đã làm liên quan đến việc xây dựng structure của một cái LLM app, có thể lấy cái đó ra phân tích thử nhé. Phân tích lấy cái đó để làm sâu hơn luôn nhé.</p>
<p><strong>01:35:56</strong>Toàn bộ mọi người hy vọng là tất cả anh em đều pass hết để đi chơi cho nó vui vẻ. Tuần sau sẽ có một cái bài khác. Tuần sau request là bên chỗ của Minh L. Minh ơi, chắc là lên làm một cái demo nha, tiếp tục về cái finite state machine, FSM á. Vì trong định hướng những công nghệ nền tảng như blockchain, AI, nhưng phần chính vẫn sẽ là các anh em làm engineer sẽ có một ngách khác để đi, đó là hiểu rõ các hệ thống lớn vận hành thế nào. Tương lai, nếu mình không phải là người sinh ra để làm data manipulation AI sẽ làm giùm mình, mình không cần tự thiết kế hay làm mấy việc của junior nữa.</p>
<p><strong>01:37:35</strong> Cách duy nhất để lên senior là hiểu rõ vấn đề và làm kiến trúc thôi. Phần finite state machine đóng vai trò tương đối quan trọng, liên quan đến chuyện scale mà trước giờ tụi mình đã nói nhiều. Trước đó Minh có đọc và hiểu đúng góc nhìn mà anh đang muốn hướng tới. Nên là xem thử làm bài phân biệt các loại general server của nó nhé. Server state machine và event-based server. Rồi làm một cái sample để biểu diễn và implement nó luôn bằng Erlang nha. Erlang có sẵn hết các framework rồi.</p>
<p><strong>01:39:01</strong> Bài này chắc là khi nào Minh Lưu. ready, nếu tuần sau không kịp có thể là hai tuần. Đề nghị mấy bạn backend và mấy bạn sen team mình gom lại, có gì confirm trước nhé. Vì bài này rất quan trọng trong chuyện phân tích thiết kế phần mềm. Bài này rất quan trọng. Trước giờ mọi người chỉ nói tới modeling và làm C4 thôi, nhưng Erlang là ngôn ngữ đi sát cái này nhất rồi, thường mọi người sẽ không biết hết. Chúng ta không nhất thiết phải học Erlang nhưng có thể nhìn cách thiết kế và build của họ để làm phần đó rất chuẩn, giống như là họ có framework sẵn, mình chỉ cần gắn vào để sử dụng thôi.</p>
<p><strong>01:39:37 T</strong>ranh thủ, ngày 20 tháng 10 là chủ nhật, Mỹ với Ngọc và Giang có post rồi. Hôm đó là các chị em đi chơi, còn không ở Sài Gòn đại diện team sẽ chúc mọi người phát tài. Chúc mọi người phát tài chắc hợp lý nhất trong trường hợp này. Một chút chúc khác có vẻ không liên quan lắm. Rồi vậy nha, anh em tham gia được đăng ký với Mỹ để book bàn và đi cho hợp lý.</p>
<p><strong>01:41:19 N</strong>hờ Thành những buổi sau cấu trúc lại thành mấy cái talk nhé. Rồi làm goal đó, team mình có thêm Builder-club nữa, đội đó chắc để xem mấy anh em lúc trước làm Super Bit ổn định lại hoặc làm console ổn định lại anh sẽ cấu trúc lại sau nhé. Đợt này chắc là nghỉ ngơi đầy đủ rồi. Rồi ok, anh em có câu hỏi gì cho bài test không kết thúc ở đây nhé. Rồi tạm biệt mấy anh em, hẹn gặp lại tuần sau. Cảm ơn Thành, cảm ơn tất cả mọi người.</p>
<hr>
<p><strong>English Transcript</strong></p>
<p><strong>0:28</strong> The topic still includes Go Weekly, and Nam is currently testing the weekly design commentary. Let's see how it goes over the next few weeks.</p>
<p><strong>11:19</strong> Nam will continue to present to the team, and there are a few topics from Hoang, Cat, and Dat. We’re currently researching various use cases that other companies are applying and some of the tools being used by developers. There will likely be a presentation this week or next about these findings. The focus will be on generating a UX design button. In the past, there have been questions about where AI is applied and how it plays a role, whether it serves as a small, standalone component or as part of a broader application for digital products. Today, I will address how AI contributes and how it functions.</p>
<p><strong>12:11</strong> First, I will talk about system scope relationships. This diagram illustrates how AI is integrated into systems at different levels, from a small component to a comprehensive ecosystem. AI can be a small part of a component or evolve into a larger function, automating features to improve user experience (UX). Here, AI plays a crucial role in digital products, and when integrated, it can fit into various parts—from components to flows, to features, or even as an entire application. It can be part of a platform or ecosystem.</p>
<p><strong>12:53</strong> For example, as a feature within an app, AI can help users interact with the app more easily, saving time by automating tasks that would otherwise be done manually. As a standalone application, there are many examples like ChatGPT, which serves a specific purpose, or as a platform like Rewind AI, which offers multiple features supporting AI in different tasks within the same app. These are examples of the scope of AI's current operations.</p>
<p><strong>13:39</strong> Next, regarding the spatial relationship, this helps us understand how AI features are placed and organized within the user interface (UI). There are several ways to integrate AI into design, and it's important to know how to position them in the app so that they optimize user experience without causing confusion or making the interface too complex. Spatial relationships directly affect user experience. For example, AI can operate independently or alongside other features while still maintaining its own space. When you understand these relationships, you can choose how to place and use AI features in a way that enhances usability without overwhelming the user.</p>
<p><strong>15:11</strong> There are six different methods for presenting AI: it can be entirely separate, alongside other features, layered, integrated with the parent feature, or in small points such as icons. These methods include:</p>
<ul>
<li>Separate: AI operates as a separate feature.</li>
<li>Alongside: AI is placed next to other features.</li>
<li>Layer: AI overlays with another feature.</li>
<li>Integrated Parent: AI serves a major role in navigating and managing core content.</li>
<li>Integrated Child: AI operates as a secondary, smaller feature.</li>
<li>Point: AI is a small icon or widget that helps the user understand its function.</li>
</ul>
<p><strong>16:41</strong> Moving on to the functional relationship, this describes the functional interactions between AI and other features in the system. AI can exist separately but still adapt to the overall content and functionality of the app at a higher level. AI can integrate with existing features to improve performance, replacing manual tasks. Understanding how AI works functionally allows us to define its role clearly in the app and design in a way that ensures the functional actions don’t conflict with one another and don't disrupt the user flow.</p>
<p><strong>17:28</strong> There are six methods to describe this functional relationship, which are similar to the spatial relationships I mentioned earlier:</p>
<ol>
<li>Separate: AI operates independently.</li>
<li>Aware Of: AI exists separately but is aware of how it affects the main feature.</li>
<li>Acting Up: AI interacts back and forth with other features, adapting data between them.</li>
<li>Feature Incorporate: AI is incorporated as a part of an existing feature.</li>
<li>Usage: AI adapts based on how it's used within the app.</li>
<li>Usage Conventionally: AI communicates directly with other features in a two-way interaction.</li>
</ol>
<p>I will provide an example of this functional relationship in the code I am about to show, where AI generates a panel on the right side of the screen.</p>
<p><strong>19:06</strong> For example, the acting-up relationship means AI can be aware of and react to changes made by other features, like data syncing between two systems. In contrast, feature incorporation would mean AI is integrated as part of the overall functionality of a specific feature.</p>
<p><strong>19:57</strong> That covers the main aspects I’ve discussed so far, with three key elements for integrating AI into product design: optimizing product features, improving user functionality, and enhancing the overall effectiveness of the AI-powered system. It’s important to understand how to apply AI properly to provide clear value to the user. If we understand how to apply AI effectively, it becomes easier to design a system that brings value to the user by integrating AI in a meaningful way.</p>
<p><strong>20:53</strong> I realized I missed an example earlier, so let me go back and explain. I’ll share a few examples that I think will clarify the functional relationships we discussed. For instance, in Microsoft, there’s a tool that generates images—this operates alongside other features in a parallel fashion. There’s also a feature that sits beside the main functions of the app but doesn’t serve as a core part of the experience.</p>
<p><strong>22:01</strong> Yes, that's a good example. The functional actions and spatial relationships you presented seem to be similar to common patterns. These are just standard patterns for AI design—how to integrate an AI feature into an app or design an AI-driven app, depending on how it’s categorized.</p>
<p><strong>22:31</strong> Yes, these are patterns we often use when designing AI applications or integrating AI into a separate application or product. Essentially, they are familiar structures to help us better understand how to apply AI. You can categorize and break them down into smaller features. This part is very clear.</p>
<p><strong>23:31</strong> Thank you, Nam. Ok, next will be Hoàng and Đạt’s presentation.</p>
<p>Today, I will introduce a topic called "AI Button in LLM Applications." Before diving in, let me briefly cover the content and agenda. First, we will explore design patterns related to the AI Button. These patterns are applied in various applications. I’ll pick out the most common and understandable ones to introduce to everyone.</p>
<p><strong>24:35</strong> This presentation will revolve around using AI in digital products. These applications leverage the power of AI models to solve specific problems or assist users in tasks. When using LLMs, many may encounter the issue where the model does not provide the expected result. This happens because the model operates based on its ability to respond using the data it has been trained on. There are multiple ways to address this issue. One of the most expensive ways is to retrain the entire model from scratch, which can take a lot of time and resources.</p>
<p><strong>25:15</strong> We have a technique called <strong>in-context learning</strong>, which means AI can learn directly within the current context while you are using it. This technique includes few-shot learning or zero-shot learning, allowing the AI to learn without needing to be retrained from scratch. For example, you only need to provide the AI with a few small examples in the context, and it will adjust its behavior based on what is provided. Instead of retraining the entire model, this method saves a lot of time and resources while still ensuring the AI can learn from the specific context you give it.</p>
<p><strong>25:52</strong> In this case, <strong>in-context learning</strong> is widely used in <strong>prompt engineering</strong>. People provide available examples directly into the prompt, and the model learns from those examples to generate subsequent results. That's the main idea of in-context learning. Essentially, the design works like this: you have a query, then you build a prompt with the necessary examples and few-shot learning data, and you pass it through the model, which returns a result based on those examples. However, it doesn’t stop at just examples; many other factors are involved as well.</p>
<p><strong>26:37</strong> Broadly speaking, in-context learning involves feeding the context into the prompt by providing information that the model doesn’t inherently have. Since this is a pre-trained model, its knowledge is limited, so you provide additional information in the context and prompt for the model to learn during the result generation process. For instance, in medical image diagnosis, the model may not have enough specialized knowledge. Therefore, you provide that expertise into the context and prompt so the model can learn during the result generation process. That’s the core of in-context learning.</p>
<p>Next, we have another important design button, which is <strong>data preprocessing/editing</strong>.</p>
<p><strong>27:54</strong> This section describes the process of preparing data for the language model (LM). As you know, LMs operate based on vector databases, using vector comparisons to find similar data points. This process often involves handling multimedia data and various types of information. To ensure optimal output, applying data preprocessing steps is crucial. For example, you can preprocess text by filtering out unnecessary details to shorten it, or with images and audio, you can remove noise or compress the data to reduce size before passing it through the language model.</p>
<p><strong>29:19</strong> Data preprocessing or editing helps the model operate more efficiently. There are many ways to preprocess, depending on the type of data or context. You perform this based on specific requirements. The next design button I want to mention is a commonly used one, though it goes by different names. I call it the <strong>example agent</strong>. This design is commonly seen when you want your query to pass through multiple contexts. For example, if you have a content review application, you can let that content pass through a pipeline where each agent evaluates the content from a different perspective.</p>
<p><strong>30:11</strong> One agent might evaluate the content from a writer's perspective, and another agent might do so from a different angle. After going through all these agents, there will be a final synthesis layer to combine or process those results, ultimately providing the user with a comprehensive output. This design is often seen in evaluation systems where results from different models are evaluated, and the best outcome is chosen based on predefined conditions.</p>
<p><strong>30:55</strong> The next design button is called <strong>agentic button</strong>. So, what does agentic mean? In the context of language models (LMs), <strong>agentic LMs</strong> refer to enhancing the model's capabilities. Since the model only knows what’s in its training data, we upgrade it to increase its power and minimize human intervention. This design helps the system become more automated, allowing it to operate with less human interference.</p>
<p><strong>32:24</strong> This design has several key components that help you achieve this level of automation. There are four main components: <strong>reflection</strong>, <strong>planning</strong>, <strong>execution</strong>, and <strong>multi-collaboration</strong>. Each of these components helps make your system more automated. First, let’s talk about <strong>reflection</strong>. Reflection involves evaluating the initial results of the model based on a specific criterion or metric to determine if the result has been optimized. If it hasn’t, the system adjusts and repeats the process, continuing to generate results until it reaches an optimal outcome.</p>
<p><strong>33:06</strong> Reflection helps reduce human intervention because, instead of producing an initial result that doesn’t meet your expectations, the system refines itself based on pre-established criteria, eventually delivering a more accurate result without manual adjustment.</p>
<p>The Reflection button means that it will evaluate the initial output of an AI, then assess it according to a certain standard or metric to see if the result has been optimized. If not, it will adjust slightly and run the AI again to generate another result until the optimal result is achieved. This helps reduce the need for human intervention, as if the first output is not what you expected, you don’t need to manually adjust it—the system will optimize itself.</p>
<p><strong>33:42</strong> The second button is the tool. Tools can be external, such as external APIs or functions that people code. These tools are used to allow the model to access knowledge from the outside world, real-time knowledge, or external resources that it hasn’t been pre-trained on. For example, OpenAI or Claude both support this. The model can know when to call the tool based on the description you write for the tool. The model will know how to retrieve and extract information from the tool and then return it to the LM to generate an output.</p>
<p><strong>34:30</strong> Next is planning. The planning button means that you give the LM the ability to plan, preventing the need to prompt multiple times. For example, if you have a complex task, you provide a large prompt for the LM to plan out all the steps it needs to take in a step-by-step manner. This allows it to perform smaller tasks first, which are eventually combined into a larger task. This planning design has many variations, and this is the simplest version: planning and then executing step by step.</p>
<p><strong>35:10</strong> Finally, multi-collaboration. I presented this about a month ago. Essentially, it's like having the AI excel at a particular task. You have a context, right? You divide it and pass it through to different agents. Each agent is good at its specific task, and after they complete their tasks, it passes on to the next agent. In this way, it can complete the requirement. This design heavily utilizes the divide-and-conquer principle—breaking a large task into smaller tasks and assigning each to a specialized agent. This is a design button I’ve seen being used in many places.</p>
<p><strong>36:24</strong> Those are the design buttons that I’ve seen used in many places and understand the most. I’ve finished my presentation. Does anyone have any questions?</p>
<p><strong>37:10</strong> Hoàng, can you repeat the part about planning to confirm Bảo’s comment? It’s like it reads the prompt, right? It understands your prompt first, then breaks it down into smaller tasks, and then there are workers—perhaps IDE workers or smaller prompts—to complete the task. Is that correct?</p>
<p><strong>37:40</strong> Yes, you can think of it that way. You can split the prompt, for example, in a complex task, into several smaller plans. These smaller plans will be done step by step. For instance, it executes plan 1 first, then plan 2, then plan 3. Once all the plans are completed, they are compiled somewhere or in a final component to produce the final answer.</p>
<p><strong>38:06</strong> It’s like the Zero you presented last time, right? The worker can do tasks like reading files, deleting files, modifying files, or interacting with the Internet, sending emails, and so on. So basically, agents work in this way.</p>
<p><strong>38:52</strong> Exactly. Instead of handling a massive task all at once, which requires repeated prompting, you start with a prompt that breaks the task into smaller tasks, and then a pipeline runs through each worker, handling small tasks for you.</p>
<p><strong>39:23</strong> Ok, pull up slide 14, Hoàng. Slide 14. I also see this is kind of like the Mule Automation setup that Tom created, right? The Mule button that Tom set up. I’ve finished the code, but this design and the button look exactly the same.</p>
<p><strong>39:46</strong> Yes, this is a looping process with Tom, which looks somewhat similar. It’s like planning, as Tom mentioned, where it breaks down the task into parts and handles each part. It has iterations within it, like a list of steps you described earlier. Referring back to yours, the agents can see that. What I’m seeing looks more like planning: it splits the plan upfront and then works step by step on each plan, moving through each round one by one. This one, though, works more in parallel, where they run simultaneously, produce the output, evaluate it, and then return the final result. I think I got the workflow mixed up; it’s now corrected.</p>
<p><strong>42:28</strong> Exactly, give it a try. It works like that, breaking down into different tasks. It’s more like a classification, running through each one. This is closer to multi-collaboration because it’s like a question classifier, where only one agent runs for each task. Each agent works on its specific expertise, then combines everything.</p>
<p><strong>43:33</strong> But do you think the parts like reasoning and input analysis are correct? Tom’s expert part. Specifically, for picking domains, there’s a classifier, but reasoning and input analyzers are separate agents. In that group, they’re experts, right? We consider them a group of experts, and they combine with the five agents underneath.</p>
<p><strong>45:33</strong> If we try to do everything within a single prompt, I’m certain it won’t give us the desired result. The context is too large and lacks specific examples. The main issue is that accuracy will definitely decrease because there’s too much data at once. The key is to split it into multiple layers, step by step. In reality, we need the output from the LM; we can’t hardcode it all in advance. We just want the simplest prompt so it can generate small answers that ultimately lead to a large answer.</p>
<p><strong>46:59</strong> Exactly, by breaking it down, we can identify where the problem lies and debug it. Like you mentioned, specify clearly and break it down into layers. If something goes wrong, we can fix that part. If you throw everything in at once, you won’t know where the error is, and you’ll have to fix it repeatedly.</p>
<p><strong>48:43</strong> Exactly. For example, creating an event in the calendar for tomorrow—if there’s no event at that time, it creates the event, but if there is already one, it sends a notification. If we throw in a large request at once, it will get confusing because it has to execute step by step. Breaking it into layers and testing each step will make it work better.</p>
<p><strong>49:23</strong> I'm almost certain that 99% of the time, it will get lost if it’s done in one go. However, if we split it into layers, into multiple layers, and do the tests, it will work much better. Ok, let's go. If anyone's at the office, Tom’s probably there to argue with. If no one has any more questions, thanks to Hoàng first. Now, Đạt, you’re up. Đạt, are you sharing your screen? Ok, can everyone see my screen? Yes, we can.</p>
<p><strong>50:38</strong> Today, I’m going to talk about Yelp use cases. Wait a second, Đạt, let me introduce some context first. So this time, the team will focus somewhere and search for some use cases. There are different types of use cases. The type Đạt is sharing is where we look at how startups or enterprises are applying AI to solve specific problems. It could be something completely new, like a greenfield, or it could be optimizing the current workflow of their system. They will write use cases and report updates monthly. In addition, there’s another type of use case, which involves tuning to boost the development on the tech side. They will also report that part somewhere in tech. We’re testing this for about two weeks. This is the first report, and it’s about Yelp. Yelp is a startup, right? Now, Đạt, introduce how they are applying AI.</p>
<p><strong>52:01</strong> Yelp is a company that provides software to stores and businesses that want to offer services like fast delivery, restaurants, or basic utilities. Yelp sells the software for those tasks. I’ll share a bit about how they use AI in their tools.</p>
<p><strong>53:00</strong> Before this, they had a machine learning system, but now they’ve added AI to improve the accuracy of their recommendations. Yelp has many types of reviews on its system, like restaurant reviews, which may not always be good. Based on those reviews, they do some text editing to compare whether the results are spam or legitimate. AI is used here in several ways. First, they use AI to create datasets to train a model to assess whether a review is spam or a good/bad review. They use AI to generate datasets based on LinkedIn. From what I’ve read, they use techniques like Zero-shot and Few-shot learning to create these datasets. They use some models from Hugging Face and then classify the reviews as good or bad. This is one use case where AI is applied in text editing.</p>
<p><strong>54:18</strong> Now onto the second use case—they use the Clip Model. The Clip Model primarily processes images. What does that mean? It means that based on reviews... wait a minute, let me find the reference... Ah, Clip processes two things: one is the caption of the image, and the other is the image itself. Through Clip, it can understand the context of the image. Yelp uses Clip for tasks such as when someone goes into a restaurant or pub and posts reviews or captures images of the place. For example, before applying Clip, it couldn’t identify if there were waffles in a dish; it could only identify fried chicken. After applying Clip, it can now recognize both fried chicken and waffles. Essentially, it uses Clip as part of AI to process images, captions, and convert images into vectors to compare them. So, these are the two use cases for Yelp.</p>
<p><strong>55:38</strong> These two use cases are applied in situations where you have many reviews, and you can summarize them into a highlight review. Based on the information converted into vectors, it can annotate what the images are conveying, and what they are supporting. Just give it a moment, it will highlight it for you. It understands the context of the image and can annotate it accordingly. This is the use case for how AI is used in image summarization.</p>
<p><strong>56:15</strong> Earlier this year, Yelp released the Yelp Assistant. Based on their existing platform, they were able to create a chatbot that reviews highlights like this. You simply ask, and it recommends something for you. It's as simple as that. Additionally, I noticed a use case from 2020 when the trend of short review clips started becoming popular. Yelp had a dataset specifically for that purpose. They mentioned that they are about to release something, as Tom referred to, that can convert text to speech. Based on the review dataset, they might support creating short video clips to describe a restaurant.</p>
<p><strong>57:45</strong> Based on reviews or videos posted by people, Yelp could generate a script and run it through AI to automatically create a video about a restaurant. That’s the use case. It’s simple as that. Ok, going back to the first question, this use case is essentially using AI to label data, right?</p>
<p><strong>58:35</strong> Ok, so it checks whether the comment is negative or positive, right? That’s one example. The second one is using the Clip Model, correct? It’s similar to Vision but more live, also for labeling, right? Like with Plot, labeling for images. So, these two use cases are applied for what?</p>
<p><strong>59:18</strong> I think there's an interesting point that hasn't been mentioned yet, which is the story about having a ready-made dataset. For instance, when someone leaves a review or gives a rating, based on these short clips, Yelp could generate an intro video for the restaurant. It uses AI for that. I think they use AI to write the script and then pass that script to an AI voice to narrate. But where do they get the images from? How do they get the video content?</p>
<p><strong>59:57</strong> From the review, when someone comes to review, they will have a video to review. Ok, so it's automatically generating an advertisement, right? Yes, for TikTok or similar platforms, summarizing user reviews. Sounds pretty creative. Yeah, I guess you guys have confirmed what Bảo mentioned, right?</p>
<p><strong>01:00:07</strong> Yeah, this one is about the caption, and it's mostly correct. You're right, I think the initial purpose of this use case was for recommendation. Before they had AI, they already had a hybrid recommendation model in place. Basically... I think with this new AI, they will likely replace the old model. One interesting point that wasn't mentioned much is business messaging. I think it’s based on, say, the top 50 reviews or top 50 interactions—how are the ratings, and if the reviews are good and the ratings are good, then the business messaging will also be good. But Yelp didn’t bring up this topic, and we can’t blame them for that.</p>
<p><strong>01:00:51</strong> Does anyone have any questions for Đạt? This is his first presentation. Đạt mentioned he’s working on adding more, probably for enterprise too. But I’ve seen Viettel, FPT, and VNG, and I’m still not sure how they are doing things. Đạt said some of FPT's coding tools are kind of lame.</p>
<p><strong>01:01:41</strong> Haha, is it just a continuation of a previous version? Yeah, it’s not great. It’s a bit rough and underdeveloped. Are we done with that? I guess so. Ok, Đạt. Today we’ve covered Yelp and Tech Linh, so maybe next week or the week after that, if time permits.</p>
<p><strong>01:02:01</strong> Let's do a demo real quick, Đạt. Could you demo something for us? What about a bot that can handle questions or understand short code from a developer’s perspective? Or something like an auditor checking the code quality? Could you demo the workflow or the bot you’re working on with that diff you mentioned? Please turn on the screen, Đạt.</p>
<p><strong>01:03:01</strong> So this is a project I’m working on for joining the AI Club. I’m pretty new at this, so if the project looks rough, please bear with me. The basic workflow is that I take a query and extract the URL of a repository. Here, I reused Tom’s scraper, but it didn’t fully meet my needs, so I created my own local scraper to fetch all the content from the repo. However, that takes too long and generates too much data. As of now, I haven't found a way to add it to the context unless I use knowledge retrieval. But to use knowledge retrieval, I have to prepare it in advance; I can’t select the repo directly.</p>
<p><strong>01:05:45</strong> Tom’s scraper doesn’t capture the content of the files, so I haven’t been able to draw a diagram yet. I might use it for the diagram later, I’ll test it out. This scraper only fetches the content from the root directory and some doc files. Those files might not answer Huy’s question accurately. Let me try it; I have my full setup ready offline. The content is already prepared, not online. This was generated directly, so it doesn’t have it either.</p>
<p><strong>01:07:07</strong> This scraper fetches the full content, so it’s more complete. Let me try asking questions like Huy’s or Hoàng’s. Let’s try BC chat and ask a question there. Do you have it? Ah no. Maybe the context is too large, and I haven’t figured out how to integrate it properly into the knowledge retrieval part.</p>
<p><strong>01:09:19</strong> The retrieval process is very optimized. This text file has tens of thousands of lines, tens of thousands! Let’s open it and see. Are you using a mini machine? Try switching to a more powerful machine to see if it runs better. The mini machine is a bit weak. Two million words... how is it even handling that? I think you’d need a dedicated server to run it efficiently. I’m curious how it's even running; we’re talking about 29U words, as we saw. Multiply that by 4, and the number is huge. The size... Let's follow up and see. Ok, so you’re working directly from the context, right? You’re querying like a typical query vb, rather than feeding all the data into the context.</p>
<p><strong>01:10:57</strong> Right, exactly. I’m not sure how the retrieval in this diffy system works. I don’t know if it’s retrieving the correct data or if it’s retrieving at all. I haven’t been able to trace it, but I have a tracing tool that I can test later to see how it works. But the idea is that if the retrieval works like this, it probably won’t give accurate results. You’re unsure about how much data it's running, right? It seems to only prefer 2-300 items, and that’s not enough data for these kinds of tasks. This requires at least several hundred data points. So yeah, this is still a work in progress.</p>
<p><strong>01:11:35</strong> Just joking—there’s always the AI Club at the company! Oh, so is this the full version, or is it the fixed one? If it’s fixed, demo it for us in the office, and try to leave it for me. OK, let me see. It still hasn’t built, so people are just watching for now. The build seems to have some issues—can everyone see the screen?</p>
<p><strong>01:13:08</strong> So, this week, as I mentioned last week, I will upload the sync.Map article. I think it's really useful, with details that give people using Go a general overview of maps. Regarding sync.Map, let's first go over the context. When writing maps, especially concurrent maps or concurrent operations, before version 1.16, it wouldn’t show any errors, but it wasn’t safe either. From version 1.16 onward, it throws an error like this. So to solve this issue, people usually write maps with a sync package, like using manual sync.RWMutex.</p>
<p><strong>01:13:56</strong> Besides that, there’s another option called sync.Map. Later, I’ll explain why this option exists and what its use case is. This sync.Map was created so that you don’t have to worry much about using mutexes to lock data for synchronization. You just use it. It’s as simple as this, and it’s friendly—just like using a map to check values. For example, when you load a key with a value, if it's available, it returns true; otherwise, it returns false, just like a regular map.</p>
<p><strong>01:14:38</strong> Additionally, it has several handy functions. For example, version 12.23 has <code>clear</code> to clear everything, <code>load</code> to get a value, <code>store</code> to update or store a key, and so on. Besides writing concurrently, when you range (loop) over a map, race conditions can also occur. However, with sync.Map’s range function, it handles that, so you don’t have to worry about it. It doesn’t behave like a typical range function. However, it doesn’t give you a fully consistent snapshot. When you first enter, the snapshot may not be updated. So, during this, you have to change your writing method, but at least it won’t error like this.</p>
<p><strong>01:16:06</strong> Now, let’s go over how it works. When you write and define the map, it’s structured with two maps. At this point, you might be thinking, “Wow, this sounds like it’s heavy on RAM and memory!” There’s a Read-Only map and a Dirty map. From this, you can infer that values, when written, will be updated in the Dirty map. It just keeps updating there, while the Read-Only map.</p>
<p><strong>01:16:46</strong> The Read-Only map will always be used when you're reading. Meanwhile, the writes will always be made to the Dirty map. As for the underlying flow, we’ll look at the chart in a moment to better understand it. Both of these maps have a common point: they both use a pointer called an entry. Pay attention to this part to make the flow easier to follow. For example, when you add a new entry, it will be added to the Dirty map, and both will point to this entry. This works as a flag that indicates the map has been changed. So, at this point, the Read-Only map is no longer the most up-to-date version. The system will know that the Dirty map is the one to read from.</p>
<p><strong>01:17:27</strong> This diagram shows that, for example, when you update a value, since it’s using a pointer underneath, you only need to update the pointer itself, not each value as you would in a traditional map. To achieve this, the system implements a mechanism that defines three states for the entry pointer. The first state is the <strong>normal state</strong>, meaning that the old values in the map are still intact and can be used, without any issues. The second state is <strong>amended</strong>, meaning that the entry has been modified. And the third state is the <strong>delete state</strong>, where an entry has been deleted from the map, but it hasn’t been completely removed. It’s still held in a transitional state, and the entry pointer is moved to a new position, but it hasn’t been fully removed yet.</p>
<p><strong>01:18:59</strong> The pointer <code>entry</code> is assigned to the <code>new entry</code>, but it hasn’t been removed yet. The <code>expired state</code> refers to complete deletion, like a hard delete, meaning the entry is completely removed from the map. To help visualize this, you can refer to this flow: for example, at the beginning, the map has a <code>key1</code> and <code>value1</code>, and at this point, the <code>Dirty map</code> has nothing, meaning nothing has been added or changed yet. Then, if you add a <code>key2</code>, it will be added to the <code>Dirty map</code>, and at this point, the map is marked as <code>amended</code> because a <code>flag</code> indicating <code>amended</code> is set here.</p>
<p><strong>01:19:40</strong> Afterward, when you delete a <code>key</code>, the map will be assigned a <code>new entry</code>, right? The same thing happens on the other side, as it is also assigned a <code>new entry</code>, similar to the previous diagram. In essence, you’re only updating the pointer without having to update the values themselves. Then, after completing the deletion, to promote the <code>Dirty map</code>, you must update it through the <code>Read Only map</code> so that the <code>Dirty map</code> returns to a <code>new state</code>, like resetting it to the original state.</p>
<p><strong>01:20:18</strong> Similarly, when adding a new <code>key3</code>, after the state has returned to the <code>new state</code>, and you add <code>key3</code>, the system identifies that the previous entry has been deleted entirely. This means that next time when it compares with the <code>Dirty map</code>, it knows that the <code>value1</code> has been deleted and no longer exists. At this point, the <code>Read Only map</code> will only contain <code>key2</code> and <code>key3</code>.</p>
<p><strong>01:20:51</strong> Due to this, <code>sync.Map</code> does not have a <code>len</code> function for users to utilize. This is because, if you used the <code>len</code> function here, it would not account for the actual values, as it would count even those that have been expired or deleted. As you can see, because <code>sync.Map</code> is structured this way, its use case is recommended for scenarios that require more reading (<code>read</code>) than writing (<code>write</code>). If you perform a lot of <code>write</code> or <code>delete</code> operations, just imagine the pointer being used continuously, and there’s even an issue reported by the Go team that this map is never garbage collected.</p>
<p><strong>01:21:36</strong> Later, the Go team confirmed that this <code>sync.Map</code> was designed primarily to support some of the internal Go Library processes. If you find it handy because of its user-friendly functions, you can use it, but for use cases that involve storing (<code>store</code>), updating, or deleting often, it’s not recommended, as it may slow down the system.</p>
<p><strong>01:22:24</strong> That’s about it. I’ve written some code based on this topic, and there’s a blogger who shares detailed posts on this subject, so you might want to follow them. Oh, what’s the topic, Phát? Show me the post again. Ah, <code>sync.Map</code>, right? <code>Sync.Map</code>. Does it differ from what you just passed in? What’s different? I think it does. The point is that I remember, depending on the community, people might have different use cases. For instance, if someone wants to implement something specific, they can adapt it as needed.</p>
<p><strong>01:23:30</strong> You can see that some people add an extra layer on top for their own use cases. For example, some want to implement generics on <code>sync.Map</code>. This is partly because of the linking issue I mentioned earlier, where the map isn’t garbage collected. That’s the problem. The Go team has already confirmed that this behavior is intentional, and they won’t fix it. They’re not going to change it, right? So now, what the community does is figure out how to work around it. They like how easy <code>sync.Map</code> is to use, with those nice functions, so they just add another layer to customize it further, making it usable for their specific needs.</p>
<p><strong>01:24:07</strong> Why are we discussing this old clip now? Oh, it’s just an insight for people to use. This use case can be applied to enterprise environments too. For example, in enterprise projects, if we use <code>map</code> and need concurrency, typically, people would write a custom <code>struct</code>, add a <code>mutex</code>, and then write everything themselves. But <code>sync.Map</code> is handy, as I showed earlier, with functions that follow certain standards. If you want to <code>load</code>, you have to call a specific function, and everything is structured that way, making it more reliable.</p>
<p><strong>01:24:50</strong> People usually write a custom <code>struct</code>, then add a <code>mutex</code>, and start writing all the necessary logic themselves. Meanwhile, <code>sync.Map</code> is really handy. As I showed you earlier, it has several functions that adhere to a specific standard. If you want to <code>load</code>, you must call a specific function. This structure ensures consistency. However, you still need to be aware of the trade-offs when using <code>sync.Map</code>, making sure to apply it correctly in the right context. Right, so you have to understand the proper workflow and <code>map</code> usage.</p>
<p><strong>01:25:26</strong> Phát: Yes, about <code>Map</code>. Ok, thanks, Phát. Now, let’s quickly get through a few things. Thành, I need about 10 more minutes from the team. It’ll take a bit more time because I’ve received a total of 11 submissions for the test. Not many have attached images, so some of you can review them. Our deadline is set for the 20th, which is next week. I think earlier, I mentioned the 27th, or was it 26th or 27th? Anyway, that's the deadline. So, please review everything this week and get the submissions ready. This test is important because the market is shifting significantly, and there’s a big change in the demand for software roles.</p>
<p><strong>01:26:15</strong> Of course, the demand is still there, but the volume has decreased. That's why I refer to it as a shift in the market demand, similar to what happened around 2014, where it’s like things are changing all over again. New technology is coming out, new opportunities, new markets, and emerging potentials. So, this test will be essential in helping us assess, especially when it comes to team culture. We’re taking this opportunity to evaluate the team, particularly to see how the research study team and the consulting team are becoming more distinct.</p>
<p><strong>01:27:36</strong> There’s a clear distinction between the two teams now. Like I mentioned in the post on Notion about two weeks ago, this distinction is becoming more pronounced. In the future, there will be more specific policies related to different benefits between these two teams. But for now, as you can see, OGIF is gradually becoming a session where we report on all the studies that the team has been reviewing and reporting back on. Some of those reports might be added later, and you can see that some team members have been picking up new knowledge and sharing it.</p>
<p><strong>01:27:36</strong> Gradually, it's becoming clearer that we want this differentiation to become more distinct over time. And there will be clear policies around this. So, those who enjoy diving deep into topics and taking them to the level of MVP, or applying them in actual projects, or going deeper into knowledge, they will get different benefits. Those who don't necessarily want to focus on study-related topics can continue working on projects as usual, but there will be other issues involved, which I've listed in the Notion link from two weeks ago. Everyone should review that link to understand the direction we're going in. This test is designed to assess how well you can keep up with new knowledge and how aligned you are with the culture during this time of significant changes.</p>
<p><strong>01:29:20</strong> Because of these goals, I’ll be the only one grading this test. None of the other team members will be grading. Everyone has to do it, and I’ve set the standard for this. So, the important thing is that everyone does the test themselves. Even if the quality isn’t the best, it’s fine. I’ll just give it a lower score, but as long as it’s completed, you’ll pass. The immediate outcome I see from this is that I’ll group the results into two clusters.</p>
<p>The Foundation team and the Lab team, they’re still the core teams we’ve had for the past eight or nine years. This is the main announcement. If you’ve finished your test and feel like you can improve based on what I’ve just said, the Foundation team and the Lab team will still be prioritized in various aspects. So, if you feel like you did the test carelessly, please take some time to do it thoroughly. Focus on two things: the culture aspect and the knowledge.</p>
<p><strong>01:29:56</strong> The immediate result you’ll see is that I’ll group the results into two clusters. The Foundation team and the Lab team will remain the core of our team from now until the next eight or nine years. That’s the main announcement. Out of these 11 submissions, if anyone feels they can improve after hearing what I’ve said, please focus on making it better, especially since the Foundation and Lab teams will be prioritized more in different areas. So, if you feel like you’ve done it hastily, take the time to refine it. Check two things: the culture aspect and the latest, hottest topic cluster, which right now is LLM.</p>
<p>But in reality, our team still covers many different areas. We still have people focusing on design, and others still working on Go, right? Blockchain might have moved a bit out of the spotlight, and the market is going sideways, but consulting still demands a lot of expertise in those areas.</p>
<p><strong>01:31:46</strong> Regarding mini apps for Telegram, they quickly clone them, and now the business logic (BL) and tech (TCH) approaches have shifted a bit from the early days. But for consulting, we can still use them as usual, or we can view them from a different angle, where they become a new asset class. As developers, we should look at how these affect our workflow and how we manage assets.</p>
<p><strong>01:32:29</strong> That’s the matter concerning the test. Pay attention to that. Second, as mentioned earlier, regarding team direction and numbers, I mentioned the Notion link I sent earlier. The Foundation team, which started over again, initially had just three people, and then gradually it grew to four, then five. We added Quan, Hiếu, and others. Initially, it was just three of us, but now the team is much stronger. With 40 people, all highly skilled, we’ll certainly move faster. That’s the general overview, so everyone should be aware of the current situation.</p>
<p><strong>01:33:12</strong> Third, Huy Nguyễn, once you’re done, next week please take a look at the ICY numbers. Earlier, you mentioned the numbers were starting to grow, so we’ll need to review and balance those out. For this task, Huy and Thành, please take charge and ensure it’s handled properly. Thành also has an additional task, which is to review benefits for the Lab team members and propose something. It could be considered as a payon, but it won’t go through the normal channels, as there will be a different mechanism for this.</p>
<p><strong>01:33:52</strong> But the Lab team members will have that, and everyone’s familiar with it. Lastly, regarding the LLM, in the current question list, there’s an important question about how to use LLM externally and how to adapt it. Emphasize that question, as it’s about knowledge discovery. The test question is not only about using it but about all the tools our team currently uses. When some people use them effectively and others less so, it creates a very clear spectrum—those who are weaker remain weaker, and those who are stronger stand out much more.</p>
<p><strong>01:34:38</strong> We want to raise the standard. We want to shorten that spectrum, to make it as compact as possible. Right now, the gap is too wide. Beyond using tools for discovery, this question also asks us to look at how our field of work can apply these tools to elevate our competencies and make us more productive. That’s the whole issue, so everyone should confirm whether what they’ve done is correct or not. It has a deeper meaning than it seems.</p>
<p><strong>01:35:20</strong> Lastly, to wrap up today’s session, Thành, for the next OGIF meetings, apart from diving deeper into use cases, there are things Tom has done related to building the structure of an LLM app. We could take that and analyze it. Let’s break it down and dive deeper into it.</p>
<p><strong>01:35:56</strong> Hopefully, everyone passes the test so we can all have a good time. Next week, there will be another test. Next week, Minh L., can you do a demo? Continue with the finite state machine, FSM. As part of our focus on foundational technologies like blockchain and AI, the key point is that engineers will have a different path forward. The goal is to understand how large systems operate. In the future, if you’re not the one handling data manipulation—AI will do that for us, we won’t need to design things ourselves or do junior-level tasks anymore.</p>
<p><strong>01:37:35</strong> The only way to become senior is to understand the issues and work on architecture. The finite state machine plays an important role, especially in scaling, something we’ve talked about a lot. Minh has read through it and understood the direction we’re aiming for. So, we need to do a comparison between the types of general servers it covers. State machine-based servers versus event-based servers. Then create a sample to show how it’s modeled, implemented using Erlang. Erlang already has the frameworks for it.</p>
<p><strong>01:39:01</strong> This topic will proceed when Minh Lưu is ready. If it’s not next week, it could be in two weeks. I suggest that the backend team and the senior team gather together, and if there’s anything, confirm it beforehand. This topic is critical for software analysis and design. It’s a very important session. Up until now, we’ve only talked about modeling and doing C4 diagrams, but Erlang is the language that goes deepest into this area. Most people don’t know it entirely. We don’t necessarily need to learn Erlang, but we can look at how they design and build systems to handle this area properly, as they already have frameworks available. We just need to plug them in and use them.</p>
<p><strong>01:39:37</strong> Speaking of which, October 20th is a Sunday, and Mỹ, Ngọc, and Giang have already posted about it. The ladies are going out on that day, and for those not in Saigon, the team representatives will wish everyone prosperity. It seems like wishing prosperity is the most appropriate thing to say in this situation. Any other wishes might not fit as well. Alright, so if anyone wants to join, register with Mỹ to book a table and plan accordingly.</p>
<p><strong>01:41:19</strong> Thành, in the upcoming meetings, structure things into talks. Then set the goal for that. Our team now has a Builder Club as well. I’ll look into how the team members who used to work on Super Bit and console are stabilizing things, and I’ll restructure afterward. This time, it seems like we’ve had a good rest. Alright, does anyone have any questions about the test? If not, we’ll wrap up here. Alright, goodbye everyone, see you next week. Thanks, Thành, and thanks to everyone.</p>
<hr></div></div></div><section class="bg-background-secondary dark:bg-secondary-background my-8 flex flex-col items-center justify-between gap-4 rounded-lg p-6 xl:flex-row xl:items-center"><div><h6 class="m-0 mb-1.5 text-sm leading-5 font-medium">Subscribe to Dwarves Memo</h6><p class="text-muted-foreground mt-0 text-sm leading-5">Receive the latest updates directly to your inbox.</p></div><form class="mt-5 flex font-[initial] xl:mt-0"><input type="email" class="border-border dark:border-border dark:bg-background focus:border-primary min-w-[160px] flex-1 rounded-l-lg border bg-white px-4 py-3 text-[13px] leading-4 transition-colors duration-200 ease-in-out outline-none placeholder:opacity-70" placeholder="Email Address" required="" value=""/><button type="submit" class="bg-primary hover:bg-primary/90 dark:hover:bg-primary/80 text-primary-foreground inline-flex w-[100px] cursor-pointer items-center justify-center rounded-r-lg border-none px-4 py-3 text-sm text-[13px] leading-4 font-medium transition-all duration-200 ease-in-out disabled:cursor-not-allowed disabled:opacity-70 "><span>Subscribe</span><span class="border-primary-foreground ml-2 h-2 w-2 flex-shrink-0 animate-spin rounded-full border-2 border-t-transparent hidden"></span></button></form></section><div class="relative"></div></div></div></main><div class="toc-space"></div></div></div><footer class="border-t-border bg-background fixed right-0 bottom-0 left-0 z-40 flex h-8 items-stretch overflow-hidden border-t px-3 py-0 text-[0.875rem] leading-[140%] font-normal tracking-[-0.0125rem]"><div class="socials flex items-center gap-x-[10px] pr-3"><a href="https://github.com/dwarvesf" target="_blank" rel="noreferrer" class="aspect-square cursor-pointer"><svg width="18" height="18" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="Plus/Github"><path id="Vector" d="M9 1.5C8.01509 1.5 7.03982 1.69399 6.12987 2.0709C5.21993 2.44781 4.39314 3.00026 3.6967 3.6967C2.29018 5.10322 1.5 7.01088 1.5 9C1.5 12.315 3.6525 15.1275 6.63 16.125C7.005 16.185 7.125 15.9525 7.125 15.75V14.4825C5.0475 14.9325 4.605 13.4775 4.605 13.4775C4.26 12.6075 3.7725 12.375 3.7725 12.375C3.09 11.91 3.825 11.925 3.825 11.925C4.575 11.9775 4.9725 12.6975 4.9725 12.6975C5.625 13.8375 6.7275 13.5 7.155 13.32C7.2225 12.8325 7.4175 12.5025 7.6275 12.315C5.9625 12.1275 4.215 11.4825 4.215 8.625C4.215 7.7925 4.5 7.125 4.9875 6.5925C4.9125 6.405 4.65 5.625 5.0625 4.6125C5.0625 4.6125 5.6925 4.41 7.125 5.3775C7.7175 5.2125 8.3625 5.13 9 5.13C9.6375 5.13 10.2825 5.2125 10.875 5.3775C12.3075 4.41 12.9375 4.6125 12.9375 4.6125C13.35 5.625 13.0875 6.405 13.0125 6.5925C13.5 7.125 13.785 7.7925 13.785 8.625C13.785 11.49 12.03 12.12 10.3575 12.3075C10.6275 12.54 10.875 12.9975 10.875 13.695V15.75C10.875 15.9525 10.995 16.1925 11.3775 16.125C14.355 15.12 16.5 12.315 16.5 9C16.5 8.01509 16.306 7.03982 15.9291 6.12987C15.5522 5.21993 14.9997 4.39314 14.3033 3.6967C13.6069 3.00026 12.7801 2.44781 11.8701 2.0709C10.9602 1.69399 9.98491 1.5 9 1.5Z" fill="#9B9B9B"></path></g></svg></a><a href="https://discord.gg/dwarvesv" target="_blank" rel="noreferrer" class="aspect-square cursor-pointer"><svg width="18" height="18" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="Discord"><path id="Union" d="M14.1919 3.95003C13.2419 3.50716 12.2133 3.18572 11.1418 3C11.1324 2.9997 11.1231 3.00146 11.1144 3.00517C11.1058 3.00887 11.0981 3.01442 11.0918 3.02143C10.9632 3.25715 10.8132 3.5643 10.7132 3.80002C9.57677 3.62859 8.42102 3.62859 7.28456 3.80002C7.18456 3.55716 7.03455 3.25715 6.89884 3.02143C6.89169 3.00715 6.87026 3 6.84883 3C5.77738 3.18572 4.75592 3.50716 3.79875 3.95003C3.79161 3.95003 3.78447 3.95717 3.77732 3.96431C1.83441 6.87154 1.29868 9.70019 1.56298 12.5003C1.56298 12.5145 1.57012 12.5288 1.58441 12.536C2.87015 13.4789 4.1059 14.0503 5.32737 14.4289C5.34879 14.436 5.37022 14.4289 5.37737 14.4146C5.66309 14.0217 5.92024 13.6074 6.14167 13.1717C6.15596 13.1431 6.14167 13.1146 6.1131 13.1074C5.70595 12.9503 5.32022 12.7646 4.94164 12.5503C4.91307 12.536 4.91307 12.4931 4.9345 12.4717C5.01307 12.4145 5.09164 12.3503 5.17022 12.2931C5.1845 12.2788 5.20593 12.2788 5.22022 12.286C7.67743 13.4074 10.3275 13.4074 12.7561 12.286C12.7704 12.2788 12.7919 12.2788 12.8061 12.2931C12.8847 12.3574 12.9633 12.4145 13.0419 12.4788C13.0704 12.5003 13.0704 12.5431 13.0347 12.5574C12.6633 12.7788 12.2704 12.9574 11.8633 13.1146C11.8347 13.1217 11.8275 13.1574 11.8347 13.1789C12.0633 13.6146 12.3204 14.0289 12.599 14.4217C12.6204 14.4289 12.6419 14.436 12.6633 14.4289C13.8919 14.0503 15.1276 13.4789 16.4134 12.536C16.4277 12.5288 16.4348 12.5145 16.4348 12.5003C16.7491 9.26446 15.9134 6.45724 14.2205 3.96431C14.2133 3.95717 14.2062 3.95003 14.1919 3.95003ZM6.51311 10.7931C5.77738 10.7931 5.16307 10.1145 5.16307 9.27875C5.16307 8.44301 5.76309 7.76442 6.51311 7.76442C7.27028 7.76442 7.87029 8.45015 7.86315 9.27875C7.86315 10.1145 7.26313 10.7931 6.51311 10.7931ZM11.4918 10.7931C10.7561 10.7931 10.1418 10.1145 10.1418 9.27875C10.1418 8.44301 10.7418 7.76442 11.4918 7.76442C12.249 7.76442 12.849 8.45015 12.8419 9.27875C12.8419 10.1145 12.249 10.7931 11.4918 10.7931Z" fill="#9B9B9B"></path></g></svg></a><a href="https://www.facebook.com/dwarvesf" target="_blank" rel="noreferrer" class="aspect-square cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24"><path fill="#9b9b9b" d="M22 12c0-5.52-4.48-10-10-10S2 6.48 2 12c0 4.84 3.44 8.87 8 9.8V15H8v-3h2V9.5C10 7.57 11.57 6 13.5 6H16v3h-2c-.55 0-1 .45-1 1v2h3v3h-3v6.95c5.05-.5 9-4.76 9-9.95"></path></svg></a><a href="https://dwarves.foundation/" target="_blank" rel="noreferrer" class="aspect-square cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24"><path fill="#9b9b9b" d="M17.9 17.39c-.26-.8-1.01-1.39-1.9-1.39h-1v-3a1 1 0 0 0-1-1H8v-2h2a1 1 0 0 0 1-1V7h2a2 2 0 0 0 2-2v-.41a7.984 7.984 0 0 1 2.9 12.8M11 19.93c-3.95-.49-7-3.85-7-7.93c0-.62.08-1.22.21-1.79L9 15v1a2 2 0 0 0 2 2m1-16A10 10 0 0 0 2 12a10 10 0 0 0 10 10a10 10 0 0 0 10-10A10 10 0 0 0 12 2"></path></svg></a><a href="mailto:team@dwarves.foundation" target="_blank" rel="noreferrer" class="aspect-square cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 36 36"><path fill="#9b9b9b" d="M32.33 6a2 2 0 0 0-.41 0h-28a2 2 0 0 0-.53.08l14.45 14.39Z" class="clr-i-solid clr-i-solid-path-1"></path><path fill="#9b9b9b" d="m33.81 7.39l-14.56 14.5a2 2 0 0 1-2.82 0L2 7.5a2 2 0 0 0-.07.5v20a2 2 0 0 0 2 2h28a2 2 0 0 0 2-2V8a2 2 0 0 0-.12-.61M5.3 28H3.91v-1.43l7.27-7.21l1.41 1.41Zm26.61 0h-1.4l-7.29-7.23l1.41-1.41l7.27 7.21Z" class="clr-i-solid clr-i-solid-path-2"></path><path fill="none" d="M0 0h36v36H0z"></path></svg></a></div><div class="authors !hidden items-center border-r border-r-[var(--border-color-light)] px-3 text-[#9b9b9b] md:flex dark:border-r-[var(--border-color)]"><span class="text-[var(--secondary-font-color-light-2)]">Dwarves Foundation</span></div><div class="filename !hidden items-center border-r border-r-[var(--border-color-light)] px-3 text-[#9b9b9b] md:flex dark:border-r-[var(--border-color)]"><span class="text-[var(--secondary-font-color-light-2)]">Memo</span></div><div class="last-updated hidden items-center px-3 text-[#9b9b9b]"><span class="text-[var(--secondary-font-color-light-2)]">© 2025</span></div></footer></div><section aria-label="Notifications alt+T" tabindex="-1" aria-live="polite" aria-relevant="additions text" aria-atomic="false"></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"directoryTree":{"/pinned":{"label":"Pinned Notes","children":{"/playbook/operations/ogif":{"label":"OGIF - Oh God It's Friday","children":{}}}},"/":{"label":"Home","children":{"/consulting":{"label":"Consulting","children":{"/consulting/case-study":{"label":"Case Study","children":{"/consulting/case-study/screenz-ai":{"label":"Screenz.ai","children":{}},"/consulting/case-study/kafi":{"label":"Kafi","children":{}},"/consulting/case-study/droppii":{"label":"Droppii","children":{}},"/consulting/case-study/konvoy":{"label":"Konvoy","children":{}},"/consulting/case-study/cimb":{"label":"CIMB","children":{}},"/consulting/case-study/swift":{"label":"Swift","children":{}},"/consulting/case-study/startupvn":{"label":"StartupVN","children":{}},"/consulting/case-study/open-fabric":{"label":"Open Fabric","children":{}},"/consulting/case-study/icrosschain":{"label":"iCrosschain","children":{}},"/consulting/case-study/hedge-foundation":{"label":"Hedge Foundation","children":{}},"/consulting/case-study/searchio":{"label":"Search.io","children":{}},"/consulting/case-study/tokenomy":{"label":"Tokenomy","children":{}},"/consulting/case-study/basehq":{"label":"BaseHQ","children":{}},"/consulting/case-study/momos":{"label":"Momos","children":{}},"/consulting/case-study/attrace":{"label":"Attrace","children":{}},"/consulting/case-study/setel":{"label":"Setel","children":{}},"/consulting/case-study/joinpara":{"label":"JoinPara","children":{}},"/consulting/case-study/relay":{"label":"Relay","children":{}},"/consulting/case-study/naru":{"label":"Naru","children":{}},"/consulting/case-study/mudah":{"label":"Mudah","children":{}},"/consulting/case-study/reapit":{"label":"Reapit","children":{}},"/consulting/case-study/aharooms":{"label":"Aharooms","children":{}},"/consulting/case-study/begroup":{"label":"beGroup","children":{}},"/consulting/case-study/airwatt":{"label":"AirWatt","children":{}},"/consulting/case-study/voconic":{"label":"Voconic","children":{}},"/consulting/case-study/sol":{"label":"Sol","children":{}},"/consulting/case-study/dental-marketplace":{"label":"Dental Marketplace","children":{}},"/consulting/case-study/bhd":{"label":"BHD Cinema","children":{}}}},"/consulting/market-report":{"label":"Market Report","children":{"/consulting/market-report/event-takeaways-2nd":{"label":"2nd Talks and Takeaways","children":{}},"/consulting/market-report/event-takeaways-1st":{"label":"1st Talks and Takeaways","children":{}},"/consulting/market-report/2025-28th-feb":{"label":"#9: Bybit Loses $1.5B in Hack, Claude 3.7 Sonnet Drops, and OpenArt Designs Characters","children":{}},"/consulting/market-report/2025-21th-feb":{"label":"#8: R1 1776 Goes Open-Source, Cardex Gets Hacked, and Grok-3 Debuts","children":{}},"/consulting/market-report/2025-14th-feb":{"label":"#7: 10x AI Cost Reduction, Lyft’s 2026 Robotaxi Milestone, and Solana ETF Buzz","children":{}},"/consulting/market-report/2025-7th-feb":{"label":"#6 Trending Products, DeepSeek Wave, and Ethereum Predictions","children":{}},"/consulting/market-report/2025-17th-jan":{"label":"#5 VC Trends, Blockchain Breakthroughs, and AI Innovations","children":{}},"/consulting/market-report/2025-10th-jan":{"label":"#4 AI Supercomputers, Mini AI PCs, SEA VC","children":{}},"/consulting/market-report/2025-3rd-jan":{"label":"#3 AI at CES, Wall Street Boom, Blockchain Trends","children":{}},"/consulting/market-report/2024-27th-dec":{"label":"#2 AI Talent Wars, OpenAI’s New Models, Hyperliquid","children":{}},"/consulting/market-report/2024-13th-dec":{"label":"#1 Gemini 2.0, OpenAI’s Sora,  a16z’s Predictions","children":{}}}},"/consulting/wala":{"label":"Wala","children":{"/consulting/wala/43-factory":{"label":"43 Factory","children":{}},"/consulting/wala/dzs-media":{"label":"DZS Media","children":{}},"/consulting/wala/sp-group":{"label":"SP Group","children":{}}}},"/consulting/partners-network":{"label":"Partners Network","children":{}},"/consulting/readme":{"label":"Consulting Team","children":{}}}},"/handbook":{"label":"Handbook","children":{"/handbook/navigate-changes":{"label":"Navigate changes","children":{}},"/handbook/community":{"label":"Community","children":{"/handbook/community/icy-worth":{"label":"How much is your ICY worth","children":{}},"/handbook/community/icy-swap":{"label":"How to swap ICY to BTC","children":{}},"/handbook/community/icy":{"label":"ICY","children":{}},"/handbook/community/discord":{"label":"Discord","children":{}},"/handbook/community/earn":{"label":"Earn","children":{}},"/handbook/community/radar":{"label":"Radar","children":{}},"/handbook/community/sharing":{"label":"Sharing knowledge","children":{}},"/handbook/community/showcase":{"label":"Showcase","children":{}},"/handbook/community/memo":{"label":"Memo","children":{}}}},"/handbook/guides":{"label":"Guides","children":{"/handbook/guides/check-in-at-office":{"label":"Office check-in process for earning ICY","children":{}},"/handbook/guides/leave-request":{"label":"Leave request","children":{}},"/handbook/guides/configure-the-company-email":{"label":"Configure your company email","children":{}},"/handbook/guides/one-on-one-meeting":{"label":"1-on-1 meetings","children":{}},"/handbook/guides/continuing-education-allowance":{"label":"Continuing education allowance","children":{}},"/handbook/guides/reimbursement":{"label":"Reimbursement","children":{}},"/handbook/guides/email-communication-and-use":{"label":"Email Communication and Use","children":{}},"/handbook/guides/password-sharing":{"label":"Password Sharing","children":{}},"/handbook/guides/asset-request":{"label":"Assets","children":{}},"/handbook/guides/effective-meeting":{"label":"Effective meetings","children":{}},"/handbook/guides/conduct-a-meeting":{"label":"How to conduct a meeting","children":{}}}},"/handbook/making-a-career":{"label":"Making a career","children":{}},"/handbook/as-a-community":{"label":"As a community","children":{}},"/handbook/knowledge-base":{"label":"Knowledge base","children":{}},"/handbook/stock-option-plan":{"label":"Stock option plan","children":{}},"/handbook/compliance":{"label":"Compliance","children":{}},"/handbook/mma":{"label":"MMA","children":{}},"/handbook/hybrid-working":{"label":"Hybrid Working","children":{}},"/handbook/routine":{"label":"Work routine","children":{}},"/handbook/ventures":{"label":"Ventures arm","children":{}},"/handbook/purpose":{"label":"Purpose","children":{}},"/handbook/benefits-and-perks":{"label":"Benefits \u0026 perks","children":{}},"/handbook/dwarves-foundation-is-you":{"label":"You are Dwarves Foundation","children":{}},"/handbook/getting-started":{"label":"💎 Getting started","children":{}},"/handbook/how-we-hire":{"label":"How we hire","children":{}},"/handbook/how-we-spend-money":{"label":"How we spend money","children":{}},"/handbook/misc":{"label":"Misc","children":{"/handbook/misc/marketing-assets":{"label":"Marketing assets","children":{}}}},"/handbook/moonlighting":{"label":"Moonlighting","children":{}},"/handbook/places-to-work":{"label":"Places to work","children":{}},"/handbook/security-rules":{"label":"Security rules","children":{}},"/handbook/tools-and-systems":{"label":"Tools and systems","children":{}},"/handbook/what-we-stand-for":{"label":"What we stand for","children":{}},"/handbook/what-we-value":{"label":"What we value","children":{}},"/handbook/where-we-work":{"label":"Where we work","children":{}},"/handbook/who-does-what":{"label":"Who does what","children":{}},"/handbook/faq":{"label":"FAQ","children":{}},"/handbook/how-we-work":{"label":"How we work","children":{}}}},"/playground":{"label":"Playground","children":{"/playground/01_literature":{"label":"01_literature","children":{"/playground/01_literature/evolutionary-database-design":{"label":"Evolutionary Database Design: Managing Change and Scaling with the System","children":{}},"/playground/01_literature/design":{"label":"Design","children":{"/playground/01_literature/design/product-design-commentary-20241122":{"label":"Product Design Commentary #7: Hyper-personalization - How AI improves user experience personalization","children":{}},"/playground/01_literature/design/product-design-commentary-20241115":{"label":"Product Design Commentary #6: AI in Design - Cool ideas and how to make them happen","children":{}},"/playground/01_literature/design/product-design-commentary-20241101":{"label":"Product Design Commentary #5: Figma to SwiftUI (functional code) with Claude AI","children":{}},"/playground/01_literature/design/product-design-commentary-20241018":{"label":"Product Design Commentary #4: Generative AI UX design patterns","children":{}},"/playground/01_literature/design/product-design-commentary-20241011":{"label":"Product Design Commentary #3: The art of prompting in AI-human interaction","children":{}},"/playground/01_literature/design/product-design-commentary-20241004":{"label":"Product Design Commentary #2: Unpacking the sparkles icon and AI onboarding challenges","children":{}},"/playground/01_literature/design/product-design-commentary-20240927":{"label":"Product Design Commentary #1: New technologies changing UX/UI and product design","children":{}}}},"/playground/01_literature/giving-a-talk-checklist":{"label":"Giving a talk","children":{}},"/playground/01_literature/database-design-circular":{"label":"Database design Circular","children":{}},"/playground/01_literature/a-lens-to-modern-data-engineering":{"label":"A Lens to Modern Data Engineering","children":{}},"/playground/01_literature/security":{"label":"Security","children":{"/playground/01_literature/security/a-holistic-guide-to-security":{"label":"A Holistic Guide to Security","children":{}},"/playground/01_literature/security/how-i-came-up-with-our-security-standard":{"label":"How I came up with our Security Standard","children":{}}}},"/playground/01_literature/record-reward-sharing-culture":{"label":"Record and reward sharing at Dwarves","children":{}},"/playground/01_literature/designing-for-forgiveness":{"label":"Designing for Forgiveness: Creating Error-Tolerant Interfaces","children":{}},"/playground/01_literature/design-file-sharing-system-part-2-permission-and-password":{"label":"Design file-sharing system - Part 2: Permission \u0026 Password","children":{}},"/playground/01_literature/designing-a-model-with-dynamic-properties":{"label":"Designing a model with dynamic properties","children":{}},"/playground/01_literature/hybrid-search":{"label":"Evaluating search engine in RAG systems","children":{}},"/playground/01_literature/design-file-sharing-system-part-1-directory-structure":{"label":"Design file-sharing system - Part 1: Directory Structure","children":{}},"/playground/01_literature/using-foundry-for-evm-smart-contract-developement":{"label":"Using Foundry for EVM smart contract development","children":{}},"/playground/01_literature/creating-a-fully-local-search-engine-on-memo":{"label":"Building a Local Search Engine for Our Memo Website","children":{}},"/playground/01_literature/observer-pattern":{"label":"Introduce the Observer pattern and its use cases","children":{}},"/playground/01_literature/visitor-design-pattern":{"label":"Visitor design pattern, the concept, problem solution and use cases","children":{}},"/playground/01_literature/strategy-design-pattern":{"label":"Strategy design pattern, the concept, use cases and difference with the state design pattern","children":{}},"/playground/01_literature/vietnam-tech-ecosystem-report":{"label":"Vietnam Tech Ecosystem 2024 Report","children":{}},"/playground/01_literature/how-we-crafted-the-ogif-summarizer-bot-to-streamline-weekly-knowledge-sharing":{"label":"How we crafted the OGIF summarizer bot to streamline weekly knowledge-sharing","children":{}},"/playground/01_literature/feedback-mechanism":{"label":"Design feedback mechanism for LLM applications","children":{}},"/playground/01_literature/local-first-software":{"label":"Local-first Software","children":{}},"/playground/01_literature/error-handling-in-rust":{"label":"Error handling on Rust","children":{}},"/playground/01_literature/engineering":{"label":"Engineering","children":{"/playground/01_literature/engineering/backend":{"label":"Backend","children":{"/playground/01_literature/engineering/backend/bloom-filter":{"label":"Bloom Filter","children":{}},"/playground/01_literature/engineering/backend/introduction-to-crdt":{"label":"Introduction to CRDT","children":{}},"/playground/01_literature/engineering/backend/sql-sargable-queries-and-their-impact-on-database-performance":{"label":"SQL Saragable Queries and Their Impact on Database Performance","children":{}},"/playground/01_literature/engineering/backend/the-removal-of-apache-kafkas-dependency-on-zookeeper":{"label":"The removal of Apache Kafka's dependency on Zookeeper","children":{}},"/playground/01_literature/engineering/backend/sql-and-how-it-relates-to-disk-reads-and-writes":{"label":"SQL and how it relates to Disk Reads and Writes","children":{}}}},"/playground/01_literature/engineering/data":{"label":"Data","children":{"/playground/01_literature/engineering/data/data-pipeline-design-framework":{"label":"Data Pipeline Design Framework","children":{}},"/playground/01_literature/engineering/data/quick-learning-vector-database":{"label":"Quick Learning Vector Database","children":{}},"/playground/01_literature/engineering/data/mapreduce":{"label":"MapReduce","children":{}}}},"/playground/01_literature/engineering/google-data-fusion":{"label":"Google Data Fusion","children":{}},"/playground/01_literature/engineering/google-dataproc":{"label":"Google Dataproc","children":{}},"/playground/01_literature/engineering/introducing-htmx-navigating-the-advantages-and-concerns":{"label":"Introducing HTMX - Navigating the Advantages and Concerns","children":{}},"/playground/01_literature/engineering/typesafe-client-server":{"label":"Typesafe Client Server","children":{}},"/playground/01_literature/engineering/url-redirect-vs-rewrite":{"label":"URL Redirect vs. Rewrite; What’s the difference?","children":{}}}},"/playground/01_literature/template-method-design-pattern":{"label":"A Tour of Template method pattern with Golang","children":{}},"/playground/01_literature/command-pattern":{"label":"Command Pattern","children":{}},"/playground/01_literature/radix-sort":{"label":"Radix Sort","children":{}},"/playground/01_literature/state-pattern":{"label":"State Pattern","children":{}},"/playground/01_literature/dynamic-liquidity-market-a-new-form-of-concentrated-liquidity-amm-on-solana":{"label":"Dynamic Liquidity Market Maker - a new form of concentrated liquidity AMM on Solana","children":{}},"/playground/01_literature/memo-knowledge-base-meeting":{"label":"Memo Knowledge Base Meeting","children":{}},"/playground/01_literature/peep-nft":{"label":"Claim your Peeps NFT","children":{}},"/playground/01_literature/recording-flow":{"label":"How We Set Up a Recording Workflow for Dwarves Office Hours","children":{}},"/playground/01_literature/memo-publication-workflow":{"label":"Memo Publication Workflow","children":{}},"/playground/01_literature/history-of-structured-output-for-llms":{"label":"History of Structured Outputs for LLMs","children":{}},"/playground/01_literature/builder-design-pattern":{"label":"Introduce the Builder pattern and its use cases","children":{}},"/playground/01_literature/how-to-make-a-moc":{"label":"How to make a MOC","children":{}},"/playground/01_literature/prototype-design-pattern":{"label":"Going Through use cases of the prototype design pattern and it place among the creational patterns","children":{}},"/playground/01_literature/singleton-design-pattern":{"label":"A tour of Singleton design pattern with Golang","children":{}},"/playground/01_literature/echelon-x-singapore-2024-where-innovations-meet-inspiration":{"label":"Echelon X Singapore 2024: Where Innovations Meet Inspiration","children":{}},"/playground/01_literature/c4-modelling":{"label":"Breaking Down Complexity: The Role of Abstractions and UML in C4 Modelling","children":{}},"/playground/01_literature/dollar-cost-averaging":{"label":"Dollar Cost Averaging (DCA)","children":{}},"/playground/01_literature/how-i-create-content-for-multiple-platforms-at-dwarves":{"label":"How I Create Content for Multiple Platforms at Dwarves","children":{}},"/playground/01_literature/understanding-saving-investing-and-speculating-key-differences-and-strategies":{"label":"Understanding Saving, Investing, and Speculating: Key Differences and Strategies","children":{}},"/playground/01_literature/writing-content-for-multimedia-guidelines":{"label":"Writing Content for Multimedia Guidelines","children":{}},"/playground/01_literature/how-to-earn-reward-from-staking-dfg":{"label":"How to earn reward from staking DFG","children":{}},"/playground/01_literature/how-to-transfer-dfg-from-eth-to-base-for-staking":{"label":"How to bridge $DFG from Ethereum Mainnet to Base Network for staking","children":{}},"/playground/01_literature/design-less-present-more-with-deckset":{"label":"Design less, present more with Deckset","children":{}},"/playground/01_literature/level-up-your-markdown-memos":{"label":"Level Up Your Markdown Memos: Avoiding Common Pitfalls","children":{}},"/playground/01_literature/tech-canvas":{"label":"Tech Canvas","children":{}},"/playground/01_literature/how-to-recap-a-publication":{"label":"Recapping A publication","children":{}},"/playground/01_literature/lifecycle-of-a-publication":{"label":"Life cycle of a publication","children":{}},"/playground/01_literature/how-to-set-up-environment-for-editing-memo":{"label":"How to set up environment to edit memo","children":{}},"/playground/01_literature/how-to-take-better-screenshots-on-mac":{"label":"How To Take Better Screenshots On Mac","children":{}},"/playground/01_literature/how-to-push-content-on-note-d":{"label":"How to push content on memo.d.foundation","children":{}},"/playground/01_literature/labs-weekly-catchup-5":{"label":"Labs Weekly Catchup #5","children":{}},"/playground/01_literature/labs-weekly-catchup-4":{"label":"Labs Weekly Catchup #4","children":{}},"/playground/01_literature/labs-weekly-catchup-3":{"label":"Labs Weekly Catchup #3","children":{}},"/playground/01_literature/labs-weekly-catchup-2":{"label":"Labs Weekly Catchup #2","children":{}},"/playground/01_literature/labs-weekly-catchup-1":{"label":"Labs Weekly Catchup #1","children":{}},"/playground/01_literature/labs-who-we-are":{"label":"Labs - Who we are","children":{}},"/playground/01_literature/readme":{"label":"Dwarves Memo","children":{}},"/playground/01_literature/duckdb-demo-and-showcase":{"label":"DuckDB demo and showcase","children":{}},"/playground/01_literature/salary-advance":{"label":"$icy Salary Advance","children":{}},"/playground/01_literature/how-rd-contributes-to-performance-review":{"label":"How R\u0026D contributes to Performance Review","children":{}},"/playground/01_literature/knowledge-journey":{"label":"Knowledge Journey","children":{}},"/playground/01_literature/labs-new-member-onboarding":{"label":"Labs - New Member Onboarding","children":{}},"/playground/01_literature/labs-roadmap-nov-23-update":{"label":"Labs Roadmap (Nov 23 update)","children":{}},"/playground/01_literature/labs-topic-proposal-progress-tracking":{"label":"Labs - Topic proposal \u0026 progress tracking","children":{}},"/playground/01_literature/labs-x-consulting-workflow":{"label":"Labs x Consulting Workflow","children":{}},"/playground/01_literature/reward-model-nomination":{"label":"Reward Model \u0026 Nomination","children":{}},"/playground/01_literature/our-view-on-fullstack-engineering":{"label":"Our View On Fullstack Engineering","children":{}},"/playground/01_literature/adoption-of-pnpm":{"label":"Adoption Of Pnpm","children":{}},"/playground/01_literature/working-on-a-project-interview-assessment-at-dwarves":{"label":"Working On A Project Interview Assessment At Dwarves","children":{}},"/playground/01_literature/how-we-created-an-ai-powered-interview-system-using-openais-chatgpt":{"label":"How We Created An Ai Powered Interview System Using Openais Chatgpt","children":{}},"/playground/01_literature/easy-prompt-engineering-for-business-use-and-mitigating-risks-in-llms":{"label":"Easy Prompt Engineering For Business Use And Mitigating Risks In Llms","children":{}},"/playground/01_literature/exploring-machine-learning-approaches-for-fine-tuning-llama-models":{"label":"Exploring Machine Learning Approaches For Fine Tuning Llama Models","children":{}},"/playground/01_literature/managing-dataflow-and-sql-database-with-concurrency-control":{"label":"Managing Dataflow And Sql Database With Concurrency Control","children":{}},"/playground/01_literature/choosing-the-right-javascript-framework-a-deep-dive-into-react-vs-angular-vs-vue":{"label":"Choosing The Right Javascript Framework A Deep Dive Into React Vs Angular Vs Vue","children":{}},"/playground/01_literature/design-system-for-layer-2-using-zk-rollup":{"label":"Design System For Layer 2 Using Zk Rollup","children":{}},"/playground/01_literature/lessons-learned-from-being-a-part-of-corporate-micro-frontend-implementation":{"label":"Lessons Learned From Being A Part Of Corporate Micro Frontend Implementation","children":{}},"/playground/01_literature/cost-of-react-native":{"label":"Cost Of React Native","children":{}},"/playground/01_literature/lessons-learned-from-concurrency-practices-in-blockchain-projects":{"label":"Lessons Learned From Concurrency Practices In Blockchain Projects","children":{}},"/playground/01_literature/database-designs-for-multilingual-apps":{"label":"Database Designs For Multilingual Apps","children":{}},"/playground/01_literature/accelerate-project-initiation-with-advanced-nextjs-boilerplate-react-toolkit":{"label":"Accelerate Project Initiation With Advanced Nextjs Boilerplate React Toolkit","children":{}},"/playground/01_literature/how-blue-green-deployment-helped-mochi":{"label":"How Blue Green Deployment Helped Mochi","children":{}},"/playground/01_literature/i18n-frontend-guideline":{"label":"I18n Frontend Guideline","children":{}},"/playground/01_literature/radio-talk-61-monorepo":{"label":"Radio Talk 61 Monorepo","children":{}},"/playground/01_literature/from-multi-repo-to-monorepo-a-case-study-with-nghenhan-turbo-monorepo":{"label":"From Multi Repo To Monorepo A Case Study With Nghenhan Turbo Monorepo","children":{}},"/playground/01_literature/radio-talk-60-blue-green-deployment":{"label":"Radio Talk 60 Blue Green Deployment","children":{}},"/playground/01_literature/growth-is-our-universal-language":{"label":"Growth Is Our Universal Language","children":{}},"/playground/01_literature/the-key-of-security-mechanisms-in-tackling-cyber-threats":{"label":"The Key Of Security Mechanisms In Tackling Cyber Threats","children":{}},"/playground/01_literature/responsibility":{"label":"Responsibility","children":{}},"/playground/01_literature/configure-the-company-email":{"label":"Configure The Company Email","children":{}},"/playground/01_literature/tech-event-in-the-latest-transforming-healthcare-with-technology":{"label":"Tech Event In The Latest Transforming Healthcare With Technology","children":{}},"/playground/01_literature/from-data-to-backend-an-apprentice-sharing":{"label":"From Data To Backend An Apprentice Sharing","children":{}},"/playground/01_literature/data-analyst-in-retail-trading":{"label":"Data Analyst In Retail Trading","children":{}},"/playground/01_literature/passing-the-probation-get-3-upvotes":{"label":"Passing The Probation Get 3 Upvotes","children":{}},"/playground/01_literature/react-native-new-architecture":{"label":"React Native New Architecture","children":{}},"/playground/01_literature/writing":{"label":"Writing","children":{"/playground/01_literature/writing/state-explain-link":{"label":"State, Explain, Link - An all-purpose writing technique","children":{}}}},"/playground/01_literature/dwarves-radio-talk-17-conduct-a-1-1-session":{"label":"Dwarves Radio Talk 17 Conduct A 1 1 Session","children":{}},"/playground/01_literature/dwarves-radio-talk-16-run-an-effective-performance-review":{"label":"Dwarves Radio Talk 16 Run An Effective Performance Review","children":{}},"/playground/01_literature/understanding-an-application-design":{"label":"Understanding An Application Design","children":{}},"/playground/01_literature/sql-practices-orm-vs-plain-sql":{"label":"Sql Practices Orm Vs Plain Sql","children":{}},"/playground/01_literature/what-i-learned-on-design-thinking-and-software-development":{"label":"What I Learned On Design Thinking And Software Development","children":{}},"/playground/01_literature/six-things-i-extracted-from-design-thinking":{"label":"Six Things I Extracted From Design Thinking","children":{}},"/playground/01_literature/gitflow-pull-request":{"label":"Gitflow Pull Request","children":{}},"/playground/01_literature/git-commit-message-convention":{"label":"Git Commit Message Convention","children":{}},"/playground/01_literature/are-we-really-engineers":{"label":"Are We Really Engineers","children":{}},"/playground/01_literature/how-we-setup-cicd":{"label":"How We Setup Cicd","children":{}},"/playground/01_literature/getting-started-with-webflow":{"label":"Getting Started With Webflow","children":{}},"/playground/01_literature/ui-design-best-practices-dwarves":{"label":"Ui Design Best Practices Dwarves","children":{}},"/playground/01_literature/xpc-services-on-macos-app-using-swift":{"label":"Xpc Services On Macos App Using Swift","children":{}},"/playground/01_literature/the-correct-way-to-build-kpi":{"label":"The Correct Way To Build Kpi","children":{}},"/playground/01_literature/domain-insight-research-framework":{"label":"Domain Insight Research Framework","children":{}},"/playground/01_literature/asking-as-a-junior":{"label":"Asking As A Junior","children":{}},"/playground/01_literature/infinite-image-gallery-with-r3f-an-approach":{"label":"Infinite Image Gallery With R3f An Approach","children":{}},"/playground/01_literature/market":{"label":"Market","children":{"/playground/01_literature/market/an-overview-of-micro-investment-in-real-estate":{"label":"An Overview Of Micro Investment In Real Estate","children":{}}}},"/playground/01_literature/grid-and-layout":{"label":"Grid And Layout","children":{}},"/playground/01_literature/startups-vs-junior-designers":{"label":"Startups Vs Junior Designers","children":{}},"/playground/01_literature/gestalt-principles-in-ui-design":{"label":"Gestalt Principles In Ui Design","children":{}},"/playground/01_literature/aarrr-framework-in-a-nutshell":{"label":"Aarrr Framework In A Nutshell","children":{}},"/playground/01_literature/a-quick-intro-to-webassembly":{"label":"A Quick Intro To Webassembly","children":{}},"/playground/01_literature/sdk-event-sourcing":{"label":"Sdk Event Sourcing","children":{}},"/playground/01_literature/software-development-life-cycle-101":{"label":"Software Development Life Cycle 101","children":{}},"/playground/01_literature/introduce-to-dwarves-memo":{"label":"Introduce To Dwarves Memo","children":{}},"/playground/01_literature/daemons-and-services-programming-guide":{"label":"Daemons And Services Programming Guide","children":{}},"/playground/01_literature/remote-moderated-usability-testing":{"label":"Remote Moderated Usability Testing","children":{}},"/playground/01_literature/an-alternative-to-tm":{"label":"An Alternative To Tm","children":{}},"/playground/01_literature/how-a-design-system-work":{"label":"How A Design System Work","children":{}},"/playground/01_literature/software-modeling":{"label":"Software Modeling","children":{}},"/playground/01_literature/reusability-in-software-development":{"label":"Reusability In Software Development","children":{}},"/playground/01_literature/blockchain-for-designers":{"label":"Blockchain For Designers","children":{}},"/playground/01_literature/design-better-mobile-application":{"label":"Design Better Mobile Application","children":{}},"/playground/01_literature/introduction-to-software-craftsmanship":{"label":"Introduction To Software Craftsmanship","children":{}},"/playground/01_literature/domain-glossary":{"label":"Domain Glossary","children":{}},"/playground/01_literature/architecture-decision-record":{"label":"Architecture Decision Record","children":{}},"/playground/01_literature/build-an-assistant-on-the-terminal":{"label":"Build An Assistant On The Terminal","children":{}},"/playground/01_literature/create-circular-text-using-swiftui":{"label":"Create Circular Text Using Swiftui","children":{}},"/playground/01_literature/draw-watch-face-using-swiftui":{"label":"Draw Watch Face Using Swiftui","children":{}},"/playground/01_literature/applied-security-basis":{"label":"Applied Security Basis","children":{}},"/playground/01_literature/swiftui":{"label":"Swiftui","children":{}},"/playground/01_literature/bunk-license-check":{"label":"Bunk License Check","children":{}},"/playground/01_literature/well-crafted-software":{"label":"Well Crafted Software","children":{}},"/playground/01_literature/objective":{"label":"Objective","children":{}},"/playground/01_literature/project-management":{"label":"Project Management","children":{}},"/playground/01_literature/kubernetes-helm-101":{"label":"Kubernetes Helm 101","children":{}},"/playground/01_literature/what-is-kubernetes":{"label":"What Is Kubernetes","children":{}},"/playground/01_literature/traits-to-assess-during-an-interview":{"label":"Traits To Assess During An Interview","children":{}},"/playground/01_literature/recursively-export-file-pattern-in-javascript-es6-application":{"label":"Recursively Export File Pattern In Javascript Es6 Application","children":{}},"/playground/01_literature/playaround-with-clojure":{"label":"Playaround With Clojure","children":{}},"/playground/01_literature/playaround-with-rust":{"label":"Playaround With Rust","children":{}},"/playground/01_literature/overview-on-broker-pattern-in-distributed-system":{"label":"Overview On Broker Pattern In Distributed System","children":{}},"/playground/01_literature/fundamental-end-to-end-frontend-testing-with-cypress":{"label":"Fundamental End To End Frontend Testing With Cypress","children":{}},"/playground/01_literature/uidynamicanimator":{"label":"Uidynamicanimator","children":{}},"/playground/01_literature/reproduce-apple-find-me-bottom-menu-view":{"label":"Reproduce Apple Find Me Bottom Menu View","children":{}},"/playground/01_literature/build-a-passcode-view-with-swift":{"label":"Build A Passcode View With Swift","children":{}},"/playground/01_literature/istio":{"label":"Istio","children":{}},"/playground/01_literature/different-ways-to-test-react-application":{"label":"Different Ways To Test React Application","children":{}},"/playground/01_literature/federated-byzantine":{"label":"Federated Byzantine","children":{}},"/playground/01_literature/fabric-hyperledger-architecture-explanation":{"label":"Fabric Hyperledger Architecture Explanation","children":{}},"/playground/01_literature/setup-react-project-with-webpack-and-babel":{"label":"Setup React Project With Webpack And Babel","children":{}},"/playground/01_literature/split-and-reuse-code-in-react-application":{"label":"Split And Reuse Code In React Application","children":{}},"/playground/01_literature/hoc-renderprops-and-hook-in-reactjs":{"label":"Hoc Renderprops And Hook In Reactjs","children":{}},"/playground/01_literature/resource-assignment":{"label":"Resource Assignment","children":{}},"/playground/01_literature/the-principle-of-spacing-in-ui-design-part-2":{"label":"The Principle Of Spacing In Ui Design Part 2","children":{}},"/playground/01_literature/finite-state-machine":{"label":"Finite State Machine","children":{}},"/playground/01_literature/card-sorting-and-a-glimpse-at-experimental-sorting-session":{"label":"Card Sorting And A Glimpse At Experimental Sorting Session","children":{}},"/playground/01_literature/about-devops":{"label":"About Devops","children":{}},"/playground/01_literature/our-daily-standup-format":{"label":"Our Daily Standup Format","children":{}},"/playground/01_literature/good-design-understanding":{"label":"Good Design Understanding","children":{}},"/playground/01_literature/competency-mapping":{"label":"Competency Mapping","children":{}},"/playground/01_literature/design-resourcestools":{"label":"Design Resourcestools","children":{}},"/playground/01_literature/design-tips-tricks":{"label":"Design Tips Tricks","children":{}},"/playground/01_literature/design-system":{"label":"Design System","children":{}},"/playground/01_literature/design-workflow":{"label":"Design Workflow","children":{}},"/playground/01_literature/three-levels-of-design":{"label":"Three Levels Of Design","children":{}},"/playground/01_literature/ui-design-fundamental":{"label":"Ui Design Fundamental","children":{}},"/playground/01_literature/ux-model":{"label":"Ux Model","children":{}},"/playground/01_literature/the-principle-of-spacing-in-ui-design-part-1":{"label":"The Principle Of Spacing In Ui Design Part 1","children":{}},"/playground/01_literature/be-careful-with-your-code-splitting-setup":{"label":"Be Careful With Your Code Splitting Setup","children":{}},"/playground/01_literature/qc-onboarding":{"label":"Qc Onboarding","children":{}},"/playground/01_literature/dcos-series-part-5-gitlab":{"label":"Dcos Series Part 5 Gitlab","children":{}},"/playground/01_literature/dcos-series-part-4-deploy-simple-application-with-backend-database":{"label":"Dcos Series Part 4 Deploy Simple Application With Backend Database","children":{}},"/playground/01_literature/dcos-series-part-3-service-discovery-and-load-balancing":{"label":"Dcos Series Part 3 Service Discovery And Load Balancing","children":{}},"/playground/01_literature/dcos-series-part-2-deploy-simple-applications":{"label":"Dcos Series Part 2 Deploy Simple Applications","children":{}},"/playground/01_literature/dcos-series-part-1-quick-look-installation":{"label":"Dcos Series Part 1 Quick Look Installation","children":{}},"/playground/01_literature/skill-of-software-engineer":{"label":"Skill Of Software Engineer","children":{}},"/playground/01_literature/docker-registry":{"label":"Docker Registry","children":{}},"/playground/01_literature/agile-using-clickup-as-agile-management-tool":{"label":"Agile Using Clickup As Agile Management Tool","children":{}},"/playground/01_literature/agile-how-to-create-clickup-tickets":{"label":"Agile How To Create Clickup Tickets","children":{}},"/playground/01_literature/considering-factors-for-performance-evaluating":{"label":"Considering Factors For Performance Evaluating","children":{}},"/playground/01_literature/how-we-contribute-to-homebrew":{"label":"How We Contribute To Homebrew","children":{}},"/playground/01_literature/the-10x-engineer":{"label":"The 10x Engineer","children":{}},"/playground/01_literature/definition-of-done":{"label":"Definition Of Done","children":{}},"/playground/01_literature/estimation-in-agile":{"label":"Estimation In Agile","children":{}},"/playground/01_literature/sprint-lifecycle":{"label":"Sprint Lifecycle","children":{}},"/playground/01_literature/remote-prepare-and-get-going":{"label":"Remote Prepare And Get Going","children":{}},"/playground/01_literature/docker-microcontainers":{"label":"Docker Microcontainers","children":{}}}},"/playground/00_fleeting":{"label":"00_fleeting","children":{"/playground/00_fleeting/automata":{"label":"Automata","children":{}},"/playground/00_fleeting/error-handling-patterns":{"label":"Error Handling Patterns","children":{}},"/playground/00_fleeting/founder-liquidity":{"label":"Founder Liquidity","children":{}},"/playground/00_fleeting/why-hollywood-and-gaming-struggle-with-ai":{"label":"Why Hollywood and gaming struggle with AI","children":{}},"/playground/00_fleeting/subscription-pricing-models":{"label":"Subscription Pricing Models","children":{}},"/playground/00_fleeting/erlang-fsm":{"label":"Erlang Finite State Machine","children":{}},"/playground/00_fleeting/rust-trait":{"label":"Rust Trait","children":{}},"/playground/00_fleeting/explaining-gradient-descent-in-machine-learning-with-a-simple-analogy":{"label":"Explaining Gradient Descent in Machine Learning with a simple analogy","children":{}},"/playground/00_fleeting/organize-team-know-how-with-zettelkasten-method":{"label":"Organize team know-how with Zettelkasten Method","children":{}},"/playground/00_fleeting/how-to-talk-to-chatgpt-effectively":{"label":"How to talk to ChatGPT effectively","children":{}},"/playground/00_fleeting/202302281019-case-study-write-heavy-scalable-and-reliable-inventory-platform":{"label":"Case study: Write-heavy scalable and reliable inventory platform","children":{}},"/playground/00_fleeting/202301191192-multi-column-index-in-db":{"label":"Multi-column index in DB","children":{}},"/playground/00_fleeting/202301091379-invoking-component-functions-in-react":{"label":"Invoking component functions in React","children":{}},"/playground/00_fleeting/202212131609-how-to-deal-with-technical-debt-in-scrum":{"label":"How to deal with technical debt in Scrum","children":{}},"/playground/00_fleeting/202211141287-go-json-parsing":{"label":"Go JSON parser: number \u003c-\u003e interface","children":{}},"/playground/00_fleeting/202211141513-materialized-view-pattern":{"label":"Materialized View Pattern","children":{}},"/playground/00_fleeting/202211081111-error-messaging":{"label":"Error Messaging","children":{}},"/playground/00_fleeting/202210172128-sign-in-form-best-practices":{"label":"Sign-in Form Best Practices","children":{}},"/playground/00_fleeting/202210162154-the-best-of-css-tldr":{"label":"The Best of CSS TLDR","children":{}},"/playground/00_fleeting/202210150019-migration-planning":{"label":"Migration Planning","children":{}},"/playground/00_fleeting/202210131000-behavior-driven-development":{"label":"Behavior Driven Development","children":{}},"/playground/00_fleeting/202210131516-react-fiber":{"label":"React Fiber","children":{}},"/playground/00_fleeting/202210122014-forward-proxy":{"label":"Forward Proxy","children":{}}}},"/playground/_radar":{"label":"_radar","children":{"/playground/_radar/readme":{"label":"Tech Radar","children":{}},"/playground/_radar/apache-spark":{"label":"Apache Spark","children":{}},"/playground/_radar/ant-design":{"label":"Ant Design","children":{}},"/playground/_radar/apache-kafka":{"label":"Apache Kafka","children":{}},"/playground/_radar/argocd":{"label":"Argocd","children":{}},"/playground/_radar/astro":{"label":"Astro","children":{}},"/playground/_radar/backstage":{"label":"Backstage","children":{}},"/playground/_radar/blue-green-deployment":{"label":"Blue Green Deployment","children":{}},"/playground/_radar/browserstack":{"label":"Browserstack","children":{}},"/playground/_radar/carbon":{"label":"Carbon","children":{}},"/playground/_radar/chatgpt-assistance":{"label":"Chatgpt Assistance","children":{}},"/playground/_radar/chromatic":{"label":"Chromatic","children":{}},"/playground/_radar/clickhouse":{"label":"Clickhouse","children":{}},"/playground/_radar/cloudflare-workers":{"label":"Cloudflare Workers","children":{}},"/playground/_radar/codecept":{"label":"Codecept","children":{}},"/playground/_radar/commitlint":{"label":"Commitlint","children":{}},"/playground/_radar/copilot":{"label":"Copilot","children":{}},"/playground/_radar/cucumber":{"label":"Cucumber","children":{}},"/playground/_radar/cypress":{"label":"Cypress","children":{}},"/playground/_radar/dapr":{"label":"Dapr","children":{}},"/playground/_radar/deno":{"label":"Deno","children":{}},"/playground/_radar/detox":{"label":"Detox","children":{}},"/playground/_radar/devcontainers":{"label":"Devcontainers","children":{}},"/playground/_radar/devpod":{"label":"Devpod","children":{}},"/playground/_radar/dora-metrics":{"label":"Dora Metrics","children":{}},"/playground/_radar/duckdb":{"label":"Duckdb","children":{}},"/playground/_radar/earthly":{"label":"Earthly","children":{}},"/playground/_radar/elixir-umbrella-project":{"label":"Elixir Umbrella Project","children":{}},"/playground/_radar/elixir":{"label":"Elixir","children":{}},"/playground/_radar/erlang":{"label":"Erlang","children":{}},"/playground/_radar/error-logging-convention":{"label":"Error Logging Convention","children":{}},"/playground/_radar/eslint":{"label":"Eslint","children":{}},"/playground/_radar/event-sourcing":{"label":"Event Sourcing","children":{}},"/playground/_radar/excalidraw":{"label":"Excalidraw","children":{}},"/playground/_radar/expo":{"label":"Expo","children":{}},"/playground/_radar/figma":{"label":"Figma","children":{}},"/playground/_radar/formal-verification":{"label":"Formal Verification","children":{}},"/playground/_radar/fullstack-tracing":{"label":"Fullstack Tracing","children":{}},"/playground/_radar/gestalt-principle":{"label":"Gestalt Principle","children":{}},"/playground/_radar/github-actions":{"label":"Github Actions","children":{}},"/playground/_radar/golang":{"label":"Golang","children":{}},"/playground/_radar/grafana":{"label":"Grafana","children":{}},"/playground/_radar/graylog":{"label":"Graylog","children":{}},"/playground/_radar/headless-ui":{"label":"Headless Ui","children":{}},"/playground/_radar/hoppscotch":{"label":"Hoppscotch","children":{}},"/playground/_radar/ipfs":{"label":"Ipfs","children":{}},"/playground/_radar/jotai":{"label":"Jotai","children":{}},"/playground/_radar/k6":{"label":"K6","children":{}},"/playground/_radar/k9s":{"label":"K9s","children":{}},"/playground/_radar/kaniko":{"label":"Kaniko","children":{}},"/playground/_radar/kotlin":{"label":"Kotlin","children":{}},"/playground/_radar/kubeseal-sops":{"label":"Kubeseal Sops","children":{}},"/playground/_radar/ladle":{"label":"Ladle","children":{}},"/playground/_radar/langchain":{"label":"Langchain","children":{}},"/playground/_radar/large-language-model-llm":{"label":"Large Language Model Llm","children":{}},"/playground/_radar/loki":{"label":"Loki","children":{}},"/playground/_radar/makefile":{"label":"Makefile","children":{}},"/playground/_radar/micro-frontend":{"label":"Micro Frontend","children":{}},"/playground/_radar/monorepo":{"label":"Monorepo","children":{}},"/playground/_radar/msw":{"label":"Msw","children":{}},"/playground/_radar/n6n":{"label":"N6n","children":{}},"/playground/_radar/nestjs":{"label":"Nestjs","children":{}},"/playground/_radar/netlify":{"label":"Netlify","children":{}},"/playground/_radar/newrelic":{"label":"Newrelic","children":{}},"/playground/_radar/nextjs":{"label":"Nextjs","children":{}},"/playground/_radar/nodejs":{"label":"Nodejs","children":{}},"/playground/_radar/nostrum":{"label":"Nostrum","children":{}},"/playground/_radar/nx":{"label":"Nx","children":{}},"/playground/_radar/orval":{"label":"Orval","children":{}},"/playground/_radar/page-object-model":{"label":"Page Object Model","children":{}},"/playground/_radar/partytown":{"label":"Partytown","children":{}},"/playground/_radar/phaser":{"label":"Phaser","children":{}},"/playground/_radar/phoenix":{"label":"Phoenix","children":{}},"/playground/_radar/playwright":{"label":"Playwright","children":{}},"/playground/_radar/pnpm":{"label":"Pnpm","children":{}},"/playground/_radar/progressive-delivery":{"label":"Progressive Delivery","children":{}},"/playground/_radar/prometheus":{"label":"Prometheus","children":{}},"/playground/_radar/prompt-engineering":{"label":"Prompt Engineering","children":{}},"/playground/_radar/qwik":{"label":"Qwik","children":{}},"/playground/_radar/radix-ui":{"label":"Radix Ui","children":{}},"/playground/_radar/react-hook-form":{"label":"React Hook Form","children":{}},"/playground/_radar/react-llm":{"label":"React Llm","children":{}},"/playground/_radar/react-native":{"label":"React Native","children":{}},"/playground/_radar/react-query":{"label":"React Query","children":{}},"/playground/_radar/react-server-component":{"label":"React Server Component","children":{}},"/playground/_radar/react-testing-library":{"label":"React Testing Library","children":{}},"/playground/_radar/react":{"label":"React","children":{}},"/playground/_radar/reinforcement-learning-from-human-feedback":{"label":"Reinforcement Learning From Human Feedback","children":{}},"/playground/_radar/remix":{"label":"Remix","children":{}},"/playground/_radar/replayio":{"label":"Replayio","children":{}},"/playground/_radar/reverse-engineering":{"label":"Reverse Engineering","children":{}},"/playground/_radar/rust":{"label":"Rust","children":{}},"/playground/_radar/selenium":{"label":"Selenium","children":{}},"/playground/_radar/semantic-release-auto-release":{"label":"Semantic Release Auto Release","children":{}},"/playground/_radar/sentry":{"label":"Sentry","children":{}},"/playground/_radar/serverlessq":{"label":"Serverlessq","children":{}},"/playground/_radar/solidity":{"label":"Solidity","children":{}},"/playground/_radar/solidjs":{"label":"Solidjs","children":{}},"/playground/_radar/stern":{"label":"Stern","children":{}},"/playground/_radar/svelte":{"label":"Svelte","children":{}},"/playground/_radar/swagger":{"label":"Swagger","children":{}},"/playground/_radar/swift-ui":{"label":"Swift Ui","children":{}},"/playground/_radar/swift":{"label":"Swift","children":{}},"/playground/_radar/swr":{"label":"Swr","children":{}},"/playground/_radar/tailwindcss":{"label":"Tailwindcss","children":{}},"/playground/_radar/tauri":{"label":"Tauri","children":{}},"/playground/_radar/team-topologies":{"label":"Team Topologies","children":{}},"/playground/_radar/timeline":{"label":"Timeline","children":{"/playground/_radar/timeline/create-working-devcontainer-for-nextjs-boilerplate":{"label":"Create Working Devcontainer For Nextjs Boilerplate","children":{}},"/playground/_radar/timeline/open-source-devpod-paperspace-provider":{"label":"Open Source Devpod Paperspace Provider","children":{}},"/playground/_radar/timeline/create-working-devcontainer-for-go-api":{"label":"Create Working Devcontainer For Go Api","children":{}},"/playground/_radar/timeline/fe-23-training-type-safe-client-server":{"label":"Fe 23 Training Type Safe Client Server","children":{}},"/playground/_radar/timeline/first-introduced-use-of-duckdb-in-consolelabs-logconsoleso":{"label":"First Introduced Use Of Duckdb In Consolelabs Logconsoleso","children":{}},"/playground/_radar/timeline/add-type-safe-client-server-support-for-next-boilerplate":{"label":"Add Type Safe Client Server Support For Next Boilerplate","children":{}},"/playground/_radar/timeline/building-reliable-apps-sentry-and-distributed-tracing-for-effective-monitoring":{"label":"Building Reliable Apps Sentry And Distributed Tracing For Effective Monitoring","children":{}},"/playground/_radar/timeline/an-engineering-story-map-for-llms":{"label":"An Engineering Story Map For Llms","children":{}},"/playground/_radar/timeline/exploring-resumable-server-side-rendering-with-qwik":{"label":"Exploring Resumable Server Side Rendering With Qwik","children":{}},"/playground/_radar/timeline/challenge-faced-when-researching-rlhf-with-open-assistant":{"label":"Challenge Faced When Researching Rlhf With Open Assistant","children":{}},"/playground/_radar/timeline/embracing-go-1210s-slog-a-unified-logging-interface-with-benchmarks-against-zerolog-and-zap":{"label":"Embracing Go 1210s Slog A Unified Logging Interface With Benchmarks Against Zerolog And Zap","children":{}},"/playground/_radar/timeline/adoption-of-pnpm":{"label":"Adoption Of Pnpm","children":{}},"/playground/_radar/timeline/diagnosing-and-resolving-performance-issues-with-pprof-and-trace-in-go":{"label":"Diagnosing And Resolving Performance Issues With Pprof And Trace In Go","children":{}},"/playground/_radar/timeline/migrate-yarn-to-pnpm-in-fortress":{"label":"Migrate Yarn To Pnpm In Fortress","children":{}},"/playground/_radar/timeline/level-up-your-testing-game-harnessing-gomock-for-unbeatable-unit-testing-in-go":{"label":"Level Up Your Testing Game Harnessing Gomock For Unbeatable Unit Testing In Go","children":{}},"/playground/_radar/timeline/migrate-yarn-to-pnpm-in-nghe-nhan-droppii":{"label":"Migrate Yarn To Pnpm In Nghe Nhan Droppii","children":{}},"/playground/_radar/timeline/common-design-patterns-in-golang-part-1":{"label":"Common Design Patterns In Golang Part 1","children":{}},"/playground/_radar/timeline/go-training-2023-from-basic-to-advanced":{"label":"Go Training 2023 From Basic To Advanced","children":{}},"/playground/_radar/timeline/llms-accuracy-self-refinement":{"label":"Llms Accuracy Self Refinement","children":{}},"/playground/_radar/timeline/adversarial-prompting":{"label":"Adversarial Prompting","children":{}},"/playground/_radar/timeline/chunking-strategies-to-overcome-context-limitation-in-llm":{"label":"Chunking Strategies To Overcome Context Limitation In Llm","children":{}},"/playground/_radar/timeline/dealing-with-long-term-memory-of-chatbot":{"label":"Dealing With Long Term Memory Of Chatbot","children":{}},"/playground/_radar/timeline/error-handling-and-failure-management-in-a-go-system":{"label":"Error Handling And Failure Management In A Go System","children":{}},"/playground/_radar/timeline/migrate-yarn-to-pnpm-in-nextjs-boilerplate":{"label":"Migrate Yarn To Pnpm In Nextjs Boilerplate","children":{}},"/playground/_radar/timeline/lessons-learned-building-an-llm-chatbot-a-case-study":{"label":"Lessons Learned Building An Llm Chatbot A Case Study","children":{}},"/playground/_radar/timeline/foundation-model":{"label":"Foundation Model","children":{}},"/playground/_radar/timeline/integrate-zod-to-nextjs-boilerplate":{"label":"Integrate Zod To Nextjs Boilerplate","children":{}},"/playground/_radar/timeline/llm-query-caching":{"label":"Llm Query Caching","children":{}},"/playground/_radar/timeline/build-your-chatbot-with-open-source-large-language-models":{"label":"Build Your Chatbot With Open Source Large Language Models","children":{}},"/playground/_radar/timeline/integrate-playwright-x-codecept-with-discord":{"label":"Integrate Playwright X Codecept With Discord","children":{}},"/playground/_radar/timeline/overcoming-distributed-system-challenges-using-golang":{"label":"Overcoming Distributed System Challenges Using Golang","children":{}},"/playground/_radar/timeline/easy-prompt-engineering-for-business-use-and-mitigating-risks-in-llms":{"label":"Easy Prompt Engineering For Business Use And Mitigating Risks In Llms","children":{}},"/playground/_radar/timeline/migrate-headlessui-to-radixui":{"label":"Migrate Headlessui To Radixui","children":{}},"/playground/_radar/timeline/llm-101-enhance-developer-productivity":{"label":"Llm 101 Enhance Developer Productivity","children":{}},"/playground/_radar/timeline/approaches-to-manage-concurrent-workloads-like-worker-pools-and-pipelines":{"label":"Approaches To Manage Concurrent Workloads Like Worker Pools And Pipelines","children":{}},"/playground/_radar/timeline/lessons-learned-from-being-a-part-of-corporate-microfrontend-implementation":{"label":"Lessons Learned From Being A Part Of Corporate Microfrontend Implementation","children":{}},"/playground/_radar/timeline/migrate-yarn-to-pnpm-in-react-toolkit":{"label":"Migrate Yarn To Pnpm In React Toolkit","children":{}},"/playground/_radar/timeline/lessons-learned-from-concurrency-practices-in-blockchain-projects":{"label":"Lessons Learned From Concurrency Practices In Blockchain Projects","children":{}},"/playground/_radar/timeline/applying-mock-service-worker-msw-for-seamless-web-development":{"label":"Applying Mock Service Worker Msw For Seamless Web Development","children":{}},"/playground/_radar/timeline/integrate-playwright-to-run-e2e-test-with-fortress":{"label":"Integrate Playwright To Run E2e Test With Fortress","children":{}},"/playground/_radar/timeline/from-multi-repo-to-monorepo-a-case-study-with-nghenhan":{"label":"From Multi Repo To Monorepo A Case Study With Nghenhan","children":{}},"/playground/_radar/timeline/case-study-how-blue-green-deployment-help-mochi":{"label":"Case Study How Blue Green Deployment Help Mochi","children":{}},"/playground/_radar/timeline/develop-codecept-to-integrate-with-fortress":{"label":"Develop Codecept To Integrate With Fortress","children":{}},"/playground/_radar/timeline/case-study-from-multiple-repo-to-monorepo-at-nghe-nhan":{"label":"Case Study From Multiple Repo To Monorepo At Nghe Nhan","children":{}},"/playground/_radar/timeline/apply-blue-green-deployment-to-mochi":{"label":"Apply Blue Green Deployment To Mochi","children":{}},"/playground/_radar/timeline/memo-blue-green-deployment":{"label":"Memo Blue Green Deployment","children":{}},"/playground/_radar/timeline/brainery-blue-green-deployment":{"label":"Brainery Blue Green Deployment","children":{}},"/playground/_radar/timeline/brainery-validation-with-zod":{"label":"Brainery Validation With Zod","children":{}},"/playground/_radar/timeline/brainery-progressive-delivery":{"label":"Brainery Progressive Delivery","children":{}},"/playground/_radar/timeline/memo-react-native-new-architecture":{"label":"Memo React Native New Architecture","children":{}},"/playground/_radar/timeline/backend-for-call-requests-to-binance-and-get-data-from-multiple-platforms":{"label":"Backend For Call Requests To Binance And Get Data From Multiple Platforms","children":{}},"/playground/_radar/timeline/create-backend-monorepo-to-share-code-and-manage-multiple-services-in-one-repo":{"label":"Create Backend Monorepo To Share Code And Manage Multiple Services In One Repo","children":{}},"/playground/_radar/timeline/nextjs-boilerplate":{"label":"Nextjs Boilerplate","children":{}},"/playground/_radar/timeline/apply-page-object-model-structure-to-wego":{"label":"Apply Page Object Model Structure To Wego","children":{}},"/playground/_radar/timeline/apply-page-object-model-structure-to-aharooms":{"label":"Apply Page Object Model Structure To Aharooms","children":{}},"/playground/_radar/timeline/apply-page-object-model-structure-to-artzy":{"label":"Apply Page Object Model Structure To Artzy","children":{}},"/playground/_radar/timeline/apply-page-object-model-structure-to-sci":{"label":"Apply Page Object Model Structure To Sci","children":{}},"/playground/_radar/timeline/build-automation-for-sci":{"label":"Build Automation For Sci","children":{}},"/playground/_radar/timeline/apply-page-object-model-structure-to-basehq":{"label":"Apply Page Object Model Structure To Basehq","children":{}},"/playground/_radar/timeline/mdx-document-for":{"label":"Mdx Document For","children":{}},"/playground/_radar/timeline/develop":{"label":"Develop","children":{}},"/playground/_radar/timeline/apply-monorepos-to-repit-to-resolve-the-problem-of-consistency":{"label":"Apply Monorepos To Repit To Resolve The Problem Of Consistency","children":{}},"/playground/_radar/timeline/learn-typescript-as-a-mandatory-to-develop-reapit-foundation":{"label":"Learn Typescript As A Mandatory To Develop Reapit Foundation","children":{}},"/playground/_radar/timeline/develop-sdk-integration-demo-for-sajari":{"label":"Develop Sdk Integration Demo For Sajari","children":{}},"/playground/_radar/timeline/live-view":{"label":"Live View","children":{}},"/playground/_radar/timeline/migrate-aharooms-pms-to-typescript":{"label":"Migrate Aharooms Pms To Typescript","children":{}},"/playground/_radar/timeline/create-api-service-for-urbox-to-sync-orders-from-3rd-parties-and-manage-shipment":{"label":"Create Api Service For Urbox To Sync Orders From 3rd Parties And Manage Shipment","children":{}},"/playground/_radar/timeline/nghenhan-microservices":{"label":"Nghenhan Microservices","children":{}},"/playground/_radar/timeline/radio-talk-65-fullstack-type-safe-with-trpc":{"label":"Radio Talk 65 Fullstack Type Safe With Trpc","children":{}},"/playground/_radar/timeline/understanding-test-doubles-an-in-depth-look":{"label":"Understanding Test Doubles An In Depth Look","children":{}},"/playground/_radar/timeline/radio-talk-64-coding-best-practice-that-optimizing-go-compiler":{"label":"Radio Talk 64 Coding Best Practice That Optimizing Go Compiler","children":{}},"/playground/_radar/timeline/reward-model":{"label":"Reward Model","children":{}},"/playground/_radar/timeline/q-learning":{"label":"Q Learning","children":{}},"/playground/_radar/timeline/sum-command":{"label":"Sum Command","children":{}},"/playground/_radar/timeline/reinforcement-learning":{"label":"Reinforcement Learning","children":{}},"/playground/_radar/timeline/react-server-component":{"label":"React Server Component","children":{}},"/playground/_radar/timeline/select-vector-database-for-llm":{"label":"Select Vector Database For Llm","children":{}},"/playground/_radar/timeline/workaround-with-openais-token-limit-with-langchain":{"label":"Workaround With Openais Token Limit With Langchain","children":{}},"/playground/_radar/timeline/working-with-langchain-document-loaders":{"label":"Working With Langchain Document Loaders","children":{}},"/playground/_radar/timeline/the-cost-of-react-native":{"label":"The Cost Of React Native","children":{}},"/playground/_radar/timeline/state-of-frontend-2023-react-vs-angular-vs-vue":{"label":"State Of Frontend 2023 React Vs Angular Vs Vue","children":{}},"/playground/_radar/timeline/unit-testing-best-practices-in-golang":{"label":"Unit Testing Best Practices In Golang","children":{}},"/playground/_radar/timeline/what-is-pnpm":{"label":"What Is Pnpm","children":{}},"/playground/_radar/timeline/tackling-server-state-complexity-in-frontend-development":{"label":"Tackling Server State Complexity In Frontend Development","children":{}},"/playground/_radar/timeline/why-we-chose-our-tech-stack":{"label":"Why We Chose Our Tech Stack","children":{}},"/playground/_radar/timeline/why-micro-frontend":{"label":"Why Micro Frontend","children":{}},"/playground/_radar/timeline/radio-talk-monorepo":{"label":"Radio Talk Monorepo","children":{}},"/playground/_radar/timeline/radio-talk-blue-green-deployment":{"label":"Radio Talk Blue Green Deployment","children":{}},"/playground/_radar/timeline/radio-talk-a-demo-of-query-engine-postgresql-vs-apache-spark":{"label":"Radio Talk A Demo Of Query Engine Postgresql Vs Apache Spark","children":{}},"/playground/_radar/timeline/rnd-team-mentioned-apache-spark-as-a-solution-to-handle-query-big-data":{"label":"Rnd Team Mentioned Apache Spark As A Solution To Handle Query Big Data","children":{}},"/playground/_radar/timeline/radio-talk-engineering-health-metrics":{"label":"Radio Talk Engineering Health Metrics","children":{}},"/playground/_radar/timeline/radio-talk-nextjs-13":{"label":"Radio Talk Nextjs 13","children":{}},"/playground/_radar/timeline/radio-talk-using-nextjs-as-a-fullstack-framework":{"label":"Radio Talk Using Nextjs As A Fullstack Framework","children":{}},"/playground/_radar/timeline/use-yup-to-validate-form-values-in-droppii":{"label":"Use Yup To Validate Form Values In Droppii","children":{}},"/playground/_radar/timeline/vitejs-native-modules":{"label":"Vitejs Native Modules","children":{}},"/playground/_radar/timeline/radio-talk-introduction-to-apache-spark":{"label":"Radio Talk Introduction To Apache Spark","children":{}},"/playground/_radar/timeline/vercel-switching-their-packages-from-yarn-to-pnpm-caught-our-attention":{"label":"Vercel Switching Their Packages From Yarn To Pnpm Caught Our Attention","children":{}},"/playground/_radar/timeline/radio-talk-remix-vs-nextjs":{"label":"Radio Talk Remix Vs Nextjs","children":{}},"/playground/_radar/timeline/radio-talk-turborepo":{"label":"Radio Talk Turborepo","children":{}},"/playground/_radar/timeline/react-toolkit-migrate-from-lerna-to-turporepo":{"label":"React Toolkit Migrate From Lerna To Turporepo","children":{}},"/playground/_radar/timeline/use-monorepos-to-build-v3-of-react-sdk-for-searchio":{"label":"Use Monorepos To Build V3 Of React Sdk For Searchio","children":{}},"/playground/_radar/timeline/react-toolkit":{"label":"React Toolkit","children":{}},"/playground/_radar/timeline/use-nx-for-managing-basehq-frontend-monorepos":{"label":"Use Nx For Managing Basehq Frontend Monorepos","children":{}},"/playground/_radar/timeline/practice-and-using-selenium-in-setel-project":{"label":"Practice And Using Selenium In Setel Project","children":{}},"/playground/_radar/timeline/urbox-backend-api":{"label":"Urbox Backend Api","children":{}},"/playground/_radar/timeline/using-k6-in-setel":{"label":"Using K6 In Setel","children":{}},"/playground/_radar/timeline/use-monorepos-to-resolve-the-problem-of-sharing-ui-components-in-aharoom":{"label":"Use Monorepos To Resolve The Problem Of Sharing Ui Components In Aharoom","children":{}},"/playground/_radar/timeline/a-case-study-interview-into-micro-frontends-building-design-system-for-e-commerce-platform":{"label":"A Case Study Interview Into Micro Frontends Building Design System For E Commerce Platform","children":{}},"/playground/_radar/timeline/accelerate-project-initiation-with-advanced-nextjs-boilerplate-react-toolkit":{"label":"Accelerate Project Initiation With Advanced Nextjs Boilerplate React Toolkit","children":{}},"/playground/_radar/timeline/adapt-cucumber-as-a-bdd-for-wego":{"label":"Adapt Cucumber As A Bdd For Wego","children":{}}}},"/playground/_radar/timescaledb":{"label":"Timescaledb","children":{}},"/playground/_radar/tla":{"label":"Tla","children":{}},"/playground/_radar/trunk-based-development":{"label":"Trunk Based Development","children":{}},"/playground/_radar/turborepo":{"label":"Turborepo","children":{}},"/playground/_radar/type-safe-client-server":{"label":"Type Safe Client Server","children":{}},"/playground/_radar/typescript":{"label":"Typescript","children":{}},"/playground/_radar/ui-documentation":{"label":"Ui Documentation","children":{}},"/playground/_radar/uno-css":{"label":"Uno Css","children":{}},"/playground/_radar/upptime":{"label":"Upptime","children":{}},"/playground/_radar/v-model":{"label":"V Model","children":{}},"/playground/_radar/vector-database":{"label":"Vector Database","children":{}},"/playground/_radar/vercel":{"label":"Vercel","children":{}},"/playground/_radar/vitejs":{"label":"Vitejs","children":{}},"/playground/_radar/volta":{"label":"Volta","children":{}},"/playground/_radar/wasm":{"label":"Wasm","children":{}},"/playground/_radar/webdriverio":{"label":"Webdriverio","children":{}},"/playground/_radar/webflow":{"label":"Webflow","children":{}},"/playground/_radar/yup":{"label":"Yup","children":{}},"/playground/_radar/zod":{"label":"Zod","children":{}},"/playground/_radar/zustand":{"label":"Zustand","children":{}}}},"/playground/blockchain":{"label":"Blockchain","children":{"/playground/blockchain/build-custom-ai-agent-with-elizaos":{"label":"Build custom AI Agent with ElizaOS","children":{}},"/playground/blockchain/web3-development-with-foundry":{"label":"Web3 Development with Foundry","children":{}},"/playground/blockchain/cross-chain-transfers-implementing-a-token-swap-from-base-chain-to-bitcoin":{"label":"Implement a Token Swap from the Base chain to Bitcoin for cross-chain transactions","children":{}},"/playground/blockchain/ton_core_concept":{"label":"Ton's base concepts","children":{}},"/playground/blockchain/ton_blockchain_of_blockchains":{"label":"Ton: Blockchain of blockchains","children":{}},"/playground/blockchain/introduce-to-solana-token-2022-new-standard-to-create-a-token-in-solana":{"label":"Introduce to Solana Token 2022 - new standard to create a token in solana","children":{}},"/playground/blockchain/solana-core-concept":{"label":"Solana core concepts","children":{}},"/playground/blockchain/metaplex-nft-compression":{"label":"Metaplex NFT Compression","children":{}},"/playground/blockchain/plonky2":{"label":"Plonky2","children":{}},"/playground/blockchain/polygon-zkevm-architecture":{"label":"Polygon zkEVM architecture","children":{}},"/playground/blockchain/starknet-architecture":{"label":"StarkNet architecture","children":{}},"/playground/blockchain/zk-snarks":{"label":"zk-SNARKs","children":{}},"/playground/blockchain/layer-2":{"label":"Layer 2: Scaling Solutions for Ethereum","children":{}},"/playground/blockchain/solana-account":{"label":"Solana Account","children":{}},"/playground/blockchain/foundational-topics":{"label":"Foundational Topics","children":{"/playground/blockchain/foundational-topics/zero-knowledge-proofs":{"label":"Zero-knowledge Proofs","children":{}},"/playground/blockchain/foundational-topics/blocks":{"label":"Blocks","children":{}},"/playground/blockchain/foundational-topics/distributed-systems":{"label":"Distributed systems","children":{}},"/playground/blockchain/foundational-topics/pos":{"label":"PoS","children":{}},"/playground/blockchain/foundational-topics/smart-contract":{"label":"Smart Contract","children":{}},"/playground/blockchain/foundational-topics/topics":{"label":"Topics","children":{}}}},"/playground/blockchain/multisign-wallet":{"label":"Multisign wallet","children":{}},"/playground/blockchain/anchor-framework":{"label":"Anchor framework","children":{}},"/playground/blockchain/blockchain-bridge":{"label":"Blockchain Bridge","children":{}},"/playground/blockchain/nft-fractionalization":{"label":"NFT Fractionalization","children":{}},"/playground/blockchain/how-tokens-work-on-solana":{"label":"How Tokens Work on Solana","children":{}},"/playground/blockchain/liquidity-pool":{"label":"Liquidity pool","children":{}}}},"/playground/frontend":{"label":"Frontend","children":{"/playground/frontend/report":{"label":"Report","children":{"/playground/frontend/report/frontend-report-march-2025":{"label":"Frontend Report March 2025","children":{}},"/playground/frontend/report/frontend-report-february-2025":{"label":"February 2025","children":{}},"/playground/frontend/report/frontend-report-january-2025":{"label":"January 2025","children":{}},"/playground/frontend/report/frontend-report-second-half-of-november-2024":{"label":"Nov 2024 (Second Half)","children":{}},"/playground/frontend/report/frontend-report-first-half-of-november-2024":{"label":"Nov 2024 (First Half)","children":{}},"/playground/frontend/report/frontend-report-october-2024":{"label":"October 2024","children":{}},"/playground/frontend/report/frontend-report-september-2024":{"label":"September 2024","children":{}},"/playground/frontend/report/frontend-report-august-2024":{"label":"August 2024","children":{}},"/playground/frontend/report/frontend-report-july-2024":{"label":"July 2024","children":{}}}},"/playground/frontend/react":{"label":"React","children":{"/playground/frontend/react/code-splitting":{"label":"Code splitting","children":{}},"/playground/frontend/react/component-composition-patterns":{"label":"Component composition patterns","children":{}},"/playground/frontend/react/design-system-integration":{"label":"Design system integration","children":{}},"/playground/frontend/react/hook-architecture":{"label":"Hook architecture","children":{}},"/playground/frontend/react/rendering-strategies":{"label":"Rendering strategies","children":{}},"/playground/frontend/react/state-management-strategy":{"label":"State management strategy","children":{}},"/playground/frontend/react/testing-strategies":{"label":"Testing strategies","children":{}}}},"/playground/frontend/websockets":{"label":"WebSockets","children":{}},"/playground/frontend/from-markup-to-pixels-a-look-inside-the-dom-cssom-and-render-tree":{"label":"From Markup to Pixels - A look inside the DOM, CSSOM, and Render Tree","children":{}},"/playground/frontend/window-and-iframe-communication":{"label":"Window and iframe communication","children":{}},"/playground/frontend/applying-mock-service-worker-msw-for-seamless-web-development":{"label":"Applying Mock Service Worker (MSW) for Seamless Web Development","children":{}},"/playground/frontend/render-optimization-in-data-fetching-libraries":{"label":"Render optimization in data-fetching libraries","children":{}},"/playground/frontend/a-fragment-colocation-pattern-with-react-apollo-graphql":{"label":"A Fragment Colocation Pattern with React \u0026 Apollo GraphQL","children":{}},"/playground/frontend/scroll-driven-animations":{"label":"Scroll-driven animations","children":{}},"/playground/frontend/react-server-component":{"label":"React Server Components, NextJs Route and Data Fetching","children":{}},"/playground/frontend/url-formats-for-sharing-via-social-networks":{"label":"URL formats for sharing via social networks","children":{}},"/playground/frontend/shadow-dom":{"label":"Shadow DOM","children":{}},"/playground/frontend/retain-scroll-position-in-infinite-scroll":{"label":"Retain scroll position in infinite scroll","children":{}},"/playground/frontend/continuous-translation":{"label":"Continuous Translation","children":{}},"/playground/frontend/what-is-pnpm-compare-to-npmyarn":{"label":"What is PNPM Compare To NPM/Yarn","children":{}},"/playground/frontend/why-micro-frontend":{"label":"Why Micro Frontend","children":{}},"/playground/frontend/why-we-chose-our-tech-stack-accelerating-development-with-a-robust-frontend-solution":{"label":"Why We Chose Our Tech Stack Accelerating Development With A Robust Frontend Solution","children":{}},"/playground/frontend/tackling-server-state-complexity-in-frontend-development":{"label":"Tackling Server State complexity in Frontend Development","children":{}},"/playground/frontend/variable-fonts":{"label":"Variable Fonts","children":{}},"/playground/frontend/when-should-we-use-usereducer-instead-of-usestate":{"label":"When should we use useReducer instead of useState?","children":{}},"/playground/frontend/preserving-and-resetting-state-in-react":{"label":"Preserving and Resetting state in React","children":{}},"/playground/frontend/mixpanel":{"label":"Mixpanel","children":{}},"/playground/frontend/validation-with-zod":{"label":"Validation with Zod","children":{}},"/playground/frontend/parse-dont-validate-in-typescript":{"label":"Parse, don't validate in TypeScript","children":{}},"/playground/frontend/webassembly":{"label":"Webassembly","children":{}},"/playground/frontend/singleton-design-pattern-in-javascript":{"label":"Singleton Design Pattern in Javascript","children":{}},"/playground/frontend/an-introduction-to-atomic-css":{"label":"An Introduction to Atomic CSS","children":{}},"/playground/frontend/intro-to-indexeddb":{"label":"Intro to IndexedDB","children":{}},"/playground/frontend/the-fundamental-of-web-performance":{"label":"The fundamental of web performance","children":{}},"/playground/frontend/wai-aria":{"label":"WAI-ARIA","children":{}},"/playground/frontend/build-polymorphic-react-components-with-typescript":{"label":"Build polymorphic React components with Typescript","children":{}},"/playground/frontend/threejs":{"label":"Threejs","children":{"/playground/frontend/threejs/cameras-in-threejs":{"label":"Cameras in ThreeJS","children":{}}}},"/playground/frontend/prevent-layout-thrashing":{"label":"Prevent Layout Thrashing","children":{}},"/playground/frontend/pure-css-parallax":{"label":"Pure CSS Parallax","children":{}},"/playground/frontend/css-container-queries":{"label":"CSS Container Queries","children":{}},"/playground/frontend/hsl-color":{"label":"HSL Color","children":{}},"/playground/frontend/mitigate-blocking-the-main-thread":{"label":"Mitigate blocking the main thread","children":{}},"/playground/frontend/css-in-js":{"label":"CSS in JS","children":{}},"/playground/frontend/dark-mode-flickers-a-white-background-for-a-fraction-of-a-second":{"label":"Dark mode flickers a white background for a fraction of a second","children":{}},"/playground/frontend/why-dom-manipulation-is-slow":{"label":"Why DOM manipulation is slow?","children":{}},"/playground/frontend/why-virtual-dom-is-fast":{"label":"Why Virtual DOM is fast?","children":{}},"/playground/frontend/vitejs-native-modules":{"label":"ViteJS native modules","children":{}},"/playground/frontend/javascript-modules":{"label":"JavaScript modules","children":{}},"/playground/frontend/atomic-design-pattern":{"label":"Atomic Design Pattern","children":{}},"/playground/frontend/focus-trap":{"label":"Focus trap","children":{}},"/playground/frontend/html-inert":{"label":"HTML inert","children":{}},"/playground/frontend/useeffect-double-calls-in-react-18":{"label":"useEffect double calls in React 18","children":{}},"/playground/frontend/react-18":{"label":"React 18","children":{}},"/playground/frontend/remix-versus-nextjs":{"label":"Remix Versus Nextjs","children":{}},"/playground/frontend/zaplib-post-mortem":{"label":"Zaplib post-mortem","children":{}},"/playground/frontend/parallelism-in-javascript":{"label":"Parallelism in JavaScript","children":{}},"/playground/frontend/mpa-spa-and-partial-hydration":{"label":"MPA, SPA and Partial Hydration","children":{}},"/playground/frontend/micro-frontends-microservices-for-frontend-development":{"label":"Micro Frontends Microservices For Frontend Development","children":{}},"/playground/frontend/using-correct-html-element-to-increase-website-accessibility":{"label":"Using Correct Html Element To Increase Website Accessibility","children":{}},"/playground/frontend/remove-unused-css-styles-from-bootstrap-using-purgecss":{"label":"Remove Unused CSS Styles From Bootstrap Using Purgecss","children":{}}}},"/playground/ai":{"label":"AI","children":{"/playground/ai/securing-your-remote-mcp-servers":{"label":"Securing your remote MCP servers","children":{}},"/playground/ai/tool-level-security-for-remote-mcp-servers":{"label":"Tool-Level Security for Remote MCP Servers","children":{}},"/playground/ai/model-context-protocol":{"label":"Intro to Model Context Protocol","children":{}},"/playground/ai/building-llm-system":{"label":"Building LLM System","children":{"/playground/ai/building-llm-system/quantization-in-llm":{"label":"Quantization for large language models","children":{}},"/playground/ai/building-llm-system/graphrag":{"label":"GraphRAG - Building a knowledge graph for RAG system","children":{}},"/playground/ai/building-llm-system/guardrails-in-llm":{"label":"Guardrails in llm","children":{}},"/playground/ai/building-llm-system/react-in-llm":{"label":"ReAct(Reason + Act) in LLM","children":{}},"/playground/ai/building-llm-system/rewoo-in-llm":{"label":"ReWOO: Reasoning without observation - A deeper look","children":{}},"/playground/ai/building-llm-system/model-selection":{"label":"Model selection","children":{}},"/playground/ai/building-llm-system/logs-pillar":{"label":"Logging","children":{}},"/playground/ai/building-llm-system/metric-pillar":{"label":"Metrics","children":{}},"/playground/ai/building-llm-system/observability-in-ai-platforms":{"label":"Observability in AI platforms","children":{}},"/playground/ai/building-llm-system/trace-pillar":{"label":"Tracing","children":{}},"/playground/ai/building-llm-system/intent-classification-by-llm":{"label":"Intent classification by LLM","children":{}},"/playground/ai/building-llm-system/llm-as-a-judge":{"label":"LLM as a judge","children":{}},"/playground/ai/building-llm-system/use-cases-for-llm-applications":{"label":"Use cases for LLM applications","children":{}},"/playground/ai/building-llm-system/the-rise-of-ai-applications-with-llm":{"label":"The rise of AI applications with LLM","children":{}},"/playground/ai/building-llm-system/evaluation-guideline-for-llm-application":{"label":"Evaluation guidelines for LLM applications","children":{}},"/playground/ai/building-llm-system/prevent-prompt-injection":{"label":"Prevent prompt injection","children":{}},"/playground/ai/building-llm-system/building-llm-system":{"label":"§ Building LLM system","children":{}},"/playground/ai/building-llm-system/multi-agent-collaboration-for-task-completion":{"label":"Multi-agent collaboration for task completion","children":{}},"/playground/ai/building-llm-system/multimodal-in-rag":{"label":"Multimodal in rag","children":{}}}},"/playground/ai/digest":{"label":"Digest","children":{"/playground/ai/digest/ai-digest-02":{"label":"AI digest #2 New command Aider, OpenHands, Qwen2.5 Coder 32B, Predicted Output","children":{}},"/playground/ai/digest/ai-digest-01":{"label":"AI digest #1 Aider reasoning, OpenAI Realtime API, Cline - pre Claude-dev ","children":{}}}},"/playground/ai/copilots":{"label":"Copilots","children":{"/playground/ai/copilots/projects-operations":{"label":"Project Operations Copilots","children":{}},"/playground/ai/copilots/team-copilots":{"label":"Team Copilots","children":{}}}},"/playground/ai/text-to-mongodb":{"label":"Natural Language to Database Queries: Text-to-MongoDB","children":{}},"/playground/ai/use-cases":{"label":"Use Cases","children":{"/playground/ai/use-cases/salesforce":{"label":"Salesforce use cases","children":{}},"/playground/ai/use-cases/yelp":{"label":"Yelp use cases","children":{}}}},"/playground/ai/evaluate-chatbot-agent-by-simulated-user":{"label":"Evaluate Chatbot Agent by User Simulation","children":{}},"/playground/ai/journey-of-thought-prompting":{"label":"Journey of Thought Prompting: Harnessing AI to Craft Better Prompts","children":{}},"/playground/ai/llm-tracing-in-ai-system":{"label":"LLM tracing in AI system","children":{}},"/playground/ai/caching-with-rag-system":{"label":"Evaluating caching in RAG systems","children":{}},"/playground/ai/generative-ui":{"label":"What is Generative UI?","children":{}},"/playground/ai/re-ranking-in-rag":{"label":"Re-ranking in RAG","children":{}},"/playground/ai/function-calling":{"label":"Function calling in AI agents","children":{}},"/playground/ai/building-llm-powered-tools-with-dify":{"label":"Streamlining Internal Tool Development with Managed LLMOps: A Dify Case Study","children":{}},"/playground/ai/thumbs-up-and-thumbs-down-pattern":{"label":"Thumbs up and Thumbs down pattern","children":{}},"/playground/ai/supervisor-ai-agents":{"label":"Building Agent Supervisors to Generate Insights","children":{}},"/playground/ai/raptor-llm-retrieval":{"label":"RAPTOR: Tree-based Retrieval for Language Models","children":{}},"/playground/ai/proximal-policy-optimization":{"label":"Proximal Policy Optimization","children":{}},"/playground/ai/a-grand-unified-theory-of-the-ai-hype-cycle":{"label":"A Grand Unified Theory of the AI Hype Cycle","children":{}},"/playground/ai/developing-rapidly-with-generative-ai":{"label":"Developing rapidly with Generative AI","children":{}},"/playground/ai/rlhf-with-open-assistant":{"label":"RLHF with Open Assistant","children":{}},"/playground/ai/story-map-for-llms":{"label":"Story map for LLMs","children":{}},"/playground/ai/adversarial-prompting":{"label":"Adversarial Prompting in Prompt Engineering","children":{}},"/playground/ai/chunking-strategies-to-overcome-context-limitation-in-llm":{"label":"Chunking strategies to overcome context limitation in LLM","children":{}},"/playground/ai/llms-accuracy-self-refinement":{"label":"LLM's Accuracy - Self Refinement","children":{}},"/playground/ai/llm-query-caching":{"label":"Query Caching for Large Language Models","children":{}},"/playground/ai/reinforcement-learning":{"label":"Introduction to Reinforcement Learning and Its Application with LLMs","children":{}},"/playground/ai/foundation-model":{"label":"Foundation Models: The Latest Advancement in AI","children":{}},"/playground/ai/select-vector-database-for-llm":{"label":"Select Vector Database for LLM","children":{}},"/playground/ai/build-your-chatbot-with-open-source-large-language-models":{"label":"Build your chatbot with open source Large Language Models","children":{}},"/playground/ai/workaround-with-openais-token-limit-with-langchain":{"label":"Workaround with OpenAI's token limit with Langchain","children":{}},"/playground/ai/working-with-langchain-document-loaders":{"label":"Working with langchain document loaders","children":{}}}},"/playground/use-cases":{"label":"Use Cases","children":{"/playground/use-cases/create-slides-with-overleaf":{"label":"Create slides with Overleaf and ChatGPT","children":{}},"/playground/use-cases/optimize-init-load-time-for-trading-platform":{"label":"Optimizing initial load time for a Trading Platform","children":{}},"/playground/use-cases/ai-interview-platform-mvp":{"label":"Building MVP for AI-driven interview platform","children":{}},"/playground/use-cases/optimizing-ui-for-effective-investment-experience":{"label":"Hedge Foundation - Optimizing UI for effective investment experience","children":{}},"/playground/use-cases/implement-binance-future-pnl-analysis-page":{"label":"Implement Binance Futures PNL analysis page by Phoenix LiveView","children":{}},"/playground/use-cases/migrate-normal-table-to-timescale-table":{"label":"Migrate regular tables into TimescaleDB hypertables to improve query performance","children":{}},"/playground/use-cases/bitcoin-alt-performance-tracking":{"label":"Tracking Bitcoin-Altcoin Performance Indicators in BTC Hedging Strategy","children":{}},"/playground/use-cases/database-hardening-for-trading-platform":{"label":"Database hardening for a trading platform","children":{}},"/playground/use-cases/data-archive-and-recovery":{"label":"Building a data archive and recovery strategy for high-volume trading system","children":{}},"/playground/use-cases/persist-history-using-data-snapshot-pattern":{"label":"Implementing data snapshot pattern to persist historical data","children":{}},"/playground/use-cases/ai-ruby-travel-assistant-chatbot":{"label":"AI-powered Ruby travel assistant","children":{}},"/playground/use-cases/building-chatbot-agent-for-project-management-tool":{"label":"Building chatbot agent to streamline project management","children":{}},"/playground/use-cases/building-data-pipeline-ogif-transcriber":{"label":"Building data pipeline for OGIF transcriber","children":{}},"/playground/use-cases/centralized-monitoring-setup-for-trading-platform":{"label":"Setup centralized monitoring system for Hedge Foundation trading platform","children":{}},"/playground/use-cases/binance-transfer-matching":{"label":"Building better Binance transfer tracking","children":{}},"/playground/use-cases/crypto-market-outperform-chart-rendering":{"label":"Visualizing crypto market performance: BTC-Alt dynamic indicators in Golang","children":{}},"/playground/use-cases/enhancing-cryptocurrency-transfer-logger":{"label":"Transfer mapping: enhancing loggers for better transparency","children":{}},"/playground/use-cases/reconstructing_trading_pnl_data_pipeline_approach":{"label":"Reconstructing historical trading PnL: a data pipeline approach","children":{}},"/playground/use-cases/ai-powered-monthly-project-reports":{"label":"Project reports system: a case study","children":{}}}},"/playground/go":{"label":"Go","children":{"/playground/go/weekly":{"label":"Weekly","children":{"/playground/go/weekly/dec-13":{"label":"#24 Go 1.24 testing/synctest experiment for time and concurrency testing","children":{}},"/playground/go/weekly/dec-06":{"label":"#23 Draft Release Notes for Go 1.24 and weak pointers in Go","children":{}},"/playground/go/weekly/nov-29":{"label":"#22 GoMLX: ML in Go without Python","children":{}},"/playground/go/weekly/nov-22":{"label":"#21 Go sync.Once is Simple","children":{}},"/playground/go/weekly/nov-15":{"label":"#20 Go Turns 15","children":{}},"/playground/go/weekly/nov-08":{"label":"#19 Writing secure Go code","children":{}},"/playground/go/weekly/nov-01":{"label":"#18 Fuzz Testing Go HTTP Services","children":{}},"/playground/go/weekly/oct-25":{"label":"#17 Leveraging benchstat Projects in Go benchmark and Go Plan9 memo on 450% speeding up calculations","children":{}},"/playground/go/weekly/oct-18":{"label":"#16 Understand sync.Map","children":{}},"/playground/go/weekly/oct-11":{"label":"#15 Go embed and Reflect","children":{}},"/playground/go/weekly/oct-04":{"label":"#14 Compile-time eval \u0026 SQLite with wazero","children":{}},"/playground/go/weekly/sep-27":{"label":"#13 Compiler Quests and Vector Vexations","children":{}},"/playground/go/weekly/sep-20":{"label":"#12 CLI Tools for K8s, REST, and Terminals","children":{}},"/playground/go/weekly/sep-13":{"label":"#11 Actors, Frameworks, and the Future of Go","children":{}},"/playground/go/weekly/sep-06":{"label":"#10 Script, Telemetry","children":{}},"/playground/go/weekly/aug-30":{"label":"#9 TinyGo, SQLite vector search, and Permify","children":{}},"/playground/go/weekly/aug-23":{"label":"#8 GoNB, kubetrim, and GopherCon UK 2024","children":{}},"/playground/go/weekly/aug-16":{"label":"#7 Go 1.23, Websockets, and Structs","children":{}},"/playground/go/weekly/aug-09":{"label":"#6 Cogent Core, Russ Cox stepping down","children":{}},"/playground/go/weekly/aug-02":{"label":"#5 Go 1.23 features, Memory, Minecraft, and More","children":{}},"/playground/go/weekly/jul-26":{"label":"#4 Ethical Hacking, HTTP Requests, Mac App Development","children":{}},"/playground/go/weekly/jul-12":{"label":"#3 Generic Collections, Generics Constraints, AI Bot","children":{}},"/playground/go/weekly/jul-05":{"label":"#2 Go 1.23 Iterators","children":{}},"/playground/go/weekly/june-27":{"label":"#1 eBPF and PGO Optimization Techniques","children":{}}}},"/playground/go/extension-interface-pattern":{"label":"Go extension interface pattern","children":{}},"/playground/go/go-import":{"label":"Go import design: using git repo path","children":{}},"/playground/go/go-package":{"label":"Package first design","children":{}},"/playground/go/go-generics-type-safety":{"label":"How does Go achieve type safety when it enables generics?","children":{}},"/playground/go/go-for-enterprise":{"label":"Go For Enterprise","children":{"/playground/go/go-for-enterprise/who-using-golang-in-enterprise":{"label":"Who is using Go in enterprise?","children":{}},"/playground/go/go-for-enterprise/enterprise-standard-language":{"label":"Go as an Enterprise Standard Language","children":{}},"/playground/go/go-for-enterprise/how-to-use-go-in-enterprise":{"label":"How to use Go in the Enterprise","children":{}},"/playground/go/go-for-enterprise/when-to-use-golang-in-enterprise":{"label":"When to use Go in the Enterprise","children":{}},"/playground/go/go-for-enterprise/why-enterprise-chose-java":{"label":"Why Enterprise Chose Java","children":{}},"/playground/go/go-for-enterprise/why-go":{"label":"Why Go?","children":{}}}},"/playground/go/compute-union-2-finite-automata":{"label":"Efficient Union of Finite Automata in Golang: A Practical Approach","children":{}},"/playground/go/approaches-to-manage-concurrent-workloads-like-worker-pools-and-pipelines":{"label":"Approaches To Manage Concurrent Workloads Like Worker Pools And Pipelines","children":{}},"/playground/go/message-queues-and-streaming-platforms-eg-kafka-nats-rabbitmq":{"label":"Message Queues And Streaming Platforms Eg Kafka Nats Rabbitmq","children":{}},"/playground/go/unit-testing-best-practices-in-golang":{"label":"Unit Testing Best Practices In Golang","children":{}},"/playground/go/profiling-in-go":{"label":"Profiling in Go","children":{}},"/playground/go/go-in-software-engineering":{"label":"Go In Software Engineering","children":{}},"/playground/go/go-concurrency":{"label":"Go Concurrency","children":{}},"/playground/go/slice-and-array-in-golang":{"label":"Slice And Array In Golang","children":{}},"/playground/go/use-go-selenium-to-crawl-data":{"label":"Use Go Selenium To Crawl Data","children":{}},"/playground/go/connecting-vim-with-golang":{"label":"Connecting Vim With Golang","children":{}}}},"/playground/market-report":{"label":"Market Report","children":{"/playground/market-report/2024-october":{"label":"October 2024","children":{}},"/playground/market-report/2024-september":{"label":"September 2024","children":{}},"/playground/market-report/2024-august":{"label":"August 2024","children":{}},"/playground/market-report/2024-july":{"label":"July 2024","children":{}},"/playground/market-report/2024-may":{"label":"May 2024","children":{}},"/playground/market-report/2024-april":{"label":"April 2024","children":{}},"/playground/market-report/2024-march":{"label":"March 2024","children":{}},"/playground/market-report/2024-february":{"label":"February 2024","children":{}},"/playground/market-report/2024-january":{"label":"January 2024","children":{}},"/playground/market-report/2023-december":{"label":"December 2023","children":{}}}},"/playground/devbox":{"label":"Devbox","children":{"/playground/devbox/devbox":{"label":"§ Devbox","children":{}},"/playground/devbox/story":{"label":"Story","children":{"/playground/devbox/story/devbox-production-success-story":{"label":"Devbox in Production: Our Success Story","children":{}},"/playground/devbox/story/devbox-local-development-env":{"label":"Using Devbox to setup local development environment","children":{}},"/playground/devbox/story/devbox-nix-and-our-devbox-adoption":{"label":"The overview into Nix \u0026 how we use Devbox @ Dwarves","children":{}},"/playground/devbox/story/devbox-docker-adoption-and-challenges":{"label":"Our Docker adoption and its challenges","children":{}},"/playground/devbox/story/devbox-a-world-before-docker":{"label":"The world before Docker","children":{}}}},"/playground/devbox/guide":{"label":"Guide","children":{"/playground/devbox/guide/containerless":{"label":"Ditch the Containers: Go Containerless with Devbox","children":{}},"/playground/devbox/guide/devboxjson":{"label":"Devbox.json: Your Project's DNA","children":{}},"/playground/devbox/guide/run-your-own-shell":{"label":"Devbox Shell: Your Dev Environment, Your Rules","children":{}}}},"/playground/devbox/introduction":{"label":"Introduction","children":{"/playground/devbox/introduction/the-reason-for-being":{"label":"The reason for being","children":{}},"/playground/devbox/introduction/why-devbox-but-not-nix":{"label":"Devbox vs Nix: Why We Chose Simplicity","children":{}}}},"/playground/devbox/research":{"label":"Research","children":{"/playground/devbox/research/content-addressable-storage-in-docker":{"label":"Devbox vs Nix: Why We Chose Simplicity","children":{}},"/playground/devbox/research/fixed-output-derivation":{"label":"Fixed-output Derivation in Nix","children":{}},"/playground/devbox/research/nix-is-faster-than-docker-build":{"label":"Nix is Faster Than Docker Build","children":{}},"/playground/devbox/research/pinning-nixpkgs":{"label":"Pinning nixpkgs in Nix","children":{}},"/playground/devbox/research/shadow-copies":{"label":"Shadow Copies in Docker Builds","children":{}},"/playground/devbox/research/unstable-package-installation":{"label":"Unstable Package Installation in Docker","children":{}}}}}}}},"/careers":{"label":"Careers","children":{"/careers/archived":{"label":"Archived","children":{"/careers/archived/full-stack-engineer":{"label":"Full-Stack Engineer","children":{}},"/careers/archived/executive-assistant":{"label":"Executive Assistant","children":{}},"/careers/archived/technical-recruiter":{"label":"Technical Recruiter","children":{}},"/careers/archived/backend-engineer-go-elixir-rust":{"label":"Backend Engineer, Go/Elixir/Rust","children":{}},"/careers/archived/react-native-developer":{"label":"React Native Developer","children":{}},"/careers/archived/android-developer":{"label":"Mobile Engineer, Android","children":{}},"/careers/archived/community-executive":{"label":"Community Executive","children":{}},"/careers/archived/data-engineering":{"label":"Energy - Data Engineering","children":{}},"/careers/archived/devops":{"label":"DevOps Engineer - FinTech","children":{}},"/careers/archived/frontend-developer-junior":{"label":"Junior Frontend Developer","children":{}},"/careers/archived/frontend":{"label":"Frontend","children":{}},"/careers/archived/ios-developer":{"label":"iOS Developer - EnergyTech","children":{}},"/careers/archived/macos-developer":{"label":"Software Engineer, macOS","children":{}},"/careers/archived/product-designer-new-grad":{"label":"Product Designer, New Grad","children":{}},"/careers/archived/product-designer":{"label":"Product Designer","children":{}},"/careers/archived/qc-automation":{"label":"QC Engineer, Automation - Logistics","children":{}},"/careers/archived/qc-manual":{"label":"Fintech - QC Engineer, Manual","children":{}},"/careers/archived/reactjs-web-engineer":{"label":"Web Engineer, React.js","children":{}},"/careers/archived/visual-designer":{"label":"Visual Designer","children":{}},"/careers/archived/android":{"label":"Android","children":{}},"/careers/archived/golang":{"label":"Golang","children":{}},"/careers/archived/intern":{"label":"Intern","children":{}},"/careers/archived/ios":{"label":"iOS Developer","children":{}},"/careers/archived/qa":{"label":"QA Engineer","children":{}}}},"/careers/open-positions":{"label":"Open Positions","children":{"/careers/open-positions/business-development-manager":{"label":"Business Development","children":{}},"/careers/open-positions/growth":{"label":"Growth","children":{}}}},"/careers/life":{"label":"Life","children":{"/careers/life/dat-nguyen":{"label":"Dat Nguyen","children":{}},"/careers/life/software-design-group":{"label":"Software Design Group","children":{}},"/careers/life/hieu-vu":{"label":"Hieu Vu","children":{}},"/careers/life/nam-nguyen":{"label":"Nam Nguyen","children":{}},"/careers/life/an-tran":{"label":"An Tran","children":{}},"/careers/life/tom-nguyen":{"label":"Tom Nguyen","children":{}},"/careers/life/anh-tran":{"label":"Anh Tran","children":{}},"/careers/life/thanh-pham":{"label":"Thanh Pham","children":{}}}},"/careers/additional-info":{"label":"Additional Info","children":{"/careers/additional-info/culture-handbook":{"label":"Culture Handbook","children":{}},"/careers/additional-info/how-we-hire":{"label":"How we hire","children":{}},"/careers/additional-info/how-we-work":{"label":"How we work","children":{}},"/careers/additional-info/making-a-career":{"label":"Making a career","children":{}},"/careers/additional-info/the-manifesto":{"label":"The Manifesto","children":{}},"/careers/additional-info/what-we-stand-for":{"label":"What we stand for","children":{}},"/careers/additional-info/what-we-value":{"label":"What we value","children":{}},"/careers/additional-info/where-we-work":{"label":"Where we work","children":{}},"/careers/additional-info/life-at-dwarves":{"label":"Life at Dwarves","children":{}},"/careers/additional-info/benefits-and-perks":{"label":"Benefits And Perks","children":{}}}},"/careers/hiring":{"label":"Hiring","children":{"/careers/hiring/readme":{"label":"Careers","children":{}}}},"/careers/apprentice":{"label":"Apprentice","children":{"/careers/apprentice/batch-of-2022":{"label":"Batch of 2022","children":{}},"/careers/apprentice/2022-meet-ngoc-thanh-pham":{"label":"Meet the Mentors: Ngoc Thanh Pham","children":{}},"/careers/apprentice/2022-meet-tuan-dao":{"label":"Meet the Mentors: Tuan Dao","children":{}},"/careers/apprentice/apprentice":{"label":"Apprentice Program","children":{}}}}}},"/playbook":{"label":"Playbook","children":{"/playbook/operations":{"label":"Operations","children":{"/playbook/operations/checklists":{"label":"Checklists","children":{"/playbook/operations/checklists/leave-and-request-checklist":{"label":"Leave Request","children":{}},"/playbook/operations/checklists/offboarding-checklist":{"label":"Offboarding","children":{}},"/playbook/operations/checklists/artifact-checklist":{"label":"Back up Artifact","children":{}},"/playbook/operations/checklists/project-archive":{"label":"Project Archive","children":{}},"/playbook/operations/checklists/project-case-study":{"label":"Project Case Study","children":{}},"/playbook/operations/checklists/project-communication":{"label":"Project Communication","children":{}},"/playbook/operations/checklists/project-handover":{"label":"Project Handover","children":{}},"/playbook/operations/checklists/project-initialization":{"label":"Project Initialization","children":{}},"/playbook/operations/checklists/assets-checklist":{"label":"Assets","children":{}},"/playbook/operations/checklists/billing-checklist":{"label":"Billing","children":{}},"/playbook/operations/checklists/candidate-checklist":{"label":"Candidate","children":{}},"/playbook/operations/checklists/consulting-contract-checklist":{"label":"Consulting Contract","children":{}},"/playbook/operations/checklists/hiring-checklist":{"label":"Hiring","children":{}},"/playbook/operations/checklists/onboarding-checklist":{"label":"Onboarding","children":{}},"/playbook/operations/checklists/unemployment-social-health-insurance":{"label":"Unemployment, Social, Health Insurance","children":{}},"/playbook/operations/checklists/vietnam-invoice-checklist":{"label":"Vietnam Invoice","children":{}}}},"/playbook/operations/project-schedule-delivery-guidelines":{"label":"Project Delivery Schedule and Guidelines","children":{}},"/playbook/operations/ogif":{"label":"OGIF - Oh God It's Friday","children":{}},"/playbook/operations/red-flags":{"label":"Red Flags","children":{}},"/playbook/operations/focus-on-software-delivery":{"label":"Focus On Software Delivery","children":{}},"/playbook/operations/are-you-helping":{"label":"Are You Helping","children":{}},"/playbook/operations/the-inner-circle":{"label":"The Inner Circle","children":{}},"/playbook/operations/mbti-type-intj":{"label":"MBTI Type INTJ","children":{}},"/playbook/operations/mbti-type-istp":{"label":"MBTI Type ISTP","children":{}},"/playbook/operations/mbti-type-estj":{"label":"MBTI Type ESTJ","children":{}},"/playbook/operations/mbti-type-istj":{"label":"MBTI Type ISTJ","children":{}},"/playbook/operations/applying-myersbriggs-type-indicator-in-hr":{"label":"Applying Myersbriggs Type Indicator In Hiring","children":{}},"/playbook/operations/the-four-preferences":{"label":"The Four Preferences","children":{}},"/playbook/operations/making-decision-as-a-team-member":{"label":"Making Decision As A Team Member","children":{}},"/playbook/operations/adjust-the-way-we-work-in-basecamp-style":{"label":"Adjust The Way We Work In Basecamp Style","children":{}},"/playbook/operations/beyond-the-title":{"label":"Beyond The Title","children":{}},"/playbook/operations/go-the-extra-mile":{"label":"Go The Extra Mile","children":{}},"/playbook/operations/the-dwarves-runs-by-ideas":{"label":"The Dwarves Runs By Ideas","children":{}},"/playbook/operations/a-tips-of-hiring-dont":{"label":"A Tips Of Hiring - Do \u0026 Don't","children":{}},"/playbook/operations/the-dwarves-culture-handbook":{"label":"The Dwarves Culture Handbook","children":{}},"/playbook/operations/delegation-and-believe-it-will-work":{"label":"Delegation And Believe It Will Work","children":{}},"/playbook/operations/constructive-feedback":{"label":"Constructive Feedback","children":{}},"/playbook/operations/transparency":{"label":"Transparency","children":{}},"/playbook/operations/bric-a-brac":{"label":"Bric A Brac","children":{}},"/playbook/operations/account":{"label":"Account","children":{}},"/playbook/operations/avoid-burn-out":{"label":"Avoid Burn Out","children":{}},"/playbook/operations/writing-management-objectives-in-smart":{"label":"Writing Management Objectives In Smart","children":{}},"/playbook/operations/building-a-solid-high-performing-team":{"label":"Building A Solid High Performing Team","children":{}},"/playbook/operations/hiring-for-operations-team":{"label":"Hiring For Operations Team","children":{}},"/playbook/operations/annual-bonus-for-sales":{"label":"Annual bonus for sales","children":{}},"/playbook/operations/bunk-license-check":{"label":"Bunk license check","children":{}},"/playbook/operations/collaboration-guidelines":{"label":"Collaboration Guidelines","children":{}},"/playbook/operations/compliance-check-process":{"label":"Compliance Check Process","children":{}},"/playbook/operations/email-template":{"label":"Email Template","children":{"/playbook/operations/email-template/assignment-invitation-2":{"label":"Assignment Inviation (Skip pre-assessment)","children":{}},"/playbook/operations/email-template/assignment-invitation":{"label":"Assignment Inviation","children":{}},"/playbook/operations/email-template/confirm-resume-date":{"label":"Confirm Employee's Resume Date Day","children":{}},"/playbook/operations/email-template/farewell":{"label":"Farewell Letter","children":{}},"/playbook/operations/email-template/follow-up-onboarding-items":{"label":"Follow-up Onboarding Items","children":{}},"/playbook/operations/email-template/hung-king-commemoration-day":{"label":"Hung King Commemoration Day","children":{}},"/playbook/operations/email-template/information-about-resource-change":{"label":"Inform about resource change","children":{}},"/playbook/operations/email-template/international-labour-day":{"label":"International Labour Day","children":{}},"/playbook/operations/email-template/interview-invitation":{"label":"Interview Invitation","children":{}},"/playbook/operations/email-template/milestone-sign-off":{"label":"Milestone sign-off","children":{}},"/playbook/operations/email-template/national-day":{"label":"National Day","children":{}},"/playbook/operations/email-template/new-year-day":{"label":"New Year Day","children":{}},"/playbook/operations/email-template/offer-letter":{"label":"Offer Letter","children":{}},"/playbook/operations/email-template/referral-bonus-confirmation-note":{"label":"Referral Bonus Confirmation Note","children":{}},"/playbook/operations/email-template/rejection-email":{"label":"Rejection","children":{}},"/playbook/operations/email-template/salary-increment":{"label":"Salary Increment Announcement","children":{}},"/playbook/operations/email-template/tet-holiday":{"label":"Tet Holiday","children":{}},"/playbook/operations/email-template/thank-you-letter":{"label":"Thank you letter","children":{}},"/playbook/operations/email-template/welcome-onboard":{"label":"Welcome Onboard","children":{}},"/playbook/operations/email-template/welcome-to-dwarves-update":{"label":"Welcome to Dwarves Updates","children":{}}}},"/playbook/operations/naming-convention":{"label":"Naming convention","children":{}},"/playbook/operations/delegate-work-not-responsibility":{"label":"Delegate Work Not Responsibility","children":{}},"/playbook/operations/types-of-employees":{"label":"Types Of Employees","children":{}},"/playbook/operations/hiring-approach":{"label":"Hiring Approach","children":{}},"/playbook/operations/the-okr":{"label":"The OKR","children":{}},"/playbook/operations/our-metrics-for-performance-review":{"label":"Our Metrics For Performance Review","children":{}},"/playbook/operations/make-remote-working-works":{"label":"Make Remote Working Works","children":{}},"/playbook/operations/blocking-distraction":{"label":"Blocking Distraction","children":{}},"/playbook/operations/effective-meeting":{"label":"Effective Meeting","children":{}},"/playbook/operations/our-policy-for-remote-working":{"label":"Our Policy For Remote Working","children":{}}}},"/playbook/business":{"label":"Business","children":{"/playbook/business/pricing-model-bill-by-hours":{"label":"Pricing model: Bill by hours","children":{}},"/playbook/business/invoice":{"label":"Invoice","children":{}},"/playbook/business/nda":{"label":"NDA","children":{}},"/playbook/business/collaboration-guideline":{"label":"Collaboration Guideline","children":{}},"/playbook/business/df-workflow":{"label":"Dwarves Workflow","children":{}},"/playbook/business/fbsc":{"label":"FBSC","children":{}},"/playbook/business/how-to-work-with-clients":{"label":"How to work with clients","children":{}},"/playbook/business/service-feedbacks":{"label":"Service Feedbacks","children":{}},"/playbook/business/setting-the-budget":{"label":"Setting The Budget","children":{}},"/playbook/business/fixed-budget-scope-controlled":{"label":"Fixed Budget Scope Controlled","children":{}},"/playbook/business/the-adjacent-possible":{"label":"The Adjacent Possible","children":{}}}},"/playbook/engineering":{"label":"Engineering","children":{"/playbook/engineering/estimation-guidelines":{"label":"Estimation Guidelines","children":{}},"/playbook/engineering/presentation":{"label":"monitoring","children":{}},"/playbook/engineering/repo-icon":{"label":"release","children":{}}}},"/playbook/design":{"label":"Design","children":{"/playbook/design/design-system":{"label":"lean-canvas","children":{}},"/playbook/design/ia":{"label":"nda","children":{}},"/playbook/design/ix":{"label":"IA","children":{}},"/playbook/design/aarrr":{"label":"aarrr","children":{}},"/playbook/design/design-sprint":{"label":"Design Sprint","children":{}},"/playbook/design/lean-canvas":{"label":"Lean Canvas","children":{}},"/playbook/design/prototype":{"label":"Low-fidelity prototype: UI Design","children":{}},"/playbook/design/ui":{"label":"UI","children":{}},"/playbook/design/ux":{"label":"UX","children":{}},"/playbook/design/wireframe":{"label":"wireframe","children":{}}}}}},"/earn":{"label":"Earn","children":{"/earn/readme":{"label":"Open Bounties","children":{}}}},"/updates":{"label":"Updates","children":{"/updates/changelog":{"label":"Changelog","children":{"/updates/changelog/2025-whats-new-march":{"label":"What's New in March 2025","children":{}},"/updates/changelog/2025-whats-new-february":{"label":"What's New in February 2025","children":{}},"/updates/changelog/2024-in-review":{"label":"2024 In Review","children":{}},"/updates/changelog/2024-whats-new-december":{"label":"What's New in December 2024","children":{}},"/updates/changelog/2024-summit-building-bonds-our-way":{"label":"Summit 2024: Building bonds our way","children":{}},"/updates/changelog/2024-whats-new-november":{"label":"What's New in November 2024","children":{}},"/updates/changelog/2024-whats-new-oct":{"label":"What's New in October 2024","children":{}},"/updates/changelog/2024-whats-new-september":{"label":"What's New in September 2024","children":{}},"/updates/changelog/2024-navigating-changes":{"label":"Navigating changes","children":{}},"/updates/changelog/2024-whats-new-august":{"label":"What's New in August 2024","children":{}},"/updates/changelog/2024-whats-new-july":{"label":"What's New in July 2024","children":{}},"/updates/changelog/2024-semi-annual-review":{"label":"State of Dwarves: 2024 Semi-annual Review","children":{}},"/updates/changelog/2024-whats-new-june":{"label":"What's New in June 2024","children":{}},"/updates/changelog/2024-whats-new-may":{"label":"What's New in May 2024","children":{}},"/updates/changelog/2024-community-meet-up":{"label":"Dwarves’ 2nd community offline meet-up","children":{}},"/updates/changelog/2024-whats-new-april":{"label":"What's New in April 2024","children":{}},"/updates/changelog/2024-whats-new-march":{"label":"What's New in March 2024","children":{}},"/updates/changelog/2024-whats-new-february":{"label":"What's New in February 2024","children":{}},"/updates/changelog/2024-whats-new-january":{"label":"What's New in January 2024","children":{}},"/updates/changelog/2023-whats-new-december":{"label":"What's New in December 2023","children":{}},"/updates/changelog/readme":{"label":"Changelog","children":{}},"/updates/changelog/2023-whats-new-november":{"label":"What's New in November 2023","children":{}},"/updates/changelog/2023-whats-new-october":{"label":"What's New in October 2023","children":{}},"/updates/changelog/2023-happy":{"label":"Happy 2023","children":{}},"/updates/changelog/2022-dwarves-of-the-year":{"label":"Dwarves Of The Year 2022","children":{}},"/updates/changelog/2022-in-review":{"label":"2022 In Review","children":{}},"/updates/changelog/2022-summit-engineering-a-good-time":{"label":"Summit 2022: Engineering A Good Time","children":{}},"/updates/changelog/road-to-100":{"label":"Road To 100","children":{}},"/updates/changelog/2022-whats-new-may":{"label":"What's New in May 2022","children":{}},"/updates/changelog/2022-whats-new-january":{"label":"What's New in January 2022","children":{}},"/updates/changelog/2021-whats-new-december":{"label":"What's New in December 2021","children":{}},"/updates/changelog/2021-dwarves-of-the-year":{"label":"Dwarves Of The Year 2021","children":{}},"/updates/changelog/2021-whats-new-july":{"label":"What's New in July 2021","children":{}},"/updates/changelog/2020-in-review":{"label":"2020 In Review","children":{}},"/updates/changelog/2021-in-review":{"label":"2021 In Review","children":{}},"/updates/changelog/2019-in-review":{"label":"2019 In Review","children":{}},"/updates/changelog/2018-in-review":{"label":"2018 In Review","children":{}}}},"/updates/ogif":{"label":"OGIF","children":{"/updates/ogif/41-20250314":{"label":"#41 ICY-BTC, GitHub Bot, MCP-DB, Pocket Turing","children":{}},"/updates/ogif/28-20241018":{"label":"#28 Go sync.Map, AI UX, Yelp AI, LLM Patterns, Git Analysis","children":{}},"/updates/ogif/27-20241011":{"label":"#27 Go weekly, Frontend, AI UX, Finite Automata","children":{}},"/updates/ogif/26-20241004":{"label":"#26 Design insights, Go tools, Trading app, Chatbots, Essays","children":{}},"/updates/ogif/25-20240927":{"label":"#25 Team updates, Hybrid work, AI insights, Go weekly","children":{}},"/updates/ogif/24-20240920":{"label":"#24 Go weekly, AI workflows, Team AI demo, Figma-UI with Claude","children":{}},"/updates/ogif/23-20240913":{"label":"#23 Go weekly, FE report, Hybrid work, AI agents","children":{}},"/updates/ogif/22-20240906":{"label":"#22 Hybrid work, Tech report, Go weekly, AI demo","children":{}},"/updates/ogif/21-20240830":{"label":"#21 Community engagement, Go weekly, Journey of thought for prompt engineering","children":{}},"/updates/ogif/20-20240823":{"label":"#20 Go weekly, Dynamic objects, Devbox, LLM tracing, Cursor AI","children":{}},"/updates/ogif/19-20240821":{"label":"#19 Go weekly, UI design, File sharing, Dify AI","children":{}},"/updates/ogif/18-20240809":{"label":"#18 Go weekly, RAG, UI, FE updates","children":{}},"/updates/ogif/17-20240802":{"label":"#17 Community Call July, C4 Model, Interview Life in the US","children":{}},"/updates/ogif/16-20240726":{"label":"#16 Go weekly, Dune query, AI voice clone, RAG re-ranking","children":{}},"/updates/ogif/15-20240719":{"label":"#15 AI Supervisors, Local-first Software, Code Completion, Bot Commands","children":{}},"/updates/ogif/14-20240712":{"label":"#14 Generic Collections, Pricing Models, and OGIF Summarizer","children":{}},"/updates/ogif/13-20240705":{"label":"#13 Go Weekly updates, Radix Sort, Human Feedback Mechanism, and effective ChatGPT usage","children":{}},"/updates/ogif/12-20240628":{"label":"#12 June updates, Go Performance, eBPF, PGO, Multimodal RAG","children":{}},"/updates/ogif/11-20240621":{"label":"#11 Design patterns: template method \u0026 visitor, Radix sort, and weekly tech commentary","children":{}},"/updates/ogif/10-20240614":{"label":"#10 Behavioral Patterns and Map Content Organization","children":{}},"/updates/ogif/9-20240607":{"label":"#9 What's next for June and Behavior Design Patterns","children":{}},"/updates/ogif/7-20240517":{"label":"#7 Echelon EXPO, Programming patterns, and Moonlighting","children":{}},"/updates/ogif/6-20240510":{"label":"#6 Factory Pattern, Erlang State Machines, and Trading Process","children":{}},"/updates/ogif/5-20240503":{"label":"#5 Singapore Market Report, C4 Modelling, Memo's Nested Sidebar","children":{}},"/updates/ogif/4-20240426":{"label":"#4 DCA, Devbox","children":{}},"/updates/ogif/3-20240419":{"label":"#3 Generative AI, Tokenomics, and Finance Talks","children":{}},"/updates/ogif/2-20240412":{"label":"#2 Devbox as the new Docker, Security Standards, and Understanding Liquidity","children":{}},"/updates/ogif/1-20240405":{"label":"#1 Markdown Presentations, Research Pipeline, Screenshots How-to","children":{}},"/updates/ogif/readme":{"label":"OGIF - Oh God It's Friday","children":{}}}},"/updates/forward-engineering":{"label":"Forward Engineering","children":{"/updates/forward-engineering/2024-2025":{"label":20242025,"children":{}},"/updates/forward-engineering/2024-quarter-3":{"label":"Quarter 3 2024","children":{}},"/updates/forward-engineering/2023-november":{"label":"November 2023","children":{}},"/updates/forward-engineering/2023-october":{"label":"October 2023","children":{}},"/updates/forward-engineering/2023-august":{"label":"August 2023","children":{}},"/updates/forward-engineering/2023-june":{"label":"June 2023","children":{}},"/updates/forward-engineering/2023-may":{"label":"May 2023","children":{}},"/updates/forward-engineering/2023-march":{"label":"March 2023","children":{}},"/updates/forward-engineering/2023-december":{"label":"December 2023","children":{}},"/updates/forward-engineering/2022":{"label":2022,"children":{}},"/updates/forward-engineering/tech-radar-volume-03":{"label":"Tech Radar Volume 03","children":{}},"/updates/forward-engineering/tech-radar-volume-02":{"label":"Tech Radar Volume 02","children":{}},"/updates/forward-engineering/tech-radar-volume-01":{"label":"Tech Radar Volume 01","children":{}},"/updates/forward-engineering/tech-radar-the-introduction":{"label":"Tech Radar Introduction","children":{}}}},"/updates/digest":{"label":"Digest","children":{"/updates/digest/15-new-year-gathering":{"label":"#15 New year gathering","children":{}},"/updates/digest/14-back-to-the-office":{"label":"#14 Hybrid work harmony","children":{}},"/updates/digest/13-more-than-lines-of-code":{"label":"#13 More than lines of code","children":{}},"/updates/digest/12-summer-moments":{"label":"#12 Summer moments","children":{}},"/updates/digest/11-come-grow-with-us":{"label":"#11 Come grow with us","children":{}},"/updates/digest/10-from-lean-to-learner":{"label":"#10 From lean to learner","children":{}},"/updates/digest/9-a-little-more-speed-for-summer":{"label":"#9 A little more speed for summer","children":{}},"/updates/digest/8-then-came-the-last-days-of-may":{"label":"#8 Then came the last days of May","children":{}},"/updates/digest/7-a-journey-through-time":{"label":"#7 A journey through time","children":{}},"/updates/digest/6-stay-for-the-culture":{"label":"#6 Come for the conversation, stay for the culture","children":{}},"/updates/digest/5-delay-the-gratification":{"label":"#5 Endure the hardship, delay the gratification","children":{}},"/updates/digest/4-finding-your-authentic-tribe":{"label":"#4 Finding your authentic tribe","children":{}},"/updates/digest/3-we-all-start-somewhere":{"label":"#3 We all start somewhere","children":{}},"/updates/digest/2-walk-around-learn-around":{"label":"#2 Walk around learn around","children":{}},"/updates/digest/1-what-do-you-stand-for":{"label":"#1 What do you stand for?","children":{}},"/updates/digest/readme":{"label":"Digest","children":{}}}},"/updates/newsletter":{"label":"Newsletter","children":{"/updates/newsletter/knowledge-base":{"label":"Build your knowledge base","children":{}},"/updates/newsletter/dwarve-updates-ai-llm":{"label":"The Stage of AI and LLM at Dwarves","children":{}},"/updates/newsletter/readme":{"label":"_base","children":{}},"/updates/newsletter/growth-stages":{"label":"The Stage of Growth at Dwarves","children":{}},"/updates/newsletter/the-next-leading-chairs":{"label":"The Next Leading Chairs","children":{}},"/updates/newsletter/blockchain-and-data":{"label":"The future is blockchain and data","children":{}},"/updates/newsletter/hiring-stages":{"label":"The stages of hiring at Dwarves","children":{}},"/updates/newsletter/2021-in-review":{"label":"It's a wrap: 2021 in Review","children":{}},"/updates/newsletter/engineering-org-structure":{"label":"Engineering Organizational Structure","children":{}},"/updates/newsletter/path-to-growth":{"label":"The Path To Growth at Dwarves","children":{}},"/updates/newsletter/engineer-performance-review":{"label":"Engineer Performance Review","children":{}},"/updates/newsletter/project-compliance":{"label":"Project Compliance","children":{}},"/updates/newsletter/dalat-office":{"label":"Da Lat Office","children":{}},"/updates/newsletter/dwarves-updates":{"label":"Dwarves Updates","children":{}}}},"/updates/culture-test":{"label":"Culture Test","children":{}},"/updates/fund":{"label":"Fund","children":{"/updates/fund/dwarves-ventures-fund-1":{"label":"Dwarves Ventures Fund 1","children":{}},"/updates/fund/dwarves-ventures-fund-0":{"label":"Dwarves Ventures Fund 0","children":{}}}}}}}},"/tags":{"label":"Popular Tags","children":{"/tags/ai":{"label":"#ai","children":{},"count":58},"/tags/hiring":{"label":"#hiring","children":{},"count":61},"/tags/case-study":{"label":"#case-study","children":{},"count":29},"/tags/handbook":{"label":"#handbook","children":{},"count":43},"/tags/business":{"label":"#business","children":{},"count":10},"/tags/growth":{"label":"#growth","children":{},"count":2},"/tags/consulting":{"label":"#consulting","children":{},"count":24},"/tags/market-report":{"label":"#market-report","children":{},"count":34},"/tags/tech-report":{"label":"#tech-report","children":{},"count":15},"/tags/software-development":{"label":"#software-development","children":{},"count":1},"/tags/database-management":{"label":"#database-management","children":{},"count":1},"/tags/icy":{"label":"#icy","children":{},"count":10},"/tags/career":{"label":"#career","children":{},"count":44},"/tags/full-stack":{"label":"#full-stack","children":{},"count":1},"/tags/engineer":{"label":"#engineer","children":{},"count":3},"/tags/ux-ui":{"label":"#ux-ui","children":{},"count":13},"/tags/product-design":{"label":"#product-design","children":{},"count":7},"/tags/report":{"label":"#report","children":{},"count":8},"/tags/checklist":{"label":"#checklist","children":{},"count":17},"/tags/presentation":{"label":"#presentation","children":{},"count":1},"/tags/business-development":{"label":"#business-development","children":{},"count":1},"/tags/database":{"label":"#database","children":{},"count":8},"/tags/sql":{"label":"#sql","children":{},"count":4},"/tags/data-modeling":{"label":"#data-modeling","children":{},"count":1},"/tags/data-engineering":{"label":"#data-engineering","children":{},"count":4},"/tags/system-design":{"label":"#system-design","children":{},"count":2},"/tags/architecture":{"label":"#architecture","children":{},"count":4},"/tags/etl":{"label":"#etl","children":{},"count":3},"/tags/automata":{"label":"#automata","children":{},"count":1},"/tags/fintech":{"label":"#fintech","children":{},"count":16},"/tags/mobile":{"label":"#mobile","children":{},"count":1},"/tags/wala":{"label":"#wala","children":{},"count":3},"/tags/fnb":{"label":"#fnb","children":{},"count":2},"/tags/film":{"label":"#film","children":{},"count":1},"/tags/go":{"label":"#go","children":{},"count":5},"/tags/error":{"label":"#error","children":{},"count":1},"/tags/startup":{"label":"#startup","children":{},"count":9},"/tags/shares":{"label":"#shares","children":{},"count":1},"/tags/founder":{"label":"#founder","children":{},"count":1},"/tags/entertainment":{"label":"#entertainment","children":{},"count":1},"/tags/life-at-dwarves":{"label":"#life-at-dwarves","children":{},"count":8},"/tags/hybrid-working":{"label":"#hybrid-working","children":{},"count":3},"/tags/guide":{"label":"#guide","children":{},"count":10},"/tags/security":{"label":"#security","children":{},"count":9},"/tags/reward":{"label":"#reward","children":{},"count":3},"/tags/team":{"label":"#team","children":{},"count":47},"/tags/community":{"label":"#community","children":{},"count":40},"/tags/design":{"label":"#design","children":{},"count":31},"/tags/ux":{"label":"#ux","children":{},"count":2},"/tags/directory-structure":{"label":"#directory-structure","children":{},"count":2},"/tags/file-management":{"label":"#file-management","children":{},"count":2},"/tags/file-system":{"label":"#file-system","children":{},"count":2},"/tags/permissions":{"label":"#permissions","children":{},"count":1},"/tags/database-modelling":{"label":"#database-modelling","children":{},"count":1},"/tags/people":{"label":"#people","children":{},"count":25},"/tags/operations":{"label":"#operations","children":{},"count":75},"/tags/llm":{"label":"#llm","children":{},"count":76},"/tags/rag":{"label":"#rag","children":{},"count":5},"/tags/search":{"label":"#search","children":{},"count":1},"/tags/evaluation":{"label":"#evaluation","children":{},"count":3},"/tags/project":{"label":"#project","children":{},"count":16},"/tags/billbyhours":{"label":"#billbyhours","children":{},"count":1},"/tags/careers":{"label":"#careers","children":{},"count":2},"/tags/engineering":{"label":"#engineering","children":{},"count":64},"/tags/delivery":{"label":"#delivery","children":{},"count":2},"/tags/subscription":{"label":"#subscription","children":{},"count":1},"/tags/pricing":{"label":"#pricing","children":{},"count":1},"/tags/product":{"label":"#product","children":{},"count":1},"/tags/blockchain":{"label":"#blockchain","children":{},"count":50},"/tags/evm":{"label":"#evm","children":{},"count":5},"/tags/foundry":{"label":"#foundry","children":{},"count":2},"/tags/search-engine":{"label":"#search-engine","children":{},"count":1},"/tags/duckdb":{"label":"#duckdb","children":{},"count":3},"/tags/transformers.js":{"label":"#transformers.js","children":{},"count":1},"/tags/hybrid-search":{"label":"#hybrid-search","children":{},"count":1},"/tags/erlang":{"label":"#erlang","children":{},"count":1},"/tags/elixir":{"label":"#elixir","children":{},"count":5},"/tags/fsm":{"label":"#fsm","children":{},"count":1},"/tags/design-pattern":{"label":"#design-pattern","children":{},"count":9},"/tags/gang-of-four":{"label":"#gang-of-four","children":{},"count":9},"/tags/observer-pattern":{"label":"#observer-pattern","children":{},"count":1},"/tags/behavior-pattern":{"label":"#behavior-pattern","children":{},"count":2},"/tags/visitor-design-pattern":{"label":"#visitor-design-pattern","children":{},"count":1},"/tags/strategy-design-pattern":{"label":"#strategy-design-pattern","children":{},"count":1},"/tags/ogif":{"label":"#ogif","children":{},"count":29},"/tags/guidelines":{"label":"#guidelines","children":{},"count":3},"/tags/feedback":{"label":"#feedback","children":{},"count":2},"/tags/mechanism":{"label":"#mechanism","children":{},"count":1},"/tags/local-first":{"label":"#local-first","children":{},"count":1},"/tags/crdt":{"label":"#crdt","children":{},"count":2},"/tags/data-synchronization":{"label":"#data-synchronization","children":{},"count":1},"/tags/data-ownership":{"label":"#data-ownership","children":{},"count":1},"/tags/real-time-collaboration":{"label":"#real-time-collaboration","children":{},"count":1},"/tags/rust":{"label":"#rust","children":{},"count":10},"/tags/trait":{"label":"#trait","children":{},"count":1},"/tags/error-handling":{"label":"#error-handling","children":{},"count":1},"/tags/data-structure":{"label":"#data-structure","children":{},"count":1},"/tags/bloom-filter":{"label":"#bloom-filter","children":{},"count":1},"/tags/big-o":{"label":"#big-o","children":{},"count":1},"/tags/behavioral-pattern":{"label":"#behavioral-pattern","children":{},"count":1},"/tags/golang":{"label":"#golang","children":{},"count":44},"/tags/behavior-patterns":{"label":"#behavior-patterns","children":{},"count":2},"/tags/algorithms":{"label":"#algorithms","children":{},"count":1},"/tags/sorting":{"label":"#sorting","children":{},"count":1},"/tags/network":{"label":"#network","children":{},"count":2},"/tags/machine-learning":{"label":"#machine-learning","children":{},"count":2},"/tags/zettelkasten":{"label":"#zettelkasten","children":{},"count":1},"/tags/prompt":{"label":"#prompt","children":{},"count":1},"/tags/chatgpt":{"label":"#chatgpt","children":{},"count":1},"/tags/solana":{"label":"#solana","children":{},"count":7},"/tags/amm":{"label":"#amm","children":{},"count":1},"/tags/memo":{"label":"#memo","children":{},"count":14},"/tags/instructions":{"label":"#instructions","children":{},"count":10},"/tags/guideline":{"label":"#guideline","children":{},"count":15},"/tags/ops":{"label":"#ops","children":{},"count":2},"/tags/nft":{"label":"#nft","children":{},"count":3},"/tags/workflow":{"label":"#workflow","children":{},"count":4},"/tags/recording":{"label":"#recording","children":{},"count":1},"/tags/history":{"label":"#history","children":{},"count":1},"/tags/creational-design-pattern":{"label":"#creational-design-pattern","children":{},"count":1},"/tags/moc":{"label":"#moc","children":{},"count":3},"/tags/software-design":{"label":"#software-design","children":{},"count":2},"/tags/software-architecture":{"label":"#software-architecture","children":{},"count":3},"/tags/graphical-notation":{"label":"#graphical-notation","children":{},"count":2},"/tags/energy":{"label":"#energy","children":{},"count":1},"/tags/techecosystem":{"label":"#techecosystem","children":{},"count":1},"/tags/summit":{"label":"#summit","children":{},"count":4},"/tags/crypto":{"label":"#crypto","children":{},"count":1},"/tags/content":{"label":"#content","children":{},"count":6},"/tags/investment":{"label":"#investment","children":{},"count":1},"/tags/personal-finance":{"label":"#personal-finance","children":{},"count":1},"/tags/dfg":{"label":"#dfg","children":{},"count":2},"/tags/tutorial":{"label":"#tutorial","children":{},"count":5},"/tags/standardization":{"label":"#standardization","children":{},"count":1},"/tags/work-adoption":{"label":"#work-adoption","children":{},"count":1},"/tags/research":{"label":"#research","children":{},"count":3},"/tags/field-notes":{"label":"#field-notes","children":{},"count":1},"/tags/innovation":{"label":"#innovation","children":{},"count":2},"/tags/radar":{"label":"#radar","children":{},"count":10},"/tags/bounty":{"label":"#bounty","children":{},"count":4},"/tags/communications":{"label":"#communications","children":{},"count":3},"/tags/token":{"label":"#token","children":{},"count":2},"/tags/brain":{"label":"#brain","children":{},"count":1},"/tags/knowledge-base":{"label":"#knowledge-base","children":{},"count":1},"/tags/engineering/data":{"label":"#engineering/data","children":{},"count":5},"/tags/data-pipeline":{"label":"#data-pipeline","children":{},"count":1},"/tags/vector-database":{"label":"#vector-database","children":{},"count":4},"/tags/partners":{"label":"#partners","children":{},"count":1},"/tags/brainery":{"label":"#brainery","children":{},"count":2},"/tags/devops":{"label":"#devops","children":{},"count":5},"/tags/google-cloud":{"label":"#google-cloud","children":{},"count":1},"/tags/google-data-studio":{"label":"#google-data-studio","children":{},"count":1},"/tags/google-data-fusion":{"label":"#google-data-fusion","children":{},"count":1},"/tags/reliability":{"label":"#reliability","children":{},"count":2},"/tags/cdap":{"label":"#cdap","children":{},"count":1},"/tags/data":{"label":"#data","children":{},"count":14},"/tags/google-dataproc":{"label":"#google-dataproc","children":{},"count":1},"/tags/hadoop":{"label":"#hadoop","children":{},"count":2},"/tags/streaming":{"label":"#streaming","children":{},"count":1},"/tags/earn":{"label":"#earn","children":{},"count":2},"/tags/ecommerce":{"label":"#ecommerce","children":{},"count":2},"/tags/dropshipping":{"label":"#dropshipping","children":{},"count":1},"/tags/dwarves":{"label":"#dwarves","children":{},"count":23},"/tags/work":{"label":"#work","children":{},"count":18},"/tags/internal":{"label":"#internal","children":{},"count":10},"/tags/discussion":{"label":"#discussion","children":{},"count":6},"/tags/event":{"label":"#event","children":{},"count":7},"/tags/labs":{"label":"#labs","children":{},"count":28},"/tags/catchup":{"label":"#catchup","children":{},"count":5},"/tags/policies":{"label":"#policies","children":{},"count":1},"/tags/home":{"label":"#home","children":{},"count":2},"/tags/tauri":{"label":"#tauri","children":{},"count":1},"/tags/htmx":{"label":"#htmx","children":{},"count":2},"/tags/frontend":{"label":"#frontend","children":{},"count":68},"/tags/performance":{"label":"#performance","children":{},"count":37},"/tags/culture":{"label":"#culture","children":{},"count":10},"/tags/emplpoyee":{"label":"#emplpoyee","children":{},"count":1},"/tags/estimation":{"label":"#estimation","children":{},"count":1},"/tags/code-generation":{"label":"#code-generation","children":{},"count":1},"/tags/typesafe":{"label":"#typesafe","children":{},"count":1},"/tags/fullstack":{"label":"#fullstack","children":{},"count":2},"/tags/lifeatdwarves":{"label":"#lifeatdwarves","children":{},"count":1},"/tags/craftsmanship":{"label":"#craftsmanship","children":{},"count":1},"/tags/workshop":{"label":"#workshop","children":{},"count":1},"/tags/demo":{"label":"#demo","children":{},"count":1},"/tags/performance-review":{"label":"#performance-review","children":{},"count":2},"/tags/assessment":{"label":"#assessment","children":{},"count":1},"/tags/knowledge":{"label":"#knowledge","children":{},"count":2},"/tags/tech-radar":{"label":"#tech-radar","children":{},"count":1},"/tags/evaluating-tech":{"label":"#evaluating-tech","children":{},"count":1},"/tags/process":{"label":"#process","children":{},"count":9},"/tags/updates":{"label":"#updates","children":{},"count":41},"/tags/distributed-system":{"label":"#distributed-system","children":{},"count":1},"/tags/data-types":{"label":"#data-types","children":{},"count":1},"/tags/data-structures":{"label":"#data-structures","children":{},"count":2},"/tags/client":{"label":"#client","children":{},"count":6},"/tags/guidline":{"label":"#guidline","children":{},"count":1},"/tags/playbook":{"label":"#playbook","children":{},"count":3},"/tags/software":{"label":"#software","children":{},"count":11},"/tags/framework":{"label":"#framework","children":{},"count":6},"/tags/productivity":{"label":"#productivity","children":{},"count":7},"/tags/learning":{"label":"#learning","children":{},"count":4},"/tags/system design":{"label":"#system design","children":{},"count":1},"/tags/enterprise":{"label":"#enterprise","children":{},"count":10},"/tags/australia":{"label":"#australia","children":{},"count":1},"/tags/sargable-queries":{"label":"#sargable-queries","children":{},"count":1},"/tags/zookeeper":{"label":"#zookeeper","children":{},"count":1},"/tags/kafka":{"label":"#kafka","children":{},"count":1},"/tags/sequential-reads":{"label":"#sequential-reads","children":{},"count":1},"/tags/sequential-writes":{"label":"#sequential-writes","children":{},"count":1},"/tags/random-reads":{"label":"#random-reads","children":{},"count":1},"/tags/random-writes":{"label":"#random-writes","children":{},"count":1},"/tags/url-redirect":{"label":"#url-redirect","children":{},"count":1},"/tags/url-rewrite":{"label":"#url-rewrite","children":{},"count":1},"/tags/http":{"label":"#http","children":{},"count":1},"/tags/seo":{"label":"#seo","children":{},"count":1},"/tags/dx":{"label":"#dx","children":{},"count":1},"/tags/machine learning":{"label":"#machine learning","children":{},"count":1},"/tags/r\u0026d":{"label":"#r\u0026d","children":{},"count":1},"/tags/web":{"label":"#web","children":{},"count":9},"/tags/micro-frontend":{"label":"#micro-frontend","children":{},"count":3},"/tags/backend":{"label":"#backend","children":{},"count":4},"/tags/tool":{"label":"#tool","children":{},"count":3},"/tags/technique":{"label":"#technique","children":{},"count":9},"/tags/vietnam":{"label":"#vietnam","children":{},"count":1},"/tags/write-heavy":{"label":"#write-heavy","children":{},"count":1},"/tags/inventory-platform":{"label":"#inventory-platform","children":{},"count":1},"/tags/scalability":{"label":"#scalability","children":{},"count":1},"/tags/doordash":{"label":"#doordash","children":{},"count":1},"/tags/low-latency":{"label":"#low-latency","children":{},"count":1},"/tags/observability":{"label":"#observability","children":{},"count":5},"/tags/teamwork":{"label":"#teamwork","children":{},"count":2},"/tags/leadership":{"label":"#leadership","children":{},"count":4},"/tags/multi-column-index":{"label":"#multi-column-index","children":{},"count":1},"/tags/index":{"label":"#index","children":{},"count":1},"/tags/composite-index":{"label":"#composite-index","children":{},"count":1},"/tags/react":{"label":"#react","children":{},"count":15},"/tags/hooks":{"label":"#hooks","children":{},"count":2},"/tags/components":{"label":"#components","children":{},"count":1},"/tags/scrum":{"label":"#scrum","children":{},"count":2},"/tags/technicaldebt":{"label":"#technicaldebt","children":{},"count":1},"/tags/projectmanagement":{"label":"#projectmanagement","children":{},"count":1},"/tags/email":{"label":"#email","children":{},"count":22},"/tags/decoder":{"label":"#decoder","children":{},"count":1},"/tags/json":{"label":"#json","children":{},"count":1},"/tags/materialized-view":{"label":"#materialized-view","children":{},"count":1},"/tags/data-warehouse":{"label":"#data-warehouse","children":{},"count":1},"/tags/mapreduce":{"label":"#mapreduce","children":{},"count":1},"/tags/distributed":{"label":"#distributed","children":{},"count":3},"/tags/form":{"label":"#form","children":{},"count":1},"/tags/uilibraries":{"label":"#uilibraries","children":{},"count":1},"/tags/migrations":{"label":"#migrations","children":{},"count":1},"/tags/agile":{"label":"#agile","children":{},"count":6},"/tags/behavior-driven-development":{"label":"#behavior-driven-development","children":{},"count":1},"/tags/testing":{"label":"#testing","children":{},"count":4},"/tags/ubiquitous-language":{"label":"#ubiquitous-language","children":{},"count":1},"/tags/forward-proxy":{"label":"#forward-proxy","children":{},"count":1},"/tags/payment":{"label":"#payment","children":{},"count":1},"/tags/apprenticeship":{"label":"#apprenticeship","children":{},"count":4},"/tags/remote":{"label":"#remote","children":{},"count":12},"/tags/showcase":{"label":"#showcase","children":{},"count":1},"/tags/practice":{"label":"#practice","children":{},"count":6},"/tags/senior":{"label":"#senior","children":{},"count":1},"/tags/internship":{"label":"#internship","children":{},"count":4},"/tags/swap":{"label":"#swap","children":{},"count":2},"/tags/quant":{"label":"#quant","children":{},"count":1},"/tags/radio":{"label":"#radio","children":{},"count":3},"/tags/writing":{"label":"#writing","children":{},"count":1},"/tags/english":{"label":"#english","children":{},"count":1},"/tags/apprentice":{"label":"#apprentice","children":{},"count":1},"/tags/designer":{"label":"#designer","children":{},"count":1},"/tags/meeting":{"label":"#meeting","children":{},"count":4},"/tags/us":{"label":"#us","children":{},"count":4},"/tags/mbti":{"label":"#mbti","children":{},"count":6},"/tags/intj":{"label":"#intj","children":{},"count":1},"/tags/istp":{"label":"#istp","children":{},"count":1},"/tags/estj":{"label":"#estj","children":{},"count":1},"/tags/istj":{"label":"#istj","children":{},"count":1},"/tags/personalities":{"label":"#personalities","children":{},"count":1},"/tags/management":{"label":"#management","children":{},"count":4},"/tags/early-stage":{"label":"#early-stage","children":{},"count":3},"/tags/design-thinking":{"label":"#design-thinking","children":{},"count":2},"/tags/healthcare":{"label":"#healthcare","children":{},"count":1},"/tags/browser-extension":{"label":"#browser-extension","children":{},"count":2},"/tags/git":{"label":"#git","children":{},"count":2},"/tags/marketplace":{"label":"#marketplace","children":{},"count":2},"/tags/tips":{"label":"#tips","children":{},"count":10},"/tags/real-estate":{"label":"#real-estate","children":{},"count":1},"/tags/nocode":{"label":"#nocode","children":{},"count":1},"/tags/hospitality":{"label":"#hospitality","children":{},"count":1},"/tags/ride-hailing":{"label":"#ride-hailing","children":{},"count":1},"/tags/iot":{"label":"#iot","children":{},"count":1},"/tags/macos":{"label":"#macos","children":{},"count":3},"/tags/swift":{"label":"#swift","children":{},"count":7},"/tags/partnership":{"label":"#partnership","children":{},"count":1},"/tags/pm":{"label":"#pm","children":{},"count":4},"/tags/travel":{"label":"#travel","children":{},"count":1},"/tags/operation":{"label":"#operation","children":{},"count":7},"/tags/idea":{"label":"#idea","children":{},"count":1},"/tags/ventures":{"label":"#ventures","children":{},"count":3},"/tags/purpose":{"label":"#purpose","children":{},"count":2},"/tags/wasm":{"label":"#wasm","children":{},"count":2},"/tags/transparency":{"label":"#transparency","children":{},"count":1},"/tags/event-sourcing":{"label":"#event-sourcing","children":{},"count":1},"/tags/sdlc":{"label":"#sdlc","children":{},"count":1},"/tags/modeling":{"label":"#modeling","children":{},"count":2},"/tags/goal":{"label":"#goal","children":{},"count":2},"/tags/license":{"label":"#license","children":{},"count":1},"/tags/template":{"label":"#template","children":{},"count":20},"/tags/k8s":{"label":"#k8s","children":{},"count":1},"/tags/js":{"label":"#js","children":{},"count":2},"/tags/clojure":{"label":"#clojure","children":{},"count":1},"/tags/react.js":{"label":"#react.js","children":{},"count":2},"/tags/employee":{"label":"#employee","children":{},"count":2},"/tags/onboarding":{"label":"#onboarding","children":{},"count":1},"/tags/company":{"label":"#company","children":{},"count":1},"/tags/tooling":{"label":"#tooling","children":{},"count":9},"/tags/human-resource":{"label":"#human-resource","children":{},"count":1},"/tags/dcos":{"label":"#dcos","children":{},"count":5},"/tags/docker":{"label":"#docker","children":{},"count":11},"/tags/okr":{"label":"#okr","children":{},"count":1},"/tags/oss":{"label":"#oss","children":{},"count":1},"/tags/newsletter":{"label":"#newsletter","children":{},"count":45},"/tags/web3":{"label":"#web3","children":{},"count":4},"/tags/mcp":{"label":"#mcp","children":{},"count":3},"/tags/overleaf":{"label":"#overleaf","children":{},"count":1},"/tags/slide":{"label":"#slide","children":{},"count":1},"/tags/office-hours":{"label":"#office-hours","children":{},"count":28},"/tags/discord":{"label":"#discord","children":{},"count":35},"/tags/btc":{"label":"#btc","children":{},"count":1},"/tags/forward-engineering":{"label":"#forward-engineering","children":{},"count":14},"/tags/tech-community":{"label":"#tech-community","children":{},"count":1},"/tags/weekly-digest":{"label":"#weekly-digest","children":{},"count":15},"/tags/wrap-up":{"label":"#wrap-up","children":{},"count":7},"/tags/real-time":{"label":"#real-time","children":{},"count":1},"/tags/phoenix-live-view":{"label":"#phoenix-live-view","children":{},"count":1},"/tags/timescaledb":{"label":"#timescaledb","children":{},"count":1},"/tags/go-weekly":{"label":"#go-weekly","children":{},"count":24},"/tags/finance":{"label":"#finance","children":{},"count":1},"/tags/protocol":{"label":"#protocol","children":{},"count":1},"/tags/agents":{"label":"#agents","children":{},"count":4},"/tags/monitoring":{"label":"#monitoring","children":{},"count":1},"/tags/defi":{"label":"#defi","children":{},"count":2},"/tags/aider":{"label":"#aider","children":{},"count":2},"/tags/qwen2.5":{"label":"#qwen2.5","children":{},"count":1},"/tags/openhand":{"label":"#openhand","children":{},"count":1},"/tags/predicted output":{"label":"#predicted output","children":{},"count":1},"/tags/project-management":{"label":"#project-management","children":{},"count":1},"/tags/copilots":{"label":"#copilots","children":{},"count":2},"/tags/team-management":{"label":"#team-management","children":{},"count":1},"/tags/mongodb":{"label":"#mongodb","children":{},"count":1},"/tags/salesforce":{"label":"#salesforce","children":{},"count":1},"/tags/use cases":{"label":"#use cases","children":{},"count":2},"/tags/design-system":{"label":"#design-system","children":{},"count":1},"/tags/storybook":{"label":"#storybook","children":{},"count":1},"/tags/hook":{"label":"#hook","children":{},"count":1},"/tags/cline":{"label":"#cline","children":{},"count":1},"/tags/realtime api":{"label":"#realtime api","children":{},"count":1},"/tags/interface":{"label":"#interface","children":{},"count":1},"/tags/import":{"label":"#import","children":{},"count":1},"/tags/package":{"label":"#package","children":{},"count":1},"/tags/yelp":{"label":"#yelp","children":{},"count":1},"/tags/generics":{"label":"#generics","children":{},"count":2},"/tags/log":{"label":"#log","children":{},"count":1},"/tags/pillar":{"label":"#pillar","children":{},"count":3},"/tags/metric":{"label":"#metric","children":{},"count":1},"/tags/tracing":{"label":"#tracing","children":{},"count":1},"/tags/intent-classification":{"label":"#intent-classification","children":{},"count":1},"/tags/prompting":{"label":"#prompting","children":{},"count":1},"/tags/changelog":{"label":"#changelog","children":{},"count":1},"/tags/test":{"label":"#test","children":{},"count":1},"/tags/language":{"label":"#language","children":{},"count":5},"/tags/ai-agents":{"label":"#ai-agents","children":{},"count":2},"/tags/ai-evaluation":{"label":"#ai-evaluation","children":{},"count":1},"/tags/prompt-engineering":{"label":"#prompt-engineering","children":{},"count":4},"/tags/ai-integration":{"label":"#ai-integration","children":{},"count":1},"/tags/networking":{"label":"#networking","children":{},"count":7},"/tags/finite-automata":{"label":"#finite-automata","children":{},"count":1},"/tags/pattern-matching":{"label":"#pattern-matching","children":{},"count":1},"/tags/state-machines":{"label":"#state-machines","children":{},"count":1},"/tags/java":{"label":"#java","children":{},"count":1},"/tags/programming":{"label":"#programming","children":{},"count":1},"/tags/caching":{"label":"#caching","children":{},"count":1},"/tags/devbox":{"label":"#devbox","children":{},"count":17},"/tags/nix":{"label":"#nix","children":{},"count":9},"/tags/generative-ui":{"label":"#generative-ui","children":{},"count":1},"/tags/function-calling":{"label":"#function-calling","children":{},"count":1},"/tags/ton":{"label":"#ton","children":{},"count":2},"/tags/ai-powered":{"label":"#ai-powered","children":{},"count":1},"/tags/pattern":{"label":"#pattern","children":{},"count":1},"/tags/supervisor-architecture":{"label":"#supervisor-architecture","children":{},"count":1},"/tags/document-processing":{"label":"#document-processing","children":{},"count":1},"/tags/information-retrieval":{"label":"#information-retrieval","children":{},"count":1},"/tags/iterators":{"label":"#iterators","children":{},"count":1},"/tags/reinforcement-learning":{"label":"#reinforcement-learning","children":{},"count":3},"/tags/kernel-programing":{"label":"#kernel-programing","children":{},"count":1},"/tags/anchor":{"label":"#anchor","children":{},"count":2},"/tags/containerization":{"label":"#containerization","children":{},"count":4},"/tags/virtualization":{"label":"#virtualization","children":{},"count":4},"/tags/meet-up":{"label":"#meet-up","children":{},"count":4},"/tags/meetup":{"label":"#meetup","children":{},"count":2},"/tags/motivation":{"label":"#motivation","children":{},"count":1},"/tags/cybersecurity":{"label":"#cybersecurity","children":{},"count":2},"/tags/serverless":{"label":"#serverless","children":{},"count":1},"/tags/doty":{"label":"#doty","children":{},"count":5},"/tags/websocket":{"label":"#websocket","children":{},"count":1},"/tags/protocols":{"label":"#protocols","children":{},"count":1},"/tags/nextjs":{"label":"#nextjs","children":{},"count":2},"/tags/open-source":{"label":"#open-source","children":{},"count":2},"/tags/rendering":{"label":"#rendering","children":{},"count":1},"/tags/dom":{"label":"#dom","children":{},"count":3},"/tags/cssom":{"label":"#cssom","children":{},"count":1},"/tags/render-tree":{"label":"#render-tree","children":{},"count":1},"/tags/iframe":{"label":"#iframe","children":{},"count":1},"/tags/postmessage":{"label":"#postmessage","children":{},"count":1},"/tags/mock-service-worker":{"label":"#mock-service-worker","children":{},"count":1},"/tags/api-mocking":{"label":"#api-mocking","children":{},"count":1},"/tags/web-development-tool":{"label":"#web-development-tool","children":{},"count":1},"/tags/data-fetching":{"label":"#data-fetching","children":{},"count":1},"/tags/frontend,":{"label":"#frontend,","children":{},"count":1},"/tags/graphql":{"label":"#graphql","children":{},"count":1},"/tags/reactjs":{"label":"#reactjs","children":{},"count":2},"/tags/scroll-driven-animations":{"label":"#scroll-driven-animations","children":{},"count":1},"/tags/animations":{"label":"#animations","children":{},"count":1},"/tags/intersection-observer":{"label":"#intersection-observer","children":{},"count":1},"/tags/server-component":{"label":"#server-component","children":{},"count":1},"/tags/caching-data":{"label":"#caching-data","children":{},"count":1},"/tags/social-networks":{"label":"#social-networks","children":{},"count":1},"/tags/foundation-model":{"label":"#foundation-model","children":{},"count":1},"/tags/fine-tuning":{"label":"#fine-tuning","children":{},"count":1},"/tags/vector database":{"label":"#vector database","children":{},"count":1},"/tags/shadow-dom":{"label":"#shadow-dom","children":{},"count":1},"/tags/web-api":{"label":"#web-api","children":{},"count":1},"/tags/swr-infinite":{"label":"#swr-infinite","children":{},"count":1},"/tags/web-design":{"label":"#web-design","children":{},"count":1},"/tags/tuning-llm":{"label":"#tuning-llm","children":{},"count":2},"/tags/langchain":{"label":"#langchain","children":{},"count":1},"/tags/translation":{"label":"#translation","children":{},"count":1},"/tags/profiling":{"label":"#profiling","children":{},"count":1},"/tags/state-mangement":{"label":"#state-mangement","children":{},"count":1},"/tags/global-state-management":{"label":"#global-state-management","children":{},"count":1},"/tags/css":{"label":"#css","children":{},"count":5},"/tags/fonts":{"label":"#fonts","children":{},"count":1},"/tags/variable-fonts":{"label":"#variable-fonts","children":{},"count":1},"/tags/state-management":{"label":"#state-management","children":{},"count":2},"/tags/component":{"label":"#component","children":{},"count":1},"/tags/proof-of-knowledge":{"label":"#proof-of-knowledge","children":{},"count":1},"/tags/fronten":{"label":"#fronten","children":{},"count":1},"/tags/typescript":{"label":"#typescript","children":{},"count":4},"/tags/analytics-tools":{"label":"#analytics-tools","children":{},"count":1},"/tags/analytics-platform":{"label":"#analytics-platform","children":{},"count":1},"/tags/software engineer":{"label":"#software engineer","children":{},"count":1},"/tags/parsing":{"label":"#parsing","children":{},"count":1},"/tags/technology":{"label":"#technology","children":{},"count":5},"/tags/validation":{"label":"#validation","children":{},"count":1},"/tags/webassembly":{"label":"#webassembly","children":{},"count":1},"/tags/sandbox":{"label":"#sandbox","children":{},"count":1},"/tags/zk-rollup":{"label":"#zk-rollup","children":{},"count":2},"/tags/polygon":{"label":"#polygon","children":{},"count":1},"/tags/starknet":{"label":"#starknet","children":{},"count":1},"/tags/ethereum":{"label":"#ethereum","children":{},"count":2},"/tags/zero-knowledge":{"label":"#zero-knowledge","children":{},"count":1},"/tags/atomic-css":{"label":"#atomic-css","children":{},"count":1},"/tags/client-side":{"label":"#client-side","children":{},"count":1},"/tags/storage":{"label":"#storage","children":{},"count":1},"/tags/frontend/performance":{"label":"#frontend/performance","children":{},"count":2},"/tags/wai-aria":{"label":"#wai-aria","children":{},"count":1},"/tags/accessibility":{"label":"#accessibility","children":{},"count":4},"/tags/polymorphic-component":{"label":"#polymorphic-component","children":{},"count":1},"/tags/threejs":{"label":"#threejs","children":{},"count":1},"/tags/web-performance":{"label":"#web-performance","children":{},"count":2},"/tags/html":{"label":"#html","children":{},"count":4},"/tags/animation":{"label":"#animation","children":{},"count":1},"/tags/zk-proof":{"label":"#zk-proof","children":{},"count":1},"/tags/guides":{"label":"#guides","children":{},"count":1},"/tags/responsive-design":{"label":"#responsive-design","children":{},"count":1},"/tags/hsl":{"label":"#hsl","children":{},"count":1},"/tags/javascript":{"label":"#javascript","children":{},"count":4},"/tags/css-in-js":{"label":"#css-in-js","children":{},"count":1},"/tags/tip":{"label":"#tip","children":{},"count":1},"/tags/dark-mode":{"label":"#dark-mode","children":{},"count":1},"/tags/multisign-wallet":{"label":"#multisign-wallet","children":{},"count":1},"/tags/virtual-dom":{"label":"#virtual-dom","children":{},"count":1},"/tags/native-modules":{"label":"#native-modules","children":{},"count":1},"/tags/vitejs":{"label":"#vitejs","children":{},"count":1},"/tags/esm":{"label":"#esm","children":{},"count":1},"/tags/modules":{"label":"#modules","children":{},"count":1},"/tags/blockchain-bridge":{"label":"#blockchain-bridge","children":{},"count":1},"/tags/foundational-topics":{"label":"#foundational-topics","children":{},"count":5},"/tags/distributed-systems":{"label":"#distributed-systems","children":{},"count":1},"/tags/pos":{"label":"#pos","children":{},"count":1},"/tags/smart-contract":{"label":"#smart-contract","children":{},"count":1},"/tags/atomic-design":{"label":"#atomic-design","children":{},"count":1},"/tags/a11y":{"label":"#a11y","children":{},"count":1},"/tags/useeffect":{"label":"#useeffect","children":{},"count":1},"/tags/concurrency":{"label":"#concurrency","children":{},"count":2},"/tags/parallelism":{"label":"#parallelism","children":{},"count":1},"/tags/liquidity":{"label":"#liquidity","children":{},"count":1},"/tags/engineering/frontend":{"label":"#engineering/frontend","children":{},"count":1},"/tags/funding":{"label":"#funding","children":{},"count":2},"/tags/wfh":{"label":"#wfh","children":{},"count":1},"/tags/tech radar":{"label":"#tech radar","children":{},"count":1},"/tags/policy":{"label":"#policy","children":{},"count":1},"/tags/vim":{"label":"#vim","children":{},"count":1}}}},"content":"\u003cp\u003e\u003cstrong\u003eTopic Highlights\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eGo Weekly #16\u003c/strong\u003e: Phat discussed concurrent data structures in Go, focusing on \u003ccode\u003esync.Map\u003c/code\u003e. He explored its structure, use cases, and performance trade-offs in high-read, low-write scenarios. He also touched on garbage collection issues reported by the Go team.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGenerative AI UX Design Patterns\u003c/strong\u003e: Nam presented on UX design patterns for AI integration, covering System Scope Relationship, Spatial Relationship, and Functional Relationship. He explained how AI can be incorporated at various levels in digital products and discussed different ways to present AI features in user interfaces.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eYelp Usecase AI\u003c/strong\u003e: Dat presented real-world AI use cases from Yelp, explaining how AI is used for recommendation systems, text editing, and image summarization. He explored AI applications in generating datasets, spam detection, and auto-generating short video reviews for restaurants.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLLM Pattern\u003c/strong\u003e: Hoang introduced design patterns for integrating LLMs (Large Language Models) into applications. Key patterns included in-context learning, data preprocessing, and multi-agent collaboration, highlighting their practical use in AI-powered systems.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDify Git Analyze\u003c/strong\u003e: Cat demonstrated a Git repository analysis tool built using Dify. The tool scrapes content from repositories and supports diagram generation for code structure analysis, with a focus on optimizing the knowledge retrieval process in large datasets\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cstrong\u003eVietnamese Transcript\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e0:28\u003c/strong\u003e Chủ đề hôm nay vẫn có Go Weekly, và Nam đang thử nghiệm phần commentary về thiết kế hàng tuần. Chúng ta sẽ theo dõi trong vài tuần tới xem nội dung như thế nào.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e11:19\u003c/strong\u003e Nam sẽ trình bày tiếp cho anh em, và sau đó sẽ có một vài bài của Hoàng, Cát, Đạt. Chúng ta đang nghiên cứu về các trường hợp sử dụng mà các công ty khác đang áp dụng, hoặc các công cụ mà dev đang sử dụng, và có thể sẽ mở một bài chia sẻ trong tuần này hoặc tuần sau. Bài hôm nay sẽ xoay quanh việc tạo một nút thiết kế UX. Trước đây, có rất nhiều câu hỏi về phạm vi mà AI đang áp dụng và vai trò của nó sẽ như thế nào – liệu nó chỉ đóng góp như một thành phần nhỏ riêng lẻ hay là cả một ứng dụng trong các sản phẩm số. Hôm nay, em sẽ giải đáp thắc mắc đó, tức là AI đang đóng vai trò như thế nào và cách thức hoạt động của nó ra sao.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e12:11\u003c/strong\u003e Đầu tiên, em sẽ nói về \"System Scope Relationship.\" Hình ảnh này sẽ mô tả AI được tích hợp vào các hệ thống ở nhiều cấp độ khác nhau, từ một thành phần nhỏ lẻ đến một hệ sinh thái toàn diện hơn. AI có thể chỉ là một phần nhỏ trong một thành phần hoặc có thể phát triển thành các tính năng lớn hơn, giúp tự động hóa nhiều chức năng. Điều này sẽ giúp người dùng trải nghiệm ứng dụng dễ dàng hơn. AI có thể đóng vai trò trong bất kỳ phần nào của sản phẩm số – từ thành phần, luồng xử lý, tính năng cho đến toàn bộ ứng dụng, hoặc thậm chí là một nền tảng hoặc hệ sinh thái.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e12:53\u003c/strong\u003e Ví dụ, trong một ứng dụng, AI có thể đóng vai trò một tính năng nhỏ, giúp người dùng thao tác nhanh hơn thay vì phải làm thủ công. Hoặc AI có thể là toàn bộ một ứng dụng như ChatGPT, nơi toàn bộ ứng dụng được xây dựng trên nền tảng AI, phục vụ cho một mục đích nhất định. Hoặc AI có thể là một nền tảng như Rewind AI, với nhiều tính năng hỗ trợ AI cho nhiều công việc khác nhau trong cùng một ứng dụng. Đây là phạm vi của AI trong các sản phẩm hiện nay.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e13:39\u003c/strong\u003e Tiếp theo, về \"Spatial Relationship,\" phần này giúp chúng ta hiểu về cách tính năng AI được bố trí và sắp xếp trong giao diện người dùng (UI). Có nhiều cách để tích hợp AI vào thiết kế, và quan trọng là làm sao để bố trí chúng sao cho hợp lý, tối ưu trải nghiệm người dùng mà không gây rối mắt hay phức tạp giao diện. Spatial Relationship ảnh hưởng trực tiếp đến trải nghiệm người dùng. Ví dụ, AI có thể hoạt động độc lập hoặc song song với các tính năng khác, nhưng vẫn giữ không gian riêng của mình. Khi hiểu được các mối quan hệ này, chúng ta có thể chọn cách sử dụng và sắp xếp tính năng AI một cách tối ưu, không gây phân tâm cho người dùng.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e15:11\u003c/strong\u003e Có sáu cách để trình bày tính năng AI, bao gồm:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eSeparate\u003c/strong\u003e: AI hoạt động độc lập.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAlongside\u003c/strong\u003e: AI được đặt bên cạnh các tính năng khác.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLayer\u003c/strong\u003e: AI hoạt động dưới dạng lớp phủ.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eIntegrated Parent\u003c/strong\u003e: AI đóng vai trò chính trong điều hướng hoặc quản lý nội dung chính.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eIntegrated Child\u003c/strong\u003e: AI đóng vai trò nhỏ hơn, bổ trợ cho tính năng chính.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePoint\u003c/strong\u003e: AI chỉ xuất hiện như một biểu tượng nhỏ, giúp người dùng hiểu thêm về cách nó hoạt động.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e16:41\u003c/strong\u003e Tiếp theo là \"Functional Relationship,\" phần này mô tả các mối quan hệ chức năng giữa AI và các tính năng khác trong hệ thống. AI có thể tồn tại độc lập nhưng vẫn adapt (thích nghi) với các nội dung và tính năng của hệ thống ở mức cao hơn. AI có thể tích hợp với các tính năng hiện có để cải thiện hiệu suất, thay vì người dùng phải thao tác thủ công. Khi hiểu rõ cách hoạt động chức năng của AI, chúng ta sẽ xác định rõ vai trò của nó trong ứng dụng và thiết kế để các hành động chức năng của nó không bị xung đột, cũng như không làm gián đoạn luồng sử dụng của người dùng.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e17:28\u003c/strong\u003e Có sáu cách để mô tả mối quan hệ chức năng của AI:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eSeparate\u003c/strong\u003e: AI hoạt động riêng biệt.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAware Of\u003c/strong\u003e: AI tách biệt nhưng có khả năng nhận biết các thay đổi trong tính năng chính.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eActing Up\u003c/strong\u003e: AI tương tác qua lại giữa các tính năng.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFeature Incorporate\u003c/strong\u003e: AI được tích hợp như một phần của một tính năng hiện có.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eUsage\u003c/strong\u003e: AI được sử dụng theo cách mà nó tương tác với các phần khác trong ứng dụng.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eUsage Conventionally\u003c/strong\u003e: AI tương tác hai chiều với các tính năng khác một cách trực tiếp.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e18:14\u003c/strong\u003e Nó sẽ không ảnh hưởng trực tiếp đến tính năng chính, nhưng nó sẽ có tác động qua lại với AI và từ đó giúp cải thiện tính năng chính. Đây là một ví dụ cụ thể hơn về cách sử dụng của nó, chẳng hạn như trong code này có thể generate một panel bên phải.\u003c/p\u003e\n\u003cp\u003eTiếp theo là \u003cstrong\u003eActing Up\u003c/strong\u003e, nghĩa là hai bên sẽ có tác động qua lại, có thể trao đổi dữ liệu qua lại với nhau. Ví dụ, tính năng A có thể hiểu được dữ liệu từ tính năng B và ngược lại. Các dữ liệu này sẽ được trao đổi qua lại liên tục để cải thiện sự tương tác.\u003c/p\u003e\n\u003cp\u003eTiếp theo là \u003cstrong\u003eFeature Incorporate\u003c/strong\u003e, nghĩa là AI được tích hợp trực tiếp vào các tính năng hiện có của ứng dụng. Cuối cùng là \u003cstrong\u003eUsage Conventionally\u003c/strong\u003e, nghĩa là AI sẽ tương tác theo cách thông thường với các tính năng khác, giống như cách các ứng dụng truyền thống hoạt động.\u003c/p\u003e\n\u003cp\u003eVí dụ như khi bạn dùng một ứng dụng và có nhiều tính năng khác nhau, AI sẽ đóng vai trò trong các phần như feature, nhưng không phải lúc nào cũng là phần chính, mà sẽ đóng vai trò bổ trợ.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e19:06\u003c/strong\u003e Ví dụ khác là ứng dụng Quora hay các ứng dụng khác, AI sẽ có nhiều tính năng nhỏ được tích hợp vào, như kiểu gợi ý trả lời câu hỏi, giúp người dùng thực hiện các tác vụ dễ dàng hơn. Vậy là nãy giờ em đã đi qua ba phần chính:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eSystem Scope\u003c/strong\u003e: Giới thiệu cách AI tích hợp vào sản phẩm.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSpatial Relationship\u003c/strong\u003e: Giới thiệu cách sắp xếp AI trong giao diện người dùng.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFunctional Relationship\u003c/strong\u003e: Giới thiệu các mối quan hệ chức năng giữa AI và các tính năng khác.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eNhững phần này giúp tối ưu hóa sản phẩm, cải thiện trải nghiệm người dùng và nâng cao hiệu quả cho ứng dụng AI.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e19:57\u003c/strong\u003e Điều này rất quan trọng bởi vì nếu mình hiểu rõ cách áp dụng AI, tính năng mình làm sẽ mang lại nhiều giá trị hơn cho người dùng. Ví dụ mà em quên chưa nhắc đến là phần \"separate.\" Em đã đưa ra một số ví dụ, nhưng để quay lại một chút về \"separate\" – tính năng AI hoạt động độc lập. Mình có thể xem xét trường hợp Microsoft có một cái slider để generate hình ảnh song song với tính năng khác. Hoặc với một ứng dụng như Shopee, AI sẽ đóng vai trò hỗ trợ bên cạnh tính năng chính của ứng dụng.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e20:53\u003c/strong\u003e Đó là những ví dụ minh họa cho việc sắp xếp và bố trí AI trong giao diện và sản phẩm. Anh Thành có thấy phần này như thế nào? Em thấy nó giống với các patterns thông thường trong thiết kế.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e22:01\u003c/strong\u003e Anh Thành: Đúng rồi, những cái này là các mẫu patterns mình hay dùng trong việc thiết kế ứng dụng AI, hoặc khi tích hợp AI vào một ứng dụng hoặc sản phẩm riêng biệt. Về cơ bản, nó là những cấu trúc quen thuộc để mình hiểu rõ hơn về cách áp dụng AI. Em có thể phân loại, chia nhỏ chúng ra thành những tính năng nhỏ hơn. Phần này rất rõ ràng.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e23:31\u003c/strong\u003e Cảm ơn Nam. Ok, tiếp theo là bài của Hoàng và Đạt nhé.\u003c/p\u003e\n\u003cp\u003eHôm nay, em sẽ giới thiệu một bài gọi là \"AI Button trong các ứng dụng LLM.\" Trước khi vào bài, em sẽ nói qua về nội dung và agenda. Đầu tiên là chúng ta sẽ tìm hiểu về các design patterns liên quan đến AI Button. Những cái pattern này được áp dụng trong nhiều ứng dụng khác nhau. Em sẽ lấy ra những cái phổ biến và dễ hiểu nhất để giới thiệu cho mọi người.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e24:35\u003c/strong\u003e Bài này sẽ xoay quanh việc sử dụng ứng dụng AI trong các sản phẩm số. Ứng dụng này tận dụng sức mạnh của các mô hình AI để giải quyết các bài toán cụ thể hoặc hỗ trợ người dùng trong các tác vụ. Khi sử dụng LLM, nhiều người có thể gặp vấn đề là mô hình không đưa ra đúng kết quả như mong đợi. Điều này là do bản chất của các mô hình này chỉ dựa trên khả năng phản hồi dựa trên chuỗi dữ liệu. Có nhiều cách để giải quyết vấn đề này. Một trong những cách tốn kém nhất là phải điều chỉnh lại toàn bộ mô hình từ đầu. Điều này có thể mất nhiều thời gian và nguồn lực.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e25:15\u003c/strong\u003e Mình có một cách gọi là \u003cstrong\u003ein-context learning\u003c/strong\u003e, có nghĩa là AI có thể học trực tiếp ngay trong ngữ cảnh hiện tại khi bạn đang sử dụng nó. Đây là một kỹ thuật như là few-shot learning hoặc zero-shot learning, giúp AI tự học mà không cần phải được huấn luyện lại từ đầu. Ví dụ, bạn chỉ cần cho AI một vài ví dụ nhỏ trong ngữ cảnh và nó sẽ tự điều chỉnh cách hoạt động của mình dựa trên những gì được cung cấp. Thay vì phải retrain toàn bộ mô hình, cách này giúp tiết kiệm thời gian và tài nguyên rất nhiều, và nó vẫn đảm bảo AI có thể học từ ngữ cảnh cụ thể mà bạn cung cấp.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e25:52\u003c/strong\u003e Với trường hợp này, \u003cstrong\u003ein-context learning\u003c/strong\u003e được sử dụng rất nhiều trong \u003cstrong\u003eprompt engineering\u003c/strong\u003e. Mọi người sẽ cung cấp các ví dụ có sẵn trực tiếp vào prompt và mô hình sẽ học từ những ví dụ đó để tạo ra các kết quả tiếp theo. Đó là ý tưởng chính của in-context learning. Về cơ bản, thiết kế sẽ hoạt động như thế này: bạn có một truy vấn, sau đó bạn xây dựng prompt với các ví dụ cần thiết và dữ liệu few-shot learning, rồi bạn đưa nó qua mô hình, mô hình sẽ trả về kết quả dựa trên các ví dụ đó. Tuy nhiên, nó không chỉ dừng lại ở các ví dụ, mà còn bao gồm rất nhiều yếu tố khác.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e26:37\u003c/strong\u003e Nhìn rộng hơn, in-context learning liên quan đến việc cung cấp ngữ cảnh vào prompt bằng cách truyền vào các thông tin mà mô hình không có sẵn. Vì đây là một mô hình được huấn luyện trước, kiến thức của nó bị giới hạn, vì vậy bạn truyền thêm thông tin vào ngữ cảnh và prompt để mô hình học trong quá trình tạo ra kết quả. Ví dụ, trong chẩn đoán hình ảnh y khoa, mô hình có thể không có đủ kiến thức chuyên môn. Vì vậy, bạn cung cấp kiến thức đó vào ngữ cảnh và prompt để mô hình học trong quá trình tạo ra kết quả. Đó là cốt lõi của in-context learning.\u003c/p\u003e\n\u003cp\u003eTiếp theo là nút thiết kế thứ hai quan trọng, được gọi là \u003cstrong\u003edata preprocessing/ editing\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e27:54\u003c/strong\u003e Phần này miêu tả quy trình chuẩn bị dữ liệu cho mô hình ngôn ngữ (LM). Như mọi người biết, LM hoạt động dựa trên các cơ sở dữ liệu vector, sử dụng so sánh vector để tìm các điểm dữ liệu tương tự. Quy trình này thường liên quan đến việc xử lý dữ liệu đa phương tiện và các loại thông tin khác nhau. Để đảm bảo đầu ra là tối ưu, việc áp dụng các bước xử lý trước dữ liệu là rất quan trọng. Ví dụ, bạn có thể xử lý trước văn bản bằng cách lọc ra các chi tiết không cần thiết để làm ngắn lại, hoặc với hình ảnh và âm thanh, bạn có thể loại bỏ nhiễu hoặc nén dữ liệu để giảm kích thước trước khi đưa qua mô hình ngôn ngữ.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e29:19\u003c/strong\u003e Việc xử lý trước hoặc chỉnh sửa dữ liệu giúp mô hình hoạt động hiệu quả hơn. Có nhiều cách để xử lý trước, tuỳ thuộc vào loại dữ liệu hoặc ngữ cảnh. Bạn sẽ thực hiện điều này dựa trên các yêu cầu cụ thể. Nút thiết kế tiếp theo mà tôi muốn đề cập đến là một thiết kế thường được sử dụng, mặc dù có nhiều tên gọi khác nhau. Tôi gọi nó là \u003cstrong\u003eexample agent\u003c/strong\u003e. Đây là một thiết kế thường thấy khi bạn muốn truy vấn của mình đi qua nhiều ngữ cảnh khác nhau. Ví dụ, nếu bạn có một ứng dụng đánh giá bài viết, bạn có thể cho bài viết đó đi qua một đường ống nơi mỗi agent đánh giá bài viết từ một góc độ khác nhau.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e30:11\u003c/strong\u003e Một agent có thể đánh giá bài viết từ góc nhìn của một nhà văn, một agent khác có thể từ một góc nhìn khác. Sau khi đi qua tất cả các agent này, sẽ có một lớp tổng hợp cuối cùng để kết hợp hoặc xử lý các kết quả đó, và cuối cùng cung cấp cho người dùng một kết quả tổng hợp. Thiết kế này thường thấy trong các hệ thống đánh giá, nơi bạn đánh giá kết quả từ các mô hình khác nhau và chọn ra kết quả tốt nhất dựa trên các điều kiện đã được thiết lập trước.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e30:55\u003c/strong\u003e Nút thiết kế tiếp theo, gọi là \u003cstrong\u003eagentic button\u003c/strong\u003e. Vậy agentic có nghĩa là gì? Trong ngữ cảnh của các mô hình ngôn ngữ (LMs), \u003cstrong\u003eagentic LMs\u003c/strong\u003e ám chỉ việc nâng cấp khả năng của mô hình. Vì mô hình chỉ biết những gì nằm trong dữ liệu huấn luyện của nó, chúng ta sẽ nâng cấp nó để tăng cường sức mạnh của nó và giảm thiểu sự can thiệp của con người. Thiết kế này giúp hệ thống tự động hoá nhiều hơn, cho phép nó hoạt động với ít sự can thiệp của con người hơn.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e32:24\u003c/strong\u003e Thiết kế này có một số thành phần chính giúp bạn đạt được mức độ tự động hóa này. Có bốn thành phần chính: \u003cstrong\u003ereflection\u003c/strong\u003e, \u003cstrong\u003eplanning\u003c/strong\u003e, \u003cstrong\u003eexecution\u003c/strong\u003e, và \u003cstrong\u003emulti-collaboration\u003c/strong\u003e. Mỗi thành phần này đều giúp hệ thống của bạn trở nên tự động hóa hơn. Đầu tiên, chúng ta hãy nói về \u003cstrong\u003ereflection\u003c/strong\u003e. Reflection liên quan đến việc đánh giá kết quả ban đầu của mô hình dựa trên một tiêu chí hoặc một chỉ số cụ thể để xác định xem kết quả đó đã được tối ưu hóa chưa. Nếu chưa, hệ thống sẽ điều chỉnh và lặp lại quá trình này, tiếp tục tạo ra kết quả cho đến khi đạt được kết quả tối ưu.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e33:06\u003c/strong\u003e Reflection giúp giảm thiểu sự can thiệp của con người vì thay vì tạo ra một kết quả ban đầu không đáp ứng mong đợi của bạn, hệ thống sẽ tinh chỉnh dựa trên các tiêu chí đã được thiết lập trước, cuối cùng đưa ra một kết quả chính xác hơn mà không cần điều chỉnh thủ công.\u003c/p\u003e\n\u003cp\u003eReflection button này có nghĩa là nó sẽ đánh giá cái output ban đầu của một con AI, rồi nó sẽ đánh giá dựa theo một tiêu chuẩn nào đó hoặc là một cái chỉ số nào đó để xem là cái kết quả này đã tối ưu chưa. Nếu chưa tối ưu nó sẽ thêm thắt một chút và nó sẽ chạy vòng lại con AI đó để nó tạo ra kết quả khác cho tới khi nào đạt được kết quả tối ưu nó sẽ trả cho mình cái kết quả cuối cùng. cái này nó sẽ giúp giảm thiểu việc con người phải can thiệp vào quá trình làm việc, bởi vì nếu mà output đầu tiên không đúng ý mình, mình không cần phải tự chỉnh lại nữa mà nó sẽ tự tối ưu.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e33:42\u003c/strong\u003e Button thứ hai là tool. Tool có thể là external, nó có thể là external API hoặc là những cái function mà mọi người code. Những cái tool này được sử dụng để cho model có thể lấy được những knowledge từ thế giới bên ngoài, những real-time knowledge, những external resource mà nó không được train sẵn. Như OpenAI hay là Claude đều có hỗ trợ. Khi đó, con model có thể tự biết khi nào cần gọi tool dựa vào cái description mà mọi người viết trên cái tool đó. Model sẽ tự biết cách lấy và extract thông tin từ tool, rồi trả về cho con LM để nó generate ra output.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e34:30\u003c/strong\u003e Kế tiếp là planning. Planning button có nghĩa là mọi người cho con LM có khả năng lập kế hoạch, để tránh việc phải prompt đi prompt lại nhiều lần. Ví dụ, nếu có một task phức tạp, mình sẽ có một cái prompt lớn cho nó plan ra tất cả các step mà nó cần làm theo kiểu step by step. Cách này sẽ cho nó làm những việc nhỏ trước, rồi cuối cùng kết hợp lại thành một cái task lớn. Cái kiểu planning design này có nhiều biến thể, và đây là biến thể đơn giản nhất: lập kế hoạch xong rồi làm từng bước một.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e35:10 C\u003c/strong\u003euối cùng là multi-collaboration. Cái này em đã present cách đây một tháng rồi. Nói chung, nó giống như kiểu là AI giỏi việc nào làm việc đó. Mình có một cái context đúng không? mình chia nó ra, rồi đưa qua từng người. Người nào giỏi việc đó nó sẽ giải quyết việc đó, xong rồi pass qua con agent tiếp theo. Cứ thế, cuối cùng nó sẽ complete được cái requirement. Cái design này sử dụng tính chất divide and conquer khá nhiều. Chia việc lớn thành việc nhỏ, rồi đưa việc nhỏ cho người giỏi chuyên môn. Đây là một cái design button mà em thấy khá nhiều nơi bên ngoài sử dụng.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e36:24\u003c/strong\u003e Đó là những design button mà em thấy nhiều nơi sử dụng và hiểu nhất. Em đã trình bày xong. Mọi người có câu hỏi gì không?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e37:10\u003c/strong\u003e Hoàng, em nói lại cái phần planning, để confirm lại cái comment của anh Bảo. Nó giống như là kiểu đọc cái prompt đúng không? Nó sẽ hiểu cái prompt của anh trước, xong rồi nó sẽ chia cái prompt ra thành những cái nhỏ hơn, xong rồi nó sẽ có những con worker, có thể là những IDE worker hoặc là những cái prompt nhỏ để nó hoàn thành task đó. Đúng không?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e37:40\u003c/strong\u003e Đúng rồi, anh có thể hiểu như vậy. Mình có thể chia prompt ra, ví dụ như là một task phức tạp, nó sẽ chia ra nhiều cái plan nhỏ. Những cái plan nhỏ này sẽ làm step by step. Ví dụ nó làm plan 1 trước, rồi làm plan 2, rồi làm plan 3. Sau khi hoàn thành tất cả các plan, nó sẽ tổng hợp lại ở một cái chỗ nào đó, hoặc là một cái component cuối cùng để nó ra được câu trả lời cuối cùng.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e38:06\u003c/strong\u003e Ý là nó giống như cái con Zero mà hôm trước anh Tom present ấy. Con worker sẽ có thể làm một số task như đọc file, xóa file, sửa file, hay là talk với Internet, gửi email các thể loại. basically, agent các thứ như vậy.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e38:52\u003c/strong\u003e Đúng rồi, bản chất của nó là thay vì làm một cục rất lớn để giải quyết hết cái task đó, mình phải đi prompt đi prompt lại nhiều lần để nó cho ra kết quả. Mình có một cái prompt trước, để chia nhỏ thành các task nhỏ, rồi sau đó có một cái pipeline để nó đi qua từng con worker, làm những việc nhỏ nhỏ cho mình.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e39:23\u003c/strong\u003e Ok, kéo lên slide 14 đi Hoàng, slide 14. Anh cũng thấy là kiểu con này giống giống con Mule Automation mà Tom setup đúng không? Con Mule button mà Tom setup ấy. Em đã code xong rồi nhưng nhìn cái design này với cả cái button giống hệ nhau này.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e39:46\u003c/strong\u003e Ừ, cái này là thằng Tpm nó chạy loop rồi, nhìn ra giống giống một tí. Nó giống planning mà anh Tom vừa nói, là nó break task ra từng phần, rồi xử lý từng phần một. Nó có iteration trong đó, giống như là nó có một list các step mà em đã mô tả ở trên. Back lại cái của em, chính là chỗ mà agent đang thấy. Cái của anh thấy nó giống planning hơn, là nó chia plan ra trước, rồi làm step by step từng plan một, đi qua mỗi vòng làm từng cái một. Còn cái này nó giống như là làm song song với nhau, nó parallel với nhau, để ra output xong rồi đánh giá lại output đó, rồi đưa ra kết quả cuối cùng. Chắc anh nhầm cái work rồi, đã correct lại.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e42:28\u003c/strong\u003e Đúng rồi, thử đi. Nó là kiểu như vậy đó, nó chia ra thành nhiều việc khác nhau. Nó giống như là classify, nó chạy qua từng cái. Cái này giống multi-collaboration hơn, vì nó giống như question classifier, chỉ chạy một trong mấy cái này thôi. Mỗi agent làm việc đúng chuyên môn của nó, rồi combine lại.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e43:33\u003c/strong\u003e Nhưng mà anh thấy mấy phần như reason với input analysis có đúng không? Của Tom, phần expert ấy. Riêng vụ pick domain ấy, nó có classifier ở đó, nhưng mà mấy phần reason với input analyzer là những agent khác nhau. Bên group đó là expert thôi, mình consider nó như là một group expert đúng không? Và nó combine với năm cái agent mình phía dưới.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e45:33\u003c/strong\u003e Nếu mà làm tất cả mọi thứ trong cùng một cái prompt, em chắc chắn nó sẽ không ra được kết quả mình mong muốn đâu. Vì context quá nhiều và không có example cụ thể. Đầu tiên là accuracy chắc chắn sẽ giảm vì quá nhiều dữ liệu cùng lúc. Cái chính là phải chia ra nhiều layer, từng bước một. Thực tế mình cần output từ con LM, chứ không thể hardcode từ trước được. Mình chỉ muốn một cái prompt đơn giản nhất, để nó làm ra các câu trả lời nhỏ, rồi từ đó có một câu trả lời lớn.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e46:59\u003c/strong\u003e Đúng rồi, khi làm nhỏ ra, mình sẽ biết vấn đề nằm ở đâu để debug. Như anh đã nói, specify kỹ, chia ra từng layer, nếu thấy sai ở đâu mình sửa ở đó. Còn nếu quăng một cục, mình sẽ không biết nó sai chỗ nào, rồi phải sửa rất nhiều lần.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e48:43\u003c/strong\u003e Đúng rồi anh. Ví dụ như tạo một cái event trong calendar vào ngày mai, nếu không có sự kiện trong giờ đó tạo event, còn nếu có rồi thông báo. Nếu mình quăng một cục request đảm bảo nó sẽ rối ngay, vì nó phải thực hiện theo step by step. Nếu chia thành từng layer, test từng bước sẽ ổn hơn.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e49:23\u003c/strong\u003e Nó sẽ em chắc là 99% là nó sẽ mù luôn á. Nếu mà còn nếu mình chia cái thành layer cơ, thành nhiều lớp layer á, làm test bài test nó sẽ ok hơn. Rồi, hô nào nên nữ, nên văn phòng là có Tôm ở đấy người chửi nhau. Anh không có hỏi nào chắc là cảm ơn Hoàng trước. À, đến Đạt nhé. Đạt nhờ. À, em không thị xem màn hình. Ok rồi, mọi người thấy màn hình của em chưa? Ừ, thấy rồi.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e50:38\u003c/strong\u003e Hôm nay em nói về Yelp use cases. Từ từ Đạt, để anh giới thiệu context một chút. đợt này team mấy bạn sẽ focus vô đâu đó và đi search thử mấy cái phần use case ấy. Use case ở đây có nhiều dạng. Cái dạng mà Đạt đang sharing nó sẽ là mình xem thử các bên startup hay enterprise nó đang apply vào để giải quyết vấn đề gì. Là có thể là những cái green field, tức là những cái hoàn toàn mới. Hoặc là những cái mà nó optimize cho cái phần current workflow của chúng đó, kiểu vậy. Nó sẽ viết những use case và report lại hàng tháng, những cái phần update. Ngoài ra có một cái phần dạng use case khác nữa đó là những cái phần tuning mà để boost phần development của bên phía bên phía là tech các thứ. nó sẽ có những cái technique hay là có những cái phần editor mới, hay là mấy cái tool mới các thứ. đ cũng sẽ report cái phần đấy đâu đó trong tech. Đang testing thử trong khoảng hai tuần một đấy. đây là một cái bài đầu tiên chắc con Yelp này, nó đang dạng là con start-up phải không, chắc là. tiếp tục giới thiệu cho anh em một tí về cách mà bọn này đang apply AI là như thế nào?\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e52:01\u003c/strong\u003e Yelp là cái đơn vị nó đưa ra cái software, nó cung cấp cái software cho các store, các bên mà doanh nghiệp muốn làm các đơn vị nhỏ lẻ như kiểu là giao hàng nhanh, hay là nhà hàng, rồi các bánh dụng cụ cơ bản, kiểu như vậy. Yelp này nó bán cái software cho mọi người làm việc đó. em sẽ chia sẻ chút về thằng này, nó sử dụng AI vào trong cái tooling của nó như thế nào.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e53:00\u003c/strong\u003e trước đó chúng nó có một cái machine learning system rồi, bây giờ nó app thêm AI vào để giúp cho cái việc recommendation nó đúng hơn. bọn Yelp này nó có trên hệ thống của chúng nó, nó có nhiều cái thể loại đánh giá như kiểu đánh giá nhà hàng nó không bị tốt chẳng hạn. dựa trên những cái review đó, chúng nó có làm cái trò là text editing để so sánh được những cái kết quả mà spam hay không á. nó sẽ sử dụng AI vào trong cái việc gì. Thứ nhất là chúng nó sẽ tạo, chúng nó sử dụng AI để làm cái việc làm dataset, để train được cái model đánh giá là nó đang spam hay nó đang review tốt hay xấu như thế nào á. nó sẽ sử dụng AI để tạo ra cái dataset dựa trên LinkedIn. ở trong đây, em đọc có thấy bảo là chúng có sử dụng số tính như Zero-shot và Few-shot để làm dataset. chúng nó chỉ sử dụng một số cái model ở trên Hugging Face, rồi xong chúng nó làm classify để đánh giá được là review tốt hay xấu. đây là một cái use case cho cái việc AI dùng để làm text editing.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e54:18\u003c/strong\u003e À, sang cái use case thứ hai của chúng nó, là chúng nó có sử dụng Clip Model. Clip Model bản chất của nó là xử lý hình ảnh. Xử lý hình ảnh có nghĩa là sao? Có nghĩa là dựa trên review, dựa trên review... đợi em chút để em kiếm nè. À, Clip á, nó sẽ xử lý hai thứ. Một là cái caption của cái ảnh, và cái ảnh nó như thế nào. qua Clip này á, nó sẽ hiểu được cái context của cái ảnh là cái gì. chúng nó sử dụng Clip vào trong những cái công việc như là những cái người ta đi vào trong một quán ăn hay một cái quán nhậu á, chúng nó sẽ review, chụp ảnh để capture lại những cái thứ này. Và ví dụ như hình ảnh của một cái món sản phẩm đi, trước khi apply Clip nó không đánh giá được, nó không đánh giá được là nó có bánh quế không, nó chỉ đánh giá được mỗi gà rán thôi chẳng hạn. Sau khi apply Clip vào á, nó sẽ biết được là có gà rán và có bánh quế. bản chất, nó sử dụng cái Clip này là một phần của AI, là nó xử lý ảnh, xử lý ảnh và caption của ảnh, và hình ảnh thành vector để nó so sánh với nhau. đây là hai use case của nó. những cái use case này được áp dụng cho cái gì?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e55:38\u003c/strong\u003e Hai cái use case trên nó sẽ áp dụng trong cái tình huống là khi mà mình có nhiều review á, mình có thể summarize nó lại thành một cái highlight review ở trên đây. dựa trên những cái thứ mà nó chuyển thành vector được á, nó có thể annotation được cái việc là những cái hình ảnh đang nói cái gì, nó support cho mình được cái gì ở trong đây. Đợi một chút, nó sẽ highlight cho mình luôn. nó sẽ biết được cho mình cái context của cái ảnh là gì, nó có thể annotation được cái việc này. đó là cái use case của cái việc mà AI dùng để làm image summarization.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e56:15\u003c/strong\u003e Đầu năm nay nó có release thêm cái là Yelp Assistant. Dựa trên những cái nền tảng cũ của chúng nó, chúng nó có thể tạo ra chatbot rồi, xong nó có thể review lại cái highlight như thế này, mình cứ hỏi nó xong nó recommendation cho mình cái gì thôi. Đơn giản là như vậy. Ngoài ra em có thấy một cái use case cũng khá đặc biệt, có nghĩa là trong cái giai đoạn từ 2020 á, nó nổ ra cái câu chuyện là làm clip ngắn review các thứ á. chúng nó có một cái nguồn dataset nhất định cho cái việc đó. em thấy chúng nó bảo chúng nó sắp release một cái như anh Tom có đề cập, cái bọn đó có thể chuyển văn bản thành giọng nói á. dựa trên cái nguồn dataset review này á, có lẽ chúng nó support review thêm cái việc mà làm video clip ngắn để mô tả cái nhà hàng.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e57:45\u003c/strong\u003e Dựa trên những cái review, những cái video mà người ta tới người ta review á, mình có thể tạo ra được một cái đoạn script, xong cho nó chạy qua AI, nó tự động làm ra một cái video về một cái nhà hàng như mình. đây là use case của bọn này, đơn giản nó có thế thôi. Ok, quay lại cái câu hỏi đầu tiên, cái này nó sẽ dạng là dùng AI để label data, đúng không?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e58:35\u003c/strong\u003e Ok, vậy là check xem là cái comment là negative hay positive, đúng không? Kể kiểu đấy là một ví dụ. Cái thứ hai nữa là nó sử dụng cái clip model, đúng không? Chắc là sẽ dạng giống như Vision, nhưng mà live hơn, cũng để dán nhãn, đúng không? Để dán nhãn giống như cái của bên phía Plot, dán nhãn cho ảnh. hai cái use case đó, nó sẽ được ứng dụng trong cái việc gì?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e59:18\u003c/strong\u003e Em nghĩ có một cái ý khá hay mà nó chưa nói tới, là câu chuyện là nó có nguồn dataset sẵn. Như là ai tới review, ai tới đánh giá các thứ, dựa trên những cái clip ngắn như thế này, nó có thể tạo ra được một cái video intro về cái nhà hàng đó. Nó sử dụng AI. Em nghĩ là nó sử dụng AI để viết kịch bản, rồi sau đó đưa kịch bản đó cho một con AI voice để nói. Nhưng mà hình ảnh nó lấy ở đâu? Như kiểu là video nó sẽ lấy từ đâu ra?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e59:57\u003c/strong\u003e Từ trong cái review, ai tới review họ sẽ có một cái video để review. Ok, tự động tạo advertisement, đúng không? Dạ vâng, cho TikTok hay những nền tảng như TikTok các thứ, kiểu summarize từ review của user. Nghe cũng có vẻ sáng tạo đấy. Ừ, chắc anh em confirm mấy cái của anh bảo làm rồi đúng không?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:00:07\u003c/strong\u003e Đang vậy, cái này ok là cái caption. Ok, đúng hầu như là đúng anh. Bạn nói đúng, là chúng nó sẽ, em nghĩ em nghĩ cái use case này bọn này ban đầu á, cái mục đích ban đầu của bọn này là làm recommendation. trước đó, trước khi có AI chúng nó đã có một cái hybrid recommendation model trước. Căn bản là nó sẽ... Em nghĩ là khi mà có cái này á, nó dẹp gần hết cái model cũ này luôn. Em nghĩ có một cái khá hay là cái business messaging mà chúng nó không có đề cập nhiều. Có nghĩa là em nghĩ là nó sẽ dựa trên là có review top 50 review chẳng hạn. Xong top 50 cái interaction, kiểu như rating như thế nào. Thứ nhất là review tốt, n rating tốt, cái business messaging của nó sẽ tốt. Mà Yelp không đề cập vấn đề này, mình không trách nó được.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:00:51\u003c/strong\u003e Ok, anh em có câu hỏi cho Đạt không? Bài đầu tiên đấy. Đạt bảo đang thêm mấy cái, mình phải enterprise nữa, nhưng mà thầy thấy đang Viettel với cả FPT, với cả VNG các thứ, đang chưa biết thấy chúng nó thế nào. Đạt kêu mấy cái tool, cái tool gì coding của bên phía FPT hả, đang kêu cùi.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:01:41\u003c/strong\u003e Hì, một bản for, một bản for của của continue à? Nó thế, nó thế không tốt. Nó hơi cùi, thô. Hai, chị hết rồi à? Chắc vậy. Đạt nhé. Hôm nay mấy bài về Yelp và Tech Linh chắc tuần sau, tuần sau, tuần sau nữa, nếu kịp.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:02:01\u003c/strong\u003e Tí demo luôn đi, Đạt luôn. Để Đạt demo một tí cái gì nhỉ? Cá đang là một con bot, để có thể question với cả question một cái short code dưới dạng kiểu developer mà hiểu rõ hơn về code, hay là test kiểu như là một vai trò auditor đi kiểm tra chất lượng của code. Đạt đang demo dev cái workflow hay con bot dựa trên diff đó cho anh em xem thử nào. Mình bật hình rồi Đạt ơi.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:03:01\u003c/strong\u003e đây là một cái project để em xin vào club ai nha. Trình em gọi là hơi 'newb' nên project này mà có lem quá mọi người thông cảm. Workflow cơ bản là em sẽ lấy query, rồi trích xuất ra được cái URL của repo. Ở đây em có dùng lại cái scrapper của anh Tom, nhưng mà nó chưa đúng ý em, nên em có tạo một con scrapper ở local nó sẽ lấy được tất cả content của repo luôn. Nhưng mà cái đó nó quá lâu với quá lớn. Ờ, default hiện tại em chưa thấy làm cách nào mà bỏ vào con context được, trừ khi dùng cái knowledge retrieval, mà dùng knowledge retrieval em không có gọi là trực tiếp được mà phải bỏ vào trước. Mình không có chọn, không có chọn repo được.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:05:45\u003c/strong\u003e Cái scraper này của anh Tom nó không có lấy content của file, cho nên em chưa vẽ diagram được. Vẽ diagram có thể em dùng, tí nữa em test thử. Cái này là em lấy được content của những file nè, ở root, ở những file doc. Những file đó không chắc câu hỏi của Huy vừa đưa ra chắc là cũng không trả lời được. Để em thử, em có sẵn cái full của em vô đây rồi, offline nhỉ. Bên phía in sẵn content rồi, chứ không online. Cái này em generate bằng luôn, cũng không có.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e01:07:07\u003c/strong\u003e Cái này nó sẽ scrap full content, nó sẽ đầy đủ hơn. Để em thử đặt câu hỏi của bên Huy hay của Hoàng các em thử nào. Mình thử BC chat lên rồi đặt câu hỏi xem. Anh có không? À không. Maybe là cái context này quá lớn, cái phần knowledge retrieval này em chưa tìm được cách mà cho nó vào context tốt được.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:09:19\u003c/strong\u003e Retrieve tối ưu lắm. Cái file text này cũng mấy chục ngàn dòng, mấy chục ngàn dòng á. Mở lên xem thử nà, đ đang dùng mini hả, đổi sang máy đ xịn hơn xem có ok hơn không. Đồ mini hơi cùi. 2 triệu từ như thế, từ làm sao mà nó còn xong được ta? Em nghĩ là phải có một cái server, cái dedicated server luôn nó mới ok. Anh đang tò mò tại sao nó chạy được ấy, bởi vì 29U word à, như vừa thấy à. Nhân với cả 4 này là số to. Kích cỡ đấy, Follow up xem thử. Ok, tức là em vẫn là từ cái context thôi đúng không, là mình cũng chỉ dạng là query kiểu query vb đúng không, chứ không phải mình nhập hết tất cả cái đấy vào context.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:10:57\u003c/strong\u003e Ok, đúng rồi anh. em chưa nắm được là cái retrieval của thằng dify nó sẽ chạy như thế nào. Không biết nó chạy có đúng không, nó retrieve có đúng không. Em chưa tracing được nó mà em có cái tool tracing ở phía trước nữa, có thể test lại thử xem như thế nào. Nhưng mà ý là nếu mà kiểu retrieval như này chắc là kết quả nó sẽ không đúng được đâu anh. Anh cũng đang chưa biết là nó sẽ run bao nhiêu data ấy. Kiểu nó chỉ prefer 2-300 thôi, kiểu data không thể nào đủ mà để làm mấy cái task kiểu này. Cái này ít nhất cũng phải vài trăm tương đối data ấy. Dạ cái này còn work in progress.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:11:35\u003c/strong\u003e Đùa đấy, cứ lên công ty là có AI Club rồi. À, là của full version hay là fix được cái vụ này demo với bọn anh ở trên office nhé, mà try em để lại cho anh. OK, để em xem nó vẫn không build ra chắc mọi người coi đỡ. Cái chắc build bị gì đó, mọi người thấy màn hình không ạ?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:13:08\u003c/strong\u003e Dạ tuần này như em nói tuần trước em sẽ up cái bài sync.Map này. Em thấy nó hay với chi tiết để mọi người mà xài Go có cái nhìn tổng quan hơn về map nói chung. Và cái thằng sync map này đi qua trước là phần context. khi mọi người viết map đúng không, mà mình nếu mà mình viết concurrent map hay operation đó, mình làm concurrent á, về bản 1.16 trước nó sẽ không báo đâu, nhưng mà nó vẫn không safe nha. Còn bản từ 1.16 trở đi á nó sẽ error như thế này đó. Cho nên là để mà solve được problem này bình thường mọi người có thể viết map kèm với tại package sync, viết manual đó được.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e01:13:56\u003c/strong\u003e Bên cạnh đó nó có một cái option khác đó là thằng sync.Map này. chút nữa đến cuối mình sẽ sẽ nói tại sao nó lại được đề ra xài và cái usecase của nó như thế nào. thằng này nó được đề ra để mà mình không cần quan tâm lắm về cái việc mà mình phải xài mutex để lock lại cho việc synchronize. Tức là mình chỉ có việc xài thôi. Xài nó trông đơn giản như thế này nha, nó friendly như là mình viết map kiểm tra value vậy. Ví dụ như mình load một cái key lên có value ok nó sẽ giống như là việc map value bình thường thôi. Trong như này, nếu có là ok true, còn nếu không có false của y chang.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:14:38\u003c/strong\u003e Còn có một số cái function mà mình có thể xài rất handy. Đây là bảng 12.23 sẽ có clear, clear hết. Ví dụ như load là để lấy value, store là để update hoặc store cái key. Update vậy. Delete các thứ. ngoài cái việc mà mình viết concurrent đó đi đó, bên cạnh đó khi mà mình range, tức là mình loop một cái map nó cũng bị race condition nữa. thằng sync map này nó có cái hàm range này, mình xài mình sẽ không quan tâm nó là ấy, nó sẽ không bị nhưng mà như hàm range bình thường thôi. nó sẽ không cho mình cái cái snapshot mà gọi là consistent nhất, là khi mà mình vừa mới vô cái snapshot nó không được update là.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:15:28\u003c/strong\u003e Mà mình range, tức là mình loop một cái map, nó cũng bị race condition nữa. thằng \u003ccode\u003esync.Map\u003c/code\u003e này nó có cái hàm \u003ccode\u003eRange\u003c/code\u003e, mình xài, mình sẽ không quan tâm nó là cái gì, nó sẽ không bị như bình thường đâu. Nhưng mà như hàm \u003ccode\u003eRange\u003c/code\u003e bình thường thôi, nó sẽ không cho mình cái snapshot mà gọi là consistent nhất, là khi mà mình vừa mới vào cái snapshot nó không được update. trong lúc đó mình sẽ phải thay đổi cách viết, nhưng ít nhất là nó sẽ không bị phải error như thế này.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:16:06\u003c/strong\u003e Đến cái phần bên dưới nó work như thế nào á. mọi người, nếu mà mọi người viết khi mà xem \u003ccode\u003eCH\u003c/code\u003e và \u003ccode\u003edefinition\u003c/code\u003e cái \u003ccode\u003emap\u003c/code\u003e nó được cấu trúc như thế này: nó sẽ bao gồm hai cái \u003ccode\u003emap\u003c/code\u003e. Đó, nghe đến đây là mọi người sẽ thấy hơi kinh, nghe hơi thốn \u003ccode\u003eRAM\u003c/code\u003e với \u003ccode\u003ememory\u003c/code\u003e. Nó có một cái \u003ccode\u003eRead Only map\u003c/code\u003e và một cái \u003ccode\u003eDirty map\u003c/code\u003e. nghe như thế mọi người có thể đoán được là nó sẽ làm việc theo kiểu là những cái value mà nếu mà được \u003ccode\u003ewrite\u003c/code\u003e nó sẽ được viết vào cái thằng \u003ccode\u003eDirty map\u003c/code\u003e này hết. Cứ viết \u003ccode\u003eupdate\u003c/code\u003e vào đây, \u003ccode\u003eupdate\u003c/code\u003e vào đây, con này nó sẽ giống như là.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:16:46\u003c/strong\u003e Cái \u003ccode\u003eRead Only map\u003c/code\u003e này nó sẽ là những cái khi mà mình đọc vào á, mình sẽ luôn đọc ở đây. Còn \u003ccode\u003ewrite\u003c/code\u003e sẽ luôn \u003ccode\u003ewrite\u003c/code\u003e mới vào thằng \u003ccode\u003eDirty map\u003c/code\u003e. Còn cái flow bên dưới nó làm việc như thế nào chút xíu nữa mình sẽ nhìn cái chart flow mình sẽ thấy. À, cả hai cái \u003ccode\u003emap\u003c/code\u003e này có một điểm chung: nó đều có một cái con trỏ \u003ccode\u003eentry\u003c/code\u003e nha mọi người, để ý để dễ hiểu cái flow. Ví dụ, ở đây mình thêm một cái \u003ccode\u003eentry\u003c/code\u003e mới, đúng không? nó sẽ thêm vào \u003ccode\u003eDirty map\u003c/code\u003e và nó đều trỏ đến \u003ccode\u003eentry\u003c/code\u003e này. Cái này nó sẽ giống như là một cái \u003ccode\u003eflag\u003c/code\u003e để đánh dấu rằng là cái \u003ccode\u003emap\u003c/code\u003e này đã được thay đổi rồi. Tức là cái thằng \u003ccode\u003eRead Only map\u003c/code\u003e này nó không phải là mới nhất nữa. Khi này bên dưới nó sẽ nhìn và hiểu rằng là thằng \u003ccode\u003eDirty map\u003c/code\u003e mới là cái nên đọc vào.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:17:27\u003c/strong\u003e Hình này thể hiện rằng là ví dụ như mình \u003ccode\u003eupdate\u003c/code\u003e một cái value nào đó, do bên dưới nó là con trỏ đúng không, mình chỉ việc \u003ccode\u003eupdate\u003c/code\u003e cái con trỏ đó thôi, không cần phải \u003ccode\u003eupdate\u003c/code\u003e từng cái value như là mình làm với \u003ccode\u003emap\u003c/code\u003e truyền thống. để làm được điều này á, bên dưới nó để ra một cơ chế là ba cái trạng thái (\u003ccode\u003estate\u003c/code\u003e) cho cái con trỏ \u003ccode\u003eentry\u003c/code\u003e này. \u003ccode\u003eState\u003c/code\u003e thứ nhất là \u003ccode\u003enormal state\u003c/code\u003e, đúng không? \u003ccode\u003eNormal state\u003c/code\u003e tức là những cái value cũ của \u003ccode\u003emap\u003c/code\u003e, nó đang có đủ và có thể xài được, không có bị gì hết. Còn trạng thái \u003ccode\u003eamended\u003c/code\u003e là khi mà \u003ccode\u003eentry\u003c/code\u003e đã bị sửa lại. Còn \u003ccode\u003edelete state\u003c/code\u003e là khi một \u003ccode\u003eentry\u003c/code\u003e nào đó đã được \u003ccode\u003edelete\u003c/code\u003e khỏi \u003ccode\u003emap\u003c/code\u003e, nhưng nó chưa được remove hoàn toàn nha. Tức là nó sẽ được...\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:18:59\u003c/strong\u003e ...assign cái con trỏ \u003ccode\u003eentry\u003c/code\u003e vào \u003ccode\u003enew entry\u003c/code\u003e, chứ chưa remove ra. Còn cái \u003ccode\u003eexpired state\u003c/code\u003e là xóa hoàn toàn, giống như là \u003ccode\u003ehard delete\u003c/code\u003e là mất khỏi \u003ccode\u003emap\u003c/code\u003e luôn. Để hình dung rõ hơn, mọi người có thể nhìn cái flow như thế này nha: ví dụ ban đầu cái \u003ccode\u003emap\u003c/code\u003e của mình đang có một cái \u003ccode\u003ekey1\u003c/code\u003e và \u003ccode\u003evalue1\u003c/code\u003e đúng không? bên \u003ccode\u003eDirty map\u003c/code\u003e chưa có gì cả, tức là chưa được thêm bớt gì. Sau đó, mình thêm một cái \u003ccode\u003ekey2\u003c/code\u003e nào đó, đúng không? nó sẽ được thêm vào \u003ccode\u003eDirty map\u003c/code\u003e, và khúc này là thằng \u003ccode\u003emap\u003c/code\u003e đã \u003ccode\u003eamended\u003c/code\u003e rồi, nó đã có một cái \u003ccode\u003eflag\u003c/code\u003e \u003ccode\u003eamended\u003c/code\u003e ở đây.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:19:40\u003c/strong\u003e Sau đó, khi mình xóa (\u003ccode\u003edelete\u003c/code\u003e) một cái \u003ccode\u003ekey\u003c/code\u003e, \u003ccode\u003emap\u003c/code\u003e này sẽ bị gán \u003ccode\u003enew entry\u003c/code\u003e, đúng không? Bên này cũng sẽ được tương tự gán \u003ccode\u003enew entry\u003c/code\u003e, giống như cái hình trước. Tức là mình chỉ cần cập nhật con trỏ thôi, không cần phải cập nhật value. Rồi, sau khi \u003ccode\u003edelete\u003c/code\u003e xong, đúng không, để \u003ccode\u003epromote\u003c/code\u003e được cái \u003ccode\u003eDirty map\u003c/code\u003e này, mình phải cập nhật lại qua bên \u003ccode\u003eRead Only map\u003c/code\u003e, để \u003ccode\u003eDirty map\u003c/code\u003e trở về \u003ccode\u003enew state\u003c/code\u003e, giống như đưa về trạng thái ban đầu.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:20:18\u003c/strong\u003e Tương tự, thêm một \u003ccode\u003ekey3\u003c/code\u003e nữa, khi thêm cái \u003ccode\u003ekey3\u003c/code\u003e này á, cái \u003ccode\u003estate\u003c/code\u003e này nè, sau khi nó đã trở về \u003ccode\u003enew state\u003c/code\u003e rồi đúng không, mình thêm \u003ccode\u003ekey3\u003c/code\u003e vào á, nó xác định rằng thằng này đã được \u003ccode\u003edelete\u003c/code\u003e rồi, nó sẽ là \u003ccode\u003edelete\u003c/code\u003e hoàn toàn. Điều này có nghĩa là lần sau, khi nó so sánh với \u003ccode\u003eDirty map\u003c/code\u003e, nó biết rằng bên này cái \u003ccode\u003evalue1\u003c/code\u003e đã bị xóa rồi, không còn nữa. cái \u003ccode\u003eRead Only map\u003c/code\u003e lúc này chỉ còn lại \u003ccode\u003ekey2\u003c/code\u003e và \u003ccode\u003ekey3\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:20:51\u003c/strong\u003e Cho nên chính vì lý do này, \u003ccode\u003esync.Map\u003c/code\u003e không có hàm \u003ccode\u003elen\u003c/code\u003e cho mọi người xài. Tại vì nếu như mọi người dùng hàm \u003ccode\u003elen\u003c/code\u003e ở đây, sẽ không biết được \u003ccode\u003evalue\u003c/code\u003e của nó, tại vì lúc đó nó sẽ đếm cả những cái \u003ccode\u003evalue\u003c/code\u003e đã \u003ccode\u003eexpired\u003c/code\u003e hay \u003ccode\u003edeleted\u003c/code\u003e. Mọi người có thể thấy, chính vì cái cấu trúc của \u003ccode\u003esync.Map\u003c/code\u003e được build như thế này, use case của nó được recommended là nên dùng cho những use case mà đọc (\u003ccode\u003eread\u003c/code\u003e) nhiều hơn ghi (\u003ccode\u003ewrite\u003c/code\u003e). Tức là nếu mà \u003ccode\u003ewrite\u003c/code\u003e hoặc \u003ccode\u003edelete\u003c/code\u003e nhiều, mọi người tưởng tượng chỗ này nó xài con trỏ liên tục, và có một cái issue bên Go team đã report là thằng này không bao giờ được garbage collected.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:21:36\u003c/strong\u003e Sau đó Go team họ confirm rằng cái \u003ccode\u003esync.Map\u003c/code\u003e này được sinh ra chủ yếu để support mấy cái bên trong Go Library thôi. Nếu mọi người thấy nó \u003ccode\u003ehandy\u003c/code\u003e vì có những function dễ xài có thể xài, nhưng nếu use case của mọi người mà cần lưu trữ (\u003ccode\u003estore\u003c/code\u003e), hoặc là \u003ccode\u003eupdate\u003c/code\u003e, \u003ccode\u003edelete\u003c/code\u003e nhiều không nên xài, vì nó sẽ làm chậm hệ thống.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:22:24\u003c/strong\u003e Dạ chắc chỉ vậy thôi ạ. Em có code lại cái bài bên này là cái bác này hay share mấy bài cũng khá chi tiết, mọi người có thể follow theo dõi. Ủa, cái này là topic gì Phát? Cho anh coi lại cái bài kịch bản đúp đầu r. À, cái sync map à? Ừ, sync map á. Ủa, nó có khác gì với lại cái anh vừa pass vô không vậy? Khác ở cái gì? Hình như là khác á anh. Ý là cái này em nhớ không nhầm là kiểu như cộng đồng tùy. Anh ví dụ use case họ muốn viết một cái gì đó mà họ thấy. Đó, anh nhìn thấy, họ ghi cái trong cái bên đấy, link mà nhìn thấy cách nó chạy mà lý do tụi nó làm thêm cái gì ấy nhỉ?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:23:30\u003c/strong\u003e Anh nhìn thấy nè, họ thêm một cái lớp nữa để họ xài. Ví dụ như là họ sẽ có những cái use case đúng không? Ví dụ như họ muốn implement generic trên \u003ccode\u003esync.Map\u003c/code\u003e đó. Cái này cũng có ảnh hưởng do cái vụ link nãy em nói, do thằng này nó không được garbage collected nè. Đó, kiểu vậy. ví dụ như bên này Go team ở dưới, họ đã confirm chốt xong cái này là cái \u003ccode\u003esync.Map\u003c/code\u003e này họ kêu là cái này là \u003ccode\u003eintended\u003c/code\u003e, intentional choice rồi, cho nên họ sẽ không sửa. Họ sẽ không đổi đúng không? Bây giờ cộng đồng làm gì mình chỉ biết là họ tự xài thôi. Ý là họ thích cái việc \u003ccode\u003esync.Map\u003c/code\u003e này được để ra dễ xài, có mấy cái function ngon lành, họ ráng thêm một tầng nữa, rồi chế những cái mà họ cảm thấy là ok, mình có thể xài được. Kiểu vậy.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:24:07\u003c/strong\u003e Ủa mà sao cái clip này cũng lâu mà bữa nay lại chọn à? Ờ, thế kiểu insight thôi, insight cho mọi người xài. Ý là cái use case này cũng có thể được apply cho bên mình. Ví dụ như bên enterprise đúng không? ví dụ mình xài \u003ccode\u003emap\u003c/code\u003e, mà mình xài concurrency đúng không? mọi người sẽ tự viết một cái \u003ccode\u003estruct\u003c/code\u003e, xong rồi mọi người sẽ nhét một cái \u003ccode\u003emutex\u003c/code\u003e vào, rồi tùy người sẽ ngồi bắt đầu viết lại. Đủ các kiểu. Trong khi đó thằng \u003ccode\u003esync.Map\u003c/code\u003e rất handy, như nãy em show anh, là mấy cái function này là nó luôn follow cái chuẩn, là anh muốn \u003ccode\u003eload\u003c/code\u003e anh phải gọi hàm này. Kiểu vậy, nó chuẩn hơn.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:24:50 M\u003c/strong\u003eọi người sẽ tự viết một cái \u003ccode\u003estruct\u003c/code\u003e như thế, xong rồi mọi người sẽ nhét một cái mutex vào, tùy người sẽ ngồi bắt đầu viết rồi đú các kiểu. Trong khi đó \u003ccode\u003esync.Map\u003c/code\u003e rất là handy. \u003ccode\u003eSync.Map\u003c/code\u003e này như em show anh nãy đó, những cái function của nó, nó luôn follow cái chuẩn này hết. Anh muốn load anh phải gọi hàm này, kiểu vậy nó sẽ chuẩn hơn. Nhưng mà như cái bài này là mình phải để ý những cái trade-off của nó, xài cho đúng quy. Ok, hiểu rồi, tức là quy chuẩn cái cách mà sử dụng \u003ccode\u003emap\u003c/code\u003e hả? Với lại workflow hả?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:25:26 C\u003c/strong\u003eảm ơn Phát. Rồi để tranh thủ, mấy cái Thành ơi, nhất là xin anh em thêm 10 phút nữa nhé. Nó sẽ hơi tốn thời gian thêm xíu. Nhất là anh nhận được tổng cộng 11 cái submission cho cái bài test của mình. Có ít bài hình ở trên, mấy anh em nhìn ở trên tí. Deadline của mình là đến ngày 20, tức là tuần sau nhé. Bữa trước anh thông báo như là 27 ha, phải không? 26, 27 gì đó là deadline, mấy anh em coi tranh thủ còn một tuần nhìn bài đó rồi làm ha. Cái bài đó nó sẽ quan trọng, có một số cái mà chi tiết của từng bài đó anh chưa có nhìn kỹ. Chỉ có bài của Tôm bữa trước, Tôm nó quăng nhanh lên trên lobby quá, thành ra là có nhìn sơ qua xíu. Nhưng mà còn của mấy anh em chưa nhìn rồi. Nhưng mà cái ý chính là mọi người xem thử nha, cái chất lượng bài của mình á, tập trung ở chuyện là đợt này khi mà market nó thay đổi nhiều vậy, cái demand của thị trường cho cái nghề làm software nó có sự thay đổi lớn á.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:26:15\u003c/strong\u003e Tất nhiên những cái nhu cầu nó vẫn sẽ còn ở đó thôi, nhưng mà cái số lượng đó nó giảm xuống. Thành ra đó anh gọi là cái sự thay đổi về cái nhu cầu thị trường gần như với góc nhìn của anh trải qua nó là giống như 2014, nhưng mà on-over-again, vậy là sự thay đổi công nghệ mới ra, mọi thứ mới ra, thị trường mới rồi những cái tiềm năng mới nó sẽ xuất hiện trên đó. cái bài test nó sẽ quan trọng với việc là giúp cho mình, nhất là test về văn hóa, nhìn lại trong cái lúc mà tụi anh muốn check lại cái team á, muốn là hai cái đội: đội làm research study với cả đội làm consulting nó có một cái sự phân hóa rõ ràng.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:27:36\u003c/strong\u003e Nó có một cái sự phân hóa rõ ràng. Như trong cái bài viết anh post lên notion cách đây khoảng hai tuần hả, sẽ có sự phân hóa rõ ràng. Tương lai nó sẽ có thêm một số những cái policy mới cho chính sách về lợi ích khác nhau giữa hai đội nữa. Nhưng mà hiện nay là, như mình thấy đó, mọi người thấy OGIF dần dần nó được chuyển qua gần như thành cái buổi là report lại tất cả những cái study. Cái phần mà anh em đang coi mới và report lại trên này. Có thể những bài đó do được add, có thể những bài đó là do mọi người bắt đầu anh nhìn thấy, có một vài thành viên trong team mình thật sự là thấy cái kiến thức mới đó, xong rồi pick up những kiến thức mới đó để mà coi.\u003c/p\u003e\n\u003cp\u003eTừ từ thấy rõ ràng là tụi anh muốn cái sự phân hóa đó nó diễn ra càng ngày càng rõ hơn. Và cũng có chính sách rõ ràng cho cái chuyện đó. Tức là ai mà thích coi mấy cái phần topic nhiều hơn, xong rồi ra ứng dụng ở tới mức là MVP, hay là ứng dụng vô những cái dự án nếu có, hoặc là đi deep dive thêm về kiến thức á, sẽ có một cái benefit khác. Những anh em nào mà không nhất thiết để phải ngồi coi những cái phần liên quan tới phần study như vậy, cứ ngồi làm dự án bình thường thôi. Nhưng mà nó sẽ có một số vấn đề khác đi kèm mà anh cũng có list ra trong cái link notion cách đây hai tuần. mọi người xem nhìn lại cái link đó một tí, để biết là vì cái định hướng như vậy nên là cái bài test này nó mang ý nghĩa là xem thử coi là cái mức độ của mọi người trong chuyện bắt kịp kiến thức mới, hoặc là cái độ tương thích với lại văn hóa trong cái giai đoạn mà tất cả mọi thứ nó thay đổi như vậy tới mức nào ha.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:29:20\u003c/strong\u003e Để hiểu vì cái mục tiêu là như vậy, nên là cái lúc mà chấm cái bài á, anh sẽ là người duy nhất chấm cái bài đó. Team mấy anh chị khác không có chấm đâu. Tất cả mọi người sẽ phải làm mà, nên là anh nghĩ rằng anh set cái standard cho chuyện đó. Nên là mấy bạn chịu khó làm bài đó tự làm là một chuyện. Thứ hai nữa là bài nào mà chất lượng thấp thật ra cũng không có vấn đề gì hết, chấm điểm thấp một xíu thôi, nhưng mà vừa làm hết vẫn sẽ được đủ điểm để mà coi như là pass cái đó. Chỉ là sau đó cái kết quả trước mắt thể hiện được á, là anh sẽ phân cụm thành hai cụm khác nhau.\u003c/p\u003e\n\u003cp\u003eĐội Foundation hay là đội Lab á, vẫn là đội core của mình từ năm nay, ha. Đó là cái thông báo chính. Nên là trên 11 cái bài này, nếu bạn nào làm xong rồi mà cảm thấy là mình có thể làm tốt hơn được cho cái chuyện mà anh vừa mới nói đó, đội mình thật ra là cái team Foundation và cái team Lab á vẫn sẽ được ưu tiên nhiều hơn trong những vấn đề khác nhau. Được ha. Nên là nếu mà anh em cái bài đó mà đang kiểu làm qua loa á, tập trung ngồi làm kỹ lại tí. Check hai thứ ha: văn hóa trên đó là một, thứ hai nữa là kiến thức.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:29:56\u003c/strong\u003e Sau đó cái kết quả trước mắt thể thấy được á, là anh sẽ ân cụm thành hai cụm khác nhau, cái đội Foundation hay là đội Lab á vẫn là sẽ đội core của mình từ từ từ 8-9 năm nay ha. đó là vậy, đó là cái thông báo chính. Nên là trên 11 cái bài này, nếu bạn nào làm xong rồi mà cảm thấy là mình có thể làm tốt hơn được cho cái chuyện là anh vừa mới stay ra, là đội mình thiệt ra là cái team Foundation, cái team Lab á vẫn sẽ được ưu tiên nhiều hơn trong những vấn đề khác nhau. Được ha. Nên là nếu mà anh em cái bài đó mà đang kiểu làm qua loa á, tập trung ngồi làm kỹ lại tí, check hai thứ ha: văn hóa trên đó là một, thứ hai nữa là kiến thức cho cái cụm thông tin cái cụm gần nhất mà nó đang có vẻ hot nhất là LLM thôi.\u003c/p\u003e\n\u003cp\u003eNhưng thực ra team mình vẫn cover rất là nhiều mảng khác nhau, vẫn đang có xem về design, mấy bạn cũng đang xem đúng không. Vẫn có đội đang xem đúng không. Go vẫn đang xem. Blockchain có vẻ nó qua trend tí rồi, thị trường nó đang sideways thôi, nhưng mà về demand của consulting nó vẫn yêu cầu những cái đó rất là nhiều.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:31:46\u003c/strong\u003e Mấy cái mini app cho telegram, họ mua về rồi clone nhanh lên, thấy góc nhìn của mấy bạn làm business logic (BL) và tech (TCH) bây giờ nó khác một xíu rồi, không còn như ngày đầu nữa. Nhưng mà với consulting mình vẫn có thể sử dụng thôi, bình thường. Hoặc là mình có thể nhìn theo một góc nhìn khác, theo dạng là nó như một cái asset class mới xuất hiện. Với vai trò là developer, mình phải nhìn nó theo góc nhìn làm sao để nó ảnh hưởng đến cái workflow của mình như thế nào, quản lý tài sản ra sao.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:32:29\u003c/strong\u003e Đó là vấn đề về bài test nhé. Mấy anh em chú ý cái đó. Thứ hai, nãy có nhắc tới cái định hướng về team và số lượng nhân sự. Trong đó có nhắc lại cái link notion hôm trước anh có gửi nhé. Đội Foundation, đội chính khi start lại lần nữa như vậy. Lúc trước team tụi anh bắt đầu chỉ có ba người thôi, sau đó dần dần tăng lên bốn người, rồi lên năm người. Có thêm Quan, có thêm Hiếu, có thêm mấy bạn khác. Nhưng mà ban đầu start với ba người, giờ đội hình xịn hơn rồi. Bây giờ 40 người toàn là thứ dữ, chắc chắn sẽ đi nhanh hơn. Câu chuyện chung là vậy, đánh giá chung cũng là như thế, nên mấy anh em nắm tình hình nha.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:33:12\u003c/strong\u003e Cái thứ ba nữa có liên quan là Huy Nguyễn, nếu mà xong rồi, chắc tuần sau xem lại thống kê con số về ICY giùm anh nha. Hôm trước em cũng báo là số lượng bắt đầu chạy hơi nhiều, nên mình phải xem lại, cân lại con số cho nó hợp lý. Riêng phần này nhờ Huy và Thành chủ động làm giùm, xử lý giùm anh, xem lại cân số cho nó hợp lý. Thành có một công việc phụ là phần benefit cho thành viên team Lab, xem thử đề xuất như thế nào. Nó có thể được coi là một cái payon, nhưng mình sẽ không trả qua kênh bình thường, mà sẽ có cái cơ chế khác.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:33:52\u003c/strong\u003e Nhưng mà mấy thành viên team Lab sẽ có cái đó, mọi người quen với cái đó rồi. Cuối cùng là, riêng phần về LLM hiện tại, trong cái list câu hỏi có một câu hỏi quan trọng là làm sao để sử dụng, tìm hiểu bên ngoài sử dụng LLM như thế nào và adapt ra sao. Nhấn mạnh lại câu đó, vì nó là một câu mang ý nghĩa trong việc làm knowledge discovery. Câu hỏi này liên quan đến việc test là không chỉ đơn thuần là dùng, mà là tất cả các công cụ mà mấy anh em thấy được trong team hiện tại. Khi có người sử dụng hiệu quả, có người sử dụng kém hiệu quả hơn, RT (retrieval technology) nó thành một spectrum rất rõ ràng, những người thấp là thấp, những người cao rất cao.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:34:38\u003c/strong\u003e Tụi anh muốn nâng cái standard đó lên. Spectrum đó tụi anh muốn rút ngắn lại, càng cô động lại càng tốt. Bây giờ nó đang rất dài. Câu này ngoài việc dùng tool để làm discovery, nó còn mang ý nghĩa xem ngành nghề của mình sẽ như thế nào trong việc ứng dụng đó để nâng cao competency của mình, làm việc có năng suất hơn. Đó là toàn bộ vấn đề, và mọi người xác nhận lại xem cái mình làm có đúng chưa, nó có tầng ý nghĩa sâu xa hơn vậy.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:35:20\u003c/strong\u003e Cuối cùng để kết thúc buổi này, Thành ơi, mấy buổi OGIF sau, những phần mà Tom đã làm liên quan đến việc xây dựng structure của một cái LLM app, có thể lấy cái đó ra phân tích thử nhé. Phân tích lấy cái đó để làm sâu hơn luôn nhé.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:35:56\u003c/strong\u003eToàn bộ mọi người hy vọng là tất cả anh em đều pass hết để đi chơi cho nó vui vẻ. Tuần sau sẽ có một cái bài khác. Tuần sau request là bên chỗ của Minh L. Minh ơi, chắc là lên làm một cái demo nha, tiếp tục về cái finite state machine, FSM á. Vì trong định hướng những công nghệ nền tảng như blockchain, AI, nhưng phần chính vẫn sẽ là các anh em làm engineer sẽ có một ngách khác để đi, đó là hiểu rõ các hệ thống lớn vận hành thế nào. Tương lai, nếu mình không phải là người sinh ra để làm data manipulation AI sẽ làm giùm mình, mình không cần tự thiết kế hay làm mấy việc của junior nữa.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:37:35\u003c/strong\u003e Cách duy nhất để lên senior là hiểu rõ vấn đề và làm kiến trúc thôi. Phần finite state machine đóng vai trò tương đối quan trọng, liên quan đến chuyện scale mà trước giờ tụi mình đã nói nhiều. Trước đó Minh có đọc và hiểu đúng góc nhìn mà anh đang muốn hướng tới. Nên là xem thử làm bài phân biệt các loại general server của nó nhé. Server state machine và event-based server. Rồi làm một cái sample để biểu diễn và implement nó luôn bằng Erlang nha. Erlang có sẵn hết các framework rồi.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:39:01\u003c/strong\u003e Bài này chắc là khi nào Minh Lưu. ready, nếu tuần sau không kịp có thể là hai tuần. Đề nghị mấy bạn backend và mấy bạn sen team mình gom lại, có gì confirm trước nhé. Vì bài này rất quan trọng trong chuyện phân tích thiết kế phần mềm. Bài này rất quan trọng. Trước giờ mọi người chỉ nói tới modeling và làm C4 thôi, nhưng Erlang là ngôn ngữ đi sát cái này nhất rồi, thường mọi người sẽ không biết hết. Chúng ta không nhất thiết phải học Erlang nhưng có thể nhìn cách thiết kế và build của họ để làm phần đó rất chuẩn, giống như là họ có framework sẵn, mình chỉ cần gắn vào để sử dụng thôi.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:39:37 T\u003c/strong\u003eranh thủ, ngày 20 tháng 10 là chủ nhật, Mỹ với Ngọc và Giang có post rồi. Hôm đó là các chị em đi chơi, còn không ở Sài Gòn đại diện team sẽ chúc mọi người phát tài. Chúc mọi người phát tài chắc hợp lý nhất trong trường hợp này. Một chút chúc khác có vẻ không liên quan lắm. Rồi vậy nha, anh em tham gia được đăng ký với Mỹ để book bàn và đi cho hợp lý.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:41:19 N\u003c/strong\u003ehờ Thành những buổi sau cấu trúc lại thành mấy cái talk nhé. Rồi làm goal đó, team mình có thêm Builder-club nữa, đội đó chắc để xem mấy anh em lúc trước làm Super Bit ổn định lại hoặc làm console ổn định lại anh sẽ cấu trúc lại sau nhé. Đợt này chắc là nghỉ ngơi đầy đủ rồi. Rồi ok, anh em có câu hỏi gì cho bài test không kết thúc ở đây nhé. Rồi tạm biệt mấy anh em, hẹn gặp lại tuần sau. Cảm ơn Thành, cảm ơn tất cả mọi người.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cstrong\u003eEnglish Transcript\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e0:28\u003c/strong\u003e The topic still includes Go Weekly, and Nam is currently testing the weekly design commentary. Let's see how it goes over the next few weeks.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e11:19\u003c/strong\u003e Nam will continue to present to the team, and there are a few topics from Hoang, Cat, and Dat. We’re currently researching various use cases that other companies are applying and some of the tools being used by developers. There will likely be a presentation this week or next about these findings. The focus will be on generating a UX design button. In the past, there have been questions about where AI is applied and how it plays a role, whether it serves as a small, standalone component or as part of a broader application for digital products. Today, I will address how AI contributes and how it functions.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e12:11\u003c/strong\u003e First, I will talk about system scope relationships. This diagram illustrates how AI is integrated into systems at different levels, from a small component to a comprehensive ecosystem. AI can be a small part of a component or evolve into a larger function, automating features to improve user experience (UX). Here, AI plays a crucial role in digital products, and when integrated, it can fit into various parts—from components to flows, to features, or even as an entire application. It can be part of a platform or ecosystem.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e12:53\u003c/strong\u003e For example, as a feature within an app, AI can help users interact with the app more easily, saving time by automating tasks that would otherwise be done manually. As a standalone application, there are many examples like ChatGPT, which serves a specific purpose, or as a platform like Rewind AI, which offers multiple features supporting AI in different tasks within the same app. These are examples of the scope of AI's current operations.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e13:39\u003c/strong\u003e Next, regarding the spatial relationship, this helps us understand how AI features are placed and organized within the user interface (UI). There are several ways to integrate AI into design, and it's important to know how to position them in the app so that they optimize user experience without causing confusion or making the interface too complex. Spatial relationships directly affect user experience. For example, AI can operate independently or alongside other features while still maintaining its own space. When you understand these relationships, you can choose how to place and use AI features in a way that enhances usability without overwhelming the user.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e15:11\u003c/strong\u003e There are six different methods for presenting AI: it can be entirely separate, alongside other features, layered, integrated with the parent feature, or in small points such as icons. These methods include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSeparate: AI operates as a separate feature.\u003c/li\u003e\n\u003cli\u003eAlongside: AI is placed next to other features.\u003c/li\u003e\n\u003cli\u003eLayer: AI overlays with another feature.\u003c/li\u003e\n\u003cli\u003eIntegrated Parent: AI serves a major role in navigating and managing core content.\u003c/li\u003e\n\u003cli\u003eIntegrated Child: AI operates as a secondary, smaller feature.\u003c/li\u003e\n\u003cli\u003ePoint: AI is a small icon or widget that helps the user understand its function.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e16:41\u003c/strong\u003e Moving on to the functional relationship, this describes the functional interactions between AI and other features in the system. AI can exist separately but still adapt to the overall content and functionality of the app at a higher level. AI can integrate with existing features to improve performance, replacing manual tasks. Understanding how AI works functionally allows us to define its role clearly in the app and design in a way that ensures the functional actions don’t conflict with one another and don't disrupt the user flow.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e17:28\u003c/strong\u003e There are six methods to describe this functional relationship, which are similar to the spatial relationships I mentioned earlier:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eSeparate: AI operates independently.\u003c/li\u003e\n\u003cli\u003eAware Of: AI exists separately but is aware of how it affects the main feature.\u003c/li\u003e\n\u003cli\u003eActing Up: AI interacts back and forth with other features, adapting data between them.\u003c/li\u003e\n\u003cli\u003eFeature Incorporate: AI is incorporated as a part of an existing feature.\u003c/li\u003e\n\u003cli\u003eUsage: AI adapts based on how it's used within the app.\u003c/li\u003e\n\u003cli\u003eUsage Conventionally: AI communicates directly with other features in a two-way interaction.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eI will provide an example of this functional relationship in the code I am about to show, where AI generates a panel on the right side of the screen.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e19:06\u003c/strong\u003e For example, the acting-up relationship means AI can be aware of and react to changes made by other features, like data syncing between two systems. In contrast, feature incorporation would mean AI is integrated as part of the overall functionality of a specific feature.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e19:57\u003c/strong\u003e That covers the main aspects I’ve discussed so far, with three key elements for integrating AI into product design: optimizing product features, improving user functionality, and enhancing the overall effectiveness of the AI-powered system. It’s important to understand how to apply AI properly to provide clear value to the user. If we understand how to apply AI effectively, it becomes easier to design a system that brings value to the user by integrating AI in a meaningful way.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e20:53\u003c/strong\u003e I realized I missed an example earlier, so let me go back and explain. I’ll share a few examples that I think will clarify the functional relationships we discussed. For instance, in Microsoft, there’s a tool that generates images—this operates alongside other features in a parallel fashion. There’s also a feature that sits beside the main functions of the app but doesn’t serve as a core part of the experience.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e22:01\u003c/strong\u003e Yes, that's a good example. The functional actions and spatial relationships you presented seem to be similar to common patterns. These are just standard patterns for AI design—how to integrate an AI feature into an app or design an AI-driven app, depending on how it’s categorized.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e22:31\u003c/strong\u003e Yes, these are patterns we often use when designing AI applications or integrating AI into a separate application or product. Essentially, they are familiar structures to help us better understand how to apply AI. You can categorize and break them down into smaller features. This part is very clear.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e23:31\u003c/strong\u003e Thank you, Nam. Ok, next will be Hoàng and Đạt’s presentation.\u003c/p\u003e\n\u003cp\u003eToday, I will introduce a topic called \"AI Button in LLM Applications.\" Before diving in, let me briefly cover the content and agenda. First, we will explore design patterns related to the AI Button. These patterns are applied in various applications. I’ll pick out the most common and understandable ones to introduce to everyone.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e24:35\u003c/strong\u003e This presentation will revolve around using AI in digital products. These applications leverage the power of AI models to solve specific problems or assist users in tasks. When using LLMs, many may encounter the issue where the model does not provide the expected result. This happens because the model operates based on its ability to respond using the data it has been trained on. There are multiple ways to address this issue. One of the most expensive ways is to retrain the entire model from scratch, which can take a lot of time and resources.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e25:15\u003c/strong\u003e We have a technique called \u003cstrong\u003ein-context learning\u003c/strong\u003e, which means AI can learn directly within the current context while you are using it. This technique includes few-shot learning or zero-shot learning, allowing the AI to learn without needing to be retrained from scratch. For example, you only need to provide the AI with a few small examples in the context, and it will adjust its behavior based on what is provided. Instead of retraining the entire model, this method saves a lot of time and resources while still ensuring the AI can learn from the specific context you give it.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e25:52\u003c/strong\u003e In this case, \u003cstrong\u003ein-context learning\u003c/strong\u003e is widely used in \u003cstrong\u003eprompt engineering\u003c/strong\u003e. People provide available examples directly into the prompt, and the model learns from those examples to generate subsequent results. That's the main idea of in-context learning. Essentially, the design works like this: you have a query, then you build a prompt with the necessary examples and few-shot learning data, and you pass it through the model, which returns a result based on those examples. However, it doesn’t stop at just examples; many other factors are involved as well.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e26:37\u003c/strong\u003e Broadly speaking, in-context learning involves feeding the context into the prompt by providing information that the model doesn’t inherently have. Since this is a pre-trained model, its knowledge is limited, so you provide additional information in the context and prompt for the model to learn during the result generation process. For instance, in medical image diagnosis, the model may not have enough specialized knowledge. Therefore, you provide that expertise into the context and prompt so the model can learn during the result generation process. That’s the core of in-context learning.\u003c/p\u003e\n\u003cp\u003eNext, we have another important design button, which is \u003cstrong\u003edata preprocessing/editing\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e27:54\u003c/strong\u003e This section describes the process of preparing data for the language model (LM). As you know, LMs operate based on vector databases, using vector comparisons to find similar data points. This process often involves handling multimedia data and various types of information. To ensure optimal output, applying data preprocessing steps is crucial. For example, you can preprocess text by filtering out unnecessary details to shorten it, or with images and audio, you can remove noise or compress the data to reduce size before passing it through the language model.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e29:19\u003c/strong\u003e Data preprocessing or editing helps the model operate more efficiently. There are many ways to preprocess, depending on the type of data or context. You perform this based on specific requirements. The next design button I want to mention is a commonly used one, though it goes by different names. I call it the \u003cstrong\u003eexample agent\u003c/strong\u003e. This design is commonly seen when you want your query to pass through multiple contexts. For example, if you have a content review application, you can let that content pass through a pipeline where each agent evaluates the content from a different perspective.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e30:11\u003c/strong\u003e One agent might evaluate the content from a writer's perspective, and another agent might do so from a different angle. After going through all these agents, there will be a final synthesis layer to combine or process those results, ultimately providing the user with a comprehensive output. This design is often seen in evaluation systems where results from different models are evaluated, and the best outcome is chosen based on predefined conditions.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e30:55\u003c/strong\u003e The next design button is called \u003cstrong\u003eagentic button\u003c/strong\u003e. So, what does agentic mean? In the context of language models (LMs), \u003cstrong\u003eagentic LMs\u003c/strong\u003e refer to enhancing the model's capabilities. Since the model only knows what’s in its training data, we upgrade it to increase its power and minimize human intervention. This design helps the system become more automated, allowing it to operate with less human interference.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e32:24\u003c/strong\u003e This design has several key components that help you achieve this level of automation. There are four main components: \u003cstrong\u003ereflection\u003c/strong\u003e, \u003cstrong\u003eplanning\u003c/strong\u003e, \u003cstrong\u003eexecution\u003c/strong\u003e, and \u003cstrong\u003emulti-collaboration\u003c/strong\u003e. Each of these components helps make your system more automated. First, let’s talk about \u003cstrong\u003ereflection\u003c/strong\u003e. Reflection involves evaluating the initial results of the model based on a specific criterion or metric to determine if the result has been optimized. If it hasn’t, the system adjusts and repeats the process, continuing to generate results until it reaches an optimal outcome.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e33:06\u003c/strong\u003e Reflection helps reduce human intervention because, instead of producing an initial result that doesn’t meet your expectations, the system refines itself based on pre-established criteria, eventually delivering a more accurate result without manual adjustment.\u003c/p\u003e\n\u003cp\u003eThe Reflection button means that it will evaluate the initial output of an AI, then assess it according to a certain standard or metric to see if the result has been optimized. If not, it will adjust slightly and run the AI again to generate another result until the optimal result is achieved. This helps reduce the need for human intervention, as if the first output is not what you expected, you don’t need to manually adjust it—the system will optimize itself.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e33:42\u003c/strong\u003e The second button is the tool. Tools can be external, such as external APIs or functions that people code. These tools are used to allow the model to access knowledge from the outside world, real-time knowledge, or external resources that it hasn’t been pre-trained on. For example, OpenAI or Claude both support this. The model can know when to call the tool based on the description you write for the tool. The model will know how to retrieve and extract information from the tool and then return it to the LM to generate an output.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e34:30\u003c/strong\u003e Next is planning. The planning button means that you give the LM the ability to plan, preventing the need to prompt multiple times. For example, if you have a complex task, you provide a large prompt for the LM to plan out all the steps it needs to take in a step-by-step manner. This allows it to perform smaller tasks first, which are eventually combined into a larger task. This planning design has many variations, and this is the simplest version: planning and then executing step by step.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e35:10\u003c/strong\u003e Finally, multi-collaboration. I presented this about a month ago. Essentially, it's like having the AI excel at a particular task. You have a context, right? You divide it and pass it through to different agents. Each agent is good at its specific task, and after they complete their tasks, it passes on to the next agent. In this way, it can complete the requirement. This design heavily utilizes the divide-and-conquer principle—breaking a large task into smaller tasks and assigning each to a specialized agent. This is a design button I’ve seen being used in many places.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e36:24\u003c/strong\u003e Those are the design buttons that I’ve seen used in many places and understand the most. I’ve finished my presentation. Does anyone have any questions?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e37:10\u003c/strong\u003e Hoàng, can you repeat the part about planning to confirm Bảo’s comment? It’s like it reads the prompt, right? It understands your prompt first, then breaks it down into smaller tasks, and then there are workers—perhaps IDE workers or smaller prompts—to complete the task. Is that correct?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e37:40\u003c/strong\u003e Yes, you can think of it that way. You can split the prompt, for example, in a complex task, into several smaller plans. These smaller plans will be done step by step. For instance, it executes plan 1 first, then plan 2, then plan 3. Once all the plans are completed, they are compiled somewhere or in a final component to produce the final answer.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e38:06\u003c/strong\u003e It’s like the Zero you presented last time, right? The worker can do tasks like reading files, deleting files, modifying files, or interacting with the Internet, sending emails, and so on. So basically, agents work in this way.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e38:52\u003c/strong\u003e Exactly. Instead of handling a massive task all at once, which requires repeated prompting, you start with a prompt that breaks the task into smaller tasks, and then a pipeline runs through each worker, handling small tasks for you.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e39:23\u003c/strong\u003e Ok, pull up slide 14, Hoàng. Slide 14. I also see this is kind of like the Mule Automation setup that Tom created, right? The Mule button that Tom set up. I’ve finished the code, but this design and the button look exactly the same.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e39:46\u003c/strong\u003e Yes, this is a looping process with Tom, which looks somewhat similar. It’s like planning, as Tom mentioned, where it breaks down the task into parts and handles each part. It has iterations within it, like a list of steps you described earlier. Referring back to yours, the agents can see that. What I’m seeing looks more like planning: it splits the plan upfront and then works step by step on each plan, moving through each round one by one. This one, though, works more in parallel, where they run simultaneously, produce the output, evaluate it, and then return the final result. I think I got the workflow mixed up; it’s now corrected.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e42:28\u003c/strong\u003e Exactly, give it a try. It works like that, breaking down into different tasks. It’s more like a classification, running through each one. This is closer to multi-collaboration because it’s like a question classifier, where only one agent runs for each task. Each agent works on its specific expertise, then combines everything.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e43:33\u003c/strong\u003e But do you think the parts like reasoning and input analysis are correct? Tom’s expert part. Specifically, for picking domains, there’s a classifier, but reasoning and input analyzers are separate agents. In that group, they’re experts, right? We consider them a group of experts, and they combine with the five agents underneath.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e45:33\u003c/strong\u003e If we try to do everything within a single prompt, I’m certain it won’t give us the desired result. The context is too large and lacks specific examples. The main issue is that accuracy will definitely decrease because there’s too much data at once. The key is to split it into multiple layers, step by step. In reality, we need the output from the LM; we can’t hardcode it all in advance. We just want the simplest prompt so it can generate small answers that ultimately lead to a large answer.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e46:59\u003c/strong\u003e Exactly, by breaking it down, we can identify where the problem lies and debug it. Like you mentioned, specify clearly and break it down into layers. If something goes wrong, we can fix that part. If you throw everything in at once, you won’t know where the error is, and you’ll have to fix it repeatedly.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e48:43\u003c/strong\u003e Exactly. For example, creating an event in the calendar for tomorrow—if there’s no event at that time, it creates the event, but if there is already one, it sends a notification. If we throw in a large request at once, it will get confusing because it has to execute step by step. Breaking it into layers and testing each step will make it work better.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e49:23\u003c/strong\u003e I'm almost certain that 99% of the time, it will get lost if it’s done in one go. However, if we split it into layers, into multiple layers, and do the tests, it will work much better. Ok, let's go. If anyone's at the office, Tom’s probably there to argue with. If no one has any more questions, thanks to Hoàng first. Now, Đạt, you’re up. Đạt, are you sharing your screen? Ok, can everyone see my screen? Yes, we can.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e50:38\u003c/strong\u003e Today, I’m going to talk about Yelp use cases. Wait a second, Đạt, let me introduce some context first. So this time, the team will focus somewhere and search for some use cases. There are different types of use cases. The type Đạt is sharing is where we look at how startups or enterprises are applying AI to solve specific problems. It could be something completely new, like a greenfield, or it could be optimizing the current workflow of their system. They will write use cases and report updates monthly. In addition, there’s another type of use case, which involves tuning to boost the development on the tech side. They will also report that part somewhere in tech. We’re testing this for about two weeks. This is the first report, and it’s about Yelp. Yelp is a startup, right? Now, Đạt, introduce how they are applying AI.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e52:01\u003c/strong\u003e Yelp is a company that provides software to stores and businesses that want to offer services like fast delivery, restaurants, or basic utilities. Yelp sells the software for those tasks. I’ll share a bit about how they use AI in their tools.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e53:00\u003c/strong\u003e Before this, they had a machine learning system, but now they’ve added AI to improve the accuracy of their recommendations. Yelp has many types of reviews on its system, like restaurant reviews, which may not always be good. Based on those reviews, they do some text editing to compare whether the results are spam or legitimate. AI is used here in several ways. First, they use AI to create datasets to train a model to assess whether a review is spam or a good/bad review. They use AI to generate datasets based on LinkedIn. From what I’ve read, they use techniques like Zero-shot and Few-shot learning to create these datasets. They use some models from Hugging Face and then classify the reviews as good or bad. This is one use case where AI is applied in text editing.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e54:18\u003c/strong\u003e Now onto the second use case—they use the Clip Model. The Clip Model primarily processes images. What does that mean? It means that based on reviews... wait a minute, let me find the reference... Ah, Clip processes two things: one is the caption of the image, and the other is the image itself. Through Clip, it can understand the context of the image. Yelp uses Clip for tasks such as when someone goes into a restaurant or pub and posts reviews or captures images of the place. For example, before applying Clip, it couldn’t identify if there were waffles in a dish; it could only identify fried chicken. After applying Clip, it can now recognize both fried chicken and waffles. Essentially, it uses Clip as part of AI to process images, captions, and convert images into vectors to compare them. So, these are the two use cases for Yelp.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e55:38\u003c/strong\u003e These two use cases are applied in situations where you have many reviews, and you can summarize them into a highlight review. Based on the information converted into vectors, it can annotate what the images are conveying, and what they are supporting. Just give it a moment, it will highlight it for you. It understands the context of the image and can annotate it accordingly. This is the use case for how AI is used in image summarization.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e56:15\u003c/strong\u003e Earlier this year, Yelp released the Yelp Assistant. Based on their existing platform, they were able to create a chatbot that reviews highlights like this. You simply ask, and it recommends something for you. It's as simple as that. Additionally, I noticed a use case from 2020 when the trend of short review clips started becoming popular. Yelp had a dataset specifically for that purpose. They mentioned that they are about to release something, as Tom referred to, that can convert text to speech. Based on the review dataset, they might support creating short video clips to describe a restaurant.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e57:45\u003c/strong\u003e Based on reviews or videos posted by people, Yelp could generate a script and run it through AI to automatically create a video about a restaurant. That’s the use case. It’s simple as that. Ok, going back to the first question, this use case is essentially using AI to label data, right?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e58:35\u003c/strong\u003e Ok, so it checks whether the comment is negative or positive, right? That’s one example. The second one is using the Clip Model, correct? It’s similar to Vision but more live, also for labeling, right? Like with Plot, labeling for images. So, these two use cases are applied for what?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e59:18\u003c/strong\u003e I think there's an interesting point that hasn't been mentioned yet, which is the story about having a ready-made dataset. For instance, when someone leaves a review or gives a rating, based on these short clips, Yelp could generate an intro video for the restaurant. It uses AI for that. I think they use AI to write the script and then pass that script to an AI voice to narrate. But where do they get the images from? How do they get the video content?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e59:57\u003c/strong\u003e From the review, when someone comes to review, they will have a video to review. Ok, so it's automatically generating an advertisement, right? Yes, for TikTok or similar platforms, summarizing user reviews. Sounds pretty creative. Yeah, I guess you guys have confirmed what Bảo mentioned, right?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:00:07\u003c/strong\u003e Yeah, this one is about the caption, and it's mostly correct. You're right, I think the initial purpose of this use case was for recommendation. Before they had AI, they already had a hybrid recommendation model in place. Basically... I think with this new AI, they will likely replace the old model. One interesting point that wasn't mentioned much is business messaging. I think it’s based on, say, the top 50 reviews or top 50 interactions—how are the ratings, and if the reviews are good and the ratings are good, then the business messaging will also be good. But Yelp didn’t bring up this topic, and we can’t blame them for that.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:00:51\u003c/strong\u003e Does anyone have any questions for Đạt? This is his first presentation. Đạt mentioned he’s working on adding more, probably for enterprise too. But I’ve seen Viettel, FPT, and VNG, and I’m still not sure how they are doing things. Đạt said some of FPT's coding tools are kind of lame.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:01:41\u003c/strong\u003e Haha, is it just a continuation of a previous version? Yeah, it’s not great. It’s a bit rough and underdeveloped. Are we done with that? I guess so. Ok, Đạt. Today we’ve covered Yelp and Tech Linh, so maybe next week or the week after that, if time permits.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:02:01\u003c/strong\u003e Let's do a demo real quick, Đạt. Could you demo something for us? What about a bot that can handle questions or understand short code from a developer’s perspective? Or something like an auditor checking the code quality? Could you demo the workflow or the bot you’re working on with that diff you mentioned? Please turn on the screen, Đạt.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:03:01\u003c/strong\u003e So this is a project I’m working on for joining the AI Club. I’m pretty new at this, so if the project looks rough, please bear with me. The basic workflow is that I take a query and extract the URL of a repository. Here, I reused Tom’s scraper, but it didn’t fully meet my needs, so I created my own local scraper to fetch all the content from the repo. However, that takes too long and generates too much data. As of now, I haven't found a way to add it to the context unless I use knowledge retrieval. But to use knowledge retrieval, I have to prepare it in advance; I can’t select the repo directly.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:05:45\u003c/strong\u003e Tom’s scraper doesn’t capture the content of the files, so I haven’t been able to draw a diagram yet. I might use it for the diagram later, I’ll test it out. This scraper only fetches the content from the root directory and some doc files. Those files might not answer Huy’s question accurately. Let me try it; I have my full setup ready offline. The content is already prepared, not online. This was generated directly, so it doesn’t have it either.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:07:07\u003c/strong\u003e This scraper fetches the full content, so it’s more complete. Let me try asking questions like Huy’s or Hoàng’s. Let’s try BC chat and ask a question there. Do you have it? Ah no. Maybe the context is too large, and I haven’t figured out how to integrate it properly into the knowledge retrieval part.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:09:19\u003c/strong\u003e The retrieval process is very optimized. This text file has tens of thousands of lines, tens of thousands! Let’s open it and see. Are you using a mini machine? Try switching to a more powerful machine to see if it runs better. The mini machine is a bit weak. Two million words... how is it even handling that? I think you’d need a dedicated server to run it efficiently. I’m curious how it's even running; we’re talking about 29U words, as we saw. Multiply that by 4, and the number is huge. The size... Let's follow up and see. Ok, so you’re working directly from the context, right? You’re querying like a typical query vb, rather than feeding all the data into the context.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:10:57\u003c/strong\u003e Right, exactly. I’m not sure how the retrieval in this diffy system works. I don’t know if it’s retrieving the correct data or if it’s retrieving at all. I haven’t been able to trace it, but I have a tracing tool that I can test later to see how it works. But the idea is that if the retrieval works like this, it probably won’t give accurate results. You’re unsure about how much data it's running, right? It seems to only prefer 2-300 items, and that’s not enough data for these kinds of tasks. This requires at least several hundred data points. So yeah, this is still a work in progress.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:11:35\u003c/strong\u003e Just joking—there’s always the AI Club at the company! Oh, so is this the full version, or is it the fixed one? If it’s fixed, demo it for us in the office, and try to leave it for me. OK, let me see. It still hasn’t built, so people are just watching for now. The build seems to have some issues—can everyone see the screen?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:13:08\u003c/strong\u003e So, this week, as I mentioned last week, I will upload the sync.Map article. I think it's really useful, with details that give people using Go a general overview of maps. Regarding sync.Map, let's first go over the context. When writing maps, especially concurrent maps or concurrent operations, before version 1.16, it wouldn’t show any errors, but it wasn’t safe either. From version 1.16 onward, it throws an error like this. So to solve this issue, people usually write maps with a sync package, like using manual sync.RWMutex.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:13:56\u003c/strong\u003e Besides that, there’s another option called sync.Map. Later, I’ll explain why this option exists and what its use case is. This sync.Map was created so that you don’t have to worry much about using mutexes to lock data for synchronization. You just use it. It’s as simple as this, and it’s friendly—just like using a map to check values. For example, when you load a key with a value, if it's available, it returns true; otherwise, it returns false, just like a regular map.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:14:38\u003c/strong\u003e Additionally, it has several handy functions. For example, version 12.23 has \u003ccode\u003eclear\u003c/code\u003e to clear everything, \u003ccode\u003eload\u003c/code\u003e to get a value, \u003ccode\u003estore\u003c/code\u003e to update or store a key, and so on. Besides writing concurrently, when you range (loop) over a map, race conditions can also occur. However, with sync.Map’s range function, it handles that, so you don’t have to worry about it. It doesn’t behave like a typical range function. However, it doesn’t give you a fully consistent snapshot. When you first enter, the snapshot may not be updated. So, during this, you have to change your writing method, but at least it won’t error like this.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:16:06\u003c/strong\u003e Now, let’s go over how it works. When you write and define the map, it’s structured with two maps. At this point, you might be thinking, “Wow, this sounds like it’s heavy on RAM and memory!” There’s a Read-Only map and a Dirty map. From this, you can infer that values, when written, will be updated in the Dirty map. It just keeps updating there, while the Read-Only map.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:16:46\u003c/strong\u003e The Read-Only map will always be used when you're reading. Meanwhile, the writes will always be made to the Dirty map. As for the underlying flow, we’ll look at the chart in a moment to better understand it. Both of these maps have a common point: they both use a pointer called an entry. Pay attention to this part to make the flow easier to follow. For example, when you add a new entry, it will be added to the Dirty map, and both will point to this entry. This works as a flag that indicates the map has been changed. So, at this point, the Read-Only map is no longer the most up-to-date version. The system will know that the Dirty map is the one to read from.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:17:27\u003c/strong\u003e This diagram shows that, for example, when you update a value, since it’s using a pointer underneath, you only need to update the pointer itself, not each value as you would in a traditional map. To achieve this, the system implements a mechanism that defines three states for the entry pointer. The first state is the \u003cstrong\u003enormal state\u003c/strong\u003e, meaning that the old values in the map are still intact and can be used, without any issues. The second state is \u003cstrong\u003eamended\u003c/strong\u003e, meaning that the entry has been modified. And the third state is the \u003cstrong\u003edelete state\u003c/strong\u003e, where an entry has been deleted from the map, but it hasn’t been completely removed. It’s still held in a transitional state, and the entry pointer is moved to a new position, but it hasn’t been fully removed yet.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:18:59\u003c/strong\u003e The pointer \u003ccode\u003eentry\u003c/code\u003e is assigned to the \u003ccode\u003enew entry\u003c/code\u003e, but it hasn’t been removed yet. The \u003ccode\u003eexpired state\u003c/code\u003e refers to complete deletion, like a hard delete, meaning the entry is completely removed from the map. To help visualize this, you can refer to this flow: for example, at the beginning, the map has a \u003ccode\u003ekey1\u003c/code\u003e and \u003ccode\u003evalue1\u003c/code\u003e, and at this point, the \u003ccode\u003eDirty map\u003c/code\u003e has nothing, meaning nothing has been added or changed yet. Then, if you add a \u003ccode\u003ekey2\u003c/code\u003e, it will be added to the \u003ccode\u003eDirty map\u003c/code\u003e, and at this point, the map is marked as \u003ccode\u003eamended\u003c/code\u003e because a \u003ccode\u003eflag\u003c/code\u003e indicating \u003ccode\u003eamended\u003c/code\u003e is set here.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:19:40\u003c/strong\u003e Afterward, when you delete a \u003ccode\u003ekey\u003c/code\u003e, the map will be assigned a \u003ccode\u003enew entry\u003c/code\u003e, right? The same thing happens on the other side, as it is also assigned a \u003ccode\u003enew entry\u003c/code\u003e, similar to the previous diagram. In essence, you’re only updating the pointer without having to update the values themselves. Then, after completing the deletion, to promote the \u003ccode\u003eDirty map\u003c/code\u003e, you must update it through the \u003ccode\u003eRead Only map\u003c/code\u003e so that the \u003ccode\u003eDirty map\u003c/code\u003e returns to a \u003ccode\u003enew state\u003c/code\u003e, like resetting it to the original state.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:20:18\u003c/strong\u003e Similarly, when adding a new \u003ccode\u003ekey3\u003c/code\u003e, after the state has returned to the \u003ccode\u003enew state\u003c/code\u003e, and you add \u003ccode\u003ekey3\u003c/code\u003e, the system identifies that the previous entry has been deleted entirely. This means that next time when it compares with the \u003ccode\u003eDirty map\u003c/code\u003e, it knows that the \u003ccode\u003evalue1\u003c/code\u003e has been deleted and no longer exists. At this point, the \u003ccode\u003eRead Only map\u003c/code\u003e will only contain \u003ccode\u003ekey2\u003c/code\u003e and \u003ccode\u003ekey3\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:20:51\u003c/strong\u003e Due to this, \u003ccode\u003esync.Map\u003c/code\u003e does not have a \u003ccode\u003elen\u003c/code\u003e function for users to utilize. This is because, if you used the \u003ccode\u003elen\u003c/code\u003e function here, it would not account for the actual values, as it would count even those that have been expired or deleted. As you can see, because \u003ccode\u003esync.Map\u003c/code\u003e is structured this way, its use case is recommended for scenarios that require more reading (\u003ccode\u003eread\u003c/code\u003e) than writing (\u003ccode\u003ewrite\u003c/code\u003e). If you perform a lot of \u003ccode\u003ewrite\u003c/code\u003e or \u003ccode\u003edelete\u003c/code\u003e operations, just imagine the pointer being used continuously, and there’s even an issue reported by the Go team that this map is never garbage collected.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:21:36\u003c/strong\u003e Later, the Go team confirmed that this \u003ccode\u003esync.Map\u003c/code\u003e was designed primarily to support some of the internal Go Library processes. If you find it handy because of its user-friendly functions, you can use it, but for use cases that involve storing (\u003ccode\u003estore\u003c/code\u003e), updating, or deleting often, it’s not recommended, as it may slow down the system.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:22:24\u003c/strong\u003e That’s about it. I’ve written some code based on this topic, and there’s a blogger who shares detailed posts on this subject, so you might want to follow them. Oh, what’s the topic, Phát? Show me the post again. Ah, \u003ccode\u003esync.Map\u003c/code\u003e, right? \u003ccode\u003eSync.Map\u003c/code\u003e. Does it differ from what you just passed in? What’s different? I think it does. The point is that I remember, depending on the community, people might have different use cases. For instance, if someone wants to implement something specific, they can adapt it as needed.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:23:30\u003c/strong\u003e You can see that some people add an extra layer on top for their own use cases. For example, some want to implement generics on \u003ccode\u003esync.Map\u003c/code\u003e. This is partly because of the linking issue I mentioned earlier, where the map isn’t garbage collected. That’s the problem. The Go team has already confirmed that this behavior is intentional, and they won’t fix it. They’re not going to change it, right? So now, what the community does is figure out how to work around it. They like how easy \u003ccode\u003esync.Map\u003c/code\u003e is to use, with those nice functions, so they just add another layer to customize it further, making it usable for their specific needs.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:24:07\u003c/strong\u003e Why are we discussing this old clip now? Oh, it’s just an insight for people to use. This use case can be applied to enterprise environments too. For example, in enterprise projects, if we use \u003ccode\u003emap\u003c/code\u003e and need concurrency, typically, people would write a custom \u003ccode\u003estruct\u003c/code\u003e, add a \u003ccode\u003emutex\u003c/code\u003e, and then write everything themselves. But \u003ccode\u003esync.Map\u003c/code\u003e is handy, as I showed earlier, with functions that follow certain standards. If you want to \u003ccode\u003eload\u003c/code\u003e, you have to call a specific function, and everything is structured that way, making it more reliable.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:24:50\u003c/strong\u003e People usually write a custom \u003ccode\u003estruct\u003c/code\u003e, then add a \u003ccode\u003emutex\u003c/code\u003e, and start writing all the necessary logic themselves. Meanwhile, \u003ccode\u003esync.Map\u003c/code\u003e is really handy. As I showed you earlier, it has several functions that adhere to a specific standard. If you want to \u003ccode\u003eload\u003c/code\u003e, you must call a specific function. This structure ensures consistency. However, you still need to be aware of the trade-offs when using \u003ccode\u003esync.Map\u003c/code\u003e, making sure to apply it correctly in the right context. Right, so you have to understand the proper workflow and \u003ccode\u003emap\u003c/code\u003e usage.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:25:26\u003c/strong\u003e Phát: Yes, about \u003ccode\u003eMap\u003c/code\u003e. Ok, thanks, Phát. Now, let’s quickly get through a few things. Thành, I need about 10 more minutes from the team. It’ll take a bit more time because I’ve received a total of 11 submissions for the test. Not many have attached images, so some of you can review them. Our deadline is set for the 20th, which is next week. I think earlier, I mentioned the 27th, or was it 26th or 27th? Anyway, that's the deadline. So, please review everything this week and get the submissions ready. This test is important because the market is shifting significantly, and there’s a big change in the demand for software roles.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:26:15\u003c/strong\u003e Of course, the demand is still there, but the volume has decreased. That's why I refer to it as a shift in the market demand, similar to what happened around 2014, where it’s like things are changing all over again. New technology is coming out, new opportunities, new markets, and emerging potentials. So, this test will be essential in helping us assess, especially when it comes to team culture. We’re taking this opportunity to evaluate the team, particularly to see how the research study team and the consulting team are becoming more distinct.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:27:36\u003c/strong\u003e There’s a clear distinction between the two teams now. Like I mentioned in the post on Notion about two weeks ago, this distinction is becoming more pronounced. In the future, there will be more specific policies related to different benefits between these two teams. But for now, as you can see, OGIF is gradually becoming a session where we report on all the studies that the team has been reviewing and reporting back on. Some of those reports might be added later, and you can see that some team members have been picking up new knowledge and sharing it.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:27:36\u003c/strong\u003e Gradually, it's becoming clearer that we want this differentiation to become more distinct over time. And there will be clear policies around this. So, those who enjoy diving deep into topics and taking them to the level of MVP, or applying them in actual projects, or going deeper into knowledge, they will get different benefits. Those who don't necessarily want to focus on study-related topics can continue working on projects as usual, but there will be other issues involved, which I've listed in the Notion link from two weeks ago. Everyone should review that link to understand the direction we're going in. This test is designed to assess how well you can keep up with new knowledge and how aligned you are with the culture during this time of significant changes.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:29:20\u003c/strong\u003e Because of these goals, I’ll be the only one grading this test. None of the other team members will be grading. Everyone has to do it, and I’ve set the standard for this. So, the important thing is that everyone does the test themselves. Even if the quality isn’t the best, it’s fine. I’ll just give it a lower score, but as long as it’s completed, you’ll pass. The immediate outcome I see from this is that I’ll group the results into two clusters.\u003c/p\u003e\n\u003cp\u003eThe Foundation team and the Lab team, they’re still the core teams we’ve had for the past eight or nine years. This is the main announcement. If you’ve finished your test and feel like you can improve based on what I’ve just said, the Foundation team and the Lab team will still be prioritized in various aspects. So, if you feel like you did the test carelessly, please take some time to do it thoroughly. Focus on two things: the culture aspect and the knowledge.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:29:56\u003c/strong\u003e The immediate result you’ll see is that I’ll group the results into two clusters. The Foundation team and the Lab team will remain the core of our team from now until the next eight or nine years. That’s the main announcement. Out of these 11 submissions, if anyone feels they can improve after hearing what I’ve said, please focus on making it better, especially since the Foundation and Lab teams will be prioritized more in different areas. So, if you feel like you’ve done it hastily, take the time to refine it. Check two things: the culture aspect and the latest, hottest topic cluster, which right now is LLM.\u003c/p\u003e\n\u003cp\u003eBut in reality, our team still covers many different areas. We still have people focusing on design, and others still working on Go, right? Blockchain might have moved a bit out of the spotlight, and the market is going sideways, but consulting still demands a lot of expertise in those areas.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:31:46\u003c/strong\u003e Regarding mini apps for Telegram, they quickly clone them, and now the business logic (BL) and tech (TCH) approaches have shifted a bit from the early days. But for consulting, we can still use them as usual, or we can view them from a different angle, where they become a new asset class. As developers, we should look at how these affect our workflow and how we manage assets.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:32:29\u003c/strong\u003e That’s the matter concerning the test. Pay attention to that. Second, as mentioned earlier, regarding team direction and numbers, I mentioned the Notion link I sent earlier. The Foundation team, which started over again, initially had just three people, and then gradually it grew to four, then five. We added Quan, Hiếu, and others. Initially, it was just three of us, but now the team is much stronger. With 40 people, all highly skilled, we’ll certainly move faster. That’s the general overview, so everyone should be aware of the current situation.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:33:12\u003c/strong\u003e Third, Huy Nguyễn, once you’re done, next week please take a look at the ICY numbers. Earlier, you mentioned the numbers were starting to grow, so we’ll need to review and balance those out. For this task, Huy and Thành, please take charge and ensure it’s handled properly. Thành also has an additional task, which is to review benefits for the Lab team members and propose something. It could be considered as a payon, but it won’t go through the normal channels, as there will be a different mechanism for this.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:33:52\u003c/strong\u003e But the Lab team members will have that, and everyone’s familiar with it. Lastly, regarding the LLM, in the current question list, there’s an important question about how to use LLM externally and how to adapt it. Emphasize that question, as it’s about knowledge discovery. The test question is not only about using it but about all the tools our team currently uses. When some people use them effectively and others less so, it creates a very clear spectrum—those who are weaker remain weaker, and those who are stronger stand out much more.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:34:38\u003c/strong\u003e We want to raise the standard. We want to shorten that spectrum, to make it as compact as possible. Right now, the gap is too wide. Beyond using tools for discovery, this question also asks us to look at how our field of work can apply these tools to elevate our competencies and make us more productive. That’s the whole issue, so everyone should confirm whether what they’ve done is correct or not. It has a deeper meaning than it seems.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:35:20\u003c/strong\u003e Lastly, to wrap up today’s session, Thành, for the next OGIF meetings, apart from diving deeper into use cases, there are things Tom has done related to building the structure of an LLM app. We could take that and analyze it. Let’s break it down and dive deeper into it.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:35:56\u003c/strong\u003e Hopefully, everyone passes the test so we can all have a good time. Next week, there will be another test. Next week, Minh L., can you do a demo? Continue with the finite state machine, FSM. As part of our focus on foundational technologies like blockchain and AI, the key point is that engineers will have a different path forward. The goal is to understand how large systems operate. In the future, if you’re not the one handling data manipulation—AI will do that for us, we won’t need to design things ourselves or do junior-level tasks anymore.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:37:35\u003c/strong\u003e The only way to become senior is to understand the issues and work on architecture. The finite state machine plays an important role, especially in scaling, something we’ve talked about a lot. Minh has read through it and understood the direction we’re aiming for. So, we need to do a comparison between the types of general servers it covers. State machine-based servers versus event-based servers. Then create a sample to show how it’s modeled, implemented using Erlang. Erlang already has the frameworks for it.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:39:01\u003c/strong\u003e This topic will proceed when Minh Lưu is ready. If it’s not next week, it could be in two weeks. I suggest that the backend team and the senior team gather together, and if there’s anything, confirm it beforehand. This topic is critical for software analysis and design. It’s a very important session. Up until now, we’ve only talked about modeling and doing C4 diagrams, but Erlang is the language that goes deepest into this area. Most people don’t know it entirely. We don’t necessarily need to learn Erlang, but we can look at how they design and build systems to handle this area properly, as they already have frameworks available. We just need to plug them in and use them.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:39:37\u003c/strong\u003e Speaking of which, October 20th is a Sunday, and Mỹ, Ngọc, and Giang have already posted about it. The ladies are going out on that day, and for those not in Saigon, the team representatives will wish everyone prosperity. It seems like wishing prosperity is the most appropriate thing to say in this situation. Any other wishes might not fit as well. Alright, so if anyone wants to join, register with Mỹ to book a table and plan accordingly.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e01:41:19\u003c/strong\u003e Thành, in the upcoming meetings, structure things into talks. Then set the goal for that. Our team now has a Builder Club as well. I’ll look into how the team members who used to work on Super Bit and console are stabilizing things, and I’ll restructure afterward. This time, it seems like we’ve had a good rest. Alright, does anyone have any questions about the test? If not, we’ll wrap up here. Alright, goodbye everyone, see you next week. Thanks, Thành, and thanks to everyone.\u003c/p\u003e\n\u003chr\u003e","frontmatter":{"tags":["office-hours","ogif","discord"],"title":"OGIF Office Hours #28 - Golang sync.Map, Generative AI UX design patterns, Yelp's AI use cases, Design patterns in LLM application, and Dify github analyzer","short_title":"#28 Go sync.Map, AI UX, Yelp AI, LLM Patterns, Git Analysis","date":"2024-10-21T00:00:00.000Z","description":"OGIF Office Hours #28 covered Go Weekly #16 by Phat on sync.Map concurrency, Nam's Product Commentary #4 on Generative AI UX design patterns, Dat Nguyen's presentation on Yelp's AI use cases including recommendation systems, Hoang's discussion on LLM application design patterns, and Cat's demonstration of a Dify-based Git repository analysis tool.","authors":["innno_"]},"slug":["updates","ogif","28-20241018"],"backlinks":[],"tocItems":[],"metadata":{"created":"Mon Oct 21 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","updated":null,"author":"innno_","coAuthors":[],"tags":["office-hours","ogif","discord"],"folder":"updates/ogif","wordCount":19058,"readingTime":"96m","characterCount":104707,"blocksCount":6},"isListPage":false},"__N_SSG":true},"page":"/[...slug]","query":{"slug":["updates","ogif","28-20241018"]},"buildId":"HnnQnlZeGCflQP9U2OWmW","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>