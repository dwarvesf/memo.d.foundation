<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>vector database on Dwarves Foundation</title><link>https://memo.d.foundation/tags/vector-database/</link><description>Recent content in vector database on Dwarves Foundation</description><generator>Hugo</generator><language>en-us</language><managingEditor>han@d.foundation (Han Ngo)</managingEditor><webMaster>han@d.foundation (Han Ngo)</webMaster><copyright>Â© 2024 Dwarves Foundation.</copyright><lastBuildDate>Fri, 28 Jun 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://memo.d.foundation/tags/vector-database/index.xml" rel="self" type="application/rss+xml"/><item><title>Multimodal in rag</title><link>https://memo.d.foundation/playground/ai/building-llm-system/multimodal-in-rag/</link><pubDate>Fri, 28 Jun 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/building-llm-system/multimodal-in-rag/</guid><description>In spite of having taken the world by storm, Large Language Models(LLM) still has some limitations such as limited context window and a knowledge cutoff date.</description></item><item><title>Quick Learning Vector Database</title><link>https://memo.d.foundation/playground/01_literature/engineering/data/quick-learning-vector-database/</link><pubDate>Fri, 15 Mar 2024 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/01_literature/engineering/data/quick-learning-vector-database/</guid><description>Motivation of Vector Database The motivation of this thoughts that trying to discover the LLMs and Generative AI In order to create or build, train any models there are multiple factors will need to be considered: lakes of data, metadata, data management, infrastructure, etc.</description></item><item><title>Chunking strategies to overcome context limitation in LLM</title><link>https://memo.d.foundation/playground/ai/chunking-strategies-to-overcome-context-limitation-in-llm/</link><pubDate>Sat, 08 Jul 2023 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/chunking-strategies-to-overcome-context-limitation-in-llm/</guid><description>When it comes to Large Language Models (LLMs) like GPT, managing context size - the number of tokens per prompt - is a unique challenge.</description></item><item><title>Query Caching for Large Language Models</title><link>https://memo.d.foundation/playground/ai/llm-query-caching/</link><pubDate>Fri, 09 Jun 2023 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/llm-query-caching/</guid><description>It&amp;rsquo;s quite fascinating to see the increasingly pivotal role that Large Language Models (LLMs) are playing in various applications, covering the spectrum from natural language processing tasks to predictive typing, and more.</description></item><item><title>Select Vector Database for LLM</title><link>https://memo.d.foundation/playground/ai/select-vector-database-for-llm/</link><pubDate>Thu, 18 May 2023 00:00:00 +0000</pubDate><author>han@d.foundation (Han Ngo)</author><guid>https://memo.d.foundation/playground/ai/select-vector-database-for-llm/</guid><description>During our research on applying LLM to real-world applications, we have observed the widespread usage and increasing popularity of Vector databases in various fields.</description></item></channel></rss>