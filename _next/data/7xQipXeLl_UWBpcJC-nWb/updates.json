{"pageProps":{"directoryTree":{"/pinned":{"label":"Pinned Notes","children":{"/playbook/operations/ogif":{"label":"OGIF - Oh God It's Friday","children":{}}}},"/":{"label":"Home","children":{"/careers":{"label":"Careers","children":{"/careers/additional-info":{"label":"Additional Info","children":{"/careers/additional-info/benefits-and-perks":{"label":"Benefits And Perks","children":{}},"/careers/additional-info/culture-handbook":{"label":"Culture Handbook","children":{}},"/careers/additional-info/how-we-hire":{"label":"How we hire","children":{}},"/careers/additional-info/how-we-work":{"label":"How we work","children":{}},"/careers/additional-info/life-at-dwarves":{"label":"Life at Dwarves","children":{}},"/careers/additional-info/making-a-career":{"label":"Making a career","children":{}},"/careers/additional-info/the-manifesto":{"label":"The Manifesto","children":{}},"/careers/additional-info/what-we-stand-for":{"label":"What we stand for","children":{}},"/careers/additional-info/what-we-value":{"label":"What we value","children":{}},"/careers/additional-info/where-we-work":{"label":"Where we work","children":{}}}},"/careers/apprentice":{"label":"Apprentice","children":{"/careers/apprentice/2022-meet-ngoc-thanh-pham":{"label":"Dwarves Apprenticeship 2022: Meet The Mentors Ngoc Thanh Pham","children":{}},"/careers/apprentice/2022-meet-tuan-dao":{"label":"Dwarves Apprenticeship 2022: Meet The Mentors Tuan Dao","children":{}},"/careers/apprentice/apprentice":{"label":"Apprentice Program","children":{}},"/careers/apprentice/batch-of-2022":{"label":"Dwarves Foundation Apprenticeship: Batch Of 2022","children":{}}}},"/careers/archived":{"label":"Archived","children":{"/careers/archived/android-developer":{"label":"Mobile Engineer, Android","children":{}},"/careers/archived/android":{"label":"Android","children":{}},"/careers/archived/backend-engineer-go-elixir-rust":{"label":"Backend Engineer, Go/Elixir/Rust","children":{}},"/careers/archived/community-executive":{"label":"Community Executive","children":{}},"/careers/archived/data-engineering":{"label":"Energy - Data Engineering","children":{}},"/careers/archived/devops":{"label":"DevOps Engineer - FinTech","children":{}},"/careers/archived/executive-assistant":{"label":"Executive Assistant","children":{}},"/careers/archived/frontend-developer-junior":{"label":"Junior Frontend Developer","children":{}},"/careers/archived/frontend":{"label":"Frontend","children":{}},"/careers/archived/full-stack-engineer":{"label":"Full-Stack Engineer","children":{}},"/careers/archived/golang":{"label":"Golang","children":{}},"/careers/archived/intern":{"label":"Intern","children":{}},"/careers/archived/ios-developer":{"label":"iOS Developer - EnergyTech","children":{}},"/careers/archived/ios":{"label":"iOS Developer","children":{}},"/careers/archived/macos-developer":{"label":"Software Engineer, macOS","children":{}},"/careers/archived/product-designer-new-grad":{"label":"Product Designer, New Grad","children":{}},"/careers/archived/product-designer":{"label":"Product Designer","children":{}},"/careers/archived/qa":{"label":"QA Engineer","children":{}},"/careers/archived/qc-automation":{"label":"QC Engineer, Automation - Logistics","children":{}},"/careers/archived/qc-manual":{"label":"Fintech - QC Engineer, Manual","children":{}},"/careers/archived/react-native-developer":{"label":"React Native Developer","children":{}},"/careers/archived/reactjs-web-engineer":{"label":"Web Engineer, React.js","children":{}},"/careers/archived/technical-recruiter":{"label":"Technical Recruiter","children":{}},"/careers/archived/visual-designer":{"label":"Visual Designer","children":{}}}},"/careers/life":{"label":"Life","children":{"/careers/life/an-tran":{"label":"Meet An Tran: Senior engineer's growth journey","children":{}},"/careers/life/anh-tran":{"label":"Meet Anh Tran: Crafting Dwarves' visual identity as Head of UI","children":{}},"/careers/life/dat-nguyen":{"label":"Meet Dat Nguyen: AI Dev Intern on hybrid working at Dwarves","children":{}},"/careers/life/hieu-vu":{"label":"Meet Hieu Vu: Golang passion and Dwarves community","children":{}},"/careers/life/nam-nguyen":{"label":"Meet Nam Nguyen: From Frontend to DevOps - A journey of continuous growth","children":{}},"/careers/life/software-design-group":{"label":"Software design group: Nurturing architects at Dwarves","children":{}},"/careers/life/thanh-pham":{"label":"Meet Thanh Pham: Ensuring a healthy environment for everyone to thrive","children":{}},"/careers/life/tom-nguyen":{"label":"Meet Tom Nguyen: Remote working fits him perfectly","children":{}}}},"/careers/open-positions":{"label":"Open Positions","children":{"/careers/open-positions/business-development-manager":{"label":"Business Development","children":{}},"/careers/open-positions/growth":{"label":"Growth","children":{}}}}}},"/consulting":{"label":"Consulting","children":{"/consulting/case-study":{"label":"Case Study","children":{"/consulting/case-study/aharooms":{"label":"Building a complete tech system for small Vietnamese hotels","children":{}},"/consulting/case-study/airwatt":{"label":"Creating a smart system to monitor electricity Use","children":{}},"/consulting/case-study/attrace":{"label":"Building blockchain solutions for affiliate marketing","children":{}},"/consulting/case-study/basehq":{"label":"Creating the first platform for Executive assistants","children":{}},"/consulting/case-study/begroup":{"label":"Helping launch beCorporate enterprise ride-hailing service","children":{}},"/consulting/case-study/bhd":{"label":"Redesigning BHD Cinema's ticket booking app for a better experience","children":{}},"/consulting/case-study/cimb":{"label":"Building CIMB's digital wealth platform for better customer experience","children":{}},"/consulting/case-study/dental-marketplace":{"label":"Making dental work easier in Singapore","children":{}},"/consulting/case-study/droppii":{"label":"Helping Droppii build a better dropshipping platform that users love","children":{}},"/consulting/case-study/hedge-foundation":{"label":"Building a powerful crypto trading dashboard for professionals","children":{}},"/consulting/case-study/icrosschain":{"label":"Making crypto transfers faster and easier","children":{}},"/consulting/case-study/joinpara":{"label":"Connecting healthcare workers with hospitals during COVID-19","children":{}},"/consulting/case-study/kafi":{"label":"Kafi: Making stock trading easier for everyone","children":{}},"/consulting/case-study/konvoy":{"label":"Making keg management smarter for breweries","children":{}},"/consulting/case-study/momos":{"label":"Building a central hub for food and beverage businesses in Singapore","children":{}},"/consulting/case-study/mudah":{"label":"Upgrading Malaysia's largest online marketplace","children":{}},"/consulting/case-study/naru":{"label":"Naru: A task manager that works right in your browser","children":{}},"/consulting/case-study/open-fabric":{"label":"Building a payment platform from scratch","children":{}},"/consulting/case-study/reapit":{"label":"Building cloud solutions for UK real estate","children":{}},"/consulting/case-study/relay":{"label":"Helping Relay launch their workflow automation MVP for the US market","children":{}},"/consulting/case-study/searchio":{"label":"Building AI-powered search for online stores","children":{}},"/consulting/case-study/setel":{"label":"Building Setel's fuel payment super-app for Malaysian drivers","children":{}},"/consulting/case-study/sol":{"label":"Sol: Making group travel easier and more fun","children":{}},"/consulting/case-study/startupvn":{"label":"Building a community platform for Vietnamese Entrepreneurs","children":{}},"/consulting/case-study/swift":{"label":"Swift: Building a micro frontend design system for e-commerce","children":{}},"/consulting/case-study/tokenomy":{"label":"Building a modern crypto investment platform for Tokenomy","children":{}},"/consulting/case-study/voconic":{"label":"Building Voconic's cloud platform with Google for financial services","children":{}}}},"/consulting/market-report":{"label":"Market Report","children":{"/consulting/market-report/2024-13th-dec":{"label":"Weekly Consulting Snapshot #1: Gemini 2.0, OpenAI’s Sora, a16z’s Predictions","children":{}},"/consulting/market-report/2024-27th-dec":{"label":"Weekly Consulting Snapshot #2: AI Talent Wars, OpenAI’s New Models, Hyperliquid’s Rise","children":{}},"/consulting/market-report/2025-10th-jan":{"label":"Weekly Consulting Snapshot #4: AI Supercomputers, Mini AI PCs, Worldcoin Expansion, and SEA VC","children":{}},"/consulting/market-report/2025-14th-feb":{"label":"Weekly Consulting Snapshot #7: 10x AI Cost Reduction, Lyft’s 2026 Robotaxi Milestone, and Solana ETF Buzz","children":{}},"/consulting/market-report/2025-17th-jan":{"label":"Weekly Consulting Snapshot #5: VC Trends, Blockchain Breakthroughs, and AI Innovations","children":{}},"/consulting/market-report/2025-21th-feb":{"label":"Weekly Consulting Snapshot #8: R1 1776 Goes Open-Source, Cardex Gets Hacked, and Grok-3 Debuts","children":{}},"/consulting/market-report/2025-28th-feb":{"label":"Weekly Consulting Snapshot #9: Bybit Loses $1.5B in Hack, Claude 3.7 Sonnet Drops, and OpenArt Designs Characters","children":{}},"/consulting/market-report/2025-3rd-jan":{"label":"Weekly Consulting Snapshot #3: AI’s Ubiquity at CES, Wall Street’s AI Boom, and Blockchain Innovations","children":{}},"/consulting/market-report/2025-7th-feb":{"label":"Weekly Consulting Snapshot #6: Trending Products, DeepSeek Wave, and Ethereum Predictions","children":{}},"/consulting/market-report/event-takeaways-1st":{"label":"Talks and Takeaways from the Scene: Part 1","children":{}},"/consulting/market-report/event-takeaways-2nd":{"label":"Talks and Takeaways from the Scene: Part 2","children":{}}}},"/consulting/partners-network":{"label":"Partners Network","children":{}},"/consulting/wala":{"label":"Wala","children":{"/consulting/wala/43-factory":{"label":"43 Factory WALA: Lessons from coffee craftsmanship for software engineering","children":{}},"/consulting/wala/dzs-media":{"label":"DZS Media WALA: Lessons from film production for software engineering","children":{}},"/consulting/wala/sp-group":{"label":"SP Group WALA: Insights on digital transformation and partnership in energy sector","children":{}}}}}},"/contributing":{"label":"Home","children":{}},"/contributor":{"label":"Contributor","children":{"/contributor/0xlight":{"label":"0xlight","children":{}},"/contributor/0xm":{"label":"0xm","children":{}},"/contributor/anhnh":{"label":"anhnh","children":{}},"/contributor/anna":{"label":"anna","children":{}},"/contributor/annaconsole":{"label":"anna.console","children":{}},"/contributor/antran":{"label":"antran","children":{}},"/contributor/bienvh":{"label":"bienvh","children":{}},"/contributor/bievh":{"label":"bievh","children":{}},"/contributor/changtrailucluong":{"label":"changtrailucluong","children":{}},"/contributor/chinhld12":{"label":"chinhld12","children":{}},"/contributor/cor3co":{"label":"cor3.co","children":{}},"/contributor/datnguyennnx":{"label":"datnguyennnx","children":{}},"/contributor/datpv":{"label":"datpv","children":{}},"/contributor/dudaka":{"label":"dudaka","children":{}},"/contributor/duy":{"label":"duy","children":{}},"/contributor/fuatto":{"label":"fuatto","children":{}},"/contributor/giangthan":{"label":"giangthan","children":{}},"/contributor/han":{"label":"han","children":{}},"/contributor/haongo1":{"label":"haongo1","children":{}},"/contributor/hienld":{"label":"hienld","children":{}},"/contributor/hieuphq":{"label":"hieuphq","children":{}},"/contributor/hieuthu1":{"label":"hieuthu1","children":{}},"/contributor/hieuvd":{"label":"hieuvd","children":{}},"/contributor/hmhoang13":{"label":"hmhoang13","children":{}},"/contributor/hnh":{"label":"hnh","children":{}},"/contributor/hoangnnh":{"label":"hoangnnh","children":{}},"/contributor/hollow3333":{"label":"hollow#3333","children":{}},"/contributor/hthai2201":{"label":"hthai2201","children":{}},"/contributor/huygn":{"label":"huygn","children":{}},"/contributor/huymaius":{"label":"huymaius","children":{}},"/contributor/huytd":{"label":"huytd","children":{}},"/contributor/huytq":{"label":"huytq","children":{}},"/contributor/ics3rd":{"label":"ics3rd","children":{}},"/contributor/innno_":{"label":"innno_","children":{}},"/contributor/jack":{"label":"jack","children":{}},"/contributor/jim":{"label":"jim","children":{}},"/contributor/khacvy":{"label":"khacvy","children":{}},"/contributor/longddl":{"label":"longddl","children":{}},"/contributor/mashiro5951":{"label":"mashiro5951","children":{}},"/contributor/mickwan1234":{"label":"mickwan1234","children":{}},"/contributor/minh":{"label":"minh","children":{}},"/contributor/minh_cloud":{"label":"minh_cloud","children":{}},"/contributor/minhcloud":{"label":"minhcloud","children":{}},"/contributor/minhkek":{"label":"minhkek","children":{}},"/contributor/minhlq":{"label":"minhlq","children":{}},"/contributor/minhth":{"label":"minhth","children":{}},"/contributor/monotykamary":{"label":"monotykamary","children":{}},"/contributor/namanh":{"label":"namanh","children":{}},"/contributor/namanh14mn":{"label":"namanh14mn","children":{}},"/contributor/nambui":{"label":"nambui","children":{}},"/contributor/namnanh14mn":{"label":"namnanh14mn","children":{}},"/contributor/namnd":{"label":"namnd","children":{}},"/contributor/namth":{"label":"namth","children":{}},"/contributor/namtran":{"label":"namtran","children":{}},"/contributor/namtrhg":{"label":"namtrhg","children":{}},"/contributor/nghiaphm":{"label":"nghiaphm","children":{}},"/contributor/ngolapnguyen":{"label":"ngolapnguyen","children":{}},"/contributor/nguyend-nam":{"label":"nguyend-nam","children":{}},"/contributor/nikki":{"label":"nikki","children":{}},"/contributor/nikkingtr":{"label":"nikkingtr","children":{}},"/contributor/pham-ngoc-thanh":{"label":"Pham Ngoc Thanh","children":{}},"/contributor/phatgha":{"label":"phatgha","children":{}},"/contributor/quang":{"label":"quang","children":{}},"/contributor/rjim":{"label":".rjim","children":{}},"/contributor/taipn":{"label":"taipn","children":{}},"/contributor/taynguyen":{"label":"taynguyen","children":{}},"/contributor/taynguyen294":{"label":"taynguyen294","children":{}},"/contributor/thangnt294":{"label":"thangnt294","children":{}},"/contributor/thanh":{"label":"thanh","children":{}},"/contributor/thanhlmm":{"label":"thanhlmm","children":{}},"/contributor/thanhpham":{"label":"thanh.pham","children":{}},"/contributor/thanhpn":{"label":"thanhpn","children":{}},"/contributor/thecodister":{"label":"TheCodister","children":{}},"/contributor/tieubao":{"label":"tieubao","children":{}},"/contributor/toanbku":{"label":"toanbku","children":{}},"/contributor/toanhq":{"label":"toanhq","children":{}},"/contributor/tom":{"label":"tom","children":{}},"/contributor/tran-hoang-nam":{"label":"Tran Hoang Nam","children":{}},"/contributor/trankhacvy":{"label":"trankhacvy","children":{}},"/contributor/vhbien":{"label":"vhbien","children":{}},"/contributor/vincent":{"label":"vincent","children":{}},"/contributor/vitran":{"label":"vitran","children":{}}}},"/handbook":{"label":"Handbook","children":{"/handbook/as-a-community":{"label":"Dwarves as a community","children":{}},"/handbook/benefits-and-perks":{"label":"Benefits & perks","children":{}},"/handbook/community":{"label":"Community","children":{"/handbook/community/discord":{"label":"Dwarves Network Discord","children":{}},"/handbook/community/earn":{"label":"Earning with sidegig","children":{}},"/handbook/community/icy-swap":{"label":"How to swap ICY to BTC","children":{}},"/handbook/community/icy-worth":{"label":"How much is your ICY worth","children":{}},"/handbook/community/icy":{"label":"ICY Token","children":{}},"/handbook/community/radar":{"label":"Tech Radar","children":{}},"/handbook/community/sharing":{"label":"Sharing knowledge","children":{}},"/handbook/community/showcase":{"label":"Showcase","children":{}}}},"/handbook/compliance":{"label":"Compliance","children":{}},"/handbook/dwarves-foundation-is-you":{"label":"You are Dwarves Foundation","children":{}},"/handbook/faq":{"label":"FAQ","children":{}},"/handbook/getting-started":{"label":"Getting started","children":{}},"/handbook/guides":{"label":"Guides","children":{"/handbook/guides/asset-request":{"label":"Assets","children":{}},"/handbook/guides/check-in-at-office":{"label":"Office check-in process for earning ICY","children":{}},"/handbook/guides/conduct-a-meeting":{"label":"How to conduct a meeting","children":{}},"/handbook/guides/configure-the-company-email":{"label":"Configure your company email","children":{}},"/handbook/guides/continuing-education-allowance":{"label":"Continuing education allowance","children":{}},"/handbook/guides/effective-meeting":{"label":"Effective meetings","children":{}},"/handbook/guides/email-communication-and-use":{"label":"Email Communication and Use","children":{}},"/handbook/guides/leave-request":{"label":"Leave request","children":{}},"/handbook/guides/one-on-one-meeting":{"label":"1-on-1 meetings","children":{}},"/handbook/guides/password-sharing":{"label":"Password Sharing","children":{}},"/handbook/guides/reimbursement":{"label":"Reimbursement","children":{}}}},"/handbook/how-we-hire":{"label":"How we hire","children":{}},"/handbook/how-we-spend-money":{"label":"How we spend money","children":{}},"/handbook/how-we-work":{"label":"How we work","children":{}},"/handbook/hybrid-working":{"label":"Hybrid Working","children":{}},"/handbook/making-a-career":{"label":"Making a career","children":{}},"/handbook/misc":{"label":"Misc","children":{"/handbook/misc/marketing-assets":{"label":"Marketing assets","children":{}}}},"/handbook/mma":{"label":"MMA","children":{}},"/handbook/moonlighting":{"label":"Moonlighting","children":{}},"/handbook/navigate-changes":{"label":"Navigate changes","children":{}},"/handbook/places-to-work":{"label":"Places to work","children":{}},"/handbook/purpose":{"label":"Our purpose","children":{}},"/handbook/routine":{"label":"Work routine","children":{}},"/handbook/security-rules":{"label":"Security rules","children":{}},"/handbook/stock-option-plan":{"label":"Stock option plan","children":{}},"/handbook/tools-and-systems":{"label":"Tools and systems","children":{}},"/handbook/ventures":{"label":"Ventures arm","children":{}},"/handbook/what-we-stand-for":{"label":"What we stand for","children":{}},"/handbook/what-we-value":{"label":"What we value","children":{}},"/handbook/where-we-work":{"label":"Where we work","children":{}},"/handbook/who-does-what":{"label":"Who does what","children":{}}}},"/playbook":{"label":"Playbook","children":{"/playbook/business":{"label":"Business","children":{"/playbook/business/collaboration-guideline":{"label":"Collaboration Guideline","children":{}},"/playbook/business/df-workflow":{"label":"Dwarves Workflow","children":{}},"/playbook/business/fbsc":{"label":"FBSC","children":{}},"/playbook/business/fixed-budget-scope-controlled":{"label":"Fixed Budget Scope Controlled","children":{}},"/playbook/business/how-to-work-with-clients":{"label":"How to work with clients","children":{}},"/playbook/business/invoice":{"label":"Invoice","children":{}},"/playbook/business/nda":{"label":"NDA","children":{}},"/playbook/business/pricing-model-bill-by-hours":{"label":"Pricing model: Bill by hours","children":{}},"/playbook/business/service-feedbacks":{"label":"Service Feedbacks","children":{}},"/playbook/business/setting-the-budget":{"label":"Setting The Budget","children":{}},"/playbook/business/the-adjacent-possible":{"label":"The Adjacent Possible","children":{}}}},"/playbook/design":{"label":"Design","children":{"/playbook/design/aarrr":{"label":"aarrr","children":{}},"/playbook/design/design-sprint":{"label":"Design Sprint","children":{}},"/playbook/design/design-system":{"label":"lean-canvas","children":{}},"/playbook/design/ia":{"label":"nda","children":{}},"/playbook/design/ix":{"label":"IA","children":{}},"/playbook/design/lean-canvas":{"label":"Lean Canvas","children":{}},"/playbook/design/prototype":{"label":"Low-fidelity prototype: UI Design","children":{}},"/playbook/design/ui":{"label":"UI","children":{}},"/playbook/design/ux":{"label":"UX","children":{}},"/playbook/design/wireframe":{"label":"wireframe","children":{}}}},"/playbook/engineering":{"label":"Engineering","children":{"/playbook/engineering/estimation-guidelines":{"label":"Estimation Guidelines","children":{}},"/playbook/engineering/presentation":{"label":"monitoring","children":{}},"/playbook/engineering/repo-icon":{"label":"release","children":{}}}},"/playbook/operations":{"label":"Operations","children":{"/playbook/operations/a-tips-of-hiring-dont":{"label":"A Tips Of Hiring - Do & Don't","children":{}},"/playbook/operations/account":{"label":"Account","children":{}},"/playbook/operations/adjust-the-way-we-work-in-basecamp-style":{"label":"Adjust The Way We Work In Basecamp Style","children":{}},"/playbook/operations/annual-bonus-for-sales":{"label":"Annual bonus for sales","children":{}},"/playbook/operations/applying-myersbriggs-type-indicator-in-hr":{"label":"Applying Myersbriggs Type Indicator In Hiring","children":{}},"/playbook/operations/are-you-helping":{"label":"Are You Helping","children":{}},"/playbook/operations/avoid-burn-out":{"label":"Avoid Burn Out","children":{}},"/playbook/operations/beyond-the-title":{"label":"Beyond The Title","children":{}},"/playbook/operations/blocking-distraction":{"label":"Blocking Distraction","children":{}},"/playbook/operations/bric-a-brac":{"label":"Bric A Brac","children":{}},"/playbook/operations/building-a-solid-high-performing-team":{"label":"Building A Solid High Performing Team","children":{}},"/playbook/operations/bunk-license-check":{"label":"Bunk license check","children":{}},"/playbook/operations/checklists":{"label":"Checklists","children":{"/playbook/operations/checklists/artifact-checklist":{"label":"Back up Artifact","children":{}},"/playbook/operations/checklists/assets-checklist":{"label":"Assets","children":{}},"/playbook/operations/checklists/billing-checklist":{"label":"Billing","children":{}},"/playbook/operations/checklists/candidate-checklist":{"label":"Candidate","children":{}},"/playbook/operations/checklists/consulting-contract-checklist":{"label":"Consulting Contract","children":{}},"/playbook/operations/checklists/hiring-checklist":{"label":"Hiring","children":{}},"/playbook/operations/checklists/leave-and-request-checklist":{"label":"Leave Request","children":{}},"/playbook/operations/checklists/offboarding-checklist":{"label":"Offboarding","children":{}},"/playbook/operations/checklists/onboarding-checklist":{"label":"Onboarding","children":{}},"/playbook/operations/checklists/project-archive":{"label":"Project Archive","children":{}},"/playbook/operations/checklists/project-case-study":{"label":"Project Case Study","children":{}},"/playbook/operations/checklists/project-communication":{"label":"Project Communication","children":{}},"/playbook/operations/checklists/project-handover":{"label":"Project Handover","children":{}},"/playbook/operations/checklists/project-initialization":{"label":"Project Initialization","children":{}},"/playbook/operations/checklists/unemployment-social-health-insurance":{"label":"Unemployment, Social, Health Insurance","children":{}},"/playbook/operations/checklists/vietnam-invoice-checklist":{"label":"Vietnam Invoice","children":{}}}},"/playbook/operations/collaboration-guidelines":{"label":"Collaboration Guidelines","children":{}},"/playbook/operations/compliance-check-process":{"label":"Compliance Check Process","children":{}},"/playbook/operations/constructive-feedback":{"label":"Constructive Feedback","children":{}},"/playbook/operations/delegate-work-not-responsibility":{"label":"Delegate Work Not Responsibility","children":{}},"/playbook/operations/delegation-and-believe-it-will-work":{"label":"Delegation And Believe It Will Work","children":{}},"/playbook/operations/effective-meeting":{"label":"Effective Meeting","children":{}},"/playbook/operations/email-template":{"label":"Email Template","children":{"/playbook/operations/email-template/assignment-invitation-2":{"label":"Assignment Inviation (Skip pre-assessment)","children":{}},"/playbook/operations/email-template/assignment-invitation":{"label":"Assignment Inviation","children":{}},"/playbook/operations/email-template/confirm-resume-date":{"label":"Confirm Employee's Resume Date Day","children":{}},"/playbook/operations/email-template/farewell":{"label":"Farewell Letter","children":{}},"/playbook/operations/email-template/follow-up-onboarding-items":{"label":"Follow-up Onboarding Items","children":{}},"/playbook/operations/email-template/hung-king-commemoration-day":{"label":"Hung King Commemoration Day","children":{}},"/playbook/operations/email-template/information-about-resource-change":{"label":"Inform about resource change","children":{}},"/playbook/operations/email-template/international-labour-day":{"label":"International Labour Day","children":{}},"/playbook/operations/email-template/interview-invitation":{"label":"Interview Invitation","children":{}},"/playbook/operations/email-template/milestone-sign-off":{"label":"Milestone sign-off","children":{}},"/playbook/operations/email-template/national-day":{"label":"National Day","children":{}},"/playbook/operations/email-template/new-year-day":{"label":"New Year Day","children":{}},"/playbook/operations/email-template/offer-letter":{"label":"Offer Letter","children":{}},"/playbook/operations/email-template/referral-bonus-confirmation-note":{"label":"Referral Bonus Confirmation Note","children":{}},"/playbook/operations/email-template/rejection-email":{"label":"Rejection","children":{}},"/playbook/operations/email-template/salary-increment":{"label":"Salary Increment Announcement","children":{}},"/playbook/operations/email-template/tet-holiday":{"label":"Tet Holiday","children":{}},"/playbook/operations/email-template/thank-you-letter":{"label":"Thank you letter","children":{}},"/playbook/operations/email-template/welcome-onboard":{"label":"Welcome Onboard","children":{}},"/playbook/operations/email-template/welcome-to-dwarves-update":{"label":"Welcome to Dwarves Updates","children":{}}}},"/playbook/operations/focus-on-software-delivery":{"label":"Focus On Software Delivery","children":{}},"/playbook/operations/go-the-extra-mile":{"label":"Go The Extra Mile","children":{}},"/playbook/operations/hiring-approach":{"label":"Hiring Approach","children":{}},"/playbook/operations/hiring-for-operations-team":{"label":"Hiring For Operations Team","children":{}},"/playbook/operations/make-remote-working-works":{"label":"Make Remote Working Works","children":{}},"/playbook/operations/making-decision-as-a-team-member":{"label":"Making Decision As A Team Member","children":{}},"/playbook/operations/mbti-type-estj":{"label":"MBTI Type ESTJ","children":{}},"/playbook/operations/mbti-type-intj":{"label":"MBTI Type INTJ","children":{}},"/playbook/operations/mbti-type-istj":{"label":"MBTI Type ISTJ","children":{}},"/playbook/operations/mbti-type-istp":{"label":"MBTI Type ISTP","children":{}},"/playbook/operations/naming-convention":{"label":"Naming convention","children":{}},"/playbook/operations/ogif":{"label":"OGIF - Oh God It's Friday","children":{}},"/playbook/operations/our-metrics-for-performance-review":{"label":"Our Metrics For Performance Review","children":{}},"/playbook/operations/our-policy-for-remote-working":{"label":"Our Policy For Remote Working","children":{}},"/playbook/operations/project-schedule-delivery-guidelines":{"label":"Project Delivery Schedule and Guidelines","children":{}},"/playbook/operations/red-flags":{"label":"Red Flags","children":{}},"/playbook/operations/the-dwarves-culture-handbook":{"label":"The Dwarves Culture Handbook","children":{}},"/playbook/operations/the-dwarves-runs-by-ideas":{"label":"The Dwarves Runs By Ideas","children":{}},"/playbook/operations/the-four-preferences":{"label":"The Four Preferences","children":{}},"/playbook/operations/the-inner-circle":{"label":"The Inner Circle","children":{}},"/playbook/operations/the-okr":{"label":"The OKR","children":{}},"/playbook/operations/transparency":{"label":"Transparency","children":{}},"/playbook/operations/types-of-employees":{"label":"Types Of Employees","children":{}},"/playbook/operations/writing-management-objectives-in-smart":{"label":"Writing Management Objectives In Smart","children":{}}}}}},"/playground":{"label":"Playground","children":{"/playground/00_fleeting":{"label":"00_fleeting","children":{"/playground/00_fleeting/202210122014-forward-proxy":{"label":"Forward Proxy","children":{}},"/playground/00_fleeting/202210131000-behavior-driven-development":{"label":"Behavior Driven Development","children":{}},"/playground/00_fleeting/202210131516-react-fiber":{"label":"React Fiber","children":{}},"/playground/00_fleeting/202210150019-migration-planning":{"label":"Migration Planning","children":{}},"/playground/00_fleeting/202210162154-the-best-of-css-tldr":{"label":"The Best of CSS TLDR","children":{}},"/playground/00_fleeting/202210172128-sign-in-form-best-practices":{"label":"Sign-in Form Best Practices","children":{}},"/playground/00_fleeting/202211081111-error-messaging":{"label":"Error Messaging","children":{}},"/playground/00_fleeting/202211141287-go-json-parsing":{"label":"Go JSON parser: number <-> interface","children":{}},"/playground/00_fleeting/202211141513-materialized-view-pattern":{"label":"Materialized View Pattern","children":{}},"/playground/00_fleeting/202212131609-how-to-deal-with-technical-debt-in-scrum":{"label":"How to deal with technical debt in Scrum","children":{}},"/playground/00_fleeting/202301091379-invoking-component-functions-in-react":{"label":"Invoking component functions in React","children":{}},"/playground/00_fleeting/202301191192-multi-column-index-in-db":{"label":"Multi-column index in DB","children":{}},"/playground/00_fleeting/202302281019-case-study-write-heavy-scalable-and-reliable-inventory-platform":{"label":"Case study: Write-heavy scalable and reliable inventory platform","children":{}},"/playground/00_fleeting/automata":{"label":"Automata","children":{}},"/playground/00_fleeting/erlang-fsm":{"label":"Erlang Finite State Machine","children":{}},"/playground/00_fleeting/error-handling-patterns":{"label":"Error Handling Patterns","children":{}},"/playground/00_fleeting/explaining-gradient-descent-in-machine-learning-with-a-simple-analogy":{"label":"Explaining Gradient Descent in Machine Learning with a simple analogy","children":{}},"/playground/00_fleeting/founder-liquidity":{"label":"Founder Liquidity","children":{}},"/playground/00_fleeting/how-to-talk-to-chatgpt-effectively":{"label":"How to talk to ChatGPT effectively","children":{}},"/playground/00_fleeting/organize-team-know-how-with-zettelkasten-method":{"label":"Organize team know-how with Zettelkasten Method","children":{}},"/playground/00_fleeting/rust-trait":{"label":"Rust Trait","children":{}},"/playground/00_fleeting/subscription-pricing-models":{"label":"Subscription Pricing Models","children":{}},"/playground/00_fleeting/why-hollywood-and-gaming-struggle-with-ai":{"label":"Why Hollywood and gaming struggle with AI","children":{}}}},"/playground/01_literature":{"label":"01_literature","children":{"/playground/01_literature/a-lens-to-modern-data-engineering":{"label":"Building a Data-Driven Project Reporting System: A Lens into Modern Data Engineering","children":{}},"/playground/01_literature/a-quick-intro-to-webassembly":{"label":"A Quick Intro To Webassembly","children":{}},"/playground/01_literature/aarrr-framework-in-a-nutshell":{"label":"Aarrr Framework In A Nutshell","children":{}},"/playground/01_literature/about-devops":{"label":"About Devops","children":{}},"/playground/01_literature/accelerate-project-initiation-with-advanced-nextjs-boilerplate-react-toolkit":{"label":"Accelerate Project Initiation With Advanced Nextjs Boilerplate React Toolkit","children":{}},"/playground/01_literature/adoption-of-pnpm":{"label":"Adoption Of Pnpm","children":{}},"/playground/01_literature/agile-how-to-create-clickup-tickets":{"label":"Agile How To Create Clickup Tickets","children":{}},"/playground/01_literature/agile-using-clickup-as-agile-management-tool":{"label":"Agile Using Clickup As Agile Management Tool","children":{}},"/playground/01_literature/an-alternative-to-tm":{"label":"An Alternative To Tm","children":{}},"/playground/01_literature/applied-security-basis":{"label":"Applied Security Basis","children":{}},"/playground/01_literature/architecture-decision-record":{"label":"Architecture Decision Record","children":{}},"/playground/01_literature/are-we-really-engineers":{"label":"Are We Really Engineers","children":{}},"/playground/01_literature/asking-as-a-junior":{"label":"Asking As A Junior","children":{}},"/playground/01_literature/be-careful-with-your-code-splitting-setup":{"label":"Be Careful With Your Code Splitting Setup","children":{}},"/playground/01_literature/blockchain-for-designers":{"label":"Blockchain For Designers","children":{}},"/playground/01_literature/build-a-passcode-view-with-swift":{"label":"Build A Passcode View With Swift","children":{}},"/playground/01_literature/build-an-assistant-on-the-terminal":{"label":"Build An Assistant On The Terminal","children":{}},"/playground/01_literature/builder-design-pattern":{"label":"Introduce the Builder pattern and its use cases","children":{}},"/playground/01_literature/bunk-license-check":{"label":"Bunk License Check","children":{}},"/playground/01_literature/c4-modelling":{"label":"Breaking Down Complexity: The Role of Abstractions and UML in C4 Modelling","children":{}},"/playground/01_literature/card-sorting-and-a-glimpse-at-experimental-sorting-session":{"label":"Card Sorting And A Glimpse At Experimental Sorting Session","children":{}},"/playground/01_literature/choosing-the-right-javascript-framework-a-deep-dive-into-react-vs-angular-vs-vue":{"label":"Choosing The Right Javascript Framework A Deep Dive Into React Vs Angular Vs Vue","children":{}},"/playground/01_literature/command-pattern":{"label":"Command Pattern","children":{}},"/playground/01_literature/competency-mapping":{"label":"Competency Mapping","children":{}},"/playground/01_literature/configure-the-company-email":{"label":"Configure The Company Email","children":{}},"/playground/01_literature/considering-factors-for-performance-evaluating":{"label":"Considering Factors For Performance Evaluating","children":{}},"/playground/01_literature/cost-of-react-native":{"label":"Cost Of React Native","children":{}},"/playground/01_literature/create-circular-text-using-swiftui":{"label":"Create Circular Text Using Swiftui","children":{}},"/playground/01_literature/creating-a-fully-local-search-engine-on-memo":{"label":"Building a Local Search Engine for Our Memo Website","children":{}},"/playground/01_literature/daemons-and-services-programming-guide":{"label":"Daemons And Services Programming Guide","children":{}},"/playground/01_literature/data-analyst-in-retail-trading":{"label":"Data Analyst In Retail Trading","children":{}},"/playground/01_literature/database-design-circular":{"label":"Database design Circular","children":{}},"/playground/01_literature/database-designs-for-multilingual-apps":{"label":"Database Designs For Multilingual Apps","children":{}},"/playground/01_literature/dcos-series-part-1-quick-look-installation":{"label":"Dcos Series Part 1 Quick Look Installation","children":{}},"/playground/01_literature/dcos-series-part-2-deploy-simple-applications":{"label":"Dcos Series Part 2 Deploy Simple Applications","children":{}},"/playground/01_literature/dcos-series-part-3-service-discovery-and-load-balancing":{"label":"Dcos Series Part 3 Service Discovery And Load Balancing","children":{}},"/playground/01_literature/dcos-series-part-4-deploy-simple-application-with-backend-database":{"label":"Dcos Series Part 4 Deploy Simple Application With Backend Database","children":{}},"/playground/01_literature/dcos-series-part-5-gitlab":{"label":"Dcos Series Part 5 Gitlab","children":{}},"/playground/01_literature/definition-of-done":{"label":"Definition Of Done","children":{}},"/playground/01_literature/design":{"label":"Design","children":{"/playground/01_literature/design/product-design-commentary-20240927":{"label":"Product Design Commentary #1: New technologies changing UX/UI and product design","children":{}},"/playground/01_literature/design/product-design-commentary-20241004":{"label":"Product Design Commentary #2: Unpacking the sparkles icon and AI onboarding challenges","children":{}},"/playground/01_literature/design/product-design-commentary-20241011":{"label":"Product Design Commentary #3: The art of prompting in AI-human interaction","children":{}},"/playground/01_literature/design/product-design-commentary-20241018":{"label":"Product Design Commentary #4: Generative AI UX design patterns","children":{}},"/playground/01_literature/design/product-design-commentary-20241101":{"label":"Product Design Commentary #5: Figma to SwiftUI (functional code) with Claude AI","children":{}},"/playground/01_literature/design/product-design-commentary-20241115":{"label":"Product Design Commentary #6: AI in Design - Cool ideas and how to make them happen","children":{}},"/playground/01_literature/design/product-design-commentary-20241122":{"label":"Product Design Commentary #7: Hyper-personalization - How AI improves user experience personalization","children":{}}}},"/playground/01_literature/design-better-mobile-application":{"label":"Design Better Mobile Application","children":{}},"/playground/01_literature/design-file-sharing-system-part-1-directory-structure":{"label":"Design file-sharing system - Part 1: Directory Structure","children":{}},"/playground/01_literature/design-file-sharing-system-part-2-permission-and-password":{"label":"Design file-sharing system - Part 2: Permission & Password","children":{}},"/playground/01_literature/design-less-present-more-with-deckset":{"label":"Design less, present more with Deckset","children":{}},"/playground/01_literature/design-resourcestools":{"label":"Design Resourcestools","children":{}},"/playground/01_literature/design-system-for-layer-2-using-zk-rollup":{"label":"Design System For Layer 2 Using Zk Rollup","children":{}},"/playground/01_literature/design-system":{"label":"Design System","children":{}},"/playground/01_literature/design-tips-tricks":{"label":"Design Tips Tricks","children":{}},"/playground/01_literature/design-workflow":{"label":"Design Workflow","children":{}},"/playground/01_literature/designing-a-model-with-dynamic-properties":{"label":"Designing a model with dynamic properties","children":{}},"/playground/01_literature/designing-for-forgiveness":{"label":"Designing for Forgiveness: Creating Error-Tolerant Interfaces","children":{}},"/playground/01_literature/different-ways-to-test-react-application":{"label":"Different Ways To Test React Application","children":{}},"/playground/01_literature/docker-microcontainers":{"label":"Docker Microcontainers","children":{}},"/playground/01_literature/docker-registry":{"label":"Docker Registry","children":{}},"/playground/01_literature/dollar-cost-averaging":{"label":"Dollar Cost Averaging (DCA)","children":{}},"/playground/01_literature/domain-glossary":{"label":"Domain Glossary","children":{}},"/playground/01_literature/domain-insight-research-framework":{"label":"Domain Insight Research Framework","children":{}},"/playground/01_literature/draw-watch-face-using-swiftui":{"label":"Draw Watch Face Using Swiftui","children":{}},"/playground/01_literature/duckdb-demo-and-showcase":{"label":"DuckDB demo and showcase","children":{}},"/playground/01_literature/dwarves-radio-talk-16-run-an-effective-performance-review":{"label":"Dwarves Radio Talk 16 Run An Effective Performance Review","children":{}},"/playground/01_literature/dwarves-radio-talk-17-conduct-a-1-1-session":{"label":"Dwarves Radio Talk 17 Conduct A 1 1 Session","children":{}},"/playground/01_literature/dynamic-liquidity-market-a-new-form-of-concentrated-liquidity-amm-on-solana":{"label":"Dynamic Liquidity Market Maker - a new form of concentrated liquidity AMM on Solana","children":{}},"/playground/01_literature/easy-prompt-engineering-for-business-use-and-mitigating-risks-in-llms":{"label":"Easy Prompt Engineering For Business Use And Mitigating Risks In Llms","children":{}},"/playground/01_literature/echelon-x-singapore-2024-where-innovations-meet-inspiration":{"label":"Echelon X Singapore 2024: Where Innovations Meet Inspiration","children":{}},"/playground/01_literature/engineering":{"label":"Engineering","children":{"/playground/01_literature/engineering/backend":{"label":"Backend","children":{"/playground/01_literature/engineering/backend/bloom-filter":{"label":"Bloom Filter","children":{}},"/playground/01_literature/engineering/backend/introduction-to-crdt":{"label":"Introduction to CRDT","children":{}},"/playground/01_literature/engineering/backend/sql-and-how-it-relates-to-disk-reads-and-writes":{"label":"SQL and how it relates to Disk Reads and Writes","children":{}},"/playground/01_literature/engineering/backend/sql-sargable-queries-and-their-impact-on-database-performance":{"label":"SQL Saragable Queries and Their Impact on Database Performance","children":{}},"/playground/01_literature/engineering/backend/the-removal-of-apache-kafkas-dependency-on-zookeeper":{"label":"The removal of Apache Kafka's dependency on Zookeeper","children":{}}}},"/playground/01_literature/engineering/data":{"label":"Data","children":{"/playground/01_literature/engineering/data/data-pipeline-design-framework":{"label":"Data Pipeline Design Framework","children":{}},"/playground/01_literature/engineering/data/mapreduce":{"label":"MapReduce","children":{}},"/playground/01_literature/engineering/data/quick-learning-vector-database":{"label":"Quick Learning Vector Database","children":{}}}},"/playground/01_literature/engineering/google-data-fusion":{"label":"Google Data Fusion","children":{}},"/playground/01_literature/engineering/google-dataproc":{"label":"Google Dataproc","children":{}},"/playground/01_literature/engineering/introducing-htmx-navigating-the-advantages-and-concerns":{"label":"Introducing HTMX - Navigating the Advantages and Concerns","children":{}},"/playground/01_literature/engineering/typesafe-client-server":{"label":"Typesafe Client Server","children":{}},"/playground/01_literature/engineering/url-redirect-vs-rewrite":{"label":"URL Redirect vs. Rewrite; What’s the difference?","children":{}}}},"/playground/01_literature/error-handling-in-rust":{"label":"Error handling on Rust","children":{}},"/playground/01_literature/estimation-in-agile":{"label":"Estimation In Agile","children":{}},"/playground/01_literature/evolutionary-database-design":{"label":"Evolutionary Database Design: Managing Change and Scaling with the System","children":{}},"/playground/01_literature/exploring-machine-learning-approaches-for-fine-tuning-llama-models":{"label":"Exploring Machine Learning Approaches For Fine Tuning Llama Models","children":{}},"/playground/01_literature/fabric-hyperledger-architecture-explanation":{"label":"Fabric Hyperledger Architecture Explanation","children":{}},"/playground/01_literature/federated-byzantine":{"label":"Federated Byzantine","children":{}},"/playground/01_literature/feedback-mechanism":{"label":"Design feedback mechanism for LLM applications","children":{}},"/playground/01_literature/finite-state-machine":{"label":"Finite State Machine","children":{}},"/playground/01_literature/from-data-to-backend-an-apprentice-sharing":{"label":"From Data To Backend An Apprentice Sharing","children":{}},"/playground/01_literature/from-multi-repo-to-monorepo-a-case-study-with-nghenhan-turbo-monorepo":{"label":"From Multi Repo To Monorepo A Case Study With Nghenhan Turbo Monorepo","children":{}},"/playground/01_literature/fundamental-end-to-end-frontend-testing-with-cypress":{"label":"Fundamental End To End Frontend Testing With Cypress","children":{}},"/playground/01_literature/gestalt-principles-in-ui-design":{"label":"Gestalt Principles In Ui Design","children":{}},"/playground/01_literature/getting-started-with-webflow":{"label":"Getting Started With Webflow","children":{}},"/playground/01_literature/git-commit-message-convention":{"label":"Git Commit Message Convention","children":{}},"/playground/01_literature/gitflow-pull-request":{"label":"Gitflow Pull Request","children":{}},"/playground/01_literature/giving-a-talk-checklist":{"label":"Giving a talk","children":{}},"/playground/01_literature/good-design-understanding":{"label":"Good Design Understanding","children":{}},"/playground/01_literature/grid-and-layout":{"label":"Grid And Layout","children":{}},"/playground/01_literature/growth-is-our-universal-language":{"label":"Growth Is Our Universal Language","children":{}},"/playground/01_literature/history-of-structured-output-for-llms":{"label":"History of Structured Outputs for LLMs","children":{}},"/playground/01_literature/hoc-renderprops-and-hook-in-reactjs":{"label":"Hoc Renderprops And Hook In Reactjs","children":{}},"/playground/01_literature/how-a-design-system-work":{"label":"How A Design System Work","children":{}},"/playground/01_literature/how-blue-green-deployment-helped-mochi":{"label":"How Blue Green Deployment Helped Mochi","children":{}},"/playground/01_literature/how-i-create-content-for-multiple-platforms-at-dwarves":{"label":"How I Create Content for Multiple Platforms at Dwarves","children":{}},"/playground/01_literature/how-rd-contributes-to-performance-review":{"label":"How R&D contributes to Performance Review","children":{}},"/playground/01_literature/how-to-earn-reward-from-staking-dfg":{"label":"How to earn reward from staking DFG","children":{}},"/playground/01_literature/how-to-make-a-moc":{"label":"How to make a MOC","children":{}},"/playground/01_literature/how-to-push-content-on-note-d":{"label":"How to push content on memo.d.foundation","children":{}},"/playground/01_literature/how-to-recap-a-publication":{"label":"Recapping A publication","children":{}},"/playground/01_literature/how-to-set-up-environment-for-editing-memo":{"label":"How to set up environment to edit memo","children":{}},"/playground/01_literature/how-to-take-better-screenshots-on-mac":{"label":"How To Take Better Screenshots On Mac","children":{}},"/playground/01_literature/how-to-transfer-dfg-from-eth-to-base-for-staking":{"label":"How to bridge $DFG from Ethereum Mainnet to Base Network for staking","children":{}},"/playground/01_literature/how-we-contribute-to-homebrew":{"label":"How We Contribute To Homebrew","children":{}},"/playground/01_literature/how-we-crafted-the-ogif-summarizer-bot-to-streamline-weekly-knowledge-sharing":{"label":"How we crafted the OGIF summarizer bot to streamline weekly knowledge-sharing","children":{}},"/playground/01_literature/how-we-created-an-ai-powered-interview-system-using-openais-chatgpt":{"label":"How We Created An Ai Powered Interview System Using Openais Chatgpt","children":{}},"/playground/01_literature/how-we-setup-cicd":{"label":"How We Setup Cicd","children":{}},"/playground/01_literature/hybrid-search":{"label":"Evaluating search engine in RAG systems","children":{}},"/playground/01_literature/i18n-frontend-guideline":{"label":"I18n Frontend Guideline","children":{}},"/playground/01_literature/infinite-image-gallery-with-r3f-an-approach":{"label":"Infinite Image Gallery With R3f An Approach","children":{}},"/playground/01_literature/introduce-to-dwarves-memo":{"label":"Introduce To Dwarves Memo","children":{}},"/playground/01_literature/introduction-to-software-craftsmanship":{"label":"Introduction To Software Craftsmanship","children":{}},"/playground/01_literature/istio":{"label":"Istio","children":{}},"/playground/01_literature/knowledge-journey":{"label":"Knowledge Journey","children":{}},"/playground/01_literature/kubernetes-helm-101":{"label":"Kubernetes Helm 101","children":{}},"/playground/01_literature/labs-new-member-onboarding":{"label":"Labs - New Member Onboarding","children":{}},"/playground/01_literature/labs-roadmap-nov-23-update":{"label":"Labs Roadmap (Nov 23 update)","children":{}},"/playground/01_literature/labs-topic-proposal-progress-tracking":{"label":"Labs - Topic proposal & progress tracking","children":{}},"/playground/01_literature/labs-weekly-catchup-1":{"label":"Labs Weekly Catchup #1","children":{}},"/playground/01_literature/labs-weekly-catchup-2":{"label":"Labs Weekly Catchup #2","children":{}},"/playground/01_literature/labs-weekly-catchup-3":{"label":"Labs Weekly Catchup #3","children":{}},"/playground/01_literature/labs-weekly-catchup-4":{"label":"Labs Weekly Catchup #4","children":{}},"/playground/01_literature/labs-weekly-catchup-5":{"label":"Labs Weekly Catchup #5","children":{}},"/playground/01_literature/labs-who-we-are":{"label":"Labs - Who we are","children":{}},"/playground/01_literature/labs-x-consulting-workflow":{"label":"Labs x Consulting Workflow","children":{}},"/playground/01_literature/lessons-learned-from-being-a-part-of-corporate-micro-frontend-implementation":{"label":"Lessons Learned From Being A Part Of Corporate Micro Frontend Implementation","children":{}},"/playground/01_literature/lessons-learned-from-concurrency-practices-in-blockchain-projects":{"label":"Lessons Learned From Concurrency Practices In Blockchain Projects","children":{}},"/playground/01_literature/level-up-your-markdown-memos":{"label":"Level Up Your Markdown Memos: Avoiding Common Pitfalls","children":{}},"/playground/01_literature/lifecycle-of-a-publication":{"label":"Life cycle of a publication","children":{}},"/playground/01_literature/local-first-software":{"label":"Local-first Software","children":{}},"/playground/01_literature/managing-dataflow-and-sql-database-with-concurrency-control":{"label":"Managing Dataflow And Sql Database With Concurrency Control","children":{}},"/playground/01_literature/market":{"label":"Market","children":{"/playground/01_literature/market/an-overview-of-micro-investment-in-real-estate":{"label":"An Overview Of Micro Investment In Real Estate","children":{}}}},"/playground/01_literature/memo-knowledge-base-meeting":{"label":"Memo Knowledge Base Meeting","children":{}},"/playground/01_literature/memo-publication-workflow":{"label":"Memo Publication Workflow","children":{}},"/playground/01_literature/objective":{"label":"Objective","children":{}},"/playground/01_literature/observer-pattern":{"label":"Introduce the Observer pattern and its use cases","children":{}},"/playground/01_literature/our-daily-standup-format":{"label":"Our Daily Standup Format","children":{}},"/playground/01_literature/our-view-on-fullstack-engineering":{"label":"Our View On Fullstack Engineering","children":{}},"/playground/01_literature/overview-on-broker-pattern-in-distributed-system":{"label":"Overview On Broker Pattern In Distributed System","children":{}},"/playground/01_literature/passing-the-probation-get-3-upvotes":{"label":"Passing The Probation Get 3 Upvotes","children":{}},"/playground/01_literature/peep-nft":{"label":"Claim your Peeps NFT","children":{}},"/playground/01_literature/playaround-with-clojure":{"label":"Playaround With Clojure","children":{}},"/playground/01_literature/playaround-with-rust":{"label":"Playaround With Rust","children":{}},"/playground/01_literature/project-management":{"label":"Project Management","children":{}},"/playground/01_literature/prototype-design-pattern":{"label":"Going Through use cases of the prototype design pattern and it place among the creational patterns","children":{}},"/playground/01_literature/qc-onboarding":{"label":"Qc Onboarding","children":{}},"/playground/01_literature/radio-talk-60-blue-green-deployment":{"label":"Radio Talk 60 Blue Green Deployment","children":{}},"/playground/01_literature/radio-talk-61-monorepo":{"label":"Radio Talk 61 Monorepo","children":{}},"/playground/01_literature/radix-sort":{"label":"Radix Sort","children":{}},"/playground/01_literature/react-native-new-architecture":{"label":"React Native New Architecture","children":{}},"/playground/01_literature/record-reward-sharing-culture":{"label":"Record and reward sharing at Dwarves","children":{}},"/playground/01_literature/recording-flow":{"label":"How We Set Up a Recording Workflow for Dwarves Office Hours","children":{}},"/playground/01_literature/recursively-export-file-pattern-in-javascript-es6-application":{"label":"Recursively Export File Pattern In Javascript Es6 Application","children":{}},"/playground/01_literature/remote-moderated-usability-testing":{"label":"Remote Moderated Usability Testing","children":{}},"/playground/01_literature/remote-prepare-and-get-going":{"label":"Remote Prepare And Get Going","children":{}},"/playground/01_literature/reproduce-apple-find-me-bottom-menu-view":{"label":"Reproduce Apple Find Me Bottom Menu View","children":{}},"/playground/01_literature/resource-assignment":{"label":"Resource Assignment","children":{}},"/playground/01_literature/responsibility":{"label":"Responsibility","children":{}},"/playground/01_literature/reusability-in-software-development":{"label":"Reusability In Software Development","children":{}},"/playground/01_literature/reward-model-nomination":{"label":"Reward Model & Nomination","children":{}},"/playground/01_literature/salary-advance":{"label":"$icy Salary Advance","children":{}},"/playground/01_literature/sdk-event-sourcing":{"label":"Sdk Event Sourcing","children":{}},"/playground/01_literature/security":{"label":"Security","children":{"/playground/01_literature/security/a-holistic-guide-to-security":{"label":"A Holistic Guide to Security","children":{}},"/playground/01_literature/security/how-i-came-up-with-our-security-standard":{"label":"How I came up with our Security Standard","children":{}}}},"/playground/01_literature/setup-react-project-with-webpack-and-babel":{"label":"Setup React Project With Webpack And Babel","children":{}},"/playground/01_literature/singleton-design-pattern":{"label":"A tour of Singleton design pattern with Golang","children":{}},"/playground/01_literature/six-things-i-extracted-from-design-thinking":{"label":"Six Things I Extracted From Design Thinking","children":{}},"/playground/01_literature/skill-of-software-engineer":{"label":"Skill Of Software Engineer","children":{}},"/playground/01_literature/software-development-life-cycle-101":{"label":"Software Development Life Cycle 101","children":{}},"/playground/01_literature/software-modeling":{"label":"Software Modeling","children":{}},"/playground/01_literature/split-and-reuse-code-in-react-application":{"label":"Split And Reuse Code In React Application","children":{}},"/playground/01_literature/sprint-lifecycle":{"label":"Sprint Lifecycle","children":{}},"/playground/01_literature/sql-practices-orm-vs-plain-sql":{"label":"Sql Practices Orm Vs Plain Sql","children":{}},"/playground/01_literature/startups-vs-junior-designers":{"label":"Startups Vs Junior Designers","children":{}},"/playground/01_literature/state-pattern":{"label":"State Pattern","children":{}},"/playground/01_literature/strategy-design-pattern":{"label":"Strategy design pattern, the concept, use cases and difference with the state design pattern","children":{}},"/playground/01_literature/swiftui":{"label":"Swiftui","children":{}},"/playground/01_literature/tech-canvas":{"label":"Tech Canvas","children":{}},"/playground/01_literature/tech-event-in-the-latest-transforming-healthcare-with-technology":{"label":"Tech Event In The Latest Transforming Healthcare With Technology","children":{}},"/playground/01_literature/template-method-design-pattern":{"label":"A Tour of Template method pattern with Golang","children":{}},"/playground/01_literature/the-10x-engineer":{"label":"The 10x Engineer","children":{}},"/playground/01_literature/the-correct-way-to-build-kpi":{"label":"The Correct Way To Build Kpi","children":{}},"/playground/01_literature/the-key-of-security-mechanisms-in-tackling-cyber-threats":{"label":"The Key Of Security Mechanisms In Tackling Cyber Threats","children":{}},"/playground/01_literature/the-principle-of-spacing-in-ui-design-part-1":{"label":"The Principle Of Spacing In Ui Design Part 1","children":{}},"/playground/01_literature/the-principle-of-spacing-in-ui-design-part-2":{"label":"The Principle Of Spacing In Ui Design Part 2","children":{}},"/playground/01_literature/three-levels-of-design":{"label":"Three Levels Of Design","children":{}},"/playground/01_literature/traits-to-assess-during-an-interview":{"label":"Traits To Assess During An Interview","children":{}},"/playground/01_literature/ui-design-best-practices-dwarves":{"label":"Ui Design Best Practices Dwarves","children":{}},"/playground/01_literature/ui-design-fundamental":{"label":"Ui Design Fundamental","children":{}},"/playground/01_literature/uidynamicanimator":{"label":"Uidynamicanimator","children":{}},"/playground/01_literature/understanding-an-application-design":{"label":"Understanding An Application Design","children":{}},"/playground/01_literature/understanding-saving-investing-and-speculating-key-differences-and-strategies":{"label":"Understanding Saving, Investing, and Speculating: Key Differences and Strategies","children":{}},"/playground/01_literature/using-foundry-for-evm-smart-contract-developement":{"label":"Using Foundry for EVM smart contract development","children":{}},"/playground/01_literature/ux-model":{"label":"Ux Model","children":{}},"/playground/01_literature/vietnam-tech-ecosystem-report":{"label":"Vietnam Tech Ecosystem 2024 Report","children":{}},"/playground/01_literature/visitor-design-pattern":{"label":"Visitor design pattern, the concept, problem solution and use cases","children":{}},"/playground/01_literature/well-crafted-software":{"label":"Well Crafted Software","children":{}},"/playground/01_literature/what-i-learned-on-design-thinking-and-software-development":{"label":"What I Learned On Design Thinking And Software Development","children":{}},"/playground/01_literature/what-is-kubernetes":{"label":"What Is Kubernetes","children":{}},"/playground/01_literature/working-on-a-project-interview-assessment-at-dwarves":{"label":"Working On A Project Interview Assessment At Dwarves","children":{}},"/playground/01_literature/writing":{"label":"Writing","children":{"/playground/01_literature/writing/state-explain-link":{"label":"State, Explain, Link - An all-purpose writing technique","children":{}}}},"/playground/01_literature/writing-content-for-multimedia-guidelines":{"label":"Writing Content for Multimedia Guidelines","children":{}},"/playground/01_literature/xpc-services-on-macos-app-using-swift":{"label":"Xpc Services On Macos App Using Swift","children":{}}}},"/playground/_radar":{"label":"_radar","children":{"/playground/_radar/ant-design":{"label":"Ant Design","children":{}},"/playground/_radar/apache-kafka":{"label":"Apache Kafka","children":{}},"/playground/_radar/apache-spark":{"label":"Apache Spark","children":{}},"/playground/_radar/argocd":{"label":"Argocd","children":{}},"/playground/_radar/astro":{"label":"Astro","children":{}},"/playground/_radar/backstage":{"label":"Backstage","children":{}},"/playground/_radar/blue-green-deployment":{"label":"Blue Green Deployment","children":{}},"/playground/_radar/browserstack":{"label":"Browserstack","children":{}},"/playground/_radar/carbon":{"label":"Carbon","children":{}},"/playground/_radar/chatgpt-assistance":{"label":"Chatgpt Assistance","children":{}},"/playground/_radar/chromatic":{"label":"Chromatic","children":{}},"/playground/_radar/clickhouse":{"label":"Clickhouse","children":{}},"/playground/_radar/cloudflare-workers":{"label":"Cloudflare Workers","children":{}},"/playground/_radar/codecept":{"label":"Codecept","children":{}},"/playground/_radar/commitlint":{"label":"Commitlint","children":{}},"/playground/_radar/copilot":{"label":"Copilot","children":{}},"/playground/_radar/cucumber":{"label":"Cucumber","children":{}},"/playground/_radar/cypress":{"label":"Cypress","children":{}},"/playground/_radar/dapr":{"label":"Dapr","children":{}},"/playground/_radar/deno":{"label":"Deno","children":{}},"/playground/_radar/detox":{"label":"Detox","children":{}},"/playground/_radar/devcontainers":{"label":"Devcontainers","children":{}},"/playground/_radar/devpod":{"label":"Devpod","children":{}},"/playground/_radar/dora-metrics":{"label":"Dora Metrics","children":{}},"/playground/_radar/duckdb":{"label":"Duckdb","children":{}},"/playground/_radar/earthly":{"label":"Earthly","children":{}},"/playground/_radar/elixir-umbrella-project":{"label":"Elixir Umbrella Project","children":{}},"/playground/_radar/elixir":{"label":"Elixir","children":{}},"/playground/_radar/erlang":{"label":"Erlang","children":{}},"/playground/_radar/error-logging-convention":{"label":"Error Logging Convention","children":{}},"/playground/_radar/eslint":{"label":"Eslint","children":{}},"/playground/_radar/event-sourcing":{"label":"Event Sourcing","children":{}},"/playground/_radar/excalidraw":{"label":"Excalidraw","children":{}},"/playground/_radar/expo":{"label":"Expo","children":{}},"/playground/_radar/figma":{"label":"Figma","children":{}},"/playground/_radar/formal-verification":{"label":"Formal Verification","children":{}},"/playground/_radar/fullstack-tracing":{"label":"Fullstack Tracing","children":{}},"/playground/_radar/gestalt-principle":{"label":"Gestalt Principle","children":{}},"/playground/_radar/github-actions":{"label":"Github Actions","children":{}},"/playground/_radar/golang":{"label":"Golang","children":{}},"/playground/_radar/grafana":{"label":"Grafana","children":{}},"/playground/_radar/graylog":{"label":"Graylog","children":{}},"/playground/_radar/headless-ui":{"label":"Headless Ui","children":{}},"/playground/_radar/hoppscotch":{"label":"Hoppscotch","children":{}},"/playground/_radar/ipfs":{"label":"Ipfs","children":{}},"/playground/_radar/jotai":{"label":"Jotai","children":{}},"/playground/_radar/k6":{"label":"K6","children":{}},"/playground/_radar/k9s":{"label":"K9s","children":{}},"/playground/_radar/kaniko":{"label":"Kaniko","children":{}},"/playground/_radar/kotlin":{"label":"Kotlin","children":{}},"/playground/_radar/kubeseal-sops":{"label":"Kubeseal Sops","children":{}},"/playground/_radar/ladle":{"label":"Ladle","children":{}},"/playground/_radar/langchain":{"label":"Langchain","children":{}},"/playground/_radar/large-language-model-llm":{"label":"Large Language Model Llm","children":{}},"/playground/_radar/loki":{"label":"Loki","children":{}},"/playground/_radar/makefile":{"label":"Makefile","children":{}},"/playground/_radar/micro-frontend":{"label":"Micro Frontend","children":{}},"/playground/_radar/monorepo":{"label":"Monorepo","children":{}},"/playground/_radar/msw":{"label":"Msw","children":{}},"/playground/_radar/n6n":{"label":"N6n","children":{}},"/playground/_radar/nestjs":{"label":"Nestjs","children":{}},"/playground/_radar/netlify":{"label":"Netlify","children":{}},"/playground/_radar/newrelic":{"label":"Newrelic","children":{}},"/playground/_radar/nextjs":{"label":"Nextjs","children":{}},"/playground/_radar/nodejs":{"label":"Nodejs","children":{}},"/playground/_radar/nostrum":{"label":"Nostrum","children":{}},"/playground/_radar/nx":{"label":"Nx","children":{}},"/playground/_radar/orval":{"label":"Orval","children":{}},"/playground/_radar/page-object-model":{"label":"Page Object Model","children":{}},"/playground/_radar/partytown":{"label":"Partytown","children":{}},"/playground/_radar/phaser":{"label":"Phaser","children":{}},"/playground/_radar/phoenix":{"label":"Phoenix","children":{}},"/playground/_radar/playwright":{"label":"Playwright","children":{}},"/playground/_radar/pnpm":{"label":"Pnpm","children":{}},"/playground/_radar/progressive-delivery":{"label":"Progressive Delivery","children":{}},"/playground/_radar/prometheus":{"label":"Prometheus","children":{}},"/playground/_radar/prompt-engineering":{"label":"Prompt Engineering","children":{}},"/playground/_radar/qwik":{"label":"Qwik","children":{}},"/playground/_radar/radix-ui":{"label":"Radix Ui","children":{}},"/playground/_radar/react-hook-form":{"label":"React Hook Form","children":{}},"/playground/_radar/react-llm":{"label":"React Llm","children":{}},"/playground/_radar/react-native":{"label":"React Native","children":{}},"/playground/_radar/react-query":{"label":"React Query","children":{}},"/playground/_radar/react-server-component":{"label":"React Server Component","children":{}},"/playground/_radar/react-testing-library":{"label":"React Testing Library","children":{}},"/playground/_radar/react":{"label":"React","children":{}},"/playground/_radar/reinforcement-learning-from-human-feedback":{"label":"Reinforcement Learning From Human Feedback","children":{}},"/playground/_radar/remix":{"label":"Remix","children":{}},"/playground/_radar/replayio":{"label":"Replayio","children":{}},"/playground/_radar/reverse-engineering":{"label":"Reverse Engineering","children":{}},"/playground/_radar/rust":{"label":"Rust","children":{}},"/playground/_radar/selenium":{"label":"Selenium","children":{}},"/playground/_radar/semantic-release-auto-release":{"label":"Semantic Release Auto Release","children":{}},"/playground/_radar/sentry":{"label":"Sentry","children":{}},"/playground/_radar/serverlessq":{"label":"Serverlessq","children":{}},"/playground/_radar/solidity":{"label":"Solidity","children":{}},"/playground/_radar/solidjs":{"label":"Solidjs","children":{}},"/playground/_radar/stern":{"label":"Stern","children":{}},"/playground/_radar/svelte":{"label":"Svelte","children":{}},"/playground/_radar/swagger":{"label":"Swagger","children":{}},"/playground/_radar/swift-ui":{"label":"Swift Ui","children":{}},"/playground/_radar/swift":{"label":"Swift","children":{}},"/playground/_radar/swr":{"label":"Swr","children":{}},"/playground/_radar/tailwindcss":{"label":"Tailwindcss","children":{}},"/playground/_radar/tauri":{"label":"Tauri","children":{}},"/playground/_radar/team-topologies":{"label":"Team Topologies","children":{}},"/playground/_radar/timeline":{"label":"Timeline","children":{"/playground/_radar/timeline/a-case-study-interview-into-micro-frontends-building-design-system-for-e-commerce-platform":{"label":"A Case Study Interview Into Micro Frontends Building Design System For E Commerce Platform","children":{}},"/playground/_radar/timeline/accelerate-project-initiation-with-advanced-nextjs-boilerplate-react-toolkit":{"label":"Accelerate Project Initiation With Advanced Nextjs Boilerplate React Toolkit","children":{}},"/playground/_radar/timeline/adapt-cucumber-as-a-bdd-for-wego":{"label":"Adapt Cucumber As A Bdd For Wego","children":{}},"/playground/_radar/timeline/add-type-safe-client-server-support-for-next-boilerplate":{"label":"Add Type Safe Client Server Support For Next Boilerplate","children":{}},"/playground/_radar/timeline/adoption-of-pnpm":{"label":"Adoption Of Pnpm","children":{}},"/playground/_radar/timeline/adversarial-prompting":{"label":"Adversarial Prompting","children":{}},"/playground/_radar/timeline/an-engineering-story-map-for-llms":{"label":"An Engineering Story Map For Llms","children":{}},"/playground/_radar/timeline/apply-blue-green-deployment-to-mochi":{"label":"Apply Blue Green Deployment To Mochi","children":{}},"/playground/_radar/timeline/apply-monorepos-to-repit-to-resolve-the-problem-of-consistency":{"label":"Apply Monorepos To Repit To Resolve The Problem Of Consistency","children":{}},"/playground/_radar/timeline/apply-page-object-model-structure-to-aharooms":{"label":"Apply Page Object Model Structure To Aharooms","children":{}},"/playground/_radar/timeline/apply-page-object-model-structure-to-artzy":{"label":"Apply Page Object Model Structure To Artzy","children":{}},"/playground/_radar/timeline/apply-page-object-model-structure-to-basehq":{"label":"Apply Page Object Model Structure To Basehq","children":{}},"/playground/_radar/timeline/apply-page-object-model-structure-to-sci":{"label":"Apply Page Object Model Structure To Sci","children":{}},"/playground/_radar/timeline/apply-page-object-model-structure-to-wego":{"label":"Apply Page Object Model Structure To Wego","children":{}},"/playground/_radar/timeline/applying-mock-service-worker-msw-for-seamless-web-development":{"label":"Applying Mock Service Worker Msw For Seamless Web Development","children":{}},"/playground/_radar/timeline/approaches-to-manage-concurrent-workloads-like-worker-pools-and-pipelines":{"label":"Approaches To Manage Concurrent Workloads Like Worker Pools And Pipelines","children":{}},"/playground/_radar/timeline/backend-for-call-requests-to-binance-and-get-data-from-multiple-platforms":{"label":"Backend For Call Requests To Binance And Get Data From Multiple Platforms","children":{}},"/playground/_radar/timeline/brainery-blue-green-deployment":{"label":"Brainery Blue Green Deployment","children":{}},"/playground/_radar/timeline/brainery-progressive-delivery":{"label":"Brainery Progressive Delivery","children":{}},"/playground/_radar/timeline/brainery-validation-with-zod":{"label":"Brainery Validation With Zod","children":{}},"/playground/_radar/timeline/build-automation-for-sci":{"label":"Build Automation For Sci","children":{}},"/playground/_radar/timeline/build-your-chatbot-with-open-source-large-language-models":{"label":"Build Your Chatbot With Open Source Large Language Models","children":{}},"/playground/_radar/timeline/building-reliable-apps-sentry-and-distributed-tracing-for-effective-monitoring":{"label":"Building Reliable Apps Sentry And Distributed Tracing For Effective Monitoring","children":{}},"/playground/_radar/timeline/case-study-from-multiple-repo-to-monorepo-at-nghe-nhan":{"label":"Case Study From Multiple Repo To Monorepo At Nghe Nhan","children":{}},"/playground/_radar/timeline/case-study-how-blue-green-deployment-help-mochi":{"label":"Case Study How Blue Green Deployment Help Mochi","children":{}},"/playground/_radar/timeline/challenge-faced-when-researching-rlhf-with-open-assistant":{"label":"Challenge Faced When Researching Rlhf With Open Assistant","children":{}},"/playground/_radar/timeline/chunking-strategies-to-overcome-context-limitation-in-llm":{"label":"Chunking Strategies To Overcome Context Limitation In Llm","children":{}},"/playground/_radar/timeline/common-design-patterns-in-golang-part-1":{"label":"Common Design Patterns In Golang Part 1","children":{}},"/playground/_radar/timeline/create-api-service-for-urbox-to-sync-orders-from-3rd-parties-and-manage-shipment":{"label":"Create Api Service For Urbox To Sync Orders From 3rd Parties And Manage Shipment","children":{}},"/playground/_radar/timeline/create-backend-monorepo-to-share-code-and-manage-multiple-services-in-one-repo":{"label":"Create Backend Monorepo To Share Code And Manage Multiple Services In One Repo","children":{}},"/playground/_radar/timeline/create-working-devcontainer-for-go-api":{"label":"Create Working Devcontainer For Go Api","children":{}},"/playground/_radar/timeline/create-working-devcontainer-for-nextjs-boilerplate":{"label":"Create Working Devcontainer For Nextjs Boilerplate","children":{}},"/playground/_radar/timeline/dealing-with-long-term-memory-of-chatbot":{"label":"Dealing With Long Term Memory Of Chatbot","children":{}},"/playground/_radar/timeline/develop-codecept-to-integrate-with-fortress":{"label":"Develop Codecept To Integrate With Fortress","children":{}},"/playground/_radar/timeline/develop-sdk-integration-demo-for-sajari":{"label":"Develop Sdk Integration Demo For Sajari","children":{}},"/playground/_radar/timeline/develop":{"label":"Develop","children":{}},"/playground/_radar/timeline/diagnosing-and-resolving-performance-issues-with-pprof-and-trace-in-go":{"label":"Diagnosing And Resolving Performance Issues With Pprof And Trace In Go","children":{}},"/playground/_radar/timeline/easy-prompt-engineering-for-business-use-and-mitigating-risks-in-llms":{"label":"Easy Prompt Engineering For Business Use And Mitigating Risks In Llms","children":{}},"/playground/_radar/timeline/embracing-go-1210s-slog-a-unified-logging-interface-with-benchmarks-against-zerolog-and-zap":{"label":"Embracing Go 1210s Slog A Unified Logging Interface With Benchmarks Against Zerolog And Zap","children":{}},"/playground/_radar/timeline/error-handling-and-failure-management-in-a-go-system":{"label":"Error Handling And Failure Management In A Go System","children":{}},"/playground/_radar/timeline/exploring-resumable-server-side-rendering-with-qwik":{"label":"Exploring Resumable Server Side Rendering With Qwik","children":{}},"/playground/_radar/timeline/fe-23-training-type-safe-client-server":{"label":"Fe 23 Training Type Safe Client Server","children":{}},"/playground/_radar/timeline/first-introduced-use-of-duckdb-in-consolelabs-logconsoleso":{"label":"First Introduced Use Of Duckdb In Consolelabs Logconsoleso","children":{}},"/playground/_radar/timeline/foundation-model":{"label":"Foundation Model","children":{}},"/playground/_radar/timeline/from-multi-repo-to-monorepo-a-case-study-with-nghenhan":{"label":"From Multi Repo To Monorepo A Case Study With Nghenhan","children":{}},"/playground/_radar/timeline/go-training-2023-from-basic-to-advanced":{"label":"Go Training 2023 From Basic To Advanced","children":{}},"/playground/_radar/timeline/integrate-playwright-to-run-e2e-test-with-fortress":{"label":"Integrate Playwright To Run E2e Test With Fortress","children":{}},"/playground/_radar/timeline/integrate-playwright-x-codecept-with-discord":{"label":"Integrate Playwright X Codecept With Discord","children":{}},"/playground/_radar/timeline/integrate-zod-to-nextjs-boilerplate":{"label":"Integrate Zod To Nextjs Boilerplate","children":{}},"/playground/_radar/timeline/learn-typescript-as-a-mandatory-to-develop-reapit-foundation":{"label":"Learn Typescript As A Mandatory To Develop Reapit Foundation","children":{}},"/playground/_radar/timeline/lessons-learned-building-an-llm-chatbot-a-case-study":{"label":"Lessons Learned Building An Llm Chatbot A Case Study","children":{}},"/playground/_radar/timeline/lessons-learned-from-being-a-part-of-corporate-microfrontend-implementation":{"label":"Lessons Learned From Being A Part Of Corporate Microfrontend Implementation","children":{}},"/playground/_radar/timeline/lessons-learned-from-concurrency-practices-in-blockchain-projects":{"label":"Lessons Learned From Concurrency Practices In Blockchain Projects","children":{}},"/playground/_radar/timeline/level-up-your-testing-game-harnessing-gomock-for-unbeatable-unit-testing-in-go":{"label":"Level Up Your Testing Game Harnessing Gomock For Unbeatable Unit Testing In Go","children":{}},"/playground/_radar/timeline/live-view":{"label":"Live View","children":{}},"/playground/_radar/timeline/llm-101-enhance-developer-productivity":{"label":"Llm 101 Enhance Developer Productivity","children":{}},"/playground/_radar/timeline/llm-query-caching":{"label":"Llm Query Caching","children":{}},"/playground/_radar/timeline/llms-accuracy-self-refinement":{"label":"Llms Accuracy Self Refinement","children":{}},"/playground/_radar/timeline/mdx-document-for":{"label":"Mdx Document For","children":{}},"/playground/_radar/timeline/memo-blue-green-deployment":{"label":"Memo Blue Green Deployment","children":{}},"/playground/_radar/timeline/memo-react-native-new-architecture":{"label":"Memo React Native New Architecture","children":{}},"/playground/_radar/timeline/migrate-aharooms-pms-to-typescript":{"label":"Migrate Aharooms Pms To Typescript","children":{}},"/playground/_radar/timeline/migrate-headlessui-to-radixui":{"label":"Migrate Headlessui To Radixui","children":{}},"/playground/_radar/timeline/migrate-yarn-to-pnpm-in-fortress":{"label":"Migrate Yarn To Pnpm In Fortress","children":{}},"/playground/_radar/timeline/migrate-yarn-to-pnpm-in-nextjs-boilerplate":{"label":"Migrate Yarn To Pnpm In Nextjs Boilerplate","children":{}},"/playground/_radar/timeline/migrate-yarn-to-pnpm-in-nghe-nhan-droppii":{"label":"Migrate Yarn To Pnpm In Nghe Nhan Droppii","children":{}},"/playground/_radar/timeline/migrate-yarn-to-pnpm-in-react-toolkit":{"label":"Migrate Yarn To Pnpm In React Toolkit","children":{}},"/playground/_radar/timeline/nextjs-boilerplate":{"label":"Nextjs Boilerplate","children":{}},"/playground/_radar/timeline/nghenhan-microservices":{"label":"Nghenhan Microservices","children":{}},"/playground/_radar/timeline/open-source-devpod-paperspace-provider":{"label":"Open Source Devpod Paperspace Provider","children":{}},"/playground/_radar/timeline/overcoming-distributed-system-challenges-using-golang":{"label":"Overcoming Distributed System Challenges Using Golang","children":{}},"/playground/_radar/timeline/practice-and-using-selenium-in-setel-project":{"label":"Practice And Using Selenium In Setel Project","children":{}},"/playground/_radar/timeline/q-learning":{"label":"Q Learning","children":{}},"/playground/_radar/timeline/radio-talk-64-coding-best-practice-that-optimizing-go-compiler":{"label":"Radio Talk 64 Coding Best Practice That Optimizing Go Compiler","children":{}},"/playground/_radar/timeline/radio-talk-65-fullstack-type-safe-with-trpc":{"label":"Radio Talk 65 Fullstack Type Safe With Trpc","children":{}},"/playground/_radar/timeline/radio-talk-a-demo-of-query-engine-postgresql-vs-apache-spark":{"label":"Radio Talk A Demo Of Query Engine Postgresql Vs Apache Spark","children":{}},"/playground/_radar/timeline/radio-talk-blue-green-deployment":{"label":"Radio Talk Blue Green Deployment","children":{}},"/playground/_radar/timeline/radio-talk-engineering-health-metrics":{"label":"Radio Talk Engineering Health Metrics","children":{}},"/playground/_radar/timeline/radio-talk-introduction-to-apache-spark":{"label":"Radio Talk Introduction To Apache Spark","children":{}},"/playground/_radar/timeline/radio-talk-monorepo":{"label":"Radio Talk Monorepo","children":{}},"/playground/_radar/timeline/radio-talk-nextjs-13":{"label":"Radio Talk Nextjs 13","children":{}},"/playground/_radar/timeline/radio-talk-remix-vs-nextjs":{"label":"Radio Talk Remix Vs Nextjs","children":{}},"/playground/_radar/timeline/radio-talk-turborepo":{"label":"Radio Talk Turborepo","children":{}},"/playground/_radar/timeline/radio-talk-using-nextjs-as-a-fullstack-framework":{"label":"Radio Talk Using Nextjs As A Fullstack Framework","children":{}},"/playground/_radar/timeline/react-server-component":{"label":"React Server Component","children":{}},"/playground/_radar/timeline/react-toolkit-migrate-from-lerna-to-turporepo":{"label":"React Toolkit Migrate From Lerna To Turporepo","children":{}},"/playground/_radar/timeline/react-toolkit":{"label":"React Toolkit","children":{}},"/playground/_radar/timeline/reinforcement-learning":{"label":"Reinforcement Learning","children":{}},"/playground/_radar/timeline/reward-model":{"label":"Reward Model","children":{}},"/playground/_radar/timeline/rnd-team-mentioned-apache-spark-as-a-solution-to-handle-query-big-data":{"label":"Rnd Team Mentioned Apache Spark As A Solution To Handle Query Big Data","children":{}},"/playground/_radar/timeline/select-vector-database-for-llm":{"label":"Select Vector Database For Llm","children":{}},"/playground/_radar/timeline/state-of-frontend-2023-react-vs-angular-vs-vue":{"label":"State Of Frontend 2023 React Vs Angular Vs Vue","children":{}},"/playground/_radar/timeline/sum-command":{"label":"Sum Command","children":{}},"/playground/_radar/timeline/tackling-server-state-complexity-in-frontend-development":{"label":"Tackling Server State Complexity In Frontend Development","children":{}},"/playground/_radar/timeline/the-cost-of-react-native":{"label":"The Cost Of React Native","children":{}},"/playground/_radar/timeline/understanding-test-doubles-an-in-depth-look":{"label":"Understanding Test Doubles An In Depth Look","children":{}},"/playground/_radar/timeline/unit-testing-best-practices-in-golang":{"label":"Unit Testing Best Practices In Golang","children":{}},"/playground/_radar/timeline/urbox-backend-api":{"label":"Urbox Backend Api","children":{}},"/playground/_radar/timeline/use-monorepos-to-build-v3-of-react-sdk-for-searchio":{"label":"Use Monorepos To Build V3 Of React Sdk For Searchio","children":{}},"/playground/_radar/timeline/use-monorepos-to-resolve-the-problem-of-sharing-ui-components-in-aharoom":{"label":"Use Monorepos To Resolve The Problem Of Sharing Ui Components In Aharoom","children":{}},"/playground/_radar/timeline/use-nx-for-managing-basehq-frontend-monorepos":{"label":"Use Nx For Managing Basehq Frontend Monorepos","children":{}},"/playground/_radar/timeline/use-yup-to-validate-form-values-in-droppii":{"label":"Use Yup To Validate Form Values In Droppii","children":{}},"/playground/_radar/timeline/using-k6-in-setel":{"label":"Using K6 In Setel","children":{}},"/playground/_radar/timeline/vercel-switching-their-packages-from-yarn-to-pnpm-caught-our-attention":{"label":"Vercel Switching Their Packages From Yarn To Pnpm Caught Our Attention","children":{}},"/playground/_radar/timeline/vitejs-native-modules":{"label":"Vitejs Native Modules","children":{}},"/playground/_radar/timeline/what-is-pnpm":{"label":"What Is Pnpm","children":{}},"/playground/_radar/timeline/why-micro-frontend":{"label":"Why Micro Frontend","children":{}},"/playground/_radar/timeline/why-we-chose-our-tech-stack":{"label":"Why We Chose Our Tech Stack","children":{}},"/playground/_radar/timeline/workaround-with-openais-token-limit-with-langchain":{"label":"Workaround With Openais Token Limit With Langchain","children":{}},"/playground/_radar/timeline/working-with-langchain-document-loaders":{"label":"Working With Langchain Document Loaders","children":{}}}},"/playground/_radar/timescaledb":{"label":"Timescaledb","children":{}},"/playground/_radar/tla":{"label":"Tla","children":{}},"/playground/_radar/trunk-based-development":{"label":"Trunk Based Development","children":{}},"/playground/_radar/turborepo":{"label":"Turborepo","children":{}},"/playground/_radar/type-safe-client-server":{"label":"Type Safe Client Server","children":{}},"/playground/_radar/typescript":{"label":"Typescript","children":{}},"/playground/_radar/ui-documentation":{"label":"Ui Documentation","children":{}},"/playground/_radar/uno-css":{"label":"Uno Css","children":{}},"/playground/_radar/upptime":{"label":"Upptime","children":{}},"/playground/_radar/v-model":{"label":"V Model","children":{}},"/playground/_radar/vector-database":{"label":"Vector Database","children":{}},"/playground/_radar/vercel":{"label":"Vercel","children":{}},"/playground/_radar/vitejs":{"label":"Vitejs","children":{}},"/playground/_radar/volta":{"label":"Volta","children":{}},"/playground/_radar/wasm":{"label":"Wasm","children":{}},"/playground/_radar/webdriverio":{"label":"Webdriverio","children":{}},"/playground/_radar/webflow":{"label":"Webflow","children":{}},"/playground/_radar/yup":{"label":"Yup","children":{}},"/playground/_radar/zod":{"label":"Zod","children":{}},"/playground/_radar/zustand":{"label":"Zustand","children":{}}}},"/playground/ai":{"label":"Ai","children":{"/playground/ai/a-grand-unified-theory-of-the-ai-hype-cycle":{"label":"A Grand Unified Theory of the AI Hype Cycle","children":{}},"/playground/ai/adversarial-prompting":{"label":"Adversarial Prompting in Prompt Engineering","children":{}},"/playground/ai/build-your-chatbot-with-open-source-large-language-models":{"label":"Build your chatbot with open source Large Language Models","children":{}},"/playground/ai/building-llm-powered-tools-with-dify":{"label":"Streamlining Internal Tool Development with Managed LLMOps: A Dify Case Study","children":{}},"/playground/ai/building-llm-system":{"label":"Building Llm System","children":{"/playground/ai/building-llm-system/building-llm-system":{"label":"§ Building LLM system","children":{}},"/playground/ai/building-llm-system/evaluation-guideline-for-llm-application":{"label":"Evaluation guidelines for LLM applications","children":{}},"/playground/ai/building-llm-system/graphrag":{"label":"GraphRAG - Building a knowledge graph for RAG system","children":{}},"/playground/ai/building-llm-system/guardrails-in-llm":{"label":"Guardrails in llm","children":{}},"/playground/ai/building-llm-system/intent-classification-by-llm":{"label":"Intent classification by LLM","children":{}},"/playground/ai/building-llm-system/llm-as-a-judge":{"label":"LLM as a judge","children":{}},"/playground/ai/building-llm-system/logs-pillar":{"label":"Logging","children":{}},"/playground/ai/building-llm-system/metric-pillar":{"label":"Metrics","children":{}},"/playground/ai/building-llm-system/model-selection":{"label":"Model selection","children":{}},"/playground/ai/building-llm-system/multi-agent-collaboration-for-task-completion":{"label":"Multi-agent collaboration for task completion","children":{}},"/playground/ai/building-llm-system/multimodal-in-rag":{"label":"Multimodal in rag","children":{}},"/playground/ai/building-llm-system/observability-in-ai-platforms":{"label":"Observability in AI platforms","children":{}},"/playground/ai/building-llm-system/prevent-prompt-injection":{"label":"Prevent prompt injection","children":{}},"/playground/ai/building-llm-system/quantization-in-llm":{"label":"Quantization for large language models","children":{}},"/playground/ai/building-llm-system/react-in-llm":{"label":"ReAct(Reason + Act) in LLM","children":{}},"/playground/ai/building-llm-system/rewoo-in-llm":{"label":"ReWOO: Reasoning without observation - A deeper look","children":{}},"/playground/ai/building-llm-system/the-rise-of-ai-applications-with-llm":{"label":"The rise of AI applications with LLM","children":{}},"/playground/ai/building-llm-system/trace-pillar":{"label":"Tracing","children":{}},"/playground/ai/building-llm-system/use-cases-for-llm-applications":{"label":"Use cases for LLM applications","children":{}}}},"/playground/ai/caching-with-rag-system":{"label":"Evaluating caching in RAG systems","children":{}},"/playground/ai/chunking-strategies-to-overcome-context-limitation-in-llm":{"label":"Chunking strategies to overcome context limitation in LLM","children":{}},"/playground/ai/copilots":{"label":"Copilots","children":{"/playground/ai/copilots/projects-operations":{"label":"Project Operations Copilots","children":{}},"/playground/ai/copilots/team-copilots":{"label":"Team Copilots","children":{}}}},"/playground/ai/developing-rapidly-with-generative-ai":{"label":"Developing rapidly with Generative AI","children":{}},"/playground/ai/digest":{"label":"Digest","children":{"/playground/ai/digest/ai-digest-01":{"label":"AI digest #1 Aider reasoning, OpenAI Realtime API, Cline - pre Claude-dev ","children":{}},"/playground/ai/digest/ai-digest-02":{"label":"AI digest #2 New command Aider, OpenHands, Qwen2.5 Coder 32B, Predicted Output","children":{}}}},"/playground/ai/evaluate-chatbot-agent-by-simulated-user":{"label":"Evaluate Chatbot Agent by User Simulation","children":{}},"/playground/ai/foundation-model":{"label":"Foundation Models: The Latest Advancement in AI","children":{}},"/playground/ai/function-calling":{"label":"Function calling in AI agents","children":{}},"/playground/ai/generative-ui":{"label":"What is Generative UI?","children":{}},"/playground/ai/journey-of-thought-prompting":{"label":"Journey of Thought Prompting: Harnessing AI to Craft Better Prompts","children":{}},"/playground/ai/llm-query-caching":{"label":"Query Caching for Large Language Models","children":{}},"/playground/ai/llm-tracing-in-ai-system":{"label":"LLM tracing in AI system","children":{}},"/playground/ai/llms-accuracy-self-refinement":{"label":"LLM's Accuracy - Self Refinement","children":{}},"/playground/ai/model-context-protocol":{"label":"Intro to Model Context Protocol","children":{}},"/playground/ai/proximal-policy-optimization":{"label":"Proximal Policy Optimization","children":{}},"/playground/ai/raptor-llm-retrieval":{"label":"RAPTOR: Tree-based Retrieval for Language Models","children":{}},"/playground/ai/re-ranking-in-rag":{"label":"Re-ranking in RAG","children":{}},"/playground/ai/reinforcement-learning":{"label":"Introduction to Reinforcement Learning and Its Application with LLMs","children":{}},"/playground/ai/rlhf-with-open-assistant":{"label":"RLHF with Open Assistant","children":{}},"/playground/ai/securing-your-remote-mcp-servers":{"label":"Securing your remote MCP servers","children":{}},"/playground/ai/select-vector-database-for-llm":{"label":"Select Vector Database for LLM","children":{}},"/playground/ai/story-map-for-llms":{"label":"Story map for LLMs","children":{}},"/playground/ai/supervisor-ai-agents":{"label":"Building Agent Supervisors to Generate Insights","children":{}},"/playground/ai/text-to-mongodb":{"label":"Natural Language to Database Queries: Text-to-MongoDB","children":{}},"/playground/ai/thumbs-up-and-thumbs-down-pattern":{"label":"Thumbs up and Thumbs down pattern","children":{}},"/playground/ai/tool-level-security-for-remote-mcp-servers":{"label":"Tool-Level Security for Remote MCP Servers","children":{}},"/playground/ai/use-cases":{"label":"Use Cases","children":{"/playground/ai/use-cases/salesforce":{"label":"Salesforce use cases","children":{}},"/playground/ai/use-cases/yelp":{"label":"Yelp use cases","children":{}}}},"/playground/ai/workaround-with-openais-token-limit-with-langchain":{"label":"Workaround with OpenAI's token limit with Langchain","children":{}},"/playground/ai/working-with-langchain-document-loaders":{"label":"Working with langchain document loaders","children":{}}}},"/playground/blockchain":{"label":"Blockchain","children":{"/playground/blockchain/anchor-framework":{"label":"Anchor framework","children":{}},"/playground/blockchain/blockchain-bridge":{"label":"Blockchain Bridge","children":{}},"/playground/blockchain/cross-chain-transfers-implementing-a-token-swap-from-base-chain-to-bitcoin":{"label":"Implement a Token Swap from the Base chain to Bitcoin for cross-chain transactions","children":{}},"/playground/blockchain/foundational-topics":{"label":"Foundational Topics","children":{"/playground/blockchain/foundational-topics/blocks":{"label":"Blocks","children":{}},"/playground/blockchain/foundational-topics/distributed-systems":{"label":"Distributed systems","children":{}},"/playground/blockchain/foundational-topics/pos":{"label":"PoS","children":{}},"/playground/blockchain/foundational-topics/smart-contract":{"label":"Smart Contract","children":{}},"/playground/blockchain/foundational-topics/topics":{"label":"Topics","children":{}},"/playground/blockchain/foundational-topics/zero-knowledge-proofs":{"label":"Zero-knowledge Proofs","children":{}}}},"/playground/blockchain/how-tokens-work-on-solana":{"label":"How Tokens Work on Solana","children":{}},"/playground/blockchain/introduce-to-solana-token-2022-new-standard-to-create-a-token-in-solana":{"label":"Introduce to Solana Token 2022 - new standard to create a token in solana","children":{}},"/playground/blockchain/layer-2":{"label":"Layer 2: Scaling Solutions for Ethereum","children":{}},"/playground/blockchain/liquidity-pool":{"label":"Liquidity pool","children":{}},"/playground/blockchain/metaplex-nft-compression":{"label":"Metaplex NFT Compression","children":{}},"/playground/blockchain/multisign-wallet":{"label":"Multisign wallet","children":{}},"/playground/blockchain/nft-fractionalization":{"label":"NFT Fractionalization","children":{}},"/playground/blockchain/plonky2":{"label":"Plonky2","children":{}},"/playground/blockchain/polygon-zkevm-architecture":{"label":"Polygon zkEVM architecture","children":{}},"/playground/blockchain/solana-account":{"label":"Solana Account","children":{}},"/playground/blockchain/solana-core-concept":{"label":"Solana core concepts","children":{}},"/playground/blockchain/starknet-architecture":{"label":"StarkNet architecture","children":{}},"/playground/blockchain/ton_blockchain_of_blockchains":{"label":"Ton: Blockchain of blockchains","children":{}},"/playground/blockchain/ton_core_concept":{"label":"Ton's base concepts","children":{}},"/playground/blockchain/zk-snarks":{"label":"zk-SNARKs","children":{}}}},"/playground/devbox":{"label":"Devbox","children":{"/playground/devbox/devbox":{"label":"§ Devbox","children":{}},"/playground/devbox/guide":{"label":"Guide","children":{"/playground/devbox/guide/containerless":{"label":"Ditch the Containers: Go Containerless with Devbox","children":{}},"/playground/devbox/guide/devboxjson":{"label":"Devbox.json: Your Project's DNA","children":{}},"/playground/devbox/guide/run-your-own-shell":{"label":"Devbox Shell: Your Dev Environment, Your Rules","children":{}}}},"/playground/devbox/introduction":{"label":"Introduction","children":{"/playground/devbox/introduction/the-reason-for-being":{"label":"The reason for being","children":{}},"/playground/devbox/introduction/why-devbox-but-not-nix":{"label":"Devbox vs Nix: Why We Chose Simplicity","children":{}}}},"/playground/devbox/research":{"label":"Research","children":{"/playground/devbox/research/content-addressable-storage-in-docker":{"label":"Devbox vs Nix: Why We Chose Simplicity","children":{}},"/playground/devbox/research/fixed-output-derivation":{"label":"Fixed-output Derivation in Nix","children":{}},"/playground/devbox/research/nix-is-faster-than-docker-build":{"label":"Nix is Faster Than Docker Build","children":{}},"/playground/devbox/research/pinning-nixpkgs":{"label":"Pinning nixpkgs in Nix","children":{}},"/playground/devbox/research/shadow-copies":{"label":"Shadow Copies in Docker Builds","children":{}},"/playground/devbox/research/unstable-package-installation":{"label":"Unstable Package Installation in Docker","children":{}}}},"/playground/devbox/story":{"label":"Story","children":{"/playground/devbox/story/devbox-a-world-before-docker":{"label":"The world before Docker","children":{}},"/playground/devbox/story/devbox-docker-adoption-and-challenges":{"label":"Our Docker adoption and its challenges","children":{}},"/playground/devbox/story/devbox-local-development-env":{"label":"Using Devbox to setup local development environment","children":{}},"/playground/devbox/story/devbox-nix-and-our-devbox-adoption":{"label":"The overview into Nix & how we use Devbox @ Dwarves","children":{}},"/playground/devbox/story/devbox-production-success-story":{"label":"Devbox in Production: Our Success Story","children":{}}}}}},"/playground/frontend":{"label":"Frontend","children":{"/playground/frontend/a-fragment-colocation-pattern-with-react-apollo-graphql":{"label":"A Fragment Colocation Pattern with React & Apollo GraphQL","children":{}},"/playground/frontend/an-introduction-to-atomic-css":{"label":"An Introduction to Atomic CSS","children":{}},"/playground/frontend/applying-mock-service-worker-msw-for-seamless-web-development":{"label":"Applying Mock Service Worker (MSW) for Seamless Web Development","children":{}},"/playground/frontend/atomic-design-pattern":{"label":"Atomic Design Pattern","children":{}},"/playground/frontend/build-polymorphic-react-components-with-typescript":{"label":"Build polymorphic React components with Typescript","children":{}},"/playground/frontend/continuous-translation":{"label":"Continuous Translation","children":{}},"/playground/frontend/css-container-queries":{"label":"CSS Container Queries","children":{}},"/playground/frontend/css-in-js":{"label":"CSS in JS","children":{}},"/playground/frontend/dark-mode-flickers-a-white-background-for-a-fraction-of-a-second":{"label":"Dark mode flickers a white background for a fraction of a second","children":{}},"/playground/frontend/focus-trap":{"label":"Focus trap","children":{}},"/playground/frontend/from-markup-to-pixels-a-look-inside-the-dom-cssom-and-render-tree":{"label":"From Markup to Pixels - A look inside the DOM, CSSOM, and Render Tree","children":{}},"/playground/frontend/hsl-color":{"label":"HSL Color","children":{}},"/playground/frontend/html-inert":{"label":"HTML inert","children":{}},"/playground/frontend/intro-to-indexeddb":{"label":"Intro to IndexedDB","children":{}},"/playground/frontend/javascript-modules":{"label":"JavaScript modules","children":{}},"/playground/frontend/micro-frontends-microservices-for-frontend-development":{"label":"Micro Frontends Microservices For Frontend Development","children":{}},"/playground/frontend/mitigate-blocking-the-main-thread":{"label":"Mitigate blocking the main thread","children":{}},"/playground/frontend/mixpanel":{"label":"Mixpanel","children":{}},"/playground/frontend/mpa-spa-and-partial-hydration":{"label":"MPA, SPA and Partial Hydration","children":{}},"/playground/frontend/parallelism-in-javascript":{"label":"Parallelism in JavaScript","children":{}},"/playground/frontend/parse-dont-validate-in-typescript":{"label":"Parse, don't validate in TypeScript","children":{}},"/playground/frontend/preserving-and-resetting-state-in-react":{"label":"Preserving and Resetting state in React","children":{}},"/playground/frontend/prevent-layout-thrashing":{"label":"Prevent Layout Thrashing","children":{}},"/playground/frontend/pure-css-parallax":{"label":"Pure CSS Parallax","children":{}},"/playground/frontend/react":{"label":"React","children":{"/playground/frontend/react/code-splitting":{"label":"Code splitting in React","children":{}},"/playground/frontend/react/component-composition-patterns":{"label":"Component composition patterns in React","children":{}},"/playground/frontend/react/design-system-integration":{"label":"Design system integration in react","children":{}},"/playground/frontend/react/hook-architecture":{"label":"Hook architecture in react","children":{}},"/playground/frontend/react/rendering-strategies":{"label":"Rendering strategies in React","children":{}},"/playground/frontend/react/state-management-strategy":{"label":"State management strategy in React","children":{}},"/playground/frontend/react/testing-strategies":{"label":"Testing strategies in React","children":{}}}},"/playground/frontend/react-18":{"label":"React 18","children":{}},"/playground/frontend/react-server-component":{"label":"React Server Components, NextJs Route and Data Fetching","children":{}},"/playground/frontend/remix-versus-nextjs":{"label":"Remix Versus Nextjs","children":{}},"/playground/frontend/remove-unused-css-styles-from-bootstrap-using-purgecss":{"label":"Remove Unused CSS Styles From Bootstrap Using Purgecss","children":{}},"/playground/frontend/render-optimization-in-data-fetching-libraries":{"label":"Render optimization in data-fetching libraries","children":{}},"/playground/frontend/report":{"label":"Report","children":{"/playground/frontend/report/frontend-report-august-2024":{"label":"Frontend Report August 2024","children":{}},"/playground/frontend/report/frontend-report-february-2025":{"label":"Frontend Report February 2025","children":{}},"/playground/frontend/report/frontend-report-first-half-of-november-2024":{"label":"Frontend Report First Half of November 2024","children":{}},"/playground/frontend/report/frontend-report-january-2025":{"label":"Frontend Report January 2025","children":{}},"/playground/frontend/report/frontend-report-july-2024":{"label":"Frontend Report July 2024","children":{}},"/playground/frontend/report/frontend-report-march-2025":{"label":"Frontend Report March 2025","children":{}},"/playground/frontend/report/frontend-report-october-2024":{"label":"Frontend Report October 2024","children":{}},"/playground/frontend/report/frontend-report-second-half-of-november-2024":{"label":"Frontend Report Second Half of November 2024","children":{}},"/playground/frontend/report/frontend-report-september-2024":{"label":"Frontend Report September 2024","children":{}}}},"/playground/frontend/retain-scroll-position-in-infinite-scroll":{"label":"Retain scroll position in infinite scroll","children":{}},"/playground/frontend/scroll-driven-animations":{"label":"Scroll-driven animations","children":{}},"/playground/frontend/shadow-dom":{"label":"Shadow DOM","children":{}},"/playground/frontend/singleton-design-pattern-in-javascript":{"label":"Singleton Design Pattern in Javascript","children":{}},"/playground/frontend/tackling-server-state-complexity-in-frontend-development":{"label":"Tackling Server State complexity in Frontend Development","children":{}},"/playground/frontend/the-fundamental-of-web-performance":{"label":"The fundamental of web performance","children":{}},"/playground/frontend/threejs":{"label":"Threejs","children":{"/playground/frontend/threejs/cameras-in-threejs":{"label":"Cameras in ThreeJS","children":{}}}},"/playground/frontend/url-formats-for-sharing-via-social-networks":{"label":"URL formats for sharing via social networks","children":{}},"/playground/frontend/useeffect-double-calls-in-react-18":{"label":"useEffect double calls in React 18","children":{}},"/playground/frontend/using-correct-html-element-to-increase-website-accessibility":{"label":"Using Correct Html Element To Increase Website Accessibility","children":{}},"/playground/frontend/validation-with-zod":{"label":"Validation with Zod","children":{}},"/playground/frontend/variable-fonts":{"label":"Variable Fonts","children":{}},"/playground/frontend/vitejs-native-modules":{"label":"ViteJS native modules","children":{}},"/playground/frontend/wai-aria":{"label":"WAI-ARIA","children":{}},"/playground/frontend/webassembly":{"label":"Webassembly","children":{}},"/playground/frontend/websockets":{"label":"WebSockets","children":{}},"/playground/frontend/what-is-pnpm-compare-to-npmyarn":{"label":"What is PNPM Compare To NPM/Yarn","children":{}},"/playground/frontend/when-should-we-use-usereducer-instead-of-usestate":{"label":"When should we use useReducer instead of useState?","children":{}},"/playground/frontend/why-dom-manipulation-is-slow":{"label":"Why DOM manipulation is slow?","children":{}},"/playground/frontend/why-micro-frontend":{"label":"Why Micro Frontend","children":{}},"/playground/frontend/why-virtual-dom-is-fast":{"label":"Why Virtual DOM is fast?","children":{}},"/playground/frontend/why-we-chose-our-tech-stack-accelerating-development-with-a-robust-frontend-solution":{"label":"Why We Chose Our Tech Stack Accelerating Development With A Robust Frontend Solution","children":{}},"/playground/frontend/window-and-iframe-communication":{"label":"Window and iframe communication","children":{}},"/playground/frontend/zaplib-post-mortem":{"label":"Zaplib post-mortem","children":{}}}},"/playground/go":{"label":"Go","children":{"/playground/go/approaches-to-manage-concurrent-workloads-like-worker-pools-and-pipelines":{"label":"Approaches To Manage Concurrent Workloads Like Worker Pools And Pipelines","children":{}},"/playground/go/compute-union-2-finite-automata":{"label":"Efficient Union of Finite Automata in Golang: A Practical Approach","children":{}},"/playground/go/connecting-vim-with-golang":{"label":"Connecting Vim With Golang","children":{}},"/playground/go/extension-interface-pattern":{"label":"Go extension interface pattern","children":{}},"/playground/go/go-concurrency":{"label":"Go Concurrency","children":{}},"/playground/go/go-for-enterprise":{"label":"Go For Enterprise","children":{"/playground/go/go-for-enterprise/enterprise-standard-language":{"label":"Go as an Enterprise Standard Language","children":{}},"/playground/go/go-for-enterprise/how-to-use-go-in-enterprise":{"label":"How to use Go in the Enterprise","children":{}},"/playground/go/go-for-enterprise/when-to-use-golang-in-enterprise":{"label":"When to use Go in the Enterprise","children":{}},"/playground/go/go-for-enterprise/who-using-golang-in-enterprise":{"label":"Who is using Go in enterprise?","children":{}},"/playground/go/go-for-enterprise/why-enterprise-chose-java":{"label":"Why Enterprise Chose Java","children":{}},"/playground/go/go-for-enterprise/why-go":{"label":"Why Go?","children":{}}}},"/playground/go/go-generics-type-safety":{"label":"How does Go achieve type safety when it enables generics?","children":{}},"/playground/go/go-import":{"label":"Go import design: using git repo path","children":{}},"/playground/go/go-in-software-engineering":{"label":"Go In Software Engineering","children":{}},"/playground/go/go-package":{"label":"Package first design","children":{}},"/playground/go/message-queues-and-streaming-platforms-eg-kafka-nats-rabbitmq":{"label":"Message Queues And Streaming Platforms Eg Kafka Nats Rabbitmq","children":{}},"/playground/go/profiling-in-go":{"label":"Profiling in Go","children":{}},"/playground/go/slice-and-array-in-golang":{"label":"Slice And Array In Golang","children":{}},"/playground/go/unit-testing-best-practices-in-golang":{"label":"Unit Testing Best Practices In Golang","children":{}},"/playground/go/use-go-selenium-to-crawl-data":{"label":"Use Go Selenium To Crawl Data","children":{}},"/playground/go/weekly":{"label":"Weekly","children":{"/playground/go/weekly/aug-02":{"label":"Go Commentary #5: Features, Memory Optimization, Minecraft Server, Code Editor, and LLM Tool","children":{}},"/playground/go/weekly/aug-09":{"label":"Go Commentary #6: GUI Framework, Leadership Change","children":{}},"/playground/go/weekly/aug-16":{"label":"Go Commentary #7: Releases, Websockets, and Struct Behavior","children":{}},"/playground/go/weekly/aug-23":{"label":"Go Commentary #8: Jupyter Notebooks, Kubernetes Tools, GopherCon Talks","children":{}},"/playground/go/weekly/aug-30":{"label":"Go Commentary #9: TinyGo, SQLite Vector Search, and Authorization","children":{}},"/playground/go/weekly/dec-06":{"label":"Go Commentary #23: Draft Release Notes for Go 1.24 and weak pointers in Go","children":{}},"/playground/go/weekly/dec-13":{"label":"Go Commentary #24: Coming in Go 1.24: testing/synctest experiment for time and concurrency testing","children":{}},"/playground/go/weekly/jul-05":{"label":"Go Weekly #2: Go 1.23 Iterators","children":{}},"/playground/go/weekly/jul-12":{"label":"Go Commentary #3: Generic Collections, Generics Constraints, AI Bot","children":{}},"/playground/go/weekly/jul-26":{"label":"Go Commentary #4: Ethical Hacking, HTTP Requests, Mac App Development","children":{}},"/playground/go/weekly/june-27":{"label":"Go Weekly #1: Mastering Go Performance - eBPF and PGO Optimization Techniques","children":{}},"/playground/go/weekly/nov-01":{"label":"Go Commentary #18: Fuzz Testing Go HTTP Services","children":{}},"/playground/go/weekly/nov-08":{"label":"Go Commentary #19: Writing secure Go code","children":{}},"/playground/go/weekly/nov-15":{"label":"Go Commentary #20: Go Turns 15","children":{}},"/playground/go/weekly/nov-22":{"label":"Go Commentary #21: Go sync.Once is Simple","children":{}},"/playground/go/weekly/nov-29":{"label":"Go Commentary #22: GoMLX: ML in Go without Python","children":{}},"/playground/go/weekly/oct-04":{"label":"Go Commentary #14: Golang compile-time evaluation and Go bindings to SQLite using wazero","children":{}},"/playground/go/weekly/oct-11":{"label":"Go Commentary #15: Using Go embed, and Reflect","children":{}},"/playground/go/weekly/oct-18":{"label":"Go Commentary #16: Understand sync.Map","children":{}},"/playground/go/weekly/oct-25":{"label":"Go Commentary #17: Leveraging benchstat Projects in Go benchmark and Go Plan9 memo on 450% speeding up calculations","children":{}},"/playground/go/weekly/sep-06":{"label":"Go Commentary #10: Script, Telemetry","children":{}},"/playground/go/weekly/sep-13":{"label":"Go Commentary #11: The Gopher's LLM Revolution - Actors, Frameworks, and the Future of Go","children":{}},"/playground/go/weekly/sep-20":{"label":"Go Commentary #12: CLI Renaissance with Kubernetes, REST, and Terminal Readers in the Age of Complexity","children":{}},"/playground/go/weekly/sep-27":{"label":"Go Commentary #13: Compiler Quests and Vector Vexations","children":{}}}}}},"/playground/market-report":{"label":"Market Report","children":{"/playground/market-report/2023-december":{"label":"Market report December 2023","children":{}},"/playground/market-report/2024-april":{"label":"Market report April 2024","children":{}},"/playground/market-report/2024-august":{"label":"Market report August 2024","children":{}},"/playground/market-report/2024-february":{"label":"Market report February 2024","children":{}},"/playground/market-report/2024-january":{"label":"Market report January 2024","children":{}},"/playground/market-report/2024-july":{"label":"Market report July 2024","children":{}},"/playground/market-report/2024-march":{"label":"Market report March 2024","children":{}},"/playground/market-report/2024-may":{"label":"Market report may 2024","children":{}},"/playground/market-report/2024-october":{"label":"Market report October 2024","children":{}},"/playground/market-report/2024-september":{"label":"Market report September 2024","children":{}}}},"/playground/use-cases":{"label":"Use Cases","children":{"/playground/use-cases/ai-interview-platform-mvp":{"label":"Building MVP for AI-driven interview platform","children":{}},"/playground/use-cases/ai-powered-monthly-project-reports":{"label":"Project reports system: a case study","children":{}},"/playground/use-cases/ai-ruby-travel-assistant-chatbot":{"label":"AI-powered Ruby travel assistant","children":{}},"/playground/use-cases/binance-transfer-matching":{"label":"Building better Binance transfer tracking","children":{}},"/playground/use-cases/bitcoin-alt-performance-tracking":{"label":"Tracking Bitcoin-Altcoin Performance Indicators in BTC Hedging Strategy","children":{}},"/playground/use-cases/building-chatbot-agent-for-project-management-tool":{"label":"Building chatbot agent to streamline project management","children":{}},"/playground/use-cases/building-data-pipeline-ogif-transcriber":{"label":"Building data pipeline for OGIF transcriber","children":{}},"/playground/use-cases/centralized-monitoring-setup-for-trading-platform":{"label":"Setup centralized monitoring system for Hedge Foundation trading platform","children":{}},"/playground/use-cases/create-slides-with-overleaf":{"label":"Create slides with Overleaf and ChatGPT","children":{}},"/playground/use-cases/crypto-market-outperform-chart-rendering":{"label":"Visualizing crypto market performance: BTC-Alt dynamic indicators in Golang","children":{}},"/playground/use-cases/data-archive-and-recovery":{"label":"Building a data archive and recovery strategy for high-volume trading system","children":{}},"/playground/use-cases/database-hardening-for-trading-platform":{"label":"Database hardening for a trading platform","children":{}},"/playground/use-cases/enhancing-cryptocurrency-transfer-logger":{"label":"Transfer mapping: enhancing loggers for better transparency","children":{}},"/playground/use-cases/implement-binance-future-pnl-analysis-page":{"label":"Implement Binance Futures PNL analysis page by Phoenix LiveView","children":{}},"/playground/use-cases/migrate-normal-table-to-timescale-table":{"label":"Migrate regular tables into TimescaleDB hypertables to improve query performance","children":{}},"/playground/use-cases/optimize-init-load-time-for-trading-platform":{"label":"Optimizing initial load time for a Trading Platform","children":{}},"/playground/use-cases/optimizing-ui-for-effective-investment-experience":{"label":"Hedge Foundation - Optimizing UI for effective investment experience","children":{}},"/playground/use-cases/persist-history-using-data-snapshot-pattern":{"label":"Implementing data snapshot pattern to persist historical data","children":{}},"/playground/use-cases/reconstructing_trading_pnl_data_pipeline_approach":{"label":"Reconstructing historical trading PnL: a data pipeline approach","children":{}}}}}},"/site-index":{"label":"Dwarves Index","children":{}},"/updates":{"label":"Updates","children":{"/updates/changelog":{"label":"Changelog","children":{"/updates/changelog/2018-in-review":{"label":"2018 In Review","children":{}},"/updates/changelog/2019-in-review":{"label":"2019 In Review","children":{}},"/updates/changelog/2020-in-review":{"label":"2020 In Review","children":{}},"/updates/changelog/2021-dwarves-of-the-year":{"label":"Dwarves Of The Year 2021","children":{}},"/updates/changelog/2021-in-review":{"label":"2021 In Review","children":{}},"/updates/changelog/2021-whats-new-december":{"label":"What's New in December 2021","children":{}},"/updates/changelog/2021-whats-new-july":{"label":"What's New in July 2021","children":{}},"/updates/changelog/2022-dwarves-of-the-year":{"label":"Dwarves Of The Year 2022","children":{}},"/updates/changelog/2022-in-review":{"label":"2022 In Review","children":{}},"/updates/changelog/2022-summit-engineering-a-good-time":{"label":"Summit 2022: Engineering A Good Time","children":{}},"/updates/changelog/2022-whats-new-january":{"label":"What's New in January 2022","children":{}},"/updates/changelog/2022-whats-new-may":{"label":"What's New in May 2022","children":{}},"/updates/changelog/2023-happy":{"label":"Happy 2023","children":{}},"/updates/changelog/2023-whats-new-december":{"label":"What's New in December 2023","children":{}},"/updates/changelog/2023-whats-new-november":{"label":"What's New in November 2023","children":{}},"/updates/changelog/2023-whats-new-october":{"label":"What's New in October 2023","children":{}},"/updates/changelog/2024-community-meet-up":{"label":"Dwarves’ 2nd community offline meet-up","children":{}},"/updates/changelog/2024-in-review":{"label":"2024 In Review","children":{}},"/updates/changelog/2024-navigating-changes":{"label":"Navigating changes","children":{}},"/updates/changelog/2024-semi-annual-review":{"label":"State of Dwarves: 2024 Semi-annual Review","children":{}},"/updates/changelog/2024-summit-building-bonds-our-way":{"label":"Summit 2024: Building bonds our way","children":{}},"/updates/changelog/2024-whats-new-april":{"label":"What's New in April 2024","children":{}},"/updates/changelog/2024-whats-new-august":{"label":"What's New in August 2024","children":{}},"/updates/changelog/2024-whats-new-december":{"label":"What's New in December 2024","children":{}},"/updates/changelog/2024-whats-new-february":{"label":"What's New in February 2024","children":{}},"/updates/changelog/2024-whats-new-january":{"label":"What's New in January 2024","children":{}},"/updates/changelog/2024-whats-new-july":{"label":"What's New in July 2024","children":{}},"/updates/changelog/2024-whats-new-june":{"label":"What's New in June 2024","children":{}},"/updates/changelog/2024-whats-new-march":{"label":"What's New in March 2024","children":{}},"/updates/changelog/2024-whats-new-may":{"label":"What's New in May 2024","children":{}},"/updates/changelog/2024-whats-new-november":{"label":"What's New in November 2024","children":{}},"/updates/changelog/2024-whats-new-oct":{"label":"What's New in October 2024","children":{}},"/updates/changelog/2024-whats-new-september":{"label":"What's New in September 2024","children":{}},"/updates/changelog/2025-whats-new-february":{"label":"What's New in February 2025","children":{}},"/updates/changelog/road-to-100":{"label":"Road To 100","children":{}}}},"/updates/culture-test":{"label":"Culture Test","children":{}},"/updates/digest":{"label":"Digest","children":{"/updates/digest/1-what-do-you-stand-for":{"label":"Weekly Digest #1: What do you stand for?","children":{}},"/updates/digest/10-from-lean-to-learner":{"label":"Weekly Digest #10: From lean to learner","children":{}},"/updates/digest/11-come-grow-with-us":{"label":"Weekly Digest #11: Come grow with us","children":{}},"/updates/digest/12-summer-moments":{"label":"Weekly Digest #12: Summer moments - Our team's remote work adventures","children":{}},"/updates/digest/13-more-than-lines-of-code":{"label":"Weekly Digest #13: More than lines of code","children":{}},"/updates/digest/14-back-to-the-office":{"label":"Weekly Digest #14: Embracing hybrid work - the best of both worlds","children":{}},"/updates/digest/15-new-year-gathering":{"label":"Weekly Digest #15: New year Gathering: Sharing Tết, starting strong","children":{}},"/updates/digest/2-walk-around-learn-around":{"label":"Weekly Digest #2: Walk around learn around","children":{}},"/updates/digest/3-we-all-start-somewhere":{"label":"Weekly Digest #3: We all start somewhere","children":{}},"/updates/digest/4-finding-your-authentic-tribe":{"label":"Weekly Digest #4: Finding your authentic tribe","children":{}},"/updates/digest/5-delay-the-gratification":{"label":"Weekly Digest #5: Endure the hardship, delay the gratification","children":{}},"/updates/digest/6-stay-for-the-culture":{"label":"Weekly Digest #6: Come for the conversation, stay for the culture","children":{}},"/updates/digest/7-a-journey-through-time":{"label":"Weekly Digest #7: A journey through time","children":{}},"/updates/digest/8-then-came-the-last-days-of-may":{"label":"Weekly Digest #8: Then came the last days of May","children":{}},"/updates/digest/9-a-little-more-speed-for-summer":{"label":"Weekly Digest #9: A little more speed for summer","children":{}}}},"/updates/forward-engineering":{"label":"Forward Engineering","children":{"/updates/forward-engineering/2022":{"label":"Forward Engineering 2022","children":{}},"/updates/forward-engineering/2023-august":{"label":"Forward Engineering August 2023","children":{}},"/updates/forward-engineering/2023-december":{"label":"Forward Engineering December 2023","children":{}},"/updates/forward-engineering/2023-june":{"label":"Forward Engineering June 2023","children":{}},"/updates/forward-engineering/2023-march":{"label":"Forward Engineering March 2023","children":{}},"/updates/forward-engineering/2023-may":{"label":"Forward Engineering May 2023","children":{}},"/updates/forward-engineering/2023-november":{"label":"Forward Engineering November 2023","children":{}},"/updates/forward-engineering/2023-october":{"label":"Forward Engineering October 2023","children":{}},"/updates/forward-engineering/2024-2025":{"label":"Forward Engineering 2024 - 2025","children":{}},"/updates/forward-engineering/2024-quarter-3":{"label":"Forward Engineering Quarter 3, 2024","children":{}},"/updates/forward-engineering/tech-radar-the-introduction":{"label":"Dwarves Tech Radar: The Introduction","children":{}},"/updates/forward-engineering/tech-radar-volume-01":{"label":"Dwarves Tech Radar Volume 01","children":{}},"/updates/forward-engineering/tech-radar-volume-02":{"label":"Dwarves Tech Radar Volume 02","children":{}},"/updates/forward-engineering/tech-radar-volume-03":{"label":"Dwarves Tech Radar Volume 03","children":{}}}},"/updates/fund":{"label":"Fund","children":{"/updates/fund/dwarves-ventures-fund-0":{"label":"Dwarves Ventures Fund 0","children":{}},"/updates/fund/dwarves-ventures-fund-1":{"label":"Dwarves Ventures Fund 1","children":{}}}},"/updates/newsletter":{"label":"Newsletter","children":{"/updates/newsletter/2021-in-review":{"label":"It's a wrap: 2021 in Review","children":{}},"/updates/newsletter/blockchain-and-data":{"label":"The future is blockchain and data","children":{}},"/updates/newsletter/dalat-office":{"label":"Da Lat Office","children":{}},"/updates/newsletter/dwarve-updates-ai-llm":{"label":"The Stage of AI and LLM at Dwarves","children":{}},"/updates/newsletter/dwarves-updates":{"label":"Dwarves Updates","children":{}},"/updates/newsletter/engineer-performance-review":{"label":"Engineer Performance Review","children":{}},"/updates/newsletter/engineering-org-structure":{"label":"Engineering Organizational Structure","children":{}},"/updates/newsletter/growth-stages":{"label":"The Stage of Growth at Dwarves","children":{}},"/updates/newsletter/hiring-stages":{"label":"The stages of hiring at Dwarves","children":{}},"/updates/newsletter/knowledge-base":{"label":"Build your knowledge base","children":{}},"/updates/newsletter/path-to-growth":{"label":"The Path To Growth at Dwarves","children":{}},"/updates/newsletter/project-compliance":{"label":"Project Compliance","children":{}},"/updates/newsletter/the-next-leading-chairs":{"label":"The Next Leading Chairs","children":{}}}},"/updates/ogif":{"label":"Ogif","children":{"/updates/ogif/1-20240405":{"label":"OGIF Office Hours #1: Markdown Presentations, Research Content Pipeline, and Professional Screenshots","children":{}},"/updates/ogif/10-20240614":{"label":"OGIF Office Hours #10 -  Behavioral Patterns and Map Content Organization","children":{}},"/updates/ogif/11-20240621":{"label":"OGIF Office Hours #11 - Design patterns: template method & visitor, Radix sort, and weekly tech commentary","children":{}},"/updates/ogif/12-20240628":{"label":"OGIF Office Hours #12 - Community June updates, Project progress, Go Weekly: Mastering Go Performance - eBPF and PGO Optimization Techniques, Multimodal in RAG (Retrieval Augmented Generation)","children":{}},"/updates/ogif/13-20240705":{"label":"OGIF Office Hours #13 - Go Weekly updates, Radix Sort, Human Feedback Mechanism, and effective ChatGPT usage","children":{}},"/updates/ogif/14-20240712":{"label":"OGIF Office Hours #14 - Generic Collections, Pricing Models, and OGIF Summarizer","children":{}},"/updates/ogif/15-20240719":{"label":"OGIF Office Hours #15 - Architecting AI supervisors, Local-first software, AI code completion overview and crawl list bot command","children":{}},"/updates/ogif/16-20240726":{"label":"OGIF Office Hours #16 - Golang weekly #4, TIL in Dune's query, AI voice clone demo and Re-ranking in RAG system.","children":{}},"/updates/ogif/17-20240802":{"label":"OGIF Office Hours #17 - Community Call July, C4 Model, and Interview Life in the US","children":{}},"/updates/ogif/18-20240809":{"label":"OGIF Office Hours #18 - Golang weekly, Devbox MOC, Search retrieval in RAG, Generative UI, FE monthly #1","children":{}},"/updates/ogif/19-20240821":{"label":"OGIF Office Hours #19 - Golang weekly, Designing for forgiveness, File sharing system design, Dify AI demo","children":{}},"/updates/ogif/2-20240412":{"label":"OGIF Office Hours #2: Devbox as the new Docker, Security Standards, and Understanding Liquidity","children":{}},"/updates/ogif/20-20240823":{"label":"OGIF Office Hours #20 - Golang weekly, Modeling dynamic object properties, Devbox demo, LLM tracing, Cursor AI editor","children":{}},"/updates/ogif/21-20240830":{"label":"OGIF Office Hours #21 - Community engagement, Go weekly, Journey of thought for prompt engineering","children":{}},"/updates/ogif/22-20240906":{"label":"OGIF Office Hours #22 - Hybrid working, Tech market report, Go commentary weekly, AI demo for Go weekly content production.","children":{}},"/updates/ogif/23-20240913":{"label":"OGIF Office Hours #23 - Go weekly, Frontend report, Hybrid working support, and AI mixture agent","children":{}},"/updates/ogif/24-20240920":{"label":"OGIF Office Hours #24 - Go weekly, AI-Driven Workflows, Holistic Team AI Demo, and Figma to UI Component with Claude","children":{}},"/updates/ogif/25-20240927":{"label":"OGIF Office Hours #25 - Team & Community updates, Hybrid culture, Product design commentary, AI Tooling Insights, Golang weekly","children":{}},"/updates/ogif/26-20241004":{"label":"OGIF Office Hours #26 - Product Design Commentary, Go Weekly, Trading App Case Study, Chatbot Evaluations, and Announcement for Essay Assignments","children":{}},"/updates/ogif/27-20241011":{"label":"OGIF Office Hours #27 - Go Weekly, Frontend Report Sep, UX Guide to Prompt with AI, Computing the Union of Two Finite Automata","children":{}},"/updates/ogif/28-20241018":{"label":"OGIF Office Hours #28 - Golang sync.Map, Generative AI UX design patterns, Yelp's AI use cases, Design patterns in LLM application, and Dify github analyzer","children":{}},"/updates/ogif/3-20240419":{"label":"OGIF Office Hours #3 - Generative AI, Tokenomics, and Finance Talks","children":{}},"/updates/ogif/4-20240426":{"label":"OGIF Office Hours #4 - DCA, Devbox","children":{}},"/updates/ogif/41-20250314":{"label":"OGIF Office Hours #41 - ICY-BTC Swap, GitHub Bot, MCP-DB, Pocket Turing, Recapable, and Arbitrage Strategy","children":{}},"/updates/ogif/5-20240503":{"label":"OGIF Office Hours #5 - Singapore market report, C4 modelling, How we created Memo's nested sidebar","children":{}},"/updates/ogif/6-20240510":{"label":"OGIF Office Hours #6 - Looking at the Factory pattern, Erlang state machines, and the Trading Process","children":{}},"/updates/ogif/7-20240517":{"label":"OGIF Office Hours #7 - Echelon EXPO, Programming patterns, and Moonlighting","children":{}},"/updates/ogif/9-20240607":{"label":"OGIF Office Hours #9 -  What's next for June and Behavior Design Patterns","children":{}}}}}}}},"/tags":{"label":"Popular Tags","children":{"/tags/operations":{"label":"#operations","children":{},"count":74},"/tags/hiring":{"label":"#hiring","children":{},"count":59},"/tags/team":{"label":"#team","children":{},"count":47},"/tags/career":{"label":"#career","children":{},"count":43},"/tags/lifeatdwarves":{"label":"#lifeatdwarves","children":{},"count":1},"/tags/performance":{"label":"#performance","children":{},"count":36},"/tags/culture":{"label":"#culture","children":{},"count":9},"/tags/emplpoyee":{"label":"#emplpoyee","children":{},"count":1},"/tags/apprenticeship":{"label":"#apprenticeship","children":{},"count":4},"/tags/internship":{"label":"#internship","children":{},"count":4},"/tags/apprentice":{"label":"#apprentice","children":{},"count":1},"/tags/engineering":{"label":"#engineering","children":{},"count":64},"/tags/communications":{"label":"#communications","children":{},"count":3},"/tags/frontend":{"label":"#frontend","children":{},"count":65},"/tags/full-stack":{"label":"#full-stack","children":{},"count":1},"/tags/engineer":{"label":"#engineer","children":{},"count":2},"/tags/design":{"label":"#design","children":{},"count":31},"/tags/life-at-dwarves":{"label":"#life-at-dwarves","children":{},"count":8},"/tags/senior":{"label":"#senior","children":{},"count":1},"/tags/designer":{"label":"#designer","children":{},"count":1},"/tags/hybrid-working":{"label":"#hybrid-working","children":{},"count":3},"/tags/software":{"label":"#software","children":{},"count":10},"/tags/fullstack":{"label":"#fullstack","children":{},"count":2},"/tags/business-development":{"label":"#business-development","children":{},"count":1},"/tags/hospitality":{"label":"#hospitality","children":{},"count":1},"/tags/case-study":{"label":"#case-study","children":{},"count":28},"/tags/iot":{"label":"#iot","children":{},"count":1},"/tags/blockchain":{"label":"#blockchain","children":{},"count":48},"/tags/startup":{"label":"#startup","children":{},"count":9},"/tags/US":{"label":"#US","children":{},"count":4},"/tags/ride-hailing":{"label":"#ride-hailing","children":{},"count":1},"/tags/fintech":{"label":"#fintech","children":{},"count":16},"/tags/marketplace":{"label":"#marketplace","children":{},"count":2},"/tags/ecommerce":{"label":"#ecommerce","children":{},"count":2},"/tags/dropshipping":{"label":"#dropshipping","children":{},"count":1},"/tags/quant":{"label":"#quant","children":{},"count":1},"/tags/swap":{"label":"#swap","children":{},"count":2},"/tags/healthcare":{"label":"#healthcare","children":{},"count":1},"/tags/mobile":{"label":"#mobile","children":{},"count":1},"/tags/enterprise":{"label":"#enterprise","children":{},"count":10},"/tags/Australia":{"label":"#Australia","children":{},"count":1},"/tags/fnb":{"label":"#fnb","children":{},"count":2},"/tags/early-stage":{"label":"#early-stage","children":{},"count":3},"/tags/browser-extension":{"label":"#browser-extension","children":{},"count":2},"/tags/payment":{"label":"#payment","children":{},"count":1},"/tags/real-estate":{"label":"#real-estate","children":{},"count":1},"/tags/travel":{"label":"#travel","children":{},"count":1},"/tags/Vietnam":{"label":"#Vietnam","children":{},"count":1},"/tags/partnership":{"label":"#partnership","children":{},"count":1},"/tags/consulting":{"label":"#consulting","children":{},"count":22},"/tags/market-report":{"label":"#market-report","children":{},"count":34},"/tags/tech-report":{"label":"#tech-report","children":{},"count":15},"/tags/partners":{"label":"#partners","children":{},"count":1},"/tags/wala":{"label":"#wala","children":{},"count":3},"/tags/film":{"label":"#film","children":{},"count":1},"/tags/energy":{"label":"#energy","children":{},"count":1},"/tags/contribution":{"label":"#contribution","children":{},"count":1},"/tags/community":{"label":"#community","children":{},"count":39},"/tags/network":{"label":"#network","children":{},"count":2},"/tags/handbook":{"label":"#handbook","children":{},"count":41},"/tags/employee":{"label":"#employee","children":{},"count":2},"/tags/earn":{"label":"#earn","children":{},"count":1},"/tags/icy":{"label":"#icy","children":{},"count":7},"/tags/token":{"label":"#token","children":{},"count":2},"/tags/showcase":{"label":"#showcase","children":{},"count":1},"/tags/policies":{"label":"#policies","children":{},"count":1},"/tags/onboarding":{"label":"#onboarding","children":{},"count":1},"/tags/guide":{"label":"#guide","children":{},"count":10},"/tags/meeting":{"label":"#meeting","children":{},"count":4},"/tags/email":{"label":"#email","children":{},"count":22},"/tags/learning":{"label":"#learning","children":{},"count":2},"/tags/careers":{"label":"#careers","children":{},"count":2},"/tags/business":{"label":"#business","children":{},"count":10},"/tags/workflow":{"label":"#workflow","children":{},"count":4},"/tags/remote":{"label":"#remote","children":{},"count":12},"/tags/company":{"label":"#company","children":{},"count":1},"/tags/growth":{"label":"#growth","children":{},"count":2},"/tags/purpose":{"label":"#purpose","children":{},"count":2},"/tags/security":{"label":"#security","children":{},"count":9},"/tags/tooling":{"label":"#tooling","children":{},"count":9},"/tags/ventures":{"label":"#ventures","children":{},"count":3},"/tags/work":{"label":"#work","children":{},"count":17},"/tags/guidline":{"label":"#guidline","children":{},"count":1},"/tags/project":{"label":"#project","children":{},"count":16},"/tags/playbook":{"label":"#playbook","children":{},"count":3},"/tags/client":{"label":"#client","children":{},"count":6},"/tags/guideline":{"label":"#guideline","children":{},"count":15},"/tags/pm":{"label":"#pm","children":{},"count":4},"/tags/billbyhours":{"label":"#billbyhours","children":{},"count":1},"/tags/innovation":{"label":"#innovation","children":{},"count":2},"/tags/framework":{"label":"#framework","children":{},"count":6},"/tags/productivity":{"label":"#productivity","children":{},"count":7},"/tags/UX":{"label":"#UX","children":{},"count":2},"/tags/dwarves":{"label":"#dwarves","children":{},"count":21},"/tags/UX-UI":{"label":"#UX-UI","children":{},"count":11},"/tags/system design":{"label":"#system design","children":{},"count":1},"/tags/internal":{"label":"#internal","children":{},"count":10},"/tags/estimation":{"label":"#estimation","children":{},"count":1},"/tags/tips":{"label":"#tips","children":{},"count":10},"/tags/people":{"label":"#people","children":{},"count":25},"/tags/operation":{"label":"#operation","children":{},"count":7},"/tags/management":{"label":"#management","children":{},"count":4},"/tags/process":{"label":"#process","children":{},"count":9},"/tags/mbti":{"label":"#mbti","children":{},"count":6},"/tags/leadership":{"label":"#leadership","children":{},"count":4},"/tags/checklist":{"label":"#checklist","children":{},"count":17},"/tags/delivery":{"label":"#delivery","children":{},"count":2},"/tags/template":{"label":"#template","children":{},"count":20},"/tags/ESTJ":{"label":"#ESTJ","children":{},"count":1},"/tags/INTJ":{"label":"#INTJ","children":{},"count":1},"/tags/ISTJ":{"label":"#ISTJ","children":{},"count":1},"/tags/ISTP":{"label":"#ISTP","children":{},"count":1},"/tags/policy":{"label":"#policy","children":{},"count":1},"/tags/teamwork":{"label":"#teamwork","children":{},"count":2},"/tags/practice":{"label":"#practice","children":{},"count":6},"/tags/idea":{"label":"#idea","children":{},"count":1},"/tags/personalities":{"label":"#personalities","children":{},"count":1},"/tags/okr":{"label":"#okr","children":{},"count":1},"/tags/goal":{"label":"#goal","children":{},"count":2},"/tags/transparency":{"label":"#transparency","children":{},"count":1},"/tags/human-resource":{"label":"#human-resource","children":{},"count":1},"/tags/forward-proxy":{"label":"#forward-proxy","children":{},"count":1},"/tags/agile":{"label":"#agile","children":{},"count":6},"/tags/behavior-driven-development":{"label":"#behavior-driven-development","children":{},"count":1},"/tags/testing":{"label":"#testing","children":{},"count":4},"/tags/ubiquitous-language":{"label":"#ubiquitous-language","children":{},"count":1},"/tags/react":{"label":"#react","children":{},"count":14},"/tags/migrations":{"label":"#migrations","children":{},"count":1},"/tags/uilibraries":{"label":"#uilibraries","children":{},"count":1},"/tags/form":{"label":"#form","children":{},"count":1},"/tags/ux-ui":{"label":"#ux-ui","children":{},"count":2},"/tags/backend":{"label":"#backend","children":{},"count":4},"/tags/golang":{"label":"#golang","children":{},"count":44},"/tags/decoder":{"label":"#decoder","children":{},"count":1},"/tags/json":{"label":"#json","children":{},"count":1},"/tags/data":{"label":"#data","children":{},"count":14},"/tags/materialized-view":{"label":"#materialized-view","children":{},"count":1},"/tags/sql":{"label":"#sql","children":{},"count":3},"/tags/database":{"label":"#database","children":{},"count":8},"/tags/data-warehouse":{"label":"#data-warehouse","children":{},"count":1},"/tags/scrum":{"label":"#scrum","children":{},"count":2},"/tags/technicaldebt":{"label":"#technicaldebt","children":{},"count":1},"/tags/projectmanagement":{"label":"#projectmanagement","children":{},"count":1},"/tags/hooks":{"label":"#hooks","children":{},"count":2},"/tags/components":{"label":"#components","children":{},"count":1},"/tags/multi-column-index":{"label":"#multi-column-index","children":{},"count":1},"/tags/index":{"label":"#index","children":{},"count":1},"/tags/composite-index":{"label":"#composite-index","children":{},"count":1},"/tags/write-heavy":{"label":"#write-heavy","children":{},"count":1},"/tags/inventory-platform":{"label":"#inventory-platform","children":{},"count":1},"/tags/scalability":{"label":"#scalability","children":{},"count":1},"/tags/reliability":{"label":"#reliability","children":{},"count":2},"/tags/doordash":{"label":"#doordash","children":{},"count":1},"/tags/low-latency":{"label":"#low-latency","children":{},"count":1},"/tags/observability":{"label":"#observability","children":{},"count":5},"/tags/automata":{"label":"#automata","children":{},"count":1},"/tags/erlang":{"label":"#erlang","children":{},"count":1},"/tags/elixir":{"label":"#elixir","children":{},"count":5},"/tags/fsm":{"label":"#fsm","children":{},"count":1},"/tags/go":{"label":"#go","children":{},"count":5},"/tags/error":{"label":"#error","children":{},"count":1},"/tags/ai":{"label":"#ai","children":{},"count":38},"/tags/LLM":{"label":"#LLM","children":{},"count":17},"/tags/machine-learning":{"label":"#machine-learning","children":{},"count":2},"/tags/shares":{"label":"#shares","children":{},"count":1},"/tags/founder":{"label":"#founder","children":{},"count":1},"/tags/prompt":{"label":"#prompt","children":{},"count":1},"/tags/chatgpt":{"label":"#chatgpt","children":{},"count":1},"/tags/zettelkasten":{"label":"#zettelkasten","children":{},"count":1},"/tags/rust":{"label":"#rust","children":{},"count":10},"/tags/trait":{"label":"#trait","children":{},"count":1},"/tags/subscription":{"label":"#subscription","children":{},"count":1},"/tags/pricing":{"label":"#pricing","children":{},"count":1},"/tags/product":{"label":"#product","children":{},"count":1},"/tags/AI":{"label":"#AI","children":{},"count":18},"/tags/entertainment":{"label":"#entertainment","children":{},"count":1},"/tags/data-engineering":{"label":"#data-engineering","children":{},"count":4},"/tags/system-design":{"label":"#system-design","children":{},"count":2},"/tags/architecture":{"label":"#architecture","children":{},"count":4},"/tags/etl":{"label":"#etl","children":{},"count":1},"/tags/wasm":{"label":"#wasm","children":{},"count":2},"/tags/devops":{"label":"#devops","children":{},"count":5},"/tags/tool":{"label":"#tool","children":{},"count":3},"/tags/DX":{"label":"#DX","children":{},"count":1},"/tags/radar":{"label":"#radar","children":{},"count":9},"/tags/technique":{"label":"#technique","children":{},"count":9},"/tags/swift":{"label":"#swift","children":{},"count":7},"/tags/tutorial":{"label":"#tutorial","children":{},"count":5},"/tags/design-pattern":{"label":"#design-pattern","children":{},"count":9},"/tags/creational-design-pattern":{"label":"#creational-design-pattern","children":{},"count":1},"/tags/gang-of-four":{"label":"#gang-of-four","children":{},"count":9},"/tags/license":{"label":"#license","children":{},"count":1},"/tags/software-design":{"label":"#software-design","children":{},"count":2},"/tags/software-architecture":{"label":"#software-architecture","children":{},"count":3},"/tags/graphical-notation":{"label":"#graphical-notation","children":{},"count":2},"/tags/web":{"label":"#web","children":{},"count":9},"/tags/behavior-patterns":{"label":"#behavior-patterns","children":{},"count":2},"/tags/updates":{"label":"#updates","children":{},"count":39},"/tags/search-engine":{"label":"#search-engine","children":{},"count":1},"/tags/duckdb":{"label":"#duckdb","children":{},"count":3},"/tags/transformers.js":{"label":"#transformers.js","children":{},"count":1},"/tags/hybrid-search":{"label":"#hybrid-search","children":{},"count":1},"/tags/macos":{"label":"#macos","children":{},"count":3},"/tags/data-modeling":{"label":"#data-modeling","children":{},"count":1},"/tags/research":{"label":"#research","children":{},"count":3},"/tags/dcos":{"label":"#dcos","children":{},"count":5},"/tags/product-design":{"label":"#product-design","children":{},"count":7},"/tags/report":{"label":"#report","children":{},"count":8},"/tags/directory-structure":{"label":"#directory-structure","children":{},"count":2},"/tags/file-management":{"label":"#file-management","children":{},"count":2},"/tags/file-system":{"label":"#file-system","children":{},"count":2},"/tags/permissions":{"label":"#permissions","children":{},"count":1},"/tags/instructions":{"label":"#instructions","children":{},"count":10},"/tags/database-modelling":{"label":"#database-modelling","children":{},"count":1},"/tags/react.js":{"label":"#react.js","children":{},"count":2},"/tags/docker":{"label":"#docker","children":{},"count":11},"/tags/crypto":{"label":"#crypto","children":{},"count":1},"/tags/workshop":{"label":"#workshop","children":{},"count":1},"/tags/discussion":{"label":"#discussion","children":{},"count":6},"/tags/demo":{"label":"#demo","children":{},"count":1},"/tags/event":{"label":"#event","children":{},"count":6},"/tags/labs":{"label":"#labs","children":{},"count":28},"/tags/radio":{"label":"#radio","children":{},"count":3},"/tags/solana":{"label":"#solana","children":{},"count":7},"/tags/amm":{"label":"#amm","children":{},"count":1},"/tags/techecosystem":{"label":"#techecosystem","children":{},"count":1},"/tags/summit":{"label":"#summit","children":{},"count":4},"/tags/data-structure":{"label":"#data-structure","children":{},"count":1},"/tags/bloom-filter":{"label":"#bloom-filter","children":{},"count":1},"/tags/big-o":{"label":"#big-o","children":{},"count":1},"/tags/distributed-system":{"label":"#distributed-system","children":{},"count":1},"/tags/crdt":{"label":"#crdt","children":{},"count":2},"/tags/data-types":{"label":"#data-types","children":{},"count":1},"/tags/data-structures":{"label":"#data-structures","children":{},"count":2},"/tags/sequential-reads":{"label":"#sequential-reads","children":{},"count":1},"/tags/sequential-writes":{"label":"#sequential-writes","children":{},"count":1},"/tags/random-reads":{"label":"#random-reads","children":{},"count":1},"/tags/random-writes":{"label":"#random-writes","children":{},"count":1},"/tags/sargable-queries":{"label":"#sargable-queries","children":{},"count":1},"/tags/zookeeper":{"label":"#zookeeper","children":{},"count":1},"/tags/kafka":{"label":"#kafka","children":{},"count":1},"/tags/engineering/data":{"label":"#engineering/data","children":{},"count":5},"/tags/data-pipeline":{"label":"#data-pipeline","children":{},"count":1},"/tags/mapreduce":{"label":"#mapreduce","children":{},"count":1},"/tags/distributed":{"label":"#distributed","children":{},"count":3},"/tags/hadoop":{"label":"#hadoop","children":{},"count":2},"/tags/vector-database":{"label":"#vector-database","children":{},"count":4},"/tags/brainery":{"label":"#brainery","children":{},"count":2},"/tags/google-cloud":{"label":"#google-cloud","children":{},"count":1},"/tags/Google-Data-Studio":{"label":"#Google-Data-Studio","children":{},"count":1},"/tags/google-data-fusion":{"label":"#google-data-fusion","children":{},"count":1},"/tags/ETL":{"label":"#ETL","children":{},"count":2},"/tags/CDAP":{"label":"#CDAP","children":{},"count":1},"/tags/google-dataproc":{"label":"#google-dataproc","children":{},"count":1},"/tags/streaming":{"label":"#streaming","children":{},"count":1},"/tags/htmx":{"label":"#htmx","children":{},"count":2},"/tags/code-generation":{"label":"#code-generation","children":{},"count":1},"/tags/typesafe":{"label":"#typesafe","children":{},"count":1},"/tags/url-redirect":{"label":"#url-redirect","children":{},"count":1},"/tags/url-rewrite":{"label":"#url-rewrite","children":{},"count":1},"/tags/http":{"label":"#http","children":{},"count":1},"/tags/seo":{"label":"#seo","children":{},"count":1},"/tags/error-handling":{"label":"#error-handling","children":{},"count":1},"/tags/software-development":{"label":"#software-development","children":{},"count":1},"/tags/database-management":{"label":"#database-management","children":{},"count":1},"/tags/machine learning":{"label":"#machine learning","children":{},"count":1},"/tags/llm":{"label":"#llm","children":{},"count":59},"/tags/feedback":{"label":"#feedback","children":{},"count":2},"/tags/mechanism":{"label":"#mechanism","children":{},"count":1},"/tags/modeling":{"label":"#modeling","children":{},"count":2},"/tags/js":{"label":"#js","children":{},"count":2},"/tags/nocode":{"label":"#nocode","children":{},"count":1},"/tags/git":{"label":"#git","children":{},"count":2},"/tags/presentation":{"label":"#presentation","children":{},"count":1},"/tags/history":{"label":"#history","children":{},"count":1},"/tags/content":{"label":"#content","children":{},"count":6},"/tags/performance-review":{"label":"#performance-review","children":{},"count":2},"/tags/assessment":{"label":"#assessment","children":{},"count":1},"/tags/dfg":{"label":"#dfg","children":{},"count":2},"/tags/moc":{"label":"#moc","children":{},"count":3},"/tags/guidelines":{"label":"#guidelines","children":{},"count":3},"/tags/oss":{"label":"#oss","children":{},"count":1},"/tags/OGIF":{"label":"#OGIF","children":{},"count":1},"/tags/rag":{"label":"#rag","children":{},"count":5},"/tags/search":{"label":"#search","children":{},"count":1},"/tags/evaluation":{"label":"#evaluation","children":{},"count":3},"/tags/knowledge":{"label":"#knowledge","children":{},"count":2},"/tags/tech-radar":{"label":"#tech-radar","children":{},"count":1},"/tags/evaluating-tech":{"label":"#evaluating-tech","children":{},"count":1},"/tags/k8s":{"label":"#k8s","children":{},"count":1},"/tags/catchup":{"label":"#catchup","children":{},"count":5},"/tags/tauri":{"label":"#tauri","children":{},"count":1},"/tags/micro-frontend":{"label":"#micro-frontend","children":{},"count":3},"/tags/local-first":{"label":"#local-first","children":{},"count":1},"/tags/data-synchronization":{"label":"#data-synchronization","children":{},"count":1},"/tags/data-ownership":{"label":"#data-ownership","children":{},"count":1},"/tags/real-time-collaboration":{"label":"#real-time-collaboration","children":{},"count":1},"/tags/R&D":{"label":"#R&D","children":{},"count":1},"/tags/memo":{"label":"#memo","children":{},"count":13},"/tags/observer-pattern":{"label":"#observer-pattern","children":{},"count":1},"/tags/ops":{"label":"#ops","children":{},"count":2},"/tags/nft":{"label":"#nft","children":{},"count":2},"/tags/clojure":{"label":"#clojure","children":{},"count":1},"/tags/algorithms":{"label":"#algorithms","children":{},"count":1},"/tags/sorting":{"label":"#sorting","children":{},"count":1},"/tags/reward":{"label":"#reward","children":{},"count":3},"/tags/recording":{"label":"#recording","children":{},"count":1},"/tags/event-sourcing":{"label":"#event-sourcing","children":{},"count":1},"/tags/standardization":{"label":"#standardization","children":{},"count":1},"/tags/work-adoption":{"label":"#work-adoption","children":{},"count":1},"/tags/design-thinking":{"label":"#design-thinking","children":{},"count":2},"/tags/SDLC":{"label":"#SDLC","children":{},"count":1},"/tags/SQL":{"label":"#SQL","children":{},"count":1},"/tags/strategy-design-pattern":{"label":"#strategy-design-pattern","children":{},"count":1},"/tags/behavior-pattern":{"label":"#behavior-pattern","children":{},"count":2},"/tags/field-notes":{"label":"#field-notes","children":{},"count":1},"/tags/bounty":{"label":"#bounty","children":{},"count":3},"/tags/behavioral-pattern":{"label":"#behavioral-pattern","children":{},"count":1},"/tags/investment":{"label":"#investment","children":{},"count":1},"/tags/personal-finance":{"label":"#personal-finance","children":{},"count":1},"/tags/ogif":{"label":"#ogif","children":{},"count":29},"/tags/evm":{"label":"#evm","children":{},"count":4},"/tags/foundry":{"label":"#foundry","children":{},"count":1},"/tags/visitor-design-pattern":{"label":"#visitor-design-pattern","children":{},"count":1},"/tags/writing":{"label":"#writing","children":{},"count":1},"/tags/english":{"label":"#english","children":{},"count":1},"/tags/Frontend":{"label":"#Frontend","children":{},"count":3},"/tags/prompt-engineering":{"label":"#prompt-engineering","children":{},"count":4},"/tags/open-source":{"label":"#open-source","children":{},"count":2},"/tags/ai-powered":{"label":"#ai-powered","children":{},"count":1},"/tags/intent-classification":{"label":"#intent-classification","children":{},"count":1},"/tags/prompting":{"label":"#prompting","children":{},"count":1},"/tags/log":{"label":"#log","children":{},"count":1},"/tags/pillar":{"label":"#pillar","children":{},"count":3},"/tags/metric":{"label":"#metric","children":{},"count":1},"/tags/ai-agents":{"label":"#ai-agents","children":{},"count":2},"/tags/ai-integration":{"label":"#ai-integration","children":{},"count":1},"/tags/tracing":{"label":"#tracing","children":{},"count":1},"/tags/caching":{"label":"#caching","children":{},"count":1},"/tags/project-management":{"label":"#project-management","children":{},"count":1},"/tags/copilots":{"label":"#copilots","children":{},"count":2},"/tags/team-management":{"label":"#team-management","children":{},"count":1},"/tags/aider":{"label":"#aider","children":{},"count":2},"/tags/cline":{"label":"#cline","children":{},"count":1},"/tags/realtime api":{"label":"#realtime api","children":{},"count":1},"/tags/qwen2.5":{"label":"#qwen2.5","children":{},"count":1},"/tags/openhand":{"label":"#openhand","children":{},"count":1},"/tags/predicted output":{"label":"#predicted output","children":{},"count":1},"/tags/ai-evaluation":{"label":"#ai-evaluation","children":{},"count":1},"/tags/foundation-model":{"label":"#foundation-model","children":{},"count":1},"/tags/fine-tuning":{"label":"#fine-tuning","children":{},"count":1},"/tags/function-calling":{"label":"#function-calling","children":{},"count":1},"/tags/generative-ui":{"label":"#generative-ui","children":{},"count":1},"/tags/protocol":{"label":"#protocol","children":{},"count":1},"/tags/mcp":{"label":"#mcp","children":{},"count":3},"/tags/reinforcement-learning":{"label":"#reinforcement-learning","children":{},"count":3},"/tags/document-processing":{"label":"#document-processing","children":{},"count":1},"/tags/information-retrieval":{"label":"#information-retrieval","children":{},"count":1},"/tags/vector database":{"label":"#vector database","children":{},"count":1},"/tags/supervisor-architecture":{"label":"#supervisor-architecture","children":{},"count":1},"/tags/mongodb":{"label":"#mongodb","children":{},"count":1},"/tags/pattern":{"label":"#pattern","children":{},"count":1},"/tags/salesforce":{"label":"#salesforce","children":{},"count":1},"/tags/use cases":{"label":"#use cases","children":{},"count":2},"/tags/yelp":{"label":"#yelp","children":{},"count":1},"/tags/tuning-llm":{"label":"#tuning-llm","children":{},"count":2},"/tags/langchain":{"label":"#langchain","children":{},"count":1},"/tags/anchor":{"label":"#anchor","children":{},"count":2},"/tags/blockchain-bridge":{"label":"#blockchain-bridge","children":{},"count":1},"/tags/web3":{"label":"#web3","children":{},"count":3},"/tags/btc":{"label":"#btc","children":{},"count":1},"/tags/foundational-topics":{"label":"#foundational-topics","children":{},"count":5},"/tags/distributed-systems":{"label":"#distributed-systems","children":{},"count":1},"/tags/PoS":{"label":"#PoS","children":{},"count":1},"/tags/smart-contract":{"label":"#smart-contract","children":{},"count":1},"/tags/zk-proof":{"label":"#zk-proof","children":{},"count":1},"/tags/defi":{"label":"#defi","children":{},"count":2},"/tags/ethereum":{"label":"#ethereum","children":{},"count":2},"/tags/liquidity":{"label":"#liquidity","children":{},"count":1},"/tags/multisign-wallet":{"label":"#multisign-wallet","children":{},"count":1},"/tags/NFT":{"label":"#NFT","children":{},"count":1},"/tags/proof-of-knowledge":{"label":"#proof-of-knowledge","children":{},"count":1},"/tags/zk-rollup":{"label":"#zk-rollup","children":{},"count":2},"/tags/polygon":{"label":"#polygon","children":{},"count":1},"/tags/StarkNet":{"label":"#StarkNet","children":{},"count":1},"/tags/ton":{"label":"#ton","children":{},"count":2},"/tags/zero-knowledge":{"label":"#zero-knowledge","children":{},"count":1},"/tags/devbox":{"label":"#devbox","children":{},"count":17},"/tags/nix":{"label":"#nix","children":{},"count":9},"/tags/containerization":{"label":"#containerization","children":{},"count":4},"/tags/virtualization":{"label":"#virtualization","children":{},"count":4},"/tags/frontend,":{"label":"#frontend,","children":{},"count":1},"/tags/graphql":{"label":"#graphql","children":{},"count":1},"/tags/reactjs":{"label":"#reactjs","children":{},"count":2},"/tags/css":{"label":"#css","children":{},"count":4},"/tags/atomic-css":{"label":"#atomic-css","children":{},"count":1},"/tags/mock-service-worker":{"label":"#mock-service-worker","children":{},"count":1},"/tags/api-mocking":{"label":"#api-mocking","children":{},"count":1},"/tags/web-development-tool":{"label":"#web-development-tool","children":{},"count":1},"/tags/atomic-design":{"label":"#atomic-design","children":{},"count":1},"/tags/polymorphic-component":{"label":"#polymorphic-component","children":{},"count":1},"/tags/typescript":{"label":"#typescript","children":{},"count":4},"/tags/translation":{"label":"#translation","children":{},"count":1},"/tags/CSS":{"label":"#CSS","children":{},"count":1},"/tags/guides":{"label":"#guides","children":{},"count":1},"/tags/responsive-design":{"label":"#responsive-design","children":{},"count":1},"/tags/css-in-js":{"label":"#css-in-js","children":{},"count":1},"/tags/tip":{"label":"#tip","children":{},"count":1},"/tags/dark-mode":{"label":"#dark-mode","children":{},"count":1},"/tags/html":{"label":"#html","children":{},"count":4},"/tags/accessibility":{"label":"#accessibility","children":{},"count":4},"/tags/rendering":{"label":"#rendering","children":{},"count":1},"/tags/dom":{"label":"#dom","children":{},"count":2},"/tags/cssom":{"label":"#cssom","children":{},"count":1},"/tags/render-tree":{"label":"#render-tree","children":{},"count":1},"/tags/hsl":{"label":"#hsl","children":{},"count":1},"/tags/a11y":{"label":"#a11y","children":{},"count":1},"/tags/client-side":{"label":"#client-side","children":{},"count":1},"/tags/storage":{"label":"#storage","children":{},"count":1},"/tags/javascript":{"label":"#javascript","children":{},"count":4},"/tags/modules":{"label":"#modules","children":{},"count":1},"/tags/frontend/performance":{"label":"#frontend/performance","children":{},"count":2},"/tags/analytics-tools":{"label":"#analytics-tools","children":{},"count":1},"/tags/analytics-platform":{"label":"#analytics-platform","children":{},"count":1},"/tags/engineering/frontend":{"label":"#engineering/frontend","children":{},"count":1},"/tags/concurrency":{"label":"#concurrency","children":{},"count":2},"/tags/parallelism":{"label":"#parallelism","children":{},"count":1},"/tags/validation":{"label":"#validation","children":{},"count":1},"/tags/fronten":{"label":"#fronten","children":{},"count":1},"/tags/state-management":{"label":"#state-management","children":{},"count":2},"/tags/web-performance":{"label":"#web-performance","children":{},"count":2},"/tags/animation":{"label":"#animation","children":{},"count":1},"/tags/design-system":{"label":"#design-system","children":{},"count":1},"/tags/storybook":{"label":"#storybook","children":{},"count":1},"/tags/hook":{"label":"#hook","children":{},"count":1},"/tags/React":{"label":"#React","children":{},"count":1},"/tags/nextjs":{"label":"#nextjs","children":{},"count":2},"/tags/server-component":{"label":"#server-component","children":{},"count":1},"/tags/caching-data":{"label":"#caching-data","children":{},"count":1},"/tags/data-fetching":{"label":"#data-fetching","children":{},"count":1},"/tags/swr-infinite":{"label":"#swr-infinite","children":{},"count":1},"/tags/web-design":{"label":"#web-design","children":{},"count":1},"/tags/scroll-driven-animations":{"label":"#scroll-driven-animations","children":{},"count":1},"/tags/animations":{"label":"#animations","children":{},"count":1},"/tags/intersection-observer":{"label":"#intersection-observer","children":{},"count":1},"/tags/shadow-dom":{"label":"#shadow-dom","children":{},"count":1},"/tags/web-api":{"label":"#web-api","children":{},"count":1},"/tags/state-mangement":{"label":"#state-mangement","children":{},"count":1},"/tags/global-state-management":{"label":"#global-state-management","children":{},"count":1},"/tags/threejs":{"label":"#threejs","children":{},"count":1},"/tags/social-networks":{"label":"#social-networks","children":{},"count":1},"/tags/useEffect":{"label":"#useEffect","children":{},"count":1},"/tags/parsing":{"label":"#parsing","children":{},"count":1},"/tags/fonts":{"label":"#fonts","children":{},"count":1},"/tags/variable-fonts":{"label":"#variable-fonts","children":{},"count":1},"/tags/native-modules":{"label":"#native-modules","children":{},"count":1},"/tags/vitejs":{"label":"#vitejs","children":{},"count":1},"/tags/esm":{"label":"#esm","children":{},"count":1},"/tags/wai-aria":{"label":"#wai-aria","children":{},"count":1},"/tags/webassembly":{"label":"#webassembly","children":{},"count":1},"/tags/sandbox":{"label":"#sandbox","children":{},"count":1},"/tags/websocket":{"label":"#websocket","children":{},"count":1},"/tags/protocols":{"label":"#protocols","children":{},"count":1},"/tags/component":{"label":"#component","children":{},"count":1},"/tags/DOM":{"label":"#DOM","children":{},"count":1},"/tags/virtual-dom":{"label":"#virtual-dom","children":{},"count":1},"/tags/iframe":{"label":"#iframe","children":{},"count":1},"/tags/postMessage":{"label":"#postMessage","children":{},"count":1},"/tags/finite-automata":{"label":"#finite-automata","children":{},"count":1},"/tags/pattern-matching":{"label":"#pattern-matching","children":{},"count":1},"/tags/state-machines":{"label":"#state-machines","children":{},"count":1},"/tags/vim":{"label":"#vim","children":{},"count":1},"/tags/interface":{"label":"#interface","children":{},"count":1},"/tags/language":{"label":"#language","children":{},"count":5},"/tags/java":{"label":"#java","children":{},"count":1},"/tags/programming":{"label":"#programming","children":{},"count":1},"/tags/generics":{"label":"#generics","children":{},"count":2},"/tags/import":{"label":"#import","children":{},"count":1},"/tags/package":{"label":"#package","children":{},"count":1},"/tags/profiling":{"label":"#profiling","children":{},"count":1},"/tags/go-weekly":{"label":"#go-weekly","children":{},"count":24},"/tags/networking":{"label":"#networking","children":{},"count":7},"/tags/iterators":{"label":"#iterators","children":{},"count":1},"/tags/kernel-programing":{"label":"#kernel-programing","children":{},"count":1},"/tags/cybersecurity":{"label":"#cybersecurity","children":{},"count":2},"/tags/serverless":{"label":"#serverless","children":{},"count":1},"/tags/agents":{"label":"#agents","children":{},"count":4},"/tags/monitoring":{"label":"#monitoring","children":{},"count":1},"/tags/overleaf":{"label":"#overleaf","children":{},"count":1},"/tags/slide":{"label":"#slide","children":{},"count":1},"/tags/finance":{"label":"#finance","children":{},"count":1},"/tags/real-time":{"label":"#real-time","children":{},"count":1},"/tags/phoenix-live-view":{"label":"#phoenix-live-view","children":{},"count":1},"/tags/timescaledb":{"label":"#timescaledb","children":{},"count":1},"/tags/newsletter":{"label":"#newsletter","children":{},"count":44},"/tags/wrap-up":{"label":"#wrap-up","children":{},"count":7},"/tags/tech radar":{"label":"#tech radar","children":{},"count":1},"/tags/doty":{"label":"#doty","children":{},"count":5},"/tags/wfh":{"label":"#wfh","children":{},"count":1},"/tags/software engineer":{"label":"#software engineer","children":{},"count":1},"/tags/meet-up":{"label":"#meet-up","children":{},"count":4},"/tags/changelog":{"label":"#changelog","children":{},"count":1},"/tags/ICY":{"label":"#ICY","children":{},"count":1},"/tags/test":{"label":"#test","children":{},"count":1},"/tags/weekly-digest":{"label":"#weekly-digest","children":{},"count":15},"/tags/discord":{"label":"#discord","children":{},"count":35},"/tags/motivation":{"label":"#motivation","children":{},"count":1},"/tags/meetup":{"label":"#meetup","children":{},"count":2},"/tags/technology":{"label":"#technology","children":{},"count":5},"/tags/forward-engineering":{"label":"#forward-engineering","children":{},"count":14},"/tags/tech-community":{"label":"#tech-community","children":{},"count":1},"/tags/funding":{"label":"#funding","children":{},"count":2},"/tags/office-hours":{"label":"#office-hours","children":{},"count":28}}}},"slug":["updates"],"childMemos":[{"content":"\n2018 was the memorable year with lots of achievements.\n\nWe adapted the new team structure.\nWe defined things we value and live that culture tediously.\nWe moved to new office. We welcomed the new dwarves to join us.\n\nWe scaled up from 15 to 30ish with all the smart people gathering around and commit to the dream of building our first global software company.\n\n![](assets/2018-in-review_2018-wrapping-up_4333853d2b402683ec67b4fa5e7c03aa_md5.webp)\n\nWe learned how to do things right and started using it to help deliver quality software.\n\nEverything is just the beginning of our first chapters and it couldn’t be that good without you. I’m very thankful for all the contributions that you have made and looking forward to 2019 with all of you.\n\n-Han","title":"2018 In Review","short_title":"","description":"2018 notable hightlights and achievements","tags":["updates","newsletter","wrap-up","team"],"pinned":false,"draft":false,"hiring":false,"authors":["tieubao","duy"],"date":"Mon Dec 31 2018 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2018-in-review.md","slugArray":["updates","changelog","2018-in-review"]},{"content":"\nAnother year has gone by. And we just celebrated the 5th year that we survived all the challenges. Everyone was facing their own, but I have seen many of you reaching new stages and achieve new targets.\n\nWe have been growing up together. As for your recall, end of 2018, we were about 30s. End of this year, we are about 50s. End of 2018, we were young and inexperienced. End of this year, we are just inexperienced.\n\nThe way we are running this organization is extraordinary, where new policies are focusing on putting people & technology in the heart of everything. Even though people come and go, their spirit stays. Dwarves Foundation is always the place the weirdest things could happen. And that gives me a strong belief in our promising future.\n\n2019 was a tough year for all of us. We achieved a lot but also failed a ton. The strong team should be built on its people and their beliefs. None of us is as smart as all of us. Remember what Uncle Ho said about teamwork? I will not put it here but leave it to you.\n\nOnce again, on behalf of all the Dwarves, I want to say thanks to all of your contributions. The main theme of 2020 is 'The borderless software firm' and I'm looking forward to it with all of you.\n\nHappy New Year 🎉\n\n-Han","title":"2019 In Review","short_title":"","description":"2019 notable highlights and achievements","tags":["updates","newsletter","wrap-up","team"],"pinned":false,"draft":false,"hiring":false,"authors":["tieubao"],"date":"Sat Jan 25 2020 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2019-in-review.md","slugArray":["updates","changelog","2019-in-review"]},{"content":"\nWrapping up 2019 with the first 5th-year milestone, many ideas popped up for the next steps. Heading into a new decade means we get to wrap up the old and in with the new. For us, the utmost target is to focus on territory expansion and team bootstrapping. Reinvest in the current foundation. Make it stable and make it impactful.\n\n![](assets/2020-in-review_2020-in-a-flashback_5235debb4b84d96dc105178e3ad4aae0_md5.webp)\n\nIt handed us the chance to come up with more cool stuff. Something to recognize each other among the crowd. A black zip hoodie and symbolic totem of the Dwarves.\n\n![](assets/2020-in-review_2020-in-a-flashback_5eee1054f25200d14884323d2f307f31_md5.webp)\n\nScaling from a few craftsmen, we reached the 50s with a firm foundation from different places. Within the year, people come and go, but their spirit stays. Each of them contributes a small puzzle for a bigger picture.\n\n### We were ready for a borderless software firm\n\nWith the Dwarves located in many countries (Toronto, Vancouver, Düsseldorf, Indonesia, and Vietnam), we headed for a borderless software firm, where we collaborate and make things work despite the distance. Running a team remotely has its downside since we hardly have physical meetups. Everything’s conducted online; every communication gets turned into thread-based messages.\n\n### But\n\nStarting from March, the world began to lockdown. Companies get hit. Businesses around the world are expected to close down and wait until the pandemic is over. Everyone will try to save their penny, and no one would love to build software or start something new. We might be affected. We haven’t known yet. The best we can do is tweak our plan to prepare for any scenarios\n\n### The Adaptation Begins\n\nThings remain in survival mode. We only **[hire when it hurts](https://memo.d.foundation/playbook/operations/a-tips-of-hiring-dont/)**. No layoffs on the ground. We keep the team with those who have the same beliefs, lifestyle, and the urge to move along with the tech industry. In the short term, a team that people are proud to work with. It’s where their outcome matters.\n\n### Level up the tech quality\n\nWe dive deep into tech, continuously improving our knowledge base through tech radar, team memo, and other activities. We optimize the workflow, simplify the process to make our work more enjoyable.\n\n### A team-built testing framework\n\nStarting from a team of two, our QC Team has now reached the number of five, which later came up with an internal testing framework that makes test cases in format and removes rework.\n\n### Real-time status page\n\nThis adoption enables us to constantly receiving the latest updates on project and website status. Other than tracking them directly on [stt.daf.ug](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*epYF6iiq6IvM4x70hcd3ZA.png), we get to log them on the currently running projects and ensure the deliverable's quality.\n\nAnd got them on team Discord.\n\n![](assets/2020-in-review_2020-in-a-flashback_e310751d76ab92238b6dacd71ecd4277_md5.webp)\n\n### A Radar Ring for Tech Adoption\n\nThe day-to-day work won’t get us as far as we could. Finding the new and stepping out of the safe zone is a great resolution to move with the industry.\n\nWe input the discoveries and assessment of the latest tech trends on [Radar Ring](https://dwarves.foundation/radar/). We define them in Rings & Quadrants. Every two months, we gather the team's research output and conduct webinars on sharing, guidelines &lesson-learned. The knowledge recap is stored as RFC on [Github](https://github.com/dwarvesf/radar) and team [Memo](https://memo.d.foundation/) for later reference.\n\n![](assets/2020-in-review_2020-in-a-flashback_897cee98638b129f3afb4a53c7de23c1_md5.webp)\n\n### Bootstrap Startup Idea, Conveniently\n\nPortray ourselves as a technical partner for startups; it’s our mission to deliver the optimized solution. That comes with a smooth process of bootstrapping their ideas and promptly turning those into products.\n\n**Metric Dashboard**\n\nWe aggregated a set of events and data from the application and displayed them in dashboards for better analytics. Each domain requires a specific metric set. That helps makers easily locate the focus point and allocate their resources accurately.\n\n**Upgrade CI/CD culture**\n\nHaving experience in project setup, we’re proud to bring the best practices in helping startup ideas take off easier. Picking Earthly as an approach to reduce the risk from local environment testing is how we help lift your project off the ground.\n\n**All Practice in One Place**\n\nNew researches must be put into practice; otherwise, it’s a waste of time. From every piece of collected knowledge, we take the first step putting them in a trial period long enough to grab the pros & cons. These practices get applied to the team, ensure the knowledge base, and put our work into one format.\n\n![](assets/2020-in-review_2020-in-a-flashback_8489fab373166d75e44a6f3948656362_md5.webp)\n\n### State of the Art\n\nEverything we do results in this internal tech-index. A hub of continuous evolving expertise.\n\n![](assets/2020-in-review_2020-in-a-flashback_d713f1fe35c7e9e35112315edc5574c5_md5.webp)\n\n### The Internal\n\nWe figured it wasn’t the right time to scale. It’s the time to maintain and make the best out of what we have. Keeping the company safe through the pandemic and building a team that people love to work with are the primary goals.\n\nSo. new plan. Restructure, strengthen the core, and focus on what we do best.\n\n### Build a place where people love to work in\n\n**Where people can develop themselves and as a team**\n\nThe urge to grow lies within us. Outside of work, we encourage the Dwarves to improve their knowledge and skills. We support this with an [Education Allowance](https://github.com/dwarvesf/handbook/blob/master/benefits-and-perks.md#continuing-education-allowance), an English Camp every Tue & Thu, and a weekly 101 training - where the team discusses and collects points of view on different topics toward [soft skills](https://youtu.be/HR4-g70UCjQ?si=v2TGHTp7YkdNJrhM), product design, [startups](https://www.youtube.com/live/z7DwXNoeeAg?si=Zdcq1_dMK-n9oMgf) & engineering.\n\n**Where the efforts are tributed**\n\nDwarves Foundation is where we value even the tiniest contribution, by all means. It’s not all about making the client happy; it’s about feeling proud of what we produce. We launch [Dwarves of The Year](https://dwarves.careers/life/activities/#dwarves-of-the-year) as a highlight to select the outstanding Dwarves. By letting people taking votes on four criteria: Influencing, Hardworking, Impactful, and Self-Development.\n\n**Where the team structure gets flattened**\n\nWearing many hats used to be our option. We do have roles, but we haven’t sat down and put them in place until earlier this year. The latest team structure lies at [https://bit.ly/df-org-chart](https://bit.ly/df-org-chart). But unlike others, we want to keep things public as much as we could. We do our best to make sure they get access to every piece of information, and despite the titles, [everyone is welcomed to raise a question.](https://memo.d.foundation/playground/_memo/asking-as-a-junior/#sidebar)\n\n**Where the engagement ain't just around the work**\n\nEvery member should feel like a part of the team. We issued [Employee Stock Option Plan](https://github.com/dwarvesf/handbook/blob/master/benefits-and-perks.md#employee-stock-option-plan) as a aprt of our benefit package, where members can be the significant contributors instead of tenured employees. This gives them the right to buy a certain amount of company shares at a predetermined price.\n\n### A Data-driven Company\n\nEverything revolves around data. Taking data as the core allows us to set realistic business goals, pinpoint what makes us outstanding, which aspect we should stay focused on based on real analytics metrics.\n\n**Workflow update - Data first**\n\nWith the concept that Program = Data + Algorithm, we weave the data culture in every workpiece. Things start with data format at first; the rest will come later.\n\n![](assets/2020-in-review_2020-in-a-flashback_ca031915c44e21e677d99389019d16aa_md5.webp)\n\n**How we gather data**\n\n![](assets/2020-in-review_2020-in-a-flashback_cbb1aa0a50be64a8455ee9e20e198dd7_md5.webp)\n\n**How does that help us make a decision**\n\nData prevents us from making biased decisions. No favoritism on the table. Data sort out the real number from the real work, where we get to analyze and evaluate objectives effectively. Keeping all data in one place enables us to set measurable goals that align with the company’s vision, predict what works and what doesn’t, and, therefore, actively turn data into real action.\n\n### We seek for Solid Partnership\n\nTo go further, seeking partnerships to co-create the future is a must. We managed to expand the connection by searching for business partners globally. Anyone who wishes to join our partner network can see if they have [the same belief in meeting business goals through innovative high-tech solutions](https://dwarves.foundation/partner).\n\nWe’ve prepared a collaboration process on commission-based. We welcome the ones with the urge to grow new business opportunities by technology and innovation.\n\n### Effective Operation\n\nRunning a company isn’t just about process and policy. It’s more on minimizing the minor disruptions that reduce the company’s ability to grow and prosper. Cleaning up the roadblocks. Eliminate the waste, and keep people aligned. And mostly, how to do more with less effort?\n\n**Going Automation**\n\nOn the way to run the team effortlessly, we figure not everything requires human's involvement. Fortress - our internal operation system, remove the redundancies by **automating the operation work**, from accounting to newbies onboarding.\n\n![](assets/2020-in-review_2020-in-a-flashback_52d81a3aa81e12a8a931fbee1e8350d8_md5.webp)\n\n**Transparency in Information**\n\nRunning a remote team means the communication relies mostly on thread-based messages. Unless we [go transparent](https://dwarves.foundation/memo/transparency-rj7dc8vkoh/)in what we are working on, losing track and feel distant from the team is predictable.\n\nWe keep the [communication](https://github.com/dwarvesf/handbook/blob/master/how-we-work.md#communication) channels open, from Basecamp check-in questions to the Discord sharing hub. More than telling people about the work, throwing the latest news into the chatroom can also help us stay tuned to what’s going on out there.\n\n**Dashboard & Valuation KPI**\n\nCompany valuation always a subtle issue to mention. Not many companies onboard with this. But we do.\n\n![](assets/2020-in-review_2020-in-a-flashback_5c4fb47066f19a5d8cc7c6b9f6422ecd_md5.webp)\n\nBringing the number to the public gives us the privilege to stay proud of what we’ve accomplished. We issue ESOP every year, and visualizing how our business strategy was turned into profit allows stakeholders to keep track of its potential growth. Dashboard valuation also reflects our predicted strategy’s accuracy, emphasizes the key goal, and portrays our ability to develop.\n\n### Hiring\n\n**We value the unconventional**\n\nOnce Covid started to invade, our goal changed accordingly. Instead of adding more people, we choose to fill the team with more culture. We picked out the value that makes us who we are and wrapped them in [Culture book.]()\n\n![](assets/2020-in-review_2020-in-a-flashback_6694c1aa16fc90f1f7189d457e439ee1_md5.webp)\n\nWe look for those with the same DNA. This small book provides insight into what it's like to work with us, how the day may transpire, what to expect, and what to prepare to become a real Dwarves.\n\n**Work where you feel best**\n\nAfter five years, we evolved as a team that works and communicates from anywhere. Some of us choose to work from coffee shops, others feel better in their PJs and start a virtual meeting, while the rest spend their day at our Saigon office.\n\n**We exposed, clearer**\n\nWe started first with the Website upgrade. We fill up the blank with Case Studies and the tech stacks, completing a Service section with precise detail on each type of work.\n\n![](assets/2020-in-review_2020-in-a-flashback_8dc9f8dc969d793887c21e026eeec3d2_md5.webp)\n\nNext, the **[Memo](https://memo.d.foundation/)**. Our crafting space for lessons learned, perspectives, and the occasional webinar recaps.\n\n![](assets/2020-in-review_2020-in-a-flashback_807943f1856a0cdf4a2c431c7f1b1d81_md5.webp)\n\n### We design for the Resilient future\n\n[Dwarves Design](https://dwarves.design/) contains our practices and methods for product design at Dwarves Foundation. Backed by talented and unique wizards, we express the Dwarvish magic in the cultivated crafts through aesthetic and intelligent design solutions.\n\n![](assets/2020-in-review_2020-in-a-flashback_f2100ed6de6241cbb830f7d4747cda6b_md5.webp)\n\n### We level up\n\nApplying the top-selected technologies, we end up expanding the business. With more than 10 new deals with technical service development and venture projects, we could step up the game and set our foot into different industries.\n\n**The year in Industries**\n\n![](assets/2020-in-review_2020-in-a-flashback_a7c681fd646975683b1c87b09d70cead_md5.webp)\n\n**Going Details**\n\n![](assets/2020-in-review_2020-in-a-flashback_a2aee1a0e0424c6344ae0bd4cb2841dd_md5.webp)\n\n**Stretch the Venture Arms**\n\nPositioning ourselves as technical distributors means delivering that through a variety of activities, including creating business opportunities.\n\n![](assets/2020-in-review_2020-in-a-flashback_5659925d4eba951d9ba6cfb07046be0a_md5.webp)\n\n[We invest and provide](https://dwarves.ventures/) them with technical solutions to lift their projects off the ground. But most importantly, we do things from our lessons learned and selective experience. Giving early-stage startups the necessary resources to turn their ideas into impactful products is how we help empower the next innovation's future.\n\n### We got your back\n\n![](assets/2020-in-review_2020-in-a-flashback_90359633895a008af577eaf3a8fae47c_md5.webp)\n\n### Giving back to the Community\n\nLearning from the community gives us the privilege to explore and grow. We have been a part of it long enough to contribute back. Describing ourselves as a tech distributor, our mission is to support and widen the tech playground and create social impact using tech solutions.\n\n**Salt Cancer Initiative - Supportive backers for cancer patients**\n\nOur first move on community support. We partner with Salt Cancer Initiative to create a supportive community that provides cancer patients with knowledge and activities using high-tech solutions.\n\n![](assets/2020-in-review_2020-in-a-flashback_024baf6bfa793a86e35f6a5ec5c39734_md5.webp)\n\n**WeBuild Day - Post-Covid 19 Developers Reunion**\n\nLast December marked **WeBuild Day 2020** - where we partner with Block71 Saigon for a full-day workshop on tech topics. A reunion chance with the developers after Covid-19, with the participation of other sponsors such as beGroup, Codelink, Flodesk and many more\n\n![](assets/2020-in-review_2020-in-a-flashback_bc600184b959d7caeb9080267fed03ff_md5.webp)\n\n**Golang for Beginner: Collaboration with Golang Vietnam**\n\nSince 2014, Golang Vietnam has been the playground for all beginner and experienced Go programmers in Vietnam. Normally, we support Golang Vietnam in organizing the annual GopherCon as a sharing workshop and lessons learned from Go experts.\n\n![](assets/2020-in-review_2020-in-a-flashback_07493a80741eafd1af67f7ebf1b63e6e_md5.webp)\n\nThough the affection of Covid limits us from conducting offline meetups, we still manage to launch some essential skills seminars throughout the year.\n\n![](assets/2020-in-review_2020-in-a-flashback_4c1b03bc8c9de2e88c3de14bde9e1d33_md5.webp)\n\n**techie.story**\n\nHaving more time inside makes us realize more corners in this industry should be shined light on. We founded [**techie.story**](https://techiestory.net/), where we get them to listen to the untold story of techies from this industry, about the hidden aspects of day-to-day work.\n\n![techiestory](assets/2020-in-review_1_qd5o2ijrtws2kucxnybjsg.webp)\n\n**We do Open-Source Software**\n\nGoing OSS means working with multiple companies on an idea or a problem, which eventually gets us to the solution more quickly with more creativity. By sharing the foundation concept and codebase, OSS enables us to trigger innovative ideas and provide and receive insights from different people in the industry. That allows the development phase to happen smoothly, and encourages the spirit of building, expanding, and evolving.\n\n![](assets/2020-in-review_2020-in-a-flashback_d9fee91f014c8de4faac3ebee2ab7af5_md5.webp)\n\nOver the years standing on shoulders of the giants, [the Dwarves's OSS](https://dwarves.foundation/opensource) mainly focuses on boosting up productivity and building differentiating value on top of cutting edge technologies.\n\n### The in-house Products\n\nWe kicked off Superbits.co earlier this year as our indie studio for team-built products. It all came from the issue we want to resolve and the unique value we aim to support the tech industry.\n\nBy engineer, for engineers.\n\n![](assets/2020-in-review_2020-in-a-flashback_2bf5ab5ed99918b1679259d986a56d07_md5.webp)\n\n### Newsletter: The NeXT Bytes\n\nNone of us knows what will happen in the future. The only thing we can do is predict, starting with the question “What’s next?”, surrounding with the “why,” and continuously sorting out the experience.\n\n![](assets/2020-in-review_2020-in-a-flashback_fe1c1d559485d446465ce343668dd4a9_md5.webp)\n\nThe NeXT Bytes jots down the ‘next’ thing we see, do, observe, or conquer on the way toward the future. It’s the lesson learned and the sacrifice, what we have put behind, and what’s waiting for us. There will be many things to throw in along the way. The cool techniques. The ability to build a better organization. How to keep things afloat. The revealing aspect of the industry.\n\nEnjoy the promising ride, join us at https://tinyletter.com/nextbytes/. \n\n### What's for 2021\n\nWe had an executive sync-up not so long ago. The operation team sat down and decided where we should head in 2021. The pandemic’s impact continues to ripple across industries. It’s risky to do things big. The best thing to look forward to is maintaining the current status and making sure people are motivated. Building a place people love to work in and be proud of what they produce.\n\n**The branding coverage**\n\nWe are doing things right, which is reflected in the financial status and the playbook we noted down. But we are still far from distributing that knowledge base. Going further on social media coverage and issuing a monthly newsletter might be a good idea to begin with.\n\nWe’ve been conducting Dwarves Radio Talk, a weekly talk show where we pitch our favorite topics on engineering, product design, startup and skills management. Knowledge sharing should be a thing to encourage. It’s the best practices we sort out after a long time working in this field, and we can’t help but bring them outside.\n\nAnyone with the same interest, or curiosity, is welcome to join us at Discord.\n\n![](assets/2020-in-review_2020-in-a-flashback_8f42ebd6dd1501246748c512e445f960_md5.webp)\n\n**The product-driven mindset**\n\nTechnical consultancy and venture investment will remain its resilient, but we want to spend more effort working on what we love. Besides scaling Superbits, we level it up as an indie studio with a product-driven business orientation, making the dev community more worth experiencing.\n\n**A life outside of tech**\n\nThe successful work with Salt Cancer Initiative kicked off our willingness to contribute more impact to social problems. We’re lucky to know and work with many other brothers with the same vision during our path to expand the tech playground. Using tech to resolve other issues outside of work, building up a platform connects like-minded people. Striving for a better world in 2021, which we believe everyone can really use.\n\nWe continue to build Dwarves Foundation the same way we do software. It works and gets bugged along the way, but the new version gets released continuously.\n\nThe door of 2021 is opening with many questions. Seeking the answers and enjoying coding along the way sounds like a good plan.\n","title":"2020 In Review","short_title":"","description":"2020 notable highlights and achievements","tags":["updates","tech radar","newsletter","wrap-up"],"pinned":false,"draft":false,"hiring":false,"authors":["tieubao","nikki","duy"],"date":"Fri Feb 05 2021 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2020-in-review.md","slugArray":["updates","changelog","2020-in-review"]},{"content":"\nApart from the team's voting result for each title, the team leads also selected the **Honorable Mention** and **Client Endorsed**, as we want to honor all of the hard work.\n\nYou can find the **[voting details here](https://docs.google.com/spreadsheets/d/1ggaJYllrIg8IK8uFOEqWFoHUATM1BP6ISTrX-emsdIc/edit#gid=0)**. The final result was close since you're all awesome!\n\nLet's all welcome our Dwarves of 2021 🛠\n\n![](assets/2021-dwarves-of-the-year_2021-december-all-hands-meeting_ff19993744fb6047810b5411ce69b707_md5.webp)\n\n### Claim Your Prize\nBased on the prize value in each title, let’s select your prize item in this sheet [https://bit.ly/3G0LuAU](https://bit.ly/3G0LuAU). A few notes on this: \n\n* You can choose ***any item*** - as long as the subtotal value is ***≤= your prize value***. \n* The prize value can’t be redeemed in cash. \n* Please help to select your prize **before Jan 14, 2022**. We will close the list by then.\n* If your name is on the list but you can’t input the prize, drop your email to Duy.\n* If you got any wishlist item that also matches your prize value, please ping Duy for further support. \n\n**We’ve also prepared you all a mini merchandise set for the rest of the team**\nHope you can travel anywhere with this combo. Please help by inputting your info in the tab Team Address - [https://bit.ly/3G0LuAU](https://bit.ly/3G0LuAU).\n\nA big congratulations to our Dwarves of 2021! And thank you to all the Dwarves teammates for being with us through the past seven years. May we all enter 2022 with happiness and success. ♡\n\n![merch](assets/2021-dwarves-of-the-year_df-merch.webp)\n\n![real-merch](assets/2021-dwarves-of-the-year_real-merch.webp)","title":"Dwarves Of The Year 2021","short_title":"","description":"A big congratulations to our Dwarves of 2021. Apart from the team's voting result for each title, the team leads also selected the Honorable Mention and Client Endorsed, as we want to honor all of the hard work.","tags":["newsletter","wrap-up","updates","doty"],"pinned":false,"draft":false,"hiring":false,"authors":["duy"],"date":"Wed Jan 05 2022 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2021-dwarves-of-the-year.md","slugArray":["updates","changelog","2021-dwarves-of-the-year"]},{"content":"\nStarted with 3 engineers working in different coffee shops because we didn't have an office back then, we are gearing up for the second coming in our journey with over 40 clients and partners worldwide, +1M lines of code later throughout more than 7 years. \n\nIt’s like building software - we call it Dwarves 2.0 - our latest major movement.\n\n## Wrapping up Dwarves 1.0\n\n2021 is full of changes and challenges, but our can-do mindset makes us gritty. We don't have all the answers, so we try and do. As we state in our [**Agile Minifesto**](https://dwarves.foundation/manifesto): Fail fast, learn often, and it's okay to start over.\n\nThe results are way beyond our expectations. We work with several great clients and partners, including: [**Setel**](http://setel.com/), **[Momos](http://momos.io/)**, [**Mudah**](http://mudah.my/), [**Attrace**](http://attrace.com/), [**SP Group**](http://spgroup.com.sg/), [**Vietcetera**](http://vietcetera.com/), [**WeBuild**](http://webuild.community/) and many more. We automate most of our operations using Notion, Basecamp, and our very own Fortress. We form a team specialized in blockchain & web3. \n\nAnd along with everything, we do everything we can to level up our team.\n\n![](assets/2021-in-review_2021-dwarves-in-review.webp)\n\n## A few things worth celebrating\n### The team benefits go up\nThe Dwarves are our greatest asset. Most of our effort goes into hiring the right ones, giving them absolute support to grow with us.\n\n- The Dwarves recently enjoyed a significant raise in compensation.\n- With Dwarves Token, everyone contributing to our growth gets rewarded a portion of the company.\n- The engineer career ladder was refined with 1-1 mentoring.\n- We offer more internal training, and the team keeps inputting their valuable piece of Knowledge.\n\nBy launching [Dwarves Discord](https://discord.gg/dwarvesv), we’re able to connect and interchange our knowledge with the people who care about tech as much as we do.\n\n![](assets/2021-in-review_2021-dwarves-discord.webp)\n\n### Making our marks in new tech\nNew technologies shape the future. It's our all-time belief. Within this year, our bet is on the Web3, the Open Internet, and the next-gen automation software using AI and Big Data.\n\n- A blockchain-specialized & web3 team was formed. [Cyber Nekos](http://pod.so/), [Legend of Fantasy War](http://legendfantasywar.com/), [Attrace](http://attrace.com/), [Tokenomy](http://tokenomy.com/) are our highlights.\n- **Multiple study groups** within the team focusing on: Blockchain & Web3, Metaverse, AI & ML, Data Science, Automation.\n\nWe attract the same DNA. Our clients are organizations that put tech at great importance to their businesses. It's always a proud feeling when our clients share their achievements with us, knowing we play a part in it.\n\n![](assets/2021-in-review_2021-dwarves-in-review-project.webp)\n\n### Our vision and belief stays the same\nEven with everything we managed to pull through and achieve, we are still makers at heart. [Our vision and belief](https://github.com/dwarvesf/handbook/) are built to stay.\n\n[Engineering is still our culture](). Software craftsmanship is still our end goal. We are still putting in hard work every day. It’s the spirit to build a company where everyone enjoys their work and stays proud of everything they ship.\n\n## We are growing fast\n### Bigger & borderless team\nRemote working shaped into our culture. Our engineers have the full support they need to perform at their best. People were granted options to upgrade their WFH station. Everything is going smoothly as a 100% remote team across 4 different time zones. \n\n**The Dwarves seek for more teammates in 2022**\n\nOur team is currently at 60 mems and we road for a double number. The list is opening at [Dwarves Career](https://memo.d.foundation/careers/hiring/) - but we will find you the best fit if we’re having the same core value. \nAnd we’d love to onboard like-minded people to our Discord Network: [**discord.gg/dwarvesv**](http://discord.gg/dwarvesv).\n\n### Forming the getaway chalets\nThough the Dwarves can work anywhere they want, we still have offices in 3 different cities in Vietnam.\n\n- **HCM**: Our first official office, sitting in the heart of HCM\n- **Dalat**: The built-in-office cafe intended for work-cations. Whenever our engineers feel like getting away from bustling cities, they can spend their days here. Our clients and partners are welcomed too.\n- **Hanoi** (*coming very soon*): An office located in the tech district of the capital of Vietnam helps us be more available for more talents in the country.\n\n![](assets/2021-in-review_2021-danang-office.webp)\n\n## Expanding the Community\n- **[Dwarves Discord Network](http://discord.gg/dwarvesv)** hit 200 users in <4 months of launching in public. We offer various channels for the community to take part in, and a weekly 101 Tech session every Monday - 5PM.\n- **[WeBuild](http://webuild.community/)**: WeBuild Day 2021 turned out with +100 attendees. It was a sum up of what’s been trending in tech, from Build in Public, Developers in Covid Support, and the so-called NFT hype.\n- **[Vietcetera](http://vietcetera.com/)**: Techie Story has now landed a new space on this fast-growing media platform, officially marking a new milestone for us to keep spreading the inspiring tech stories.\n- **[Techie Story](http://techiestory.net/)**\n- **[Golang Vietnam](http://golang.org.vn/)**\n- **[Startup.vn](https://startup.vn/)**\n\n## Dwarves 1.0 In Numbers\n\n![](assets/2021-in-review_2021-dwarves-in-numbers.webp)\n\n## Highlighted Dwarves of 2021\nWe couldn’t go this far without the teammate’s hard work. To tribute all the effort our team has made to keep this woodland going further - we continue the annual tradition Dwarves of The Year. \n\nWith the subtotal prize value up to $10.000 - we equip the nominees with what they need to level up the game in 2022. \n\n### Dwarves of 2021\n\n![](assets/2021-in-review_2021-dwarves-contribution.webp)\n\n![](assets/2021-in-review_2021-dwarves-growth.webp)\n\n![](assets/2021-in-review_2021-dwarves-knowledge.webp)\n\n![](assets/2021-in-review_2021-dwarves-influence.webp)\n\n![](assets/2021-in-review_2021-dwarves-teamwork.webp)\n\n![](assets/2021-in-review_2021-dwarves-honorable.webp)\n\n## New Iconic Items \n\n![merch](assets/2021-in-review_2021-whats-new-december_2021-december-all-hands-meeting_fd61221cb31785842fecd3ff2339aab6_md5.webp)\n","title":"2021 In Review","short_title":"","description":"2021 notable highlights and achievements","tags":["updates","newsletter","wrap-up"],"pinned":false,"draft":false,"hiring":false,"authors":["tieubao","nikki","duy"],"date":"Fri Feb 05 2021 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2021-in-review.md","slugArray":["updates","changelog","2021-in-review"]},{"content":"\n### Moving with Blockchain\nWe shift our focus to real deals. \n\nMeanwhile, **#blockchain** **#web3** channels are there for the Dwarves to learn & exchange their knowns. Grab your seat.\n\nThe teammates also propose to join blockchain projects. We’re happy to onboard Hien, Tu, and Ngoc Mai on Spike Inu and Eklipse - and actively seek more chances for our teammates.\n\n![blockchain](assets/2021-whats-new-december_2021-december-all-hands-meeting_61172e1155a4a184faddc31bf62d492b_md5.webp)\n\n### Selective in Project Decision\nIt’s a promise of bigger clients & better team deployment.\n\nWe were able to drop the long-term projects that no longer match our business direction; successfully committed to **deploying a minimum of 3 Dwarves** for almost all remaining projects. With this change, we also **increased the headcount rate** as we believe it should grow alongside our ability to deliver.\n\n### Growing The Team\nA special congrats to Cuong Mai, Tom, & Ngoc Mai for passing the probation and becoming true Dwarves. Last month brought us Phat Ha, who’s currently in charge of Nghe Nhan Trading. The Dwarves are growing, by all means. \n\n![team](assets/2021-whats-new-december_2021-december-all-hands-meeting_e3077e1e538246f43986740a60bbe2a8_md5.webp)\n\nThe Dwarves have shown their ongoing ability to deliver more credible outputs within each project and were significantly endorsed by the clients.\n\nWe got Momos, Relay, BeaverBitcoin & Tokenomy as examples. Some Dwarves joined us lately, but they’ve already shown they’re the right person for the job.\n\n* Ngoc Thanh - Spike Inu\n* An Tran - Nghe Nhan Trading\n* Tom - LFW BE lead & study group lead\n* Hoang Nguyen - SP Digital\n\n### And The Attached Benefits\nThat growth explains our **upgrade in the benefits package**. We did a full upgrade on the team, from base salary to WFH station upgrade. You guys really earned this. \n\n### Office Status\nI think it’s safe to announce that one-way tickets to our remote hubs will be available by the 1st quarter of 2022. Additionally, we might host tech events, seminars, and training in Da Nang. \n\n### Dwarves of 2021\nA huge congratulations to our **[Dwarves of 2021](https://memo.d.foundation/changelog/2021-dwarves-of-the-year/)**! Please help to tick your wishlist items so we can proceed with them as soon as possible.\n\nWe’ve received much input to help improve the team. All of those ideas have been logged into our 2022 to-do list.\n\nAnd Dwarves, don’t forget to drop your info at Team Address - I’ll have these small gifts delivered to you real soon.\n\nHere’s to rock 2022!\n\n![doty](assets/2021-whats-new-december_2021-doty.webp)\n\n![merch](assets/2021-whats-new-december_fd61221cb31785842fecd3ff2339aab6_md5.webp)","title":"What's New in December 2021","short_title":"","description":"Each month, we release a recap noting all the significant changes with our company and our team. December 2022 will go over our growth in blockchain, team members, upgrade on the benefits packages.","tags":["updates","newsletter","blockchain","doty"],"pinned":false,"draft":false,"hiring":false,"authors":["duy"],"date":"Thu Jan 06 2022 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2021-whats-new-december.md","slugArray":["updates","changelog","2021-whats-new-december"]},{"content":"\nWe're closing July with some notable highlights. Let's go through them. \n\n🚨 Note: Covid situation is getting worse. Stay safe. 🦠\n\nThe pandemic is going stronger than ever. There have been over 100k internal cases in the country until now. Take good care of yourself and your beloved ones. We hope everyone can stay safe.\n\n### Finish the shipment for our WFH station\nWe've finished the shipment for all the WFH gear. Since the annual company trip can't be done this year, we hope it could help make the working vibe more enjoyable. It's great to know you're all happy with the new setup. \n\n![wfh](assets/2021-whats-new-july_2021-july-updates_733d0121febec06d18e9531f92400ab8_md5.webp)\n\n![wfh](assets/2021-whats-new-july_2021-july-updates_541d9540dd68b6a75696f615a1a6c879_md5.webp)\n\n### Your fleeting notes\nOn July 15, a few of our Dwarves shared a reward pool of $1000 for submitting their fleeting notes to our [brainery](https://brain.d.foundation/).\n\nSome even wrote the literature notes. You are awesome. Please keep it up.\n\nThe Brainery will be the backbone for our long-term growth\n\n### Office hour at Friday, 5pm — Ask the CEO anything\nWe're going fully remote. There might be a distance between you and the team. In case you seek guidance or direction on where we want to go, we have dedicated office hours from  **4:30 to 6 pm** in the Discord AMA stage channel.\n\nFeel free to ask the CEO anything: workload, feature requests, product discussion, or career advice. He's there to help.\n\n![officehour](assets/2021-whats-new-july_2021-july-updates_0b035e736bb615bcdde24b2efa950ec5_md5.webp)\n\n### Moving toward Blockchain industry\nWe're dipping our toes in the Blockchain pool by partnering with Legend of Fantasy War, a new NFT game project. \n\nAnother chance for us to get closer to this rising technology.\n\nSneak peek at the [landing website](http://legendfantasywar.com/).\n\n![nftgame](assets/2021-whats-new-july_2021-july-updates_4ac57a6a422a69aad933db59d4c43095_md5.webp)\n\n### Notion OS: Running our team from Notion pages\nNotion is our new document base. We've migrated our written document into this, as the new structure would be\n\n* Index: Shortcuts to websites, handbooks, repo sources & social channels.\n* Process: Compliance checklist & general docs\n* Client Portal: Contacts to the current project \n* Changelog: Our moving journey\n* New memo: Company blog\n\n## What's next in Aug\n**Brain Repo: Embedded & IoT R&D**\nWe plan to have a study group for IoT and embedded applications. The study group will be led by Trung & Hieu on Discord channel.\n\n**Performance review**\nPerformance review is starting next week. For those who wish to recognize your accomplishment, please prepare a 1 - 2 page summary to reflect your performance/achievement, following this guide\n\n* [Github](http://github.com/dwarvesf/handbook/blob/master/making-a-career.md#performance-review)\n\n### The value fit\nWe have a reason to go this far. Everyone has goals and pays attention to their value fit. We encourage the Dwarves to\n\n* Develop personal growth \n* Work hard for yourself\n* Ready for new opportunities\n\nMoving towards mutual goals is a condition to get along with your teammates. It matters to know what value you can add to the game.\n\n### Senior-level hiring\nWe are hiring again. This would be a massive focus on senior level to upgrade the A-team roster. And we need your help, please spread the message to your network.\n\nThanks Vy and Hoang for the referral. Thanks everyone else for sharing the post. It works.\n\n![hiring](assets/2021-whats-new-july_2021-july-updates_1b220da25eec9897a33cce413616f132_md5.webp)\n\n### Shaping our image\nHey, it's time to update your LinkedIn, Github or Facebook profile. It makes us look cool as a team. ","title":"What's New in July 2021","short_title":"","description":"Each month, we release a recap noting all the significant changes with our company and our team. July 2021 we will move toward blockchain industry and prepare for performance review in August.","tags":["updates","newsletter","wfh","team"],"pinned":false,"draft":false,"hiring":false,"authors":["duy"],"date":"Sat Jul 31 2021 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2021-whats-new-july.md","slugArray":["updates","changelog","2021-whats-new-july"]},{"content":"\nIt's been a long journey, but we've finally made it to 2022 and what a year it's been for our team of Dwarves. Countless hours of hard work and it's all paid off with our big wins of the year. Honored for all and huge congratulations to our Dwarves of 2022.\n\nA total of **~$18,000 awarded and rewarded by** [$ICY - Dwarves official token](https://www.facebook.com/photo.php?fbid=860144451875324&set=pb.100036393316096.-2207520000.&type=3), with a few names appearing several times. We congratulate the Dwarves who went above and beyond to make 2022 an unforgettable year for everyone.\n\n![doty](assets/2022-dwarves-of-the-year-1.webp)\n\n![doty2](assets/2022-dwarves-of-the-year-2.webp)\n\n![doty3](assets/2022-dwarves-of-the-year-3.webp)\n\n![doty4](assets/2022-dwarves-of-the-year-4.webp)\n\n![doty5](assets/2022-dwarves-of-the-year-5.webp)\n\n![doty6](assets/2022-dwarves-of-the-year-6.webp)\n\nThe best part is a true testament to the power of teamwork. We want nothing more than to ship products we're proud of and to become a company that offers its employees a great life.\n\nAs we step ahead to 2023, we're excited for what the future holds. Take on new challenges and continue to push the boundaries to achieve even greater success.\n","title":"Dwarves Of The Year 2022","short_title":"","description":"It's been a long journey, but we've finally made it to 2022 and what a year it's been for our team of Dwarves. Countless hours of hard work and it's all paid off with our big wins of the year. Honored for all and huge congratulations for our Dwarves of 2022.","tags":["updates","newsletter","doty","team"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_","nikki"],"date":"Thu Jan 19 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2022-dwarves-of-the-year.md","slugArray":["updates","changelog","2022-dwarves-of-the-year"]},{"content":"\nSuccessfully went through 2022, a year that we might say -  a new record: team reached highest growth record, kickstarted community engagement, home, compliance training & individual development are speeding up, and a whole new place to call Dwarves.\n\nWe’ve achieved to this year’s resolution: A team that cares about how to build software right and can teach others on that. \n\n## TEAM GROWTH\n### 30 New Team Members\n**[2022 matched us with the 80th Dwarves](https://github.com/dwarvesf/handbook)**. A notable highlight, and we're ready to have more. It's not easy finding like-minded people. It takes true & solid seeks. Even though people come and go, the spirits stay.\n\nExpanding the team doesn’t mean we have to disregard our culture. We have launched [a mechanism](https://memo.d.foundation/playground/_memo/passing-the-probation-get-3-upvotes/#the-talent-pool) to help us protect our culture and co-create our future using tech. For us, approval happens when someone is accepted by the team, not by management.\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_f3d04cda19cc5bfc2126f840d4dddf1d_md5.webp)\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_b6627bd506ccd793e7c6177b8c941947_md5.webp)\n\n*The Dwarves Collective, using markdown to visualize bonds between members.*\n\n### The Next Leading Chairs\nLaunching 3 offices across the country - Saigon, Danang, and Dalat, more initiatives to distribute our software know-how, and a **46% growth** in team scale calls for a different way to run the business. Shifting from a remote working model to a hybrid working model is a must, but it wasn’t easy. \n\nThe bigger team and the new model require more hands on deck. Instead of the old-school Board of Directors, we divide our leadership team based on what each member delivers.\n\n### R&D Team\nResearch and Development (R&D) came about as a collective department for solving common problems we encounter across all of our projects. As an innovative software firm, we found that the foundations for creating software are vital to making them successful.\n\nAfter its launch, the R&B has completed the first challenge: **Feature Flags**\n\nFeature Flags tackled a concern spanning across our DevOps, Management, and Engineering domains.\n\n* **Feature flags**: Options to enable/disable a feature in the application to help developers have a good experience and improve performance in the development process. We have discovered 3 solutions to resolve this challenge. With a wide range of solutions, we have the ability to serve any type of usage and project in development life.\n\n* **The detailed solutions:**\n * [https://viblo.asia/p/feature-toggle-BQyJK33QJMe#_introduction-0](https://viblo.asia/p/feature-toggle-BQyJK33QJMe#_introduction-0)\n * [https://dwarvesf.hashnode.dev/common-challenges-feature-flag](https://dwarvesf.hashnode.dev/common-challenges-feature-flag)\n* [https://medium.com/dwarves-foundation/design-a-feature-flag-system-7986b4a080cc](https://medium.com/dwarves-foundation/design-a-feature-flag-system-7986b4a080cc)\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_807095e97b173fac69c60aeffb7536ec_md5.webp)\n\n### Learning As The North-star Metric\n![](assets/2022-in-review_brainery-graph-1_compressed.mp4)\n\n*A 2022 look back on our Brainery timeline, with a total of 128 notes contributed.*\n\nThe concept of **“The Fastest Learners Win”** has always been big between the Dwarves. 2022 though, we opened our learning initiatives to the tech community. Everyone can join in to learn with us, sharing their experience with us, then get rewarded in return for their contribution.\n\nThe response so far has been amazing. We got words saying peeps get to upgrade their skills and work smoother in their projects.\n\nJust a bit of research on new tech could mean a job opportunity, or perhaps a turning point in their life that make them leaders in a new segment of an industry.\n\n* [Brainery](https://brain.d.foundation/): our knowledge hub, where we share what we learn with the world.\n* [Engage & Earn](https://memo.d.foundation/): our system recognizes people who put in the effort to share knowledge.\n* [Dwarves Tech Radar Volume 4](https://www.facebook.com/photo.php?fbid=833917351164701&set=pb.100036393316096.-2207520000.&type=3): a place for our engineers to trial and evaluate emerging technologies, and to help set the direction for Dwarves’ tech stack.\n* [Engineering Publication](https://memo.d.foundation/): our extra effort goes into learning and researching on how we can get better with technology.\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_1f5bd3a773b8f02d7f50d46102c2fa01_md5.webp)\n\n## Business Growth \n### Revenue Growth\nDespite the economic uncertainties across the globe in 2022, Dwarves has seen amazing growth and we are a profitable company. **Our revenue hits a new milestone, while the growth rate is estimated at 198% compared to the previous year.**\n\nStriving to create and go the extra mile for a generation of new tech enthusiasts, we build quality software and learn new things that generate a solid groundwork, receive good feedback from clients, robust growth, and everyone gets more profit sharing from the efforts.\n\n### Investment in Console, Chumbi and Tatsu\nOn our engineering journey in creating decentralized crypto applications, our partnership with **[Console Labs](https://console.so/)** has paved the way for new undertakings in creating scalable systems.\n\nAlong with encompassing know-how on designing system architectures, we’ve also helped with blockchain integrations, smart contract development, NFT launches, and greenfield development on blockchain tools. We're growing further with blockchain technology by investing i **[Chumbi Valley](https://chumbivalley.com/)**, and **[Tatsu](https://tatsu.gg/)** - NFT-based projects.\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_8e20d43e2280cb6d73b66cb32589d347_md5.webp)\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_3ffe6be8770c28e27e4cfb57fdc52141_md5.webp)\n\n### Level up Security & Cyber Protection\nWe are putting in place the security measures necessary to protect our clients. Bringing security setups to the next level for us means we are confident now safe and protected in terms of:\n\n* Device management\n* Network security\n* Location security\n* NDA (Non-disclosure agreement)\n* ACL (access control list) checklist to onboard / off-board\n\n### Game Department\nCame after [Summit 2022](https://memo.d.foundation/changelog/2022-dwarves-summit-engineering-a-good-time/), we’ve piloted a few games such as [Hunger Game](https://df-hunger-game.netlify.app/) and [Treasure Hunt ](https://hunt.d.foundation/)apps. Heading toward the engineering-driven vision, we founded a game department to create more engaging activities that offer our engineers and community a thrilling and adventurous gaming experience.\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_2307207050288356f6f0bdf691a75197_md5.webp)\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_85890bb5c8f1c3913cd7ab75bf307868_md5.webp)\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_491ec1fee97cb5ea2f004a8fb7161e0a_md5.webp)\n\n## Community Growth \n### Online Omni-channels \nThe Dwarves actively take part in developer networks to bring makers and tech enthusiasts together. Below is the list of [social channels](https://index.d.foundation/) that you can access for Dwarves sharing. \n\n* Social Media: **[LinkedIn](https://www.linkedin.com/company/dwarvesf/)**, **[Facebook](https://www.facebook.com/dwarvesf)**, **[Instagram](https://www.instagram.com/dwarves.foundation/)**, **[Twitter](https://twitter.com/dwarvesf)**, **[Memo](https://memo.d.foundation/)**\n* Streamline: **[Youtube](https://www.youtube.com/@dwarvesfoundation2350)**, **[Let's Hear IT ](https://spoti.fi/3xi92yY)[Podcast](https://rss.com/podcasts/dwarvestechevent/)**\n\nA variety of things, from lessons learned in a well-written format to Radio Talk live every Monday on Youtube and hanging out with techies at [Dwarves Discord Network](https://discord.com/invite/dwarvesv) where we talk about technology and life as developers can help you stay tuned with us. \n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_2efc2bdd5fc9eaa0c2e3cedd125136af_md5.webp)\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_0b08b0849c1f71ecd736377f09caa3d8_md5.webp)\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_7eb2878df66bc8e99728e180f5da4eb6_md5.webp)\n\n### Offline Contests\n**[Coding Camp](https://codingcamp.so/)** of Solana Vietnam was an incredible success, with over 2000 applications for the 8-week workshop, 200 selected developers, 51 projects on Demo Day, and nearly 100,000$ for the system of prizes.\n\n**[Mochi](https://mochi.gg/)**, a product we build in partnership with Console Labs, won the 2nd prize; **[Triple Pod](https://tripod-web.vercel.app/)**- Gamefi project won the excellent UX/UI and **[iCrosschain](https://icrosschain.io/)** - transaction platforms built on multichain won the second prize in Defi at Solana Vienam Coding Camp 2022  - Build Your Own Web Kingdom.\n\nWe are proud to be a part of the movement toward blockchain-based technology and become a web3-centric tech firm. Keep up the spirit of building, expanding, and evolving!\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_95ceffdd3b94a2cdf5685c867eade869_md5.webp)\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_39671de1e1c71865eb802461a2f0ee5c_md5.webp)\n\n## Workplace growth \n### Launching Home-like Dwarves Hubs in Danang and Dalat\nSince June 2020, we've been planning on a new office, a cozy studio in Da Lat and a summer house in Danang. It’s our **second initiative**: Dwarves Hubs should be placed across the country to offer our team a comfy remote experience when they need it. After the pandemic, as a new chapter, we’re proud of how it turned out, our first time went from sketches to reality - Danang and Dalat Hub. \n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_02e84402b9218f304990d32161fe679e_md5.webp)\n\n### 1-way Flight Ticket\nWe provide a package of flight tickets **4 times a year,** with a **maximum amount of 2.000.000 VND for each travel time**. With a borderless software firm, it's our mission to provide flexibility and support their will to go there. \n\nThese benefits supporting [#WFA]() culture:\n\n- **Flight Tickets Packaging:** Covering flying fees and commute fees for employees.\n- **Accommodation:** Equipping the office in ways that allow employees to stay at.\n- **Project team dinner:** Sponsoring monthly meetups for people working on the same projects.\n\nWith the new policies set out, our people can meet, work and bond with one another at any of those 3 locations. This will create a sense of inclusion and connection, regardless of the distance.\n\n### Summit 2022\nAfter 2 years of COVID together, we were able to finally able to organize our company trip to Phu Quoc. Hosting company trips was certainly on our To-do list, but there weren’t many opportunities to organize it during the pandemic. While trying to balance remote working, we realized everyone was long due for a fun break.\n\nSince we’re engineers, we thought it would be fun to create apps and games as a way to bond as a company outside physical activities. It was definitely a challenge to organize the games for everyone, but we certainly had fun doing it.\n\nFor the games, we offered a total reward of **150,000,000 VND (~$6,361.32)** to our winning teams to help motivate everyone to participate.\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_90b18b0bb44f42737b5dbcad91a970ab_md5.webp)\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_976fd6a1b95373654d8a8870692e52d3_md5.webp)\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_1b8011f8f951e36b240fff0df5282543_md5.webp)\n\n### Dwarves Apprenticeship\n**[The wrap-up of Dwarves Foundation Apprenticeship 2022](https://memo.d.foundation/careers/apprentice/dwarves-foundation-apprenticeship-batch-of-2022/)** scaled us with a new well-trained squad. After the program, all of our apprentices are now working on client projects and constantly learning new things along the way.\n\nAnother great outcome we got from this program: more seniors who participated in mentoring and training for the program moved forward into leadership.\n\nThe signal was clear, it was time we offered proper training and coaching for leadership, our next leadership batch consists of engineers who have seniority in client-facing experience, work discipline, domain expertise, quality management, and are ready to apply that into powering up the next generation at Dwarves.\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_f42ce11a992a281b7bde8ecd70c8f861_md5.webp)\n\n## Employee Experience\n### Launching $ICY for Dwarves’ Engage & Earn System\nWe’re big on **continuous improvements**: learning, sharing, and building a community of tech lovers. Hence, the launch of $ICY, [Dwarves' official token](https://memo.d.foundation/playbook/community/icy-in-2024/) to give back to everyone who contributes to our culture and activities. \n\nBuilt on Polygon, $ICY takes co-creation within Dwarves Network to the next level. Our monthly budget for rewarding ICY is around **500 ICY per month**, and will increase based on [community contribution](https://brain.d.foundation/Rewards+and+Recognition). If you’re interested in any of the cutting-edge activities within the Dwarves Network and want to contribute, we’re all for it.\n\n### Going Crypto Native, Pay Via USDT\nOur business builds and moves alongside the industry, so we know what it takes to become a crypto-native firm, our moves shift accordingly. It starts with two things:\n\n- **Selective in project deployment**: Block-chain based projects - [Cyber Nekos](http://pod.so/), [Triple Pod](https://tripod-web.vercel.app/)\n- **New option for monthly salary:** The team just rolled out a new option to receive monthly salaries through Binance.\n\n### Employee Referral Model\nThe team size has increased by 46%, a big part of the growth comes from people referring people. Our [referral program](https://github.com/dwarvesf/handbook/blob/master/how-we-hire.md#referral) is in place and open to everyone, not just the Dwarves. The suggestion, then, appears more valuable that you already know who the missing piece is. \n\nA quick suggestion on the talent pool:\n\n- Colleagues\n- University friends\n- High school peeps\n\nWe want to spend the bonus on you rather than the headhunting agency. Once the referral gets successfully converted into a full-time position and deployed to a project, the referrer will receive **2.5%** of the project service fee.\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_95d0da92d70d9f9296c5f6272250ad6f_md5.webp)\n\n![](assets/2022-in-review_2022-dwarves-renaissance-a-year-end-rewind_8a7a01a12a0d02bfbc4ea9dc305d68e1_md5.webp)\n\n## Onto the Dwarves 3.0\nThe future of Dwarves is a place where people are empowered to make decisions, where they can be confident in their abilities, and where they are working towards positive outcomes.\n\nOur centric world will thrive the Dwarves themselves are focused, trained and empowered. All of us will grow with Mastery, Meaning and Autonomous. Shaping the team day by day with the core values that move towards the engineering culture. \n\n- **Mastery:** we head toward craftsmanship, putting responsibility, professionalism, pragmatism and pride back into software development. Thereby contributing further to the quality of the outcome.\n- **Meaning:** the desire to do a software that has meaning and is important. We understand our place in the grand scheme of things, and that scheme has value and purpose, then we perform well.\n- **Autonomous:** provides employees with a sense of collective ownership. We aim to build a flat, transparent organization where everything runs around the mission.\n\n![](assets/2022-in-review_mma.webp)\n\n2022 brought us to a new great height, with Dwarves seeing growth in multiple aspects. This year has been one of the most memorable moments in our history.\n\nWith this momentum, this is only the start.\n\nAs we continue to extract the possible from the impossible, this year taught us, above all, that our voices — no matter how big or small — with the belief that software keeps changing the world.\n\nWe wish for all of you to have a great start for your journeys ahead.\n","title":"2022 In Review","short_title":"","description":"Successfully went through 2022, a year that we might say -  a new record team reached highest growth record, kickstarted community engagement, home, compliance training & individual development are speeding up, and a whole new place to call Dwarves.","tags":["team","wrap-up","newsletter","updates"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_","nikki","Tom"],"date":"Thu Jan 19 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2022-in-review.md","slugArray":["updates","changelog","2022-in-review"]},{"content":"\nWe don’t treat team bonding the common way because we understand our engineers. Most of our engineers don’t want to run and get sweaty on the beach for “team-building” activities, or pretend to smile in front of the travel agent’s camera.\n\nThis was our first company get-together after 2 years of COVID. It was organized in a way that we can all look back at the progress we’ve made, pat ourselves on the back, have a blast together, and look forward to an even better 2023.\n\n![](assets/2022-dwarves-summit-engineering-a-good-time_50d7ea1e7a9652013fd0cecdd7596784_md5.webp)\n\n## Remote First Company\nWe started with *Remote OK* back in 2017, following 37Signals, our tech crush at that time. In 2021, COVID took how we work to the next level. Since 2021, we have transitioned from a *Remote OK* to a **Remote First company** (except for some teammates due to the client’s security requirements). Our internal processes and engineers’ soft skills have been upgraded tremendously, making sure we perform smoothly across multiple time zones and geographies.\n\n## Team scale\nGrowing cross-functional teams at Dwarves is challenging, but it’s rewarding getting to collaborate with like-minded peeps. We’ve seen 1.5x growth of our team to a total of just over 100 team members, and everyone has given us unexpected and incredible results.\n\nAlthough it’s short of our 2022 goal of doubling the team, we’re very proud nonetheless.\n\n**In 2022 alone, we:**\n\n* Received 400+ applications \n* Invited 91 engineers for interviews\n* Onboarded 29 new teammates\n\nWhile the ratio of ~0.07% is astounding, it speaks to standards and quality. We are selective with who joins the team. For anyone who joins us, it’s a given they are pros at their jobs; they also need to love the culture we are working hard to protect and build up.\n\n## Partner & Business Growth\nWe never pay a single cent to run ads, and rarely ever participate in pitching for new projects. Clients come to us through their networks and connections. Someone works with us,is happy about our services, they refer us when someone else has a need.\n\nIn 2022, we grew to 6 partners who are willing to refer our services. These partners brought in 5 new projects, at a referral rate of 5-12% over the generated revenue.\n\n## Community Growth\nWe’ve been active in a few communities, such as the Golang community, Webuild, Techie stories, Startup.vn.\n\n**Dwarves Network**\n* [Techie Story](http://techiestory.net/)\n* [WeBuild](http://webuild.community/)\n* [Startup.vn](https://startup.vn/)\n* [Golang Vietnam](http://golang.org.vn/)\n\nMost especially, Dwarves Discord Network where every techie can join to hang out and learn has grown to 600+ members.\n\nWe’ve seen various tech-focused channels and events for the community,  as well as ways for everyone  [learn and earn](https://memo.d.foundation/). \n\n* **#engineering**: share our software know-how, programming advice, and technical insights.\n* **#learning-topics:** our knowledge-sharing system, where the Dwarves keep their learning, discoveries and helpful practice to build quality software.\n* **#blockchain:** where to find the knowledge piece to build the social layer for blockchain ecosystem.\n* **#campfire:** off-topics connect with our friends, alumni, and like-minded people.\n* **#minigame**: our Thursday minigame and happy hour for the Dwarves and communities. We work and have fun.\n\n## Company Trip Summit 2022\nSince we’re engineers, we know it would be more fun to create apps and games as a way to bond as a company outside of physical activities. Organizing the games for everyone was a challenge, but we certainly had a blast.\n\n![](assets/2022-dwarves-summit-engineering-a-good-time_66146aaca24382630125b7a70713cbbc_md5.webp)\n\nIt was all for 3 things: the games, the drinks, and the prizes. A total reward of **150,000,000 VND** (~$**6,000**) was distributed into 4 original engineering styled games:\n\n### Treasure Hunt\n\n![](assets/2022-dwarves-summit-engineering-a-good-time_f78cb4d5fd1925ce0559a5b36bc5675f_md5.webp)\n\nA location-based scavenger hunt where we took pictures of proof at locations along with answering questions in our custom-made web app. \n\nWhoever answers the most questions, wins the hunt.\n\n![](assets/2022-dwarves-summit-engineering-a-good-time_1ad6a2ad398abe7041cee20a627dc685_md5.webp)\n\n### Road to Olymwibu\nA 4-team game where teams choose multiple choice questions to answer across a range of topics to acquire points. Teams are also able to attack, steal, and double down on points.\n\nTeams who answer incorrectly would have to drink. 🍺🍺\n\nWhichever team has the most points wins the round.\n\n![](assets/2022-dwarves-summit-engineering-a-good-time_51be085fcfb86c123446d15a3155c0e7_md5.webp)\n\n### Hunger Games\n\n![](assets/2022-dwarves-summit-engineering-a-good-time_133221cf791f0d75a493e92a8571d763_md5.webp)\n\nA global turn-based 4-team 12x12 grid game played on a real-time web application to collect points scatted across the grid.\n\nTeams who encountered a fruit would gain points. Those who encountered a bomb would have to drink 🍺. Whichever team has the most points wins the round.\n\n### Enigma\nA writing game to XOR decrypt a hexadecimal message to ASCII with an ASCII key. \n\nThe message must be relayed through hand signs, with no devices or prepared items allowed for use to decrypt the message. \n\n![](assets/2022-dwarves-summit-engineering-a-good-time_cb8ef0a8d44685b07d5a41daea52ed8c_md5.webp)\n\nThe encrypted message and key given to the teams at the start of the game:\n\n```yaml\n\t\tencryptedMessage: 52 1B 53 3E 49 26 47 15 2B\n\t\tkey: goggins\n```\nThe expected output after decrypting the message in ASCII:\n\n```yaml\n\t\tmessage: 5t4Y H4rD\n```\nWe took the opportunity to drink and have fun and help teams earn a bit for their efforts. We’ve also certainly enjoyed our stay in Phu Quoc. Our team had fun swimming near the coast, enjoying food, riding rides at the water park, and exploring everything at Phu Quoc.\n\n![](assets/2022-dwarves-summit-engineering-a-good-time_3b0c68bef924599e58947f20cdf3a765_md5.webp)\n\n## Look forward to Dwarves Summit 2023\nWe’re really happy about how Summit 2022 turned out. We’ve had quite a lot of fun together as a team, and we are really excited about next year.\n\nLikewise, we’ve learned a lot during the trip and have taken a few steps ahead in planning for our next trip.\n\n* **Activities developed for engineers, by engineers.**<br>We want our people to have true, meaningful fun, so we want to open opportunities for our team to take part in developing games for not just our next trip but for everyone to enjoy.\n* **International trips.**<br>With the pandemic settling down globally, we will definitely have a look at places we haven’t been to and explore them together.\n* **Even bigger incentives.**<br>Allow everyone to earn and have fun doing so.\n* **Albums and videos for everyone to look back to.** <br>Create memories that everyone can take home, enjoy watching, and brag to their friends about.\n\nOur goal for next year is to incorporate **Mastery, Meaning, and Autonomy**. These are some of the things we have in our backlog, and we’re certainly excited to try out more when we get to it.\n\nHere’s to the restart of our adventures together and to many more experiences and opportunities for 2023!\n","title":"Summit 2022: Engineering A Good Time","short_title":"","description":"Having a blast company trip after 2 years of COVID, it didn’t happen in a common way. We planned our trip differently than others and designed apps for everyone to play as a way to bond as company outside physical activities.","tags":["summit","newsletter","team","updates"],"pinned":false,"draft":false,"hiring":false,"authors":["nikki","tom","innno_"],"date":"Mon Jan 09 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2022-summit-engineering-a-good-time.md","slugArray":["updates","changelog","2022-summit-engineering-a-good-time"]},{"content":"\n### Project Highlights\n**MStation as our latest blockchain-based project**\nIt's the first BSCS Metaverse blockchain game on Binance Smart Chain (BSC). Players can summon characters, complete daily mining missions, protect the MStation, and loot rare items to play and earn. \n\nWe get to deploy a full team for this project, consisting of 6 people, with Khai Le as part-time PM and Ngọc Thành as Team Lead.\n\nWe're getting multiple upselling requests, so we need more people to join our team. Dig through your network and refer to us for a handsome bonus! Positions we're hiring can be found **[HERE](https://memo.d.foundation/careers/hiring/)**.\n\n### Performance Review\nThe team has received all of the self-review notes. Due to the volume of our teammates, 1-1 meetings for some of you will soon be scheduled after the Lunar New Year.\n\nThe final result will be announced before March. Hope to see the good updates by then — if you know what I mean. \n\n### Study Groups/ Brainery Clean-up\nWe’re resuming Brainery Repo in 2022. Currently, the repo is getting formatted and cleaned up. We also develop writing guidelines to quickly pick up with the on-goings.\n\nThe reward mechanism for presenters and knowledge crafters is also back in the game. Ops Team has begun to recollect all the notes to ensure no effort is left behind.\n\n### Profit-Sharing & 13th Bonus Salary\nAll sent through Viet Nam bank & TWise. It’s a part of our culture and is applied for teammates who have joined us for more than 24 months. Everyone has put in their hard work to keep the team moving forward. Profit-sharing is the act of 'we reap what we sow'.\n\nTo read more on the model and other team benefits, I’ve got you the latest updates of **[Dwarves Handbook/benefit-and-perks](https://github.com/dwarvesf/handbook/blob/master/benefits-and-perks.md#employee-profit-sharing)**.\n\n### 1-way Flight Ticket Policy\nBased on the submission result, we’d love to enable this as soon as possible.\n\nGuys, let us introduce the latest DF Policy: **Flight Ticket Package**\n\nWho is this package for: Full-time members who have worked with the Dwarves for more than 6 months are eligible. The model goes as follows:\n\n* **4 times a year**, the Dwarves Team provides a commuting package to its members with a maximum amount of **2.000.000 VND/ time**.\n* The timeline of this trip is up to you. However, since this was made to encourage the team to try out our work hubs and get to know their teammates- **our destination must be either Da Lat or Da Nang**, and hopefully Ha Noi soon.\n* Trips need time to prepare (and recover afterward), so the team can’t use up the budget of 4 trips per year in one travel instance. This goes against the policy.\n* For better flexibility, we encourage you to actively make the booking and send us the receipt. The Ops team will help you process the reimbursement.\n\nTo sign up for your first trip, please head to this form: [https://forms.gle/SusWDKUn2KjkewBH6](https://forms.gle/SusWDKUn2KjkewBH6)\n\n### Team Hangouts\nLast month, we finally had the chance to gather for a casual dinner to wrap up the year. Now that the Covid situation is somewhat under control, we think it's safe to slowly resume this tradition.\n\nSince we have people in HCMC, Hanoi, and Danang, we can't all meet at the same place. Therefore:\n\n* We can have 1 sponsored team dinner per month.\n* We'll try to align so teams in all locations can hang out simultaneously, at least. Facetime can also be an option. Or team airdrop.\n* Ops will refund the expense in full.\n\n### Lunar New Year Gift-set Delivery\nAll wrapped and delivered!\nA small gift to thank you for being with us for the past year. May we all enter 2022 with success and prosperity. \n\nHappy the year of Tiger. Let’s rock 2022 together!\n\n![merch](assets/2022-whats-new-january_2022-january-updates_bd881f2df5fc45b3831edf17c1ceef53_md5.webp)\n","title":"What's New in January 2022","short_title":"","description":"Each month, we release a recap noting all the significant changes with our company and our team. January 2022 will go over performance review and our growth on projects, new year highlights.","tags":["newsletter","updates","blockchain"],"pinned":false,"draft":false,"hiring":false,"authors":["nikki","duy"],"date":"Fri Jan 28 2022 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2022-whats-new-january.md","slugArray":["updates","changelog","2022-whats-new-january"]},{"content":"\n## Foundation\n### Project Allocation\nWe concluded the partnership with Relay and Eklipse. It has been a fun (and wild) ride for some of you. New resources are being allocated to help balance the current workload of active projects. If you need to discuss your workload or seek more room for project work, please ping Giang or Nikki.\n\n### Our view on Blockchain\nGot a quick chat with Ngoc Thanh, our Sr. Blockchain Engineer and his perception of blockchain at **[Memo](https://memo.d.foundation/DF-Apprenticeship-2022-Meet-The-Mentors-Ngoc-Thanh-Pham-a6f8c3c7d4a14bd5be55d6465b9f330b)**.\n\nBlockchain is taking shape in how we run the team. Peeps, please help update your insights if you haven’t. We have study groups and discussion channels. Peeps who are familiar, we’d be glad if you could share what you’ve learned with the rest of us.\n\n## Growth\n### Kicking off Apprenticeship Training\nThe training phase kicked off last week with 7 new Apprentices. To keep up with the latest session, check out that Event button in Discord space and click ‘**Interested**’ to see what you prefer. More room still needs improvements, but we’re following the right track.\n\n### Onboarding new Interns\nWe got 4 new Interns from Bach Khoa this summer. They’re all excited to pick up new workflow and work with mentors. Can see the real progress happening through their daily updates. \n\n### Data Team Form-up\nAnother direction besides blockchain? Data. Tom and Dung are the first members to take care of this. Data is becoming more and more critical to how we shape businesses. Having teammates with thorough insights on this will support us to go further.\n\nPing Tom if you want to be part of the squad. And stay tuned for Dung’s first sharing on **Apache Spark**, coming this **[Jun 06 - 5PM](https://www.youtube.com/live/6nini4cmk1E?si=8sFJdTNFv3CypQCe)**.\n\n### Revisit the Radio Talks\nHighlights will be summarized and shared through Memo to those who want to keep up:\n\n* [**React 18**](https://memo.d.foundation/playground/_memo/react-18/)\n* [**Remix versus Next.js**](https://memo.d.foundation/playground/_memo/remix-versus-nextjs/)\n\nFeels more like listening? Pay a visit to **[Dwarves Youtube](http://www.youtube.com/channel/UC_SyzGLf6wiqctQFsRI_frw)** for every streaming.\n\n![radiotalk](assets/2022-whats-new-may_2022-may-all-hands-meeting_68bd765a75c1591b2074d672d1d123e5_md5.webp)\n\n## Team\n### Dalat Office\nAs in the last update, the office is set for you to visit, but more updates are still coming. Rock fences and plant dividers are newly added to enhance our space.\n\nThe balcony was also retouched. And hear us out, standing desks will be a thing in this work hub.\n\n![dalat](assets/2022-whats-new-may_2022-may-all-hands-meeting_946b29130bc76f1374d606747319db5a_md5.webp)\n\n![dalat](assets/2022-whats-new-may_2022-may-all-hands-meeting_c8dfb110e429e31cac8a2066dfb56046_md5.webp)\n\n![dalat](assets/2022-whats-new-may_2022-may-all-hands-meeting_1c48a97cb9d7384b03048e4718d98744_md5.webp)\n\n## Coming up next\nWe’re moving with the industry. The current trend has been revolving around blockchain. You may hear some Dwarves have dipped their toes into blockchain work in partnerships with Spike Inu, Nghe Nhan Trading, MStation, or Pod Town.\n\nHenceforth, we strongly encourage the team to expand their know-how in this field, starting with smart contracts. The Senior Dwarves will also advance further in this direction, through training, project works, and even self-development.\n\nAll these efforts aim to align with our business goals. We’re sorting more resources to help with new partnerships coming up.\n\nLet’s cross our fingers and buckle up for what’s next in June. \n","title":"What's New in May 2022","short_title":"","description":"Each month, we release a recap noting all the significant changes with our company and our team. In May, we kicked off Apprenticeship training, and our new chalet is ready for community to visit.","tags":["newsletter","blockchain","internship","updates"],"pinned":false,"draft":false,"hiring":false,"authors":["duy"],"date":"Tue May 31 2022 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2022-whats-new-may.md","slugArray":["updates","changelog","2022-whats-new-may"]},{"content":"\nAs we enter a new year, I want to reflect on the role that software has played in my life. From the early days of my career to now, software has been a constant presence and something that I have dedicated countless hours to as both an engineer and project manager. I have put in over 10,000 hours of work in this field, and it has become an integral part of my existence.\n\nNot only is software a crucial aspect of my personal life, but it is also a vital part of humanity's technological advancements. The history of software development stretches back to the 1940s, with the first mechanical computer, the Babbage Difference Engine, designed by Charles Babbage in 1822. Even further back, in 1843, mathematician Ada Lovelace published an algorithm intended to be carried out by Charles Babbage's Engine, making it the first computer program.\n\nAs we look at the current state of software and consider the future, it is clear that software will continue to evolve and shape our world. The old generation of software has already made its mark in history, the current generation is displaying its importance, and the next generation of software will be different. And we, as members of this exciting industry, have the opportunity to shape and participate in this evolution.\n\nI know that for many people, software is simply seen as a tool for living or as a job opportunity. However, I believe there is a deeper meaning to being a part of this industry. This year, I want to remind us of the significance of our roles and the impact we can have on shaping the future.\n\nFor Dwarves 2.x, our goal has always been to be a borderless software firm. As we move into 2022, we are one step closer to achieving this goal. We strive to operate in new and efficient ways, different from the rest. Some of us are working with our peers to help ship their software, while others are building their own projects and striving for excellence. We are all making our way towards achieving excellence in our field.\n\nAs I always say, *coding to survive is basic, shipping software with pride is admirable, but building a software empire is truly fulfilling*. My dream is for Dwarves to be present around the globe, building and shipping the things they love with their preferred setup, all while having fun.\n\nLast year, my theme was Elixir for everything, and I will continue working on it this year. I believe that this technology has the potential to revolutionize software development and I am excited to see the advancements it will bring in the future.\n\nI wish everyone health and prosperity in the new year. Good luck to us all as we continue to strive for greatness in our field.\n\n![](assets/2023-happy_1e89b732d608e54d1edb7239b5c5c692_md5.webp)\n","title":"Happy 2023","short_title":"","description":"As we enter a new year, I want to reflect on the role that software has played in my life. For Dwarves 2.x, our goal has always been to be a borderless software firm. As we move into 2022, we are one step closer to achieving this goal. We strive to operate in new and efficient ways, different from the rest. Some of us are working with our peers to help ship their software, while others are building their own projects and striving for excellence. We are all making our way towards achieving excellence in our field.","tags":["newsletter","software engineer","updates"],"pinned":false,"draft":false,"hiring":false,"authors":["tieubao"],"date":"Sun Jan 22 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2023-happy.md","slugArray":["updates","changelog","2023-happy"]},{"content":"\n> **Before you dive in**\n> Dwarves is operated as a 50% company, 50% community. Everything we learn along the way of work, we transform into knowledge and distribute back to our tech community.\n>\n> If you want to get in touch, visit [Dwarves Network](http://discord.gg/dwarvesv)\n\nIn December, we launched our Consulting Team, released our finding on tech trends, and last but not least, got everyone ready to wrap up 2023.\n\n- **[Reporting Tech Signals](#reporting-tech-signals)** - We stay ahead by monitoring high-potential trends in tech.\n- **[Launching Consulting Team](#launching-consulting-team)** - Dwarves Consulting is shaping up.\n- **[Performance Review](#performance-review)** - The Dwarves way. We don't just base our review by performance, but also on everyone's effort to grow in their career.\n- **[Dwarves of the Year 2023](dwarves-of-the-year-2023)** - Time to tribute and reward team members who made significant impacts to our growth.\n- **[Join our team](#join-our-team)** - Admin / Ops, BD, Tech Recruiter\n\n## Reporting tech signals\nTechnologies move fast. We're not ones to get left behind. Every month we watch tech trends closely to depict which ones have high potential, and can be part of our growing tech stack.\n\nThis month highlights strong signals on AI gaining mainstream traction, the comeback of WebGPU, Actor Model in computing, Security and ComplianceAsCode, nNFT standards for asset provenance. And programming-language-wise: Rust, Lua Dart.\n\nFor the full read, [come here](https://note.d.foundation/labs/market-report-dec-2023/).\n\n## Launching Consulting Team\n[Dwarves' Consulting team](https://memo.d.foundation/consulting/) consists of anyone who’s hungry for more than just coding.\n\n- **Team of Specialists**: we favor collective expertise, knowledge sharing and collaboration, to craft innovative solutions that exceed expectations.\n- **Innovative Mindset:** we encourage out-of-the-box thinking, experimentation, and creative problem-solving.\n- **Transparent Communication**: we lay everything out on the open, fostering a collaborative environment that promotes trust, clarity, and alignment.\n\n![consult](assets/2023-whats-new-december_consulting-who-should-join-us-20231221144422875.webp)\n\n## Monthly top performers\nEach month we track how productive and valuable each of our team members by using delivery points. For now, the top 5 high-performing members get rewards with $ICY. In Dec, kudos to those peeps who outperformed the rest: Nam Nguyen, Lap Nguyen, Ngoc Thanh, Jim and Hung Vong.\n\nLast month we also shipped quite a number of features, highlighting:\n\n- [Mochi UI](https://mochiui.com/) - an open source IU library for every software project\n- Rust game - an inhouse game we're developing for our upcoming summit\n\n## Dwarves of the Year 2023\nIt's been one of our longest tradition, to tribute and reward team members who made significant impacts to our growth. Dwarves of the Year 2023 is brewing up with various categories and a total rewards of $25k.\n\n![doty](assets/2023-whats-new-december_whats-new-december-2023-20240103153356468.webp)\n\nOn Jan 13th, we're flying non-Saigon peeps to Saigon so everyone can get together and party their hearts out!\n\n## Performance Review\nThe Dwarves way. We don't just base on our review by performance, but also on everyone's effort to grow in their career. As our theme for the year is MMA (Mastery, Meaning, Autonomy), we develop a system of metrics to make sure our engineers are not only skilled, but also head toward higher purpose.\n\n## Community\n- Top contributors to our Discord server this month brought in a lot of new knowledge. Thank you, and we hope you enjoy your $ICY rewards.\n- Techie's [Tiktok](https://www.tiktok.com/@techiestory.net) reached 16k followers! We're happy to be reaching new people through each story. And you can always let us know whose story you'd want to know, we'll try to make it happen!\n\n## Join our team\nWe are looking for the following talents to join our team\n\n- [Admin / Ops]() (Fulltime)\n- [Technical Recruiter]() (Fulltime)\n\nEmail us at spawn@d.foundation or ping @nikki on Discord for JDs / to refer someone you know. TIA!\n\n## FAQ\n**Q: Do Dwarves offer internships?**\n> Currently we don't have any internship positions available. Dwarves facilitate apprenticeship and internship as a program, instead of individually. News about these programs will be updated on [note.d.foundation](noted.foundation).\n\n**Q: How can I contribute to Dwarves network?**\n\n> Everyone can contribute knowledge in our [Discord](http://discord.gg/dwarvesv) and/or contribute to our [Bounties](http://memo.d.foundation).\n> All valuable contributions will be rewarded in ICY ( 1 ICY ~ $1.5)\n\n**Q: Do Dwarves have any events?**\n\n> We have these reoccurring events:\n>\n> - Radio Talk (Weekly, Monday): sharing technical learning, demos, showcases\n> - Tech Event (Monthly): sharing programming trends, tech trends, panel discussions\n> - Community Call (Monthly): summary wins and growth of the month\n","title":"What's New in December 2023","short_title":"","description":"In December, we launched our Consulting Team, released our finding on tech trends, and last but not least, got everyone ready to wrap up 2023.","tags":["newsletter","performance-review","doty","updates"],"pinned":false,"draft":false,"hiring":false,"authors":["nikki"],"date":"Wed Jan 03 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2023-whats-new-december.md","slugArray":["updates","changelog","2023-whats-new-december"]},{"content":"\nLast November, we kicked off the Labs team, introduced Salary Advance for the Dwarves, upgraded note.d.foundation, supported Golang meetup, and demonstrated craftsmanship through various case studies and demos.\n\n- **[Launching Labs team](#launching-labs-team)** - Dwarves R&D team is officially in operation.\n- **[Monthly top performers](#monthly-top-performers)** - The top 5 high-performing members get rewards and NFT badges. NFT badges can be staked to earn shares of the company.\n- **[Salary Advance](#salary-advance)** - Dwarves' team members now can get an advance of their monthly salary in case of emergency.\n- **[memo.d.foundation](#misc)** - upgraded homepage, categorized content, and now searchable.\n- **[Join our team](#join-our-team)** - React Native Developer, Admin / Ops\n\n## Launching Labs team\nWith Labs team, it's all about researching cool, industry-moving technologies and producing practical use cases using those tech. In our backlog: WASM, Passwordless, Rust, AI, MPC, UI practices, Elixir, Golang.\n\nHead to [November Forward Engineering](https://note.d.foundation/memo/forward-engineering-november-2023/) for more details.\n\n![engineering](assets/2023-whats-new-november_whats-new-november-2023-20231206133445648.webp)\n\n## Monthly top performers\nEach month we track how productive and valuable each of our team members by using delivery points. For now, the top 5 high-performing members get rewards with $ICY. In Nov, kudos to those peeps who outperformed the rest: **Hai Huynh, Chinh Le, Phat Nguyen, Minh Tran, Ngoc Thanh.**\n\nLast month we also shipped quite a number of features for our clients: [time-sensitive alarms for a trading platform](http://hedge.foundation), [money transfer with Mochi](http://mochi.gg), live annotation for various content formats, user signup/login flow at kiosks.\n\nComing next: NFT badges. NFT badges can be staked to earn shares of the company.\n\n## Salary Advance\nDwarves' team members now can get an advance of up to 25% of their monthly salary. The payment is made in $ICY and can be redeemed via https://icy.so\n\nThis bot command can be used in our Discord server, and anonymously :)\n\n![salary](assets/2023-whats-new-november_whats-new-november-2023-20231206133455685.webp)\n\n## Misc\n- Our Discord server is for everyone. We're happy to see ~400 active users last month, and of course, the top ten voices in get 5 $ICY each.\n- More bounties are up for grab: https://memo.d.foundation/earn/\n- Techie story are now on [Tiktok](https://www.tiktok.com/@techiestory.net), highlighting 4 stories about life in tech in US & Japan\n\n## Join our team\nWe are looking for the following talents to join our team\n\n- React Native Developer (Project-based Contractor)\n- Admin / Ops (Fulltime)\n\nEmail us at spawn@d.foundation or ping @nikki on Discord for JDs / to refer someone you know. TIA!\n","title":"What's New in November 2023","short_title":"","description":"Each month, we release a recap noting all the significant changes in our company and our team. November is our month for meetups and outstanding craftsmanship.","tags":["newsletter","meet-up","golang","updates"],"pinned":false,"draft":false,"hiring":false,"authors":["nikki"],"date":"Wed Dec 06 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2023-whats-new-november.md","slugArray":["updates","changelog","2023-whats-new-november"]},{"content":"\n> **Before you dive in**\n> Dwarves is operated as a 50% company, 50% community. Everything we learn along the way of work, we transform into knowledge and distribute back to our tech community.\n>\n> If you want to get in touch, visit [Dwarves Network](http://discord.gg/dwarvesv)\n\nEach month, we release a recap noting all the significant changes in our company and our team. October's highlights include:\n\n- **[note.d.foundation](#notedfoundation)** - The wiki of how we work, learn, and operate the team at Dwarves.\n- **[New functional teams](#new-functional-teams)** - A single core team expands into 5 functional teams for better delivery.\n- **[MMA-based career development](#mma-based-career-development)** - Mastery, Meaning, Autonomy allow us transparency in what we do and ways to provide growth paths for everyone based on their interests.\n- **[Frontend Course 2023](#frontend-course-2023)** - Our free FE Course is successfully finished with a fun demo day.\n- **[Wrapping up Droppii](#wrapping-up-droppii)** - We completed our mission of helping Droppii build up their tech foundation and products.\n\n## State of Dwarves\nFor a tech team like Dwarves, there are only a few things that matter. Coming to the end of the year, we're reflecting and re-enforcing what matters to us.\n\n- Cross-team transparency: we're bringing more documentation, reports, cross-team meetings so everyone knows what the others are up to.\n- R&D: fueled by innovations, more hands are joining R&D to learn the next best thing in tech and programming.\n- Diverse projects: we are now more open to whichever projects that can promise an exciting challenge, regardless of domain, scale, or duration.\n\n## note.d.foundation\nWe think of this site as our company wiki. It's where we note (hence the name) and share everything we learn as a team and as a community, knowledge-wise and operation-wise.\n\n![informationflow](assets/2023-whats-new-october_information_flow.webp)\n\nWith [note.d.foundation](noted.foundation), we hope the time and effort we spent in the tech industry will become valuable lessons and stories for everyone who also cares about technology and innovation as we do.\n\nCommunity members are welcome to share their learning notes too. Simply drop a message in relevant channels in our [Discord](http://discord.gg/dwarvesv)\n\n## New functional teams\nIn October, we reorganized the core team into 5 functional teams with clear responsibilities and deliverables. Each team has its own thing and operates all differently. Different ways of facilitating activities, creating team bonds, delivering results and getting rewards.\n\n- Labs: folks learning, researching emerging tech\n- Consulting: folks using software to improve biz results\n- Console: folks focusing on products\n- Techie: folks enjoying celebrating humans in tech\n- Ventures: investing in cool tech teams and products\n\n## MMA-based career development\nThe only legit performance indicator at Dwarves is MMA; Mastery - Meaning - Autonomous.\n\n- Mastery: Are you highly talented and skilled? Are you doing anything to become even better?\n- Meaning: Do you work just for the money, or do you have a purpose in the tech industry?\n- Autonomy: Are you proactive? Are you a high performer?\n\nSince we adopted this model last year, everything we do revolves around it. Thanks to the consistency, we have been able to see improved performance, higher drive at work, more transparency across project teams, and more peeps expressed their interest in R&D activities.\n\nFrom there, we design personalized growth paths, that fit their interest. With enough effort and grit, soon we will see the next part of teammates taking part in the 5 functional core teams.\n\n## Frontend Course 2023\nOur free FE Course is successfully finished. The stats are astounding, because compared to our previous Golang Course, there is a 4x jump in participants. We believe this signal shows what we do is being well received by the tech community in Vietnam.\n\n## Wrapping up Droppii\nWhen [Droppii](http://droppii.com/en/) first came to Dwarves, their products were built on an outdated tech stack and couldn't handle their fast-growing user base.\n\nWhen we came on board as a technical partner, we helped develop the tech foundation, shape up their processes, and also participate in development. After 15 months, we have completed our mission of helping Droppii build & run their own tech team, and shipping 4 different products.\n\n## Community Growth\n- Discord welcomes 2050 members in total. Lots of good stuff on tech being shared at #tech #til #random\n- Top 10 voices contributing to our server get rewarded in ICY\n- [Techie Story](http://techiestory.net) fanbase reached 8.8K members\n- Elixir Meetup in Saigon was a fun experience for the team\n\n**Coming up:**\n- Golang Meetup\n- Techie x Webuild Summit\n\n## FAQ\n**Q: Do Dwarves offer internships?**\n\n> Currently we don't have any internship positions available. Dwarves facilitate apprenticeship and internship as a program, instead of individually. News about these programs will be updated on [note.d.foundation](noted.foundation).\n\n**Q: How can I contribute to Dwarves network?**\n\n> Everyone can contribute knowledge in our [Discord](http://discord.gg/dwarvesv) and/or contribute to our [Bounties](http://earn.d.foundation).\n> All valuable contributions will be rewarded in ICY ( 1 ICY ~ $1.5)\n\n**Q: Do Dwarves have any events?**\n\n> We have these reoccurring events:\n>\n> - Radio Talk (Weekly, Monday): sharing technical learning, demos, showcases\n> - Tech Event (Monthly): sharing programming trends, tech trends, panel discussions\n> - Community Call (Monthly): summary wins and growth of the month","title":"What's New in October 2023","short_title":"","description":"Each month, we release a recap noting all the significant changes with our company and our team. October is our month for open-source and reflections.","tags":["open-source","newsletter","community"],"pinned":false,"draft":false,"hiring":false,"authors":["nikki"],"date":"Fri Nov 10 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2023-whats-new-october.md","slugArray":["updates","changelog","2023-whats-new-october"]},{"content":"\nAt the end of May, we had the pleasure of hosting our second community meet-up. With over 50 folks, including notable community members @jack, @congiomat, and @tannhatcms, it was a meaningful gathering.\n\nA key part of the meet-up was a discussion on “Building a Resilient System” led by @hoangnguyen and @hieuthu2. Their insights encouraged thoughtful conversations and provided design system knowledge to everyone present. We also caught up with the latest happenings at Dwarves.\n\nAfter the discussion, we had a chance to bond and share stories over a casual dinner and drinks, creating a warm and supportive atmosphre within our community.\n\nAt the same time, feedback from members gave the team more motivation to improve for the next offline session. @congiomat shared that he was happy with the meeting content and found everyone very friendly. He saw the second meet-up was already a great success.\n\nWe organize these meet-ups every three months to share knowledge and connect people. Whether you're a partner, an alumni, or simply interested in what we do, you're always welcome to join us.\n\nWe are grateful to our operations team for ensuring the event went smoothly. We look forward to our next gathering and hope to see even more of you there.\n\nIf you’d like to be a part of the Dwarves network, we’d love to have you at our [discord](discord.gg/dwarvesv). \n\nSee you next time.\n\n![](assets/dwarves-2nd-community-meet-up_dwarves-2nd-meetup.webp)\n","title":"Dwarves’ 2nd community offline meet-up","short_title":"","description":"At the end of May, we had the pleasure of hosting our second community meet-up. Over 50 folks, including notable community members, joined us.","tags":["meet-up","community","newsletter"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Tue Jun 11 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2024-community-meet-up.md","slugArray":["updates","changelog","2024-community-meet-up"]},{"content":"\n> **Before you dive in** Dwarves is operated as a 50% company, 50% community. Everything we learn along the way of work, we transform into knowledge and distribute back to our tech community.\nIf you want to get in touch, visit [Dwarves Network](http://discord.gg/dwarvesv) \n\nClosing another milestone with 2024, it has been a year of building and rebuilding — strengthening what works, fixing what doesn’t, and uncovering new paths along the way. Every milestone reached this year carries the marks of teamwork and persistence.\n\nMarket shifts opened new territories, while our core in sharing knowledge and AI grew stronger. We turned AI from experiments into daily tools, grew our lab team into a real force for innovation, and watched 37 OGIF sessions turn into solutions everyone uses. Knowledge sharing became part of our DNA, with 335 memo entries proving that good ideas need to be shared.\n\nStarting with a handful of tech enthusiasts, our community now spans across different domain. For a tech team like Dwarves, there are only a few things that matter. Let’s reflect and reinforce what matters to us.\n\n# Team growth\n## memo.d.foundation: Capturing a year of collective knowledge with 335 entries\n[memo.d.foundation](https://memo.d.foundation/) started as a company wiki and grew into a central hub for documenting what we learn as a team and community. From tech know-how to operational know-how, it's all here. **With 335 entries published this year**, it shows how knowledge sharing has become part of our DNA.\n\nThe focus on Mastery, Meaning, and Autonomy (MMA) drove real growth in our knowledge base. You can see it in the increased contributions, covering everything from practical work solutions to foundational concepts. \n\nHighlights:\n\n- Streamlined memo submissions with quick commands like `?memo pr` and `?memo list`.\n- Real-time PR notifications in Discord for easier collaboration.\n\n![](assets/2024-in-review-memo.png)\n\n## OGIF: When learning and sharing became part of our DNA\nEvery Friday at 5PM, we gather on Discord to share what we've learned. **37 sessions** this year, each adding something useful to how we think and work.\n\nThe idea stays simple: take 10 minutes to teach everyone learn something new. From coding patterns to market shifts, if it helps, it belongs here. We've covered everything from Go weekly, system design, AI/LLM, blockchain to product design and tech signal reports.\n\nOGIF showed us who digs deep into problems, who explains clearly, who brings different angles. These talks helped form our labs’ team naturally.\n\n## ICY in 2024: A reward system knowledge powers team growth\nLaunched in September 2022, ICY was used to reward for all members for engaging in discussions, research on Dwarves’ tech, and more.\n\nThis year, a monthly pool of 2500 ICY (~$4000) sparked more learning than we anticipated. When AI and LLM insights took center stage, we tripled the rewards to keep good ideas flowing.\n\n**6,660 ICY (~$9k)** distributed highlighted our commitment to learning together, with 70% of rewards going to AI/LLM, Golang, Software Architecture, and Blockchain. Made sense, given how fast this space moves. Check it out at [🧊・earn-icy](https://discord.com/channels/462663954813157376/1006198672486309908/1239502938918096960).\n\n**Key contributors:**\n\n- **OGIF Talks:** @fuatto, @datnguyennnx, @monotykamary, @hoangnnh, @lapnn, @nambui.\n- **Memo Notes:** @thanh, @hoangnnh, @datnguyennnx, @fuatto.\n- **Bounties:** @bienvh, @innno, @minhcloud, @quang.\n- **Tech sharing:** @monotykamary, @phucld, @minhlq, @antran, @huymaius, @datnguyenxx.\n\nICY enhancements included moving contracts to Base chain, GitHub account linking, and laying the groundwork for NFT and staking opportunities. Even guests now earn ICY - a warm welcome and simple way to reward collaboration.\n\n![](assets/2024-in-review-icy.png)\n\n## Team copilots: AI tools that made workflows faster\nWe didn’t just build tools; we shared them. The team copilots index became a collection of practical solutions, built by us, for us, and ready for the team to use. \n\n**Why it mattered:**\n\n- Tools solving real problems, tested and proven by teammates.\n- A hub for sparking ideas to build your own copilots.\n- AI helpers simplifying and speeding up daily tasks.\n\nYou can explore the full list of copilots [here](https://memo.d.foundation/playground/ai/copilots/team-copilots).\n\nThe focus was never on complexity but on simplicity and utility. Every tool was built with a clear purpose: to help the team do better work with less friction.\n\n![](assets/2024-in-review-team-copilot.png)\n\n## Internal tools upgrade: How Fortress, Tono, and Mochi automated operations\nOur Discord bots got some nice upgrades this year, thanks to @hnh, @tom, and @bienvh putting in the work. Each improvement made day-to-day stuffs easier, from tracking contributions to sharing knowledge.\n\n- Tonobot streamlined tracking contributors, created helpful reading lists, and introduced the `sum` command (thanks to @nam and @tom) for breaking down links into concise insights. It made spotting activity and key content easier.\n- Fortress enhanced real-time memo updates, delivered detailed weekly reports, and improved issue tracking. Progress tracking became seamless, ensuring important details never slipped through.\n- Mochi brought a virtual kudos system for recognizing contributions, boosting community spirit with simple yet meaningful appreciation.\n\nThese updates came from understanding team needs and making them happen. Simple improvements that lead to smoother workflows.\n\n![](assets/2024-in-review-fortress.png)\n\n![](assets/2024-in-review-tono.png)\n\n## Weekly Commentary: Turning trends, insights into actionable items\nAs a research-focused team, collecting and sharing knowledge became part of our speed. We saw it in our velocity - shipping got smoother when everyone knew more. \n\nThis year, our weekly updates grew from Go-weekly insights into a broader lens on what we’re building and learning as a team. \n\n**Commentary series expanded into four practical domains**\n\n- **Go weekly** grew with @fuatto's Enterprise MOC, showing how we're using Golang for real business challenges.\n- **AI Digest** delivered clear, tool-focused updates for applying AI effectively.\n- **Product Design Weekly** offered actionable UI/UX tips that go beyond surface-level advice.\n- **Consulting Snapshot** highlighted key tech and business trends that matter.\n\nWeekly OGIF sessions and memo notes kept the insights flowing. Each series aims for the same thing: useful knowledge you can put to work.\n\n![](assets/2024-in-review-commentary.png)\n\n## AI Club: Adapting to change with smarter workflows and practical AI tools\nThe **🧙・ai-club** opened its doors this year. It became a hub for exploring AI and Large Language Models (LLMs) while delivering tools that made an impact on daily workflows.\n\n- **🧙・ai-club** served as a collaborative corner, designing AI agents tailored to projects, from coding accelerators to workflow enhancers.\n- The **ai-sheep role** recognized those engaging with AI through shared content, lightning talks, or practice tasks, encouraging contributions from all levels of interest.\n- **Copilot Bounties**: rewarded meaningful contributions, whether insights, tools, or advancements in AI/LLM applications.\n\nThe AI-Club showed us what happens when team effort meets focused exploration: smarter tools, better workflows, and new skills to take forward.\n\n## Research topics 2024: Exploring 40 topics on the most promising technologies\nGood tech solves real problems, and that’s what drives us. **40 topics stood out,** each selected for its impact and relevance.These topics were pitched, prioritized, and led by the team with input from senior members:\n\n- **Tooling:** Streamlined workflows using tools like Devbox, Colima, and better monitoring systems.\n- **Architecture:** Explored event-driven systems and modular design for scalable solutions.\n- **LLM:** Applied RAG and MLOps to practical, real-world use cases.\n- **Blockchain:** Investigated Solana’s infrastructure and evaluated blockchain models.\n- **Security:** Focused on zero-trust systems and robust practices to enhance safety.\n\nKey actions included leveling up **Tono Bot** and **Memo** with RAG, refining **Devbox** with better organization, and solidifying our **Cybersecurity Framework**.\n\nWe’re happy to have everyone on board and joining hands.\n\n![](assets/2024-in-review-research-topics.png)\n\n## Connecting our tools: How small improvements made daily work flow\nMaking our daily tools talk to each other properly. Notion and Slack integrations wrapped up, Telegram and JIRA next in line. Each connection means less manual work, easier knowledge flow.\n\nThe **🧊・bounties** channel tracks where we're headed. You can see what's done, what's next, and how it all ties together.\n\nWe keep improving based on what teams actually need. Check the bounties channel for updates as they happen.\n\n![](assets/2024-in-review-bounties.png)\n\n## Welcoming new members to the team\nThis year, we proudly welcomed @minhkek as a permanent addition to our BD team. Minh’s ability to bridge our work with business and deliver results made the transition seamless. Many of this year’s projects owe their success to his efforts.\n\nWe also had @datnguyennnx and @ngocquang join us as interns this summer, showcasing their capabilities and potential.\n\nLooking ahead, we’ve resumed hiring and are excited to welcome more like-minded folks to the team. [Check out hiring](https://memo.d.foundation/careers/hiring//).\n\n# Business growth\n2024 brought shifts worth noting. Markets changed direction, services adapted, and Vietnam's tech scene showed signs of life.\n\n## Market shifts\n### New partnerships and team growth\n\n- **Research Lab**: Led by [@thanh](https://memo.d.foundation/contributor/thanh) and [@Tom](https://memo.d.foundation/contributor/tom), we broke new ground in AI with professional collaborations alongside **Ascenda**, **FornaxAI**, and **Plot**.\n- **Web3 and Quant Teams**: Thriving teams delivered impactful results with **Y[Redacted]** and **Hedge**, while laying the foundation for upcoming projects already in the pipeline.\n\n### Navigating a changing landscape in 2024\nTech kept moving in 2024, and the changes caught our attention. New partnerships in AI, blockchain, and fintech brought fresh challenges, pushing us from development work to technical consulting. Engineers stepped up, taking on key roles in project decisions.\n\nMay took us to Singapore's Echelon Asia Summit, where [@tieubao](https://memo.d.foundation/contributor/tieubao), [@nikki](https://memo.d.foundation/contributor/nikki), and [@huytq](https://memo.d.foundation/contributor/huytq)  explored Southeast Asia’s tech future, uncovering trends in funding, AI, and emerging APAC projects.\n\n### Expanding skills and expertise to meet the demands\nGenerative AI shifted how we talked about projects. Clients looked beyond specialists, wanting people who could mix backend with blockchain, blend full-stack with data skills. Work concentrated on four areas: **Blockchain, Data, Platform Engineering, AI/LLM.**\n\nOur engineering team embraced these shifts naturally, adding new strengths while staying rooted in solid engineering practices.\n\n![](assets/2024-in-review-echelon-summit.png)\n\n## Dwarves’ services in 2025\n### Introducing hourly billing: Flexibility for clients, clarity for teams\nThe year brought changes to how we deliver value. We moved to hourly billing - giving clients more flexibility and teams more clarity. Simple idea: fair hours for good work. To understand how this new model benefits both our team and our clients, read the full article [here.](https://memo.d.foundation/playbook/business/pricing-model-bill-by-hours/)\n\n![](assets/2024-in-review-hourly-billing.png)\n\n### Refining service packages for what clients actually need\nWe’re re-centering our focus to meet the moment. AI, blockchain, data - this is where we’re investing our time and talent, as we keep pace with client needs and market demands.\n\n1. **Consulting shift**: As client requirements change, so do our team’s. We’re doubling down on adaptable, high-impact contributors while others may pause or refocus to match our direction.\n2. **Lab team**: The Lab remains the heartbeat of our innovation. Expectations (and rewards) are higher for those pushing the boundaries, writing, exploring, and applying new ideas.\n3. **Community backbone**: Nine years in, our Discord stays strong - a space for learning, sharing, and connecting, whether you’re new, tenured, or alumni.\n\nSimplifying where it counts, we’ve delivered faster solutions and brought clarity to every project.\n\n## Vietnam tech ecosystem\n### Building a network of trusted partners in Vietnam’s tech ecosystem\nVietnam’s tech market is vibrant and growing, attracting startups and investors. Following the forecast, Vietnam’s digital economy is projected to reach $43 billion by 2025, fueled by breakthroughs in AI, fintech, and crypto - areas we’re eager to shape alongside nearly 100 active investors.\n\nLeading firms like 500 Startups Vietnam, VSV Capital, and VinaCapital Ventures are driving this progress, supporting innovative startups and the broader ecosystem. By connecting key players in the ecosystem, this report aims to establish a network of trusted partners who can collaborate and drive mutual growth.\n\n# Community growth\nBeing part of the tech community means stepping up, sharing what you’ve learned, and helping others grow. At Dwarves network, contributing back is woven into everything we do.\n\nHaven’t properly highlighted this yet, but 2024 brought some real bright spots in how we learn together. 37 OGIF sessions, 335 memo entries and a monthly pool of 2500 ICY for learning might just sound like numbers, but each one proved why sharing knowledge makes a difference.\n\n## A community driven by learning and sharing culture\nThrough **memo** and **OGIF**, it doesn’t just sit on a shelf, they’re put to work by anyone who needs them. The monthly rewards made sharing worth everyone's time. Discord saw more tech discussion, memo tackled harder problems, and OGIF sessions dug deeper into tech that mattered. Anyone can earn ICY by participating in community activities.\n\nShout out to:\n\n- **Long Bui Van** (@longddl): Shared valuable notes on Data Pipeline Design Framework, Vector Database.\n- **Jack** (@jack) and Phuc Le (@phucld): Collaborating on bridging $DFG from Ethereum Mainnet to Base Network for staking.\n\nBig thanks to the contributions from both the team and community that have made Dwarves thrive: @tom, @hnh, @lapnn, @theoctopus, @minhlq, @nikki, @taipham, @vincent, @phucld, @julis, @antran, @innno_, @minh_cloud, @bienvh, @huymaius, @huytq, @datnguyennnx,@nhuthm, @nam,@hieuthu1, @tristran, @truongquoctuan.\n\n\n![](assets/2024-in-review-learning-culture.png)\n\n![](assets/2024-in-review-learning-culture-2.png)\n\n## Dwarves offline meet-up: Over 50 members came together for networking and OGIF talks\nMay 31st marked our second Ho Chi Minh City meetup, and it was a night to remember. Over 50 of us gathered to talk tech, connect, and share ideas—good vibes all around. \n\nWe caught up on all things Dwarves, swapped updates, and got into discussions that mattered. Everyone left with something valuable, and seeing the energy in the room? We couldn’t be happier.\n\nA huge thank you to our community members: @jack, @tannhatcmcs, and @congiomat for their participation. Stay tuned for the next meetup, more stories to come together.\n\n![](assets/2024-in-review-offline-meetup.png)\n\n## Dwarves Open Source: Fueling innovation together\nWe deepened our commitment to open-source, empowering our team and community to build and share tools that address real problems. From practical libraries to AI-driven projects, each contribution brought us closer to collective progress.\n\nOur aim was clear: foster innovation while giving back to the tech world. Hosting and sharing projects became a way for everyone to contribute meaningfully, and earn rewards along the way.\n\n**Key highlights:**\n\n- Empowered team and community members to host projects, driving collaboration.\n- Expanded our GitHub with impactful contributions addressing tangible problems.\n- Recognized efforts with ICY rewards, making every contribution count.\n\nExplore what’s live: [Dwarves Open Source on GitHub](https://github.com/dwarvesf/opensource).\n\n![](assets/2024-in-review-open-source.png)\n\n## Engaging with the community: Showing up and sharing back\nThe tech community is active right now, and we’re right in the mix. We’re diving headfirst into events, meetups, and summits to connect with the tech community. That gives us a clearer sense of where we need to grow.\n\nWhat we’re doing:\n\n- Connecting at the right places - tech meetups, summits, and shows where we meet peers, partners, and clients who are building interesting things.\n- Bringing knowledge back home - capturing insights from every event through memos, podcasts, and OGIF sessions.\n- Adding to the conversation - taking what we’ve learned and built, and sharing it back with the community.\n\n# Workplace growth\n## Return to the office: creating spaces where good work happens\nWe focused on making Hado office a productive and flexible space for focused work. Equipped with **Apple Studio Displays, Herman Miller chairs**, high-speed internet, and serene workspaces, it’s designed to help you get into the zone. Meeting rooms and 24/7 access offered flexibility when collaboration or quiet focus was needed.\n\nWe added perks like parking, lunch, and dinner subsidies to make the experience smoother. An automated check-in system at **🏢・lobby** rewarded every visit with **3 ICY**—a small gesture to keep us connected. Thanks to [@Tom](https://memo.d.foundation/contributor/Tom) for streamlining this process.\n\n[Read our hybrid culture story.](https://memo.d.foundation/handbook/hybrid-working/)\n\n![](assets/2024-in-review-hado.png)\n\n## Exclusive Dwarves NFTs: Unique tokens to recognize our team members contributions\nTo celebrate our crew, we introduced **Peeps NFT**, an exclusive collection honoring the work and spirit of the Dwarves team. These non-transferable tokens aren’t just collectibles—they grant access to internal communications and earning opportunities, making every role feel even more special.\n\n- View your NFT: [OpenSea Collection](https://opensea.io/collection/dwarves-4)\n- How it works: Tono Bot automatically assigns the **@peeps** role when your connected wallet holds a Dwarves NFT.\n\nA token of appreciation for every team member who helps Dwarves thrive.\n\n![](assets/2024-in-review-NFT.png)\n\n## Summit 2024: Penang adventures that strengthened our team\nDecember took us off the grid and into the heart of Penang, giving us a chance to step outside our screens and into shared adventures. The team naturally broke into their own rhythms: street food trails, heritage walks, challenge courses, or simply finding peace by the waves.\n\nEvery moment shared, every snapshot dropped into **🌉・moments**. ICY was nice, but the connections made? Unbeatable. Penang reminded us of what works best: trusting the team to chart their path.\n\nComing back home with stronger bonds, and the confidence that comes from seeing our team thrive both online and off. [Catch the full Penang story here.](https://memo.d.foundation/updates/changelog/2024-summit-building-bonds-our-way/)\n\n![alt text](assets/2024-in-review-penang.png)\n\n# Onward 2025\nLike crafting software, building Dwarves Foundation has been a journey of experimentation. Some things worked, some didn’t, but every year we’ve added something meaningful to the core.\n\n2024 pushed us into interesting spaces - AI went from experiments to real tools, knowledge sharing turned into daily habit, and the community grew naturally. But this is just the beginning.\n\n2025 opens with questions we're eager to answer, about tech, others about how we work. The best lines are yet to be written.\n\nA strong team is built on its people and their beliefs. We're looking forward to the surprises ahead with all of you.","title":"2024 In Review","short_title":"","description":"Closing another milestone with 2024, it has been a year of building and rebuilding — strengthening what works, fixing what doesn’t, and uncovering new paths along the way. Every milestone reached this year carries the marks of teamwork and persistence.","tags":["team","wrap-up","newsletter","updates"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Thu Jan 16 2025 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2024-in-review.md","slugArray":["updates","changelog","2024-in-review"]},{"content":"\n### PURPOSE\n\nFor a long time, we've pursued innovation. It is our motivation. I believe that at some point, we don't want to take on boring maintenance work but instead focus on new ideas, exciting technology, or projects of significant value—not just routine tasks.\n\nWe are here to ship software, but what if we can't?\n\n### COMPETENCY\n\nGlobal competition is tough as the internet and technology continue to advance. To win and earn more, we have to compete with talent globally.\n\nAnd let's be honest—some of us are falling behind. We need to move forward if we want to stay relevant and tackle more complex problems.\n\n![pep_talk.png](https://imgs.xkcd.com/comics/pep_talk.png)\n\n### FACTS\n\nIn the last few months, there have been deals in AI and Blockchain—not simple CRUD—that we wanted to participate in, but we didn't have a candidate to step up and handle the project. A few individuals are working on more than two projects at the same time, while the rest have less to do. \n\nIn every ZIRP period, easy money floats around, creating the illusion that many are good enough to secure a job, earn, and flaunt their superiority, without successfully delivering results. We’ve all done great work in the past, but now it’s time to adapt.\n\n![how_it_works.png](https://imgs.xkcd.com/comics/how_it_works.png)\n\nThe last tech cycle is ending, and we're already in the new normal. We are not in the best shape to compete with certain competitors, especially with a new market meta emerging.\n\n### **ROAD AHEAD**\n\nWe are now in a future of new automation paradigms via AI and assets are moving on-chain. Enterprise-level requirements in these areas are still being considered by many.\n\nThe demand for traditional custom software is squeezing, with more clients opting for cost-effective, off-the-shelf solutions. And it’s hard for us to maintain the balance.\n\n### NEXT\n\nSo, what’s next? We need to pause, regroup, and focus on growth. Here’s how we’ll move forward:\n\n**Consulting**\n\nFor our consulting team, this means changes. We can't promise permanent engagement for everyone. If you're not actively contributing, you might feel the change. \n\nAs a team, we're still observing the tech funding market, and until we can secure a decent number of jobs, you might need to take a break, improve ourselves, and look for new opportunities.\n\n**Lab Team**\n\nOur lab remains central to what we do, but with a sharper focus on innovation and discovery. Rewards for lab members will be increased accordingly.\n\nNew hires are required to perform under the lab team requirements (explore/write/apply).\n\n**Alumni / Community**\n\nOur community is our backbone. The Dwarves brand is nine years strong because of the relationships we've built, and everyone owns a piece of it.\n\nOur Discord isn't just a chatroom; it will remain a hub of learning and connection for current and former team members. Members and alumni will receive a permanent **@d.foundation** alias email. \n\nLet’s continue to nurture this space.\n\n### RECAP — TL;DR\n\n1. The innovation market has changed progressively.\n2. Our target customers are changing accordingly (Blockchain, AI, Data).\n3. Our requirements for consulting members are changing.\n4. Incompetent members or those without active contributing are seeing changes:\n- We don't have work for your skillset.\n- We can't justify the cost as clients believe others can do it more efficient.\n- We might need to take a break in work.\n- You will have a window of 15/30 days to adapt.\n5. Team leaders will pick their A-team.","title":"Navigating changes","short_title":"","description":"The last tech cycle is ending, and we're already in the new normal. We are not in the best shape to compete with certain competitors, especially with a new market meta emerging. We are now in a future of new automation paradigms via AI and assets are moving on-chain.","tags":["updates","changelog"],"pinned":false,"draft":false,"hiring":false,"authors":["tieubao"],"date":"Mon Sep 30 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2024-navigating-changes.md","slugArray":["updates","changelog","2024-navigating-changes"]},{"content":"\nIn the past six months, we've made some pretty impressive strides in testing new standards and adding more automation, activities, and rewards to our Discord server to foster a supportive community among tech lovers.\n\nTake a moment to reflect on our journey so far, and let's get excited about what we'll accomplish together before the year ends.\n\n![](assets/2024-state-of-dwarves-semi-annual-review.webp)\n\n## Community Growth\n### Organized offline meet-up\nOur Year-End Party (YEP) was the first offline meet-up that set the tone for future gatherings,  where peeps can connect in person with like-minded people. Building on its success, we hosted our second Ho Chi Minh City meetup on May 31st.\n\nOver 50 enthusiastic members joined us for a night of tech talks, and all-around good vibes. It was an opportunity to connect with our community in person and share our passion for technology.\n\n![](assets/2024-state-of-dwarves-semi-annual-review-meet-up.webp)\n\n### Dwarves community is growing with more contributions\nA big thanks to our active members who have taken part in learning and sharing knowledge with our peeps. \n\nLong Bui Van (@longddl) has published helpful notes on data pipelines and learning vector databases. You can explore at:\n\n- [Data Pipeline Design Framework](https://memo.d.foundation/playground/engineering/data/data-pipeline-design-framework/)\n- [Quick Learning Vector Database](https://memo.d.foundation/playground/engineering/data/quick-learning-vector-database/)\n\n@jack collaborated with @phucld on [How to bridge $DFG from Ethereum Mainnet to Base Network for staking.](https://memo.d.foundation/playground/01_literature/how-to-transfer-dfg-from-eth-to-base-for-staking/)\n\nAdditionally, several other members have made noteworthy contributions from @tom, @hnh, @vincent, @bienvh, @innno_, @nikki, @huytq, @minhlq, @nhuthm, @hieuthu1, @antran, @ngocthanh, @thanh, @minh_cloud, @minh, @truongquoctuan, @tristran, @anna, @nambui, @tay, @datpv, @datnguyennnx, @nam, @taipn, @hoangnnh, @lapnn, @hieuthu2, @huymaius, @phucld for keeping our server active and full of great content.\n\n![](assets/2024-state-of-dwarves-semi-annual-review-community.webp)\n\n## Team Growth\n### Building Dwarves’ wiki - memo.d.foundation\n[memo.d.foundation](http://memo.d.foundation/) is where we share how we work, learn, and operate as a team. This site is part of our continuous learning engine, aiming to build a 1% improvement habit by learning in public.\n\nThere's a long road ahead to make it the ultimate knowledge source for the team, as a research-focused firm. We aim for the memo to be a centralized knowledge hub that uses a markdown format, displays a graph view, and connects through topic nodes.\n\nThrough learning, sharing, applying, and elevating our core knowledge, we can grow as a team and ship software more efficiently.\n\nYou will get a 5-15 ICY reward for each publication. Community members are welcome to share their learning notes too. \n\n![](assets/2024-state-of-dwarves-semi-annual-review-dwarves-memo.webp)\n\n### Upgrading ICY reward for Dwarves learning system\nWe're excited about the future of ICY and our plans rolled out since its launch in September 2022:\n\n- Monthly reward system for learning contribution up to 3000 ICY.\n- ICY contract moved to Base chain for NFT/staking.\n- New members joining our Discord with a verified account will get 0.1 ICY.\n- Share links in **💻・tech, 💡・til** earn 1 ICY.\n- Share your expertise in OGIF talks and earn 15-25 ICY per talk.\n- Rewarding our top contributors weekly on Friday receives 3 ICY.\n- Link Mochi wallet to GitHub for ICY rewards\n- Earn & Stake ICY for rewards and future benefits.\n\n![](assets/2024-state-of-dwarves-semi-annual-review-icy.webp)\n\n### Exclusive Dwarves NFTs for our team members\nPeeps NFT is an exclusive collection for Dwarves Foundation members, granting access to internal communications and earning opportunities.\n\nEach NFT signifies a unique role with special perks and privileges for our members.\n\nThese unique non-transferable tokens can be viewed on OpenSea at https://opensea.io/collection/dwarves-4.\n\n[@Tono](https://memo.d.foundation/contributor/Tono) Bot will automatically grant the [@peeps](https://memo.d.foundation/contributor/peeps) role to NFT holders with connected wallets.\n\n![](assets/2024-state-of-dwarves-semi-annual-review-nft-role.webp)\n\n### Improvement in internal tooling: Fortress, Tono, Mochi\nWe’ve made several upgrades to enhance our Discord server with our self-built bots, improving task management and overall server experience.\n\n**Tono:** Server management bot that keeps the network running smoothly, tracks weekly activities, and generates top contributor and top reading lists both daily and weekly.\n\n**Fortress:** Tracks performance and issue reporting, offering real-time memo updates and weekly memo publication reports.\n\n**Mochi:** Tip bot for sending virtual kudos to show appreciation for others.\n\n![](assets/2024-state-of-dwarves-semi-annual-review-tooling.webp)\n\n### Research topics: the road to expand the knowledge base\nSolving problems using the latest technologies has always been our goal. This year's research focus is based on five key pillars:\n\n- **Tooling:** Devbox, Colima, alert/monitoring standards\n- **Software Architecture:** Event-driven architecture, Modular Monolith\n- **LLM:** RAG, MLOps\n- **Blockchain:** Solana infrastructure, Monolithic vs. Modular blockchain\n- **Coding Security:** Standard security procedures, Zero trust infrastructure, GitOps\n\nWe've made progress in building internal tools like Tono Bot and Memo using LLM/RAG. Additionally, we've introduced our [Cyber Security Framework](https://memo.d.foundation/playground/01_literature/security/how-i-came-up-with-our-security-standard/) and adopted & built a Map of Content for [Devbox](https://memo.d.foundation/playground/01_literature/devbox-local-development-env/).\n\n![](assets/2024-state-of-dwarves-semi-annual-review-tech-topics.webp)\n\n### Tech research advancements in tooling, architecture, & LLM\nWe closely monitor tech trends every month to identify those with high potential that could become part of our growing tech stack. \n\nIn the past six months, our radar has detected:\n\n- AI/LLM dominating the market. We've seen advanced models like GPT-4o and Sora, and open-source models like Llama 3 and Mistra, [providing new opportunities](https://memo.d.foundation/playground/01_literature/market-report-may-2024#gpt-4o-opportunities-and-disruptions) for richer applications and automation tools.\n- RAG remains the top architecture for applications with LLM models. The [next advancements](https://www.notion.so/State-of-Dwarves-2024-Semi-annual-Review-7915e90978c14739be0ad7e66a377718?pvs=21) will refine retrieval processes to manage the growing online information, including multimodal data integration.\n- Rust is the top choice for developing tooling and system-level software due to its performance. Big names like [Google and Microsoft advocate for Rust](https://memo.d.foundation/playground/01_literature/market-report-mar-2024/#other-notable-trends) to address [memory safety vulnerabilities](https://www.notion.so/State-of-Dwarves-2024-Semi-annual-Review-7915e90978c14739be0ad7e66a377718?pvs=21).\n- Edge computing and serverless architecture are the [new wave in modern web development](https://www.notion.so/State-of-Dwarves-2024-Semi-annual-Review-7915e90978c14739be0ad7e66a377718?pvs=21). Platforms like Cloudflare and Fly.io are simplifying complexity for developers. Building web applications with edge computing speeds up page load times and reduces server maintenance costs.\n\n![](assets/2024-state-of-dwarves-semi-annual-review-gpt4o.webp)\n\n### Resume OGIF - Dwarves' weekly Friday sharing\nOGIF is our weekly Friday tradition where members share 10-minute talks. After three months we have discussed diverse topics like software development, industry trends, finance, entrepreneurship, blockchain, AI, and more. It's a quick, engaging way to learn something new.\n\nIn this era of public learning, we’re excited to see what the team will create. You can revisit our OGIF sharing [here](https://memo.d.foundation/updates/ogif/11-ogif-office-hours-0621/). \n\n![](assets/2024-state-of-dwarves-semi-annual-review-office-hour.webp)\n\n### Reorganize Discord roles: MMA system\nWe've revamped our Discord roles, now ladder-based and function-based, offering additional activities and benefits, especially with NFT and ICY staking.\n\n**MMA-based new roles system**\n\n- Mastery: Recognizing expertise.\n- [@sers](https://memo.d.foundation/contributor/sers) (Meaning): Acknowledging contributions both at work and beyond.\n- [@chad](https://memo.d.foundation/contributor/chad) (Autonomy): Highlighting high performers who excel in quality, quantity, communication, cooperation, and reliability.\n\n**Consulting staff**\n\n- Peeps: Newcomers, qualified to work with us.\n- Baby dwarf: Purpose-seeking individuals.\n- Dwarf: Members involved in R&D and learning activities.\n\n![](assets/2024-state-of-dwarves-semi-annual-review-mma-role.webp)\n\n### Monthly top performers: Honoring your work efforts\nEach month, we use delivery points to recognize our team's efforts. Team members who earn the most points shipped and effort spent receive ICY rewards.\n\n**Highlight Top Performers:**\n\n- **January:** @ngocthanh, @chinhld, @jim, @taipn, @phatnt\n- **February:** @chinhld, @haihuynh, @khacvy, @taipn, @tay\n- **March:** @ngocthanh, @nam, @taipn, @jim, @trkhoi\n- **April:** @hoangnnh, @minhth, @nam, @haihuynh, @hieuvd\n- **May:** @trkhoi, @ngocthanh, @haihuynh, @bienvh, @chinhld\n\n### SPGroup WALA x Echelon Asia Summit 2024\nIn May, our team leaders [@tieubao](https://memo.d.foundation/contributor/tieubao), [@nikki](https://memo.d.foundation/contributor/nikki), and [@huytq](https://memo.d.foundation/contributor/huytq) attended the Echelon Asia Summit in Singapore. The event focused on the future of Southeast Asia’s tech and startup ecosystem, highlighting the trends and high-growth industries.\n\nWe observed the evolving use of funds by investors and startups, advancements in AI, and upcoming projects in the APAC tech startup landscape.\n\n![](assets/2024-state-of-dwarves-semi-annual-review-echelon.webp)\n\n### Launching Dwarves internship program\nWe’ve launched another internship batch. This time, we welcome @datnguyennnx and @ngocquang to our team. We hope Dat and Quang will thrive and grow with us as they embark on this new chapter at Dwarves.\n\n### Team promotion and new teammate\nWe've made some changes to our team structure. @hnh has been promoted to Chief of Staff, and @minh_cloud is now our Junior PM and Executive Assistant. We're also delighted to welcome our new teammate, @minh, who brings business development experience to our team.\n\n### Brand new merchandise\nThe operations team is gearing up for another batch of t-shirts and stickers. The response to the new sticker set has been positive. We’re excited to see our community members sporting these items and showcasing their pride in being part of the Dwarves Foundation.\n\n![](assets/2024-state-of-dwarves-semi-annual-review-merch.webp)\n\nLet's wrap this up with a cheer on top, celebrating the many wins we've enjoyed. Here's to continuing our journey with the same enthusiasm and dedication in 2024. \n\nThank you all for being a part of our inner circle, and helping us achieve MMA's goals.\n","title":"State of Dwarves: 2024 Semi-annual Review","short_title":"","description":"The past six months have been packed with many improvements to our Discord server from new standards and automation to engaging activities and rewards. Take a moment to reflect on our journey so far, and let's get excited about what we'll accomplish together before the year ends.","tags":["newsletter","team","community"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_","nikki","thanh.pham"],"date":"Thu Jul 04 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2024-semi-annual-review.md","slugArray":["updates","changelog","2024-semi-annual-review"]},{"content":"\n## The journey begins\nPenang's vibrant streets became our playground this year. Our goal stood clear and simple: reconnect, recharge, and create memories together. The excitement built as team members from different cities touched down, some crossing borders for the first time.\n\nWhat made it special? Letting things flow naturally. Despite working 100% remotely, our team clicked instantly in person. Those first-meeting jitters melted away faster than Penang's morning mist, proving that strong remote connections translate beautifully to real life.\n\n![](assets/2024-summit-building-bonds-our-way-penang.png)\n\n## Taking the leap beyond borders\nStepping into Penang sparked something special. First-time travelers got their passport stamps while seasoned ones became guides, sharing tips from local dishes to hidden street art spots. This wasn't just a gathering; it was our first shared adventure abroad.\n\n## Remote-first, but never distant\nWorking remotely, our team thrives on digital connections. Yet in Penang, Discord chats transformed into breakfast plans, virtual high-fives became real celebrations, and daily standups turned into evening street food hunts. Our online chemistry translated naturally to real-world friendships - proving we've built something special beyond screens, a team that's connected beyond screens.\n\n![](assets/2024-summit-building-bonds-our-way-team-1.png)\n\n![](assets/2024-summit-building-bonds-our-way-team-2.png)\n\n## The three pillars come to life\nRemember our 2022 vision of Mastery, Meaning, and Autonomy? Penang turned these from concepts into reality:\n\n**Mastery** popped up in unexpected places. Here it showed up in how we turned moments into memories. Every photo dropped in **🌉・moments** automatically earned ICY - no approvals needed, no best-shot contests, just pure team storytelling in action.\n\n**Meaning** hit different when everyone picked their path. Whether wandering heritage streets or conquering Escape Penang's challenges, each choice mattered, not a checkbox. Teams clicked over shared interests, building bonds that make Monday's Discord chats more fun.\n\n**Autonomy** did what it does best - let people be people. No scripts, no forced fun. Teams came together naturally, called their own shots, and turned Penang into their playground. From dawn coffee to twilight beach hangs, every move was team-picked and team-approved.\n\n![](assets/2024-summit-building-bonds-our-way-team-3.png)\n\n## Making memories our way\nOur **🌉・moments** lit up with photos and stories, each ICY token marking another team memory made.\n\n- **Food adventurers** dove into Penang's legendary street food scene, turning every meal into a chance to know each other better.\n- **Cultural explorers** wandered through George Town's heritage streets, their shared discoveries becoming team memories.\n- **Adventure seekers** conquered Escape Penang together, trading keyboards for climbing ropes.\n- **Beach crew** found their rhythm by the waves, where casual conversations built lasting connections.\n\n![](assets/2024-summit-building-bonds-our-way-team-4.png)\n\n![](assets/2024-summit-building-bonds-our-way-team-5.png)\n\n## Where it all came together\nThis summit showed us something powerful about our remote culture: connection transcends distance. When teammates meet, online rapport naturally turns into real-world friendships, proving we’re building something truly special.\n\nStanding back and watching these moments unfold hit different. The real win? Give people space to connect, and they'll create something better than any playbook could design. Each shared moment, each ICY token earned - they're all threads in a bigger tapestry of a team that stays close no matter the miles.\n\nHere's to the incredible family we've built - one that makes every summit feel like a homecoming. When we come together, it feels like we were never apart.\n\n![](assets/2024-summit-building-bonds-our-way-team-6.png)","title":"Summit 2024: Building bonds our way","short_title":"","description":"Our first international summit took us to Penang, where remote connections turned into real-world chemistry. No rigid schedules or forced activities - just authentic moments of teams choosing their own adventures, from heritage streets to beach sunsets. See how giving people space to connect creates something truly special.","tags":["summit","newsletter","team","updates"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Tue Dec 24 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2024-summit-building-bonds-our-way.md","slugArray":["updates","changelog","2024-summit-building-bonds-our-way"]},{"content":"\n- [**Reporting tech signals:**](#reporting-tech-signals---ai-edge-computing-and-ui-innovations-driving-change) major updates in Meta's Llama 3, the growth of RAG systems, the move to edge computing, and the influence of Bun 1.1 in JavaScript.\n- [**memo.d.foundation:**](#upgrading-the-new-sidebar-and-reading-mode-on-memodfoundation) improve experience with new sidebar, pinned notes, and reading mode.\n- [**The new features in Tonobot and Fortress are**](#new-features-in-tonobot-and-fortress-our-internally-automated-bots) top contributor reading lists, real-time memo post updates, and weekly reporting on Dwarves Network.\n- [**Upgrading learning reward system:**](#monthly-reward-system-for-learning-contribution) monthly pool up to 700 ICY, aligned with our research-focused orientation.\n- [**Dwarves office hour:**](#the-traditional-dwarves-office-hour-happens-every-friday-afternoon) weekly sharing so everyone can learn something within 10 minutes.\n\n![](assets/2024-whats-new-april_2024-whats-new-in-april-highlight.webp)\n\n## Reporting tech signals - AI, edge computing, and UI innovations driving change\nIn April 2024, we saw exciting technological advancements and key trends to influence various markets profoundly.\n\n- The release of Meta's Llama 3, Databricks' DBRX, and Mixtral 8x22B offer high-quality options for self-hosted LLM applications, making AI more accessible and affordable for businesses.\n- The trend of Retrieval Augmented Generation (RAG) systems is gaining traction, integrating real-time data for more accurate LLM responses.\n- The tech landscape is experiencing a shift towards edge computing for faster and more cost-effective web applications\n- Bun 1.1 is making waves in the JavaScript ecosystem with its speed and compatibility, while the copy-paste UI development approach offers developers greater flexibility and customization.\n\n[Read our full report](https://memo.d.foundation/playground/_labs/market-report-april-2024/) for a deeper dive into these trends and their potential impact.\n\n![](assets/2024-whats-new-april_2024-whats-new-apirl-llm.webp)\n\n## Upgrading the new sidebar and reading mode on memo.d.foundation\nIn recent months, we’ve been improving memo.d.foundation, our “digital knowledge hub”. Every piece of knowledge finally has a place to organize in a cleaner, more productive space. \n\nHere's what you can expect: \n\n- Keep your eyes comfy with the new interface: now boasting a sleek sidebar, pinned notes, and new reading mode, complete with author information, table of contents, and estimated reading time.\n- Plus, a user-friendly sidebar folder tree makes navigating your knowledge a breeze.\n- Kudos to the hard work of @Tom and @vincent for meticulously preparing the data and implementing DuckDB-WASM, resulting in lightning-fast rendering and coding on Hugo.\n- Special shoutout to @innno_ and the communication team for their efforts in learning and using development tools to contribute to this project.\n\nLet us know what you think.\n\n![](assets/2024-whats-new-april-memo-upgrade.webp)\n\n## New features in Tonobot and Fortress, our internally automated bots\nThe nitty-gritty details we've implemented to make Discord better with our self-built bots, thanks to @hnh, @nam, and @bienvh. Here are a quick rundown of Tonobot and Fortress’s latest features:\n\n- Tonobot can now track weekly Dwarves Network activities and generate top contributor reading lists. This means you can access clear reports with minimal effort.\n- Fortress bot: top reading list and real-time memo post updates provide accessibility for users engaging with our content.\n\n![](assets/2024-whats-new-april-tooling.webp)\n\n## Monthly reward system for learning contribution\nWe're set to update the reward system, introducing a monthly pool of up to ~700 ICY for your learning contributions. You can collect valuable insights from diverse sources and submit them to memo.d.foundation.\n\nAs a **research-focused firm**, we encourage the team to learn, contribute, share, and collect knowledge from around. It became clear that our velocity (ability to ship more and more regularly) and our roadmap would all improve. \n\nWe welcome everyone in the Dwarves Network to participate.\n\n![](assets/2024-whats-new-april_2024-whats-new-arpil-learn.webp)\n\n## The traditional Dwarves office hour happens every Friday afternoon\nAt 5PM, every Friday afternoon, everyone in community is invited to gather on Discord to share our work with others. In the April Community Call we walked through:\n\n- Our friend @jack demo step-by-step guide with @phucld on how to bridge [$dfg](https://bridge.d.foundation/) from ETH Mainnet to the Base chain ecosystem to experience a smooth and seamless cross-chain smkwap.\n- @minh_cloud took a further in the component liquid market: definition, benefits in trading, and examples.\n- What you need to dive in with Erlang 101 by @hieuthu1, covered getting started with Erlang.\n\n![](assets/2024-whats-new-april-liquidity.webp)\n\n**Upcoming event:**\n\n-  Community meetup in Ho Chi Minh City on Friday, May 31st. \n","title":"What's New in April 2024","short_title":"","description":"In this April, we're focused on memo upgrading, reward system, OGIF, internal tooling, community meetup and market report.","tags":["newsletter","meet-up","tech-report","community"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Thu May 23 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2024-whats-new-april.md","slugArray":["updates","changelog","2024-whats-new-april"]},{"content":"\n- [**Reporting tech signal:**](#reporting-tech-signal-ais-impact-on-programming-and-new-opportunities) How AI tools like Cursor and Claude 3.5 Sonnet are changing programming, with insights on generative apps, prompt caching, and structured outputs.\n- [**Community activities:**](#community-engagement-memo-notes-ogif-office-hours-and-tech-discussions) Increased discussions in the  [**💻・tech**](https://discord.com/channels/462663954813157376/810481888619135046/1281086341995565057), [**💡・til**](https://discord.com/channels/462663954813157376/1001883339046797342/1281097209072320615) channels. Shoutouts to key contributors from the team and community for their involvement.\n- [**Upgrading the `sum` command:**](#link-summaries-with-sum-command) The `sum` command now delivers faster summaries with key points and nuggets of knowledge. Thanks to Nam and Tom for the upgrade.\n- [**Golang enterprise MOC:**](#go-enterprise-solutions-and-what-weve-learned) Phat Nguyen compiled the Go Enterprise MOC, giving us deeper insights into how we’re tackling enterprise challenges with Golang.\n- [**dfg token:**](#dfg-token-earn-by-contributing) The dfg token can now be earned through team contributions, tracked by ICY in team activities.\n\n![](assets/2024-whats-new-august-theme.png)\n\n## Reporting tech signal: AI’s impact on programming and new opportunities\nAugust brought some exciting developments in AI-driven programming and app creation. Tools like **Cursor** and **Claude 3.5 Sonnet** are pushing programming toward AI-guided code, while **Generative Apps** are moving beyond UI, with AI tools now able to build mini apps from simple prompts.\n\nOther highlights include:\n\n- **AI in Programming:** Tools like Cursor and Claude 3.5 Sonnet are shifting coding from manual work to AI-guided, moving towards an AI-driven future.\n- **Generative Apps:** AI tools like Claude and ChatGPT are now building mini apps from prompts, reshaping app creation.\n- **Amazon's AI Development:** Amazon's GenAI assistant has slashed upgrade times and costs, automating 79% of code reviews.\n- **Prompt Caching:** Anthropic’s caching cuts costs by up to 90%, boosting efficiency in apps needing repeated context like chatbots.\n- **OpenAI’s Structured Output:** OpenAI enforces data adherence to JSON schemas, raising the bar in fields like healthcare and finance.\n- **Frontend Evolution:** Tools like shadcn and v0.dev are accelerating UI development with AI-enhanced prototyping.\n\n[Check out the latest market trends.](https://memo.d.foundation/playground/01_literature/market-report-aug-2024/)\n\n![](assets/2024-whats-new-august-tech-signal.png)\n\n## Community engagement: memo notes, OGIF office hours, and tech discussions\nSince we introduced the monthly pool for learning activities, the biggest impact has been the rise in real learning and discussions happening in memo notes, OGIF office hours, and discord network. We’ve made it simple for everyone to contribute.\n\nPractical insights are brought to the table, and we work through them together—no fluff.\n\nPlus, there’s a new Fortress bot feature to check available ICY for grabbing, making it easier to see what’s up for grabs. \n\nBig thanks to the contributions from both the team and community: @tom, @lapnn, @theoctopus, @minhlq, @taipham, @vincent, @phucld, @julis, @antran, @innno_, @minh_cloud, @bienvh, @huymaius, @huytq, @datnguyennnx, @nam, @hieuthu1, @tristran. \n\nHere’s what we covered in August:\n\n- [Devbox Map of Content](https://memo.d.foundation/playground/-devbox/) - [@bienvh](https://memo.d.foundation/contributor/bienvh)\n- [Go commentary weekly](https://memo.d.foundation/tags/go-weekly/) - [@fuatto](https://memo.d.foundation/contributor/fuatto)\n- [Market report August](https://memo.d.foundation/playground/01_literature/market-report-aug-2024/) - [@thanh](https://memo.d.foundation/contributor/thanh), [@tom](https://memo.d.foundation/contributor/tom)\n- [Frontend market report](https://memo.d.foundation/playground/01_literature/engineering/frontend/frontend-report-july-2024/), - [@lapnn](https://memo.d.foundation/contributor/lapnn), [@hienld](https://github.com/leduyhien152)\n- [Design file-sharing system - Part 1: Directory Structure](https://memo.d.foundation/playground/01_literature/design-file-sharing-system-part-1-directory-structure/), [Design file-sharing system - Part 2: Permission & Password](https://memo.d.foundation/playground/01_literature/design-file-sharing-system-part-2-permission-and-password/) - [@datpv](https://github.com/datphamcode295)\n- [Evaluating search engine in RAG systems](https://memo.d.foundation/playground/01_literature/hybrid-search/) - [@datnguyennnx](https://memo.d.foundation/contributor/datnguyennnx)\n- [Evaluating caching in RAG systems](https://memo.d.foundation/playground/01_literature/caching-with-rag-system/) - [@tay](https://github.com/taynguyen)\n- [Generative UI](https://memo.d.foundation/playground/01_literature/generative-ui/) - [@namanh](https://github.com/tonible14012002), @ngocquang\n- [Designing for forgiveness](https://memo.d.foundation/playground/01_literature/designing-for-forgiveness/) - [@nambui](https://github.com/Maniub102)\n- [Design custom/dynamic object properties](https://memo.d.foundation/playground/01_literature/designing-a-model-with-dynamic-properties/) - [@lapnn](https://memo.d.foundation/contributor/lapnn)\n- [OGIF office hour](https://memo.d.foundation/tags/office-hours/)\n\n![](assets/2024-whats-new-august-learning-activities.png)\n\n## Link summaries with `sum` command\nWe’ve upgraded the **`sum`** command on our Discord to make it easier to get the important stuff. Now, with a summary opening, key points, and nuggets of knowledge, it’s quicker to catch up on useful links. Special thanks to [@nam](https://github.com/namnhce) and [@tom](https://memo.d.foundation/contributor/tom) for leading this improvement.\n\n![](assets/2024-whats-new-august-sum-command.png)\n\n## Go enterprise solutions and what we’ve learned\nAugust brings a major update to our Go commentary. [@fuatto](https://memo.d.foundation/contributor/fuatto) has put together the Go Enterprise MOC, offering a clear look at how we’re applying Golang to tackle enterprise challenges and highlighting how we’re stretching its capabilities.\n\nWe’re still delivering our Go commentary weekly through OGIF sessions and memo notes. [Take a look here](https://memo.d.foundation/tags/go-weekly/).\n\n![](assets/2024-whats-new-august-go-enterprise.png)\n\n## dfg token: earn by contributing\nThe **dfg token** has evolved from a private stock-like idea to a way to reward team members for their contributions. It’s part of our plan to build a brand we can all be proud of.\n\nOriginally tied to our Employee Ownership Program (EOP), the **dfg token** can now be earned through team activities. Contributions are tracked and rewarded with ICY coins. Soon, ICY will be required to earn the token.\n\n[Check out for the details.](https://memo.d.foundation/playbook/community/df-protocol-icy-dfg/) \n\n![](assets/2024-whats-new-august-dfg.png)\n","title":"What's New in August 2024","short_title":"","description":"Each month, we release a recap highlighting key updates and progress within our team and community. August updates highlight AI tools, enhanced community discussions, the sum command upgrade, Go enterprise MOC insights, and earning dfg tokens through contributions.","tags":["newsletter","memo","community"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Fri Sep 06 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2024-whats-new-august.md","slugArray":["updates","changelog","2024-whats-new-august"]},{"content":"\n[**Our summit 2024 adventure in Penang:**](#summit-2024-building-our-rhythm-in-penang) a team getaway that blended cultural discoveries, shared laughs, and moments to recharge for the road ahead.\n\n[**The Final notes of 2024:**](#the-final-notes-of-2024) new momentum, year-end reflections, and Tet celebrations ahead.\n\n[**Taking time to reset and cheer to the new year 2025:**](#finding-your-reset-and-2025-begins) Finding our own rhythms, new energy before 2025 begins.\n\n![](assets/2024-whats-new-december.png)\n\n## Summit 2024: Building our rhythm in Penang\nDecember took us off the grid and into the heart of Penang, giving us a chance to step outside our screens and into shared adventures. The team naturally broke into their own rhythms: street food trails, heritage walks, challenge courses, or simply finding peace by the waves.\n\nEvery moment shared, every snapshot dropped into **🌉・moments**. ICY was nice, but the connections made? Unbeatable. Penang reminded us of what works best: trusting the team to chart their path.\n\nComing back home with stronger bonds, and the confidence that comes from seeing our team thrive both online and off. [Catch the full Penang story here.](https://memo.d.foundation/updates/changelog/2024-summit-building-bonds-our-way/)\n\n## The final notes of 2024\nThe year's wrapping up with its own rhythm. Teams are closing their projects with care, not rush. We're putting together Tet gifts - a small way to welcome the new year with meaning. The year-end reflections are coming together, capturing not just what we shipped, but what we learned along the way.\n\nSome things brewing as we wind down:\n\n- Tet gifts getting packed - a small way to start the new year right.\n- Year-end reflections capturing what we built and learned.\n- Seeds planted for what's next.\n- Stories and learnings being documented at memo.d.foundation.\n\n## Finding your reset and 2025 begins\nDecember's keeping us both productive and thoughtful. Projects are moving steadily ahead while next year's plans come together, and we're making space for those end-of-year moments that matter. Our Discord's buzzing with shipping updates and preparations for what lies ahead. \n\nAround the team, you'll find:\n\n- Final touches on 2024 projects while sketching out new builds.\n- Tech articles finding their spotlight amidst planning sessions.\n- Team sync-ups mixing with year-end wrap-ups.\n\nThese closing days of the year are yours to navigate. Some are diving deep into 2025 roadmaps, others are finding that perfect mix of prep. The work's flowing, the ideas are brewing, and the energy's just right. \n\nThe start of a new year is here, and before we dive back in, we wanted to take a moment to say thanks. Thanks for being part of what made 2024 work - we shipped things that mattered, learned stuff worth sharing, and built connections that went beyond code.\n\nSee you on [Dwarves Discord](discord.gg/dwarvesv), OGIF, and the next meetup. 2025's looking good already.","title":"What's New in December 2024","short_title":"","description":"December blended Penang team moments with steady progress, closing 2024 with energy and ready for what's next.","tags":["newsletter","updates","summit"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Fri Jan 03 2025 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2024-whats-new-december.md","slugArray":["updates","changelog","2024-whats-new-december"]},{"content":"\n- **[Reporting Tech Signals](#reporting-tech-signals)** - Latest findings on Serverless Computing, AI & ML, FinOps and CyberSecurity\n- **[Research Topics 2024](#research-topics-2024)** - 40 topics on the most promising technologies.\n- **[Dwarves' Reward System](#dwarves-reward-system)** - Developing our community reward system\n- **[Calling for Partners](#partner-network)** - One of the rare event where Dwarves and community members gather.\n\n## Reporting tech signals\nEvery month we watch tech trends closely to depict which ones have high potential, and can be part of our growing tech stack.\n\nThis month highlights:\n\n- AWS introduces Low Latency Runtime (LLRT) for **serverless applications**, promising over 10x faster startup times and up to 2x lower operational costs. Languages to look out for: Rust, QuickJS JavaScript\n- In the age of AI, **system engineering** is more crucial than traditional coding education\n- A groundbreaking method using 1.58 bits per parameter in LLMs aims to dramatically reduce the computational cost and energy consumption of running LLMs\n- **FinOps** shift towards waste reduction and managing commitment-based discounts to address global economic pressures\n- White House Office reports the critical need for memory-safe programming languages, advocating for languages like C#, Go, Java, Python, Rust, and Swift\n\n**[Read the full report here]()**\n\n## Research Topics 2024\nBeing able to solve problems using the latest, coolest technologies has always been our main goal. Therefore, we are going big on research this year.\n\n- At the moment, we have around 40 topics in our backlog.\n- Topics are chosen by nominating and voting.\n- All Dwarves' members are required to participate in research activities.\n- Each topic will be a bounty item led by our senior members.\n\n![](assets/2024-whats-new-february_whats-new-february-2024-20240308101849109.webp)\n\nA handful of community members has expressed interest in joining hands. Of course, we're happy to have everyone onboard. However, we will need to assess each contributor's skills and experience first for quality purpose.\n\nIf you want to join our research group, open a support ticket on our [**Discord**](https://discord.gg/dwarvesv) and we'll talk to you asap!\n\n## Dwarves' Reward System\nOur server has been buzzing with quite a lot of knowledge sharing and discussing from members. It's only right that we start giving back to all contributors, through a Reward System.\n\nICYMI, ICY is Dwarves' very own token used to reward both team members and community members. Anyone can earn ICY by participating in community activities. Even the simplest acts like sharing a link, or chatting count too.\n\nOur reward system is currently being developed. You can look forward to it!\n\n![](assets/2024-whats-new-february_whats-new-february-2024-20240308101902325.webp 's=90')\n\n## Monthly top performers\nEach month we track how productive and valuable each of our team members by using delivery points. The top 5 high-performing members get rewards with $ICY. \n\nIn February, kudos to those peeps who outperformed the rest: Chinh Le, Hai Huynh, Khac Vy, Tai Pham, Tay Nguyen!\n\n![](assets/2024-whats-new-february_whats-new-february-2024-20240308101913942.webp 's=90')\n\n## Partner Network\nWe are always seeking for business development partners, individuals and companies likewise, to develop a co-creation system driven by mutual purposes and interests.\n\nWith our average proejct size at $30,000, a partner can generate at least $2,400 per project. Commission is paid from project start, every month until project end.\n\nBut a stable income is not all we offer, there are [other perks and benefits]() too!\n\n[Reach out to Nikki](mailtonikkid.foundation) if you're interested or know someone who might :)\n","title":"What's New in February 2024","short_title":"","description":"In this second month of 2024, we're eyeing on what's brewing in the tech market, what's happening in our community and internally, the newest topics we're looking forward to researching and putting on the field, and expanding our partner network.","tags":["newsletter","consulting","tech-report","performance"],"pinned":false,"draft":false,"hiring":false,"authors":["nikki"],"date":"Fri Mar 08 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2024-whats-new-february.md","slugArray":["updates","changelog","2024-whats-new-february"]},{"content":"\n> **Before you dive in**\n> Dwarves is operated as a 50% company, 50% community. Everything we learn along the way of work, we transform into knowledge and distribute back to our tech community.\n>\n> If you want to get in touch, visit [Dwarves Network](http://discord.gg/dwarvesv)\n\nIn this first month of 2024, we kept tap of what's brewing in the tech market, while reviewing what we went through in 2023.\n\n- **[Reporting tech signals](#reporting-tech-signals)** - Updates on the stage of React, Rust, AI, Cybersecurity, Rust.\n- **[Dwarves' YEP 2023](#dwarves-yep-2023)** - One of the rare event where Dwarves and community members gather.\n- **[Dwarves' 2023 in review](#dwarves-2023-in-review)** - A recap of Dwarves in 2023\n\n## Reporting tech signals\nEvery month we watch tech trends closely to depict which ones have high potential, and can be part of our growing tech stack.\n\nThis month highlights:\n\n- Not-so-great news for React from the lack of updates and core members leaving\n- The rapidly growing interest HTMX\n- The idea of “Rewrite It In Rust” (RIIR) coming to life as more and more projects move to Rust\n- In-house AI-assisted productivity tools on the rise\n- LLMs stepping away from OpenAI\n- Trading bots\n- Cybersecurity taking the center stage\n\nFor the full read, [you can view our market report here]().\n\n## Monthly top performers\nEach month we track how productive and valuable each of our team members by using delivery points. The top 5 high-performing members get rewards with $ICY. \n\nIn January, kudos to those peeps who outperformed the rest: Ngoc Thanh, Chinh Le, Cuong Mai, Tai Pham, Phat Nguyen\n\n## Dwarves' 2023 in review\n2023 consisted of shifts and changes almost every step of the way. We managed to pull through, and it's all because of the hard work of our members, along with the trust from our clients & partners.\n\nOur top ten achievements through 2023 are chosen by voting from everyone. With half of them are team-related, while the other half are community-related, it shows we are still on the right path to \"50% company, 50% community\".\n\n- Biggest contract renewal from clients of all time\n- Bounty program for community grant reached $30k\n- Monthly product demos and showcases\n- System for rewarding monthly top performers and contributors\n- Dwarves & Techie communities reach 40k members in total\n- Frontend training course with 180 community members participated\n- Golang training course with 82 community members participated\n- 102 published stories about human in tech, 77 tech events and radio talks\n\nRead through our full 2023 recap: ![](assets/2024-whats-new-january_doty2023.pdf)\n\n## Dwarves' YEP 2023\nWe chose to host our YEP 2023 earlier than most companies, so that our team members can go home a bit earlier, spending a bit more time with their loved ones. \n\nOur YEP is also a bit different. It's a full one-day event filled with multiple activities, as we aim for teamwork, team bonding and also, tremendous fun.\n\n- 400 mil VND was spent as awards and gifts for everyone\n- 105 mil VND was spent donating to tree planting across Vietnam\n\nThank you to all the team members, partners, alumni and community members who joined in with us. We hope to have more fun things for everyone to take part in next year.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/2xPsj5TR_wA?si=Og_OrVtT0o16t2Bz\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n\n## Community\n- Top contributors to our Discord server this month brought in a lot of new knowledge. Thank you, and we hope you enjoy your $ICY rewards.\n- Some members asked if we will have any training courses soon. While we don't yet have the answer, as we're still planing for 2024, you can join us on Discord so you'll get notified when we do!\n","title":"What's New in January 2024","short_title":"","description":"In this first month of 2024, we kept tap of what's brewing in the tech market, while reviewing what we went through in 2023.","tags":["newsletter","doty","bounty","tech-report","community"],"pinned":false,"draft":false,"hiring":false,"authors":["nikki"],"date":"Wed Feb 07 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2024-whats-new-january.md","slugArray":["updates","changelog","2024-whats-new-january"]},{"content":"\n- [**Reporting Tech Signals:**](#reporting-tech-signals---ai-advancements-cybersecurity-focus-and-shifting-software-trends) Significant AI advancements, cybersecurity focus, and shifting software development trends.\n- [**memo.d.foundation**:](#new-memo-command-to-boost-team-contributions) You can now access new commands to view the memo list and automate weekly reports.\n- [**Dwarves Token Usage:**](#dwarves-token-usage-for-july) Community participation led to ~857 ICY being rewarded for contributions, including OGIF talks, tech sharing, memo notes, and bounties.\n- [**Reporting Tech Scene in Vietnam:**](#reporting-tech-scene-in-vietnam) Insights into Vietnam's tech landscape, investment trends, and key players in AI, fintech, and blockchain.\n- [**OGIF Automation Recording and Topics Overview:**](#ogif-automation-recording-and-topics-overview) Efforts to streamline the automation recording process and a summary of the topics discussed in July.\n- [**Golang Enterprise:**](#dwarves-advancing-with-golang-enterprise-solutions-and-industry-insights) Dwarves advancing with Golang and sharing insights through weekly commentary.\n- [**Pricing Model - Bill by Hours:**](#pricing-model-bill-by-hours) Introduction of an hourly billing model to ensure fairness, flexibility, control, and transparency in engagements.\n\n![](assets/2024-whats-new-july-thumbnail.webp)\n\n## Reporting tech signals - AI advancements, cybersecurity focus, and shifting software trends\nIn July, the tech landscape saw significant advancements in AI, a heightened focus on cybersecurity, and notable shifts in software development trends.\n\n- **Meta’s Llama 3.1:** The 405B parameter model is a major leap in open-source AI, competing with top closed-source models.\n- **OpenAI’s GPT-4o-mini:** Fine-tuning capabilities democratize AI customization for optimized business applications.\n- **Claude Sonnet 3.5:** Enhances software development speed by 10x for UI components.\n- **AI in Sports Analytics & TTS:** Roboflow and ElevenLabs' innovations boost performance analysis and communication.\n- **Cybersecurity Incidents:** Highlight the need for resilient system designs to prevent single-point failures.\n- **Software Engineering Trends:** Emphasis on \"boring\" technology, full-stack development, and AI tool integration.\n- **Programming Language Salaries:** JavaScript sees a median salary drop, while Erlang, Elixir, and Clojure command higher salaries.\n\n[Read the full report here.](https://memo.d.foundation/playground/01_literature/market-report-july-2024/)\n\n![](assets/2024-whats-new-july-tech-report.webp)\n\n## New memo command to boost team contributions\nIn the upcoming phase, the team will focus on streamlining processes and developing tools to make memo submission easier for everyone. Here are two ways we’re helping you stay up to speed:\n\n- Use commands like `?memo pr` and `?memo list` to check out the latest memos. Shoutout to [@bienvh](https://github.com/baenv) and @huymaius for this.\n- Receive webhook notifications in the Discord server for new PRs, speeding up memo operations.\n- Coming soon: Tools for submitting fleet notes directly on Discord and automating ICY distribution.\n\nThe amount of ICY distributed is still below the team’s limit, so there’s plenty of room for more contributions. Everyone can join hands.\n\nWe've seen a great increase in memo input from members this month. Here’s the list for July:\n\n1. [Devbox Map of Content](https://memo.d.foundation/playground/-devbox/), [Ton's base concepts](https://memo.d.foundation/playground/01_literature/ton_core_concept/), [Ton ecosystem](https://memo.d.foundation/playground/01_literature/ton_blockchain_of_blockchains/)  - [@bienvh](https://github.com/baenv)\n2. [Go Weekly: Go 1.23 Iterators](https://memo.d.foundation/playground/00_fleeting/go-weekly-511/), [Go Commentary July 08](https://memo.d.foundation/playground/00_fleeting/go-commentary-jul-12/), [Go Commentary July 26](https://memo.d.foundation/playground/00_fleeting/go-commentary-jul-26/) - [@fuatto](https://github.com/fuatto)\n3. [Re-ranking in RAG](https://memo.d.foundation/playground/01_literature/engineering/ai/re-ranking-in-rag/) -  [@hoangnnh](https://memo.d.foundation/contributor/hoangnnh)\n4. [Market report July](https://memo.d.foundation/playground/01_literature/market-report-july-2024/) - [@thanh](https://github.com/zlatanpham), [@tom](https://github.com/monotykamary)\n5. [Local-first Software](https://memo.d.foundation/playground/01_literature/local-first-software/) - [@lapnn](https://github.com/ngolapnguyen)\n6. [Building a Local Search Engine for Our Memo Website](https://memo.d.foundation/playground/01_literature/creating-a-fully-local-search-engine-on-memo/) - [@tom](https://memo.d.foundation/contributor/tom)\n7. [How we crafted the OGIF summarizer bot to streamline weekly knowledge-sharing](https://memo.d.foundation/playground/01_literature/how-we-crafted-the-ogif-summarizer-bot-to-streamline-weekly-knowledge-sharing/) - [@tom](https://memo.d.foundation/contributor/tom), [@innno](https://github.com/innnotruong) \n8. [Streamlining Internal Tool Development with Managed LLMOps: A Dify Case Study](https://memo.d.foundation/playground/01_literature/building-llm-powered-tools-with-dify/) - [@tom](https://memo.d.foundation/contributor/tom)\n9. [Function calling in AI agents](https://memo.d.foundation/playground/00_fleeting/function-calling/) - [@minhlq](https://github.com/minhluuquang)\n10. [Design feedback mechanism for LLM applications](https://memo.d.foundation/playground/01_literature/feedback-mechanism/), [Thumbs up and Thumbs down pattern](https://memo.d.foundation/playground/01_literature/thumbs-up-and-thumbs-down-pattern/) - [@datnguyennnx](https://github.com/datnguyennnx)\n11. [Using Foundry for EVM smart contract development](https://memo.d.foundation/playground/01_literature/using-foundry-for-evm-smart-contract-developement/) - [@haongo](https://github.com/haongo138)\n12. [State of Dwarves: 2024 Semi-annual Review](https://memo.d.foundation/updates/changelog/2024-state-of-dwarves-semi-annual-review/) - [@innno](https://github.com/innnotruong) \n13. [Subscription Pricing Models](https://memo.d.foundation/playground/00_fleeting/subscription-pricing-models/) - [@hieuvd](https://memo.d.foundation/contributor/hieuvd)\n14. [Error handling on Rust](https://memo.d.foundation/playground/01_literature/error-handling-in-rust/), [Rust Trait](https://memo.d.foundation/playground/00_fleeting/rust-trait/) - [@trankhacvy](https://github.com/trankhacvy)\n15. [Proximal Policy Optimization](https://memo.d.foundation/playground/00_fleeting/proximal-policy-optimization/) - [@ngocthanh](https://github.com/thanhpn)\n\n![](assets/2024-whats-new-july-memo-update.webp)\n\n![](assets/2024-whats-new-july-memo-command.webp)\n\n## Dwarves token usage for July\nWe’ve seen active participation from everyone, and it’s great to see so many members getting rewarded. This month, we handed out ~857 ICY for all your contributions, a significant increase from June’s.\n\nHere’s how the rewards break down:\n\n- **OGIF talks:** 210 ICY (~315 USDC)\n- **Links shared:** 373 ICY (~560 USDC)\n- **Memo notes:** 184 ICY (~276 USDC)\n- **Bounty tasks:** 90 ICY (~135 USDC)\n\nSpecial thanks to our top contributors:\n\n- **OGIF talks:** [@fuatto](https://github.com/fuatto), [@datnguyennnx](https://github.com/datnguyennnx), [@hieuvd](https://memo.d.foundation/contributor/hieuvd)\n- **Tech Sharing:** [@minhlq](https://github.com/minhluuquang), [@tom](https://github.com/monotykamary), @huytq, @tristran\n- **Memo notes:** [@fuatto](https://github.com/fuatto), [@bienvh](https://github.com/baenv), [@tom](https://github.com/monotykamary)\n- **Bounty:** [@bienvh](https://github.com/baenv), [@huymaius](https://memo.d.foundation/contributor/huymaius)\n\n## Reporting tech scene in Vietnam\nVietnam's tech market is vibrant and growing, attracting startups and investors. Following the forecast, Vietnam's digital economy is projected to reach $43 billion by 2025, fueled by breakthroughs in AI, fintech, and crypto - areas we're eager to shape alongside nearly 100 active investors. \n\nLeading firms like 500 Startups Vietnam, VSV Capital, and VinaCapital Ventures are driving this progress, supporting innovative startups and the broader ecosystem. By connecting key players in the ecosystem, this report aims to establish a network of trusted partners who can collaborate and drive mutual growth.\n\n[**Read Vietnam Tech Ecosystem 2024 Report.**](https://memo.d.foundation/playground/01_literature/vietnam-tech-ecosystem-report/)\n\n![](assets/2024-whats-new-july-vietnam-market.webp)\n\n## OGIF automation recording and topics overview\nTo improve the efficiency and accessibility of recording our OGIF sessions, thanks to @quang, @tom, and @innno_ for their efforts in streamlining the automation recording process.\n\nLast month, we’ve walked through:\n\n- [Multimodal in RAG](https://memo.d.foundation/playground/01_literature/engineering/ai/multimodal-in-rag/), [Re-ranking in RAG](https://memo.d.foundation/playground/01_literature/engineering/ai/re-ranking-in-rag/) -  [@hoangnnh](https://memo.d.foundation/contributor/hoangnnh)\n- [Go Weekly: Go 1.23 Iterators](https://memo.d.foundation/playground/00_fleeting/go-weekly-511/), [Go Commentary July 08](https://memo.d.foundation/playground/00_fleeting/go-commentary-jul-12/), [Go Commentary July 26](https://memo.d.foundation/playground/00_fleeting/go-commentary-jul-26/)  - [@fuatto](https://github.com/fuatto)\n- [Radix sort](https://memo.d.foundation/playground/01_literature/radix-sort/) - [@hieuvd](https://memo.d.foundation/contributor/hieuvd)\n- [Feedback mechanism for LLM app](https://memo.d.foundation/playground/01_literature/feedback-mechanism/) - [@datnguyennnx](https://github.com/datnguyennnx)\n- [How to talk to ChatGPT effectively](https://memo.d.foundation/playground/00_fleeting/how-to-talk-to-chatgpt-effectively/) - [@minh_cloud](https://memo.d.foundation/contributor/minh_cloud)\n- [Local-first Software](https://memo.d.foundation/playground/01_literature/local-first-software/) - [@lapnn](https://github.com/ngolapnguyen)\n- [TIL in Dune's query](https://memo.d.foundation/updates/ogif/16-ogif-office-hours-0726/) - [@phucld](https://github.com/phucledien)\n- [AI voice clone demo](https://memo.d.foundation/updates/ogif/16-ogif-office-hours-0726/) -  [@tom](https://github.com/monotykamary)\n- [Architect supervisor AI agent](https://memo.d.foundation/updates/ogif/16-ogif-office-hours-0726/) -  [@toanhq](https://github.com/toanbku), [@datnguyennnx](https://github.com/datnguyennnx)\n- [AI code completion overview](https://memo.d.foundation/updates/ogif/16-ogif-office-hours-0726/) -  [@minhlq](https://github.com/minhluuquang)\n\n## Dwarves advancing with Golang: Enterprise solutions and industry insights\nDwarves has long embraced Golang, leveraging its performance and simplicity for enterprise solutions. We’ve pushed the boundaries with Go, exploring advanced use cases and sharing our learnings through our weekly Go commentary. \n\nBy staying ahead of market trends, we're contributing insights that shape the language's direction and adoption in the industry. For more information about Golang, reach out to @fuatto. \n\nCheck out our Go weekly updates [here](https://memo.d.foundation/tags/go-weekly/).\n\n## Pricing Model: Bill by hours\nIn response to the economic challenges and the demand for comprehensive solutions, Dwarves is now implementing an hourly billing model. This ensures fairness, flexibility, control, and transparency in our engagements. \n\nTo understand how this new model benefits both our team and our clients, read the full article [here](https://memo.d.foundation/playbook/business/pricing-model-bill-by-hours/).\n\n![](assets/2024-whats-new-july-bill-by-hour.webp)\n","title":"What's New in July 2024","short_title":"","description":"Each month, we release a recap highlighting key updates and progress within our team and community. July covers AI advancements, community contributions, insights from Vietnam's tech scene, new memo commands, OGIF automation, and the introduction of our hourly billing model","tags":["newsletter","memo","community"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_","nikki"],"date":"Fri Aug 09 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2024-whats-new-july.md","slugArray":["updates","changelog","2024-whats-new-july"]},{"content":"\n- [**memo.d.foundation**](#the-growing-of-memo-pile): more entries focusing on software design, LLM and blockchain, a key focus of our continuous learning journey. \n- [**Increased ICY Rewards**](#enable-reward-for-the-learning-system): the increasing amount of fleeting notes boosted our learning reward system.\n- [**Dwarves Token Usage**](#dwarves-token-usage-for-june): our community's exceptional engagement led to ~500 ICY rewarded for contributions, with notable efforts in OGIF talks, tech sharing, and Memo notes.\n- [**Vietnam Tech Scene**](#building-a-network-of-trusted-partners-in-vietnams-tech-ecosystem) report covered notable insights into our nation's tech landscape, as well as key players in AI, fintech, and blockchain/crypto ecosystem.\n- [**Weekly OGIF Talks**](#dwarves-office-hours-at-5pm-every-friday): Our Friday sessions promote a knowledge-sharing culture. In June, we've covered design patterns, content mapping, software design, data modalities, and blockchain architecture.\n\n![](assets/2024-whats-new-june-thumbnail.webp)\n\n## The growing of memo pile\nWith the focus on Mastery, Meaning, and Autonomy (MMA) has driven significant growth in our brainery. This is evident from the increase in content submitted by our contributors on areas for work delivery, and foundational knowledge.\n\n[memo.d.foundation](http://memo.d.foundation/), is creating a rich resource that both internal and community members can benefit from. Last month, Dwarves’ team members added several new entries from LLM, design patterns to blockchain concepts. Dwarves monthly rewards will be equally shared among all contributors.\n\n1. [A Tour of Template method pattern with Golang](https://memo.d.foundation/playground/01_literature/template-method-design-pattern/) - [@anhnh](https://github.com/anhnh12) \n2. [Multimodal in RAG](https://memo.d.foundation/playground/01_literature/Engineering/AI/multimodal-in-rag/) - [@hoangnnh](https://github.com/nnhuyhoang)\n3. [Bloom filter](https://memo.d.foundation/playground/01_literature/engineering/backend/bloom-filter/) - [@hoangnnh](https://github.com/nnhuyhoang)\n4. [Command](https://memo.d.foundation/playground/01_literature/engineering/backend/bloom-filter/), [State Pattern](https://memo.d.foundation/playground/01_literature/state-pattern/), and [Radix sort](https://memo.d.foundation/playground/01_literature/radix-sort/) - [@hieuvd](https://github.com/vdhieu)\n5. [Go Weekly: Mastering Go performance](https://memo.d.foundation/playground/00_fleeting/go-weekly-510/) - [@phatnt](https://github.com/fuatto)\n6. [Using devbox to setup local development environment](https://memo.d.foundation/playground/01_literature/devbox-local-development-env/) by [@hnh](https://github.com/huynguyenh), [@bienvh](https://github.com/baenv)\n7. [Organize team know-how with the Zettenlkasten method](https://memo.d.foundation/playground/00_fleeting/organize-team-know-how-with-zettelkasten-method/) - [@minh_cloud](https://github.com/minhcloud)\n8. [How to talk to ChatGPT effectively](https://memo.d.foundation/playground/00_fleeting/how-to-talk-to-chatgpt-effectively/) - [@minh_cloud](https://github.com/minhcloud)\n9. [Dynamic Liquidity Market Maker - a new form of concentrated liquidity AMM on Solana](https://memo.d.foundation/playground/01_literature/dynamic-liquidity-market-a-new-form-of-concentrated-liquidity-amm-on-solana/) -[@huymaius](https://github.com/quanghuynguyen1902)\n10. [Introduce Solana Token 2022](https://memo.d.foundation/playground/01_literature/introduce-to-solana-token-2022-new-standard-to-create-a-token-in-solana/) - [@huymaius](https://github.com/quanghuynguyen1902)\n11. [Solana core concepts](https://memo.d.foundation/playground/01_literature/solana-core-concepts/) - [huymaius](https://github.com/quanghuynguyen1902)\n12. [Market Report May](https://memo.d.foundation/playground/01_literature/market-report-may-2024/) - [@thanh](https://github.com/zlatanpham), [@tom](https://github.com/monotykamary)\n13. [How to make an MOC](https://memo.d.foundation/playground/01_literature/how-to-make-a-moc/) - [@thanh](https://github.com/zlatanpham)\n14. [A tour of Singleton design pattern with Golang](https://memo.d.foundation/playground/01_literature/singleton-design-pattern/) - [@anhnh](https://github.com/anhnh12) \n15. [Going through use cases of the prototype design pattern and it place among the creational pattern](https://memo.d.foundation/playground/01_literature/prototype-design-pattern/) - [@.rjim](https://github.com/R-Jim)\n16. [Introduce builder pattern and its use cased](https://memo.d.foundation/playground/01_literature/builder-design-pattern/) by [@vincent](https://github.com/tuanddd)\n17. [Explaining gradient descent in ML](https://memo.d.foundation/playground/00_fleeting/explaining-gradient-descent-in-machine-learning-with-a-simple-analogy/) - [@innno_](https://github.com/innnotruong) \n\n![](assets/2024-whats-new-june-memo.webp)\n\n## Enable reward for the learning system\nDwarves has always been a playground for techies, where learning and sharing go hand-in-hand. The increase in valuable content shared by our team and community members deserves greater recognition and rewards. \n\nTo keep the momentum going, we’ve upped the ICY rewards for our learning activities.\n\nMultiple activities are going on at [🧊・earn-icy](https://discord.com/channels/462663954813157376/1006198672486309908/1239502938918096960):\n\n- Share your expertise in OGIF talks and earn 15-25 ICY per talk.\n- Distill your OGIF insights into valuable notes on Memo and earn 10-15 ICY.\n- Got a quick learning or discovery? Share it as a fleeting note and earn 3-5 ICY.\n- Each link shared in **💡・til, 💻・tech** channels receive 1 ICY.\n- Rewarding our top contributors weekly on Friday receives 3 ICY.\n- ICY airdrop when joining community calls.\n\nEveryone in the community is welcome to join hands.\n\n![](assets/2024-whats-new-june-icy-updates.webp)\n\n## Dwarves token usage for June\nOur community's engagement has been exceptional this month, reflected in the active use of Dwarves Token. We don’t limit any roles to join us; more room means more participants. \n\nIn June alone, ~500 ICY were rewarded for all contributions, highlighting:\n\n- OGIF talks: 175 ICY (~262 USDC)\n- 183 links were shared: 166.8 ICY (~238.5 USDC)\n- Memo notes: 109 ICY (~163.5 USDC)\n\nWith notable contributors: \n\n- OGIF talks: @hieuvd, @hoangnnh, @anhnh, @jim, @taipn\n- Tech Sharing: @tom, @innno_, @bienvh, @huytq\n- Memo: @thanh, @huymaius, @hoangnnh, @jim, @hieuvd\n\nKudos to those peeps who are top contributors, @hieuvd, @thanh, @tom. \n\n## Dwarves office hours at 5PM every Friday\nOur OGIF sessions continue to be a hit. These Friday afternoon talks are a chance for team members to share their knowledge on various topics. \n\nWe have discussed: \n\n- [Behavior Design Pattern: Observe pattern, Design pattern](https://memo.d.foundation/playground/01_literature/command-pattern/) by @hoangnnh, @hieuvd\n- [Design pattern: State vs Strategy](https://memo.d.foundation/playground/01_literature/state-pattern/) by @jim, @anhnh\n- [How to make MOC (content map)](https://memo.d.foundation/playground/01_literature/how-to-make-a-moc/) by @thanh\n- [Template method](https://memo.d.foundation/playground/01_literature/template-method-design-pattern/) & [Visitor radix sort](https://memo.d.foundation/playground/01_literature/radix-sort/) by @anhnh, @taipn\n- [Go Weekly: Mastering Go performance](https://memo.d.foundation/playground/00_fleeting/go-weekly-510/)  by @phatnt\n- [Solana core concepts](https://memo.d.foundation/playground/01_literature/solana-core-concepts/) by @huymaius\n- [Multimodal in RAG](https://memo.d.foundation/playground/01_literature/Engineering/AI/multimodal-in-rag/) by @hoangnnh\n\nWe have distributed **175 ICY for OGIF in June.** \n\n![](assets/2024-whats-new-june-ogif.webp)\n\n## Building a network of trusted partners in Vietnam’s tech ecosystem\nWe're monitoring developments in Vietnam's tech landscape. Despite global economic challenges, Vietnam's tech market is thriving, making it an attractive hub for startups and investors.\n\nBy connecting key players in the ecosystem, this report aims to establish a network of trusted partners who can collaborate and drive mutual growth.\n\nKey highlights include:\n\n- **Investment and Growth:** $529 million in investments in 2023, with Vietnam ranking third in Southeast Asia for deal count and value.\n- **Sector Surge:** Substantial growth in Healthcare and Education investments, up by 391% and 107%.\n- **Digital Economy:** Fastest-growing in Southeast Asia, projected to reach $43 billion by 2025.\n- **Active-Investors:** Nearly 100 investors, including major players like 500 Startups Vietnam, VSV Capital, and VinaCapital Ventures.\n- **AI/Fintech Leaders:** Influential investors like 500 Startups Vietnam, VSV Capital, and VinaCapital Ventures significantly impact the AI and fintech sectors.\n- **Blockchain and Crypto Leaders:** Animoca Brands, Foresight Ventures, and HashKey Capital are driving innovation in the blockchain/crypto space.\n- **Legal Support:** Favorable policies fostering innovation and growth, with improved public market governance and increased M&A activities driven by local conglomerates.\n\n![](assets/2024-whats-new-june-tech-market.webp)","title":"What's New in June 2024","short_title":"","description":"In June, we expanded our knowledge base on software design, LLMs, and blockchain, while actively encouraging knowledge-sharing through increased ICY rewards. Our Vietnam Tech Scene report highlighted key industry players, and weekly OGIF talks fostered discussions on diverse tech topics like design patterns, data modalities, and blockchain architecture","tags":["newsletter","memo","community"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_","nikki"],"date":"Thu Jul 04 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2024-whats-new-june.md","slugArray":["updates","changelog","2024-whats-new-june"]},{"content":"\n- **Reporting tech signals**: everything new on artificial intelligence, API techniques, toolings, programming languages, and the intersection of design and engineering.\n- **ICY in 2024**: all you need to know about ICY’ latest updates.\n- **Demo and Showcase**: Monthly product demos and showcases are now a regular event at Dwarves.\n- **Community meet-up**: the first Dwarves x Community Members offline event in Saigon.\n\n## Reporting Tech Signals: How GenAI is changing the way developers work\nIn March 2024, we identified relevant emerging technologies and business benefits to support our technology roadmap and which trends hold the most potential across various markets.\n\nHighlights for this month:\n\n- The increasing prominence of individual-led application development alongside the growing popularity of prompt engineering and AI interfaces.\n- The noteworthy productivity potential of GenAI, drives its widespread adoption across enterprises.\n- Improved infrastructure and API techniques facilitated enhanced operational efficiency, with contributions from individual developers and tech giants such as Google, OpenAI, and Microsoft.\n- Advancements in in-app design for LLMs (Large Language Models), setting the stage for more advanced virtual assistants.\n\n[Read the full report here](https://memo.d.foundation/playground/_labs/market-report-mar-2024/)\n\n![](assets/2024-whats-new-march_2024-march-tech-report.webp)\n\n## ICY Updates in 2024\nSince its launch in September 2022, ICY was used to reward the network members and allow all members to earn ICY through engagement in discussions, research on Dwarves' tech, and more.\n\nIn March:\n\n- To welcome new members to our Discord discussions, we're giving away ICY to members with the @guest role as a warm welcome from us. Additionally, we've implemented a new role system to make it more fun and organized.\n- We transferred the ICY contract from Polygon to the Base chain, paving the way for further NFT/staking advancements, with updated Mochi & Onchain balances.\n- To expand our reach beyond Discord, we've initiated the linking of Mochi wallet accounts with GitHub accounts, rewarding linked users with ICY tokens.\n\n[How we set up Discord server](https://memo.d.foundation/playbook/community/starting-your-journey-at-dwarves-discord/)\n\n![](assets/2024-whats-new-march_2024-march-icy.webp)\n\n## Community Engagement: Offline Meetups in April\nStarting this April, we're excited to launch a fresh initiative focused on nurturing stronger connections and more meaningful interactions within our community. We'll trade our usual team dinners for engaging offline meetups held every three months in Ho Chi Minh City.  We can't wait to see you there.\n\n## Demo and Showcase: Give your screenshots a cleaner look with Backr\nThe next initiative in our monthly call will have a broader range of topics to discuss, including project demos and product showcases.\n\n- Elevate your screenshots with [Backr](https://getbackr.vercel.app/), a tool crafted by Tuan Dao. It allows you to set captivating backgrounds and make your captures look stunning.\n- Also, our team member, Khac Vy actively participates in the weekly Solana event, Build Station, which is organized every Saturday. Reach out to Khac Vy if you're interested in joining. The \"Build Station\" offers developers a platform to connect, learn, and share experiences.\n\n**Coming up:**\n\n- Mark your calendars for our first offline meetup in Ho Chi Minh City (TBA).\n","title":"What's New in March 2024","short_title":"","description":"In this March, we're eyeing on what's brewing in the tech market, ICY updates in 2024, the first offline meetup and product demo.","tags":["newsletter","ICY","tech-report","community"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Wed Apr 03 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2024-whats-new-march.md","slugArray":["updates","changelog","2024-whats-new-march"]},{"content":"\n- [**Dwarves offline meet-up:**](#dwarves-community-offline-meet-up-was-a-blast) Gathering over 50 members for networking, OGIF talks, and casual team dinner.\n- [**ICY rewards:**](#icymi-leveling-up-icy-activities-for-a-learning-pool-of-up-to-1500) We've boosted the monthly ICY reward pool to a whopping $1,500. Get ready to earn even more by sharing your knowledge.\n- [**SP Group visit & Echelon X 2024:**](#spgroup-wala-x-echelon-asia-summit-2024-new-tech-will-shape-the-future) Our team leaders attended the event and gained insights into the evolving SEA tech landscape, including AI's impact, investment trends, and digital transformation opportunities.\n- [**New collaboration:**](#rolling-out-new-collaboration-fornax-ai-yololab) Fornax AI\n- [**Exclusive Dwarves NFTs for our team:**](#dwarves-nfts-for-our-crew) Introducing new NFT roles for peeps.\n- [**Dwarves office hour:**](#from-the-last-ogif-office-hour-building-a-resilient-system) Building a resilient system with Hieu Vu, Hoang Nguyen.\n\n![](assets/2024-whats-new-may-thumnail.webp)\n\n## Dwarves community offline meet-up was a blast\nWe had a great time hosting our second Ho Chi Minh City meetup on May 31st. Over 50 awesome folks joined us for a night of tech talks, mingling, and all-around good vibes.\n\nWe chatted about what's been happening with Dwarves and heard updates from the community. Everyone seemed to have an engaging time, and we couldn't be happier with how it turned out.\n\nA big thanks to community members: @jack, @tannhatcmcs, and @congiomat for their participation. Details of our next gathering will be shared soon. We hope to have more fun things for everyone to take part in the part.\n\n![](assets/2024-whats-new-may-meetup.webp)\n\n## ICYMI: Leveling up ICY activities for a learning pool of up to $1500\nWe're spicing up the way you earn ICY rewards. Now in May, the thing we are doing is so-called building a protocol reward activities across our community. Participating in server events is a certain way to amass ICY. \n\nHead on over to [**🧊・earn-icy**](https://discord.com/channels/462663954813157376/1006198672486309908/1239502938918096960) for all the deets on this exciting new chapter.\n\n![](assets/2024-whats-new-may-icy-distribution.webp)\n\n## SPGroup WALA x Echelon Asia Summit 2024: New tech will shape the future\nLast month, our team leaders @tieubao, @nikki, and @huytq attended the Echelon Asia Summit held in Singapore on May 15-16. The event focused on the future of Southeast Asia's tech and startup ecosystem, highlighting merger and acquisition trends and high-growth industries.\n\nWe had a chance to observe how investors and startups are changing their approach to using money, the evolution of AI, and upcoming projects in the APAC tech startup landscape. \n\nThe foremost is we want to stay true to our path and keep innovating in ways that help our company and positively impact the broader tech ecosystem.\n\n[The full Echelon Recap can be found here.](https://memo.d.foundation/playground/01_literature/echelon-x-singapore-2024-where-innovations-meet-inspiration/)\n\n![](assets/2024-whats-new-may-echelon.webp)\n\n## Rolling out new collaboration: Fornax AI\nWe're thrilled to share the exciting news of our latest collaboration kickstarted in May - [Fornax AI](https://fornax.ai/).\n\nFornax AI helps startup founders improve their pitch decks with detailed feedback using ChatGPT for content and visual enhancements. They also offer white-label products for pitch deck ratings, supporting digital product development. \n\nTo enhance their offerings, Fornax is teaming up with us, integrating our advanced language models and AI-driven insights. \n\n## Dwarves NFTs for our crew\nTo show our appreciation, we've launched a special Dwarves NFT collection for peeps. These unique non-transferable tokens celebrate your contribution to the Dwarves community. Check out your NFT on OpenSea at https://opensea.io/collection/dwarves-4.\n\n@Tono Bot will automatically grant the @peeps role to everyone with this NFT in their connected wallet. Connect your wallet to Tono and enjoy the @peeps role. For further information go to the ⁠🧊[**・earn-icy⁠**](https://discord.com/channels/462663954813157376/1006198672486309908/1228177919436918875) channel.\n\n![](assets/2024-whats-new-may-nft-role.webp)\n\n## From the last OGIF office hour: Building a resilient system\nThere have been many interesting discussions over the past two months since OGIF resumed. Topics ranged from new findings to techniques, software engineering, and industry insights. \n\nNotably, @hoangnguyen and @hieuthu2 gave an insightful talk on “Building a Resilient System.” They covered key aspects of system resilience, including designing for failure, implementing redundancy, and ensuring continuous availability.\n","title":"What's New in May 2024","short_title":"","description":"May was our month for meetups, upgrading our monthly learning pool, launching NFT roles for our team members, onboarding new collaboration, recapping the SP Group visit & Echelon X 2024, and hosting an OGIF office hour.","tags":["newsletter","meet-up","community"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Thu Jun 13 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2024-whats-new-may.md","slugArray":["updates","changelog","2024-whats-new-may"]},{"content":"\n- [**Building the team’s second brain:**](#building-smarter-systems-with-platform--data-engineering) Progress in platform & data engineering, smarter decision-making, and new directions ahead.\n- [**Sharpening OGIF weekly sharing:**](#sharpening-ogif-office-hours-where-learning-grows) Updates to align with team priorities and industry trends for deeper learning.\n- [**Team copilot tools:**](#team-copilots-index-smarter-tools-to-simplify-your-work) Advancing productivity with AI copilots - tools designed to streamline and elevate our work.\n- [**Adapting to market shifts:**](#in-demand-skills-staying-ahead-in-market-shifts) Insights into client demands and the rise of Blockchain, Data, Platform, and AI/LLM.\n- [**Market insights radar:**](#industry-radar-sharing-signals-that-drive-us) Biz team is tracking trends and delivering weekly updates to keep us aligned.\n- [**New service offerings:**](#new-service-packages-solutions-designed-for-real-needs) Redesigned packages tailored to meet client needs with innovative solutions.\n- [**Earn more ICY:**](#high-quality-knowledge-sharing-earns-bigger-icy-rewards) Recognizing quality contributions with higher rewards for impactful sharing.\n- [**Fostering connections:**](#engaging-with-the-industry-showing-up-and-sharing-back) Summits, meetups, and chances to grow valuable relationships.\n- [**Let’s go to Penang:**](#pack-your-bags-penang-awaits-for-the-company-trip) Company trip confirmed for 14 - 17/12/2024, get ready for a memorable team retreat.\n- [**Join the team:**](#join-us-opportunities-in-marketing-biz-dev-and-full-stack-roles) Open roles for Marketing Executive, Business Development Specialist, and Full-stack Engineering, be part of Dwarves.\n\n![](assets/2024-whats-new-november-thumbnail.png)\n\n## Building smarter systems with platform & data engineering\nWe’re doubling down on Platform & Data Engineering, building a “second brain” for smarter decision-making and seamless knowledge sharing. \n\nLast month's progress: wrapped up bounties for **Notion** and **Slack**, with **Telegram** and **JIRA** integrations coming up. The new **🧊・bounties** channel keeps track of all updates and next steps. The goal? A solid foundation where insights and decisions fuel smarter operations.\n\nNext up: we're fine-tuning our integrations to stay ahead of our clients' needs. Keep an eye on the bounties channel - more updates are coming as we build.\n\n![](assets/2024-whats-new-november-platform-data-engineering.png)\n\n## Sharpening OGIF office hours: Where learning grows\nOGIF Office Hours is getting better with each session. We keep things simple: pick a topic that matters, learn from each other, and walk away with something useful. Since resuming in April, these learning activities have become the cornerstone of a consistent habit. \n\nWhat's working well:\n\n- Quick, focused talks on tools and problems we face daily.\n- Everyone gets to share their take - from demos to technical deep dive sessions.\n\nDrop by and bring what you're working on or learning about. Could be a new tool you're trying out, or that tricky bug you solved. These sessions work best when we all chip in.\n\n## Team copilots index: Smarter tools to simplify your work\nWe've put together a list of all our AI copilots in one place. It’s a simple collection of tools the team built to solve real problems and make the work smoother. \n\nWhat’s in it for you?\n\n- Tools your teammates have already built and use.\n- Starting points for building your own copilot.\n- Ready-to-use AI helpers for your daily tasks.\n\nExplore the index: [**Team Copilots**](https://memo.d.foundation/playground/ai/copilots/team-copilots).\n\nGot ideas for new tools or ways to make existing ones better? We'd love to hear them.\n\n![](assets/2024-whats-new-november-team-copilot.png)\n\n## In-demand skills: Staying ahead in market shifts\nThe tech world doesn’t stand still, opening up exciting opportunities for growth and change.\n\nHere’s where we see the shifts:\n\n1. More interesting work ahead - clients want folks who can mix skills like backend/full-stack\nwith Blockchain or Data.\n2. Generative AI continues to make waves, with solution design and system architecture becoming the real differentiators.\n3. The road ahead is rich with potential in **Blockchain, Data, Platform, and AI/LLM.**\n\nHow to stay ahead:\n\n- Pick something that interests you from Blockchain, Data, Platform, or AI/LLM.\n- Chat with your manager about what you want to learn - they're here to support you.\n- Got something cool to share? Write a memo or bring it to OGIF.\n- Need a place to start? Check out Tom’s **[Bounty List](https://memo.d.foundation/earn/)** - we've got some interesting problems to solve.\n\n![](assets/2024-whats-new-november-platform-market-shift.png)\n\n## Industry radar: Sharing signals that drive us \nKeeping up with the market is a must. Our Biz Dev and Community teams are diving into trends, picking out key signals, and breaking down what they mean for us.\n\nEach week, these insights flow back to the team through OGIF updates or dedicated sessions, turning external shifts into clear, actionable steps. The goal is clarity: staying informed, aligned, and ready to adapt as opportunities arise. Stay tuned for the first relay.\n\n![](assets/2024-whats-new-november-market-signals.png)\n\n## New service packages: solutions designed for real needs\nWe've reshaped our services around a simple idea: solve real problems, do it well. After working closely with clients and seeing what really moves the needle, we're focusing on three areas where we excel - AI integration, platform scaling, and blockchain systems.\n\nWhy this matters:\n\n- Teams get solutions they can actually use, not just fancy tech.\n- Projects move faster because we know what works.\n- Everyone spends time on work that makes a difference.\n\nWith a clear focus on what works, these updates make it easier to deliver results that matter, quickly and effectively without overloading with options. \n\n## High-quality knowledge sharing earns bigger ICY rewards\nWe've been tuning up our rewards for knowledge sharing in **💻・tech**, **💡・til**, and **🧠・ux.** Good ideas deserve good rewards. \n\nHere's how it works:\n\n- Drop a useful link, grab 0.3 ICY - it's a start.\n- Got the team interested? 5+ reactions bumps you up to 3 ICY.\n- Share something that catches [@tom](https://memo.d.foundation/contributor/tom), [@thanh](https://memo.d.foundation/contributor/thanh/), or [@tieubao](https://memo.d.foundation/contributor/han/)'s eye as high-quality? That's 3 ICY right there.\n- Add your own thoughts and break it down for everyone? You could snag up to 5 ICY.\n\nPop into our Discord and share what interests you.\n\n![](assets/2024-whats-new-november-earn-more-icy.png)\n\n## Engaging with the industry: Showing up and sharing back\nThe tech community is active right now, and we're right in the mix. We’re diving headfirst into events, meetups, and summits to connect with the tech community. That gives us a clearer sense of where we need to grow. \n\nWhat we’re doing:\n\n- Connecting at the right places - tech meetups, summits, and shows where we meet peers, partners, and clients who are building interesting things.\n- Bringing knowledge back home - capturing insights from every event through memos, podcasts, and OGIF sessions.\n- Adding to the conversation - taking what we've learned and built, and sharing it back with the community.\n\n## Pack your bags: Penang awaits for the company trip\nGet ready - we're taking the team to **Penang, December 14–17, 2024**. After a year of shipping great work, it's time for some team adventures in Malaysia.\n\nFour days of good food, beach vibes, and quality time with the crew. We've planned a mix of activities that'll let you experience the best of Penang while getting to know your teammates better.\n\n Highlights to expect:\n\n- Team activities that bring us closer.\n- Local food and culture to explore.\n- Time to kick back and recharge.\n\nGrab the details in **🦄・pink-alert** and stay tuned. \n\n## Join us: opportunities in Marketing, Biz Dev, and Full-Stack roles\nWe’re still on the lookout for talented folks to join the team:\n\n- [Full-stack Engineer (Blockchain)](https://memo.d.foundation/careers/open-positions/full-stack-engineer/)\n- [Marketing Executive](https://memo.d.foundation/careers/open-positions/marketing-and-communications-specialist/)\n- [Business Development](https://memo.d.foundation/careers/open-positions/business-development/)\n\nThink you’re a fit or know someone who is? Drop us a line at [spawn@d.foundation](mailtospawnd.foundation) or ping [@nikki](https://memo.d.foundation/contributor/nikki) on Discord.\n\n![](assets/2024-whats-new-november-hiring.png)","title":"What's New in November 2024","short_title":"","description":"In November, we sharpened our focus with advancements in platform engineering, introduced streamlined service packages, elevated ICY rewards for impactful contributions, and embraced key insights from market shifts—all building momentum as we gear up for our Penang retreat.","tags":["newsletter","memo","community"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Wed Dec 04 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2024-whats-new-november.md","slugArray":["updates","changelog","2024-whats-new-november"]},{"content":"\n- [**We’re Hiring:**](#were-hiring) On the lookout for Full-stack Engineers, Biz Devs, and Marketing minds to join the team.\n- [**Labs OGIF Office Hour - Building Core Knowledge:**](#labs-ogif-office-hour---building-core-knowledge) Weekly sessions diving deep into AI, Blockchain, Architecture, and Finance fundamentals.\n- [**Join Dwarves Open Source,**](#dwarves-open-source---join-the-movement) a great time to build and learn through OSS work. From libraries to AI tools, every contribution counts.\n- [**Navigating Market Shifts:**](#navigating-market-shifts) Adapting to client needs and honing in on AI, Blockchain, and Data for a sharper edge.\n- [**Weekly Commentary - Product Design & AI Digest:**](#weekly-commentary---product-design--ai-digest) A new weekly series with fresh insights into product design and AI trends.\n- [**Vietnamese Women’s Day Throwback:**](#throwback-to-vietnamese-womens-day) We celebrated with heartfelt gifts and a dinner to honor our talented women.\n\n![](assets/2024-whats-new-oct-thumbnail.png)\n\n## We’re hiring\nOur team is growing, and we’re scouting for driven talent to join us on the journey. We’re on the lookout for:\n\n- [Full-stack Engineer](https://memo.d.foundation/careers/open-positions/full-stack-engineer/) (Project-based Contractor)\n- [Business Development](https://memo.d.foundation/careers/open-positions/business-development/) (Fulltime)\n- [Marketing & Communications](https://memo.d.foundation/careers/open-positions/marketing-and-communications-specialist/) (Fulltime)\n\nThink you know someone who’s up for the challenge? Email us at spawn@d.foundation or ping [@nikki](https://memo.d.foundation/contributor/nikki) on Discord for more info.\n\n## Labs OGIF office hour - Building core knowledge\nWe’re making knowledge-sharing worth it. AI/LLM contributions this month scored 3x-4x rewards, as a big thanks to everyone bringing in their insights.\n\nOctober’s OGIF office hour? Think deeper discussions, a sharper focus. We’re using these sessions to dig into AI, Blockchain, Architecture, and Finance - getting the team solid on these core themes while still exploring emerging trends.\n\nEvery Friday, it’s about putting learning into practice. If you’ve got an idea or a topic to add to the mix, reach out to [@thanh](https://memo.d.foundation/contributor/thanh/), [@innno_](https://memo.d.foundation/contributor/innno_/).\n\n![](assets/2024-whats-new-oct-ogif.png)\n\n## Dwarves open source - Join the movement\nWe’re leaning all the way into open source. Got a library, tool, or AI project you’re working on? Host it under your name, share it, and earn ICY rewards along the way. This is about fueling innovation from the ground up - one contribution at a time. Want to chip in? Check out our [**GitHub**](https://github.com/dwarvesf/opensource).\n\n[Join us on Discord](https://discord.gg/dwarvesv) to get started.\n\n![](assets/2024-whats-new-oct-oss.png)\n\n## Navigating market shifts\nWe’re re-centering our focus to meet the moment. AI, blockchain, data - this is where we’re investing our time and talent, as we keep pace with client needs and market demands.\n\n1. **Consulting Shift**: As client requirements change, so do our team’s. We’re doubling down on core contributors who are active, adaptable, and ready to take on high-impact projects. Others may need to pause or refocus to keep pace with where we’re going.\n2. **Lab Team**: The Lab remains the heartbeat of our innovation. Expectations (and rewards) are higher for those pushing the boundaries, writing, exploring, and applying new ideas.\n3. **Community Backbone**: Nine years in, our Discord stays strong - a space for learning, sharing, and connecting, whether you’re new, tenured, or an alumni. \n\n## Weekly commentary - Product design & AI digest\nRolling out two new series this month: a Product Design Weekly and an AI Digest. It’s insight meets action, with practical takes on where product design and AI are headed.\n\n- **Product Design Weekly:** A no-nonsense look at what’s actually working in design. Real-world insights, practical UI/UX tips, and everything you need to create experiences that stick.\n- **AI Digest:** Your weekly dose of AI, minus the hype. From useful tools to practical insights, it’s what you need to know to stay smart about where AI is headed.\n\n![](assets/2024-whats-new-oct-commentary.png)\n\n### Throwback to Vietnamese Women’s day\nWe took a moment to celebrate to celebrate the women at Dwarves. We marked the occasion with a round of gifts and a cozy team dinner - just a simple way to say thanks to the incredible women who shape our team and bring heart to our work every day.\n\n![](assets/2024-whats-new-oct-women-day.png)","title":"What's New in October 2024","short_title":"","description":"Each month, we roll out a recap of our team and community’s progress. October's updates spotlight our open source initiative, boosted rewards for sharing knowledge, navigating market shifts, weekly tech insights, and a warm celebration of Vietnamese Women’s Day.","tags":["newsletter","memo","community"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Fri Nov 15 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2024-whats-new-oct.md","slugArray":["updates","changelog","2024-whats-new-oct"]},{"content":"\n- [**🧙・ai-club:**](#ai-club-building-ai-agents-ai-sheep-role--copilot-bounties) We launched the AI-Club, your go-to hub for diving into AI and LLMs, where curiosity sparks real projects and dynamic discussions.\n- [**Record & Reward Sharing Culture:**](#record-and-reward-culture-with-a-monthly-pool-up-to-2500-icy) We’re putting real value behind shared knowledge. AI/LLM contributions earned 3x-4x rewards this month. Shoutout to those leading the charge.\n- [**Hybrid Working & Auto Check-In:**](#return-to-the-office-auto-check-in--icy-perks) Stay in sync with the team and our learning culture. Check-in and earn 5 ICY—a simple nudge to keep us connected.\n- [**Tech Report - Forward Engineering:**](#forward-engineering-q3-tech-roundup-experiments-insights-and-whats-next) This quarter, we cut through the noise, focusing on AI and what truly drives impact. The report highlights tools, insights, and trends shaping our engineering path.\n- [**Mid-Autumn Festival:**](#mid-autumn-festival-recap) We celebrated with mooncakes and meaningful moments, keeping the hustle—honoring tradition without missing a step.\n\n![](assets/2024-whats-new-sep-theme.png)\n\n## AI Club: Building AI agents, AI-Sheep role & Copilot bounties\nThe AI-Club is officially live, becoming the go-to hub for anyone eager to dive into AI and LLM technologies. It’s where exploration turns into practical, productivity-boosting outcomes:\n\n- **🧙・ai-club**: A collaborative space laser-focused on building AI agents that will turbocharge productivity across our projects. Think of it as your secret weapon—one that transforms your workday from grind to grand.\n- **Copilot Bounties**: Get involved and get rewarded. We're putting bounties on the line for those who build and contribute impactful AI/LLM insights, projects, or solutions.\n\n![](assets/2024-whats-new-sep-copilot-y.png)\n\nHere’s a thought – why not try out one of the AI tools we've built in the club or create something practical yourself? It could be fun, and you might even snag some extra ICY along the way.\n\n**Q: How do I get the ai-sheep role?**\n\n> The ai-sheep role is for those who actively show interest in AI within our server by reading, sharing lightning talk, and practicing it. It's open to everyone.\n>\n\n![](assets/2024-whats-new-sep-community-member.png)\n\n## Record and reward culture with a monthly pool up to 2500 ICY\nWe’re doubling down on creating a learning culture where knowledge isn't just shared—it's rewarded. Our aim? To push our learning culture even further.\n\n**What It Means**\n\nWe're not just talking about learning; we’re making it a core part of how we grow as a team.\n\n- **ICY Rewards**: A monthly pool of 2500 ICY (~$4000) is up for grabs. A solid 70% is earmarked for AI/LLM, Golang, Software Architecture, and Blockchain.\n- **How to Join**: Share valuable links in **💻・tech**, join OGIFs, or contribute to open-source projects that boost team productivity.\n- **Triple Rewards for AI/LLM Content**: We're boosting rewards 3-4x for AI/LLM-related contributions. Dive into topics like building LLM applications, tools, prompts, and workflows.\n\nFeel free to ping @Tom or @thanh for more guidance. Check out [🚨・red-alert](https://discord.com/channels/462663954813157376/915941020968046612/1281097666809434184) for the details.\n\nIn September, 1054 ICY (~1581 USDC) were rewarded for all contributions, including:\n\n- OGIF talks: 255 ICY (~382.5 USDC)\n- 542 links shared: 542 ICY (~813 USDC)\n- Memo notes: 81 ICY (~121.5 USDC)\n\nCheers to everyone who’s stepped up and contributed to the Dwarves community: @theoctopus, @wing, @tom, @minhlq, @ohagi, @lapnn, @taipham, @huytq, @datnguyen, @vincent, @antran, @tristran, @innno_, @catng, @Truongquoctuan, and @nam.\n\n![](assets/2024-whats-new-sep-sharing-culture.png)\n\n## Return to the office: Auto check-in & ICY perks\nWe're keeping the team sharp and connected with the latest in tech. That's why we're getting back into the groove of office life. Automation check-in is now live at 🏢・lobby, keeping us all in sync. Check-in and snag 5 ICY as a \"Welcome Back\" perk. A big nod to @Tom for making this seamless with his work on the system.\n\n[Read our hybrid culture story.](https://memo.d.foundation/updates/digest/14-a-home-away-from-home/)\n\n![](assets/2024-whats-new-sep-hado.png)\n\n## Forward engineering Q3 tech roundup: Experiments, insights, and what’s next\nQ3 was all about refining our tech approach. **Dify** speeds up LLM app prototyping, **LangGraph** is promising for multi-agent LLMs, and **RAG** enriches AI with external data. We're experimenting with **LangSmith** for production-grade LLMs, using **Cursor** in VSCode, and exploring **Devbox** for cleaner dev setups. **Shadcn/ui** is making UI work faster.\n\n**Our Learnings:** AI & LLM structured outputs, weekly **Golang** insights on Go 1.23, revisiting GoF design patterns, and dove deep into **Solana** and **TON** in blockchain.\n\nAI isn’t a fad—72% of YC’s latest batch says it all\n\n[For a deeper dive, read the full report.](https://memo.d.foundation/playground/01_literature/engineering/forward-engineering-q3-2024/)\n\n![](assets/2024-whats-new-sep-forward-engineering.webp)\n\n## Mid-Autumn festival recap\nWe had ourselves a proper little mooncake moment for the Mid-Autumn Festival. Nothing fancy, just a chance to pause, share a bit of tradition, and enjoy a sweet break together. Whether in the office or dialing in from afar, it was a reminder that it’s the little things that keep us connected.\n\n![](assets/2024-whats-new-sep-mooncake.jpg)\n","title":"What's New in September 2024","short_title":"","description":"Each month, we roll out a recap of our team and community's strides forward. September's updates spotlight the AI Club launch, rewards for our sharing culture, hybrid work check-ins, reporting tech trends in forward engineering, and our Mid-Autumn celebration.","tags":["newsletter","memo","community"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Tue Oct 01 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2024-whats-new-september.md","slugArray":["updates","changelog","2024-whats-new-september"]},{"content":"\n- [**From remote-first to hybrid:**](#the-transition-to-hybrid-mode-strengthening-team-presence-with-coordination-and-perks) We’ve transitioned to a hybrid model, coordinated schedules, and rolled out perks like lunch support, transport coverage, and an Office Leaderboard to keep engagement high.\n- [**ICY to BTC transition is in motion:**](#icy-to-btc-transition-from-experiment-to-the-next-chapter) ICY to BTC transition is in motion: We completed the first demo, proving the swap mechanism works. Now, we’re in the final testing phase before the official launch.\n- [**Reporting tech signals:**](#reporting-tech-signal-forward-engineering-2024) Dwarves Forward Engineering 2024 with moving in AI agents, blockchain applications, and the evolving talent market, key trends we’re keeping an eye on.\n- [**Engineering solutions in action:**](#technical-case-studies-updated-engineering-solutions-across-ai-data-and-trading-systems) We’ve updated case studies covering AI-powered project reporting, security enhancements, real-time trading analytics, and optimized data storage.\n- [**Skip-level meeting with CEO:**](#skip-level-meeting-open-conversations-with-ceo) A space for direct, open discussions about challenges, new ideas, and improving how we operate.\n- [**Annual health checkup:**](#annual-health-check-up-keeping-the-team-in-check) Routine screenings are scheduled for team members in HCM and Hanoi, with travel support for those in other locations.\n- [**Health insurance renewal in progress:**](#health-insurance-renewal-in-progress) Bao Minh renewal process is underway, with details being finalized and updates coming in Basecamp.\n- [**New Year gathering kicked off the year:**](#team-moments-new-year-gathering--tết-celebrations) We reunited to share stories and set the tone for 2025.\n\n![](assets/2025-whats-new-feb-thumbnail.png)\n\n## The transition to hybrid mode: Strengthening team presence with coordination and perks\nOne month into the Hybrid Working model, and we’re picking up the pace. The shift from remote-first to hybrid means more structured office days, better team alignment, and a smoother workflow.\n\nTo keep things running efficiently, we’ve:\n\n- Coordinated team schedules so office days are planned with purpose.\n- Workspace upgrades: Apple Studio Displays and Herman Miller chairs are now in place, with more improvements on the way.\n- Added perks: lunch support, transport coverage (3 ICY per check-in), and stocked office supplies.\n- Launched the Office Leaderboard with the office-lover role: shoutout to [@quang](https://github.com/lmquang) and [@vincent](https://github.com/tuanddd) for topping the chart this month. They’ll enjoy a free drink for every office day next month as a reward.\n\nMore hands in, fewer blockers. Got ideas to make the workspace better? Drop them in 🏢・lobby or open a support ticket. We’re listening.\n\n![](assets/2025-whats-new-feb-backt-to-office.png)\n\n## ICY to BTC transition: From experiment to the next chapter\nICY started in 2020 as our first community experiment, evolving into a reward system by September 2022. Since then, it has powered engagement, rewarding contributions in discussions, research, and beyond.\n\nLast month, we demoed the ICY-to-BTC swap, a major step toward transitioning to a more sustainable and future-proof reward system. The swap interface is in place, and the mechanics are working. Now, we’re fine-tuning the final details before the official launch.\n\nWhat’s next?\n\n- Final testing and security checks.\n- Launch announcement with a step-by-step guide.\n- Support for a smooth transition.\n\nStay tuned for the final rollout.\n\n![](assets/2025-whats-new-feb-icy.png)\n\n## Reporting tech signal: Forward engineering 2024\nIn 2024, we’ve mapped out key emerging technologies and their business impact to refine our technology roadmap and pinpoint the trends with the most potential across different markets.\n\nKey highlights:\n\n- AI agents are shifting from no-code to developer-driven workflows, with teams favoring self-hosted AI tools for better control.\n- On the blockchain side, AI-powered on-chain actions are being explored for smart contract analysis and automated trading.\n- Full-stack and AI/ML engineers remain the most sought-after roles, while AI automation is reshaping traditional software development. VC funding is leaning toward leaner, cost-efficient AI solutions.\n- More to watch: AI governance, performance optimizations (DuckDB, WASM), and decentralized identity tech.\n\nFor the full read, [check out.](https://memo.d.foundation/updates/forward-engineering/2024-2025/) \n\n![](assets/2025-whats-new-feb-forward-engineering.png)\n\n## Technical case studies updated: Engineering solutions across AI, data, and trading systems\nIn this cycle, we focused on refining systems, improving performance, and integrating AI across our projects. Here’s what the team has been working on:\n\n- [Project reports system](https://memo.d.foundation/playground/use-cases/ai-powered-monthly-project-reports/) *([@tom](https://memo.d.foundation/contributor/tom)):* Structuring raw data into insights that power operations.\n- [AI-powered Ruby travel assistant](https://memo.d.foundation/playground/use-cases/ai-ruby-travel-assistant-chatbot/) *([@tom](https://memo.d.foundation/contributor/tom)):* Leveraging Ruby + AWS Bedrock for a secure and maintainable AI assistant.\n- [Binance transfer tracking](https://memo.d.foundation/playground/use-cases/binance-transfer-matching/) *([@bienvh](https://memo.d.foundation/contributor/bienvh)):* Transforming fragmented transaction logs into structured fund flow data.\n- [BTC-altcoin hedging indicators](https://memo.d.foundation/playground/use-cases/bitcoin-alt-performance-tracking/) *([@bienvh](https://memo.d.foundation/contributor/bienvh)):* Visualizing performance metrics with Matplotlib & Seaborn.\n- [AI chatbot for project management](https://memo.d.foundation/playground/use-cases/building-chatbot-agent-for-project-management-tool/) *([@thanh](https://github.com/zlatanpham)):* Automating workflows using LangChain, LangGraph & GPT-4.\n- [Centralized monitoring for trading](https://memo.d.foundation/playground/use-cases/centralized-monitoring-setup-for-trading-platform/) *([@thanh](https://github.com/zlatanpham))* , *([@quang](https://github.com/lmquang)):* Implementing Grafana & Prometheus for real-time alerts and system integrity.\n- [Crypto market visualization in Golang](https://memo.d.foundation/playground/use-cases/crypto-market-outperform-chart-rendering/) *([@bienvh](https://memo.d.foundation/contributor/bienvh)):* Interactive charts tracking BTC-Alt dynamics.\n- [Data archival & recovery](https://memo.d.foundation/playground/use-cases/data-archive-and-recovery/) *([@bienvh](https://memo.d.foundation/contributor/bienvh)):* Long-term stability strategies for high-volume trading systems.\n- [Database security hardening](https://memo.d.foundation/playground/use-cases/database-hardening-for-trading-platform/) *([@thanh](https://github.com/zlatanpham)):* Strengthening access control with RBAC, MFA, and network isolation.\n- [Binance PNL analysis with Phoenix liveview](https://memo.d.foundation/playground/use-cases/implement-binance-future-pnl-analysis-page/) *([@minhtran](https://github.com/thminhVN)):* Real-time portfolio tracking using server-side rendering & WebSockets.\n- [Migrating to TimescaleDB](https://memo.d.foundation/playground/use-cases/migrate-normal-table-to-timescale-table/) *([@minhtran](https://github.com/thminhVN)):* Boosting query performance with hypertables.\n- [Hedge Foundation UI optimization](https://memo.d.foundation/playground/use-cases/optimizing-ui-for-effective-investment-experience/) *([@anna](https://memo.d.foundation/contributor/anhtran/)):* Improving investment dashboards for seamless decision-making.\n- [Historical data persistence](https://memo.d.foundation/playground/use-cases/persist-history-using-data-snapshot-pattern/) *([@bienvh](https://memo.d.foundation/contributor/bienvh)):* Implementing data snapshots for efficient long-term storage.\n\n![](assets/2025-whats-new-feb-usecase.png)\n\n## Skip-level meeting: Open conversations with CEO \nLast month, Skip Level Meetings kicked off, offering a direct space to raise blockers, no back-and-forths, just a space to bring up challenges, new directions, feedback, and talk about what’s working (or not).  \n\nWhether it’s about team operations, roadblocks in projects, or simply sharing thoughts on where we’re headed, this is a chance to have real discussions that drive change.\n\nIf there’s something on your mind, this is the place to discuss it.\n\n## Annual health check-up: Keeping the team in check\nWe are preparing for the annual health checkup, ensuring everyone gets their routine screening done. Team members in HCM and Hanoi will have designated locations, while those from other areas can arrange travel to complete theirs.\n\nFor any questions, reach out to [@innno_](https://github.com/innnotruong).\n\n## Health insurance renewal in progress\nThe Ops Team is managing the renewal process for our Bao Minh health insurance to ensure continuous coverage for everyone. Details are being finalized, and updates will be shared in the Basecamp thread once the process is complete. Stay tuned.\n\n## Team moments: New year gathering & Tết celebrations\nWe kicked off the Year of the Snake with our team reunion, creating space to share stories, reconnect, and set intentions for the year ahead. These moments remind us why we do what we do, building not just great technology but a community where everyone can thrive.\n\n[Check out Weekly Digest #15](https://memo.d.foundation/updates/digest/15-new-year-gathering/) for photos and highlights from our New Year gathering.\n\n![](assets/2025-whats-new-feb-tet-gathering.png)","title":"What's New in February 2025","short_title":"","description":"Each month, we roll out a recap of our team and community's strides forward. February’s recap covers the hybrid mode shift, ICY-to-BTC swap testing, updated use cases with AI and trading solutions, skip-level meetings, and the New Year gathering kickoff.","tags":["newsletter","memo","community"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Tue Mar 04 2025 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/2025-whats-new-february.md","slugArray":["updates","changelog","2025-whats-new-february"]},{"content":"\n2022 matched us with the 80th Dwarves. A notable highlight, and we're ready to have more. It's not easy to find people that has the same value. It takes true & solid seeks.\n\nOn our way to meet the 81th and onward, we're launching a mechanism to help us find like-minded DNAs, and co-create our future using tech.\n\n### The Dwarves Referral Program\n\nWe usually hire and keep the quality bar. The Dwarves are encouraged to recommend friends they think might be a good match for the team. The suggestion, then, appears more valuable that you already know who the missing piece is. A quick suggestion on the talent pool\n\n* Ex-colleagues\n* University acquaintance\n* High school peeps\n\nWe want to spend the bonus on you rather than the headhunting agency. Once the referral gets successfully converted into a full-time position and deployed to a project, the referrer will receive **2.5%** of the project service fee. This ratio is applicable until Jan 01/ 2023.\n\n#### Calculation\n\nThis bonus is paid upon completion of the project invoice. The referrer must still be employed with the company when the bonus is to be given.\n\nLet's take this for example:\n\n* A refers B to Dwarves Foundation\n* B works on project C, with a monthly service fee of $5000\n* Every time clients finish the monthly invoice for project C, A will receive a referral bonus of $125\n\n📍 Thus, for **5** referral cases, you’ve just grown the passive income to **$625/ month**.\n\n### Backed by the automation\n\nIf there's one amongst the things we stay proud of, is that whenever the situation calls for ad-hoc solutions, the team is ready to provide. Folks, meet the **Dwarves' Referral Dashboard of 2022**.\n\nThe latest stats on our current referral bonus & the top leaderboard. A huge thanks to Huy Nguyen & Khoi Le for helping making this happened.\n\n![](assets/road-to-100_95d0da92d70d9f9296c5f6272250ad6f_md5.webp)\n\n![](assets/road-to-100_8a7a01a12a0d02bfbc4ea9dc305d68e1_md5.webp)\n\nReferral from the team will have a higher chance of being prompted.\n","title":"Road To 100","short_title":"","description":"2022 matched us with the 80th Dwarves. A notable highlight, and we're ready to have more. It's not easy to find people that has the same value. It takes true & solid seeks.","tags":["team","software","employee","updates"],"pinned":false,"draft":false,"hiring":false,"authors":["tieubao","nikki","duy"],"date":"Fri Aug 26 2022 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/changelog/road-to-100.md","slugArray":["updates","changelog","road-to-100"]},{"content":"\nThis is the culture test for Dwarves, developed as we face the challenges of the late 2024 market. The goal is simple: to focus on what matters most—our cultural values. This test isn’t about jumping through hoops; it’s about understanding how we work, what we stand for, and how you can contribute. \n\nIt includes personal stories, practical applications, and creative problem-solving tasks. Scoring 60+ points is great, but what really matters is being honest, thoughtful, and aligned with the Dwarves Foundation spirit.\n\n**Language:** You may write in **Vietnamese** or **English.**  \n**Passing Score:** Achieving **60 points** is considered **qualified.**\n\n### Submission Instructions\n\n- Prepare your responses in **multiple Markdown files (.md).**\n- Submit your work via a link to **[gist.github.com](https://gist.github.com).**\n\n### 1. Warm-Up (10 pts)\n\nChoose **one** prompt and provide your answer:\n\na) Reflect on something that happened in the last 90 days that you’re proud of.  \nb) Name a person who has had the most powerful influence on who you are today. How has this person shaped you?  \nc) Imagine being diagnosed with a rare disease. Would you prefer to live healthily for 6 more months, or live dependent and debilitated for 6 more years? Explain your choice.  \nd) Recall the last time you cried when you were alone. What was the situation?  \ne) Do you feel you’ve achieved mastery in any area of your life? If so, where?\n\n### 2. Culture (20 pts)\n\nChoose **one** topic and share:\n- **Personal Story (50%)**: Share a personal experience related to the topic.\n- **Reflection (50%)**: Share your thoughts or insights about it.\n\na) _Pressure makes diamonds._  \nb) _Like attracts like._  \nc) _No mud, no lotus._\n\n### 3. Knowledge (30 pts)\n\nExplain how professionals in **design, development, sales, project management,** or **leadership roles** are using **LLMs (Large Language Models)** to enhance their workflows. Provide a detailed **demonstration** or example.\n\n### 4. Productivity (40 pts)\n\nChoose **one** and elaborate:\n\na) Identify a productivity technique relevant to your position. Explain how to adopt and implement it effectively.  \nb) Use **Dify** to create an agent or design a workflow.\n\n### 5. Optional (Bonus 10 pts each)\n\na) Demonstrate how to use LLMs to quickly learn a new domain. Provide an example.  \nb) Explain how to leverage LLMs to identify gaps in knowledge or uncover what we don’t know.","title":"Culture Test","short_title":"","description":"Here's the culture test created during the market challenges of late 2024. It is designed to highlight and reinforce the cultural values at Dwarves Foundation. It’s a chance to reflect, share, and show how you fit into our team.","tags":["culture","test"],"pinned":false,"draft":false,"hiring":false,"authors":["tieubao"],"date":"Mon Sep 30 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/culture-test.md","slugArray":["updates","culture-test"]},{"content":"\n### Lock in Your Workspace. Show the World.\nOur Discord crew is buzzing with energy after our last Friday community call, with folks sharing snapshots of their workspaces. It's awesome to witness such enthusiasm and engagement. We embrace the digital nomad lifestyle and cultivate a \"work hard, play hard\" spirit. This ethos keeps us motivated and creates a space where people do their best work and feel like they belong.\n\nNo matter who you are, real work happens when you feel your best self. If you want to share your current workplace with us, please do. You are warmly welcome to be part of our community.\n\n![workspace](assets/1-what-do-you-stand-for_2024-weekly-digest-april-8_2024-weekly-digest-april_2024-first-digest-workspace.webp)\n\n### What’s in the #Motivation?\nAfter watching a movie, Anna, our UX designer shared this interesting quote, sparking some serious quality sharing from the team. We've been diving deep into the question, 'What do you stand for?'\n\n![motivation](assets/1-what-do-you-stand-for_2024-weekly-digest-april-8_2024-weekly-digest-april_2024-first-digest-motivation.webp)\n\nWe were blown away by the tons of quality sharing from the team, with a range of ideas and perspectives. \n\nSome stand for the power of curiosity, others for family, and some for the ongoing pursuit of inner peace and freedom from life's distractions. We’re happy to see our tribe embracing their most authentic selves through this open sharing, giving '100% Real' answers.\n\n![motivation](assets/1-what-do-you-stand-for_2024-weekly-digest-april-8_2024-weekly-digest-april_2024-digest-motivation.webp)\n\nSo, how about you? What do you stand for?\n\n[Jump right into the conversation](https://discord.com/channels/462663954813157376/1214231226282418228/1224942206280929310). And if you've got something worth sharing, we're all ears. \n\n### What’s around you?\nPay [#random](https://discord.com/channels/462663954813157376/788084358991970337/1225783749988319252), [#lobby](https://discord.com/channels/462663954813157376/907727610417655898/1225767773708222566) channel a visit - where we love sharing our daily things, stories and having fun with peeps. You'll always find something interesting going on here. It's like catching up with friends in a cozy virtual hangout spot and a dose of good vibes. \n\nHas anyone heard from @bien lately? Hope he's doing alright. And @vincent, did you hear about his plans for his next trip in Europe this summer? Man, I'm already jealous just thinking about it.\n\nLet's keep the conversation going and the good times rolling. See you around next week for a catch-up.\n\n![random](assets/1-what-do-you-stand-for_2024-weekly-digest-april-8_2024-weekly-digest-april_2024-first-digest-random.webp)\n","title":"Weekly Digest #1: What do you stand for?","short_title":"#1 What do you stand for?","description":"Our Discord crew is buzzing with energy after our last Friday community call, with folks sharing snapshots of their workspaces, Anna shared the movie quote and catch-up with peeps at lobby, random channels.","tags":["weekly-digest","remote","discord","community"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Tue Apr 09 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/1-what-do-you-stand-for.md","slugArray":["updates","digest","1-what-do-you-stand-for"]},{"content":"\nDouble digits, I can't believe we've reached our 10th digest! It's been quite a journey putting together each edition and a blast creating these for you.\n\nWhen we talk about memo, we're highlighting an essential part of our learning culture. We’ve just noted a few updates for the cycle ahead. Now, let's dive into this round-up.\n\n### Building the best Dwarves wiki - memo.d.foundation\nThere's a long road ahead as we work on making [memo](https://memo.d.foundation/) the best it can be. It's where we keep track of what we learn—as a team and as a community—about tech, how we work, and anything else interesting.\n\nWe upgraded a monthly pool of 3000 ICY (~4500 USDC) to reward contributors who support our journey of lifelong growth in knowledge and network.\n\nCommunity members, you're welcome to read, contribute, and suggest additions. Simply drop a message in the relevant channels on our [Discord](http://discord.gg/dwarvesv), or ping @thanh or @Tom for help.\n\nWe'd love to see more contributions.\n\n![](assets/10-from-lean-to-learner-memo.webp)\n\n### Dwarves sponsor for researching and learning\nIf you've been with us for a while, you'll know we're big fans of sharing software developments. We've boosted the ICY reward in the tech channel to 1 ICY per shared link. And guess what? The **💡・til** channel is now included too.\n\nKeep spreading your knowledge. Every Friday, we'll be rewarding our top contributors. And remember, these rewards are for everyone, so bring your friends along.\n\n![](assets/10-from-lean-to-learner-icy-reward.webp)\n\n![](assets/10-from-lean-to-learner-top-contributors.webp)\n\n### AI takes center stage at Apple’s WWDC 2024\n2024 is shaping up to be a pivotal year in the evolution of artificial intelligence, and Apple's recent WWDC only solidified this notion.\n\nBut in addition to Apple Intelligence, iOS 18 is also bringing plenty of other cool features to the iPhone. The partnership with OpenAI to enhance Siri's capabilities is a testament to Apple's dedication to improving its AI services.\n\nThe trajectory is clear: AI is no longer a futuristic concept; it's rapidly becoming an integral part of our everyday lives.\n\nDon’t get me wrong—I’m excited about the performance boost this transition promises. But I can’t help feeling a bit nervous about a future like in the movie \"Her\" becoming real.\n\n![](assets/10-from-lean-to-learner-wwdc.webp)\n\n### Annual health checkup\nAs mentioned, our Dwarves will have their health checkup in June. We will keep you posted in the 📌[**・message**](https://discord.com/channels/462663954813157376/1249591418746306570/1249591981248872501) channel. Drop @Gthan a ping if you have any questions about this.\n\n![](assets/10-from-lean-to-learner-health-checkup.webp)\n\n### Market recap: VN-Index Takes a wild ride\nOver the weekend session, the market decided to have a big sell-off for no specific reason. The VN-Index closed down 21.6 points (-1.66%), wiping out all the gains from earlier in the week. Our team members @ngocthanh, @nikki, @huy, @hieuthu2, and @huytq had a lively discussion about this rollercoaster in the 📈・**econ-cafe** channel.\n\nRight now, the market’s mood swings are mostly driven by investment psychology, especially when there’s not much news to go on. In this sideways market, picking the right strategy is key—otherwise, you might feel like you're on a rollercoaster without a seatbelt.\n\n![](assets/10-from-lean-to-learner-econ-cafe.webp)\n\n### Prepare for thrilling matches from EURO 2024\nEURO 2024 kicked off on June 14th and the action will keep rolling until July 14th. Our community is excited about all the epic matches ahead. Get ready for some nail-biting finishes, jaw-dropping goals, and maybe even a few penalty shootouts to keep us on the edge of our seats.\n\nSo, grab your favorite snacks, rally your friends, and join us for the most thrilling match predictions.\n\n![](assets/10-from-lean-to-learner-euro.webp)\n\nLastly, HUGE thanks to our members who have shared a lot of interesting technical stuff. You rock!\n\nPlease keep sharing how we can make your days on the internet even better, including the small stuff, too small to see.\n","title":"Weekly Digest #10: From lean to learner","short_title":"#10 From lean to learner","description":"Double digits, I can't believe we've reached our 10th digest! It's been quite a journey putting together each edition and a blast creating these for you. When we talk about memo, we're highlighting an essential part of our learning culture. We’ve just noted a few updates for the cycle ahead. Now, let's dive into this round-up.","tags":["weekly-digest","memo","community","reward"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Sun Jun 16 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/10-from-lean-to-learner.md","slugArray":["updates","digest","10-from-lean-to-learner"]},{"content":"\nThings are always cooking on our Discord. So grab a virtual seat at our table, pour yourself a cup of something tasty, and enjoy the digest.\n\nIf you're reading this, why not pop into the woodland and say hello? We'd love to meet you. \n\n### This week's knowledge bombs on memo.d.foundation\nWe've got some cool stuff to share from memo.d.foundation this week. Publications have skyrocketed. Big shoutout to @huymaius for the [Dynamic Liquidity Market Maker](https://memo.d.foundation/playground/01_literature/dynamic-liquidity-market-a-new-form-of-concentrated-liquidity-amm-on-solana/)—a new kind of concentrated liquidity AMM on Solana. Also, check out the new [Solana Token 2022 standard](https://memo.d.foundation/playground/01_literature/introduce-to-solana-token-2022-new-standard-to-create-a-token-in-solana/).\n\nDon't miss @minhcloud's guide on [How to talk to ChatGPT effectively](https://memo.d.foundation/playground/00_fleeting/how-to-talk-to-chatgpt-effectively/). You can use `?memo list 7d` to see all the latest posts. \n\n**Bonus:** you get a 5-15 ICY reward for each publication. Everyone can contribute to memo and hopefully expand on the new topics.\n\n![](assets/11-come-grow-with-us-memo-publication.png)\n\n### Rolling out fleeting notes\nDwarves has always been a playground for techies, where learning and sharing go hand-in-hand. We're stoked to see you all playing, learning, and sharing your discoveries.\n\nTo keep the momentum going, we're bringing back fleeting notes – for those quick tech insights and discoveries you want to share with the community. Whether it's a hot new tech trend, a clever coding trick, or just something interesting you stumbled upon, we want to hear about it.\n\nRemember to keep it short, sweet, and easy to digest with a clear TL;DR. We've got a monthly pool of 3000 ICY that will be split equally among everyone contributing to the learning activities.\n\n![](assets/11-come-grow-with-us-fleeting-note.png)\n\n### Tech sharing is heating up\nWe've seen a surge in tech sharing—seriously, you all are killing it. If you have new findings, just drop them at **💡・til, 💻・tech channels.** Dwarves Rewards is here to support your learning.\n\n![](assets/11-come-grow-with-us-reading.png)\n\n### Annual heath check-up reminder\nFolks in Ho Chi Minh City, don’t forget to check out the leaflet for your medical exam instructions at [**📌・message**](https://discord.com/channels/462663954813157376/1249591418746306570/1252160647983005706) channel. Team Hanoi, yours are on the way. \n\nIf this month's jam-packed, no worries—you've got until July 15 to wrap up your check-up. Stay healthy and take care.\n\n### Score your style with new tees\nA new batch of t-shirts has just touched down at HadoHQ. If you're in sunny Saigon this week, be sure to swing by and grab yours – we've even got a limited-edition design that's calling your name.\n\nAnd don't worry, our Hanoi crew, we haven't forgotten about you. The team will be sending your shirts your way very soon, so hang tight.\n\n![](assets/11-come-grow-with-us-tshirt.png)\n\n### Can we achieve 30% profit with Uniswap yield farming\n@baskin (community member) asked @phucld about the feasibility of achieving a 30% profit by putting $1M worth of BTC and/or ETH into Uniswap's WBTC/ETH liquidity pool, aiming to maintain the initial amount and achieve monthly and yearly profit targets.\n\n@phucld jumped in with some helpful insights: it's possible with skilled management of price range, trading volume, and impermanent loss. He also pointed to tools like Arrakis Finance for managing price ranges and PoolFish for APR simulations to assess potential earnings.\n\n*Pro tip*: sticking with pairs that tend to move together can make your life easier. [Check out the convo here](https://discord.com/channels/462663954813157376/1216788839880724562/1251504848583655515).\n\n![](assets/11-come-grow-with-uniswap.png)\n\n### Econ-café deep dive: TCB bonus shares, dividends, and market insights\nIn the recent 📈・[econ-cafe](https://discord.com/channels/462663954813157376/1216788839880724562/1252821854670946345) chat, our COO @nikki, and team members @huytq, @ngocthanh talked about the upcoming event where the Vietnam Technological and Commercial Joint Stock Bank (TCB) will issue bonus shares.\n\n@hnh and @hieuthu2 discussed how issuing dividends in shares can affect ownership value and market price. They explained that while the overall value of the company might remain the same, the value per share could change, which is crucial for investors to understand.\n\nThe conversation also touched on broader banking and market predictions.\n\n![](assets/11-come-grow-with-us-econ-cafe.png)\n\n### Belated birthday cheers to our dynamic duo\nBig birthday wishes to our CEO @tieubao and head of meme @minhlq. Hope you both had a blast and were filled with joy. Here’s to another year of unforgettable moments. Wishing you all the best.\n\n![](assets/11-come-grow-with-us-birthday.png)\n\nWell, folks, that's all she wrote for this week's digital dispatch. Now go forth and spread those summer vibes like confetti and take a moment to savor the simple joys.\n","title":"Weekly Digest #11: Come grow with us","short_title":"#11 Come grow with us","description":"Things are always cooking on our Discord. So grab a virtual seat at our table, pour yourself a cup of something tasty, and read the digest. If you're reading this, why not pop into the woodland and say hello? We'd love to meet you.","tags":["weekly-digest","memo","community","reward"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Sun Jun 23 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/11-come-grow-with-us.md","slugArray":["updates","digest","11-come-grow-with-us"]},{"content":"\nYou know, there’s something magical about bringing people together around what they love. It might seem simple, but a lot of thought goes into it. Even though our team works remotely, we have groups for activities like English, Poker, Board Games, Swimming, and Running. \n\nAs I write this memo about our summer moments, there are feelings about the times with my teammates that will last a software engineering lifetime.\n\n![](assets/12-where-are-you-working-from-this-summer-thread.webp)\n\nLooks like summer vibes hit our team early this year. @vincent kicked off the vibe with a check-in from Switzerland during his 10-day European adventure, quipping, \"Does it count if I don't have my laptop? Just taking a quick walk before getting back to coding.\" His words perfectly capture the balance of work and leisure we strive for, even amidst Europe’s stunning landscapes.\n\n![](assets/12-where-are-you-working-from-this-summer-1.webp)\n\nCloser to home, @nhuthm escaped to Danang in early July, where the heat was clearly on, while @tom shared a stunning view of Phan Rang beach. @lapnn, never one to miss a beat, chimed in with local food recommendations and a photo of his impeccably organized workspace. (Perfectionists, beware: you might want to adjust that mousepad.)\n\n![](assets/12-where-are-you-working-from-this-summer-2.webp)\n\nBack in Saigon, @phucld fueled his workday with a coffee view at Okkio café, proving that a change of scenery can boost productivity. Meanwhile, @bienvh inspired us all with a suggestion to relocate to the beach or mountains for a refreshing change of pace.\n\nWhat’s about @anna? She stole the show with her vibrant new nails, courtesy of at-home nail service, joking, \"Now the challenge is typing.\" Her playful spirit and unique flair bring a spark of joy to our team.\n\n![](assets/12-where-are-you-working-from-this-summer-3.webp)\n\nKey members at HadoHQ shared snapshots of their summer office views, complete with stunning sunsets reminding us that no matter where we are, we’re united by our shared experiences.\n\n@minhlq, currently in Lam Dong province, shared a peek into his family's business operations, showing how work and personal life can coexist.\n\n![](assets/12-where-are-you-working-from-this-summer-4.webp)\n\nOur COO, @nikki, even joked that the team should enjoy their summer travels while she handled everything back. She shared a photo from what looked like a homestay near the beach, complete with a good beer. \"The trick is to 'Photoshop' beer bottles into the frame,\" she said, perfectly capturing the vibes while balancing responsibility and relaxation.\n\n![](assets/12-where-are-you-working-from-this-summer-5.webp)\n\nJust when we thought the fun was winding down, @jim blew us away with his anime-themed workspace, complete with a collection of Pop Mart anime figurines worth a staggering 80 million VND! (Some of them are even limited editions.) He estimates that each figure costs around 4-5 million VND. Now that's dedication.\n\nTeam members @hnh, @bienvh, @anna, and @tom also shared their own impressive collections, showcasing our team's shared passion for all things anime.\n\n![](assets/12-where-are-you-working-from-this-summer-6.webp)\n\nBut wait, there's more. @hnh surprised us with a weekend check-in from the peaceful Binh An village in Da Lat. Working by the serene Tuyen Lam Lake sounds like the ultimate productivity booster. Meanwhile, @minhlq's location in the highlands seemed a bit more mysterious.\n\nLike, someone might join a group for a specific anime but not another. That’s where our different servers or “guilds” on Discord help. They let people find their smaller communities within the larger team. This way, everyone can connect with others who share their interests. In these moments, big and small, we find the essence of who we are as a team.\n","title":"Weekly Digest #12: Summer moments - Our team's remote work adventures","short_title":"#12 Summer moments","description":"There’s something special about bringing people together. Even as a remote team, we connect through shared interests and activities. \"This summer, Where Are You Working From?\" campaign sparked a wave of fun and connection across the team. Come along as we share the stories of our team members.","tags":["memo","team","remote","weekly-digest"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Thu Jul 11 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/12-summer-moments.md","slugArray":["updates","digest","12-summer-moments"]},{"content":"\nWelcome to this week's edition of our roundup, where we highlight the moments that make us more than just lines of code. This week, we're jet-setting around the world with our team's summer adventures, unveiling new memo features, and cheering for a beloved teammate's new chapter in the US. From beachside workspaces to anime figurine collections, we've got it all.\n\n### Memo submission and boosting team contributions\nIn the upcoming phase, the team will focus on streamlining processes and developing tools to make memo submission easier for everyone. Here are two ways we're helping you stay up to speed:\n\n- Use commands like `?memo pr` and `?memo list` to check out the latest memos. (Shoutout to @ohagi for this!)\n- Receive webhook notifications in the Discord server for new PRs, speeding up memo operations.\n\nWe're also introducing tooling for submitting fleet notes directly on Discord and automating the distribution of ICY to everyone. However, the amount of ICY distributed is still below the team's limit, so there's plenty of room for more contributions. Everyone can join hands.\n\n![](assets/13-more-than-lines-of-code-icy-updates.webp)\n\n![](assets/13-more-than-lines-of-code-memo.webp)\n\n### Summer snapshots: where our remote team works\nThis summer, our team's \"Summer Times, Where Are You Working From?\" updates took us on a virtual journey around the world. We saw it all: Swiss mountains, Vietnamese beaches, killer nail art, desks so neat they spark joy, anime havens, and even our COO chilling beachside (while \"working,\" of course). \n\nThese snapshots of our team's lives—filled with personal flair, with a mix of personalities and passions that make our team so rad, no matter where we're working from. \n\n[Check out the full recap of our team's summer escapades.](https://memo.d.foundation/updates/digest/12-where-are-you-working-from-this-summer/)\n\n![](assets/13-more-than-lines-of-code-summer.webp)\n\n![](assets/13-more-than-lines-of-code-summer-moments.webp)\n\n### A fond farewell and best wishes to our teammate Hieu Phan\nAs you all saw in the lobby last Friday, we had our final team dinner with @hieuthu1 before his move to the US. The memories we made together in Vietnam will always stay with us, even as he embarks on his new journey under American skies. \n\nHe was always a caring presence at Hado, a fantastic cook, and a friend who joined us on afternoon walks after work, always connecting everyone on the team. We wish you all the best on your new adventure and don't forget to call us.\n\n![](assets/13-more-than-lines-of-code-farewell.webp)\n\n![](assets/13-more-than-lines-of-code-farewell.png)\n\n### Celebrating the newborn\nCongratulations are in order for @thanh, who recently welcomed a new addition to his family. The whole team is overjoyed for him and his partner as they embark on this exciting new chapter. There's been plenty of well-wishing and baby-related chatter around the team.  \n\nOf course, with such happy news, the playful banter has already begun: who's going to be the next to share a baby announcement? We'll have to wait and see. \n\nIn the meantime, we're sending Thanh and his family all the best as they navigate the joys (and sleepless nights!) of parenthood.\n\n![](assets/13-more-than-lines-of-code_13-more-than-line-code-new-born.webp)\n\nFrom tech tips to tiny toes, this week's digest reminds us that we're more than just a team. So, whether you're sharing a memo, a vacation snapshot, or a life-changing announcement, remember: that we're here to celebrate it with you.  \n","title":"Weekly Digest #13: More than lines of code","short_title":"#13 More than lines of code","description":"Welcome to this week's edition of our roundup, where we highlight the moments that make us more than just lines of code. This week, we're jet-setting around the world with our team's summer adventures, introducing new memo features, cheering for a beloved teammate's new chapter in the US, and celebrating new born. From beachside workspaces to anime figurine collections, we've got it all.","tags":["memo","team","remote","weekly-digest"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Sat Jul 20 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/13-more-than-lines-of-code.md","slugArray":["updates","digest","13-more-than-lines-of-code"]},{"content":"\nSince the start, Dwarves has valued flexibility, allowing our team to work where inspiration strikes. But there's something special about being together—learning, sharing knowledge, and working side by side.\n\nThat's where our hybrid working model steps in.  \n\nWe didn’t aim to fill desks but to create a space where you can learn, connect, and rediscover the energy that comes from working alongside others, even if it’s just for a day or two.\n\n### What makes the Dwarves office different\nAs a borderless software team, we know not everyone finds comfort or focus working remotely all the time. Even local cafes have their charm, but let’s be honest—it’s not always smooth sailing. That’s why our engineers have the full support they need to perform at their best.\n\n**1. Work in comfort**\n\nFrom **Apple Studio Displays** to **Herman Miller chairs**, we’ve set up workspaces adapt to you. Whether you need a quiet corner or an open area for brainstorming, you’ll find a spot that suits your style.\n\n**2. Productivity perks**\n\nDistractions? Not here. With high-speed internet, tranquil meeting rooms, subsidized meals, and 24/7 access, you have everything you need to stay in the zone.\n\n**3. A supportive environment that fuels growth**\n\nEvery interaction, every conversation, is a chance to pick up something new or share what you know. \n\n![](assets/14-back-to-the-office-team.png)\n\n### Why our office check-in is worth it\nWe’ve added a little extra motivation to make coming into the office more rewarding. Every time you check in at **🏢・lobby**, you’ll earn **5 ICY** tokens as part of our daily team perks. It’s our way of encouraging you to take advantage of everything the office offers and to make every visit count.\n\n- **Simple and quick:** Check in, earn your ICY. Kick-off your day with a little boost.\n- **Earn while you work:** Whether you're here for a focused work or to catch up with teammates. You’re rewarded just for showing up.\n- **Stay connected:** These perks are little a reminder that we’re building something together, day by day.\n\n![](assets/14-back-to-the-office-checkin.png)\n\n### Shaping a place for real learning\nWhy leave your home office? What makes this place worth the trip? It’s not about fancy setups. Team members who hadn't visited in a while began dropping by, finding new ways to connect. \n\nWhen @tom picks up a new skill, he shares it with everyone in person. It was him, standing by a desk, showing others in real time. These face-to-face exchanges spread knowledge throughout the team effortlessly. We didn’t force people back; they started coming in because something changed. \n\nYou see, there are things you can’t capture in a digital thread. A quick tip, a shared screen, a face that lights up when they finally get it. That’s learning.\n\nWe didn’t aim for a typical office with rigid desks. Instead, we created a space where reaching out feels natural, and where every conversation might teach you something new, where knowledge isn’t just passed around—it’s lived and experienced.\n\n![](assets/14-back-to-the-office-teamwork.png)\n\n### Real voices: What our team says\nDon’t just take our word for it—here’s what some of our team members have to say about coming back to the office:\n\n- “The quick chats turn into real learning moments. In an environment where mentors and seniors are always learning, newbies feel encouraged to do the same. It’s all rooted in Dwarves' mentorship culture.” - @datnguyen\n- \"Working from the office helps me stay focused, and it's easy to reach out when I need a hand. It feels good to have that balance.\" – @vincent\n- \"I appreciate the mix of working remotely and coming in. The face-to-face chats and shared meals make it feel more connected. It truly embodies the spirit of engineers.\" – @nhuthuynh\n- \"It’s not just about working harder; it’s about working smarter. I’ve shared a lot of knowledge by bouncing ideas off my teammates\" – @tom\n- \"Being at the office a couple of days a week has made it easier to separate work and home life. Plus, it's good to see everyone now and then.\" – @nam\n\n### Where work meets growth\nThough this is still in the early stages, some of us have already reached the hub and made it their go-to spot for getting into the zone. We’d be glad to have you as one of them.\n\nAlong with everything, we do everything we can to level up our team. In the end, it’s not just about work; it’s about how we grow, together.\n","title":"Weekly Digest #14: Embracing hybrid work - the best of both worlds","short_title":"#14 Hybrid work harmony","description":"Discover how Dwarves embraces hybrid working, blending flexibility with in-person connections. Learn how our office space fosters productivity, learning, and real collaboration—even if it’s just for a day or two a week.","tags":["weekly-digest","team","hybrid-working"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Wed Sep 25 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/14-back-to-the-office.md","slugArray":["updates","digest","14-back-to-the-office"]},{"content":"\nWe kicked off our gathering after Tết, bringing the community back together in true Dwarves style - dropping some SOL and ICY tokens into everyone's wallets, bringing the community back together in true Dwarves style. Not a bad way to start the year.\n\n![](assets/15-new-year-gathering-airdrop.png)\n\n![](assets/15-new-year-gathering-airdrop-icy.png)\n\nOn the first day back, the team flooded Discord with Tết stories and updates. Between the usual tech talk and project discussions, conversations shifted to lucky money tales, family gatherings, and the inevitable food coma from too many bánh chưng and bánh tét.\n\nSome bragged about their winning streak (or admitted their losses) in traditional New Year games, both the triumphs and the mishaps. Others shared their first sips of spring wine, late-night card games, and that one cousin who somehow always wins.\n\n![](assets/15-new-year-gathering-convo.png)\n\nPhotos and stories kept rolling in. From pristine beaches and mountain retreats to hometown reunions and family feasts, each snapshot captured a different way the team spent the break. Some took the chance to travel, exploring new places. Others returned to familiar spots, embracing the warmth of home, reconnecting with loved ones over shared meals and old traditions.\n\n![](assets/15-new-year-gathering-moments-1.png)\n\n![](assets/15-new-year-gathering-2.png)\n\nAnd of course, there were those who simply recharged — sleeping in, catching up on games, and enjoying the rare quiet before diving back into the grind. Now, we’re back at it, picking up where we left off. The Year of the Snake has just begun.\n\n","title":"Weekly Digest #15: New year Gathering: Sharing Tết, starting strong","short_title":"#15 New year gathering","description":"Tết break came to an end, and the Dwarves team reunited to share stories, reconnect, and kick off the Year of the Snake in style. We brought it all back to Discord—along with a little SOL & ICY drop to start the year right.","tags":["weekly-digest","team","community"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Tue Feb 04 2025 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/15-new-year-gathering.md","slugArray":["updates","digest","15-new-year-gathering"]},{"content":"\nThere are so many amazingly fun and wonderfully weird things happening on Discord, both last week and of course, today. So let’s dive in with a freshly-brewed “cà phê sữa,” of course.\n\nIf you’ve stumbled upon this article, you’re welcome to spark activity within our Discord community. So take a peek once in a while and see what’s new, just come in and say ‘hi’ with us.\n\n### A battery charging up your day\nOur COO @nikki sparked a lively discussion by snapping a pic of a battery that looked like it had seen better days. Just when we thought things couldn't get any more electrifying, amidst the chaos, the conversation took a twist when the CEO saw 4 billion 6 VND on a random roll-up bread wrapper. Who knew a simple battery could recharge our spirits and spark such lively banter?\n\n![motivation](assets/2-walk-around-learn-around_2024-weekly-digest-april-15_2024-digest-5.webp)\n\n### Walk around learn around\nLast Wednesday, the Hado office crew @nam, @hieuthu1, @vincent, @innno_ decided to shake things up with an offline WALA session. Our primary goal? A visit to the Nha Nam bookstore to get our hands on copies of \"Dune Messiah.\" Of course, the secondary goal was the WALA itself. Little did we know it would turn into a mini-adventure. Finally, we surpassed the 10km target - a delightful bonus to a fulfilling day of friendship.\n\n![wala](assets/2-walk-around-learn-around_2024-weekly-digest-april-15_2024-digest-7.webp)\n\n### The really career advice - Wait But Why\nOnce you’re ready to show what you’ve learned, we’re all ears. The sharing from our COO @nikki isn’t just about giving you career advice. It’s a framework that I think can help you make career decisions that reflect who you are, what you want, and what our rapidly changing career landscape looks like today.\n\nIt’s also for those who have yet to start their careers, who aren’t sure what they want to do with their lives, or those currently in the middle of their career who aren’t sure they’re on the right path. Press the reset button on your thought process and get some clarity.\n\n![waitbutwhy](assets/2-walk-around-learn-around_2024-weekly-digest-april-15_2024-digest-6.webp)\n\n### The best AI meme\nScanning through **#⛺・random** is always a blast. With AI in the mix, it's like having a playful friend who keeps surprising you with hilarious memes. Whether it's a meme that makes you laugh or leaves you puzzled, that's all part of the fun. Let the meme odyssey commence.\n\n![meme](assets/2-walk-around-learn-around_2024-weekly-digest-april-15_2024-digest-3.webp)\n\n![meme](assets/2-walk-around-learn-around_2024-weekly-digest-april-15_2024-digest-4.webp)\n\n### Gold prices set new records, interest rates start to rise\nThe price of gold had been on a wild ride, hitting all-time highs for several days in a row. With all this back and forth, our team got together to chat about investing in gold or stocks, investment goals, and long-term investment strategies. From that convo, we ended up sparking a whole new discussion for OGIF about investing and money talk. That’s cool, right?\n\n![goldprice](assets/2-walk-around-learn-around_2024-weekly-digest-april-15_2024-digest.webp)\n\n### Happy birthday to our awesome pals\nWishing all the best for @fuatto and @tay on their birthdays last week. Here's to another year of adventures, laughter, and unforgettable moment. Cheers to you both, and may your birthdays be as legendary as you are.\n\n![birthday](assets/2-walk-around-learn-around_2024-weekly-digest-april-15_2024-digest-2.webp)\n","title":"Weekly Digest #2: Walk around learn around","short_title":"#2 Walk around learn around","description":"There are so many amazingly fun and wonderfully weird things happening on Discord, both last week and of course, today. So let’s dive in with a freshly-brewed “cà phê sữa,” of course.","tags":["weekly-digest","remote","discord","community"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Mon Apr 15 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/2-walk-around-learn-around.md","slugArray":["updates","digest","2-walk-around-learn-around"]},{"content":"\nHuge news is on the horizon. You absolutely will *not* guess what we’re about to share. We remember last week like it was yesterday, but what truly counts is that you're here with us.\n\nIf you're up for diving into conversations and discussions like these, we're eagerly awaiting your company.\n\n### We all start somewhere\nStarting over in my career after a ten-month hiatus has been quite a journey at 27. But you know what? Instead of dwelling on our greatest fears about where our careers might take us by the age of 35, why not shift the perspective?\n\nOur CEO showcased Khanh Vy as a beacon of inspiration for Gen Z, highlighting her unwavering commitment and diligence. Furthermore, he asked @innno_ what motivates her and urged her to embrace new challenges and endeavors.\n\nWhere did you start, or where are you starting from? We'd love to hear your story.\n\n![motivation](assets/3-we-all-start-somewhere_2024-weekly-digest-april-22_22-april-digest-motivation.webp)\n\n### What are your plans this holiday?\nHave you decided where you're headed for your upcoming vacation? It's fascinating to see that some Dwarves members are planning trips to Xinjiang, while others are getting together to enjoy board games and maybe even tackle some tasks (just kidding!).\n\nWhatever you choose to do, make sure you make the most of those precious three days off and recharge for the exciting new working week in May. Wishing every one of you a fantastic and joyful holiday.\n\n![holiday](assets/3-we-all-start-somewhere_2024-weekly-digest-april-22_22-april-digest-lobby.webp)\n\n### Exciting opportunities await: Southeast Asia Blockchain Event\nFor the upcoming Southeast Asia Blockchain event happening next week in none other than the beautiful land of Thailand. Our super cool CEO has decided to go all out and sponsor a whopping 50% of the cost for anyone who wants to be part of this extravaganza. How awesome is that?\n\nThere are also some events lined up for you at the **#📈・econ-cafe** channel. We attends community events as a group, where we have the opportunity to learn from others' experiences, share our knowledge, and connect with fellow tech enthusiasts in the industry.\n\n![event](assets/3-we-all-start-somewhere_2024-weekly-digest-april-22_22-april-digest-event.webp)\n\n### Investment dopamine\nEveryone's still buzzing about gold prices and investments. The constant fluctuations in the market keep us informed. \n\nAlso, our COO's passive income really got us talking. It's evident that we're all eager to explore diverse investment opportunities and grasp their role in the wider economic picture. There's always something fresh to uncover and discuss together.\n\n![investment](assets/3-we-all-start-somewhere_2024-weekly-digest-april-22_22-april-digest-market.webp)\n\n### Our community includes everyone, including you\nI just wanted to give a huge shoutout to all of you for the awesome response we got to the weekly digest. Your enthusiasm and engagement seriously made my day. It's so rad to see everyone diving in, sharing thoughts, and sparking cool discussions. \n\nKeep being awesome, and let's keep the good vibes rolling.\n\n![digest](assets/3-we-all-start-somewhere_2024-weekly-digest-april-22_22-april-digest-random.webp)\n\n### Dwarves internship program\nLastly, we launched the Internship Program for students to provide training, mentoring, and career development opportunities to shape your software skills and define your career paths.\n\nInterested in joining our Internship Program? We're here to welcome you aboard.\n\n[Shoot us an email](mailtospawndwarvesv.com) with your LinkedIn / CV\\\n[Join our Discord](https://discord.gg/dwarvesv) of +300 other engineers and designers\n","title":"Weekly Digest #3: We all start somewhere","short_title":"#3 We all start somewhere","description":"Huge news is on the horizon. You absolutely will not guess what we’re about to share. Excitement building, we remember last week like it was yesterday, but what truly counts is that you're here with us.","tags":["weekly-digest","discord","community","motivation"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Mon Apr 22 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/3-we-all-start-somewhere.md","slugArray":["updates","digest","3-we-all-start-somewhere"]},{"content":"\nWelcome back to the #4 weekly digest after a long holiday. Those Discord channels are still buzzing with active messages. Without further ado, let’s see what I’ve got to share. \n\n### Come for the culture, stay for conversation\nSome of a rapid-fire exchange of memes, hot views, controversial opinions inside jokes, and earned (and occasionally unearned) snark. It's my favorite part when creating weekly digests. There's no better low-effort, high-reward approach to connect with all of my readers.\n\n### Brand new merchandise coming soon\nGuess what's hitting the shelves soon? That's right, folks – we've got some fresh merch on the horizon and we're buzzing with excitement.\n\nThe operations team's gearing up for another batch of awesome t-shirts and stickers. Get ready to rock some serious style and show off your pride. Stay tuned for the big reveal, because trust us, you won't want to miss out on this.\n\n![](assets/4-finding-your-authentic-tribe-copy_4-finding-your-authentic-tribe-tshirt.webp)\n\n### TGIF sometime, OGIF all the time\nThere have been 4 OGIF editions since one month of resumes. To get @everyone aligned and possess the same knowledge base toward our culture. OGIF is a tradition that takes place every Friday afternoon to walk all folks through anything you can share for everyone can learn within 10 minutes.\n\nThe talk shall be rendered to be short, interesting, and easy to digest. If you and your team have an idea, we are all excited to see what you will create.\n\n![](assets/4-finding-your-authentic-tribe-copy_4-finding-your-authentic-tribe-ogif.webp)\n\n### We’re happy to have you on our team\nWelcome @minhkek - BD officially to the team after all their hard work and successful completion of probation. Also, a big shoutout to our newest intern, @datnguyennnx, as he embarks on his journey with the Dwarves team. Keep up the good work, we're here to support you every step of the way.\n\nAnd let's not forget to celebrate @jack, who's now officially part of our inner circle. Welcome aboard, Jack – here's to many more adventures together.\n\n![](assets/4-finding-your-authentic-tribe-copy_4-finding-your-authentic-tribe-onboard.webp)\n\n### Be authentic, find your tribe\nEven though the team works remotely, there is always a group for activities such as English, Poker, Board Games, Swimming, and Running. As I'm jotting down this digest, there were certain feelings about the moments walking with my mates or geeking out over a good book with the team. I feel like the Dwarves is a big fam.\n\nAnd hey, taking a look back at those epic moments like cheering on @nam for his upcoming wedding or reminiscing about that wild road trip to Mang Den for a foodie adventure.\n\n![](assets/4-finding-your-authentic-tribe-copy_4-finding-your-authentic-tribe-hado.webp)\n\n### Let’s spread the cheer to our teammates\nThank you for being such a great team player @thangnt @lapnn. I hope you have a super day and get everything you want. Here's to an epic birthday bash – enjoy every moment, you deserve it.\n\n![](assets/4-finding-your-authentic-tribe-copy_4-finding-your-authentic-tribe-birthday.webp)\n","title":"Weekly Digest #4: Finding your authentic tribe","short_title":"#4 Finding your authentic tribe","description":"Welcome back to the #4 weekly digest after a long holiday. Those Discord channels are still buzzing with active messages. Without further ado, let’s see what I’ve got to share.","tags":["weekly-digest","discord","community","team"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Mon May 06 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/4-finding-your-authentic-tribe.md","slugArray":["updates","digest","4-finding-your-authentic-tribe"]},{"content":"\nGreetings from Saigon, I’m here again, bringing you a lot of updates. There are big and small things brewing at Dwarves network. As we keep on crafting a better community day by day with you. \n\nAnd tiny but mighty ones, like new merchandise, are in progress. Let’s get through what’s new! \n\n### Heading to Echelon X Asia Summit 2024\nThis May 15-16, our leaders @tieubao, @nikki, and @huytq are gearing up for an exciting adventure at Echelon X, the largest startup summit in Southeast Asia.\n\nEchelon X is an annual tech business conference that gathers inspiring startups and ecosystem players from Southeast Asia and beyond. Get ready to make some waves because Dwarves is about to leave its mark at Echelon X Asia Summit 2024.\n\n### New Merchandise Alert\nLast week, the operations team gathered all your awesome input on the design for the t-shirt. Rest assured, every suggestion has been noted, and soon you'll get the chance to vote on the final design. \n\nThe preparation is in progress, and we're thrilled about how it's shaping up.  Cool new gear is on the way, so keep an eye out for the big reveal and happy voting.\n\n### Dwarfing It Up: OGIF (Oh God It's Friday) Tradition\nEvery Friday afternoon, all members are warmly welcomed to join us on Discord for Dwarves’ casual showcases, taking place weekly at 5 PM. Simply come and hear the people to share their work. We don't want anyone to feel pressured, though. \n\nAll OGIF sessions are recorded. Thank you, Tom for the support. [Click here](https://memo.d.foundation/changelog/3-ogif-office-hours-0419/) if you missed the sessions.\n\n![](assets/5-endure-the-hardship-delay-the-gratification-ogif.webp)\n\n### Cheers to another year on deck\nLast Thursday was a blast as we gathered around to celebrate @hieuvd's 4th working anniversary at Dwarves. Let's raise a virtual toast to Hieu for his unwavering dedication in working. Keep shining bright like a diamond, Dwarves fam.\n\nOh, and speaking of time flying by, here's a quirky tidbit for you: did you know time actually comes with its own weight? Who knew that along with deadlines, we're also carrying around some extra ounces of time on our shoulders? Time to hit the gym, folks.\n\n![](assets/5-endure-the-hardship-delay-the-gratification-celebrate.webp)\n\n### Endure the hardship, delay the gratification\nOne of our endless inspirations behind every channel we created is you. We’ve created the brand-spankin'-new channel **👑・stoicism.** Because who doesn't need a little more stoic wisdom in their lives, am I right?\n\nA while back, I randomly saw this topic on Reddit:\n\n>\n> \"The ability to discipline yourself to delay gratification in the short term in order to enjoy greater rewards in the long term, is the indispensable prerequisite for achievement.\"\n\nWho knew stoicism could be so... deliciously rewarding? Catch you on the flip side, wise wanderers.\n\n![](assets/5-endure-the-hardship-delay-the-gratification-stocism.webp)\n\n### Sticker mania: say it with style and Don't just say hello\nOK, we hear you, discord crew, who's ready to jazz up their chats with some adorable stickers? The team responded very enthusiastically to the new sticker set. You can snag 'em for yourself at the Hado office, ping @innno for help.\n\nWe might use the \"Hello\" sticker as our default greeting, but why stop there when you can sprinkle a little extra pizzazz on your messages? @vincent has sparked that idea up. Throw in a virtual high-five, a fist bump, or maybe even a funny emoji (because why not?).\n\n![](assets/5-endure-the-hardship-delay-the-gratification-sticker.webp)\n\n### Wall Street wisdom with our COO\nReady to dive into the exciting world of economics and stock trading? Then look no further than our bustling 📈・**econ-cafe** channel, where the discussions are as lively as the stock market itself.\n\nNeed advice on market trends, stock picks, or the latest in gold trading? You're in luck. Our very own COO @nikki, is here to drop some serious knowledge bombs and guide you through the maze of financial jargon. Seriously, who needs Wall Street when you've got Nikki in your corner, right?\n\n![](assets/5-endure-the-hardship-delay-the-gratification-econ.webp)\n\n### CEO SOS: hair help\nSo, here's the burning question: got any tips, tricks, or magical potions to banish dandruff? Yep, you heard it right. Our CEO @baddeed has been pondering the age-old dilemma of scalp issues. \n\nWe've already had some stellar suggestions roll in. But hey, the more, the merrier. Share your go-to remedies, maybe even some weird hacks if you've got 'em to have our CEO sporting the lushest locks in the biz.\n\n![](assets/5-endure-the-hardship-delay-the-gratification-haircare.webp)\n\nAnd that’s all for this week's digest, folks. It's my joy building the weekly digest with you - our community members.\n\nI’m here to record the most of every moment, this summer and beyond. Hope you’re enjoying the warmer days - and remember: don’t let anyone [steal your sunshine](https://www.youtube.com/watch?v=E1fzJ_AYajA).\n","title":"Weekly Digest #5: Endure the hardship, delay the gratification","short_title":"#5 Endure the hardship, delay the gratification","description":"Happy Monday, I’m here again, bringing you a lot of updates. There are big and small things brewing at Dwarves network. As we keep on crafting a better community day by day with you.","tags":["weekly-digest","discord","community","team"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Tue May 14 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/5-delay-the-gratification.md","slugArray":["updates","digest","5-delay-the-gratification"]},{"content":"\nHi, it’s @innno_ again. Summer is almost here. But don't worry, this update is all about making your day more comfortable. Now, onto this week’s updates.\n\n### Get Ready for the Community Meet-Up Extravaganza\nMark your calendars. On Friday 31st May, we’re hosting an offline community meet-up in Ho Chi Minh City. It’s a blend of news, tech topics, food, drinks, and good times – all rolled into one epic event.\n\nLocal crew, you know the drill. Out-of-towners, hit up the ⁠🎫・**support-ticket** channel and the ops team will sort you out.\n\nCheck out the announcement in **[🚨・red-alert](https://discord.com/channels/462663954813157376/915941020968046612/1239841583843639348)**. Hope to see all of you there.\n\n### ICY Distribution: What We've Got Cooking?\nAs announced, there are some exciting changes to the team's ICY distribution. We’re adding more activities and more chances to rack up those sweet ICY rewards for everyone.\n\nBut wait, there's more. In a heartwarming twist, the team is spreading the love to the tiniest members of our community. That's right, folks – newborn babies are now eligible for a whopping 100 ICY.\n\nHead on over to **[🧊・earn-icy](https://discord.com/channels/462663954813157376/1006198672486309908/1239502938918096960)** for all the deets on this exciting new chapter in ICY distribution.\n\n![](assets/6-come-for-the-conversion-stay-for-the-culture_6-come-for-the-conversation-stay-for-the-culture-icy.webp)\n\n### Friday Vibes: Let's Unwind and Celebrate\nLast week’s OGIF was a real treat, featuring topics like the Factory Pattern, State Machines in Erlang, and the Trading Process. The highlight? @quang on blowing everyone away with his trading prowess. His insights were so impressive that everyone joked about sending him their money to invest. \n\nIn other exciting news, we've had some changes in our operations structure. @hnh has been promoted to the position of Chief of Staff, and @minh_cloud is now our Junior Product Manager and Executive Assistant. Congratulations to both of you.\n\n![](assets/6-come-for-the-conversion-stay-for-the-culture_6-come-for-the-conversation-stay-for-the-culture-ogif.webp)\n\n### Hado Office Buzz: The More, the Merrier\nThings are buzzing at HadoHQ these days. We've got a full house with our Saigon regulars @hieuthu1, @innno_, and @vincent holding down the fort, and @taipham gracing us with his presence more often. It's like a family reunion every month.\n\nLast Friday was no exception, with the crew joined by the legendary @thanh.pham, @datpv, @hieuvd and the new intern @datnguyennnx. What a lineup!\n\nIt was a well-deserved Friday night feast, enjoying OGIF, grabbing some food and drinks together. Check out those smiles and [good times here and better down the road.](https://www.youtube.com/watch?v=CqOZtLy4tFA)\n\n![](assets/6-come-for-the-conversion-stay-for-the-culture_6-come-for-the-conversation-stay-for-the-culture-gathering.webp)\n\n### Wedding Bells and Roadtrip Thrills\nLove is in the air as @lap kicks off the wedding of the year. Huge congratulations to Lap. Speaking of adventures, @vincent's got the travel bug and is curious about Ninh Thuan province. Any hidden gems we should share? @hnh's already got the wheels turning with a Sunday morning road trip suggestion. \n\nSounds like an adventure waiting to happen. Who's in?\n\n![](assets/6-come-for-the-conversion-stay-for-the-culture_6-come-for-the-conversation-stay-for-the-culture-wedding.webp)\n\n### Beware of Cyber Bandits\nLast Friday night, our very own @nam had an unwelcome surprise—his credit card got hacked, resulting in a loss of 5 million VND. Ouch! While that's no small amount, let's take this as a friendly reminder to all of us to double-check those links before we click and keep a close eye on our bank accounts. Stay sharp, everyone.\n\n![](assets/6-come-for-the-conversion-stay-for-the-culture_6-come-for-the-conversation-stay-for-the-culture-hack.webp)\n\n### GPT-4o is Now Rolling Out, and Discussions Heating Up\nOpenAI's GPT-4o is impressing early adopters with its advanced abilities. Despite its initial release, GPT-4o excels at writing and error detection, boasting an average response time of 320 milliseconds. It even responds with an AI-generated voice, closely resembling human speech.\n\nWith its impressive functionality and performance, there might be more changes afoot in the future.\n\n![](assets/6-come-for-the-conversion-stay-for-the-culture_6-come-for-the-conversation-stay-for-the-culture-gpt.webp)\n\nThose stories don't stop here.\n\nAs the seasons change and the rain sets in Saigon, here’s to making small moments on Discord a little easier - and more fun.\n\nWe’ll see you around on our [server](https://discord.gg/dwarvesv).\n","title":"Weekly Digest #6: Come for the conversation, stay for the culture","short_title":"#6 Come for the conversation, stay for the culture","description":"Hi, it’s @innno again. Summer is almost here. But don't worry, this update is all about making your day more comfortable. Now, onto this week’s updates.","tags":["weekly-digest","discord","community","team"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Thu May 23 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/6-stay-for-the-culture.md","slugArray":["updates","digest","6-stay-for-the-culture"]},{"content":"\nThe sun peeks over the horizon, Saturday vibes and good news – the perfect combo. We're about to spice up your weekend with a recap of all the awesome things we whipped up this week.\n\n### Get your geek on: free GitHub Copilot with Open-Source fun\nDid you know that contributing to open-source projects on GitHub can earn you a free subscription to GitHub Copilot? @Tom shared this awesome tip with us. Even pull requests and contributions to public repositories count. It's worth checking your GitHub account to see if you already have free access to Copilot.\n\nOpen-source contributions help you learn and get access to tools like GitHub Copilot. Whether you're coding solo or collaborating, these resources can make your coding experience better. See how it can benefit you, who knows? Happy coding.\n\n![](assets/7-a-journey-through-time-copilot.webp)\n\n### Discord drama: scams, spammers\n@trkhoi brought up a wild situation in the 🏢・lobby. He was accused of hacking Discord and threatened with a ban unless he contacted a fake Discord support \"mod”. Classic scam alert.\n\nBut he's not alone - seems like everyone's got a story to share. Others reported similar shady encounters, and the plot thickened when we realized many of us have been getting spam calls from telesales lately. Our COO @nikki chimed in with a gem quote.  \n\nAbove all, stay smart, stay vigilant, and stay safe out there.\n\n![](assets/7-a-journey-through-time-scam.webp)\n\n### Cheer to your awesome birthday @anna\nHappy birthday to @anna, our amazing designer. The team's been cracking jokes and sharing more happy stories than ever – it's like a never-ending comedy show around here. Here's to you, my beloved sis Anh Tran – may your day be as fantastic as you are.\n\n![](assets/7-a-journey-through-time-birthday.webp)\n\n![](assets/7-a-journey-through-time-birthday-2.webp)\n\n### A look back: cherishing our collective memories\nAs one of the newer members of our community, I might not have much to write about this part. Yet, every time I see the pictures the team shared at [🏢・lobby](https://discord.com/channels/462663954813157376/907727610417655898/1242114588863103047), a wave of nostalgia washes over me, filled with enthusiasm and a sense of freedom. \n\nThese pictures show the fun times and amazing places the team has visited together. Every snapshot reminds us of our adventures and the great times we've had.\n\nKeep those stories coming, folks. Each one weaves another vibrant thread into the rich tapestry of our community.\n\n![](assets/7-a-journey-through-time-nostalgic-1.webp)\n\n![](assets/7-a-journey-through-time-nostalgic-2.webp)\n\n![](assets/7-a-journey-through-time-nostalgic-3.webp)\n\n### Monthly community snapshot, now with more\nFeast your eyes on this visual delight. Thanks to @vincent for the idea and @nambui for the design flair.\n\nIntroducing our new Monthly Community Snapshot, where you can catch up on all the important changes in just one quick glance. What do you think of this visual? We're all ears for your thoughts and feedback.\n\n![](assets/7-a-journey-through-time-changelog.webp)\n\n### Reflecting on our journey: celebrating two months of weekly digests\nIt's hard to believe it's been almost two months since our first weekly digest. Looking back, I remember feeling both nervous and a bit clumsy while crafting those initial updates.\n\nBut over time, as I kept a close eye on each channel, received valuable feedback from @tieubao and @nikki, and wrote and rewrote, my sense of writing grew. I’ve grown more confident in putting together these notes that you read.\n\nI care about this weekly digest, and all of you, a tremendous amount.  I love this community, and I am so grateful you all hear me out every week.\n\n![](assets/7-a-journey-through-time-snapshot.webp)\n\nLet's wrap this up with a cheer on top.\n\nAnyway, I'm actively working on the next digest round-up, and it's about a super cool community. Stay tuned.\n\nOnto today's post...\n","title":"Weekly Digest #7: A journey through time","short_title":"#7 A journey through time","description":"The sun peeks over the horizon, Saturday vibes and good news – the perfect combo. We're about to spice up your weekend with a recap of all the awesome things we whipped up this week.","tags":["weekly-digest","discord","community","team"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Thu May 30 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/7-a-journey-through-time.md","slugArray":["updates","digest","7-a-journey-through-time"]},{"content":"\nHere's to hoping for a brighter and better month on this last day of May. We’re in the heat of a community offline meet-up today, gathering to discuss the month’s progress.\n\nEveryone's a bit busy arranging their travel to Saigon, a wild place we all call home. So, let’s dive into what we’ve been up to.\n\n### Get ready for our big meet-up\nThe big day is almost here. Our first community offline meet, originally set for April, has been rescheduled to give us more time to prepare.\n\nWe’re making sure members from Hanoi, Danang, and other provinces can all fly to Ho Chi Minh City for this event. It might take a bit longer, but I'm sure it'll be worth the wait.\n\nAnd we’re finally gathering today. I really hope everyone feels comfortable opening up and getting involved. It's going to be a blast catching up with everyone. The more the merrier, right?\n\n![](assets/8-then-came-the-last-days-of-may-meetup.webp)\n\n### Wishing the happiest birthday to @datpv\nI wanted to take a moment to give a big happy birthday shoutout to our friend @datpv.\n\nWe're all so glad to have you here and we hope you have the best birthday ever. You always bring so much positivity and fun, and we appreciate everything you do. Have an awesome day filled with all your favorite things. Cheers to another fantastic year.\n\n![](assets/8-then-came-the-last-days-of-may-birthday.webp)\n\n### Discovering your inner self: zodiac and MBTI\nI couldn't help but notice that a lot of us in the community seem to be really interested in astrology and personality typing. I think it's fascinating how these things can say a lot about our traits, strengths, and even potential career paths. [See if you find any match here](https://www.notion.so/Applying-Myers-Briggs-Type-Indicator-in-HR-a22ce338e4d549b89ae8503252688957?pvs=21).\n\nWe've all had a laugh about the classic Libra @innno_ indecisiveness, Pisces @bienvh's dreaminess. And Leos? @anna brings that bold, confident energy wherever she goes. But beyond the jokes, there’s so much to learn about ourselves and each other.\n\nEither way, we want everyone to feel celebrated for who they are.\n\n![](assets/8-then-came-the-last-days-of-may-mbti.webp)\n\n![](assets/8-then-came-the-last-days-of-may-zodiac.webp)\n\n### Yay, it’s wedding time\nThis Saturday morning, the fam is heading out to Ninh Thuan for Lap's wedding, set to take place this Sunday evening. Sounds like it's going to be a fun-filled weekend - everyone's getting there a day early to do some sightseeing, traveling, and food tours.\n\nThe last members will be joining in on Sunday morning. I bet you're all feeling pretty excited (and maybe a little busy) getting ready for the wedding.\n\nCongratulations to the happy couple.\n\n![](assets/8-then-came-the-last-days-of-may-wedding.webp)\n\n### Our new team t-shirts are coming soon\nWe've got some quick updates on our team's new t-shirt status. The printing process is in full swing, and very soon, we'll all be sporting our brand-new t-shirts featuring our fresh logo. Get ready to show off your team spirit, folks.\n\nThe choice was clear: among the various options, the vast majority of you preferred the logo with the simplest design. A big thank you to @anna for creating such a sleek and stylish design that truly represents us.\n\nKeep an eye out, because soon we'll be stepping out in style as a unified team.\n\n![](assets/8-then-came-the-last-days-of-may-tshirt.webp)\n\n### Gifts from Korea and healthy moves at the HadoHQ\nLast week, @huytq took an exciting trip to Korea and didn't come back empty-handed. He brought some gifts for the members. A huge thank you to @huytq for thinking of us and sharing these wonderful surprises.\n\nAlso, did you know that sitting too long can lead to back problems? To help us stay active, @hieuthu1 has introduced a couple of plank exercises. These quick routines are perfect for breaking up long hours at the desk.\n\nA healthy team is a happy team.\n\n![](assets/8-then-came-the-last-days-of-may-hado.webp)\n\n### Uniting through shared interests\nYou know, there's something magical about bringing people together around what they love. It might seem simple, but there's actually a lot of thought that goes into it.\n\nLike, someone might join a group because they're into a specific anime, but they might not be into another one. That's where having different servers or \"guilds\" on our Discord comes in handy. It lets people find their little communities within the bigger one.\n\nThis way, everyone can find their perfect fit and connect with others who share their interests. What do you think - do you have any ideas for how we could do an even better job at it?\n\n![](assets/8-then-came-the-last-days-of-may-chatting.webp)\n\nThere’s a fun road ahead to building a better community. [Bye bye bye](https://www.youtube.com/watch?v=Eo-KmOd3i7s), May.\n\nHope you have a lucky June ahead. We’d be happy to expand this server with like-minded people.\n\nOn vous verra sur l’Internet!\n","title":"Weekly Digest #8: Then came the last days of May","short_title":"#8 Then came the last days of May","description":"Here's to hoping for a brighter and better month on this last day of May. We’re in the heat of a community offline meet-up today, gathering to discuss the month’s progress. Everyone's a bit busy arranging their travel to Saigon, a wild place we all call home. So, let’s dive into what we’ve been up to.","tags":["weekly-digest","meetup","community","team"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Fri May 31 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/8-then-came-the-last-days-of-may.md","slugArray":["updates","digest","8-then-came-the-last-days-of-may"]},{"content":"\nHow quickly the first half of the year speeds up before it slows down. It’s really the second half of 2024 already. Time flies when you're having a blast. \n\nGet ready to rewind and relive some of the awesome highlights from the last week, get pumped for the epic things we'll do together before this year is over.  \n\n### What a meet-up, a huge thank you\nBig thanks to all who joined our community meet-up last Friday. Even with the rainy weather and long trips from the north, you all showed up and made it a truly unforgettable event.\n\nThe energy was incredible, and we couldn't have asked for a better turnout. Let's keep this vibe going strong and get pumped for more fun times ahead. We really appreciate you sticking with us all the way.\n\n![](assets/9-a-little-more-speed-for-summer-meetup.webp)\n\n### Friendship blooms as we connect and celebrate\nAfter our Friday night meet-up, the excitement persisted. We organized additional activities for those who traveled a long way to join us. Saturday morning we enjoyed lively conversations and laughter at a café before savoring a tasty BBQ. Thanks @haongo1, @anna, @bienvh, @taipham, @thangnt, @hnh, and @minhth for spending your time.\n\nMeanwhile, another group set off for Ninh Thuan to celebrate @lapnguyen's wedding. It's been a week brimming with adventure and camaraderie.\n\n![](assets/9-a-little-more-speed-for-summer-side-event.webp)\n\n### Thought on the future of software engineering\n@tristran shared an article expressing concerns about GenAI's impact on software engineering careers. The article highlighted Microsoft's partnership with Cognition to deploy Software Engineer AI to Azure and the mixed reactions from developers about the world's first AI software engineer, Devin.\n\n@tieubao responded with his perspective on GenAI, offering a more optimistic view:\n\n\"In my opinion, if you provide GenAI with enough data and a solid GitHub code base, it can effectively assist you. By letting GenAI handle basic tasks like CRUD operations, developers can focus on mastering complex system design and effective implementation. This shift allows for greater skill development and a promising future in software engineering.\"\n\nWhat do you think? How do you see GenAI impacting your career?\n\nYou can check out the link @tieubao mentioned for more insights: [AI Programming](https://spectrum.ieee.org/ai-programming).\n\n![](assets/9-a-little-more-speed-for-summer-gen-ai.webp)\n\n### More on the engage to earn\nJust wanted to drop some cool news your way. We've just updated the rewards in the **💻・tech** channel. Now, every tech link you share will earn you 1 ICY. You won't believe it—some folks thought this was a glitch at first.\n\nWe do this to encourage everyone to learn new things, engage with the team, and make sharing even more worthwhile. There are multiple activities going on, and everyone is welcome to join hands. Who knows, you might just become our next ICY millionaire.\n\n![](assets/9-a-little-more-speed-for-summer-engage.webp)\n\n### Unique celebrations for special moments\nBlast off into another year @hieuthu2. Congrats on unlocking another year of life. Hope your new age is filled with epic loot drops, lovely gift from your girlfriend, super rare achievements, and a health bar filled to the max. \n\nWelcome to the Storybook Start. Congratulations on the arrival of your little hero @huynk. May your little one level up quickly, with plenty of sleep boosts and diaper loot. Here’s to joyful quests and magical moments ahead.\n\n![](assets/9-a-little-more-speed-for-summer-icy.webp)\n\n![](assets/9-a-little-more-speed-for-summer-birthday-newborn.webp)\n\nWish we could hit rewind and relive [yesterday once more](https://www.youtube.com/watch?v=Aa9YmR8SdeA). Those moments with me and the team were truly special, filled with laughter and joy that we all cherish.\n\nP.S. If you’re feeling nostalgic or just want to catch up on what you might have missed, you can find highlights from our previous edition [right here](https://memo.d.foundation/playground/digest/8-then-came-the-last-days-of-may/). \n\nUntil next time.\n","title":"Weekly Digest #9: A little more speed for summer","short_title":"#9 A little more speed for summer","description":"How quickly the first half of the year speeds up before it slows down. It’s really the second half of 2024 already. Time flies when you're having a blast. Get ready to rewind and relive some of the awesome highlights from the last week, get pumped for the epic things we'll do together before this year is over.","tags":["weekly-digest","meetup","community","team"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Sat Jun 08 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/digest/9-a-little-more-speed-for-summer.md","slugArray":["updates","digest","9-a-little-more-speed-for-summer"]},{"content":"\n## What is Learning at Dwarves?\n> At Dwarves Foundation, we believe that learning is one of the most important aspects of any organization. We also believe in creating a culture that fosters learning and innovation.\n\nWe want to demonstrate and encourage individual and organizational learning, where both gaining and sharing knowledge is prioritized, valued, and rewarded. Learning is an ongoing process that never ends in our fast-moving industry. The concept of continued learning at Dwarves Foundation has become synonymous with having a growth mindset — a belief in your own ability to change or grow through experience or study.\n\nTo grow as professionals, so we have built an environment where people feel comfortable asking questions and admitting they don't know everything. We encourage people to seek out opportunities outside their normal day-to-day work, whether that means attending conferences or taking on new projects with other departments within the company.\n\nNot only that, but we also believe that every employee has something to teach others, whether it is through formal instruction or simply by helping others with their work. We are committed to providing the tools, education, and training needed for all employees to be successful in their roles. In addition, we organize many events and activities for our people to express their ideas, share their knowledge, and learn with others:\n\n1. **Monday's radio talk**: a weekly show where people can share their thoughts on a given topic and hear what others have to say as well.\n1. **Friday's showcase**: a weekly presentation where people can share what they've been working on lately with the rest of the company.\n1. **Brainery**: a collection of learning pieces where we want to build up the 1% improvement habit of learning in public.\n1. **R&D Topics**: our hub for research and development to tackle common challenges and an environment to foster continuous improvement and learning.\n1. **Dwarves Rewind**: a curated list of trending and starred topics from our Discord and news list reviewing industry changes over every week.\n\n## Brainery\n### Inception and Growth\nWe’ve refreshed and reorganized our Brainery since the start of August 2021 in an effort to involve our company and community members in sharing knowledge.\n\nWe were surprised to see that our knowledge graph has grown into something substantial, and we’re excited to see what everyone will be learning in 2023.\n\n![brainery](assets/2022-forward-engineering_brainery-graph_compressed.mp4)\n\n### Trending Tags\nA summary of some trending tags we see in our Brainery. These tags represent what things our contributors are actively thinking about and researching.\n\nOur company, as well as the industry, is very frontend heavy, so it’s refreshing to see that frontend still has a strong place in our learning endeavors. We’ve been able to hear voices from our backend engineers, our data team, and definitely our community members.\n\n![](assets/2022-forward-engineering_forward-engineering-year-2022_fdc3f02efffae1ad50e061ba23e81362_md5.webp)\n\n### Newest Contributors\nWe collect a list of new contributors, those who have contributed knowledge for the first time in our Brainery. A shout-out to **[Thanh Le](https://github.com/thanhlmm)**, who has not only contributed to our second brain, but also contributed to a [Radio Talk Discussion with our team](https://www.youtube.com/watch?v=z37-ZS7cKJ0).\n\n**Discord Contributors**\n* **antran**: [202210150019 - Migration Planning](https://brain.d.foundation/%CE%A9+Fleeting+notes/202210150019+-+Migration+Planning)\n* **haongo**: [202211141513 - Materialized View Pattern](https://brain.d.foundation/%CE%A9+Fleeting+notes/202211141513+-+Materialized+View+Pattern)\n* **hieuvd**: [202211141287 - Go JSON Parsing](https://brain.d.foundation/%CE%A9+Fleeting+notes/202211141287+-+Go+JSON+Parsing)\n* **hollow**: [202210162154 - The Best of CSS TLDR](https://brain.d.foundation/%CE%A9+Fleeting+notes/202210162154+-+The+Best+of+CSS+TLDR)\n\n**GitHub Contributors**\n* **[chinhld12](https://github.com/chinhld12)**: [Singleton Design Pattern in Javascript](https://brain.d.foundation/Engineering/Frontend/Singleton+Design+Pattern+in+Javascript)\n* **[cnhhoang850](https://github.com/cnhhoang850)**: [What Screens Want](https://brain.d.foundation/Design/What+Screens+Want)\n* **[huytieu](https://github.com/huytieu)**: [DiSC Personality Types in teamwork](https://brain.d.foundation/Communication/DiSC+Personality+Types+in+team+work)\n* **[knguyenuit](https://github.com/knguyenuit)**: [Stateless and Stateful Widgets in Flutter](https://brain.d.foundation/Engineering/Mobile/Stateless+and+Stateful+Widgets+in+Flutter)\n* **[leduyhien152](https://github.com/leduyhien152)**: [Liquidity pool](https://brain.d.foundation/Blockchain/Liquidity+pool)\n* **[mirageruler](https://github.com/mirageruler)**: [Unexpected pitfalls and some handy patterns with concurrency in Go](https://brain.d.foundation/Engineering/Backend/Unexpected+pitfalls+and+some+handy+patterns+with+concurrency+in+Go)\n* **[nguyennh4522](https://github.com/nguyennh4522)**: [Kubeseal & Sops](https://brain.d.foundation/Engineering/DevOps/Kubeseal+%26+Sops)\n* **[nnhuyhoang](https://github.com/nnhuyhoang)**: [Full-text search with Postgresql](https://brain.d.foundation/Engineering/Full-text+search+with+Postgresql)\n* **[pthung1311](https://github.com/pthung1311)**: [Data race and race condition](https://brain.d.foundation/Engineering/Mobile/Data+race+and+race+condition)\n* **[thanhlmm](https://github.com/thanhlmm)**: [Prevent Layout Thrashing](https://brain.d.foundation/Engineering/Frontend/Prevent+Layout+Thrashing)\n* **[tienan92it](https://github.com/tienan92it)**: [CSS Container Queries](https://brain.d.foundation/Engineering/Frontend/CSS+Container+Queries)\n* **[trkhoi](https://github.com/trkhoi)**: [Software Quality Assurance](https://brain.d.foundation/Engineering/Software+Quality+Assurance)\n* **[truong-dwarvesv](https://github.com/truong-dwarvesv)**: [Scale up Application using Jetpack Navigation](https://brain.d.foundation/Engineering/Mobile/Scale+up+Application+using+Jetpack+Navigation)\n* **[yyyyaaa](https://github.com/yyyyaaa)**: [Mitigate blocking the main thread](https://brain.d.foundation/Engineering/Frontend/Mitigate+blocking+the+main+thread)\n\n## R&D Topics and Challenges\nResearch and Development (R&D) came about as a collective department for solving common problems we faced across all of our projects. As an innovative software firm, we found that the foundations surrounding innovative software were also vital to realizing their prospects.\n\nBelow are some of the common problems we’ve begun more critical research and exploration on:\n\n### Common problems\n* ***Locate on Web and Mobile:*** Have you considered making your application available in various languages, currencies, timezones, etc., to users across the globe? You can boost revenue with this method. With the help of the following research, development, and other efforts, we are currently attempting to present this engine to you as the Common Challenge solution.\n* ***Query Database 500M Records, Filter Multiple Table:*** If a day, our database contained 500 million records and despite our customers having to wait five minutes, they were still unable to complete a transaction. How would you approach this difficulty if you were a business owner? We are here to help you find a solution.\n* ***Database Connection Concurrency:*** As a Software Engineer, I'm sure you're aware that when working at the Backend level, we must manage any transactions that occur between our services and the database. Sure, have you considered how we can implement it effectively if you need to interact with more than one entity at the same time?\n\n![](assets/2022-forward-engineering_forward-engineering-year-2022_5c73807e107d674db4880be752f44319_md5.webp)\n\nThis year, we’ve completed one of our challenges, **Feature Flags**. This was a concern spanning across our DevOps, Management, and Engineering domains. We’re proud to list it as one of our completed challenges:\n\n### Completed challenges\n**Feature flags:** Options to enable/disable a feature in the application to help developers have a good experience and improve performance in the development process. We have discovered 3 solutions to resolve this challenge. With a wide range of solutions, we have the ability to serve any usage and project in development life.\n* **Solutions and articles:**\n* [https://viblo.asia/p/feature-toggle-BQyJK33QJMe#_introduction-0](https://viblo.asia/p/feature-toggle-BQyJK33QJMe#_introduction-0)\n* [https://dwarvesf.hashnode.dev/common-challenges-feature-flag](https://dwarvesf.hashnode.dev/common-challenges-feature-flag)\n* [https://medium.com/dwarves-foundation/design-a-feature-flag-system-7986b4a080cc](https://medium.com/dwarves-foundation/design-a-feature-flag-system-7986b4a080cc)\n\n### Newest challenges\nHere are some of the new topics we’ve added this year that we believe will be pressing challenges we will face very soon:\n\n1. Design an On-Ramp and Off-ramp p2p system for cryptocurrency\n1. Design system for layer 2 using ZK rollup\n1. Design system for indexing data on-chain\n1. Design multisign wallet support for all blockchain\n\n### Keywords for upcoming challenges\nHere are some of the keywords we’re on the watch for where we haven’t specified a problem statement but we expect will manifest challenges in the near future.\n\n* zkEVM/zkVM\n* Rollups\n* Staking\n* Ethereum Adoption\n\n## Research Narratives\n### Software Design Research Group\nWe’ve held our Software Design research group for just over a year. Many changes have happened, with Hoang Nguyen, our backend engineer, leading the group. We’ve had quite a lot of topics, some are, but not limited to:\n\n* **Database Normalization** by Minh Luu. An inside look at normalization strategies in databases.\n* **Event-sourcing** by Cuong Mai. A simplified but enterprise outlook on managing persistence.\n* **Database Partitioning Design** by Hoang Nguyen. A look at vertical scalable practices for PostgreSQL.\n* **Sharding Design** by Hieu Vu. A look at horizontally scalable practices for PostgreSQL through a demo on Citus.\n* **HyperLogLog** by [Huy | Maius Pay#8518]. An algorithmic solution to a count-distinct problem.\n\n### Closing December 2022\nRight before New Year, we were able to finish off the year with some exciting topics:\n* **CQRS MODELING**: We've just had an inside look at CQRS modeling and application refactoring presented by Cuong, one of our backend engineers. Domain Driven Design, Event Sourcing, and now CQRS were research topics undertaken by Cuong to understand enterprise-level design patterns better.\n\n* **DOCUMENT DATABASE**: We've also got to see a demo from Khang, our backend engineer, demoing CRUD, indexing, aggregation and other features from a distributed instance of MongoDB for his research on document databases. Khang has gone into great detail of the inner workings of MongoDB and the nuances of a document database.\n\n## Dwarves Rewind 2022\n[Dwarves Rewind](https://www.linkedin.com/newsletters/dwarves-rewind-6963734647327375360/) is a reading list serving as a collection of news we aggregate weekly. Tech is a very high-paced industry, and rewind helps to serve as a curated list of trending and high-profile topics that everyone can look back on.\n\n![](assets/2022-forward-engineering_forward-engineering-year-2022_ae9016b58831984c03b5125922855553_md5.webp)\n\n### Trending Topics\nSome of our trending topics over the year caught our eye as we see the industry progress.\n\n- **August:** Aptos and Sui Blockchain Platform\n- **September:** Grafana Tokio Console Data Source\n- **October:** Announcing TypeScript 4.9 Beta, Meta got bumped off world's top 20 companies' list, Tesla’s AI Day, Binance Becomes Second-largest Entity Of Uniswap\n- **November:** Kobecon + CloudNativeCon 2022, .NET 7 release, Meta's New AI System 'Galactica\n- **December:** Warner Music Group Joins Forces With Polygon, Starbucks Launched Web3 'Odyssey', Gate.io pledges $100M to revive the crypto industry.\n\n### Hottest Topics\nThe hottest topics that shook the tech industry, from captivating and controversial products to groundbreaking AI, emerged from state-of-the-art tech.\n\n- **August:** Stable Diffusion release, DALL-E release, Github Copilot release\n- **September:** Apple Event - Far Out, Ethereum Mainnet Merge, iOS16, Adobe to buy Figma in $20 billion bid\n- **October:** Next.js Conf 2022, Acquisition of Twitter by Elon Musk, macOS Ventura 13.0 release, Vercel announces Turbopack, Mass layoffs at Twitter and giant tech firms, Made by Google 2022: Google Pixel 7 & 7 Pros, Aptos Mainnet “Aptos Autumn.”\n- **November:** Solana Breakpoint 2022, Github Codebase, GitHub Universe 2022, Introducing Notion AI, FTX Crashed, AWS re:Invent 2022, Schema by Figma 2022,\n- **December:** ChatGPT, Orbit 1 NFT, Metaverse, Year in Review, Google in Search 2022\n\n### Thoughts List\nOn most of our Dwarves Rewind, we list our thoughts and burning questions each week. Here are some of our favorite ones:\n\n**#12:** For iOS 16, will you be able to restore or downgrade your device without losing data across versions? Ethereum will be different, but what does that mean to you?\n\n**#15:** With the introduction of “Matter” standardized home devices, Tesla’s AI Day, how will these Matter devices and AI work together in our homes? What will the future of technology look like overall?\n\n**#17:** All eyes on Aptos Mainet. While Ethereum has taken a major leap forward following ‘the merge’, challengers like Solana are making inroads with much faster transaction speeds. Do you think Aptos is likely to compete with ETH in the near future?\n\n**#18:** What will be the fate of Twitter’s employees once Musk takes the reign?\n\n**#19:** Meanwhile, some Twitter employees have expressed their desire to be laid off and get severance, and some are concerned that disagreeing with Musk means losing their jobs and packages. Does the fear of losing a job motivate employees to do better or make things worse?\n\n**#20:** Since Hey, GitHub! is an experimental tool, it seems it could reduce the amount of interaction required with a mouse and keyboard. The good news is that at the moment, it's only available when coding within VSCode.\n\n**#21:** Generative AI models are trained on copyright-protected data — is that legal? The question arises because of how generative AI systems are trained, and worked by identifying and replicating patterns in data, like most machine learning software.\n\n**#22:** What other technologies will AWS feature during re:Invent 2022? A passwordless future integrates two thought-provoking concepts—making logins more dependent on your knowledge than your identity, and integrating a login across platforms. Can it work?\n\n**#23:** It's refreshing to hear good news this crypto winter. \n\n- With the issuance of Soulbound tokens, how will the involvement of Japan’s second-largest bank affect the crypto world?\n- Web3 is gaining traction despite the crypto winter. What are the moving factors associated with the sudden rise in interest despite high pessimism?\n\n**#24:** The last week has been abuzz with ChatGPT, for the non-technical friends, it was amazing to see the transcripts. Even though they knew it was an AI (with superhuman response times), they had natural conversations with it as if it were a human. The next step will maybe affect embedded systems. What are the possibilities for the future of AI in IoT?\n\n**#25:** After FTX’s collapse, several cryptocurrency firms have been trying to show that they still hold onto their users' assets. Many people seek auditing companies to give their clients and potential investors third-party assurances.\n\n**#26:** Remember when NFTs were cool and people thought their JPGs were worth millions? All this happened. The immersive internet is already here, in Web 3.0. How much deeper can we go, and how many more phases can we take?\n","title":"Forward Engineering 2022","short_title":2022,"description":"We want to demonstrate and encourage individual and organizational learning, where both gaining and sharing knowledge is prioritized, valued, and rewarded. Learning is an ongoing process that never ends in our fast-moving industry.","tags":["technology","updates","performance","forward-engineering"],"pinned":false,"draft":false,"hiring":false,"authors":["thanh","monotykamary","innno_"],"date":"Wed Jan 11 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/forward-engineering/2022.md","slugArray":["updates","forward-engineering","2022"]},{"content":"\nAs we step into the exciting opportunities of August, we are at a crucial point in the ever-changing world of technology. Our adventure until now has been incredibly thrilling, with a strong focus on 'LLM in Production.' Now, we shift our attention to a topic that is always important and never outdated: **Fullstack Engineering**.\n\nIn a world where new businesses and product teams are always changing, there is a high demand for engineers who are skilled in many areas and can handle both sides of the development process. The rise of AI-powered development tools has blurred the lines between front-end and back-end development, making it essential for engineers to know a wide range of technologies and methods.\n\n## Tech Radar\nStep into the latest edition of the Dwarves Foundation Tech Radar Report, where we shed light on the technologies steering our engineering team's growth and success. In this report, we illuminate the technologies shaping our path forward, from evaluating new methodologies to embracing tools that amplify our efficiency.\n\n![](assets/august-forward-engineering_(1).mp4)\n\n### Type-safe Server Client Development</span>\n***Assess***\n\nDevelopers working on Javascript Applications often face the challenge of enforcing type safety between the client and server. One effective solution is to automatically generate an OpenAPI Spec file from server code. This can then be used with the OpenAPI generator to produce a client-side library for making Type-safe API calls to the backend. Our existing workflow has adopted the Type-safe approach using Swagger for API documentation. We aim to upgrade this approach by automating the generation of API methods.\n\n### Large Language Models\n***Trial***\n\nOur journey with [Large Language Models](https://radar.d.foundation/Large-language-model-LLM-60d7f1372aef4e60ae12894bdbafa473) continues to evolve. We are extending our research and learning path for engineers starting out in developing AI, as outlined in this [Engineering Story Map for LLMs](https://dwarvesf.hashnode.dev/an-engineering-story-map-for-llms). Although each engineering story is unique, this map provides a general idea of where one might be in their journey and what lies ahead. We also had a successful experiment with Reinforcement Learning from Human Feedback (RLHF), despite realizing the challenges in the process of training and fine-tuning models in terms of handling operational, data, and lack of foundational knowledge. More details on the challenges faced can be found in this [article](https://dwarvesf.hashnode.dev/challenges-faced-when-researching-rlhf-with-openassistant).\n\n### PNPM\n***Adopt***\n\nOur team has officially decided to switch to [pnpm](https://radar.d.foundation/pnpm-198b80c6b5444f8cb1d11392ddc2bf63) as our primary package management tool. After careful evaluation, we found that pnpm is widely embraced by the development community and has been successfully used by great teams at Vercel, Nx, and Chakra UI. Previously, we were using Yarn V1 classic, but as our projects grew, we faced challenges with disk space and slow installations. To streamline our development workflow, we explored pnpm and conducted thorough tests. The results were promising, proving pnpm to be efficient and reliable. Now, we have successfully migrated all major internal tools to pnpm, and it's already making a positive impact on our development speed and productivity. We've also started incorporating pnpm into some client projects. Though we encountered some difficulties with hoisted dependencies in monorepos during the migration process, the overall effort was worthwhile, contributing to our team's enhanced efficiency.\n\n### Qwik\n***Assess***\n\nThe developer world is flooded with numerous frameworks. NextJS, a comprehensive ecosystem and the reference implementation of React, has extensive libraries, documentation, and resources, aspects not paralleled by [Qwik](https://radar.d.foundation/Qwik-e37f4c5cf0ff434ea53c18a2af805864). This makes us skeptical about using Qwik for critical projects in the foreseeable future. However, Qwik's methodology could represent the future of development. It is crucial to understand Qwik's architecture, efficiency secrets, and coding technique implications. One key concept is [Resumability](https://dwarvesf.hashnode.dev/exploring-resumable-server-side-rendering-with-qwik#heading-resumability), which refers to the ability of Qwik applications to resume from a server-side-rendered (SSR) state without the need for hydration. It's not about adopting Qwik entirely, but recognizing its potential influence on stalwarts like React and NextJS. Familiarity with Qwik can provide a pioneering advantage and a fresh perspective on framework dynamics.\n\n### AI-aided development\n***Assess***\n\nIn the software industry, the exploration of rapidly evolving AI tools for code writing support is becoming increasingly common. One compelling use-case is leveraging ChatGPT to generate tests for existing implementations, or even adopting a Test-Driven Development (TTD) approach where the AI drafts the tests before we implement the details. Beyond testing, our engineers have successfully utilized GPT models to generate Entity-Relationship Diagrams (ERDs) and various UML diagrams, with promising results. While we've experimented with AI for auditing source code, this remains a work-in-progress due to security concerns. Additionally, Copilot has become an invaluable tool in our development workflow, offering next-level autocompletion features that significantly enhance productivity.\n\n## Brainery\n### Growth and Direction\nAs we proceed in our journey of knowledge and skill enhancement, our Brainery continues to bloom with exciting ideas and valuable insights. Our contributors have exhibited an increased proficiency in delivering concise writings, covering work delivery, practical concepts, and foundational knowledge.\n\nThis month, we are thrilled to highlight our learning journey towards Full stack engineering. Unlike previous months, there has been a greater focus on backend engineering from our Golang 2023 course. We’re really proud of our frontend engineers that participated in our backend course and really excited what they can do with their newfound knowledge. \n\n### Trending Tags\nThe trending tags of this month offer a fascinating snapshot of our contributors' current research interests and thought processes. It's been particularly interesting to see the ongoing focus on LLM, with the addition of our [story map for LLMs](https://brain.d.foundation/Engineering/AI/Story+map+for+LLMs), and research on [reinforcement learning](https://brain.d.foundation/Engineering/AI/RLHF+with+Open+Assistant).\n\nIn parallel with the AI-centric discussions, we have also seen increased exploration into backend techniques, such as testing and handling concurrency. These discussions underline our commitment to staying at the forefront of tech innovations while deepening our understanding of core concepts.\n\nThe tags for August include: `#backend` `#test-cases` `#best-practices` `#golang` and many others:\n\n![](assets/2023-august-forward-engineering_forward-engineering-august-2023_6ee23ade19901e6c8634676424d18388_md5.webp)\n\n### Top Contributors and Notes\nOur community continues to thrive due to the collective effort of our talented contributors. \n\nEach month, we acknowledge their contributions in our Brainery's **[Latest Notes](https://brain.d.foundation/Latest+Notes)** section, linking their GitHub accounts for further reference.\n\nWe also value and encourage our community's interaction on our **[Discord](https://discord.gg/dwarvesv)** server. It's a great space to stay updated, engage in lively discussions, and catch up on the latest from us. Be sure to join us there!\n\n![](assets/2023-august-forward-engineering_forward-engineering-august-2023_e5dccd4a857f77f41f71cc744a916605_md5.webp)\n\nHere are some noteworthy articles that were shared in our Brainery during August:\n\n* [Testing Made Simple Best Practices for Golang Test](https://brain.d.foundation/Engineering/Backend/Testing+Made+Simple+Best+Practices+for+Golang+Test) by Dat Pham\n* [Test Doubles](https://brain.d.foundation/Engineering/Backend/Test+Doubles) by Dat Pham\n* [Level up Your Testing game with Gomock](https://brain.d.foundation/Engineering/Backend/Level+up+Your+Testing+game+with+Gomock) by Dat Pham\n* [Story map for LLMs](https://brain.d.foundation/Engineering/AI/Story+map+for+LLMs) by Tom X Nguyen\n* [RLHF with Open Assistant](https://brain.d.foundation/Engineering/AI/RLHF+with+Open+Assistant) by Toan Ho\n* [UML state machine diagram](https://brain.d.foundation/Engineering/UML+state+machine+diagram) by Khac Vy\n* [Redis Leaderboard](https://brain.d.foundation/Engineering/Backend/Redis+Leaderboard) by Tuan Pham\n* [Window and iframe communcation](https://brain.d.foundation/Engineering/Frontend/Window+and+iframe+communcation) by Thanh Pham\n\n## R&D Topics and Challenges\nInnovation continues to drive us forward at R&D. For the month ahead, we're expanding our scope to encompass emerging trends in development productivity, user interface design, and engineering paradigms.\n\n### Research Topic\n* **API Code & Client Generator**: As we stride towards bolstering our development productivity, adopting or customizing a tool for API code and client generation is the next logical step. The principal objective is to find a tool that provides robust schema validation, supports authentication, and can be seamlessly integrated with API fetching libraries like react-query and swr. This will expedite our development process, making it more efficient and streamlined.\n* **Live Chat UI**: Crafting an exceptional Live Chat Widget brings multiple challenges to the forefront. Our focus here involves effective communication between iframe and window, maintaining stable socket connections, and employing the optimistic pattern for real-time updates. Performance and user experience remain at the core of our design considerations, as we aim to build a seamless and responsive live chat system.\n* **Product vs Platform Engineer**: We are reevaluating our approach to categorizing engineers based on their tech stack. Instead, we are exploring the interesting perspective of categorizing engineers as Product or Platform Engineers. Product Engineers are focused on building and enhancing features that address end user problems, whereas Platform Engineers concentrate on the infrastructure that underpins the product. This distinction will help in aligning the skill sets of our engineers more effectively with their roles, ensuring optimal productivity and outcome.\n\n### Future Challenges\nBesides our main research subjects, we are also monitoring various upcoming trends that might bring either hurdles or prospects in the upcoming times. These encompass:\n\n* **Fullstack tracing**\n* **CQRS**\n* **Documentation as Code**\n* **Just enough architecture**\n\nAs we persist in our R&D voyage, we endeavor to remain at the forefront of tech progress, delivering creative answers that propel our initiatives and the broader software sector.\n\n## Research Narratives\n### Software Design Research Group\nThis month, our Software Design Research Group is getting a bit of a revamp. The group has been exploring ways to use AI to give insights into a project, as well as explore using animations to better explain more complex topics for system design & data structures and algorithms.\n\nKey discussions this month included:\n* **Using AI to help augment System Design** - We used ChatGPT to help us event storm a warehouse inventory application which was then used to generate prompts to create AI diagram templates on Draw.io.\n\n![](assets/2023-august-forward-engineering_forward-engineering-august-2023_982514c306a616ecbd5c4451112ec201_md5.webp)\n\n* **Exploring animations with Motion Canvas and Remotion** \nWe take an introductory look into 2 libraries to help us programmatically create animations for algorithms and system design, making the topic more accessible for our engineers across domains. Shoutout to [NGs-Hjodra](https://www.youtube.com/@NGs-Hjodra) for his open-source work and examples on Motion Canvas.\n\n![](assets/2023-august-forward-engineering_forward-engineering-august-2023_insertion_sort_compressed.mp4)\n\nThese insights continue to broaden our understanding of both traditional and emerging software design concepts, equipping us to better tackle real-world challenges.\n\n## Dwarves Rewind August 2023\n[Dwarves Rewind](https://www.linkedin.com/newsletters/dwarves-rewind-6963734647327375360/) is a reading list serving as a collection of news we aggregate weekly. Tech is a very high-paced industry, and rewind helps to serve as a curated list of trending and high-profile topics that everyone can look back on.\n\n![](assets/2023-august-forward-engineering_forward-engineering-august-2023_7d72b4327ffbaf2595178ba126a3d16a_md5.webp)\n\n### Trending and Hot Topics\nThis month, our engineers have been on top of topics related to full stack and DevOps testing, such Test Doubles, Failure Management in Go, Testing AWS services with LocalStack, and using Mock Service Worker (MSW) for web development. This month also includes research journeys with LLMs and a few others:\n\n* **[Product and Platform Engineers](https://leerob.io/blog/product-engineers)** - The changing landscape of frontend and backend engineering and the emergence of product and platform engineers. Frontend developers are now building entire web applications, while backend developers are faced with the choice of supporting frontend code or focusing on infrastructure.\n\n  ![](assets/2023-august-forward-engineering_forward-engineering-august-2023_297808eb5b9e65cd393bf16028f5ea4d_md5.webp)\n\n* **[An Engineering Story Map for LLMs (by Tom Nguyen)](https://dwarvesf.hashnode.dev/an-engineering-story-map-for-llms)** - This story map aims to help engineers learn how to investigate and create AI applications like chatbots, code automation, personal assistants, and LLMs like ChatGPT and LLaMA.\n\n  ![](assets/2023-august-forward-engineering_forward-engineering-august-2023_1780847ec8d1a39bed3a7f562fd5a9a4_md5.webp)\n\n* **[Open challenges in LLM research (Huyen Chip)](https://huyenchip.com/2023/08/16/llm-research-open-challenges.html)** - [Chip Huyen](https://www.linkedin.com/in/chiphuyen?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAIQAJQBE3ykLNnsOPVvxwuuVCOir2zAjOQ) has discussed some of the open challenges in LLMs research, crucial for improving the performance and applicability of these models.\n\n  ![](assets/2023-august-forward-engineering_forward-engineering-august-2023_86c0a3ea4d4cdf5b9d0a359a22942fa0_md5.webp)\n\n* **[How to Build a Globally Distributed, Multi-Region Identity and Access Platform with Go](https://www.ory.sh/global-identity-and-access-management-multi-region/)** - Organizations are given the ability to effectively manage user identification and authorization on a worldwide scale by global identity and access management (IAM).\n\n  ![](assets/2023-august-forward-engineering_forward-engineering-august-2023_ffd18682180d9335dbe0ac7418727372_md5.webp)\n","title":"Forward Engineering August 2023","short_title":"August 2023","description":"Our adventure until now has been incredibly thrilling, with a strong focus on 'LLM in Production.' Now, we shift our attention to a topic that is always important and never outdated: **Fullstack Engineering**.","tags":["engineering","performance","updates","forward-engineering"],"pinned":false,"draft":false,"hiring":false,"authors":["thanh","monotykamary"],"date":"Wed Aug 30 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/forward-engineering/2023-august.md","slugArray":["updates","forward-engineering","2023-august"]},{"content":"\n**This month**, we have focused on revamping how we learn, familiarize, and work with tech. We are excited to announce that we have updated our Forward Engineering to better reflect the feedback and insights from our Labs team, Operations Team, and Consulting Team.\n\nThis is to hopefully provide you with a more comprehensive publication that not only keeps you informed about the latest technologies and where they are applied, but also foster collaboration and innovation within our organization. We hope you find this edition of Forward Engineering informative and give you a better idea of what we’re doing. As always, we welcome your feedback and encourage you to share your thoughts on the content.\n\n## Tech Radar\n![](assets/2023-december-forward-engineering_forward-engineering-december-2023_december-forward-engineering_compressed.mp4)\n\n### Rust\n***Assess***\n\n|          |                                                                         |\n| -------- | ----------------------------------------------------------------------- |\n| Tags     | `#memory-management` `#systems-language` `#backend` `#embedded-systems` |\n| Domain   | `Embedded Systems` `Networking and DNS` `Security` `Fintech`            |\n| Projects | `...`                                                                |\n\nRust, the programming language, has been on our radar for quite some time, primarily in the context of developing compiler tooling – a niche that sparked only modest interest within our team. However, our perspective shifted significantly after engaging in [a community project](https://github.com/webuild-community/spacebot) aimed at creating a Rust-based game server. This experience opened our eyes to Rust's impressive capabilities. Our developers have come to greatly appreciate the language's speed, safety, and performance.\n\nFurthermore, we've observed that Rust continues to evolve, increasingly supporting a wider array of applications, notably in web development and artificial intelligence. This evolution has motivated us to delve deeper into the language. Our initial steps involve comprehending Rust's concurrency model, which is pivotal for our community project. Simultaneously, we are eager to explore new facets of Rust, expanding our understanding and application of this powerful language.\n\n### Retrieval Augmented Generation\n***Trial***\n\n|          |                                                                         |\n| -------- | ----------------------------------------------------------------------- |\n| Tags     | `#ai` `#llm` `#embeddings` `#llm-knowledge` `#indexing` `#vector-database` |\n| Domain   | `AI` `MLOps` `Indexing` `Semantic Search`            |\n| Projects | `...`                                                                |\n\nRetrieval Augmented Generation (RAG) is a general technique used to embed knowledge into a Large Language Model (LLM) to be used in lieu of fine-tuning. Instead of using inherited knowledge that was used to train the LLM to retrieve information for the user, RAG takes advantage of LLM embedding models to vectorize semantics into a vector database to be later \"retrieved\" and \"augmented\" as context to \"generate\" new informed outputs for the LLM.\n\nBefore the term was coined, our team has had done several experimentation with this technique with the help of `pgvector` on Supabase on TypeScript deployments, `chroma` on Python deployments, as well as with prompt engineering to further augment context for better indexing. This technique, although coined from development with LLMs, turns out to be a useful indexing technique that can be used as an alternative to keyword-based indexing.\n\n### Self-hosting AI Model in the Browser\n***Assess***\n\n|          |                                                                         |\n| -------- | ----------------------------------------------------------------------- |\n| Tags     | `#ai` `#llm` `#llm-knowledge` `#tooling` `#computer-vision` `#object-recognition` |\n| Domain   | `AI` `Language` `Object Recognition`            |\n| Projects | `...`                                                                |\n\nYOLOv8 is a state-of-the-art machine learning algorithm designed for object detection, image classification, and instance segmentation tasks. It is the latest iteration in the YOLO family of models, which are known for their speed and accuracy in real-time object detection. Key features of YOLOv8 include:\n\n- **Decoupled head with anchor-free detection**: This improvement allows for more accurate and efficient object detection.\n- **Mosaic data augmentation**: This technique helps improve the model's performance by creating new training samples through various transformations.\n- **Ease-of-use**: YOLOv8 is easy to implement through a user-friendly package, allowing users to quickly integrate it into their projects using the CLI and Python IDE.\n\nWe've been applying YoloV8 as part of our effort in self-hosting AI models in the browser. One of our notable demos is object detection on reCaptcha and creating a basic flow to automate reCaptcha as a fun way to bypass captchas.\n\n![](assets/2023-december-forward-engineering_forward-engineering-december-2023-20240119155936091.webp)\n\n### Passkeys\n***Assess***\n\n|          |                                                                         |\n| -------- | ----------------------------------------------------------------------- |\n| Tags     | `#security` `#authentication` `#passkey` `#authorization` |\n| Domain   | `Security` `Authentication`            |\n| Projects | `...`                                                                |\n\nPasskeys are a new type of login credential that allow users to access online accounts without having to enter a password. They are FIDO credentials stored on a user's computer or phone and provide a more secure way to sign in. Passkeys offer several advantages over traditional passwords:\n\n- **Security**: Passkeys use public key cryptography and are resistant to online attacks like phishing. They are also less susceptible to data breaches and hacking attempts.\n- **Ease of use**: Users can sign in to apps and websites using their device's biometric sensor (such as a fingerprint or facial scan) or a screen lock PIN. This eliminates the need to remember and manage multiple passwords.\n- **Cross-platform compatibility**: Passkeys can be used across different devices and platforms, as long as the user is logged in to their account.\n\nOur team has been experimenting with passkeys to provide authentication alternatives for users. We believe there is a ton of convenience in using passkeys as it offers a quick way for users to authenticate themselves without passwords. We've demoed 2 similar implementations using WebAuthn.\n\n![](assets/2023-december-forward-engineering_forward-engineering-december-2023-20240119160907180.webp)\n\n### Building UI Library Practices\n***Trial***\n\n|          |                                                    |\n| -------- | -------------------------------------------------- |\n| Tags     | `#ui` `#ux` `#best-practices` `#frontend` `#react` |\n| Domain   | `Web3` `Fintech` `Frontend`                        | \n| Projects | `consolelabs/web-foundation` `mochi-web`           |\n\nAlong with making our library [open-source](https://github.com/consolelabs/web-foundation), there has been a lot of advancements making Mochi UI becoming more generally available to our team and reaching towards version 1.0. Extensive effort was made to make sure component designs stay modular and allow integrated foundations set by our designer to be represented as code. User Experience is a key detail we make sure gets ironed out in every component, and has been part of our focus in standardizing the designs on Mochi UI.\n\nWorking through these challenges has given us the opportunity to lay out and consolidate our frontend foundations, showing our efforts through our recent demo workshop. Working with new standards while creating some of our own have promising results in easing developer experience and productivity. It has been an incredible learning experience and we will continue the path to transform into best practices for both our team and the wider community.\n\n## Labs Roadmap\nIn a recent collaborative discussion between key members of the Labs and Consulting teams, we’ve made decisive strides in pinpointing key topics and potential projects for development. Each topic is paired with specific challenges to ensure we engage deeply with the technology, understanding its practical applications. The focal point for the coming month is WebAssembly (WASM), alongside a range of exciting use-cases we plan to implement and demonstrate.\n\n### Currently Researching\n![](assets/2023-december-forward-engineering_forward-engineering-december-2023-20240126104209647.webp)\n\n| Research Topics         | Progress                                                                                                                                                                             | Next Step                                                                                                                                  |\n| ----------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------ |\n| Web Assembly (WASM)     | - Self-hosted a model in the browser with Tensorflow.js + YoloV8 to bypass reCaptcha v3<br>- Worked with data processing with DuckDB through WASM on the browser and on ObservableHQ | - Continue forward with porting Rust games and running them through WASM<br>- Process data with DuckDB WASM in a SME dashboard environment |\n| Passwordless            | - Worked on a simple frontend and backend system on handling Passkeys with WebAuthn                                                                                                  | - Implement QR-based login to handle authentication across multiple devices<br>- Experiment with Magic Links                                                                |\n| Artificial Intelligence | - Introduced a low-code and simple code example of implementing RAG on ChatGPT and local models                                                                                      | - Boilerplate AI and RAG integration on Elixir<br>- Deploy a Discord bot for recording and transcribing speech with Whisper                                                                                                                                           |\n| Building UI Practices   | - Demoed a workshop on Mochi UI, encompassing techniques and API composition across components                                                                                       | - Iron out practices and have Mochi UI to be GA                                                                                                                                           |\n\n## Dwarves Rewind - Discord Community\nDwarves Rewind this month will be a collection of tech interests we see happening in our Discord community. Along with our labs roadmap, the community have also shown more interest in Elixir and scalability, with a look on some old and new tools for web development. Some of the programming languages, tools and frameworks discussed this month are:\n\n1. **Actor Model**:\n   https://newsletter.systemdesign.one/p/actor-model\n   https://underjord.io/unpacking-elixir-the-actor-model.html\n   The Actor Model is a style of software architecture in which the basic computational unit is called an actor. It is a conceptual model for dealing with concurrent computation, defining general rules for how the system's components should behave and interact with each other. It has been been trending with our community and labs team, and we're investigating tech that include Actix in Rust and native processes in Elixir.\n   \n2. **Wasp Full-stack Framework**: https://wasp-lang.dev/\n   Wasp is a full-stack framework packaged as a custom programming language to template models, routes, pages, queries, and actions. Wasp takes an explicit approach in bridging and scaffolding the frontend, backend, and deployment layers through a compiler that compiles Wasp into associated files, such as JSX, docker, Prisma, etc.\n   \n3. **Biome**: https://github.com/biomejs/biome\n   Biome is a performant toolchain for web projects, it aims to provide developer tools to maintain the health of said projects. It is a fast formatter and linter for JavaScript, TypeScript, JSX, and JSON, with high compatibility with Prettier. \n\n4. **WebAuthn**:\n   https://discord.com/blog/how-discord-modernized-mfa-with-webauthn\n   https://webauthn.wtf/\n   WebAuthn (short for Web Authentication) is an API specification that enables applications to use strong and secure authentication methods for user registration and login. It provides a way for end users to authenticate themselves using hardware- or software-based authenticators, such as USB security keys or secure hardware elements integrated with a laptop or mobile device, instead of relying solely on passwords. It is a both an interest for the community and for our labs team in understanding authentication patterns. \n","title":"Forward Engineering December 2023","short_title":"December 2023","description":"We have focused on revamping how we learn, familiarize, and work with tech. We are excited to announce that we have updated our Forward Engineering to better reflect the feedback and insights from our Labs team, Operations Team, and Consulting Team.","tags":["forward-engineering","labs","AI","LLM"],"pinned":false,"draft":false,"hiring":false,"authors":["thanh","monotykamary"],"date":"Thu Jan 19 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/forward-engineering/2023-december.md","slugArray":["updates","forward-engineering","2023-december"]},{"content":"\nAs we usher in the month of June, we embrace the ever-changing landscape of technological innovation, recognizing that every twist and turn propels us forward into a world of limitless possibilities. We continue to chart our course through this vast expanse, driven by a mission to remain at the forefront of our industry and deliver unparalleled value to our clients. In this month's report, we reflect on our achievements and share our visions for the future, focusing on a central theme: \"**LLM in Production**\".\n\n## Tech Radar\nOur engineering team strides into June with a sharp focus on realizing the operational potential of Large Language Models (LLM). Our progress in May has bolstered our confidence in the immense capabilities these models hold, and now we shift our attention towards bringing these tools to life in real-world applications. Alongside this primary pursuit, we also keep an eager eye on the integration and exploration of reinforcement learning from human feedback, and continue our assessments of technologies like prompt engineering, Vector Database, React Server Component, and Zod. As always, we strive to adapt and evolve with the fast-paced technology landscape, and remain steadfast in our commitment to delivering exceptional value to our users and addressing our business needs with agility and innovation.\n\n### Large Language Models\n***Assess***\n\nOur exploration into **[large language models](https://radar.d.foundation/Large-language-model-LLM-60d7f1372aef4e60ae12894bdbafa473)** continues with renewed vigor this June. As we delve deeper into their potential applications through various experiments, we're broadening our understanding of their capabilities. The broad range of uses for these models in real-world applications continues to impress us, further reinforcing our focus on this domain.\n\nHowever, with these new developments come new challenges. We're working diligently to ensure that these models can handle a variety of use cases when integrating them into real products. Key hurdles we're addressing include ensuring the accuracy of the generated content, keeping latency low for real-time interactions, and managing the costs associated with running these models.\n\nWhile these challenges present a steep learning curve, they also provide us with the opportunity to innovate and optimize. By addressing these issues head-on, we're not just seeking to make effective use of large language models, but also to refine the way we interact with them, leveraging their capabilities to their full potential while managing the operational challenges. As we move forward, our focus remains on making these models work for us and our users, striking a balance between potential and practicality.\n\n### Reinforcement Learning from Human Feedback\n***Assess***\n\nWe are starting to explore **[Reinforcement Learning from Human Feedback](https://radar.d.foundation/Reinforcement-Learning-from-Human-Feedback-ea2a96254aa845d68b03053e6cf1b454)** (RLHF). This technique, which involves training models using feedback from human interactions, has the potential to make our AI systems more responsive and user-centric. Our aim is to understand the dynamics of RLHF and integrate this approach into our AI applications, thereby enhancing the precision and relevance of our models' outputs.\n\n### Prompt engineering\n***Trial***\n\nAs we continue our journey with **[Prompt engineering](https://radar.d.foundation/Prompt-engineering-9739ebfed76f4cff901cb46155d0bf23)**, we are exploring [self-refinement prompts](https://brain.d.foundation/Engineering/AI/LLM%27s+Accuracy+-+Self+Refinement) that allow an existing model to improve its own output, enhancing its effectiveness over time. Despite its benefits, we're mindful of potential vulnerabilities, particularly from adversarial prompts via techniques like prompt injection, which could pose risks to LLM applications. To mitigate these risks, crafting well-structured prompts is still an effective defense tactic. Our commitment remains to leverage and enhance prompt engineering to create safer, more efficient, and contextually precise AI systems.\n\n### Vector Database\n***Assess***\n\nOur experimentation with the **[Vector Database](https://radar.d.foundation/Vector-Database-dcf2259eb65d4b81a84c4882a8f0c0d6)** reveals new dimensions for its application in our work. As the database can assess the semantic similarity of words and suggest similar text, it serves as an ideal companion for our large language models (LLMs). By harnessing a Vector Database, we can augment LLMs, such as the GPT-4 model, with long-term memory. This augmentation goes beyond model training to include data from our vector database, allowing us to fine-tune and customize prompt responses with more context derived from relevant documents. Techniques like [query caching](https://brain.d.foundation/Engineering/AI/LLM+query+caching) further leverage the Vector Database's capabilities, accelerating the performance of our LLM applications at a lower computation cost. These advancements are not only streamlining our workflows but also enriching the outcomes, promising exciting developments as we move further into the integration of Vector Database.\n\n### React Server Component\n***Assess***\n\nAs we evaluate **[React Server Components](https://radar.d.foundation/React-Server-Component-68a4a526527f44c0997b084e96b99e47)**, their flexibility stands out. Diverging from the traditional client-side rendering approach of Single-Page Applications, RSCs allow us to decide where to render components based on their purpose. By deconstructing the page into smaller components, it becomes clear that many non-interactive elements can be rendered on the server as Server Components. This approach not only improves performance and reduces the bundle size but also enhances the initial page loading time, a crucial factor in user experience. As we progress, our focus is on harnessing the potential of RSCs to build fast, efficient, and user-friendly web applications.\n\n### Zod\n***Trial***\n\n**[Zod](https://radar.d.foundation/Zod-f166f3a065f949f58b5936b34236ca3c)** is a robust, TypeScript-first schema declaration and validation library. Its primary strength lies in the elimination of duplicative type declarations, as Zod allows developers to declare a validator once, from which it automatically infers the static TypeScript type. It also offers a concise, chainable interface, and functional approach emphasizing parsing over validation. Despite its high functionality, Zod is remarkably compact with zero dependencies and compatibility across Node.js and modern browsers. Its immutable nature ensures that methods like `**.optional()**` return a new instance, and it's equally capable with plain JavaScript. With its notable advantages, we're exploring Zod as a potential replacement for [Yup](https://radar.d.foundation/Yup-9045f94c344c4c1e9b4b941cd43fb50d), seeking to incorporate this developer-friendly tool into our workflows.\n\n## Brainery\n### Growth and Direction\nAs we proceed in our journey of knowledge and skill enhancement, our Brainery continues to bloom with exciting ideas and valuable insights. Our contributors have exhibited an increased proficiency in delivering concise writings, covering work delivery, practical concepts, and foundational knowledge.\n\nThis month, we are thrilled to highlight our concentrated exploration of knowledge from our ongoing projects, notably our Quant Trading project - Nghenhan. This project-oriented focus has empowered our contributors to delve into practical applications and contribute from their hands-on experiences.\n\n### Trending Tags\nThe trending tags of this month offer a fascinating snapshot of our contributors' current research interests and thought processes. It's been particularly interesting to see the ongoing focus on LLM as we continue to bring it into production, with various insightful notes shedding light on its inner workings.\n\nIn parallel with the AI-centric discussions, we have also seen increased exploration into frontend techniques, including scroll animations and novel patterns for working with React and GraphQL. These discussions underline our commitment to staying at the forefront of tech innovations while deepening our understanding of core concepts.\n\nThe tags for June include: `#nghenhan #` `llm` `#ai` `#caching` `binance` `q-learning` and more.\n\n### Top Contributors and Notes\nOur community continues to thrive due to the collective effort of our talented contributors. Each month, we acknowledge their contributions in our Brainery's **[Latest Notes](https://brain.d.foundation/Latest+Notes)** section, linking their GitHub accounts for further reference.\n\n![](assets/2023-june-forward-engineering_forward-engineering-june-2023_2fbe2f31190fe0c73606912485107f88_md5.webp)\n\nWe also value and encourage our community's interaction on our **[Discord](https://discord.gg/dwarvesv)** server. It's a great space to stay updated, engage in lively discussions, and catch up on the latest from us. Be sure to join us there!\n\nHere are some noteworthy articles that were shared in our Brainery during June:\n\n* [LLM's Accuracy - Self Refinement](https://brain.d.foundation/Engineering/AI/LLM%27s+Accuracy+-+Self+Refinement) by [thanh](https://github.com/zlatanpham)\n* [Q Learning](https://brain.d.foundation/Engineering/AI/Q+Learning) by [ngocthanh](https://github.com/thanhpn)\n* [Deploy Branch with Vercel CLI](https://brain.d.foundation/Engineering/DevOps/Deploy+Branch+with+Vercel+CLI) by [chinhld12](https://github.com/chinhld12)\n* [Foundation model](https://brain.d.foundation/Engineering/AI/Foundation+model) by [thanh](https://github.com/zlatanpham)\n* [LLM query caching](https://brain.d.foundation/Engineering/AI/LLM+query+caching) by [thanh](https://github.com/zlatanpham)\n* [Render optimization in data-fetching libraries](https://brain.d.foundation/Engineering/Frontend/Render+optimization+in+data-fetching+libraries) by [antran](https://github.com/tienan92it)\n* [Reinforcement Learning](https://brain.d.foundation/AI%2FReinforcement%20Learning) by [ngocthanh](https://github.com/thanhpn)\n* [A Fragment Colocation Pattern with React & Apollo GraphQL](https://brain.d.foundation/Frontend%2FA%20Fragment%20Colocation%20Pattern%20with%20React%20%26%20Apollo%20GraphQL) by [lapnn](https://github.com/ngolapnguyen)\n* [Scroll-driven animations](https://brain.d.foundation/Frontend%2FScroll-driven%20animations) by [khacvy](https://github.com/trankhacvy)\n* [Applying Mock Service Worker (MSW) for Seamless Web Development](https://brain.d.foundation/Engineering/Frontend/Applying+Mock+Service+Worker+(MSW)+for+Seamless+Web+Development) by [hthai2201](https://github.com/hthai2201)\n* [Vim REPL Driven Development](https://brain.d.foundation/Engineering/Vim+REPL+Driven+Development) by [Thanh Nguyen](https://github.com/thanhnguyen2187)\n* [Utilizing Cached Table for Binance Kline API Data Processing](https://brain.d.foundation/Backend%2FUtilizing%20Cached%20Table%20for%20Binance%20Kline%20API%20Data%20Processing) by [minhth](https://github.com/thminhVN)\n* [Update highest and lowest symbol prices in real time](https://brain.d.foundation/Backend%2FUpdate%20highest%20and%20lowest%20symbol%20prices%20in%20real%20time) by [minhth](https://github.com/thminhVN)\n* [How Discord Stores Messages Part 1 - From MongoDB To Cassandra](https://brain.d.foundation/Engineering%2FHow%20Discord%20Stores%20Messages%20%20Part%201%20-%20From%20MongoDB%20To%20Cassandra) by [fuatto](https://github.com/fuatto)\n* [Redis Rate Limiter](https://brain.d.foundation/Backend%2FRedis%20Rate%20Limiter) by [@minhtuan](https://github.com/Tuanpm31)\n\n## R&D Topics and Challenges\nInnovation remains at the forefront of our operations at R&D. Our focus for June has been redefined with a continued interest in the fintech landscape and the introduction of new pivotal themes such as Go compiler optimization and reinforcement learning.\n\n### Research Topics\n* **Payment System**: This month, our exploration in the fintech domain continues as we delve into common design patterns like the command pattern and thread-safe scale. We are also investigating the double-entry ledger system, a time-tested method in accounting that can potentially add robustness to our payment system design. The objective remains to create a solution that is secure, scalable, user-friendly, and adaptable to evolving financial technologies.\n* **LLM's Accuracy**: As part of our commitment to advance AI technologies, we're venturing into testing techniques like Reinforcement Learning from Human Feedback (RLHF). Our exploration focuses on enhancing the accuracy of Language Models, especially Large Language Models (LLMs). This field promises a broad range of applications, from personalized recommendations to sophisticated natural language processing.\n* **Go Compiler Optimization**: Our new topic for the month revolves around Go language compiler optimizations. We aim to deeply understand how Go source code gets transformed into efficient machine code, exploring techniques to maximize the execution speed and efficiency of our Go applications.\n\n### Future Challenges\nIn addition to our focused research areas, we're also keeping an eye on several emerging topics that may pose challenges or opportunities in the near future. These include:\n\n* Deep Q-Learning\n* Time series database\n* Adversarial prompt engineering\n* Self-hosted LLMs\n* Live Chat implementation\n\nAs we continue our research and development journey, we strive to stay ahead of technological advances, providing innovative solutions that drive our projects and the wider software industry.\n\n## Research Narratives\n### Software Design Research Group\nThis month, our Software Design Research Group has continued to explore pressing topics for SMEs, with a particular interest in microservices architecture and back-of-the-envelope calculations.\n\nKey discussions this month included:\n\n* **Microservice Architecture Design Patterns** - We examined various patterns in the microservice architecture domain. Our focus was on their uses, benefits, and challenges, equipping us to better implement this increasingly popular software development approach.\n* **Back-of-the-Envelope Calculations** - We delved into how these rough calculations can validate design decisions, guide resource management, and even influence business decisions. Our discussions shed light on the value of approximations in dealing with software design complexities.\n\nThese insights continue to broaden our understanding of both traditional and emerging software design concepts, equipping us to better tackle real-world challenges.\n\n## Dwarves Rewind June 2023\n[Dwarves Rewind](https://www.linkedin.com/newsletters/dwarves-rewind-6963734647327375360/) is a reading list serving as a collection of news we aggregate weekly. Tech is a very high-paced industry, and rewind helps to serve as a curated list of trending and high-profile topics that everyone can look back on.\n\n![](assets/2023-june-forward-engineering_forward-engineering-june-2023_7d72b4327ffbaf2595178ba126a3d16a_md5.webp)\n\n### Trending and Hot Topics\nThis month covers a recap of the Apple WWDC Event, a visual low-code backend builder, and a technical deep dive into a simplified version of React Server Components. It also discusses design trends and technology revolution insights from Config 2023 - Figma's Annual Conference and WWDC 2023. Updates include new scene types in Swift UI and features in Visual Studio 2022 version 17.7. There have also been some hot annual events this month, with some of the trending topics this month being:\n\n* We're sure the rumors have been spread all over the Internet. So as stated in the thumbnail, this week [#DwarvesRewind](https://www.linkedin.com/feed/hashtag/dwarvesrewind) comes with a short recap of the Apple WWDC Event, a visual low-code backend builder, and technical deep dive for a very simplified version of React Server Components.\n* It's packed with big ideas about how we should interact with the design trends, and the technology revolution after Config 2023 - Figma’s Annual Conference, WWDC 2023. Discover new scene types in Swift UI and what's new in the release of Visual Studio 2022 version 17.7.\n","title":"Forward Engineering June 2023","short_title":"June 2023","description":"As we usher in the month of June, we embrace the ever-changing landscape of technological innovation, and focus on a central theme:LLM in Production.","tags":["engineering","updates","performance","forward-engineering"],"pinned":false,"draft":false,"hiring":false,"authors":["thanh","monotykamary","innno_"],"date":"Fri Jun 30 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/forward-engineering/2023-june.md","slugArray":["updates","forward-engineering","2023-june"]},{"content":"\nAt the intersection of technology and innovation, our engineering team at Dwarves Foundation has been driving change and pushing boundaries. As we continue to navigate the rapidly evolving landscape of software development, we remain steadfast in our commitment to seeking out the latest technologies and practices to deliver exceptional results.\n\nWith our eyes fixed firmly on the future, we've cultivated an engineering culture that values continuous learning and collaboration. Through initiatives like our Tech Radar, Brainery, and R&D challenges, we've created opportunities for our team to learn, grow, and share their knowledge with the wider community.\n\nAs we look back on the past month, we're excited to share our latest engineering report, which highlights our recent achievements, projects, and insights.\n\n## Tech Radar\nMarch marks a shift in our engineering focus, with an emphasis on \"**Scaling up Delivery Performance**\" as the driving force behind enhancing our software delivery pipeline. This strategic approach is aimed at expanding our team's capacity to deliver more features and services, without compromising on quality or stability. To achieve this goal, we are adopting techniques such as blue-green deployment and monorepo. However, to truly unlock the power of these techniques, it is crucial that we cultivate a shared understanding of their benefits and best practices across the organization. By instilling a culture of scalability in our engineering team, we not only accelerate our ability to meet the evolving needs of our business but also foster a stronger commitment to delivering value to our end-users through continuous innovation and improvement.\n\n### Blue-green deployment\n***Trial***\n\nWe recently implemented [blue-green deployment](https://hashnode.com/edit/clfuzxx9z000d0amk95je906q) for the Mochi Bot application, which offers numerous benefits, including zero-downtime deployments and faster, more frequent releases. With two identical environments, only one is live at a time, allowing new versions of the application to be deployed without any disruption to users. This not only improves user experience but also reduces the risk of downtime-related issues.\n\nOur experience with blue-green deployment has been positive, but there are ongoing research efforts to optimize its configuration for microservices and integrate API testing into the process. Despite this, we believe that the benefits of this deployment strategy, including its cost-effectiveness and practicality, make it a valuable addition to our current infrastructure.\n\n### Monorepo\n***Adopt***\n\nUsing a [monorepo](https://radar.d.foundation/Monorepo-6a57c7c8c7d34d4d8572cd8c2d88fcd6) approach can bring many benefits to teams looking to manage code for multiple projects or modules in a more efficient and streamlined way. This includes managing shared libraries, frameworks, and components across projects, as well as deploying applications more consistently and quickly. Recently, our team in Nghe Nhan faced [challenges](https://dwarvesf.hashnode.dev/from-multi-repo-to-monorepo-a-case-study-with-nghenhan-turbo-monorepo) with managing dependencies and deploying updates across multiple repositories as the project expanded. Coordinating changes between components and maintaining consistency across codebases became increasingly difficult as our engineering team grew. To address these challenges, we decided to migrate to a monorepo structure using [Turborepo](https://radar.d.foundation/Turborepo-0dd18b38468c4859a8beaae7bf6c511c). This decision was prompted by our previous successful experience with monorepo, but to further facilitate adoption and standardize the approach, we also have been working on a template to help our team speed up the process.\n\n### ChatGPT assistance\n***Trial***\n\nThe software development community has engaged in a conversation regarding the potential risks associated with ChatGPT.\n\nDespite the concerns raised, ChatGPT remains a valuable tool for developers seeking to streamline their workflow and increase efficiency. With its capacity to generate code snippets, offer responses to queries, and swiftly create documents, ChatGPT has the potential to enhance productivity. Nonetheless, it is crucial to bear in mind that the accuracy of its responses may not always be 100%, and extensive research may be necessary before utilizing it for more complex tasks.\n\nDespite the possible challenges associated with ChatGPT, some members of our team have begun integrating it into their workflow, such as within VSCode or Raycast.\n\n### Micro-Frontend\n***Assess***\n\nThe concept of [micro frontend](https://radar.d.foundation/Micro-Frontend-81e78d9765eb4b83b6e47639d81dc151) has been the subject of ongoing debates regarding its potential benefits for software development. At our team, we acknowledge that every technology comes with trade-offs. Despite the decrease in discussions about micro frontends, we have observed its continued adoption through our work with clients. For instance, in [a recent case study](https://hashnode.com/edit/clfv0twho000909jw1lyuegjj), we investigated the implementation of Micro-Frontend architecture on an e-commerce platform, analyzing its impact on the system's performance and its ability to streamline the integration of new applications. We found that vertically splitting the apps by sub-domains was an effective approach for the client's specific use case, and their adoption of this approach continues to be successful. Moving forward, our team will incorporate the insights and experiences gained from working with clients on micro frontend solutions to evaluate and integrate them into our practices.\n\n### Delivery metrics\n***Assess***\n\nMeasuring software delivery performance is crucial in the world of software development. One way to gauge team effectiveness is by tracking the number of story points completed and the time it takes to finish them. It is surprising how much project status can be inferred from these numbers, prompting us to ask critical questions and celebrate successes. Our team has also found value in utilizing [DORA metrics](https://radar.d.foundation/DORA-metrics-6b555bcdb782480e80504ff122d6f4c7), which provide further insight and facilitate the development of new practices to enhance productivity.\n\nIt is essential to remember the ultimate intention behind any metric and use them as tools for reflection and learning. Keeping this in mind will help teams stay on track and continuously improve their software delivery performance.\n\n## Brainery\n### Growth and Direction\nWe have been shifting our focus towards **Meaning, Mastery, and Autonomy**, (MMA). We are aiming to create a culture where our everyone can find purpose and fulfillment in their work, where they can develop their skills and talents, and where they have the freedom and responsibility to make decisions.\n\nThis has reflected in our Brainery, where we see much more concise writing from our contributors on areas for work delivery, high-level system concepts, and foundational knowledge.\n\n### Trending Tags\nA summary of some trending tags we see in our Brainery. These tags represent what things our contributors are actively thinking about and researching. For this month, we still see a strong focus on frontend, but we also see trending tags related to backend and DevOps with more focus on foundational topics such as API, state management, and algorithms.\n\n![](assets/2023-march-forward-engineering_forward-engineering-march-2023_6e1ba482fa7dd25d9da74f9114333197_md5.webp)\n\n### Top Contributors and Notes\nEvery month, we collect a list of top contributors, those who have contributed knowledge to our Brainery for this month. We consolidate our writer’s articles with their GitHub account at our Brainery’s [Latest Notes](https://brain.d.foundation/Latest+Notes).\n\nWe also make sure to give recognition on our [Discord](discord.gg/dwarvesv) server, so be sure to catch up with us there!\n\n![](assets/2023-march-forward-engineering_forward-engineering-march-2023_b3fb572286808f5d94e7fea27d48c68e_md5.webp)\n\n* [leduyhien152](https://github.com/leduyhien152) - [When should we use useReducer instead of useState?](https://brain.d.foundation/Engineering/Frontend/When+should+we+use+useReducer+instead+of+useState%3F)\n* [mirageruler](https://github.com/mirageruler) - [GraphQL in microservices - Unified API gateway](https://brain.d.foundation/Engineering/Backend/GraphQL+in+microservices+-+Unified+API+gateway)\n* [ngolapnguyen](https://github.com/ngolapnguyen) - [Variable Fonts](https://brain.d.foundation/Engineering/Frontend/Variable+Fonts)\n* [nguyend-nam](https://github.com/nguyend-nam) - [Testing AWS services locally with LocalStack](https://brain.d.foundation/Engineering/DevOps/Testing+AWS+services+locally+with+LocalStack)\n* [thangnt294](https://github.com/thangnt294) - [Profiling in Go](https://brain.d.foundation/Engineering/Profiling+in+Go)\n* [trankhacvy](https://github.com/trankhacvy) - [Metaplex NFT Compression](https://brain.d.foundation/Blockchain/Metaplex+NFT+Compression)\n* [zlatanpham](https://github.com/zlatanpham) - [Tackling Server State complexity in Frontend Development](https://brain.d.foundation/Engineering/Frontend/Tackling+Server+State+complexity+in+Frontend+Development)\n\n## R&D Topics and Challenges\nResearch and Development (R&D) came about as a collective department for solving common problems we faced across all of our projects. As an innovative software firm, we found that the foundations surrounding innovative software were also vital to realizing their prospects.\n\nBelow are some of the common problems we’ve begun more critical research and exploration on:\n\n### Common problems\n* **Multi-tenancy**: With the need for personalized development for each customer of software as a service services, the system design and application architecture need to be designed intelligently to optimize costs as well as efficiency. results, data security. The real multi-tenancy problem is encountered a lot and depending on the system, it will be implemented in different ways. We will offer total solutions to help customers have the best cost and efficiency.\n* **Distributed Concurrency over a single database**: Concurrency control is a crucial aspect of developing applications that can handle multiple user requests simultaneously. It is not uncommon for multiple users to access the same data at the same time in SQL, such that it requires concurrency control techniques over the whole application.\n* **zkEVM layer 2**: The overall design of zkEVM layer 2 blockchain follows the State Machine model and thus emulates the Ethereum Virtual Machine (EVM) and **high performance and scalability**, with the aim of providing the same user experience as in Ethereum. In addition to enabling ERC20 token payments and transfers, users can now run Ethereum smart contracts on it.\n\nThis year, we’ve completed two of our challenges, **Query Database 500M Records** and **Locale on Web and Mobile**. This was a concern spanning across our DevOps, Management, and Engineering domains. We’re proud to list it as our completed challenges:\n\n### Completed challenges\nQuery Database 500M Records, Filter Multiple Table: Querying larger datasets invites performance issues and complexity. Our research elaborates techniques for optimizing queries through caching strategies and approaches in cluster architecture.\n\n* **Locale on Web and Mobile:** Locale is a rather subtle issue that encompasses many aspects required for a multilingual application. Our research expands on database designs for multilingual apps, approaches to continuous translation, and a frontend guideline for internationalization (i18n).\n* **Solutions and articles:**\n  * [https://dwarvesf.hashnode.dev/optimizing-queries-for-big-database](https://dwarvesf.hashnode.dev/optimizing-queries-for-big-database)\n  * [https://medium.com/dwarves-foundation/optimize-query-for-big-database-c7b6952326af](https://medium.com/dwarves-foundation/optimize-query-for-big-database-c7b6952326af)\n* **Solutions and articles:**\n  * [https://dwarvesf.hashnode.dev/i18n-frontend-guideline](https://dwarvesf.hashnode.dev/i18n-frontend-guideline)\n  * [https://dwarvesf.hashnode.dev/continuous-translation](https://dwarvesf.hashnode.dev/continuous-translation)\n  * [https://dwarvesf.hashnode.dev/database-designs-for-multilingual-apps](https://dwarvesf.hashnode.dev/database-designs-for-multilingual-apps)\n\n### Keywords for upcoming challenges\nHere are some of the keywords we’re on the watch for where we haven’t specified a problem statement but we expect will manifest challenges in the near future.\n\n* Rollups\n* Staking\n* Ethereum Adoption\n* Access control management\n* Security design and DevSecOps\n* AI augmentation\n\n## Research Narratives\n### Software Design Research Group</span>\nWe’ve held our Software Design research group for just over a year. This month we have shifted our focus to more on topics and concerns for small and medium enterprises, most commonly concerning security, access control, and database models and mechanisms. This includes, but is not limited to:\n\n* **Hierarchical Database Model** - Investigates database modeling for hierarchical data types, such as an employee organization tree, and what approaches are most suited as a balance between correctness, performance, and ease of upgradability.\n* **Explicit Locking In SQL DBMS** - An approach on using explicit locks as a concurrency mechanism to handle application control flow with SQL databases.\n* **HashiCorp Vault** - A presentation on what HashiCorp Vault is, why we need it, and a demo session on how to make a basic secret resource to be augmented and consumed in the Vault agent injector on Kubernetes.\n* **Role-based Access Control (RBAC)** - A battle-proven approach to restricting system access to authorized users. A presentation and discussion on what it is, how it can be modeled, and what use-cases that often arise that demands the need for access systems such as RBAC.\n\n## Dwarves Rewind March 2023\n[Dwarves Rewind](https://www.linkedin.com/newsletters/dwarves-rewind-6963734647327375360/) is a reading list serving as a collection of news we aggregate weekly. Tech is a very high-paced industry, and rewind helps to serve as a curated list of trending and high-profile topics that everyone can look back on.\n\n![](assets/2023-march-forward-engineering_forward-engineering-march-2023_a466f7386392e5af7d8836ff803f1472_md5.webp)\n\n### Trending and Hot Topics\nArtificial intelligence is still a very trending and hot topic, especially with the advent of GPT-4 and Microsoft’s aggression on integrating AI tech. Some of the trending topics this month are:\n\n* How GPT-4 can generate realistic and engaging content for various domains and purposes, such as marketing, education, entertainment and more.\n* How Microsoft is leveraging AI to enhance its products and services, such as Bing, Office 365, Azure and Windows 11.\n* How OpenAI has launched new APIs and plugins to augment ChatGPT to other levels of productivity.\n\nOf course, there are still more notable updates on the front for frontend development, with the introduction of Next.js 13.2, as well as blockchain solutions for transaction scalability.\n\n### Thoughts List\nOn most of our Dwarves Rewind, we list our thoughts and burning questions each week. Here are some of our most recent ones:\n\n**#27:** We are not sure what Google is going on about since they literally shut down their rival gaming service to xCloud. But Nvidia is different because you use their cloud streaming service to stream games that you actually own from other PC platforms, what we can see can why Nvidia may not actually oppose the deal.\n\n**#28:** Everyone is using ChatGPT. Since its launch, more than 100 million people have signed up for the app and set a record for the fastest-growing user base. As for whether chatbot will kill a job in the future, the way AI is implemented and how society adapts to its integration will ultimately determine its net impact on employment.\n\n**#29:** If tech companies won't make as much money from selling links via search results, will they try to sell information gleaned from our interactions with search chatbots? But we all know it is an important space to keep an eye on to see how marketers can leverage it for their brands and how they utilize these features to better connect with their customers and users.\n\n**#30:** zkEVMs is a scaling solution that allows blockchain networks to process transactions on Layer 2. The launch of the zero-knowledge Ethereum Virtual Machine beta mainet is viewed by many as a significant turning point, as it will bring huge improvements to cryptography and blockchains.\n\n**#31:** Artificial intelligence is going mainstream. We want to hear from you about what's getting your attention in the field, so share your thoughts in the comments below and let us know which AI topic has piqued your interest the most.\n\n**#32:** The release of Next.js 13.2 has brought some changes to the way Route Handlers work. While it's positive that Route Handlers no longer need if statements for each method type, some users find the new app directory structure somewhat inconvenient. The mixing of the API folder with other items in the app directory can make it challenging to find a specific route.\n","title":"Forward Engineering March 2023","short_title":"March 2023","description":"As we look back on the past month, we're excited to share our latest engineering report, which highlights our recent achievements, projects, and insight in March 2023.","tags":["engineering","performance","updates","forward-engineering"],"pinned":false,"draft":false,"hiring":false,"authors":["thanh","monotykamary","innno_"],"date":"Mon Apr 03 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/forward-engineering/2023-march.md","slugArray":["updates","forward-engineering","2023-march"]},{"content":"\nThe technological landscape is vast, brimming with opportunities for exploration and growth. As we stand on the brink of May, we pause to reflect on our journey thus far and chart our course forward. In this month's report, we bring you the fruit of our endeavors and the promise of our vision.\n\n## Tech Radar\nAs we advance into a new phase, our engineering team is setting its sights on a new strategic focus - \"Exploring Large Language Models (LLM)\". This shift, at the heart of our product development and business intelligence initiatives, aims to enhance our ability to work with AI-driven language models, allowing us to offer improved user interactions, more personalized product suggestions, and better business understanding. In tandem with this, we are implementing a robust automation framework leveraging Codecept and Playwright, to automate tasks, refine workflows, and maintain high-quality standards. \n\nConcurrently, we're assessing the potential of Radix UI to help us develop highly intuitive, accessible user interfaces. While these advancements in automation and UI development play a vital role, our primary emphasis remains on the exploration of LLMs, a venture we believe will bolster our position at the cutting edge of technological innovation. Our May journey embodies our commitment to continual learning, delivering exceptional value to our users, and meeting our business needs with agility and innovation.\n\n### Large Language Models\n***Assess***\n\nIn our exploration of [large language models](https://radar.d.foundation/Large-language-model-LLM-60d7f1372aef4e60ae12894bdbafa473) (LLMs), such as GPT-3/GPT-4/ChatGPT, Poe, and Claude, we recognize the vast potential these models hold. As we continue to refine our interactions with these models, we aim to harness their capabilities to generate accurate outputs. While we have delved into model fine-tuning, the current costs prevent us from achieving the desired results. However, we remain optimistic about future developments and maintain our focus on utilizing foundation models rather than training our own, considering the high infrastructure costs and the need for quality data. We remain committed to identifying and capitalizing on opportunities to develop useful software applications built upon the power of LLMs, dedicating our energy to learning and expanding our expertise in this promising domain.\n\n### LangChain\n***Assess***\n\nWe have recently begun exploring the [LangChain](https://radar.d.foundation/LangChain-181262b7994c4b108ecf559411dc988e) framework in our AI application development workflow. Designed specifically for building applications that leverage large language models (LLMs), LangChain offers a suite of features like prompt management, chaining, data augmented generation, and agent systems for action sequencing, which collectively streamline the AI development process. As we integrate LangChain into our workflow, we have observed its potential for improving the management and utilization of LLMs, enhancing our interaction with language models, improving the generation of contextually relevant responses, and providing better control over AI behavior. This addition has broadened the spectrum of AI applications we can build, encompassing everything from customer service chatbots and content generators to advanced data analysis systems. However, we are still in the assessment phase, incorporating LangChain into smaller, non-critical projects to fully understand its capabilities and limitations.\n\n### Prompt engineering\n***Assess***\n\n[Prompt engineering](https://radar.d.foundation/Prompt-engineering-9739ebfed76f4cff901cb46155d0bf23) is an innovative field within generative AI, aimed at enhancing the outputs of large language models like ChatGPT. We strive to make AI responses more human-like and contextually precise by crafting meticulous prompts. Using prompt engineering, we can improve AI chatbots' effectiveness across various applications and customize AI behavior to meet specific industry needs. It also serves as a tool to test AI limits and contribute to its continuous improvement. Our adoption strategy involves educating our teams about prompt engineering, fostering an environment that supports learning, and gradually integrating it into our AI systems to learn and adapt based on the results.\n\n### Codecept\n***Assess***\n\nRecently, we have assessed [Codecept](https://radar.d.foundation/Codecept-a64f02c731ff4be59a914f1e4ab6de1d) as a powerful testing framework for efficient and effective end-to-end (e2e) testing. With Codecept, we can automate testing and easily manage and debug complex scenarios. Some key advantages include multi-tasking capabilities, simplicity in test writing, support for multiple test frameworks, lightweight modular structure built on CodeIgniter, and detailed reports and logs for effective debugging. With Codecept, we are able to conduct functional testing, acceptance testing, API testing, cross-browser testing, and benefit from comprehensive test reporting. As we adopt Codecept, we see it as the monorepo for Automation Testing, suitable for all projects due to its support for various testing frameworks like WebDriverIO, Playwright, and Cypress. By building an automation framework based on Codecept, we are already implementing it in several internal projects, providing a solution to the challenges of creating project-specific frameworks.\n\n### Radix UI\n***Trial***\n\nIn our continuous pursuit of effective and accessible UI development, we have adopted [Radix UI](https://radar.d.foundation/Radix-UI-13e49d353df1486ca02fbacfd1765f14), a modular and highly customizable library of pre-built components. Its compatibility with other libraries, such as TailwindCSS, enhances our ability to maintain consistent styling across our applications. The library's modular design allows us to construct unique, highly flexible UIs by combining and customizing small, focused primitives. By integrating Radix UI into our workflows, we are able to efficiently develop responsive and accessible user interfaces without the need to design components from scratch. Our adoption of Radix UI was driven by our commitment to enhance accessibility, replacing [HeadlessUI](https://radar.d.foundation/Headless-UI-53cb40046020450594f46a4cb030ef2e), which presented significant accessibility challenges. We have successfully implemented this migration in our [NextJS boilerplate](https://github.com/dwarvesf/nextjs-boilerplate/pull/23), and we're excited about the new possibilities that Radix UI unlocks for us.\n\n## Brainery\n### Growth and Direction\nWe have been shifting our focus towards **Meaning, Mastery, and Autonomy**, (MMA). We are aiming to create a culture where our everyone can find purpose and fulfillment in their work, where they can develop their skills and talents, and where they have the freedom and responsibility to make decisions.\n\nThis has reflected in our Brainery, where we see much more concise writing from our contributors on areas for work delivery, high-level system concepts, and foundational knowledge.\n\n### Trending Tags\nA summary of some trending tags we see in our Brainery. These tags represent what things our contributors are actively thinking about and researching. For this month, we see a stronger focus on LLM and AI topics, but we also see trending tags related to backend and frontend with more focus on foundational topics such as web-design, OOP, SOLID, etc.\n\n![](assets/2023-may-forward-engineering_forward-engineering-may-2023_286f7e7f87cc09dee3370332640b937d_md5.webp)\n\n### Top Contributors and Notes\nEvery month, we collect a list of top contributors, those who have contributed knowledge to our Brainery for this month. We consolidate our writer’s articles with their GitHub account at our Brainery’s [Latest Notes](https://brain.d.foundation/Latest+Notes).\n\nWe also make sure to give recognition on our [Discord](discord.gg/dwarvesv) server, so be sure to catch up with us there!\n\n![](assets/2023-may-forward-engineering_forward-engineering-may-2023_540e3597ede09140b3b405d8c88eb206_md5.webp)\n\n* [monotykamary](https://github.com/monotykamary) - [Working with langchain document loaders](https://brain.d.foundation/Engineering/AI/Working+with+langchain+document+loaders)\n* [monotykamary](https://github.com/monotykamary) - [Workaround with OpenAI's token limit with Langchain](https://brain.d.foundation/Engineering/AI/Workaround+with+OpenAI%27s+token+limit+with+Langchain)\n* [nguyend-nam](https://github.com/nguyend-nam) - [SOLID principles](https://brain.d.foundation/Engineering/SOLID+principles)\n* [nguyend-nam](https://github.com/nguyend-nam) - [Retain scroll position in infinite scroll](https://brain.d.foundation/Engineering/Frontend/Retain+scroll+position+in+infinite+scroll)\n* [R-Jim](https://github.com/R-Jim) - [Redis streaming](https://brain.d.foundation/Engineering/Redis+streaming)\n* [vhbien000](https://github.com/vhbien000) - [Database Locking](https://brain.d.foundation/Engineering/Backend/Database+Locking)\n\n## R&D Topics and Challenges\nResearch and Development (R&D) came about as a collective department for solving common problems we faced across all of our projects. As an innovative software firm, we found that the foundations surrounding innovative software were also vital to realizing their prospects.\n\nBelow are some of the common problems we’ve begun more critical research and exploration on:\n\n### Common problems\n* **Payment system**: Navigating the evolving fintech landscape, our task is to design an innovative payment system that is secure, scalable, and user-friendly. It should facilitate diverse transactions across various platforms and regions, integrating with existing financial infrastructures while remaining flexible to emerging technologies such as cryptocurrencies and AI analytics. The system must robustly manage cybersecurity risks and regulatory compliance. The system's success will hinge on its reliability, usability, scalability, security, and ability to drive customer satisfaction in a competitive fintech market.\n* **Recommender system**: Our research focuses on the pivotal role vector databases play in recommender systems, facilitating efficient searches by representing items as vectors. This feature amplifies AI systems' capability to provide personalized recommendations. Our goal is to discover strategies to optimize these databases, enhancing user experiences across digital platforms like social networks, streaming services, and e-commerce sites. Our success hinges on contributing valuable insights and innovations in this key area of AI recommender systems.\n\n### Completed challenges\n**Distributed Concurrency over a single database:** \n\nConcurrency control is a crucial aspect of developing applications that can handle multiple user requests simultaneously. It is not uncommon for multiple users to access the same data at the same time in SQL, such that it requires concurrency control techniques over the whole application. Our team has completed this challenge and is currently wrapping up write-ups on the topics.\n\n**Solutions and articles:**\n\n* [https://dwarvesf.hashnode.dev/managing-dataflow-and-sql-database-with-concurrency-control](https://dwarvesf.hashnode.dev/managing-dataflow-and-sql-database-with-concurrency-control)\n* [https://dwarvesf.hashnode.dev/lessons-learned-from-concurrency-practices-in-blockchain-projects](https://dwarvesf.hashnode.dev/lessons-learned-from-concurrency-practices-in-blockchain-projects)\n\n### Keywords for upcoming challenges\nHere are some of the keywords we’re on the watch for where we haven’t specified a problem statement but we expect will manifest challenges in the near future.\n\n* Access control management\n* Security design and DevSecOps\n* AI augmentation\n* Prompt Engineering\n* Design Payment System\n* Vector Database\n\n## Research Narratives\n### Software Design Research Group\nWe’ve held our Software Design research group for just over a year. This month we are continuing our focus to more on topics and concerns for small and medium enterprises, most commonly concerning security, access control, and database models and mechanisms. We have also begun to investigate more frontend and AI topics. This includes, but is not limited to:\n\n* **Explicit Locking In SQL DBMS** - An approach on using explicit locks as a concurrency mechanism to handle application control flow with SQL databases.\n* **Role-based Access Control (RBAC)** - A battle-proven approach to restricting system access to authorized users. A presentation and discussion on what it is, how it can be modeled, and what use-cases that often arise that demands the need for access systems such as RBAC.\n* **Load balancer** - A load balancer involves hardware and software that distributes network traffic across multiple servers to ensure that no single server is overwhelmed with traffic. This helps to improve the performance and reliability of applications, websites, and other network-based services.\n\n## Dwarves Rewind May 2023\n[Dwarves Rewind](https://www.linkedin.com/newsletters/dwarves-rewind-6963734647327375360/) is a reading list serving as a collection of news we aggregate weekly. Tech is a very high-paced industry, and rewind helps to serve as a curated list of trending and high-profile topics that everyone can look back on.\n\n![](assets/2023-may-forward-engineering_forward-engineering-may-2023_2169474a34f559c08a1f41e2a7d188c1_md5.webp)\n\n### Trending and Hot Topics\nArtificial intelligence is still a very trending and hot topic, especially with the advent of GPT-4 and Microsoft’s aggression on integrating AI tech. There has also been some hot annual events this month, with some of the trending topics this month being:\n\n* Andrew Ng & OpenAI Free Prompt Engineering Course: Renowned artificial intelligence (AI) experts, Andrew Ng from [DeepLearning.ai](http://deeplearning.ai/) and Isa Fulford from OpenAI, have teamed up to offer an exciting new course on prompt engineering, titled “ChatGPT Prompt Engineering for Developers“. The course, which is completely free, aims to help developers better understand the prompts design and implementation for various use cases.\n* Visual Studio Code Day 2023: VS Code Day is Microsoft's annual event, where you'll learn how to elevate your development workflow using the latest and most outstanding features of VS Code.\n* Generative Agents: Interactive Simulacra of Human Behavior: LLMs just hit a major milestone with the release of the new \"Generative agents\" paper. By using LLMs, generative agents were able to simulate human-like behavior in an interactive sandbox inspired by The Sims.\n\n### Thoughts List\nOn most of our Dwarves Rewind, we list our thoughts and burning questions each week. Here are some of our most recent ones:\n\n**#33:** For sure, GPT-4 long way to go, things are going to change. In general, when selecting a technology for our frontend tech stack, the foremost question we ask is: \"Has this technology achieved a certain level of stability and maturity?\". They all are associated with the relative ease of development and our ability to stay ahead of the competition. \n\n**#34:** It is now possible to build AI-powered applications without having to spend months or years learning the ins and outs of machine learning. LLMs have some general embedded knowledge, but they mainly operate on the context that you give them via prompting. \n\n**#35:** Node.js is improving at a rapid pace, and software is always evolving. We know that the JS community generally suffers from \"If it hasn't been updated in the last year, it's probably broken and not modern enough\" syndrome, but some software actually ends up being \"finished\" and good enough for the task at hand.\n\n**#36:** As with any new technology, it's not without knots. While we acknowledge that prompting skills will continue to play a role, we expect that the ability of LLMs (Language Model Models) to adjust to \"bad\" prompts will surpass our capacity to effectively instruct them.\n","title":"Forward Engineering May 2023","short_title":"May 2023","description":"As we look back on the past month, we're excited to share our latest engineering report, which highlights our recent achievements, projects, and insights in May 2023.","tags":["engineering","performance","forward-engineering","updates"],"pinned":false,"draft":false,"hiring":false,"authors":["thanh","monotykamary","innno_"],"date":"Mon May 22 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/forward-engineering/2023-may.md","slugArray":["updates","forward-engineering","2023-may"]},{"content":"\n**This month**, we have focused on revamping how we learn, familiarize, and work with tech. We are excited to announce that we have updated our Forward Engineering to better reflect the feedback and insights from our Labs team, Operations Team, and Consulting Team.\n\nThis is to hopefully provide you with a more comprehensive publication that not only keeps you informed about the latest technologies and where they are applied, but also foster collaboration and innovation within our organization. We hope you find this edition of Forward Engineering informative and give you a better idea of what we’re doing. As always, we welcome your feedback and encourage you to share your thoughts on the content.\n\n## Tech Radar\n![](assets/2023-november-forward-engineering_forward-engineering-november-2023_8e1ba07a614cb4250d5cb2d80f208379_md5_compressed.mp4)\n\n### Rust\n***Assess***\n\n|          |                                                                         |\n| -------- | ----------------------------------------------------------------------- |\n| Tags     | `#memory-management` `#systems-language` `#backend` `#embedded-systems` |\n| Domain   | `Embedded Systems` `Networking and DNS` `Security` `Fintech`            |\n| Projects | `...`                                                                |\n\nRust, the programming language, has been on our radar for quite some time, primarily in the context of developing compiler tooling – a niche that sparked only modest interest within our team. However, our perspective shifted significantly after engaging in [a community project](https://github.com/webuild-community/spacebot) aimed at creating a Rust-based game server. This experience opened our eyes to Rust's impressive capabilities. Our developers have come to greatly appreciate the language's speed, safety, and performance.\n\nFurthermore, we've observed that Rust continues to evolve, increasingly supporting a wider array of applications, notably in web development and artificial intelligence. This evolution has motivated us to delve deeper into the language. Our initial steps involve comprehending Rust's concurrency model, which is pivotal for our community project. Simultaneously, we are eager to explore new facets of Rust, expanding our understanding and application of this powerful language.\n\n### Building UI Library Practices\n***Trial***\n\n|          |                                                    |\n| -------- | -------------------------------------------------- |\n| Tags     | `#ui` `#ux` `#best-practices` `#frontend` `#react` |\n| Domain   | `Web3` `Fintech` `Frontend`                        | \n| Projects | `consolelabs/web-foundation` `mochi-web`           |\n\nIn the present fast-moving business world, both startups and established enterprises are tasked with the rapid development and maintenance of multiple web applications. Despite the availability of numerous mature UI libraries, there is a persistent demand for UI solutions tailored to specific organizational needs. Through our extensive client work, we have created several unique UI packages. Recognizing the value of these developments, we are now transitioning towards creating our own [open-source UI library](https://github.com/consolelabs/web-foundation), specifically designed for building our internal applications.\n\nThis move towards an open-source framework, however, presents a distinct set of challenges compared to closed-source development. Essential factors such as comprehensive documentation, efficient release workflows, and modular design for tree-shaking components require careful consideration. Our journey has been rich with lessons learned, which we are eager to transform into best practices for both our team and the wider community.\n\n### DuckDB\n***Trial***\n\n|          |                                                                                                                          | \n| -------- | ------------------------------------------------------------------------------------------------------------------------ |\n| Tags     | `#data` `#data-analysis` `#data-engineering` `#database` `#embedded-database` `#columnar-storage` `#sql` `#data-science` |\n| Domain   | `Data Science` `Embedded Systems` `Business Intelligence` `Machine Learning` `Research`                                  |\n| Projects | `dwarvesf/note.d.foundation` `consolelabs/log.console.so`                                                                |\n\nDuckDB is an in-process database management system designed for analytical query processing. It is easy to install and use, with no separate server software to maintain, and it runs completely embedded within a host process. DuckDB provides extensive support for complex SQL queries, window functions, and transactional guarantees through Multi-Version Concurrency Control (MVCC). It has been on our radar for some time, and we’ve been taking great care to see what use cases we can apply DuckDB on.\n\nDuckDB is fast and has great data analysis capabilities, optimized for aggregations, joins, and complex queries on large datasets. It is free, well-tested, and stable, offering comparable performance to specialized OLAP databases while being easier to deploy.\n\n![](assets/2023-november-forward-engineering_forward-engineering-november-2023_november-forward-engineering-2023-20231130164855761.webp)\n\n### Parallel Processing\n_***Trial***_\n\n|        |                                                           |\n| ------ | --------------------------------------------------------- |\n| Tags   | `#data` `#data-science` `#parallel-execution`             |\n| Domain | `Data Science` `Data Processing` `Fintech` `Ride-sharing` | \n|Projects|`dwarvesf/notion-export-markdown` `dwarvesf/note-algolia-scraper`|\n\nParallel processing is a computing technique that enables multiple streams of calculations or data processing tasks to occur concurrently through numerous central processing units (CPUs) working together. It is commonly used in scenarios where complex tasks and computations need to be performed, and it offers several advantages in various fields, including manufacturing and data processing.\n\nWe’ve also recently demoed the benefits of parallel processing in one of our DuckDB demos, that includes processing in parallel dozens of parquet files over HTTPFS (150mb each) and using a map-reduce style to output a taxi trip visual report in seconds.\n\n![](assets/2023-november-forward-engineering_forward-engineering-november-2023_november-forward-engineering-2023-20231130165019170.webp)\n\n## Labs Roadmap\nIn a recent collaborative discussion between key members of the Labs and Consulting teams, we’ve made decisive strides in pinpointing key topics and potential projects for development. Each topic is paired with specific challenges to ensure we engage deeply with the technology, understanding its practical applications. The focal point for the coming month is WebAssembly (WASM), alongside a range of exciting use-cases we plan to implement and demonstrate.\n\n### Upcoming Research\n#### WebAssembly (WASM)\n_PICs: An Tran_\n\nWASM is a technology that allows running code written in multiple languages on the web at near-native speed. The challenges in using WASM for these applications may include optimizing performance, managing memory efficiently, and ensuring compatibility across different web browsers:\n\n- [Self-host AI model on the browser (e.g. OCR for security cams, private browser chatbot…)]()\n- [Data processing and visual infographics (through DuckDB-WASM)]()\n- [Implement a Rust game through WASM]()\n\n#### Passwordless Authentication\n_PICs: An Tran_\n\nAn Tran has also discussed passwordless authentication, which involves allowing users to access systems without entering traditional passwords. The use-case challenges we hope to include are:\n\n- [Biometrics on the web (through external device connection)]()\n- [QR code based login]()\n- [Magic Links]()\n\n#### Artificial Intelligence (AI)\n_PICs: Tom Nguyen_\n\nThe challenges in this context may involve ensuring the real-time nature of the updates, managing the computational resources required for such updates, and addressing potential privacy and security concerns related to real-time knowledge updates.\n\n- [Realtime memory knowledge updates (RAG updates)]()\n\n#### Multi-Party Computation (MPC)\n_PICs: Huy Nguyen_\n\nHuy Nguyen has discussed applying MPC for authentication in the context of web3 console. MPC allows multiple parties to jointly compute a function over their inputs while keeping those inputs private. The challenges may include ensuring the security and privacy of the computation, managing the communication overhead in multi-party settings, and addressing the complexity of implementing MPC protocols in web applications.\n\n- [Applying MPC for authentication for web3 (Console)]()\n\n####  Building UI Library Practices\n_PICs: Thanh Pham_\n\nThanh Pham has written about Mochi UI, which likely refers to a set of UI design and development practices. The challenges in this context may include ensuring consistency and usability across different devices and screen sizes, addressing accessibility considerations, and managing the complexity of implementing advanced UI interactions.\n\n- [Build mochi-ui]()\n\n## Dwarves Rewind - Discord Community\n![](assets/2023-november-forward-engineering_forward-engineering-november-2023_november-forward-engineering-2023-20231130165200911.webp)\n\nDwarves Rewind this month will be a collection of tech interests we see happening in our Discord community. Along with our labs roadmap, the community have also shown more interest in WASM and optimizing performance for web development use cases. Some of the programming languages, tools and frameworks discussed this month are:\n\n1. **Ziglang**: [https://ziglang.org/documentation/0.11.0/](https://ziglang.org/documentation/0.11.0/) \n   Ziglang is a programming language that aims to combine the simplicity of C with the safety and expressiveness of modern languages like Rust and D. It was designed to be a systems programming language, with a focus on performance and ease of use. Ziglang's syntax is concise and straightforward, making it easier to learn and understand compared to other languages like Rust and D.\n   \n2. **Panda CSS**: [https://panda-css.com/docs/overview/getting-started](https://panda-css.com/docs/overview/getting-started) \n   Panda CSS is a utility CSS library that provides a set of utility classes, patterns, and recipes for building modern and responsive user interfaces in web applications. It is a build-time CSS-in-JS library that combines the productivity of CSS-in-JS with the performance of traditional CSS.\n   \n3. **Plop**: [https://plopjs.com/documentation/#what-is-plop](https://plopjs.com/documentation/#what-is-plop) \n   Plop.js is a code generator designed to save time and help teams build new files with consistency. It provides a powerful and flexible framework for generating code based on user-defined templates and prompts. Plop.js can be used to automate repetitive tasks, streamline workflows, and ensure consistency across a codebase.\n   \n4. **WASM (WebAssembly)**: [https://supabase.com/blog/postgres-wasm](https://supabase.com/blog/postgres-wasm)\n   WebAssembly is a binary instruction format for a stack-based virtual machine, designed for running code in web browsers. It allows developers to write and compile code in various programming languages, such as C++, Rust, and Python, into a format that can be executed in web browsers without the need for a plugin or virtual machine. This technology enables faster and more efficient web applications, as well as the potential for new web-based software paradigms.\n   \n5. **Langchain**: [https://youtu.be/HSZ_uaif57o](https://youtu.be/HSZ_uaif57o) \n   LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It was launched in October 2022 by Harrison Chase as an open-source project. LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis. The framework is written in Python and JavaScript.\n   \n6. **GPT4 Vision**: [https://github.com/abi/screenshot-to-code](https://github.com/abi/screenshot-to-code) \n   GPT-4 Vision (GPT-4V) is a multimodal model that allows users to upload an image as input and engage in a conversation with the model, enabling it to analyze image inputs provided by the user. It is an extension of the GPT-4 language model, which incorporates visual capabilities, allowing it to process documents and images and provide responses to queries related to them.\n   \n7. **Rust**: [https://github.blog/2023-08-30-why-rust-is-the-most-admired-language-among-developers/](https://github.blog/2023-08-30-why-rust-is-the-most-admired-language-among-developers/) \n   Rust is a programming language that focuses on safety, speed, and concurrency. It is designed to prevent memory-related errors, which makes it an attractive choice for systems programming and high-performance applications. Rust's syntax is more complex than Ziglang, but it offers powerful features like ownership and borrowing, which help prevent common programming errors.\n","title":"Forward Engineering November 2023","short_title":"November 2023","description":"We have focused on revamping how we learn, familiarize, and work with tech. We are excited to announce that we have updated our Forward Engineering to better reflect the feedback and insights from our Labs team, Operations Team, and Consulting Team.","tags":["forward-engineering","labs","AI","performance"],"pinned":false,"draft":false,"hiring":false,"authors":["thanh","monotykamary"],"date":"Thu Nov 30 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/forward-engineering/2023-november.md","slugArray":["updates","forward-engineering","2023-november"]},{"content":"\nAs we step into the exciting opportunities of October, we are at a crucial point in the ever-changing world of technology. Our adventure until now has been for the most part very exciting, with a strong focus on 'Full-stack engineering’ Now, we shift our attention to a topic that is prolific and always true: **Open-source**.\n\nOpen-source has always been the foundation for many hobby projects, learning experiences, startups, and enterprises. It has stayed true to the idea for the rights to use, study, change, and distribute the software and its source code to anyone and for any purpose - originally helping to fix bugs and later accelerating state-of-the-art tech and AI.\n\n## Tech Radar\nStep into the latest edition of the Dwarves Foundation Tech Radar Report, where we shed light on the technologies steering our engineering team's growth and success. In this report, we illuminate the technologies shaping our path forward, from evaluating new methodologies to embracing tools that amplify our efficiency.\n\nThis month has been the month of trying out new and existing tech. We’ve been more eager to get more hands-on to better understand how our tech and research can apply to our projects and our everyday lives.\n\n![](assets/2023-october-forward-engineering_forward-engineering-october-2023_october-forward-engineering_compressed.mp4)\n\n### Type-safe Server Client Development\n***Trial***\n\nAddressing type safety in JavaScript applications, we're trialing an automated OpenAPI Spec generation from server code to ensure consistent data types between client and server. This method, documented via Swagger, enhances development efficiency and reduces errors.\n\nWe've implemented a boilerplate for backend and frontend, demonstrated in our [Next.js boilerplate pull request](https://github.com/dwarvesf/nextjs-boilerplate/pull/38), and are integrating type safety into [our developer training programs](https://www.youtube.com/watch?v=OdwQ7upO1AI).\n\nThe next phase involves transitioning our internal tool, Fortress, to a type-safe framework, as outlined in the [\"Migrate Fortress to use Type-safe approach\"](https://earn.d.foundation/Migrate-Fortress-to-use-Type-safe-approach-fb2d4d8551bb44c48be18140026be5fb) proposal. This move is set to enhance application reliability and showcase the benefits of type-safe practices in our operations.\n\n### AI-aided development\n***Trial***\n\nIn the software industry, the exploration of rapidly evolving AI tools for code writing support is becoming increasingly common. This month, during our Frontend Development Course 2023, we saw a lot of promising projects from both our community and our in-house engineers in creating tools like code reviews at a project scale and automation of CV matching, worthy of a small startup. We see a very clear future of what AI can do for us and how it will be integrated within our everyday lives.\n\nTools built from frontend training courses:\n* Code reviewer - [https://github.com/tranduybau/df-final-project](https://github.com/tranduybau/df-final-project)\n* Resume AI - [https://github.com/khoatruong19/df-frontend-final](https://github.com/khoatruong19/df-frontend-final)\n\n### DuckDB\n***Assess***\n\n[DuckDB](https://radar.d.foundation/DuckDB-569aeec23bf34e418daf949228c37d30) is an embedded database management system that is designed for analytical query processing. Despite recent advances to hardware scaling and database software for data lakes and data warehouses, most workloads and use-cases fall within or below 10GB in size. This means analytical workloads can use DuckDB in lieu of a data warehouse to scope reports and analytics, without the hassle between operation and analytics teams. DuckDB may become an invaluable tool, especially as our workloads don’t reach the scale necessary for use of a data warehouse for our needs.\n\n### Devcontainers\n***Trial***\n\n[Devcontainers](https://radar.d.foundation/Devcontainers-eb3d3ded511d4843851f4ceab643e7d9) are a feature of Visual Studio Code that allow developers to use a container as a full-featured development environment. A **devcontainer.json** file in your project tells VS Code how to access (or create) a development container with a well-defined tool and runtime stack. This container can be used to run an application or to separate tools, libraries, or runtimes needed for working with a codebase. Workspace files are mounted from the local file system or copied or cloned into the container. Extensions are installed and run inside the container, where they have full access to the tools, platform, and file system. Developer experience is a growing need in the industry as well as for our use-cases, to bridge the gap to foster full-stack engineers and onboard them as quickly as possible. We’ve implemented this on many of our internal projects, as well as our public GitHub boilerplates:\n* [Frontend Next.js Boilerplate](https://github.com/dwarvesf/nextjs-boilerplate) - Our boilerplate we’ve used throughout the years as well as our main helper for our frontend course of 2023. We’ve updated it to help generate request/response code from OpenAPI and Swagger standards.\n\n## R&D Topics and Challenges\nInnovation continues to drive us forward at R&D. For the month ahead, we're expanding our scope to encompass emerging trends in development productivity, user interface design, and engineering paradigms.\n\n### Research Topics\n* **Elixir** - Our team has been focusing on expanding our expertise on new as well as current tech. Apart from Go, Elixir has been our second go-to programming language that we want to make more generally available for our engineers and community.\n\n* **Rust** - Rust has been the de-facto language for workloads that require raw performance without requiring to understand the nuances of memory management. We’ve used Rust over the years for projects like Web3 and would love to expand our journey for more systems and embedded related programming.\n\n* **WASM** - Web Assembly (WASM) has been on and off in the industry, but has proven to be relatively resilient due to it’s output being very close to machine code, offering high performance with low complexity. WASM has been an emerging technology for serverless use-cases as well as embedded databases on the web.\n\n* **Aspect-Oriented Programming** - AOP is a programming paradigm to help separate cross-cutting concerns by being more modular and introducing behavior without modifying much of the code. This approach we’ve used lightly for feature flagging, but see much more potential use for this programming paradigm.\n\n* **Passwordless** - Passwordless authentication, such as passkeys, have been a growing topic for us and the industry as a whole. The notion that the procedure for logins no longer require a password makes software interactions much quicker and more secure as a result.\n\n### New Tools\n* **Google Analytics 4** - GA4 in the recent year has been taking over UA tags ever since its deprecation. We’ve realized there are much more use-cases we can apply with GA4 that isn’t limited to it’s default analytics. This is exciting for us as we can model and clean event data to aggregate on Google Analytics.\n\n- **Passwordless** - Passwordless authentication, such as passkeys, have been a growing topic for us and the industry as a whole. The notion that the procedure for logins no longer require a password makes software interactions much quicker and more secure as a result.\n\n- **IFramely** - IFramely is an embeddable library that helps developers handle different types of URL embeds in a unified way. It provides a simple and consistent API for embedding various types of content, such as videos, images, and rich media, from different sources. iFramely takes care of the complexities of parsing and rendering embedded content, allowing developers to focus on the user experience and integration of external content into their applications. It supports a wide range of platforms and services, making it a versatile tool for content embedding.\n\nAs we persist in our R&D voyage, we endeavor to remain at the forefront of tech progress, delivering creative answers that propel our initiatives and the broader software sector.\n\n## Dwarves Rewind October 2023\n[Dwarves Rewind](https://www.linkedin.com/newsletters/dwarves-rewind-6963734647327375360/) is a reading list serving as a collection of news we aggregate weekly. Tech is a very high-paced industry, and rewind helps to serve as a curated list of trending and high-profile topics that everyone can look back on.\n\n![](assets/forward-engineering-october-2023_frame_91_(1).webp)\n\n### Trending and Hot Topics\n* **[Next.js releases version 14](https://nextjs.org/blog/next-14)** - Despite the major version update, Next.js has been very careful of introducing any breaking changes or new APIs. Next.js has been a much hotter topic seeing how as it treads closer to server-side rendering, it bares much resemblance to PHP and old-school server-rendered apps.\n\n  ![](assets/2023-october-forward-engineering_forward-engineering-october-2023_untitled.webp)\n\n* **[X releases Grok, a new state-of-the-art LLM](https://x.ai/)** - Elon Musk has been giving a lot of hints in the past of Twitter (now called X) releasing a Large Language Model to compete with OpenAI’s ChatGPT. Benchmarks seem very promising, and there is a great deal of hype within the industry for private access to this new LLM.\n\n  ![](assets/2023-october-forward-engineering_forward-engineering-october-2023_untitled-1.webp)\n","title":"Forward Engineering October 2023","short_title":"October 2023","description":"As we step into the exciting opportunities of October, we are at a crucial point in the ever-changing world of technology. Our adventure until now has been for the most part very exciting, with a strong focus on 'Full-stack engineering’ Now, we shift our attention to a topic that is prolific and always true: Open-source.","tags":["forward-engineering","AI","duckdb","nextjs"],"pinned":false,"draft":false,"hiring":false,"authors":["monotykamary","thanh"],"date":"Fri Nov 17 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/forward-engineering/2023-october.md","slugArray":["updates","forward-engineering","2023-october"]},{"content":"\n## #tech discord highlights\n\n![word-cloud.png](assets/2024_2025_word-cloud.png)\n\nDecember 2024 and early February 2025 saw our `#tech` channel buzzing with diverse perspectives from our community. Key themes emerged:\n\n- **AI-Assisted Coding Tools:** A significant focus on tools like Aider and Cursor. Members shared practical tips for overcoming limitations, such as preventing code truncation. We saw community members trying various prompts like, *\"Do not truncate any code, provide the full contents of the file\"* to achieve their desired outcome.\n- **Prompt Engineering at different levels:** With the advent of AI agents, prompts are getting much more sophisticated, especially for [coding agents](https://gist.github.com/gc-victor/9619efc9048adaf6647fef295978cc68).\n- **General AI & New Models:** Excitement around new AI model releases, particularly from Google Deepmind and OpenAI. Don’t forget about DeepSeek. The potential of AI agents in blockchain applications was also a recurring topic.\n    \n    > \"G2 generate game worlds -> AI agents train on generated worlds\" - mashiro5951\n    > \n- **Blockchain Explorations:** Beyond just following the trends, there was exploration around the intersection of AI and blockchain, experimenting with using AI for on-chain actions and analysis.\n- **Performance & Data:** A technical dive into performance optimizations, especially around DuckDB.\n\nOur community regularly shared interesting articles and videos, expanding the community's collective knowledge base. Topics ranged from building Google Meet clones to the architecture of high-throughput systems.\n\n## **Highlights on Memo**\n\n### Weekly consulting snapshots\n\nWe're always tracking advancements in AI, blockchain, and other emerging technologies. We feel it's essential to stay attuned to how different markets and spaces are adapting to change. Understanding AI trends and the bubbling emergence of AI agents is crucial to making sure our foundations stay strong while encompassing new technologies and techniques.\n\n- [**Weekly Consulting Snapshot #1: Gemini 2.0, OpenAI’s Sora, a16z’s Predictions**](https://memo.d.foundation/consulting/market-report/2024-13th-dec): An exploration of key advancements in AI, quantum computing, and emerging technologies reshaping consulting opportunities.\n- [**Weekly Consulting Snapshot #2: AI Talent Wars, OpenAI’s New Models, Hyperliquid’s Rise**](https://memo.d.foundation/consulting/market-report/2024-27th-dec): Discusses key trends in AI, blockchain, and productivity hacks shaping the consulting space.\n- [**Weekly Consulting Snapshot #3: AI’s Ubiquity at CES, Wall Street’s AI Boom, and Blockchain Innovations**](https://memo.d.foundation/consulting/market-report/2025-3rd-jan): Explores the impact of AI at CES 2025, Wall Street's AI-driven surge, and the fusion of blockchain and AI in emerging projects.\n- [**Weekly Consulting Snapshot #4: AI Supercomputers, Mini AI PCs, Worldcoin Expansion, and SEA VC**](https://memo.d.foundation/consulting/market-report/2025-10th-jan): Discusses AI breakthroughs, expanding Worldcoin, and driving SEA investments.\n- [**Weekly Consulting Snapshot #5: VC Trends, Blockchain Breakthroughs, and AI Innovations**](https://memo.d.foundation/consulting/market-report/2025-17th-jan): Showcases VC Trends, Blockchain Breakthroughs, and AI Innovations.\n\n\n### Cryptocurrency & blockchain\n\nWe've seeing increased interest in sophisticated strategies as the crypto market matures and institutional adoption grows. We believe understanding the interplay between Bitcoin and altcoin performance is crucial for successful hedging. We're also aware that transparency remains a key challenge, and robust transfer tracking is essential for both users and developers. Data visualization helps understand complex trends, and we're impressed with the growing popularity of Golang for building performant tools in this space.\n\n- [**Tracking Bitcoin-Altcoin Performance Indicators in BTC Hedging Strategy**](https://memo.d.foundation/playground/use-cases/bitcoin-alt-performance-tracking): Overview of tracking Bitcoin-Altcoin performance indicators in a Hedge trading strategy.\n- [**Transfer mapping: enhancing loggers for better transparency**](https://memo.d.foundation/playground/use-cases/enhancing-cryptocurrency-transfer-logger): Improving cryptocurrency transfer logging systems for transparency and traceability.\n- [**Building better Binance transfer tracking**](https://memo.d.foundation/playground/use-cases/binance-transfer-matching): Building a robust transfer tracking system for Binance accounts.\n- [**Visualizing crypto market outperform BTC-Alt indicators with Golang**](https://memo.d.foundation/playground/use-cases/crypto-market-outperform-chart-rendering): Implementing a Golang-based visualization for crypto market performance indicators.\n\n### Data engineering & architecture\n\nWe believe data as the lifeblood of modern applications, and we're strong advocates for implementing robust archival and recovery strategies. We appreciate the power of the data snapshot pattern for efficiently managing historical data, and the challenge of reconstructing historical P&L. We're always looking for new and innovative ways to tackle these problems.\n\n- [**Setup data recovery with archive strategy**](https://memo.d.foundation/playground/use-cases/data-archive-and-recovery): Implementing data archival and recovery strategies for high-volume transactional applications.\n- [**Implementing data snapshot pattern to persist historical data**](https://memo.d.foundation/playground/use-cases/persist-history-using-data-snapshot-pattern): Implementing the data snapshot pattern for efficient historical data persistence.\n- [**Reconstructing historical trading PnL: a data pipeline approach**](https://memo.d.foundation/playground/use-cases/reconstructing_trading_pnl_data_pipeline_approach): Rebuilding historical trading PnL data through an efficient data pipeline approach.\n\n### Frontend development\n\nThe frontend landscape is constantly evolving, and staying on top of the latest advancements is a high priority. We're excited about React 19's Actions, Next.js's Deno Deploy support, and AI-powered frontend tools like Transformers.js, and believe they'll be crucial for building the next generation of web applications.\n\n- [**Frontend Report January 2025**](https://memo.d.foundation/playground/Frontend/Report/frontend-report-january-2025): Explores key frontend advancements, including React 19's Actions, Next.js 15.1's Deno Deploy support, and innovative tools like Transformers.js for AI.\n\n### Dwarves foundation updates\n\nWe value transparency and communication a lot; sharing our team moments helps foster a strong sense of community, plus it's fun. Team building events are an important part of our DNA, and they help us connect on a personal level and start each new year with renewed energy and focus.\n\n- [**What's New in December 2024**](https://memo.d.foundation/updates/changelog/2024-whats-new-december): Highlights progress made by Dwarves in December 2024, including team moments and steady progress.\n- [**Weekly Digest #15: New year Gathering: Sharing Tết, starting strong**](https://memo.d.foundation/updates/digest/15-new-year-gathering): Shares the story of Dwarves' team reunion to share stories, reconnect, and kick off the Year of the Snake.\n\n### Golang\n\nIn the background, we're always watching how Go continues to evolve. We see the testing/synctest experiment as a small step towards improving testing and concurrency stories in the language.\n\n- [**Go Commentary #24: Coming in Go 1.24: testing/synctest experiment for time and concurrency testing**](https://memo.d.foundation/playground/go/weekly/dec-13): Discusses the upcoming features in Go 1.24, including the testing/synctest experiment for time and concurrency testing.\n\n## Market report: navigating tech tides - AI agents ascend, talent reshapes, and markets shift\n\nThe tech world is rapidly changing, driven by advancements in AI, shifts in talent demands, and evolving market dynamics. This report gives a quick overview of the key trends we're seeing right now.\n\n![image.png](assets/2024_2025_1.png)\n\n### AI agents take center stage: from no-code to pro-code autonomy\n\n![image.png](assets/2024_2025_2.png)\n\nAI agents are moving from concept to reality, transforming industries. Initially, no-code platforms democratized AI agent creation. Now, there's a shift towards more technical, self-hosted solutions like [n8n](https://blog.n8n.io/ai-agentic-workflows/), reflecting a need for greater customization and control, especially for advanced applications.\n\n> This transition highlights a growing sophistication in AI agent development, moving beyond simple automation to bespoke, enterprise-grade solutions.\n> \n\n![image.png](assets/2024_2025_3.png)\n\nModel context protocol (MCP) is becoming crucial for advanced AI agents. MCP allows agents to use rich contextual data, improving decision-making. Tools like `mcp-server-aidd` and `continue.dev` are leading to tailored AI coding assistants, essential for enterprise AI deployments. [**Even Cloudflare is in the picture**](https://blog.cloudflare.com/model-context-protocol/). Looking ahead, expect AI agents to integrate more deeply with hardware, blurring the lines between software and physical interaction.\n\n> Expect to see more AI solutions tailored for specific enterprise needs, demanding a deeper level of technical expertise to build and manage.\n> \n\n*The move to platforms like n8n and the focus on MCP signal a maturing AI agent landscape. For businesses, this means needing teams with deeper technical skills to leverage the full potential of AI autonomy.*\n\n### Talent and job market: AI expertise in high demand, traditional roles evolving\n\nThe demand for AI talent is incredibly competitive. Companies are fiercely competing for skilled AI professionals, recognizing their value as key innovators. However, traditional software engineering roles are evolving as AI automates routine coding tasks. AI is becoming a vital tool in development, handling code reviews and generation.\n\n> The rise of \"AI employees\" isn't just a buzzword; it's a reflection of how AI proficiency is becoming core to tech roles.\n> \n\nWhile the AI sector booms, layoffs across tech indicate a market recalibration. This restructuring suggests a move toward leaner operations and greater AI-driven automation. New job roles are emerging around AI – think AI supervisors and prompt engineers – even as traditional roles shift.\n\n*The talent market is bifurcating. Deep AI expertise is premium, but for broader engineering, adaptability and AI tool proficiency are becoming table stakes.*\n\n**The proof: job startup demands - Full-stack & AI roles lead**\n\n![image.png](assets/2024_2025_4.png)\n\nRecent job postings on platforms like Hacker News further emphasize current talent demands.  Full-stack and AI/ML engineers are prominently sought after, reflecting the industry's need for both versatile developers and specialized AI expertise.\n\n> The job market is clearly signaling a dual demand: for broad software engineering skills and for niche AI/ML specializations.\n> \n\nWhile remote work remains a strong trend, a notable segment of postings, particularly for senior and leadership positions, are hybrid or onsite, especially in major tech hubs. Compensation packages are competitive, with equity often included, especially in startups and for senior roles, indicating the ongoing battle to attract top tech talent.\n\n*Analyzing Hacker News job trends confirms the broader market shifts.  Full-stack skills remain crucial, but AI/ML expertise is increasingly becoming a core differentiator for both companies and individual engineers.*\n\n### Market dynamics: VC focus, regional growth, and blockchain innovations\n\nThe US continues to lead in venture capital, especially in AI. Emerging markets like India and Canada show strong VC growth, while cost-sensitive regions like China face funding declines, pushing them towards cost-efficient tech solutions.\n\n> AI-related fields are VC magnets in the US, but globally, strategic, cost-effective tech investments are on the rise.\n> \n\nBlockchain and AI are increasingly converging. We're seeing experimental projects combining decentralized tech with AI for enhanced transparency and new applications, especially in DeFi and asset tokenization. Decentralized exchanges like Hyperliquid are showcasing blockchain's potential in finance.\n\n*VC funding trends signal where the smart money is going: AI and efficient growth. For consultants, understanding these regional and sector dynamics is crucial for strategic advice.*\n\nThis market report provides a snapshot of a tech world in flux. AI's increasing sophistication, evolving job roles, and shifting investment patterns are key trends to watch and navigate.","title":"Forward Engineering 2024 - 2025","short_title":20242025,"description":"AI agents, talent shifts, & market dynamics: Explore tech trends in AI, blockchain, & software engineering. Discover key insights & analysis.","tags":["labs","market-report","forward-engineering","tech-community"],"pinned":false,"draft":false,"hiring":false,"authors":["thanh","monotykamary"],"date":"Fri Feb 07 2025 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/forward-engineering/2024-2025.md","slugArray":["updates","forward-engineering","2024-2025"]},{"content":"\nAt Dwarves, technology is our passion. We create it, study it, test it, document it, make it open source, and always striving to enhance it for the benefit of all. Our goal is to promote software craftsmanship and drive innovation. In this issue of Forward Engineering, we’ll walk you through our experiments with new tech stacks, share insights on achieving engineering excellence, and reflect on key lessons from the tech market over the past three months. Unsurprisingly, AI has been a central theme in many of our discussions. We invite you to join us as we explore these discoveries and encourage you to freely contribute your own thoughts along the way.\n\n## Tech Radar\n\n![](assets/august-forward-engineering-2024.mp4)\n\n### Dify\n\n**Adopt**\n\n[Dify](https://dify.ai/) is an open-source platform that's making waves by simplifying the development and orchestration of LLM (Large Language Model) applications. With its robust set of tools, developers can create intelligent workflows—from simple agents to sophisticated AI-driven apps—using a retrieval-augmented generation (RAG) engine. What's impressive is how it makes AI workflow orchestration intuitive and accessible, even if you're not a tech wizard. The drag-and-drop interfaces and clean UX/UI reduce the complexity of building LLM-based applications, enabling rapid prototyping and testing across multiple models.\n\nWe've been using Dify to quickly prototype product ideas by scaffolding agent workflows and testing their output with various models. It's been a game-changer, especially in building workflow automations like a tech summarizer, memo chatbot, or report composer. Its simplicity and flexibility allow us to experiment with different models and agent workflows without getting bogged down by infrastructure concerns.\n\n![](assets/forward-engineering-q3-2024-20240917163024269.webp) _Our engineers have built and experimented with dozens of workflows on our self-hosted Dify server._\n\n### LangGraph\n\n**Assess**\n\n[LangGraph](https://langchain-ai.github.io/langgraph) is an emerging library designed for building stateful, multi-actor applications using large language models (LLMs). It facilitates the creation of agent and multi-agent workflows by leveraging a graph structure. Each node in the graph acts as an agent responsible for specific tasks, and interactions are managed through edges. This approach enhances productivity by letting developers focus on the specialized functions of each node without worrying about synchronizing inputs and outputs.\n\nThe key benefits? Improved visualization and management of complex interactions, division of tasks into manageable sub-problems, and high control over individual agents and their transitions. Despite its promising capabilities, LangGraph is still in its early days. Many techniques and designs are available on GitHub, but it requires further exploration and validation in diverse real-world applications.\n\n### RAG\n\n**Adopt**\n\nRetrieval-Augmented Generation (RAG) is enhancing AI by allowing it to access and utilize data it was never trained on. This makes it invaluable for companies needing to leverage their own data efficiently. Currently, it's the most cost-effective way for organizations to integrate their proprietary information into AI models. By retrieving relevant documents or streaming the latest data, RAG enhances the contextual understanding of LLM-based applications, thereby improving their performance.\n\nWe mostly use RAG to enrich input contexts, whether by referencing static documents like PDFs or streaming real-time data from the internet. Its ability to integrate seamlessly with existing workflows and improve AI performance without extensive retraining makes it a practical choice. However, challenges like ensuring data quality and managing latency during retrieval need careful consideration. Alternatives like purely generative models lack the dynamic data access capabilities, making RAG a superior choice for many real-world applications.\n\n### LangSmith\n\n**Trial**\n\n[LangSmith](https://www.langchain.com/langsmith) builds on the foundation laid by LangChain, which simplified the prototyping of LLM applications. But LangSmith shifts focus towards production, emphasizing reliability and maintainability. Its standout features include tracing agent workflows for easier debugging and automating testing with dataset creation and evaluators.\n\nWhile its monitoring tools and tracing capabilities are beneficial for scaling and debugging, it's still relatively new, and widespread adoption is still in progress. We've been trying out LangSmith in projects where robust production support is crucial. It's got potential, but it needs further industry validation.\n\n### Cursor\n\n**Assess**\n\n[Cursor](https://www.cursor.com/) is a fork of VS Code designed to enhance coding with AI while retaining a familiar text editing experience. What sets this IDE apart is its ability to register documents for reference, significantly boosting productivity by generating accurate and contextually aware code—especially when combined with Claude 3.5 Sonnet.\n\nOur engineers have been testing it out, and the results are promising, particularly in creating templates and skeleton code. The impact is more noticeable at the unit level, making coding more enjoyable and reducing the mental load of syntax and specifics. Since it's an emerging technology, we've placed Cursor in the \"Assess\" category due to its potential to revolutionize coding practices, despite being relatively new and requiring further exploration.\n\n### Devbox\n\n**Trial**\n\n[Devbox](https://www.jetify.com/devbox) is a tool designed to create isolated, reproducible development environments without the need for Docker containers or Nix language expertise. It simplifies onboarding by using a single `devbox.json` file to set up dependencies and environment configurations, avoiding the clutter of global environments.\n\nDevbox addresses common issues like version conflicts across projects and the resource-intensive nature of Docker on Windows/Mac by leveraging native applications built with Nix. It significantly enhances battery life and system performance, but it does require some familiarity with Nix and can present file permission challenges. We're giving Devbox a trial run, especially for teams seeking cleaner, more efficient development setups.\n\n![](assets/forward-engineering-q3-2024-20240917163118424.webp)\n\n_The journey of experimenting with Devbox is documented in [our memo](https://memo.d.foundation/playground/-devbox/)._\n\n### Shadcn/ui\n\n**Trial**\n\n[Shadcn](https://ui.shadcn.com/) offers beautifully designed, accessible, and customizable UI components that you can easily copy and paste into your applications. This open-source tool enhances development speed by allowing developers to quickly scaffold UI components. In our recent projects, we saw significant time savings.\n\nInitially, we had concerns about maintaining consistency with a copy-paste model, but our experience proved otherwise. Customization at the Tailwind config level ensures a cohesive theme, and the lightweight nature of the tool keeps applications fast to load and build. While it may lack the comprehensive ecosystem of full-set frameworks like MUI or Chakra, its modularity and potential AI-backed features with [v0.dev](http://v0.dev) position Shadcn as a compelling alternative.\n\n## Highlights on Memo\n\n### AI & LLM\n\n[**History of Structured Outputs for LLMs**](https://memo.d.foundation/playground/01_literature/history-of-structured-output-for-llms/)\n\nWhy are structured outputs, like JSON, in LLM API endpoints so vital? We believe this will soon become a standard in all tooling.\n\n[**Re-ranking in RAG**](https://memo.d.foundation/playground/01_literature/engineering/ai/re-ranking-in-rag/)\n\nSometimes, embeddings might not effectively extract the most accurate sources to enrich the context. Re-ranking offers an additional step to sift out the most relevant context for the initial query.\n\n[**Design feedback mechanism for LLM applications**](https://memo.d.foundation/playground/01_literature/feedback-mechanism/)\n\nCapturing user feedback while they're using the app is crucial for understanding the app’s performance and accuracy. This indispensable step precedes any further plans to improve app performance.\n\n[**Multi-agent collaboration for task completion**](https://memo.d.foundation/playground/01_literature/engineering/ai/multi-agent-collaboration-for-task-completion/)\n\nWe discuss the architecture and setup of the \"divide and conquer\" strategy to distribute workloads to multiple agents.\n\n[**Journey of Thought Prompting: Harnessing AI to Craft Better Prompts**](https://memo.d.foundation/playground/01_literature/engineering/ai/journey-of-thought-prompting/)\n\nAI proves to be an excellent tool in crafting and improving system prompts, which are among the most important parts in maximizing any LLM benefits.\n\n**Further research**\n\n- [Evaluating search engine in RAG systems](https://memo.d.foundation/playground/01_literature/hybrid-search/)\n- [Building Agent Supervisors to Generate Insights](https://memo.d.foundation/playground/01_literature/supervisor-ai-agents/)\n- [Multimodal in RAG](https://memo.d.foundation/playground/01_literature/engineering/ai/multimodal-in-rag/)\n- [Developing rapidly with Generative AI](https://memo.d.foundation/playground/01_literature/developing-rapidly-with-generative-ai/)\n- [Evaluating caching in RAG systems](https://memo.d.foundation/playground/01_literature/caching-with-rag-system/)\n- [Function calling in AI agents](https://memo.d.foundation/playground/00_fleeting/function-calling/)\n\n### Golang\n\n[**Golang Weekly Commentary Series**](https://memo.d.foundation/tags/go-weekly/)\n\nWe've been diving into the Go Weekly commentaries, and here's what we've found:\n\n- [Go Weekly #2: Go 1.23 Iterators](https://memo.d.foundation/playground/00_fleeting/go-weekly-511/) Go 1.23's iteration proposal highlights the tension between adding functional patterns to a traditionally imperative language, raising questions about its future community adoption\n- [Go Commentary #3: Generic Collections, Generics Constraints, AI Bot](https://memo.d.foundation/playground/00_fleeting/go-commentary-jul-12/) Go's generics implementation remains underutilized and poorly documented, presenting challenges for developers\n- [Go Commentary #7: Releases, Websockets, and Struct Behavior](https://memo.d.foundation/playground/00_fleeting/go-commentary-aug-16/) Go 1.23 highlights both the subtle complexity of struct behavior and improvements in websocket handling, reinforcing the importance of understanding how slices and copies behave in the language.\n\n[**Go in Enterprise**](https://memo.d.foundation/playground/go/enterprise-standard-language/)\n\nWe strongly advocate for Go due to its simplicity and performance. We believe the Go programming language should gain more popularity, especially in enterprise adoption. This belief prompted us to collect opinions and use cases from others on the subject:\n\n- [Why Enterprise Chose Java](https://memo.d.foundation/playground/go/why-enterprise-chose-java/)\n- [When to use Go in the Enterprise](https://memo.d.foundation/playground/go/when-to-use-golang-in-enterprise/)\n- [Who is using Go in enterprise?](https://memo.d.foundation/playground/go/who-using-golang-in-enterprise/)\n\n### Software Architecture & Modeling\n\n[**GoF design pattern series**](https://memo.d.foundation/tags/gang-of-four/)\n\nWe're big fans of foundational topics, and it's interesting to revisit tried and true concepts. This time, we've chosen the Gang of Four Design Patterns. Many of the lessons are still significantly relevant to our current coding practices.\n\n[**Design file sharing system**](https://memo.d.foundation/playground/01_literature/design-file-sharing-system-part-1-directory-structure/)\n\nWe discuss the design of a file-sharing system akin to Google Drive, where the path field for file hierarchies streamlines operations, offering fast, efficient storage and retrieval.\n\n[**Designing a model with dynamic properties**](https://memo.d.foundation/playground/01_literature/designing-a-model-with-dynamic-properties/)\n\nAnyone who has used Notion is awed by the flexibility of its properties, which can be dynamically created and altered without hassle. We'll reveal the structure of this flexibility from our experience in developing a very similar feature.\n\n[**Local-first software**](https://memo.d.foundation/playground/01_literature/local-first-software/)\n\nAn overview of Local-First software, where data ownership shifts to the user, offering privacy and offline functionality, but facing technical challenges like CRDT complexity and secure synchronization.\n\n### Blockchain\n\n[**Solana core concept**](https://memo.d.foundation/playground/01_literature/solana-core-concepts/)\n\nWe dive into Solana's unique architecture, separating program code from data and leveraging innovations like Proof of History (PoH) and Program Derived Addresses (PDAs).\n\n[**Ton: Blockchain of blockchains**](https://memo.d.foundation/playground/01_literature/ton_blockchain_of_blockchains/)\n\nTON's innovative model refines how decentralized applications and transactions can function on a massive scale.\n\n[**Using Foundry for EVM smart contract development**](https://memo.d.foundation/playground/01_literature/using-foundry-for-evm-smart-contract-developement/)\n\nOur thoughts on Foundry, a framework developed for creating EVM smart contracts. This unified toolchain leverages the speed of Rust for faster workflows and supports advanced features such as Solidity scripting and dependency management.\n\n## Market Report\n\n### Layoffs continue in tech world, Surge in August\n\nAugust's surge in job cuts reflects growing economic uncertainty and shifting market dynamics. According to the report:\n\n> The biggest growth in planned layoffs came in the technology field, with companies announcing 41,829 cuts, the most in 20 months.\n\nSome of the companies announcing cuts include:\n\n- Intel (~15000)\n- Microsoft (~1000)\n- IBM (~1000)\n- Cisco (~5900)\n- Bytedance (~450)\n\nThe increasing trend in layoffs year-over-year is concerning. It suggests that the tech industry's job market instability is not a short-term phenomenon but potentially a longer-term restructuring. This could lead to a reimagining of workforce strategies in tech, possibly emphasizing more contract work or AI-augmented roles.\n\n![](assets/forward-engineering-q3-2024-20240917163259274.webp)\n\n_Source from [https://layoffs.fyi](https://layoffs.fyi)_\n\n### The State of Tech Market in 2024\n\nThe broader tech ecosystem, with JavaScript as a prominent example, is experiencing notable shifts in 2024. A tightening job market for software engineers has slowed career progression and increased competition, leading to several key trends across the industry:\n\n- A shift toward \"boring\" technology and monolithic architectures, emphasizing stability over adopting the latest innovations.\n- A surge in Full Stack development, with TypeScript gaining traction as a preferred language.\n- More responsibilities \"shifting left\" to developers, particularly in areas like testing and security.\n\nThe 2024 Stack Overflow survey highlights intriguing data:\n\n- Erlang developers earn the highest median salary at $100,836, followed by Elixir and Clojure developers.\n- AI tools are poised to become integral to development workflows, with 81% of developers expecting AI to assist in documenting code, 80% in testing, and 76% in writing code.\n- While JavaScript remains a dominant language, its median salary has seen a decline.\n\n![](assets/forward-engineering-q3-2024-20240917163336937.webp)\n\n### AI Makes a Real Impact in Programming\n\nAI is no longer just a buzzword; it's making a tangible impact in programming.\n\n![](assets/forward-engineering-q3-2024-20240917163412653.webp)\n\nAs Amazon's CEO, Andy Jassy, noted:\n\n> In under six months, we've been able to upgrade more than 50% of our production Java systems to modernized Java versions at a fraction of the usual time and effort. And, our developers shipped 79% of the auto-generated code reviews without any additional changes.\n\nOur thought on that:\n\n- This highlights how AI-assisted coding is lowering development costs and replacing tedious tasks. As AI costs become cheaper and open tools become more available, building AI-integrated solutions will become more accessible.\n- We might soon see one-person or small-team businesses becoming the norm, leveraging AI to handle tasks that previously required larger teams. The opportunities are vast for solo makers who can find niche ideas.\n- It's clear that AI is reshaping the programming landscape. Those who can effectively harness AI tools will have a significant advantage. We might even see the rise of \"AI employees,\" where founders proficient in AI lead the way, and AI application skills become a prerequisite in hiring.\n\n### AI companies continue dominating YC batch\n\nAccording to [a Reddit post](https://www.reddit.com/r/ycombinator/comments/1fbb9m0/the_rise_of_ai_companies_in_yc/), in the current Y Combinator batch (S24 - Summer 2024), a staggering 72% of startups are focused on AI—a dramatic increase from just 1% in the winter of 2012 (W12). Compared to the crypto trend, AI's momentum is exponentially greater.\n\n![](assets/forward-engineering-q3-2024-20240917163441436.webp)\n\nSome key takeaways:\n\n- AI will be utilized as a filter for data. Whoever owns the best fine-tuned models will gain the advantage in the future.\n- \"AI wrappers\" will become essential middleware software. Every industry will finally have interfaces to interact with AI.\n- As AI becomes accessible to everyone, differentiation will come from other factors—user experience, attention, branding, and distribution channels.\n- As AI's role in automation grows, the workforce will increasingly shift towards AI supervision, prompt engineering, and ethical oversight.\n- Data ownership will become a central competitive battleground, leading to more regulation, strategic acquisitions of datasets, and ethical debates around the use of data in AI training.\n\nIt's evident that AI is not just a trend but a fundamental shift in how businesses operate. The rise of AI-focused startups indicates a significant transformation in the startup ecosystem.\n\n## References\n\n- [Layoffs jump in August while hiring in 2024 is at a historic low, Challenger report shows](https://www.cnbc.com/2024/09/05/layoffs-jump-in-august-while-hiring-in-2024-is-at-a-historic-low-challenger-reports-shows.html)\n- [What is old is new again](https://newsletter.pragmaticengineer.com/p/what-is-old-is-new-again)\n- [Stackoverflow 2024 Developer Survey](https://survey.stackoverflow.co/2024/)\n- [Feeling very powerful as a technical founder with Claude Sonnet 3.5](https://www.reddit.com/r/ycombinator/comments/1e7rtdw/feeling_very_powerful_as_a_technical_founder_with/)\n- [Andy Jassy, Amazon CEO tweeting about the impact of AI in coding](https://x.com/ajassy/status/1826608791741493281)\n- [The Rise of AI Companies in YC](https://www.reddit.com/r/ycombinator/comments/1fbb9m0/the_rise_of_ai_companies_in_yc/)\n","title":"Forward Engineering Quarter 3, 2024","short_title":"Quarter 3 2024","description":"In Q3/2024 Forward Engineering, we explore new tech stacks, engineering excellence, and key trends from the tech market over the past three months, with a focus on AI. Learn about tools like Dify, LangGraph, RAG, and more as we share our experiments and insights. Whether you’re interested in AI-driven workflows or tech market trends like the surge in AI startups and hiring demand.","tags":["labs","market-report","forward-engineering","radar"],"pinned":false,"draft":false,"hiring":false,"authors":["thanh","monotykamary"],"date":"Tue Sep 17 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/forward-engineering/2024-quarter-3.md","slugArray":["updates","forward-engineering","2024-quarter-3"]},{"content":"\n## Our Perspective on Technology \nTechnology is eating the world. The technology we used yesterday may be deprecated today. New technology has enabled us to create new things. With the existing set of problems, new solutions will emerge along with new technologies.\n\nOver five years of working as an innovative software firm, other than the energetic tech-savvy workforce, we shape the team day by day with the core values that move towards the engineering culture. We start this team with the mission to empower innovation and join the force to co-create the future. This urges us to learn the newest and the best technology and new practices out there to enhance the output quality, speed up the development process, also to bring the best pieces of software to life.\n\nWe launch The Dwarves Tech Radar as a living asset to evaluate the adoption decision and keep the technology direction stays on track. Tech Radar is how we do R&D, how we work on self-growth and motivate continuous curiosity.\n\n## Adoption Process\nWhen we observe a new tech, we map to the movement of the certain market to evaluate if the new tech could fit in. The main idea is to see if the new tech could help to make anything better than before in the long run and also serve our development direction.\n\nThe Dwarves are encouraged to gather into small focus groups to discuss and study a particular topic. The below format could be found originated from ThoughtWorks. We organize the topics using two categorizing elements:\n\n* Quadrants represent different kinds of topics.\n* The rings indicate what stage in an adoption lifecycle we think they should be in.\n\n## Quadrants\nThe quadrants consist of:\n\n* Languages and Frameworks, e.g., Erlang, Svelte, R\n* Techniques, e.g., new design technique, software structure, microservices architect.\n* Tools, e.g., editors, databases, software development tools.\n* Platforms, e.g., things provided by others that we build software on top like Vault, Istio, JupyterLab.\n\n## Rings\nOur radar has four rings, start from the middle.\n\n* Adopt: proven and mature for use.\n* Trial: ready for use but not completely proven.\n* Assess: things to explore, look at closely.\n* Hold: things that not fit us or we’ve had a good experience.\n\nFor each batch, we will organize into volume in our github repository (dwarvesf/radar) and track down the changes or comments from the study group.\n\n## The Tech Knowledge Areas\n![](assets/dwarves-tech-radar-the-introduction_8e5f7f8bb132590bfbf3105155047b6c_md5.webp)\n\nAbove is the knowledge areas that we think the software engineers should have been through. Our current tech stack is the reflection of how we apply those theoretical knowledge in real life. Run through the software development lifecycle and engineering disciplines, it mainly cover\n\n* Requirement\n* Design\n* Development\n* Testing\n* Deployment\n* Maintenance / Monitoring\n\nIn each particular topic, there are new practices, tools, frameworks and services that keeps evolving. The lower the topic in knowledge areas stack, the more important it is to set the foundation for engineers.\n","title":"Dwarves Tech Radar: The Introduction","short_title":"Tech Radar Introduction","description":"We launch The Dwarves Tech Radar as a living asset to evaluate the adoption decision and keep the technology direction stays on track. Tech Radar is how we do R&D, how we work on self-growth and motivate continuous curiosity.","tags":["radar","forward-engineering","technology"],"pinned":false,"draft":false,"hiring":false,"authors":["han","duy"],"date":"Tue Aug 25 2020 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/forward-engineering/tech-radar-the-introduction.md","slugArray":["updates","forward-engineering","tech-radar-the-introduction"]},{"content":"\nThe Dwarves have their tradition to explore the tech scene and learn new things. Dwarves Tech Radar kicked the initial step since January of 2020. \n\nIt is the first time we sit down and do it in written form. It's a bit hard for the engineers at first, but we managed to complete the volume with ten reports.\n\nBesides volume 01, we have an opportunity to sort out our current technology index and put it at https://d.foundation/radar](https://d.foundation/radar). And for this edition, the theme is to get the whole team used to the concept of a central knowledge base—every study to expand our view to the tech scene counts. The design team also has a place to contribute and discuss their practices.\n\n![](assets/dwarves-tech-radar-volume-01_d6ad0adba1f212243cbd321a44cc2e53_md5.webp)\n\nLet us walk you through the first Volume.\n\n## Language & Framework\n### WebAssembly\nPreviously, it takes HTML, CSS, and Javascript to perform an interactive web-app for users. But with the continually higher demand, web-app must serve at a better velocity. Web Assembly was created to tackle the performance-critical problem that Javascript is struggling, leveraging the calculating ability in client-server, especially in multimedia processing tasks. The topic is a quick playing-around that will help engineers shorten their time to get to know the WebAssembly concepts.\n\n### Progressive Web App\nNative applications are known for being incredibly productive and reliable. It's fast, convenient, user-friendly, and work regardless of network connection and can be considered part of the device it's run on. Given this noticeable feature, PWA is an enhanced technique built with modern APIs. PWA equips web-app with native-like capabilities, reliability, and installation while reaching anyone, anywhere, on any device with a single codebase. In short, it supports and provides users with a unique opportunity to upgrade their web experience.\n\n### Three.js\nThree.js is a library that is used to create and display 3D animation in web applications. Comes with a short demo on how to turn music audio files into sound waves using three.js and WebAudio API, this topic can be considered a self-project from one of our front-end Dwarves, applying the basic concept of three.js and use it for audio visualization.\n\n### Istio\nIstio is an excellent choice for service mesh due to its amazing and useful feature set. Service discovery, traffic management, service-to-service, and origin-to-service security, observability (including telemetry and distributed tracing), rolling releases, and resiliency.\n\nStill, our infrastructure scale is far from utilizing all of those functions. Given that reason, Istio is quite complex and resource-consuming to adopt. We've decided to hold its implementation in the time being.\n\n### SwiftUI\nSwiftUI is a UI framework that lets developers create apps in a declarative way. There are minimal code changes as a lot of the same components on SwiftUI can be reused. Learn once & apply anywhere, SwiftUI Stacks, Control, and Layouts work the same with mini changes and navigation. Most controls and data work across all platforms and will be automatically translated to the user.\n\nSwift UI is still in its early stage and not yet mature to apply for any production scale. But we think it will be kicked in on iOS 15. To make sure we can be all ready by then, we are using it for our internal projects and exploring the new iOS features, like Widget and so on.\n\n### XPC Service\nRunning an application needs more than one processor. It takes support from other process helpers. This makes sure the app can still run once one of the process helpers is crashed; leave the minimum of memory footprint and enhancing security. Acts as an inter-process-communication mechanism, XPC Service manages the communication between the processors and the application by calling the processors in the time of need and turned off once the process is done.\n\nApplying XPC-service in mobile development touches some advantages: reduce memory footprint or separated permission for each service. But on the other hand, it triggers the coding boilerplate and the latency between some specific services.\n\n## Practices & Approach\n### Software Reusability\nSystems are repeatedly created in a specific field, with set variables to fulfill the requirements. Instead of rebuilding these systems every time a product is made, reusability in software is how developers shorten the effort by re-picking the elements from the previous system. This topic is a brief explanation of why we opt for frameworks in the development process or why web service standards are being used widely. It's also the answer for some software matters such as lower software production and maintenance costs, faster delivery of systems, and increased software quality to get the final goal is the increment of return on software investments.\n\n### CLI Assistant\nDuring the coding process, we realize people will soon forget about the code information. It happens every once in a while. The most usual scenario is to switch to the browser and Google the hell out of it. This terminal assistant is a heuristic-approach tool to provide the knowledge we need in the software process. Combining with a rubber duck for debugging, CLI Assistant helps reduce the effort to search for answers constantly, as it manages to contain the info we need along the way.\n\n### Gestalt UI Principles\nUser Interface isn't only about aesthetics. It's also about usability, performance, and how users experience the product along the way.\n\nGestalt Principles will be an active supporter for us during our UI design process. Before we fully understand UI's beauty and how to create it, those principles are our guidance.\n\nHowever, never limit yourself to any line or principles. Rules are subjected to be broken. Feel free to stay creative. A great UI design is a harmonious combination of accessibility, feasibility, and art.\n\n### Go-routine Underlying\nGo's native concurrency model allows it to rise in popularity for creating truly concurrent systems. Goroutines, in fact, acts as a vital part of its functioning. They are the heart and soul of the language and can provide a massive performance boost if used appropriately.\n\n### Applied Security Aspects in\n* SSH\n* SSL\n* Blockchain\n\nFrom the dawn of the network until now, security has always been essential. But as time goes by, security is embedded into frameworks and low-level level layers of the tech stacks. Hence, many developers spend their time messing around with the top-level level layers, confident that the security issues are covered by frameworks & libraries. Security somehow is placed in a black box, and we are gradually getting ignorant about how it works. This explains the underlying security principles of Blockchain and SSL (Secure Sockets Layers), providing the foundation of how to put the security into action.\n\n### AARRR Funnel\nWith AARRR funnel, we could build a product based on a concrete foundation and minimize the risks by defining what it takes to get the business goal and how to get there (metrics).\n\nAlong the way, we could define the metrics for each stage and which one deserves the utmost focus. It creates our ability to do things in the right way.\n\n### Blockchain for Designer\nThe key value proposition of Blockchain is to provide users with transparency and efficiency. Many businesses take off by applying Blockchain, especially in finance, supply chain, healthcare, and gaming. Blockchain is believed to help users resolve trust issues when it comes to personal information and assets.\n\nThus, design for Blockchain is the most critical challenge for raising adoption. Effective UX design is essential to create useful and valuable applications. This keeps end-users comfortable and, eventually, forget about the sophisticated underlying technology.\n\nAlthough Blockchain will change and develop in the future, the principle remains the same. That means product designers must always stay posted on new Tech that can become a savior for users' pain points.\n\n### Remote UX Testing\nThanks to the usability test, we were able to address the user's trouble. It lets us improve the information architecture and visual hierarchy and product performance to bring users a better experience. This reduces their effort and time to the minimum, which, in return, should drive more sales.\n\nAs we have no idea when the Covid-19 pandemic is over and work from home is strongly recommended, it's the right time to adopt remote methods in UX design, including Remote Moderated Usability Testing. Although there are some drawbacks, it's still a good solution for our team, client, and test participants.\n\n## Reaching Toward\nThese above are just the beginning of a long run. We're thinking of bringing everything alive once all the topics are wrapped up. In the meantime, we'd love to receive all of the comments, contributions, and advice to make this Radar more completed. The best can always become better.\n\nThough this began as a side project, The Dwarves Tech Radar speaks up the code that sticks us together for over the years.\n\n**Innovation** - the urge to discover new ways of solving the current problems and create impacts\n**Craftsmanship** - the mindset of dedicating your time and effort in every piece of work\n**Teamwork** - the spirit of connecting and collaborate effectively amongst the crew without breaking the present value.\n\nInnovation happens almost every day, and it's our job to pursue the latest version. It's what sets the business successful and giving them a competitive advantage. That begins with nothing but keeps the employee updated on the latest development.\n\nGrab a seat and stay abreast of our latest topic updates.\n","title":"Dwarves Tech Radar Volume 01","short_title":"Tech Radar Volume 01","description":"For this edition, the theme is to get the whole team used to the concept of a central knowledge base—every study to expand our view to the tech scene counts. The design team also has a place to contribute and discuss their practices.","tags":["radar","forward-engineering","technology"],"pinned":false,"draft":false,"hiring":false,"authors":["duy"],"date":"Wed Aug 26 2020 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/forward-engineering/tech-radar-volume-01.md","slugArray":["updates","forward-engineering","tech-radar-volume-01"]},{"content":"\nOnce every month, we gather for Radar update to round up the cool techs and assess if we should adopt that to the team. Road to a wider and more diversified rings, Dwarves Tech Radar v2 contains the practices to **simplify the workflow**, new techniques/ approach methods to **upgrade our current standards** and **expand the domain knowledge.** \n\n## Trial\n### Earthly: The combination Dockerfile + Makefile\n[https://earthly.dev/](https://earthly.dev/)\n\nA repeatable syntax builds to untangle the debugging process between the local environment and the CI platform. Earthly allows our DevOps to merge all the tools into one \"Earth\", and eventually simplify the whole CI/CD flow. As DevOps must integrate different files from both Makefile and Dockerfile for integration testing, Earthfile was created to remove this burden, automatically. Reproduce CI failures is also what makes Earthly more valuable. This enables developers to run CI on their local env, instead of the constantly `git commit -m \"try again\"`.\n\nWe applied it on Voconic, our complex on-going project about Cloud platform, to fully utilize the benefit. Earthly executes targets in parallel and makes our pipelines run much faster.\n\n![](assets/dwarves-tech-radar-volume-02_ecb87e89c8fcfad298cc445cb3c4c76b_md5.webp)\n\n## Assess\n### Webflow: Build visual canvas without coding techniques\n [https://webflow.com/](https://webflow.com/) \n\nAt some point, we figure the development phase might take more time and resources than we need. Therefore, a no-code platform is what can resolve the issue. Webflow removes the usual misunderstanding between designers and developers - enables them to convert stunning designs into production without any coding techniques. \n\nDuy P, our UI designer, approached this with KiwiPay: [https://kiwipay.webflow.io/](https://kiwipay.webflow.io/)\n\n![](assets/dwarves-tech-radar-volume-02_3306d8d315bae18a20786c33778c2b25_md5.webp)\n\nBesides the outstanding points: Sharing for multiple collaborators, easy working flow, codebases can be exported easily in HTML/ CSS & JSON data, Webflow still has its downside. The no-code mechanism prevents Webflow from performing complex animation, i.e., generates a limitation in the animated web. Furthermore, unstable responsiveness and errors in image display are things Webflow needs to work on.\n\n### Volta: Hassle-free JS Tool Manager\n[https://volta.sh/](https://volta.sh/) \n\nDuring our work with Javascript, each project comes with different node versions. Usually, managing these versions relies mostly on nvm, requiring developers to manually run their CLI every time switching between projects. It's a waste of time and can quickly cause errors.\n\nOne of our engineers started to work on Volta - a hassle-free approach to manage the CLIs. In short, Volta detects the node versions in the JSON package, unifies them into one place, and automatically switch them as developers change their projects. Since Volta supports quick engine setup, we get to install the npm package binaries into the toolchain once and for all and then let Volta take care of the rest.\n\n## Adopt\n### Upptime: Real time status update \n[https://upptime.js.org/](https://upptime.js.org/)\n\nWe tried out CState as our monitoring service, but CState requires low level setup at infrastructure level and therefore not suitable for our bootstrapping kit. Upptime, on the other hand, only requires a simple Github repository and a config file to get it started. We gave Upptime a twist, and rolled out our version at [stt.daf.ug](http://stt.daf.ug/).\n\n![](assets/dwarves-tech-radar-volume-02_3b5bb41a5a96a78fadb9fef60f1d0c24_md5.webp)\n","title":"Dwarves Tech Radar Volume 02","short_title":"Tech Radar Volume 02","description":"Dwarves Tech Radar v2 contains the practices to simplify the workflow, new techniques/ approach methods to upgrade our current standards and expand the domain knowledge.","tags":["radar","forward-engineering","technology"],"pinned":false,"draft":false,"hiring":false,"authors":["duy"],"date":"Thu Jan 14 2021 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/forward-engineering/tech-radar-volume-02.md","slugArray":["updates","forward-engineering","tech-radar-volume-02"]},{"content":"\nWe started [the 1st volume](https://github.com/dwarvesf/radar/tree/master/vol-01) a year ago, mostly about assessing all the tech indexes we have adopted for 5 years. Then we moved to [the 2nd volume](https://github.com/dwarvesf/radar/tree/master/vol-02), where we figured ways to simplify the workflow and complete our project toolkit.\n\nAnd here we go again, another version of tech radar at Dwarves Foundation. 2021 has just gone through its first quarter, and we've left with some new toys to trial and see if they create any impact. In short, this 3rd volume is all about one thing: **Trial**.\n\nWe also have the GitHub version at **[dwarvesf/radar/vol-03](https://github.com/dwarvesf/radar/tree/master/vol-03)**.\n\n## Testing\n### [k6]()\n*[https://k6.io/](https://k6.io/)*\n\n![](assets/dwarves-tech-radar-volume-03_4d92977a7295c51f3e0fdd3d3966aedd_md5.webp)\n\nOpen-sourced load testing tool to verify the system's loading tolerance. By applying k6, developers can measure the limited amount of requests that the system can handle.\n\nThough k6 is written in Go, its scripts are made out of Javascript. Thanks to its code-driven mechanism, with the powerful code-based scripting from JS, k6 was built to prioritize developers. It's easy to maintain and integrate k6 with the daily tools of developers, like GitHub, Grafana, VSCode, GraphQL.\n\nSince functional testing is still our main work, Quynh Le - our QC Team Lead, decided to take a good look at it as a reference before moving to Testlink.\n\n### [Testlink]()\n*[https://testlink.org/](https://testlink.org/)*\n\nAfter k6, Testlink is the next thing on queue - An open-sourced test management tool that oversees and controls everything in test, test cases, test report, requirement, or test execution. We hosted a radio talk on this, mainly to demo the team on how we set up and apply Testlink into our current testing workflow.\n\nCurrently, we're trialing Testlink with BaseHQ and Aharooms. We get to know the project quality status or how many percentage requirements are covered by using it. The plan is to configure and sync the automation test report with TestLink and task report tools such as Jira.\n\n## Front-end Development\n### [Preact]()\n*[https://preactjs.com/](https://preactjs.com/)*\n\nA JS library developed on React structure, with the same API, component and virtual DOM integration. Thanks to the light bundle size (3kb), the Preact-based website is faster in rendering and boosting user experience. The next level for React alternative and the smallest library in size so far.\n\nProviding the same APIs and mechanism as React, Preact can be used directly in the browser and doesn't require any build or tools. Using `preact-compat` in Webpack/ Browserify, developers create an alias to achieve 100% compatibility with React.\n\nA significant advantage of switching to Preact from React is the smaller bundle size that helps the app to load faster - this can be a key requirement for some projects. We're using Preact to bootstrap some projects of the marketplace and product showcases.\n\n## DevOps and Maintenance\n### [ArgoCD]()\nActs as a Kubernetes controller which continuously monitors running applications and compares the current, live state against the desired target state (as specified in the Git repo); ArgoCD helps update, manage and control the code versions during its development phase on k8s. Testers can export the environment configuration in different formats, such as customize files, YAML files or jsonnet.\n\n## No-code Platform\n### [Webflow and Bubble.io]()\nWe did bring up [Webflow](https://webflow.com/) in the previous version and applied it in [KiwiPay](https://kiwipay.webflow.io/) - marking our first attempt in no-code development. Succeeding this, we used Webflow to finetune the website of [ATVPro](https://atvpro.webflow.io/)\n\n![](assets/dwarves-tech-radar-volume-03_178bf3e1958cd514ccb99d9a3b4ce3bf_md5.webp)\n\nAiming for a more complex tool, we dived in [bubble](https://bubble.io/) - a no-code tool with the same concept. After using it for one of our design projects, we realize it somehow refrains developers from learning and adjusting the code. Meanwhile, it requires a deeper level of code and database, making it hard for designers to pick up. That leaves us with hitting a pause on bubble, and sticking with Webflow for our future projects.\n","title":"Dwarves Tech Radar Volume 03","short_title":"Tech Radar Volume 03","description":"In short, this 3rd volume is all about one thing: Trial","tags":["radar","forward-engineering","technology"],"pinned":false,"draft":false,"hiring":false,"authors":["duy"],"date":"Thu Apr 29 2021 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/forward-engineering/tech-radar-volume-03.md","slugArray":["updates","forward-engineering","tech-radar-volume-03"]},{"content":"\nIt all started when us, a couple of product people realized with our expertise in technology, our passion for outstanding software, we have the ability to uplift like-minded founders by helping them build and launch their startups. The idea became clearer when our network of makers, industry experts and investors broadened steadily.\n\nWe had every signal that a VC, _by makers and for makers_, would be the right path for us. Dwarves Ventures was born with that vision in mind, and Fund 0 came into action to test the water.\n\nCame 2020. It was a year like nothing anyone could have expected. For us, it was a year full of uncertainty and chaos, making our new venture a lot more challanging. We knew we wouldn’t be profitable from our investments. Instead, we decided we should just celebrate small wins whenever we can, and learn as we kept moving ahead.\n\nThroughout 2020, we managed to push boundaries and provide values with our unconventional, “founder-friendly” investment models. We kept on building great partnerships and supporting our portfolio companies in withstanding scrunity and growing. We also gave back to the community that raised us, by contributing to meaning non-profit projects.\n\n### The year in number\n- 9 team members\n- 2 trusted partners\n- 33 investment opportunities\n- 8 portfolio companies\n- 3 communities of aspiring founders and makers\n\n### The year in industry\n- Healthtech\n- Foodtech\n- Proptech\n- Marketplace\n- B2C\n- B2B\n- D2C\n\n### Highlights\n**January**\n\nNew year, new resoultion. For 2020, we set out to:\n\nRemote team. Following the success of pioneers in the tech industry, our team will go remote-first.\n\nAn allround partner for startups. Rather than the mere financial investment, we are going to become part of every startup’s journey that we invest in.\n\nWe are going to drill our focus on founders, especially those who leverage technology to transform ways of living and working.\n\n**February**\n\nCoronavirus hits hard. The economy is in complete chaos, everything is expected to go digital. The need to focus on technology is at its peak.\n\nOur response: We aim to answer one simple question, “What is the fastest thing we can do to help?” We put forward the Covid-19 relief package, giving portfolio companies, or any business in general, the alternative financial and operational support to get their business online.\n\n**March**\n\nWe put our mark in the US startup scene. We welcome Para (http://joinpara.com), a startup in the healthtech sector, into our portlofio. The investment itself is meaningful. Para connects facilities with medial professionals, just in time to support health systems fighting the pandamic.\n\nOur innitiative with going remote helps lay the groundwork for our portfolio companies to follow suit and adapt the framework into their team.\n\n**May**\n\nWe welcome Airwatt to our portfolio. Providing solutions to energy usage with AI as the backbone, Airwatt was honored first place in Startup Wheel 2019.\n\nPurchasingCare, one of our earliest portfolio comepanies, couldn’t make because of the pandemic. We see this as an opportunity to learn and reflect on our model.\n\n**July**\n\nWe welcome Artzy to our portfolio. Artzy is one of a few Vietnamese eCommerce space that revolves around the finer things, like handcraft arkworks.\n\nSince then, multiple products have been built and launched to cater to different needs of users. Artzy has been seeing a steady growth in 2020.\n\n**August**\n\nThe launch of Superbits, our own indie software studio. Superbits’ products are built by us, backed by us, and for tech-loving people like us.\n\n**September**\n\nWe partner with Salt Cancer Initiative (SCI) to build a knowledge and community hub for breast cancer patients across Vietnam.\n\n**October**\n\nWe welcome Wego to our portfolio. Wego is built around the idea of serving quality coffee to the young generations.\n\n**November**\n\nDespite the haywire situation in the US, our portfolio joinPara records stellar development, scoring partnerships with multiple hospital facilities, good numbers of users on the platform and rolling out new products.\n\n**December**\n\nWe deploy a new system for a more robust collaboration with our portfolio companies. Now monthly updates and reports are much easier and faster.\n\nThe last month of the year is dedicated to looking back and learning from our own doing.\n\nAll in all, Fund 0 was not an easy voyage, but it was also very rewarding in terms of learning and adapting.\n\nWe wouldn’t have been able to endure and move forward without the hard work put together everyday by the aspiring founders, our partners, and the team members.Thanks to everyone, our purpose and headway were not lost. Dwarves Ventures is now a reality.\n","title":"Dwarves Ventures Fund 0","short_title":"","description":"It all started when us, a couple of product people realized with our expertise in technology, our passion for outstanding software, we have the ability to uplift like-minded founders by helping them build and launch their startups. The idea became clearer when our network of makers, industry experts and investors broadened steadily.","tags":["ventures","funding","startup","business"],"pinned":false,"draft":false,"hiring":false,"authors":["han","nikki"],"date":"Thu Mar 11 2021 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/fund/dwarves-ventures-fund-0.md","slugArray":["updates","fund","dwarves-ventures-fund-0"]},{"content":"\nIt all started back in 2019 when a handful of tech people came under the name of Dwarves Ventures, with the sole mission was to give force to makers and hustlers.\n\nIn a span of over 2 years, we tested multiple models of investment with 8 portfolio companies. We did make quite a lot of mistakes and questionable decisions, but they soon enough became the guiding light for us to arrive at a structure of investment most beneficent for founders we decide to back.\n\n2021, we are finally confident and ready. Dwarves Ventures is officially on the map with our Fund 1.\n\n### What's going to happen in 2021\nIn 2020, our focus was to help founders build and grow their digital products, while internally clarifying our investment approaches. In 2021, we plan to continue doing so, but with more refinements and upgrades. Each and every of our effort will revolve around the promise of finding and funding more founders to create, launch and grow businesses.\n\n### A laser focus on technology\nWe realize through our pilot fund that with our background as makers, we were able to provide tremendous value when we devote ourselves to the tech space, given our background as tech makers.\n\nFor Fund 1, we will mainly invest in software/tech startups in their early stage, with a laser focus on setting startups to serve their customers and become profitable early on. We are also big on blockchain, but definitely not limited to it.\n\n### Transparent investment options\nRather than a big check which leaves founders having to figure out how to spend effectively, we bring our diverse expertise into the game instead. Typically, we support startups with investments up to $100k while more importantly, we get hands-on and help founders grow in three aspects: digital product, organization, and traction.\n\n### A founder-friendly VC\nWe understand the exhausting process of raising a round. That's why we prefer a more human-centric approach with our funding. We want founders to aim their focus at raising revenue and profit, instead of the next round of funding.\n\nWe have never been big on formality, bureaucracy or hierarchy. No 100-page pitch deck, no multiple meetings, no lengthy email threads. We will get in touch within 5 days, the next steps within 2 weeks, and an assigned representative to answer every question you might have if we decide to deal with you.\n\n### Applications are open all year long\nWe will not have a time frame for application. We welcome new investment opportunities every day of the year until we reach our capacity, and make an announcement about it.\n\n### Network & Community\nSince day 1 of Dwarves Ventures, we have received a massive amount of reach-outs from almost every part of the startup ecosystem, from serial entrepreneurs, founders to industry experts and investors, asking how they could be a part of what we are doing.\n\nOur community of makers is growing steadily, our network of strategic partners and advisors is spreading across verticals and industries. With our official launch, it is only right to put into action a system that maximizes the effectiveness of our network and community.\n\nMakers and founders will have unlimited access to our perks and benefits, connections to experts and advisors, organizational and financial support from our team... just to name a few.\n\nAs a matter of fact, we are always actively [seeking new partners to join us](mailtoteamdwarvesv.com), so we could provide even more value to founders on their path to revenue/profit solidity.\n\n***In fewer words,***\nDwarves Ventures will not be the “here’s a massive check, go do your thing” kind of VCs. We will be the kind of VCs that invest and work together with founders, chasing profitable growth and scale.\n\nDwarves Ventures Fund 1 will mean a lot of hustle and bustle, as we roll out our new approaches and practices. If you want to keep up with us, **[sign up for our newsletter](https://dwarves.ventures/next)**. (We never email unless we have something important and relevant to inform you.)\n\nMore importantly, if what we are doing resonates with you,[we are always ready to talk](mailtoteamdwarvesv.com).\n\nWe have a lot more to share. All updates will be on our website.","title":"Dwarves Ventures Fund 1","short_title":"","description":"In a span of over 2 years, we tested multiple models of investment with 8 portfolio companies.2021, we are finally confident and ready. Dwarves Ventures is officially on the map with our Fund 1.","tags":["funding","ventures","startup","business"],"pinned":false,"draft":false,"hiring":false,"authors":["han","nikki"],"date":"Sun Aug 08 2021 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/fund/dwarves-ventures-fund-1.md","slugArray":["updates","fund","dwarves-ventures-fund-1"]},{"content":"\nHey, it’s Han and Nikki in your inbox again. On behalf of the entire Dwarves team, happy 2022!\n\nFor us 2021 is eventful, and memorable. It was full of changes and challenges, but our can-do mindset made us gritty. While we didn’t have all the answers, we decided to just try and do. As we state in our [Agile Minifesto](https://dwarves.foundation/manifesto): fail fast, learn often, and it's okay to start over.\n\nThe results were beyond our expectation. We got to collaborate with several great clients and partners, including [Setel](http://setel.com), [Momos](http://momos.io), [Mudah](http://mudah.my), [Attrace](http://attrace.com), [SP Group](http://spgroup.com.sg), [Vietcetera](http://vietcetera.com), [WeBuild](http://webuild.community) and many more. We automated most of our operations using Notion, Basecamp and our very own self-built Fortress. We formed a team specialized in blockchain & web3. And along the way, we did everything we can to level up our team.\n\nWe wouldn’t have made it without everyone reading this email right now. So to say, we’re incredibly grateful to you, the one trusting us enough to offer us those dream collaborations, evangelizing our services and participate in helping us scaling and up-leveling our team.\n\n## 2021 - a year of innovative reconstruction, dream collaborations and our journey to be better\n### In numbers\n\n![](assets/2021-in-review-20240312110121546.webp)\n\n### In timeline\n\n![](assets/2021-in-review-20240312110136985.webp)\n\n### More room for like-minded people\nAs long as it's someone who is good at what they do and sees things the same way we do, then it's a yes - we’d love to have you here!\n\nOur people is our greatest asset. That's why most of our effort goes into hiring the right people, giving them our absolute support to grow with us.\n- Reached 60 engineers on the team.\n- Recruited only mid & senior engineers everywhere in Vietnam.\n- More teammates took on leading & mentoring roles\n- Increased compensation and benefits for every Dwarves.\n- Issued Dwarves Token to reward positive contributions.\n- Refined engineering career ladder & mentorship, raising the bar.\n- Facilitated training and learning team-wise.\n\n### Advancing in tech\nThroughout 2021, our bet was on the Web3, the Open Internet, and the next-gen automation software using AI and Big Data.\n- 6+ blockchain-based projects onboard.\n- Blockchain development team reached 20 Dwarves.\n- Active study groups organized by the Dwarves themselves.\n\n### New business directions and new partnerships\nWe’re at a stage where we have the chance to get involved in different kinds of projects. Our new business direction and project decisions brought us to:\n\n- Got bigger partnerships with certain restriction in number of deployed head counts.\n- Shifted gradually from outsourcing to software consulting.\n- Engineers involved in project decisions and hiring for projects.\n- Engineers got to work and deliver as a team.\n\nAlso, now you can visit Dwarves and have a good time at 4 different locations in Vietnam; HCMC, Danang, Hanoi, Dalat.\n\n## So what's in store for 2022?\nAs a profitable and fast-moving company, the possibilities ahead of us are limitless. Dwarves 2.0 for us is about finding a great mix of quality and quantity, and becoming greater at what we are already good at.\n\n- **Doubling down on blockchain & web3**. We are never to stay behind when it comes to tech.\n- **Partnering with even more fantastic teams** and ship more top-notch products. We want to help more and more businesses to be able to leverage technology.\n- **Leveling up**. We are going to be a team that knows how to build software right, and is able to teach others on that.\n- **Scaling up**. We are expanding the team and hope to reach those with the same DNAs. If you know someone who might be interested, send them to **[Dwarves Careers](https://memo.d.foundation/careers/hiring/).**\n\nThat's just a small part in our backlog, we are going to try our hands at many different things.\n\n![](assets/2021-in-review-20240312110210422.webp)\n\n**Here's to many more great products, meaningful partnerships and friendships, experiments and experiences, challenges and opportunities.**\n\nOnward and upward,\n\nHan & Nikki.","title":"It's a wrap: 2021 in Review","short_title":"","description":"Hey, it’s Han and Nikki in your inbox again. On behalf of the entire Dwarves team, happy 2022!","tags":["updates","newsletter","team"],"pinned":false,"draft":false,"hiring":false,"authors":["han","nikki","duy"],"date":"Thu Dec 30 2021 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/newsletter/2021-in-review.md","slugArray":["updates","newsletter","2021-in-review"]},{"content":"It’s Han and Nikki here,\n\nPlus an extra fresh voice we’re bringing to Dwarves Updates, in hope we can offer you more engineering-related insights and thoughts.\n\nIf you’re a part of our Discord server, you probably have noticed #blockchain is our most busy channel. It’s partially because of all the fusses within the crypto scene, but mainly because we’re aggressively learning, experimenting, and evolving on our blockchain expertise.\n\nThe data study group is also getting exciting. We’re seeing more learning notes submitted in our Brainery than ever before, making all the rewards, time and effort we invest in this industry fairly justify.\n\nIn this month's edition, [Thanh Pham](https://www.linkedin.com/in/thanh-pham-466326108/), our engineering manager took the stage. He shares how Dwarves are prepping designers and engineers for the next few years, even the next few decades. So they get the upper hand when trends shift and technologies change.\n\n- Our view on the direction of data\n- Blockchain as a career path for software engineers\n- Learning as the north-star metric\n- Apprenticeship Updates\n\n### Our view on the direction of data.\n2018, our bet was blockchain because we saw its endless possibilities, we weren’t wrong. Since then, we have successfully launched a team of 20 folks, focusing solely on building and shipping awesome blockchain products worldwide.\n\n2022, our bet goes to data. Here are the signals:\n\n- We've been seeing more demand for data engineers and analysts in the market.\n- Data engineers and analysts enjoy a slightly higher paycheck than software engineers.\n- More and more enterprises are making use of big data to achieve business benefits.\n- Smaller businesses are facing the challenge of organizing data such that it can help us better answer business questions.\n\nThese signals mean the data market is full of potential, but the number of good data engineers and analysts is still few and far between.\n\nAs a tech firm, our end-game for data lies in data science, AI, and machine learning. AI and machine learning help disaggregate data through inductive reasoning, find and associate patterns naturally, such as for video depth maps, and let it find ways to train and learn by itself. It’s the perfect combo.\n\nWith the direction set, for months we’ve been prepping research and discussion environments to encourage engineers to take a closer and more novel look at data, every ins and outs.\n\nThe knowledge, experience and insights we learn become talking/discussion points for our **Weekly Radio Talk (Monday 10AM UTC on Dwarves Discord)**.\n\nSince we’re big on sharing, we will also be hosting podcasts for our community, notably to share ideas about data. This is somewhat similar to Rado Talk, except no presentation, just lots of discussions, questions, and some good banter from time to time.\n\nWe hope this casual format will allow us to invite community members to express their thoughts more casually, give us insights that we may have overlooked, and make the topic around data more involved. We’re open to everyone who looks to share and discuss tech, send a ping via [**our Discord**](http://discord.gg/dwarvesv) and we’ll talk asap.\n\n### Blockchain as a career path\nThe blockchain movement shapes up and integrates into every of our business decisions. It all starts with projects, training & team knowledge base.\n\nWe got a chance to sit down with **[Ngoc Thanh](https://www.linkedin.com/in/pham-ngoc-thanh-99626249/), Sr. Blockchain Engineer**. With over 10 years in software development, and has led 5 blockchain projects, his sentiment on blockchain initiates multiple things we do to uplift the team's knowledge base.\n\n> “It no longer stays as a platform where you build and develop an application. Blockchain offers an open platform and foundation to create a decentralized application and its ecosystem. The foundation of blockchain derives from the backend technique. But as time goes by, its potential bypasses all the ongoing notions of software engineering.”\n\nHe stated once people place reliance on blockchain technology and its ability, it grows as a burgeoning software foundation. From what he concepts, blockchain opens other career paths alongside frontend or backend engineering. It's an alternative to exploring and surpassing one's seniority.\n\nCheck out the full read [here](https://memo.d.foundation/careers/apprentice/df-apprenticeship-2022-meet-the-mentors-ngoc-thanh-pham/).\n\nThanh, along with other team leads and senior engineers at Dwarves are looking for talented people to join their squads. Email us at [spawn@d.foundation](mailtospawnd.foundation) if you’re interested in joining them.\n\n### Learning as the north-star metric\nDwarves equal constant learning and sharing. Last month, our theme was Blockchain Concepts and Frontend Guidance.\n\nThe team was having a blast. **June's Brainery sees a 116% input increase compared to May's.** And here's the best thing: We got the first community contributors this time. Pretty dope.\n\nWith **Dwarves Sponsorship**, all contributors receive an appreciation reward from us, for the effort they spent to help grow our knowledge base.\n\n- [Brainery: Service-based Architecture](https://brain.d.foundation/Engineering/Service-based+architecture)\n- [Brainery: Blockchain Oracle](https://brain.d.foundation/Engineering/Blockchain+Oracle)\n- [Brainery: How token works in Solana](https://brain.d.foundation/Blockchain/How+Tokens+Work+on+Solana)\n- [Brainery: NFT Fractionalization](https://brain.d.foundation/Blockchain/NFT+Fractionalization)\n- [Brainery: Blockchain Bridge](https://brain.d.foundation/Blockchain/Blockchain+Bridge)\n- [Brainery: Useeffects double calls in React 18](https://brain.d.foundation/Frontend/useEffect+double+calls+in+React+18)\n- [Brainery: Javascript Modules](https://brain.d.foundation/Frontend/JavaScript+modules)\n- [Brainery: Finite-state Transducer](https://brain.d.foundation/Engineering/Finite-state+transducer), [Mealy machine](https://brain.d.foundation/Engineering/Mealy+machine) and [Moore machine](https://brain.d.foundation/Engineering/Moore+machine)\n- [Brainery: Overview of Domain-driven Design](https://brain.d.foundation/Engineering/Overview+of+Domain+Driven+Design)\n- [Brainery: What Screens Want](https://brain.d.foundation/Engineering/Overview+of+Domain+Driven+Design)\n- [Radio Talk: Engineering an NFT Marketplace](https://www.youtube.com/watch?v=_GEw4qIiex4)\n- [Radio Talk: Build and deploy a Solana dApp](https://www.youtube.com/watch?v=pWNjpvr8U98)\n- [Radio Talk: Mobile UI/UX - How to do it right](https://www.youtube.com/watch?v=MW9o6Q2Zwt4)\n- [Radio Talk: Generics in Go](https://www.youtube.com/watch?v=96bHvQQLaMk)\n- [Radio Talk: Apache Spark](https://www.youtube.com/watch?v=6nini4cmk1E)\n- [Radio Talk: A/B testing in practice](https://www.youtube.com/watch?v=ereZ_HpOkvI)\n\nWe’re always looking to get better for our audience, if you have any feedback or any burning questions for us, hit reply and we’ll do our best.\n\n### Apprenticeship: the drawbacks and the treasure\nWe went from screening over 150 applications to accepting 7 software engineers for the program. After that, it’s all about training and guiding those 7 gems on one thing: [How to build software right](https://bit.ly/3QH3pm4).\n\nOver the span of 4 weeks, we facilitated 15 workshops, which were led by our senior engineers and also invited university professors. We ask for the apprentices’ feedback after every workshop. While the feedback looks generally good, there are drawbacks and we'd love to log them as lessons learned.\n\n- Some presentations were a bit sparse, and some were too long (Mostly because our engineers teach from their real working experience).\n- Some sessions felt incomplete as we didn’t include case studies.\n\nThese problems are rather small, but we’ll vow to fix them and improve ourselves so we can be even more supportive to our apprentices.\n\nOnto the brighter side, our apprentices have been great listeners and doers, which significantly influences their mentors. We treasure that. We can't express how fulfilling it is to see individuals, whom we were in their shoes once, begin to take their first step in creating an impact in society, and of course - our workplace.\n\n![](assets/blockchain-and-data-20240312111132842.webp)\n\n### Launching home-like Dwarves Hubs in Danang and Dalat\nIf you’re tired of being confined within your home office, here’s the good news. **Dwarves Hub in Danang and Dalat is open for everyone**. Think of it as a place where Dwarves and friends can work, hang out, and get to know one another.\n\nAs Dwarves work from anywhere, these little hubs we build across the country serve the only purpose of offering our team a comfy remote experience when they need it.\n\nIf you work remotely and need a change in the working environment, come spend some time with Dwarves. If you still have to come to the office every day, our company is fully remote and [**we’re always hiring**](https://memo.d.foundation/careers/hiring/).\n\nThat's all for now. Until next time,\n\nHan & Nikki.","title":"The future is blockchain and data","short_title":"","description":"Hey, it’s Han and Nikki in your inbox again.","tags":["newsletter","team","updates"],"pinned":false,"draft":false,"hiring":false,"authors":["han","nikki","duy"],"date":"Sun Jun 26 2022 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/newsletter/blockchain-and-data.md","slugArray":["updates","newsletter","blockchain-and-data"]},{"content":"\nHey,\n\nIt's Han and the Dwarves team again. We work as a borderless software firm by crafting world-class products that bring great impacts for various industries.\n\nDwarves Updates notes down how we move toward that goal. You're receiving this because we would love to have you as a part of the journey. It contains our lessons learned, our adoption, our investment in the team, and how we turn those experiences into our client's success.\n\n### We're opening a new office in Da Lat\nWe're software people, we know from day one that great performance and great results come from having the freedom to choose how we work. We wanted the same flexibility for everyone in the team.\n\nSince June 2020, we've been planning on a new office/studio in Da Lat. It's a peaceful highland in the central of Viet Nam. Fresh air, cool weather, little traffic, little noise and outstanding nature. It's the perfect place for work to feel less like work. Now our engineers have one more space they can choose to work at. Be it the comfort of their own home, our headquarter in bustling HCMC, or our new cozy studio in Da Lat.\n\nDuring the pandemic, it became clear that our remote-first approach was definitely working. While other firms had to abruptly transition the entire operation online, the Dwarves sought to improve what we have been doing. Communication with clients got more active, work process got more organized, the team themselves grew closer. A few tweaks here and there, and we were good to go.\n\nBut that isn't the end of it. We understand once remote working turns full-time, caring for our employee well-being will be more vital than ever, especially in an industry as demanding and fast developing as software.\n\n### Which leads us to: upgrading WFH experience\nIt's our second initiative: every team member got a small grant to upgrade their WFH workspace. Not only that it's a chance to give the team what they need to work better, it's also a chance for the team to bond. People seem to love it, We see a lot of fun conversations going around and we are flooded with photos showing off new gears.\n\nWe like to joke within our team that the goal is to make \"every line of code resembles happiness, every software is a happy product\". It's a joke, but it's not far from the truth. With everything we do at Dwarves, we are going after better working conditions, happier employees, hence better work delivery, happier clients.\n\nAs someone who leads and serves a team, I'm convinced taking actions to improve employee well-being is a must, but the outcomes still thrive beyond our expectations. And the astounding thing is that it's not difficult, even the smallest things we can do for our people can yield significant impacts.\n\n![](assets/dalat-office-20240312101752623.webp)\n\nTil next time,\n\nHan & the Dwarves.","title":"Da Lat Office","short_title":"","description":"It's Han and the Dwarves team again. Since June 2020, we've been planning on a new office/studio in Da Lat.","tags":["remote","newsletter","updates"],"pinned":false,"draft":false,"hiring":false,"authors":["han","nikki","duy"],"date":"Sun Jul 11 2021 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/newsletter/dalat-office.md","slugArray":["updates","newsletter","dalat-office"]},{"content":"\nHello,\n\nIt’s Han & Nikki here.\n\nWe have been quite busy with setting up our knowledge system to ensure learning is the top priority for everyone in the team, not just for the management.\n\nHave a look at our [Dwarves Memo](http://memo.d.foundation), and you will see the effort starting to pay off, as more and more members’ names are showing up, more and more articles are being published.\n\nAs you might have known,  AI/LLM has been on our radar for a quite a long time. And the past few months have been all about investing in our AI/LLM competences. It’s been an interesting journey, and we’re excited to fill you in on how things are going.\n\n## Working faster and smarter with AI\nOur entire team, from engineers, and designers to operators, has started using AI tools in our workflows. With this extra brainpower, we now can get things done much faster, and deliver results faster and more accurately.\n\nAI-driven project management tools optimize our workflows, project timelines, as well as, resources. This helps a lot with driving down time and cost in development. We are seeing a cutdown of our design-to-development time by at least 30%, and we bet this number will get bigger in the future.\n\nEspecially for our engineers, it’s like having an extra set of eyes and hands, making sure everything is just right, and fast. AI-powered code generation tools are used to automate repetitive coding tasks, suggest code snippets, find bugs, and help with testing. Lesser human errors, and more mind space impactful tasks. \n\n## Learning and training always\nSince 2015, we have always known that R&D is the engine driving ideas, innovations, and all the other cool stuff in technology.\n\nNow with the focus being AI/LLM, the team is going full speed with learning, training, and building for AI adoption. \n\n- **Large Language Models** like GPT and Claude to tackle all sorts of text-based tasks, from generating content to understanding complex queries\n- **NLP Techniques** to make sense of text with techniques for sentiment analysis and summarization.\n- **Retrieval-Augmented Generation (RAG)** combines multiple methods to improve how we search and retrieve information, making our solutions more effective.\n- **Embedding Technologies** helps enhance content recommendations based on user needs.\n- **AI-Powered Analytics** covers the analytics front by predicting trends, spotting anomalies, and understanding complex data patterns, helping us make informed decisions.\n\nAdditionally, we’re involved in computer vision projects for image recognition and develop multimodal AI systems that combine text and images for more comprehensive solutions.\n\n![](assets/dwarves-agent.png)\n\nWe always share what we learn and train with other tech fellows through Dwarves Memo. \n\n- [Journey of Thought Prompting: Harnessing AI to Craft Better Prompts](https://memo.d.foundation/playground/01_literature/engineering/ai/journey-of-thought-prompting/)\n- [Streamlining Internal Tool Development with Managed LLMOps: A Dify Case Study](https://memo.d.foundation/playground/01_literature/building-llm-powered-tools-with-dify/)\n- [Evaluating search engine in RAG systems](https://memo.d.foundation/playground/01_literature/hybrid-search/)\n- [Rapid software development with AI](https://memo.d.foundation/playground/01_literature/developing-rapidly-with-generative-ai/)\n- [Building Agent Supervisors for Insight Generation](https://memo.d.foundation/playground/01_literature/supervisor-ai-agents/)\n- [Re-ranking in RAG (Retrieval-Augmented Generation)](https://memo.d.foundation/playground/01_literature/engineering/ai/re-ranking-in-rag/)\n- [AI-Powered Interview System](https://memo.d.foundation/playground/01_literature/how-we-created-an-ai-powered-interview-system-using-openais-chatgpt/)\n- [Feedback Mechanisms for LLM Applications](https://memo.d.foundation/playground/01_literature/feedback-mechanism/)\n\n## Building AI-powered solutions\nAI has allowed us to provide solutions that are a bit smarter and more tailored to our client’s needs. It’s about finding practical ways to use technology to support our clients and help them succeed while spending less time and money.\n\n- [FornaxAI](https://fornax.ai): a tool to help startup founders perfect their pitches. It provides instant feedback on content, structure, and design, leading to more compelling presentations and better fundraising outcomes. It even simplifies how investors grade and manage pitch decks.\n- [Umbrella](http://umbrellaconcierge.com): an AI-powered project management tool that integrates real-time task management, chat, and analytics. Built with Serverless NextJS and MongoDB, it’s designed to boost productivity across teams.\n- [Ascenda](http://ascenda.com): an AI and ML loyalty program integrating NLP models, Elastic search, and Kubernetes, we’ve enhanced customer loyalty in innovative ways.\n- [Plot](https://www.plot.so/): a platform centralizing project and asset management for media teams. It uses AI to streamline content handling and collaboration, making the creative process smoother and more efficient.\n\n## Looking ahead\nWe don’t think there are a lot of vendors in Vietnam going the path we’re going. All in all, running the team in the direction of a R&D-focused firm is challenging, but it is also rewarding when we see new developments, new types of requirements coming from prospects, new solutions we receive from our tech team, or a heated debate over a certain new tech on our Discord.\n\nAnd we look for even better results to come, as there are still many things we can make happen. If any of the things we are doing is also what you care about, come collaborate with us, so we can learn, work, experiment, and win together.\n\nThat’s it for now. We hope this small update brings some joy and motivation for the day.\n\nUntil next time,\n\nHan & Nikki.","title":"The Stage of AI and LLM at Dwarves","short_title":"","description":"Here's another update from Dwarves for you. We are excited to share the real journey of growth and transformation since AI and LLM have been on our radar for quite a long time.","tags":["team","updates","newsletter"],"pinned":false,"draft":false,"hiring":false,"authors":["nikki"],"date":"Fri Sep 13 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/newsletter/dwarve-updates-ai-llm.md","slugArray":["updates","newsletter","dwarve-updates-ai-llm"]},{"content":"\nHi, this is Han, the CEO of Dwarves Foundation. This month the Dwarves score 40th client that we have the honor to serve. And for that, we decide to launch the Dwarves Updates.\n\nAs we build this company like we build a product, when we think about this approach, we ask different questions: Do people work here know how to use the company? Is it simple? Is it obvious how it works? Are there bugs? What's broken that we can fix quickly and what's going to take a long time?\n\nA company is like software. It has to be usable, it has to be useful. And it probably also has bugs, places where the company crashes because of bad organizational design or cultural oversights.\n\nDwarves Updates contains what we learned, our tech adoption, our investment in the team, and how we turn those experiences into our client's and partner's success. You're receiving this because we would love to have you as a part of the journey.\n\n### HR: Apprenticeship Training\nIn the past, one of our strategies to acquire talent was to conduct the Internship Program, twice a year when the university students graduate or start looking for real-world experience.\n\nIn 2018 and 2019, with the tailored program for freshers, we hire many of them from top universities in Vietnam. Usually, it's about 150 applicants and filters out 140. That's a good number, but this year we decide to try another program call Apprenticeship.\n\nAs the Internship Program has its cons:\n- It might take an intern 6 months to pick up the pace, and on some consulting projects, they can only help with shadow work. And it brings more management effort to keep the quality up.\n- Second, if it's the first job of interns, they will leave for more experience after 12 or 18 months, even if we want to retain them. It tears down all the efforts that we spend on them.\n\nThe Apprenticeship Program comes from different aspects. Apprenticeship is a total six-month, earn-and-learn training program that we designed for individuals that have at least 1 or 2 years of work experience.\n\n![](assets/dwarves-updates-20240312105331395.webp)\n\nWe promise the same or even better paycheck for candidates and offer them the modern work environment, better experience, a guided career path, peers, and mentors.\n\nThe first launch was hit with fewer applications compared to the Internship one, but we can meet different people with a higher stage of mind and more straightforward goals for their career path. We are trialing simultaneously, so I will let you know if there's anything fun.\n\nFor the detail of the Apprenticeship Program, check out [here](https://memo.d.foundation/careers/apprentice/dwarves-foundation-apprenticeship-batch-of-2022/).\n\nThat's it for the first release. See you next time.\n\nHan & the Dwarves.","title":"Dwarves Updates","short_title":"","description":"Hi, this is Han, the CEO of Dwarves Foundation. This month the Dwarves score 40th client that we have the honor to serve. And for that, we decide to launch the Dwarves Updates.","tags":["hiring","newsletter","updates"],"pinned":false,"draft":false,"hiring":false,"authors":["han","nikki","duy"],"date":"Thu Jun 10 2021 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/newsletter/dwarves-updates.md","slugArray":["updates","newsletter","dwarves-updates"]},{"content":"\nGreetings,\n\nIt's Han and Nikki from Team Dwarves. Time does fly when we get to do something we love. As we keep working on building up the team and producing codes for our clients, we didn't even notice it's already the end of September. Here's another update from Dwarves for you. Throughout September, we have completed our bi-annual performance review.\n\n### How we approach engineer performance review\nWe all have our fair share of performance reviews, be it reviewing others or being reviewed. Saying most of our experience with performance reviews is unpleasant isn't far from the truth.\n\nWe don't want the team at Dwarves having to go through those, so we design our performance reviews around the engineers, instead of management.\n- The engineers reflect on their growth, their point of view on the team and the organization, then share with us through a self-review.\n- We also expect the engineers to have a sense of where they want to go next, in terms of their professional growth.\n- The performance review is conducted by someone who has intimate knowledge about the engineer; their direct team lead, project lead, or mentor. We believe only those who know what the engineer has been up to can give a relevant, specific, and fair review.\n- It's a two-way conversation. We are in no way above engineers just because we're branded \"management\". So we take the back seat, let the engineer feel comfortable enough to share things with us. Then together, we check back on their performance, discuss how they can be even better, celebrate any achievements they have made (a little motivation goes a long way). Everything is laid out as specific as we can be.\n\nOne important thing here is that during these performance reviews, we don't just focus on their execution and technical excellency. We also pay extra attention to their skills in leadership, collaboration, organizational contribution. We want our engineers to be excellent outside their lines of code too, if they want to move upward in their career.\n\n![](assets/engineer-performance-review-20240312105303460.webp)\n\nThe framework we use at Dwarves to set expectations and plan career growth for engineers.\n\nFor every engineer, we hope they stay with us for 3 - 5 years. It's an unspoken mission that during their time at Dwarves, we provide them all the practices and skills they need to be able to build and consult on software development. That's why we set our performance review once every 6 months, enough time for engineers to achieve certain goals.\n\nEngineers should walk out of their performance review with not just new ranks, new numbers, but also a realistic professional goal for the next 6 months, and a high-level plan to achieve that goal. One step closer to their long-term career goals.\n\nWe have been keeping at it for years. Naturally how we do performance review shapes into how we grade engineers as well. For instance, in order to reach the \"senior\" title at Dwarves, an engineer is not only capable of handling the entire cycle of their code (development, test, production, subsequent fixes, and improvements), but also needs to be able to drive execution by organizing works within their team and holding the team accountable.\n\nSome can even say we're a bit strict, but that's how we uphold a high quality bar and keep our promise of delivering great software. That's also how we give support and guidance to the people who make up our team. As we grow and scale, the now engineers will grow into leaders, managers who provide guidance to our next generation of engineers.\n\nThat's it for now. Thank you for reading through.\n\nTil next time,\n\nHan & the Dwarves.","title":"Engineer Performance Review","short_title":"","description":"Here's another update from Dwarves for you. Throughout September, we have completed our bi-annual performance review.","tags":["engineering","performance","newsletter"],"pinned":false,"draft":false,"hiring":false,"authors":["han","nikki","duy"],"date":"Wed Sep 29 2021 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/newsletter/engineer-performance-review.md","slugArray":["updates","newsletter","engineer-performance-review"]},{"content":"\nGreetings,\n\nIt's Han and Nikki from Team Dwarves. We're almost at the end of this year. While we know everyone is busy wrapping up 2021, we hope you're taking care of yourself and staying safe.\n\nRemember last month when we mentioned [refining our engineering ladder](https://memo.d.foundation/handbook/engineering-ladder/)? Executing this one initiative was our main focus for the whole November. With this new way of looking at growth, we hope to be able to expand the team on top of a scalable foundation. First by:\n\n Develop a high-level structure that enables easy scaling of teams or adding new available resources to projects.\n\n- **Some senior engineers were promoted to leads or relevant positions.** Meaning besides the technical excellency, they will also have room to have more impact, influence, and leadership on people, while taking on responsibilities for their teams and the company.\n- **Managers, tech leads, and PMs collaborate with each other to facilitate communication and processes** across teams within the company, making sure everyone knows we're working towards a common purpose which is better engineering.\n- **We also introduce a new engineering 60-day plan for new hires.** In the past, our onboarding process wasn't strictly scheduled, resulting in training and coaching taking longer than expected before a new hire can join a project. We hope with this new 60-day plan, carefully executed and supervised, we can reduce the lag time from demand to supply.\n\nThere's no one engineering organizational structure that fits all. What fits our fast-growing team today might not fit 6 months from now. We'll have to be agile and iterate. But for now, we're pretty well-set for some heavyweight talent acquisition initiatives.\n\n### Some other highlights of November\n**Recruiting team members everywhere in Vietnam**\n\nIn the last few months, we have been hard at work to build offices across the country. It's our first attempt to be able to reach more engineers. Though we're a 100% remote team, we still want to offer engineers a place to work if they feel like it.\n\nSoon with offices in HCMC, Hanoi, Danang & Dalat, we hope to tap into greater pools of Vietnamese talents, growing our team fast and increasing our capacity. These offices are more like hubs, so we welcome our partners, friends, clients, and non-Dwarves techies to come and spend their time there.\n\nPeople in our network can be granted flight tickets to these offices too, just say the word.\n\n![](assets/engineering-org-structure-20240312105149734.webp)\n\nDanang office is looking good.\n\n**Making a name for ourselves in web 3.0 space**\n\nLast month alone, we received 8 requests for partnership in building Web 3.0 products, and a dozen people reaching out for our knowledge and advice.\n\nIf you read our previous issue, you would already know how we screen for new projects during high demand, so we're not gonna talk about that again. We just want to share the good signal, and hope we get to work with you on something in web 3.0 soon. Or if you have friends looking to build something in this space, we'd completely appreciate an into :)\n\nFYI, as we want to drive focus on Web 3.0 without confusing people with our other services, we have a separate website for it [here](https://console.so).\n\n**Foster community, help others win, and get cool perks in the process**\n\n- Opening our Discord channel for the public. [**Join in the conversation**](https://discord.gg/dwarvesv) if you haven't, there are a lot of useful stuff going around.\n- Sponsoring multiple tech events in Vietnam. Vietnam is the starting point, we're excited to connect with tech talents anywhere, not just Vietnam.\n- Public weekly training and knowledge sharing (on Discord too).\n- Coming soon: engage to earn for Dwarves network.\n\n![](assets/engineering-org-structure-20240312105213068.webp)\n\nLast but not least, big thanks to everyone who reads through and reaches out to let us know that they enjoy these snippets of news we send out! We greatly appreciate it.\n\nTil next time,\n\nHan & Team Dwarves.","title":"Engineering Organizational Structure","short_title":"","description":"It's Han and Nikki from Team Dwarves. We're almost at the end of this year. While we know everyone is busy wrapping up 2021, we hope you're taking care of yourself and staying safe.","tags":["updates","newsletter","career"],"pinned":false,"draft":false,"hiring":false,"authors":["han","duy","nikki"],"date":"Wed Dec 01 2021 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/newsletter/engineering-org-structure.md","slugArray":["updates","newsletter","engineering-org-structure"]},{"content":"\nHello, It’s Han & Nikki.\n\nSince you last heard from us, we have been going through a lot of changes. There are both good changes and so-so changes. In this update, we are excited to share the real journey of growth and transformation that our team has embarked upon, as we continue to strive to become a more skilled and knowledgable software team.\n\n- Shifting focus towards techniques\n- Going full-stack engineering\n- Growing a support system for the community\n- Building stronger bonds through collaboration\n- Nurturing relationships for shared success\n\n### Shifting focuses towards techniques\nIt’s a bold decision the team has taken. Our team is investing heavily in research and development focused specifically on techniques that remain steadfast over time. With how fast the software landscape is changing, it is easy to chase the latest, trendy and cool tools out there. But it’s always the fundamental principles and techniques that build skills that last longer. When they understand the core techniques, they can pick the right tools for the job, learn new things easily, and be more creative.\n\n### Going full-stack engineering\nAs we watch the tech landscape closely, it shows that due to the tight economy, more and more businesses look for full-stack engineers to save development cost. Full-stack engineers are expected to understand the entire software development process, from conceptualization to deployment and maintenance.\n\nIt’s only natural that going fulls-stack engineering is also good next step for our engineers. We have always been big on engineers being able to take up more responsibilities and more complex problems.\n\n### Growing a support system for the community\nWe realized if we wanted to build meaningful connections with talented tech people, we needed to share what we are great at with everyone out there first. Therefore, we are moving forward to being 50% company - 50% community.\n\nThe transition is a long run, it takes tremendous time and effort. We wouldn’t have made this much progress without our team members putting in the extra hours outside of the client works. It could be small effort, like answering programming questions from the community members. It could be team effort, like organizing a free Golang course for 30 learners. We are thankful for and encouraged by each one of them. Our community activities have gained significant traction:\n\n- Golang from Basic to Advance course received ~90 registrations, 30 peeps accepted and several fun demos at the end of the course\n- 43 weekly radio talks, featured profound software engineers from around globe\n- 10 tech events, partnered with various other tech communities around Vietnam\n- Our learning site grew x1.5 members\n\nWith more members actively participating and more community members to join hands in various initiatives, we hope this trend will continue and knowledge will spread further.\n\n![](assets/growth-stages-20240312111608204.webp)\n\n### Building stronger bonds through collaboration\nIt wasn’t our intention at first, but pushing toward a 50% company - 50% community model definitely brought the team closer than ever. In a remote working setup like our team, the lack of physical activities make it hard for team bonding.\n\nWith our [**Community Earn model**](https://memo.d.foundation/), [**collaborative R&D**](https://brain.d.foundation/README), and Community Engagement activities in place, we gained back the sense of unity we partly lost due to remote working. Our internal channels on Discord are brewing again, team members feel connected. Especially, we are also seeming clear improvements when our engineers communicate with the clients and their team.\n\n![](assets/growth-stages-20240312111524954.webp)\n\n### Nurturing relationships for shared success\nIn case you forgot, rather than doing outbound marketing and sales, we are more invested in building [our partner network](https://dwarves.foundation/partner)\n\nFor our partners, a relationship with us mean:\n- having a trustworthy team to introduce to businesses in their network who need software development.\n- accessing to other lines of expertises in our network\n- having resources for other activities such as organizing events, summits, etc\n- commission rates based on project scale and longevity\n\nWe have been testing this model since 2020, some partners have been with us for years. Engaging with our partners closely has been showing great potentials. Their support and trust in our team have brought back several projects, expanding our network and opening doors for profit even in challenging times.\n\nWe don’t have much criteria for scouting partners, as long as you care about the impact of technology and have a talent for connecting people, we’re open to have a talk with you to discuss further.\n\nNow that we look back, the past few months for us has been a journey of trialing new ways of doing things, regaining unity and expanding our horizons. We look forward to the next chapter, where we aim to deliver even more remarkable results and build lasting relationships with our team members, community, partners and clients.\n\nThat's all for now. Until next time,\n\nHan and Nikki.","title":"The Stage of Growth at Dwarves","short_title":"","description":"In this update, we are excited to share the real journey of growth and transformation that our team has embarked upon, as we continue to strive to become a more skilled and knowledgable software team.","tags":[],"pinned":false,"draft":false,"hiring":false,"authors":["han","nikki","duy"],"date":"Tue Sep 12 2023 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/newsletter/growth-stages.md","slugArray":["updates","newsletter","growth-stages"]},{"content":"\nHey,\n\nIt’s Han and Nikki, back in your inbox for another Dwarves Updates.\n\nFirst, we are delighted to share that [Dwarves placed top 100 in the Financial Times’ Asia-Pacific High-Growth Company](https://www.linkedin.com/posts/dwarvesf_ft-ranking-asia-pacific-high-growth-companies-activity-6915126757280931840-ayx1).\n\nWhen we hustle daily, sometimes we forget to look back and pat ourselves in the back. This achievement serves as a reminder that we’re pretty darn good at what we’re doing.\n\nHuge appreciation to our team, alongside our friends and partners, we’re lucky to have you move along with us.\n\nIn today’s edition:\n- Job interviews need a makeover\n- The 4 stages of hiring at Dwarves\n- Dwarves Apprenticeship 2022\n- Other talking points\n\n### Job interviews need a makeover\nA few weeks back when preparing for [Dwarves Foundation Apprenticeship 2022](https://memo.d.foundation/careers/apprentice/dwarves-foundation-apprenticeship-batch-of-2022/), we got to rethink the typical interview process in the tech industry. We came across a [Reddit post](https://www.reddit.com/r/WorkReform/comments/th5eou/this_was_the_first_step_in_the_interview_process/) which almost knocked the wind out of us.\n\n![](assets/hiring-stages-20240312110733564.webp)\n\nCandidates were asked to carry out a _written interview_ answering all these questions, right out the door. We didn’t even read through all the questions. We closed the browser tab asap.\n\n#### Interviews should never leave candidates feel like they are begging for a job\nInterviews should make candidates feel they are the ones interviewing their future co-workers and getting to know the environment in which they probably spend their next 2-3 years.\n\nThe way we see it, if our hiring goal is to find talented people to work with us, and not for us, interviews should be casual conversations where equal parties get to find out more about their future collaboration, discuss software and tech, and only things that matter for the job.\n\nWe still consider Dwarves to be a small team (with 70 engineers and designers, and a handful of operating folks), hiring process is an important part for us because we know each person on the team will have a big impact.\n\n#### The 4 stages of hiring at Dwarves\nEven then, it’s not a fixed process. Sometimes when we know that the candidate is a must-have on our team, we don’t mind skipping a step or two.\n\n![](assets/hiring-stages-20240312110815550.webp)\n\n- Tech capability is the north star metric. First and foremost, we want people who will get things done. We can be very challenging when it comes to how well the person will do their job.\n- Minimal commonplace interview questions. Every candidate is well prepared for these questions, and the answers barely help us truly discover the person. We won’t ask what their hobbies are, because it’s probably listening to music, reading books or playing sports.\n- Other engineers will join the interview alongside our hiring managers. Hiring managers won’t work with the candidates on a daily basis, other engineers will. We need their opinions if the candidates are going to be a great add for the team.\n- Candidates are encouraged to ask questions, raise opinions, and leave feedback. Anything that helps them assess if the company fits their career ambitions is important. If we are to spend the next phase of our journeys with each other, might as well make sure we’re going to have a good time doing so.\n\nForm submission: 20 mins, Phone screening: 30 mins, Technical interview: 1 hour. In total: 1 hour 50 mins. That’s it.\n\n### Dwarves Foundation Apprenticeship 2022\n“If you can’t be replaced, you can’t be promoted”, that’s [Dilbert’s Law of Work](http://arith.stanford.edu/gates/dilbert.html) #3.\n\nBeing irreplaceable oftentimes means there is no advancing in our career, we get stuck at one position instead of going up. That’s not “securing a job”, that’s setting ourselves up for burnouts and failures.\n\nIn order for everyone in the team to have the needed guidance to grow and achieve great things with their career, teaching and training is a big part of what we do at Dwarves. Dwarves Apprenticeship is one of the initiatives.\n\nOur first apprenticeship program was last year, making Dwarves the first company in Vietnam offering a proper apprenticeship to tech talents.\n\nWith takeaways from last year, this year we plan to be even better.\n\n![](assets/hiring-stages-20240312110829010.webp)\n\nDwarves Foundation Apprenticeship 2022 is a 6-month fully paid work-study-train program designed to equip mid-level and above software engineers with splendid software practices, strong professional skills, and work ethics.\n\n**For the team at Dwarves,**\n\n- Senior engineers wanting to get into leadership roles will get to further develop their trainer/leader mindset.\n- Squads will be formed in which teammates work together and care for one another’s wellbeing.\n\n**For the apprentices, it’s not going to be a classroom. It’s going to be a real, fully paid job.**\n\n- Strengthen the foundation with software best practices; learn new, interesting tech stack.\n- Get hands-on practical experience by working on real projects, learning the needed skills in a real environment.\n- 1-1 mentorship and clearly defined program schedule to help develop technical skills, soft skills and English communication skills.\n- Work alongside and get support from experienced mentors and teammates.\n- Starting to develop a career path that suits their personal ambitions.\n\nWe are only open for **20** positions to ensure the program's quality. The process has started, and we've already onboarded the first Apprentices.\n\nIf you seek to take a turn in software with a dynamic workplace, to work alongside young teammates of humble spirit and the will to make impactful things happen, we’re open for application **until April 25**.\n\n- [Program Details](https://memo.d.foundation/careers/apprentice/dwarves-foundation-apprenticeship-batch-of-2022/)\n- [Application Form](https://form.typeform.com/to/LfCWfoml)\n\n### Other talking points\n[**Dwarves Discord**](http://discord.gg/dwarvesv) server hits 300 members recently.\n\n- Catching up with the tech peeps who are not (yet) part of our company, is quite cool. Even if our paths can't cross now, we're grateful to have them around for random chats & knowledge sharing.\n- More people are showing up during our Monday Radio Talk. The latest Radio Talk on [Serverless Architecture](https://www.youtube.com/watch?v=x9aBcOzirwg) was definitely a heat debate.\n\n**Dwarves’ Brainery and Engage & Earn are in full effect**\n\n- [Brainery](https://brain.d.foundation) is our knowledge hub, where we what we learn with the world.\n- [Engage & Earn](http://discord.gg/dwarvesv) is our system of recognizing people who put in the effort to share knowledge.\n- Both Brainery and Engage & Earn are open for everyone to join.\n\n**Dalat Chalet is coming very soon**\n\n- While every other company opens offices in Ha Noi or Da Nang because those locations are IT hotspots, we’re ramping up the last final steps of our Dalat Chalet because we’re already 100% remote.\n- It’s going to be a home away from home: to stay, to work, to eat, to drink, to sightsee, to chill, to bond.\n- Dwarves are packing our bags for our very first getaway to Dalat Chalet soon.\n\nMay we continue this year with genuine happiness & success. We hope your codes are flawless, your managers recognize and appreciate you, and that you get to love what you do.\n\nUntil next time,\n\nHan and Nikki.","title":"The stages of hiring at Dwarves","short_title":"","description":"In today’s edition, job interviews need a makeover, the 4 stages of hiring at Dwarves, Dwarves apprenticeship 2022, other talking points","tags":["hiring","newsletter","updates"],"pinned":false,"draft":false,"hiring":false,"authors":["han","nikki","duy"],"date":"Thu Mar 31 2022 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/newsletter/hiring-stages.md","slugArray":["updates","newsletter","hiring-stages"]},{"content":"\nIn an age where Large Language Models like ChatGPT offer instant access to a universe of information, it raises the question: does our own personal knowledge base still hold any value, and is building a personal knowledge base still a legitimate thing to do?\n\n### Capture what matters\n\nWe've come a long way from flipping pages in dusty books to having a world of information just a click away. Now, with AI tools, knowledge is served up in an instant. But here's the kicker: even with all this progress, curating your personal knowledge bank is still crucial.\n\nRemember when you'd compile a mixtape? It was all your favorite tracks, the ones that spoke to you. That's what a personal knowledge base is—your personal mixtape of insights and ideas. AI might offer the top hits, but your collection is uniquely yours.\n\nSure, AI provides quick answers. But how often do you find yourself wading through irrelevant info? Your own knowledge store is like having your favorite book open to the right page—no fluff, just what you need, when you need it. It's efficiency at its finest.\n\nEver notice how reading a book is different from skimming a headline? That's the difference between access and mastery. By curating a personal knowledge base, you're not just gobbling up information—you're digesting it, making it your own, and truly understanding it.\n\n### Connecting the dots\n\nInnovation often sparks when you connect dots others can't see. Your personal knowledge base is where those dots live, waiting for you to draw the lines between them. While AI spits out standard solutions, your tailored insights are the birthplace of creativity.\n\n![linear_regression.png](https://www.explainxkcd.com/wiki/images/9/91/linear_regression.png)\n\nIn a sea of AI-generated content, what stands out? The human touch. Your voice, your perspective. Creating a personal knowledge base ensures your ideas are infused with authenticity, offering a refreshing break from machine-made monotony.\n\nIn a world overflowing with information, it's not just about having it all at your fingertips. It's about owning it, shaping it, and letting it reflect who you are. That's the power of a personal knowledge base.\n\nIn this AI-driven era, maintaining your own knowledge base isn't just smart—it's a game-changer for your growth and success.","title":"Build your knowledge base","short_title":"","description":"In an age where Large Language Models like ChatGPT offer instant access to a universe of information, it raises the question, does our own personal knowledge base still hold any value, and is building a personal knowledge base still a legitimate thing to do?","tags":["knowledge","updates","llm"],"pinned":false,"draft":false,"hiring":false,"authors":["tieubao","nikki"],"date":"Fri Oct 25 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/newsletter/knowledge-base.md","slugArray":["updates","newsletter","knowledge-base"]},{"content":"\nGreetings,\n\nIt's Han and Nikki from Team Dwarves. We're here with the fifth edition of our Dwarves Updates. October has been a wild ride for us as a company. Most of our effort was spent on rethinking growth paths for our engineers.\n\n### The common scenarios with growth for engineers\nGrowth is pretty easy during the first few years; conquer technical skills, discover tools and become proficient in using them, getting things done better and faster.\n\nThen comes that point when growth stalls. It's when the work engineers do every day stops being exciting. They might get faster, but the code quality most likely stays the same - [good enough, perfect is an enemy of good](https://dwarves.foundation/manifesto). The stack stays still, because they only need that much to do the work. One of the easy ways out is to quit, get a new job at a new company. Only for the cycle to repeat itself.\n\nAs a company, we want people to grow and go with us for a long time, so it's our job to ask ourselves: how do we grow our engineers? The answer for us is to constantly provide engineers with new, exciting challenges.\n\n### Redefined engineering career ladder\nEvery company has a career ladder, not all companies actually make use of it. We have to admit, as we get busy with the increasing amount of projects, we did overlook the importance of the engineering career ladder. It's time we took it seriously again.\n\n![](assets/path-to-growth-20240312104656449.webp)\n\nThis career ladder is applied to everyone within the company. We sit down with engineers, define their desired growth path, then design an action plan for it.\n- Junior or mid engineers know what is expected to reach the senior level.\n- Senior engineers understand the company, the nature of the work, the process, now they know what is expected to reach the multiplier level. They can either grow into a master of their craft or a manager, a leader.\n\n### Step into consulting\nEngineers at Dwarves are always encouraged to have ideas, opinions and be free-spoken about them. That's why we believe while consulting is not much about technology or engineering, our engineers would do a good job at consulting. We already got positive words on how our engineers' ideas help clients outside of their scope of work.\n\nWe are currently training a good number of engineers at Dwarves on consulting. There will be a lot of new challenges, seeing problems from a broader perspective, analyzing products from multiple angles, experiencing other fields such as management, marketing, copywriting.\n\n### Learn a new tech\nLearning a new technology is always exciting for our engineers. It's even better when they can do so as a group. We form teams within our team to learn new tech and make stuff with it. We keep tabs on tech trends and make decisions on which tech to invest in based on its potential to impact the future.\n\nOur latest bet is on blockchain, Metaverse, AI & ML. Our blockchain-focused team has been producing some great products, including [Cyber Neko](https://www.pod.town/), LFW.\n\n![](assets/path-to-growth-20240312105235592.webp)\n\n### Screen projects more carefully\nDwarves is at a stage where we have the chance to get involved in different kinds of projects. Good project decisions can bring us to a new high and stimulate engineers to develop.\n\nGenerally, we lean forward on projects that:\n- Solve new, interesting problems\n- Have tech stack we are excellent at, or tech stack we've been learning\n- Allow our engineers to work and deliver as a team\n- Allow our engineers to develop in their roles\n\nMost importantly, our engineers also have a say in the project decisions, as we always discuss with them to understand their view of the project, making sure it's something that they want to be a part of.\n\nThose are just a few initiatives we're currently pushing, there are more in our backlog. Our people are our greatest asset, it's only right that we do whatever we can to make sure when the company grows, its people grow along. The way we see it, devoting to growth is a way to keep engineers engaged and happy. Engaged and happy engineers produce great codes, great codes make great products, great products make clients happy. And if clients are happy, we are happy too.\n\nThat's all for this update. We hope you have a great week ahead.\n\nTil next time,\n\nHan & Team Dwarves.","title":"The Path To Growth at Dwarves","short_title":"","description":"It's Han and Nikki from Team Dwarves. We're here with the fifth edition of our Dwarves Updates. October has been a wild ride for us as a company. Most of our effort was spent on rethinking growth paths for our engineers.","tags":["updates","engineering","newsletter"],"pinned":false,"draft":false,"hiring":false,"authors":["han","nikki","duy"],"date":"Sun Oct 31 2021 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/newsletter/path-to-growth.md","slugArray":["updates","newsletter","path-to-growth"]},{"content":"\nHey,\n\nIt's Han & Nikki from Team Dwarves. This email is the third month we share about our journey to Software Craftsmanship. The last two issues were in June and July. And we received quite a little feedback from our friends and past clients. Thanks for supporting.\n\nThis month, we share about how we do project delivery compliance.\n\n### How we do compliance\nIf there's something that we try to minimize at all costs, it's risks. Risks in software development come at the expense of both our clients and our team. Bigger cost, longer development time, slipping schedules, increasing in working hours, descending team spirit...\n\nThroughout August, the senior team at Dwarves put in the extra time to audit multiple projects. The goal is simple: maximize resource use and increase the success rate of the project.\n\nThat means:\n- Every procedure deemed unnecessary, unproductive needs to go.\n- Identify potential defects and weaknesses early on, so we can act on them asap.\n- Team members have an understanding of the scope of work, objectives, requirements.\n- Progress is on track, we're not holding the client back.\n\nThe technical audit goes top-down from checking if the overall system architecture and database design are appropriate to the nature of the software, to the design of objects and business application servers, to implementation and coding techniques.\n\nThe other part is the management audit, where we focus on not our engineers' performance but also how well aware they are of the software they build and the business they build it for.\n\n![](assets/project-compliance-20240312105356342.webp)\n\n### Lesson learned\nWhile we didn't detect any major technical issues that may seriously harm a project, we found intriguing what we found out during the management audit.\n\n- The importance and success criteria of a project is something that needs to reminding everyone in a while. If the engineers don't feel like they're providing values, it's easy to slip. Our PMs have been instructed on this.\n- Teams that have access to business intelligence are more fond of the software they build. A sense of product ownership allows engineers to put in the extra effort and perform even better.\n- Some of our engineers are showing signs that they can bridge the gap between tech and business challenges. When they discover room for improvements, they're not shy from raising it to the clients and volunteer to take up more responsibilities.\n\nThe last bullet point has us literally over the moon. Because only when engineers perceive what they do in a broader sight (beyond the hard coding) can they be involved further in the software development cycle.\n\nOur ultimate goal is to build and ship software. That starts with our engineers really understanding software. Therefore, we will continue to encourage our engineers to take the initiative and grow beyond their title.\n\nThat's it for the this issue. See you next time.\n\nHan & the Dwarves","title":"Project Compliance","short_title":"","description":"This email is the third month we share about our journey to Software Craftsmanship.","tags":["project","updates","newsletter"],"pinned":false,"draft":false,"hiring":false,"authors":["han","nikki","duy"],"date":"Mon Aug 23 2021 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/newsletter/project-compliance.md","slugArray":["updates","newsletter","project-compliance"]},{"content":"\n## Our vision for growth\nLast Jan 2020, we got the chance to celebrate our first milestone - [Dwarves Foundation reached 5 years old](https://dwarves.foundation/five). The remarkable moment contained the proudest thing we delivered.\n\n* **Remote Culture** - That enables us to make things work without any physical constraints. We were able to focus on what we value: Knowledge and People. To name a few:\n* **[The Handbook](https://dwarves.foundation/radar/)** - To demonstrate our culture, the future we pursue and what portrays the Dwarves.\n* **ESOP** - Once we work toward the same goal, sharing those rewards for the contributors is vital.\n* **Automation Operation** - Automating mundane processes gives us the time and effort to focus on what we do best. The ratio between engineers and operation resources is 70s to 10s.\n\n## Where are we on the succes ladder\nFor these current and upcoming triumphs, it’s an honor for me to call for a small celebration for Dwarves 2.5. - A team of 80s and still thrive to co-create the future using tech.\n\n* 3 remote offices in Saigon, Danang and Dalat.\n* Extend the tech advocates with Techie Story\n* Blockchain Squad\n* [Console Labs](https://console.so/)\n* [Pod Town](https://pod.town/)\n* 46% growth in team scale.\n\nTo step up means to diversify the way we run.\n\n![](assets/the-next-leading-chairs_4d913fb4cbfac771e8b55d79a1855b46_md5.webp)\n\n## Introducing the leading chairs\nWe like the idea of labeling teams by what they deliver. Hence, the next chapter of Dwarves will be based on five angles.\n\n* Partnership, led by Nikki Ngoc Truong: Ensure our tech know-how can bring impact through strategic partners.\n* Delivery, led by Duc Thanh Pham, Ngoc Thanh Pham & Huy Tieu: Ensure our production team ships out quality deliverables.\n* Learning, led by Tom Nguyen & Hieu Vu: Ensure our continuous learning habit is illustrated in different forms.\n* Communication, led by Nikki Ngoc Truong: Ensure our transparent information internally and externally.\n* Engagement, led by Huy Nguyen & Giang Than: Ensure the same vision across teammates despite their function teams.\n\nMy best of applause to have these rising elements for the next phase of Dwarves.\n\n![](assets/the-next-leading-chairs_0b2a2535fa84512ad9d05bd2dc24f3ae_md5.webp)\n\nTil next time,\n\nHan & the Dwarves.","title":"The Next Leading Chairs","short_title":"","description":"We like the idea of labeling teams by what they deliver. Hence, the next chapter of Dwarves will be based on five angles.","tags":["team","updates","newsletter"],"pinned":false,"draft":false,"hiring":false,"authors":["tieubao","duy"],"date":"Fri Aug 26 2022 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/newsletter/the-next-leading-chairs.md","slugArray":["updates","newsletter","the-next-leading-chairs"]},{"content":"\n74 minutes\nRecorded Apr 05, 2024\n\n## Summary\n\nHere's a summary in the requested format:\n\n1. **Meet the Server Owner**: The event kicked off with an introduction to the server owner, known as **econ-101**. This provided an opportunity for everyone to get to know the person behind the server.\n\n2. **Technical Deep Dives**: **Anna** demonstrated how to create a slide from markdown, providing a practical tutorial on an essential skill.\n\n3. **Community and Learning**: **Nikki** presented her work with how research content is pipelined from our community to our memo.\n\n4. **Interactive Components**: **Innno** shared her tips on taking good screenshots, adding a fun and useful interactive component to the event.\n\n5. **Community Engagement**: The event concluded with a **lucky draw** for **Icy**, adding an element of excitement and anticipation.\n\n6. **Future Plans and Strategies**: The organizer aimed to make this a regular event where members could share their learnings within a 10-minute timeframe. This strategy was aimed at fostering knowledge sharing and strengthening the community.\n\n## Recordings\n\n**Going into Deckset with @anna**\n![](assets/1-ogif-office-hours-0405_0405-1_compressed.mp4)\n\n**Quick break and discussion with @han**:\n![](assets/1-ogif-office-hours-0405_0405-2_compressed.mp4)\n\n**Screenshot tips and tools with @innno**:\n![](assets/1-ogif-office-hours-0405_0405-3_compressed.mp4)\n\n**Lifecycle of a publication by @nikki**:\n![](assets/1-ogif-office-hours-0405_0405-4_compressed.mp4)\n\n**Closing remarks and icy rewards**:\n![](assets/1-ogif-office-hours-0405_0405-5_compressed.mp4)\n","title":"OGIF Office Hours #1: Markdown Presentations, Research Content Pipeline, and Professional Screenshots","short_title":"#1 Markdown Presentations, Research Pipeline, Screenshots How-to","description":"Our first ever Office Hours in our series of OGIFs. Our first day to exchange knowledge and insights on topics and projects we're working on and tools we're using for our internal work and clients.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["monotykamary"],"date":"Thu Apr 25 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/1-20240405.md","slugArray":["updates","ogif","1-20240405"]},{"content":"\n77 minutes\n\nRecorded June 14, 2024\n\n**Short Summary for [Office Hours - Behavioral Patterns and Map of Contents](https://www.youtube.com/watch?v=8AmUB9q6hGc)**\n\n\n[00:14](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=14) Discussing the topics of buttons and game making in the team\n\n[07:59](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=479) Introduction to strategic behavior pattern\n\n[13:36](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=816) Using the strategy pattern to handle context and separate implementation\n\n[16:39](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=999) State pattern behavior change based on object state\n\n[21:52](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=1312) Discussing State pattern and Strategy pattern differences\n\n[24:19](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=1459) The State pattern simplifies the handling of different states and behaviors.\n\n[29:23](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=1763) Objects can change behavior based on state.\n\n[31:49](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=1909) Managing State and Logic\n\n[36:43](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=2203) Distinguishing between the use of stage and strategy.\n\n[39:13](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=2353) Different paths lead to same result based on input and state\n\n[46:02](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=2762) Understanding polymorphism in object-oriented programming\n\n[49:11](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=2951) Discussing the need for structuring and organizing work\n\n[55:08](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=3308) Creating a detailed map of content for topics\n\n[57:35](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=3455) Creating a flexible content map for ongoing updates\n\n[1:02:40](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=3760) Encouraging team members to create habits for intelligent content sharing\n\n[1:05:27](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=3927) Building a culture and streamlining the process of posting\n\n[1:10:33](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=4233) Discussion on upgrading process and game planning\n\n[1:13:07](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=4387) Create weekly commentary with news links for team engagement.\n\n---\n\n**Detailed Summary**\n\n[00:14](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=14) Discussing the topics of buttons and game making in the team\n\n- Exploration of continue and buttons on the bbr part, with a focus on game making aspects\n- Mention of upcoming presentation on creating map content and organization processes\n\n[07:59](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=479) Introduction to strategic behavior pattern\n\n- Problem statement involving a famous restaurant and its secret recipe book\n- Proposal to separate the book into parts for different cuisines and assign rights to chefs\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8AmUB9q6hGc?si=5c8r9We8Z0eZ_Odg&amp;start=411\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[13:36](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=816) Using the strategy pattern to handle context and separate implementation\n\n- The strategy pattern allows for choosing a reasonable strategy to handle different contexts\n- Each strategy is independent, allowing the client to separate implementation and decisions\n\n[16:39](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=999) State pattern behavior change based on object state\n\n- Objects behavior changes based on state (e.g., request handling)\n- State machine interactions and transitions\n\n[21:52](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=1312) Discussing State pattern and Strategy pattern differences\n\n- State pattern involves concrete states, implementations, and logic specific to each state\n- Strategy pattern focuses on different actions based on input, without changing states \n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8AmUB9q6hGc?si=g8MfYUpVUDbe-hg-&amp;start=1148\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[24:19](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=1459) The State pattern simplifies the handling of different states and behaviors.\n\n- The State pattern is focused on receiving input and returning output, making it independent of other strategies.\n- It is crucial for a component to be aware of the State pattern to handle state transitions effectively. \n\n[29:23](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=1763) Objects can change behavior based on state.\n\n- Behavioral patterns and map of contents are related to the objects and their state changes.\n- The implementation of these patterns is similar, but they differ in handling states and inputs.\n\n[31:49](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=1909) Managing State and Logic\n\n- Changing State depends on logic and is not related to staying first.\n- State management is crucial for future changes and strategy implementation.\n\n[36:43](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=2203) Distinguishing between the use of stage and strategy.\n\n- The stage is used to determine how it will act, with a clear input stage.\n- The strategy can choose many inputs but the output can only be one.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8AmUB9q6hGc?si=lTBd2AL1wcbn4WuU&amp;start=2085\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[39:13](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=2353) Different paths lead to same result based on input and state\n\n- Behavior differs based on State and Strategy\n- Can change State and Action based on input\n\n[46:02](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=2762) Understanding polymorphism in object-oriented programming\n\n- Polymorphism focuses on transition and containing one thing in the class\n- Differentiating between switching the state and switching the strategy in terms of problem solving\n\n[49:11](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=2951) Discussing the need for structuring and organizing work\n\n- Team pushing hard on writing Memo articles every week\n- Discussing the need for a specialized link for staff in different areas of expertise\n\n[55:08](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=3308) Creating a detailed map of content for topics\n\n- Intermediate nodes linking to child topics for support\n- Organizing and grouping topics into a content map\n\n[57:35](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=3455) Creating a flexible content map for ongoing updates\n\n- Continuously expanding the content map as new notes are added and interacting with related topics\n- Using symbols to denote maps within larger topics and identifying topics for content creation\n\n[1:02:40](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=3760) Encouraging team members to create habits for intelligent content sharing\n\n- Emphasizing the importance of generating content without spamming\n- Outlining the three steps towards achieving a culture of content sharing\n\n[1:05:27](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=3927) Building a culture and streamlining the process of posting\n\n- Discussing the steps involved in building the culture and streamlining the posting process.\n- Exploring the potential increase in the number of Memo numbers and its equivalent in ICY.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8AmUB9q6hGc?si=NcTIUYBhgx3JnqV6&amp;start=3148\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:10:33](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=4233) Discussion on upgrading process and game planning\n\n- Emphasis on smooth transition during upgrade process\n- Team's focus on game planning and execution for upcoming months\n\n[1:13:07](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=4387) Create weekly commentary with news links for team engagement.\n\n- Summarize news links randomly each day for team interaction and engagement.\n- Encourage team to read and discuss important links for awareness and collaboration.\n\n---\n\n**Tóm tắt nội dung [Office Hours - Behavioral Patterns and Map of Contents](https://www.youtube.com/watch?v=8AmUB9q6hGc)**\n\n[00:14](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=14) Thảo luận về các pattern trong game của team\n\n[07:59](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=479) Giới thiệu nội dung chương trình và tổ chức Map of Contents\n\n[13:36](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=816) Sử dụng mẫu chiến lược để xử lý bối cảnh và triển khai riêng biệt\n\n[16:39](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=999) Thay đổi hành vi mẫu trạng thái dựa trên trạng thái đối tượng\n\n[21:52](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=1312) Thảo luận về sự khác biệt của mô hình Nhà nước và mô hình Chiến lược\n\n[24:19](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=1459) Mẫu Trạng thái đơn giản hóa việc xử lý các trạng thái và hành vi khác nhau.\n\n[29:23](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=1763) Các đối tượng có thể thay đổi hành vi dựa trên trạng thái.\n\n[31:49](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=1909) Quản lý trạng thái và logic\n\n[36:43](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=2203) Phân biệt giữa việc sử dụng giai đoạn và chiến lược.\n\n[39:13](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=2353) Các đường dẫn khác nhau dẫn đến cùng một kết quả dựa trên đầu vào và trạng thái\n\n[46:02](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=2762) Hiểu tính đa hình trong lập trình hướng đối tượng\n\n[49:11](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=2951) Thảo luận về sự cần thiết của cơ cấu và tổ chức công việc\n\n[55:08](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=3308) Tạo bản đồ nội dung chi tiết cho các chủ đề\n\n[57:35](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=3455) Tạo bản đồ nội dung linh hoạt để cập nhật liên tục\n\n[1:02:40](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=3760) Khuyến khích các thành viên trong nhóm tạo thói quen chia sẻ kiến thức\n\n[1:05:27](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=3927) Xây dựng văn hóa và hợp lý hóa quy trình đăng bài\n\n[1:10:33](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=4233) Thảo luận về quá trình nâng cấp và lập kế hoạch trò chơi cho summit\n\n[1:13:07](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=4387) Tạo bình luận hàng tuần với các liên kết tin tức để gắn kết nhóm\n\n---\n\n**Tóm tắt chi tiết nội dung**\n\n[00:14](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=14) Thảo luận về chủ đề nút bấ và cách làm game trong team\n\n- Khám phá phần tiếp tục và các nút trên phần bbr, tập trung vào các khía cạnh tạo trò chơi\n- Đề cập đến bài thuyết trình sắp tới về tạo nội dung bản đồ và quy trình tổ chức\n\n[07:59](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=479) Giới thiệu về mô hình hành vi chiến lược\n\n- Tuyên bố vấn đề liên quan đến một nhà hàng nổi tiếng và cuốn sách công thức bí mật của nó\n- Đề xuất tách sách thành nhiều phần dành cho các món ăn khác nhau và giao quyền cho đầu bếp\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8AmUB9q6hGc?si=dlufDzO9Wv2a1A9T&amp;start=558\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[13:36](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=816) Sử dụng mẫu chiến lược để xử lý bối cảnh và triển khai riêng biệt\n\n- Mẫu chiến lược cho phép lựa chọn chiến lược hợp lý để xử lý các bối cảnh khác nhau\n- Mỗi chiến lược đều độc lập, cho phép khách hàng tách biệt việc thực hiện và đưa ra quyết định\n\n[16:39](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=999) Thay đổi hành vi mẫu trạng thái dựa trên trạng thái đối tượng\n\n- Hành vi của đối tượng thay đổi dựa trên trạng thái (ví dụ: xử lý yêu cầu)\n- Tương tác và chuyển đổi máy trạng thái\n\n[21:52](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=1312) Thảo luận về sự khác biệt của mô hình Nhà nước và mô hình Chiến lược\n\n- Mẫu trạng thái bao gồm các trạng thái cụ thể, cách triển khai và logic cụ thể cho từng trạng thái\n- Mẫu chiến lược tập trung vào các hành động khác nhau dựa trên đầu vào mà không thay đổi trạng thái\n\n[24:19](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=1459) Mẫu Trạng thái đơn giản hóa việc xử lý các trạng thái và hành vi khác nhau.\n\n- Mẫu Trạng thái tập trung vào việc nhận đầu vào và trả lại đầu ra, làm cho nó độc lập với các chiến lược khác.\n- Điều quan trọng là một thành phần phải nhận thức được mẫu Trạng thái để xử lý các chuyển đổi trạng thái một cách hiệu quả.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8AmUB9q6hGc?si=MPL3otkhOA5-R1tC&amp;start=1363\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[29:23](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=1763) Các đối tượng có thể thay đổi hành vi dựa trên trạng thái.\n\n- Các mô hình hành vi và bản đồ nội dung có liên quan đến các đối tượng và sự thay đổi trạng thái của chúng.\n- Việc triển khai các mẫu này tương tự nhau nhưng chúng khác nhau về trạng thái xử lý và đầu vào.\n\n[31:49](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=1909) Quản lý trạng thái và logic\n\n- Việc thay đổi Trạng thái phụ thuộc vào logic và không liên quan đến việc ở vị trí đầu tiên.\n- Quản lý nhà nước là rất quan trọng cho những thay đổi trong tương lai và thực hiện chiến lược.\n\n[36:43](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=2203) Phân biệt giữa việc sử dụng giai đoạn và chiến lược.\n\n- Giai đoạn được sử dụng để xác định cách nó sẽ hoạt động, với giai đoạn đầu vào rõ ràng.\n- Chiến lược có thể chọn nhiều đầu vào nhưng đầu ra chỉ có thể là một.\n\n[39:13](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=2353) Các đường dẫn khác nhau dẫn đến cùng một kết quả dựa trên đầu vào và trạng thái\n\n- Hành vi khác nhau tùy theo Trạng thái và Chiến lược\n- Có thể thay đổi Trạng thái và Hành động dựa trên đầu vào\n\n[46:02](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=2762) Hiểu tính đa hình trong lập trình hướng đối tượng\n\n- Đa hình tập trung vào quá trình chuyển đổi và chứa một thứ trong lớp\n- Phân biệt giữa chuyển trạng thái và chuyển chiến lược trong giải quyết vấn đề\n\n[49:11](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=2951) Thảo luận về sự cần thiết của cơ cấu và tổ chức công việc\n\n- Nhóm đang nỗ lực viết bài Memo mỗi tuần\n- Thảo luận về sự cần thiết của liên kết chuyên biệt giữa các nhân viên ở các lĩnh vực chuyên môn khác nhau\n\n[55:08](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=3308) Tạo bản đồ nội dung chi tiết cho các chủ đề\n\n- Các nút trung gian liên kết đến các chủ đề con để được hỗ trợ\n- Tổ chức và nhóm các chủ đề thành bản đồ nội dung\n\n[57:35](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=3455) Tạo bản đồ nội dung linh hoạt để cập nhật liên tục\n\n- Liên tục mở rộng bản đồ nội dung khi thêm ghi chú mới và tương tác với các chủ đề liên quan\n- Sử dụng các ký hiệu để biểu thị bản đồ trong các chủ đề lớn hơn và xác định chủ đề để tạo nội dung\n\n[1:02:40](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=3760) Khuyến khích các thành viên trong nhóm tạo thói quen chia sẻ nội dung thông minh\n\n- Nhấn mạnh tầm quan trọng của việc tạo nội dung mà không gửi thư rác\n- Vạch ra ba bước để đạt được văn hóa chia sẻ nội dung\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8AmUB9q6hGc?si=-fjEvKB-5ZSs-z7W&amp;start=3608\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:05:27](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=3927) Xây dựng văn hóa và hợp lý hóa quy trình đăng bài\n\n- Thảo luận về các bước liên quan đến việc xây dựng văn hóa và hợp lý hóa quy trình đăng bài.\n- Khám phá khả năng tăng số lượng Bản ghi nhớ và số tương đương trong IC.\n\n[1:10:33](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=4233) Thảo luận về quá trình nâng cấp và lập kế hoạch trò chơi\n\n- Nhấn mạnh vào quá trình chuyển đổi suôn sẻ trong quá trình nâng cấp\n- Nhóm tập trung vào việc lập kế hoạch và thực hiện trò chơi trong những tháng tới\n\n[1:13:07](https://www.youtube.com/watch?v=8AmUB9q6hGc&t=4387) Tạo bình luận hàng tuần với các liên kết tin tức để gắn kết nhóm.\n\n- Tổng hợp các link tin tức ngẫu nhiên mỗi ngày để nhóm tương tác và gắn kết.\n- Khuyến khích mọi người đọc và thảo luận các chủ đề mới. \n","title":"OGIF Office Hours #10 -  Behavioral Patterns and Map Content Organization","short_title":"#10 Behavioral Patterns and Map Content Organization","description":"Join us for our tenth office hours session to discuss behavioral design patterns and effective map content organization! We'll also catch you up on important June updates. Bring your questions and ideas, we want to hear from you.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Fri Jun 28 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/10-20240614.md","slugArray":["updates","ogif","10-20240614"]},{"content":"\n82 minutes\n\nRecorded June 21, 2024\n\n**Short Summary for [Office Hours: Template Method + Visitor and Radix Sort](https://www.youtube.com/watch?v=6FWqu1G7FLA)**\n\nThe template method, visitor, and radix sort are discussed in an office hours session on the Dwarves Foundation YouTube channel.\n\n[00:03](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3) Discussion on team size and performance metrics.\n\n[06:13](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=373) Using IC to encourage participation and motivation\n\n[11:28](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=688) Announcement of upcoming changes and events\n\n[14:12](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=852) Discussion on team activities and new team shirts\n\n[19:19](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=1159) Discussion on recent events and experiences in attending startup events\n\n[21:50](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=1310) Invest in long-term segments like healthtech and education.\n\n[26:33](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=1593) Discussing upcoming activities and market analysis\n\n[28:33](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=1713) Minh Le's talked about startup event and his observation.\n\n[33:55](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=2035) Using the template method pattern to solve code optimization and shared operations\n\n[37:35](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=2255) Template method allows customization without affecting main flow.\n\n[44:03](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=2643) Template Method defines common framework for operations\n\n[48:37](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=2917) Visitor Design Pattern combines business logic for processing data from different classes in one place.\n\n[53:37](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3217) Visitor interface for data manipulation.\n\n[56:12](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3372) Template Method + Visitor pattern simplifies adding features and maintaining single responsibility.\n\n[1:01:14](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3674) Explanation of Template Method and Visitor pattern\n\n[1:04:22](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3862) Understanding the process of creating a common object based on customer needs\n\n[1:11:12](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=4272) Demonstrating the Template Method and Visitor design patterns\n\n[1:14:00](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=4440) Discussion on the Visitor pattern and file operations\n\n[1:20:13](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=4813) Discussion on interface between seller and buyer\n\n---\n\n**Detailed Summary**\n\n[00:03](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3) Discussion on team size and performance metrics.\n\n- Team currently has 50 members with recent performance statistics shared.\n- Plans to discuss easy topics first before moving on to main agenda.\n\n[06:13](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=373) Using ICY to encourage participation and motivation\n\n- It is important to be active, watch tutorials, and engage with the community to earn rewards like ICY.\n- Token distribution and community engagement are key aspects discussed during the session.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/6FWqu1G7FLA?si=AfmRFMaHJJukwHG3&amp;start=423\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[11:28](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=688) Announcement of upcoming changes and events\n\n- Discussing increasing salaries and upcoming changes within the community\n- Mentioning plans for game development and future team activities\n\n[14:12](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=852) Discussion on team activities and new team shirts\n\n- Team planning a game in July with a summer theme.\n- Introduction of new team shirt designs and materials with unique logos.\n\n[19:19](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=1159) Discussion on recent events and experiences in attending startup events\n\n- Exploring the shift in attitudes towards startup events and insights gained from recent experiences\n- Observations on the changing dynamics and engagement levels in startup events, especially focused on women in Vietnam\n\n[21:50](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=1310) Invest in long-term segments like healthtech and education.\n\n- Consider opportunities in health and education sectors for long-term investments.\n- Explore potential opportunities in fintech and finance aside from conventional industries.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/6FWqu1G7FLA?si=ZJ2PFkxG-En9bftR&amp;start=1227\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[26:33](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=1593) Discussing upcoming activities and market analysis\n\n- Planning for specific assignments based on branch sizes and market trends\n- Emphasizing the importance of continuous learning and collaboration within the team\n\n[28:33](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=1713) Minh Luu's discussion sharing link is the best\n\n- Discusses the growth and evolution of a discord server over time, from its creation to optimization strategies\n- Highlights the technical aspects such as maintaining live connections, sockets, and scaling issues\n\n[33:55](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=2035) Utilizing the template method pattern to improve code structure and reusability\n\n- Template method pattern divides operations into small steps shared between classes for common functionalities.\n- Custom implementations for unique operations, allowing for clear visualization and structure.\n\n[37:35](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=2255) Template method allows customization without affecting main flow.\n\n- Base class defines common steps, allowing customization without affecting main flow\n- Limitations include strict control over order and structure, potential for redundant code\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/6FWqu1G7FLA?si=pKdkwmXd-eAZVmm6&amp;start=2030\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[44:03](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=2643) Template Method defines common framework for operations\n\n- It allows people to implement the interface and can be forced to override, mandatory to implement, or optionally override\n- It enables implementations and children to expand without affecting the predetermined structure\n\n[48:37](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=2917) Visitor Design Pattern combines business logic for processing data from different classes in one place.\n\n- It is a behavioral design pattern that centralizes logic processing and data combination.\n- Helps in addressing the problem of distributed requirements and compound logic.\n\n[53:37](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3217) Visitor interface for data manipulation.\n\n- Visitor interface allows different logic based on each object's data.\n- Using Visitor can centralize data access and manipulation for easier maintenance and feature addition.\n\n[56:12](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3372) Template Method + Visitor pattern simplifies adding features and maintaining single responsibility.\n\n- Extending and modifying classes becomes easier without affecting subclasses.\n- Focus on core data and implement according to pattern for efficient development.\n\n[1:01:14](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3674) Explanation of Template Method and Visitor pattern\n\n- Creating a class to classify objects based on data\n- Applying an operation to a group of objects with similar concepts but different data types\n\n[1:04:22](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3862) Understanding the process of creating a common object based on customer needs\n\n- The algorithm involves combining needs of customers to create a common object\n- Separating selling and buying actions for effective implementation\n\n[1:11:12](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=4272) Demonstrating the Template Method and Visitor design patterns\n\n- Explaining the features and interface of the Template Method design pattern in detail\n- Discussing the Visitor design pattern and its multiple Visitor approach for processing data\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/6FWqu1G7FLA?si=NJi1GkLNNo8qEgLc&amp;start=3690\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:14:00](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=4440) Discussion on the Visitor pattern and file operations\n\n- The video discusses the use of the Visitor pattern in file operations\n- It also talks about the elements and actions involved in the process\n\n[1:20:13](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=4813) Discussion on interface between seller and buyer\n\n- Explaining the concept of Visitor pattern in object-oriented design\n- Discussing the relevance of Radix Sort in the context of data sorting\n\n---\n\n**Tóm tắt nội dung [Office Hours: Template Method + Visitor and Radix Sort](https://www.youtube.com/watch?v=6FWqu1G7FLA)**\n\nPhương pháp mẫu, khách truy cập và sắp xếp cơ số được thảo luận trong phiên làm việc theo giờ hành chính trên kênh YouTube của Tổ chức Người lùn.\n\n[00:03](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3) Thảo luận về quy mô nhóm và số liệu hiệu suất.\n\n[06:13](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=373) Sử dụng ICY để khuyến khích sự tham gia và động lực\n\n[11:28](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=688) Thông báo về những thay đổi và sự kiện sắp tới\n\n[14:12](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=852) Thảo luận về hoạt động của đội và áo đội mới\n\n[19:19](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=1159) Thảo luận về các sự kiện gần đây và kinh nghiệm tham dự sự kiện khởi nghiệp\n\n[21:50](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=1310) Đầu tư vào các phân khúc dài hạn như công nghệ y tế và giáo dục.\n\n[26:33](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=1593) Thảo luận về các hoạt động sắp tới và phân tích thị trường\n\n[28:33](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=1713) Minh Lê chia sẻ về quan sát và những thu thập sau khi tham gia event\n\n[33:55](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=2035) Sử dụng mẫu phương thức mẫu để giải quyết tối ưu hóa mã và các hoạt động chia sẻ\n\n[37:35](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=2255) Phương thức mẫu cho phép tùy chỉnh mà không ảnh hưởng đến luồng chính.\n\n[44:03](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=2643) Phương thức mẫu xác định khuôn khổ chung cho các hoạt động\n\n[48:37](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=2917) Mẫu thiết kế khách truy cập kết hợp logic nghiệp vụ để xử lý dữ liệu từ các lớp khác nhau ở một nơi.\n\n[53:37](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3217) Giao diện khách truy cập để thao tác dữ liệu.\n\n[56:12](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3372) Phương thức mẫu + Mẫu khách truy cập đơn giản hóa việc thêm các tính năng và duy trì trách nhiệm duy nhất.\n\n[1:01:14](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3674) Giải thích về Phương pháp Mẫu và Mẫu khách truy cập\n\n[1:04:22](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3862) Tìm hiểu quy trình tạo đối tượng chung dựa trên nhu cầu của khách hàng\n\n[1:11:12](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=4272) Trình diễn Phương pháp mẫu và mẫu thiết kế của khách truy cập\n\n[1:14:00](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=4440) Thảo luận về mẫu khách truy cập và thao tác tệp\n\n[1:20:13](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=4813) Thảo luận về giao diện giữa người bán và người mua\n\n---\n\n**Tóm tắt chi tiết nội dung**\n\n[00:03](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3) Thảo luận về quy mô nhóm và số liệu hiệu suất.\n\n- Nhóm hiện có 50 thành viên với số liệu thống kê hiệu suất gần đây được chia sẻ.\n- Lên kế hoạch thảo luận các chủ đề dễ dàng trước khi chuyển sang chương trình chính.\n\n[06:13](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=373) Sử dụng ICY để khuyến khích sự tham gia và động lực\n\n- Trong Chế độ của, mọi người sẽ có quyền lực, thúc đẩy sự tham gia và tương tác trong kênh.\n- Khen thưởng và khuyến khích các hoạt động nhằm khuyến khích sự tham gia và phát triển của cộng đồng.\n\n[11:28](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=688) Thông báo về những thay đổi và sự kiện sắp tới\n\n- Thảo luận về tăng lương và sự tham gia của cộng đồng\n- Kế hoạch phát triển trò chơi trong tương lai và tổ chức sự kiện mùa hè\n\n[14:12](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=852) Thảo luận về hoạt động của đội và áo đội mới\n\n- Nhóm tạo Kênh về hoạt động hè\n- Công bố áo đội tuyển mới với thiết kế độc đáo\n\n[19:19](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=1159) Thảo luận về các sự kiện gần đây và kinh nghiệm tham dự sự kiện khởi nghiệp\n\n- Khám phá sự thay đổi trong thái độ đối với các sự kiện khởi nghiệp và những hiểu biết sâu sắc thu được từ những trải nghiệm gần đây\n- Quan sát về động lực thay đổi và mức độ tham gia trong các sự kiện khởi nghiệp, đặc biệt tập trung vào phụ nữ ở Việt Nam\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/6FWqu1G7FLA?si=nlEUSvEgG04Jah44&amp;start=1253\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[21:50](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=1310) Đầu tư vào các phân khúc dài hạn như công nghệ y tế và giáo dục.\n\n- Xem xét các cơ hội đầu tư dài hạn trong lĩnh vực y tế và giáo dục.\n- Khám phá các cơ hội tiềm năng trong lĩnh vực công nghệ tài chính và tài chính ngoài các ngành công nghiệp thông thường.\n\n[26:33](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=1593) Thảo luận về các hoạt động sắp tới và phân tích thị trường\n\n- Lập kế hoạch cho các nhiệm vụ cụ thể dựa trên quy mô chi nhánh và xu hướng thị trường\n- Nhấn mạnh tầm quan trọng của việc học hỏi và hợp tác liên tục trong nhóm\n\n[28:33](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=1713) Sharing của Minh Lưu là ổn nhất\n\n- Xu hướng bất hòa này đã diễn ra kể từ khi bắt đầu với nhiều máy chủ và kênh đang hoạt động.\n- Link của Minh Lưu trở nên nổi tiếng sau khi ban đầu bị đánh giá thấp nhưng sau đó nhanh chóng được nhân rộng.\n\n[33:55](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=2035) Sử dụng mẫu phương thức mẫu để giải quyết tối ưu hóa mã và các hoạt động chia sẻ\n\n- Mẫu phương thức mẫu chia các hoạt động thành các bước nhỏ và thực hiện các bước chung trong lớp cơ sở.\n- Triển khai tùy chỉnh được sử dụng cho các bước thay đổi tùy theo điều kiện, trực quan hóa việc triển khai và cấu trúc.\n\n[37:35](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=2255) Phương thức mẫu cho phép tùy chỉnh mà không ảnh hưởng đến luồng chính.\n\n- Lớp cơ sở kiểm soát trật tự và cấu trúc nên khó thay đổi.\n- Các lớp con thực hiện các bước, có nguy cơ dẫn đến kết quả sai nếu sử dụng sai.\n\n[44:03](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=2643) Phương thức mẫu xác định khuôn khổ chung cho các hoạt động\n\n- Nó cho phép mọi người triển khai giao diện với các tùy chọn để ghi đè các phương thức.\n- Phương thức này phải được đưa vào thao tác chính, cho phép thực hiện và mở rộng mà không ảnh hưởng đến cấu trúc.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/6FWqu1G7FLA?si=0xo5gHEmu5pkEtW5&amp;start=2739\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[48:37](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=2917) Mẫu thiết kế khách truy cập kết hợp logic nghiệp vụ để xử lý dữ liệu từ các lớp khác nhau ở một nơi.\n\n- Mẫu khách truy cập là một mẫu thiết kế hành vi.\n- Nó cho phép kết hợp logic nghiệp vụ và xử lý dữ liệu của các lớp khác nhau một cách hiệu quả.\n\n[53:37](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3217) Giao diện khách truy cập để thao tác dữ liệu.\n\n- Giao diện khách truy cập cho phép logic khác nhau dựa trên dữ liệu của từng đối tượng.\n- Việc sử dụng Khách truy cập có thể tập trung quyền truy cập và thao tác dữ liệu để bảo trì và bổ sung tính năng dễ dàng hơn.\n\n[56:12](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3372) Phương thức mẫu + Mẫu khách truy cập đơn giản hóa việc thêm các tính năng và duy trì trách nhiệm duy nhất.\n\n- Việc mở rộng và sửa đổi các lớp trở nên dễ dàng hơn mà không ảnh hưởng đến các lớp con.\n- Tập trung vào dữ liệu cốt lõi và triển khai theo mẫu để phát triển hiệu quả.\n\n[1:01:14](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3674) Giải thích về Phương pháp Mẫu và Mẫu khách truy cập\n\n- Tạo lớp phân loại đối tượng dựa trên dữ liệu\n- Áp dụng một thao tác cho một nhóm đối tượng có khái niệm tương tự nhưng có kiểu dữ liệu khác nhau\n\n[1:04:22](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=3862) Tìm hiểu quy trình tạo đối tượng chung dựa trên nhu cầu của khách hàng\n\n- Thuật toán liên quan đến việc kết hợp nhu cầu của khách hàng để tạo ra một đối tượng chung\n- Tách biệt hành động mua và bán để thực hiện hiệu quả\n\n[1:11:12](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=4272) Trình diễn Phương pháp mẫu và mẫu thiết kế của khách truy cập\n\n- Giải thích chi tiết các tính năng và giao diện của mẫu thiết kế Phương thức Mẫu\n- Thảo luận về mẫu thiết kế Khách truy cập và cách tiếp cận nhiều Khách truy cập để xử lý dữ liệu\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/6FWqu1G7FLA?si=AxD2F2gDTQGRQvOJ&amp;start=4193\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:14:00](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=4440) Thảo luận về mẫu khách truy cập và thao tác tệp\n\n- Video thảo luận về việc sử dụng mẫu Khách truy cập trong các thao tác với tệp\n- Nó cũng nói về các yếu tố và hành động liên quan đến quá trình\n\n[1:20:13](https://www.youtube.com/watch?v=6FWqu1G7FLA&t=4813) Thảo luận về giao diện giữa người bán và người mua\n\n- Giải thích khái niệm mẫu Visitor trong thiết kế hướng đối tượng\n- Thảo luận về sự liên quan của Radix Sort trong bối cảnh sắp xếp dữ liệu\n","title":"OGIF Office Hours #11 - Design patterns: template method & visitor, Radix sort, and weekly tech commentary","short_title":"#11 Design patterns: template method & visitor, Radix sort, and weekly tech commentary","description":"Join us for our evleventh community discussion on design patterns (Template Method and Visitor), Radix Sort, and the latest tech news. The discussion will be guided by weekly topics selected through community input, fostering a collaborative learning environment for all participants.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Sat Jun 29 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/11-20240621.md","slugArray":["updates","ogif","11-20240621"]},{"content":"\n66 minutes\n\nRecorded June 28, 2024\n\n**Short Summary for [Community Call - June](https://www.youtube.com/watch?v=01-1bj_DOO8)**\n\n[00:03](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3) Discussing progress and learning achievements\n\n[05:48](https://www.youtube.com/watch?v=01-1bj_DOO8&t=348) Discussion about internal tuning and updates\n\n[09:50](https://www.youtube.com/watch?v=01-1bj_DOO8&t=590) Updates on upcoming events and focus areas\n\n[12:05](https://www.youtube.com/watch?v=01-1bj_DOO8&t=725) Engagement rewards with ICY points\n\n[15:57](https://www.youtube.com/watch?v=01-1bj_DOO8&t=957) Update about ICY implementation for new opportunities and learning\n\n[17:46](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1066) Encourage community members to join research and learning activities\n\n[21:44](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1304) Discussing pros and cons of using user Spaces like BBGGrof\n\n[23:24](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1404) Event driven logic in program execution\n\n[26:56](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1616) Grab applies three key services\n\n[28:45](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1725) Discussion on Go profiling techniques\n\n[33:25](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2005) Programs in Sona are similar to smart contracts on other blockchains.\n\n[35:22](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2122) Understanding the concept of injection in programming\n\n[39:34](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2374) Discussing server crash and its impact\n\n[41:48](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2508) Discussion on handling transactions in ABM system\n\n[46:33](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2793) Updating and sharing knowledge through a new system\n\n[48:14](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2894) Multimodal data can include images, audio, video, and tables in PDFs.\n\n[51:18](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3078) Discussing the usage of chatbot and providing guidance on data input for better understanding\n\n[53:00](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3180) Use of PR to provide necessary images for understanding data.\n\n[56:47](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3407) Managing old records and feedback\n\n[58:44](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3524) Discussing test cases and evaluation of an app\n\n[1:02:35](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3755) Discussing career development and team operations\n\n[1:03:52](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3832) Discussing project operations and team support\n\n---\n\n**Detailed Summary**\n\n[00:03](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3) Discussing progress and learning achievements\n\n- Reviewing the accomplishments of the past month and sharing new knowledge within the community\n- Reinforcing knowledge through research, note-taking, and team collaboration to meet increasing demand\n- Aim to enhance team positioning to meet market demands\n- Emphasis on documenting and sharing knowledge within the team and the wider community\n\n[05:48](https://www.youtube.com/watch?v=01-1bj_DOO8&t=348) Discussion about internal tuning and updates\n\n- Updates on Dwarves activities and memos for the past week and month\n- Highlights of major discussion topics such as Go updates, blockchain research, and technical optimizations\n- Mention of a new machine learning method and how team discussions could aid in interview preparations\n\n[09:50](https://www.youtube.com/watch?v=01-1bj_DOO8&t=590) Updates on upcoming events and focus areas\n\n- Updates on upcoming events and focus areas in machine learning, not qualifying, and upcoming events in the next month\n- Focus on LLM, blockchain, and Go for the next month and upcoming events\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/01-1bj_DOO8?si=cmRLcGqF3375CoV-&amp;start=597\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[12:05](https://www.youtube.com/watch?v=01-1bj_DOO8&t=725) Engagement rewards with ICY points\n\n- Policies and rewards explained by Huy Nguyen\n- Introduction of new ways to earn ICY points through activities like writing Fleeting Notes\n\n[15:57](https://www.youtube.com/watch?v=01-1bj_DOO8&t=957) Update about ICY implementation for new opportunities and learning\n\n- ICY implementation for creating new opportunities and learning\n- Top performers in the team will also receive ICY\n\n[17:46](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1066) Encourage community members to join research and learning activities\n\n- Community members are invited to participate in research and learning activities\n- Participants will receive ICY similar to team members\n\n[19:29](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1169) Weekly Go updates including optimization techniques\n\n- Insights from Go Weekly number 510 on optimization techniques like BPF (Berkeley Packet Filter) and feedback-directed optimization\n- Explanation of profiling and performance assessment using tools available in Go\n- Benefits and challenges of the discussed optimization methods, including BPF and Go's feedback-directed optimization\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/01-1bj_DOO8?si=_0ZWtSiVnXXEVRmY&amp;start=1206\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[21:44](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1304) Discussing pros and cons of using user Spaces like BBG Grof\n\n- Editing the cal source is difficult but can be done\n- Creating a new module is more practical but requires security precautions\n\n[23:24](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1404) Event driven logic in program execution\n\n- Program logic combined and checked by verifier and compiler to generate machine instructions\n- bbf profile filer provides comprehensive profiling for large scale systems\n\n[26:56](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1616) Grab applies three key services\n\n- Services include Man database image, orchestrated complex system, and mono integration\n- The biggest improvement seen in image builds, while orchestrated setups are more challenging\n\n[28:45](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1725) Discussion on Go profiling techniques\n\n- Exploring the use of profiling tools in Go programming\n- Importance of thorough system profiling for performance optimization\n\n[30:00](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1800) Introduction to Solana blockchain concepts\n\n- Detailed explanation of Solana's efficiency, capability to handle fast transactions, and low costs\n- Overview of core concepts such as accounts, programs, transactions, and program-derived addresses (PDA)\n- Description of how Solana differs from other blockchains, particularly in handling data and program execution\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/01-1bj_DOO8?si=f6mfZa_MtLDhD-s9&amp;start=1886\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[33:25](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2005) Programs in Solana are similar to smart contracts on other blockchains\n\n- They contain executable code and do not store data, which is instead stored in separate accounts for execution and data manipulation\n- Instructions in programs allow for interaction and help Solana handle transactions quickly and in parallel\n\n[35:22](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2122) Understanding the concept of injection in programming\n\n- Injection in programming is a specific action to execute logic on data\n- It includes program address, access codes, and data for execution\n\n[39:34](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2374) Discussing server crash and its impact\n\n- Exploring the reasons behind server crashes and network downtime\n- Analyzing the concept introduction and its contribution to server stability\n\n[41:48](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2508) Discussion on handling transactions in ABM system\n\n- Explanation of how mem transactions are processed in ABM system\n- Impact of using different frameworks on transaction execution\n\n[45:18](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2718) Demonstration of how to work with multimodal data using LangChain\n\n- Challenges in handling multimodal data that includes text, images, audio, and tables.\n- Introduction to a technique called Multimodal EO (Embedding and Optimization) to handle diverse data types\n- Workflow for data ingestion, using pre-trained models to summarize and embed the content, then storing it in a vector database\n- Demonstration of a chatbot application that can understand and respond based on embedded multimodal data from documents\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/01-1bj_DOO8?si=kkTf9_Fi8Z02XtfO&amp;start=2875\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[46:33](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2793) Updating and sharing knowledge through a new system\n\n- Introducing a system to support knowledge transfer between individuals\n- Using vector calculations and cosine distance to provide relevant information to user queries\n\n[48:14](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2894) Multimodal data can include images, audio, video, and tables in PDFs.\n\n- Techniques like multimodal data help in extracting and managing diverse data types\n- Tools like Python libraries can be used to extract information from documents and videos\n\n[51:18](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3078) Discussing the usage of chatbot and providing guidance on data input for better understanding\n\n- Using visual aids like images and charts in a PDF format to improve comprehension for chatbot training\n- Guidance on data input methods to ensure chatbot understands the information correctly\n\n[53:00](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3180) Use of PR to provide necessary images for understanding data.\n\n- Using PR to request and provide relevant images for understanding data\n- Explaining the importance of helping the machine understand the data for effective communication\n\n[56:47](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3407) Managing old records and feedback\n\n- Discussing handling feedback and referencing in old records\n- Exploring options like reindexing or creating new data to track changes\n\n[58:44](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3524) Discussing test cases and evaluation of an app\n\n- Covers generating test cases and determining pass percentage\n- Additional topic mentioned: evaluating an app and credibility of metrics\n\n[1:02:35](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3755) Discussing career development and team operations\n\n- Exploring opportunities for growth such as consulting or project management\n- Meeting the increasing demand for full teams in business analysis, project management, and technology\n- Encouragement for the team to apply discussed techniques and participate in upcoming events.\n- Reminder of reward systems in place for active participation and contributions.\n- Open floor for questions and suggestions on enhancing team activities and research topics.\n\n[1:03:52](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3832) Closing remarks and next steps\n\n- Mention of ongoing and upcoming projects, including opportunities for team members to take on more responsibilities\n- Emphasis on continuous learning and knowledge sharing within the team to handle new verticals and domains\n- Call to action for team members to get involved and contribute to the team's growth and project success\n\n---\n\n**Tóm tắt nội dung [Community Call - June](https://www.youtube.com/watch?v=01-1bj_DOO8)**\n\n\n[00:03](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3) Thảo luận về tiến độ và thành tích học tập\n\n[05:48](https://www.youtube.com/watch?v=01-1bj_DOO8&t=348) Thảo luận về điều chỉnh và cập nhật nội bộ\n\n[09:50](https://www.youtube.com/watch?v=01-1bj_DOO8&t=590) Cập nhật về các sự kiện sắp tới và các lĩnh vực trọng tâm\n\n[12:05](https://www.youtube.com/watch?v=01-1bj_DOO8&t=725) Phần thưởng tương tác bằng điểm ICY\n\n[15:57](https://www.youtube.com/watch?v=01-1bj_DOO8&t=957) Cập nhật về việc triển khai ICY để có cơ hội và học tập mới\n\n[17:46](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1066) Khuyến khích các thành viên cộng đồng tham gia các hoạt động nghiên cứu và học tập\n\n[21:44](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1304) Thảo luận về ưu và nhược điểm của việc sử dụng Không gian người dùng như BBGGrof\n\n[23:24](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1404) Logic điều khiển sự kiện trong thực thi chương trình\n\n[26:56](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1616) Grab áp dụng 3 dịch vụ chủ đạo\n\n[28:45](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1725) Thảo luận về kỹ thuật lập hồ sơ Go\n\n[33:25](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2005) Các chương trình trong Solana tương tự như hợp đồng thông minh trên các blockchain khác.\n\n[35:22](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2122) Hiểu khái niệm về tiêm trong lập trình\n\n[39:34](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2374) Thảo luận về sự cố máy chủ và tác động của nó\n\n[41:48](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2508) Thảo luận xử lý giao dịch trong hệ thống ABM\n\n[46:33](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2793) Cập nhật và chia sẻ kiến thức thông qua hệ thống mới\n\n[48:14](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2894) Dữ liệu đa phương thức có thể bao gồm hình ảnh, âm thanh, video và bảng biểu trong tệp PDF.\n\n[51:18](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3078) Thảo luận cách sử dụng chatbot và hướng dẫn nhập dữ liệu để hiểu rõ hơn\n\n[53:00](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3180) Sử dụng PR để cung cấp hình ảnh cần thiết cho việc hiểu dữ liệu.\n\n[56:47](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3407) Quản lý hồ sơ cũ và phản hồi\n\n[58:44](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3524) Thảo luận về các trường hợp thử nghiệm và đánh giá ứng dụng\n\n[1:02:35](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3755) Thảo luận về phát triển nghề nghiệp và hoạt động nhóm\n\n[1:03:52](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3832) Thảo luận về hoạt động của dự án và hỗ trợ nhóm\n\n---\n\n**Tóm tắt chi tiết**\n\n[00:03](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3) Thảo luận về tiến độ và những thành tựu học hỏi\n\n- Điểm lại và đánh giá các hoạt động của tháng trước và chia sẻ kiến thức mới trong cộng đồng\n- Củng cố kiến thức thông qua nghiên cứu, ghi chép, và hợp tác nhóm để đáp ứng nhu cầu ngày càng tăng\n- Mục tiêu là nâng cao vị thế của team để đáp ứng nhu cầu thị trường\n- Nhấn mạnh việc ghi chép và chia sẻ kiến thức trong nhóm và cộng đồng rộng hơn\n\n[05:48](https://www.youtube.com/watch?v=01-1bj_DOO8&t=348) Thảo luận về điều chỉnh và cập nhật nội bộ\n\n- Cập nhật các hoạt động của Dwarves và các ghi chú trong tuần và tháng vừa qua\n- Điểm lại các chủ đề thảo luận chính như cập nhật Go, nghiên cứu blockchain và tối ưu hóa kỹ thuật.\n- Đề cập đến phương pháp học máy mới và cách thảo luận nhóm có thể hỗ trợ trong việc chuẩn bị phỏng vấn\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/01-1bj_DOO8?si=FdMJuuRaKPm5w1SQ&amp;start=259\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[09:50](https://www.youtube.com/watch?v=01-1bj_DOO8&t=590) Cập nhật về các sự kiện sắp tới và các lĩnh vực trọng điểm\n\n- Cập nhật về các sự kiện sắp tới và các lĩnh vực trọng điểm trong học máy, không đủ tiêu chuẩn và các sự kiện sắp tới trong tháng tới\n- Tập trung vào LLM, blockchain và Go cho tháng tới và các sự kiện sắp tới\n\n[12:05](https://www.youtube.com/watch?v=01-1bj_DOO8&t=725) Phần thưởng tham gia với ICY\n\n- Chính sách và phần thưởng được giải thích bởi Huy Nguyễn\n- Giới thiệu các cách mới để kiếm điểm ICY thông qua các hoạt động như viết Fleeting Notes\n\n[15:57](https://www.youtube.com/watch?v=01-1bj_DOO8&t=957) Cập nhật về việc triển khai ICY cho các cơ hội mới và học tập\n\n- Triển khai ICY để tạo ra các cơ hội mới và học tập\n- Những người có thành tích cao trong đội cũng sẽ nhận được ICY\n\n[17:46](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1066) Khuyến khích các thành viên cộng đồng tham gia các hoạt động nghiên cứu và học tập\n\n- Mời các thành viên cộng đồng tham gia các hoạt động nghiên cứu và học tập\n- Người tham gia sẽ nhận được ICY tương tự như các thành viên trong đội\n\n[19:29](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1169) Cập nhật hàng tuần về Go bao gồm các kỹ thuật tối ưu hóa\n\n- Thông tin từ Go Weekly số 510 về các kỹ thuật tối ưu hóa như BPF (Berkeley Packet Filter) và tối ưu hóa dựa trên phản hồi\n- Giải thích về việc tạo hồ sơ và đánh giá hiệu suất sử dụng các công cụ có sẵn trong Go\n- Lợi ích và thách thức của các phương pháp tối ưu hóa đã thảo luận, bao gồm BPF và tối ưu hóa dựa trên phản hồi của Go\n\n[21:44](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1304) Thảo luận về ưu và nhược điểm của việc sử dụng Spaces người dùng như BBG Grof\n\n- Chỉnh sửa nguồn cal rất khó nhưng có thể thực hiện được\n- Tạo một module mới thực tế hơn nhưng đòi hỏi các biện pháp bảo mật\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/01-1bj_DOO8?si=tEMU5VF0-xpFQApM&amp;start=1604\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[23:24](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1404) Logic điều khiển sự kiện trong thực thi chương trình\n\n- Logic chương trình được kết hợp và kiểm tra bởi verifier và compiler để tạo ra các lệnh máy\n- BPF profile filer cung cấp hồ sơ toàn diện cho các hệ thống quy mô lớn\n\n[26:56](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1616) Grab áp dụng ba dịch vụ chính\n\n- Các dịch vụ bao gồm cơ sở dữ liệu hình ảnh Man, hệ thống phức hợp được điều phối và tích hợp mono\n- Cải tiến lớn nhất được thấy trong việc xây dựng hình ảnh, trong khi các thiết lập điều phối gặp nhiều thách thức hơn\n\n[28:45](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1725) Thảo luận về các kỹ thuật tạo hồ sơ trong Go\n\n- Khám phá việc sử dụng các công cụ tạo hồ sơ trong lập trình Go\n- Tầm quan trọng của việc tạo hồ sơ hệ thống kỹ lưỡng để tối ưu hóa hiệu suất\n\n[30:00](https://www.youtube.com/watch?v=01-1bj_DOO8&t=1800) Giới thiệu các khái niệm blockchain cốt lõi của Solana\n\n- Giải thích chi tiết về hiệu quả của Solana, khả năng xử lý các giao dịch nhanh chóng và chi phí thấp\n- Tổng quan về các khái niệm cốt lõi như tài khoản, chương trình, giao dịch và địa chỉ chương trình được tạo ra (PDA)\n- Mô tả cách Solana khác với các blockchain khác, đặc biệt trong việc xử lý dữ liệu và thực thi chương trình\n\n[33:25](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2005) Các chương trình trong Solana tương tự như các hợp đồng thông minh trên các blockchain khác\n\n- Chúng chứa mã thực thi và không lưu trữ dữ liệu, dữ liệu thay vào đó được lưu trữ trong các tài khoản riêng biệt để thực thi và thao tác dữ liệu\n- Các lệnh trong các chương trình cho phép tương tác và giúp Solana xử lý các giao dịch nhanh chóng và song song\n\n[35:22](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2122) Hiểu khái niệm về tiêm trong lập trình\n\n- Tiêm trong lập trình là một hành động cụ thể để thực thi logic trên dữ liệu\n- Nó bao gồm địa chỉ chương trình, mã truy cập và dữ liệu để thực thi\n\n[39:34](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2374) Thảo luận về sự cố máy chủ và tác động của nó\n\n- Khám phá các lý do đằng sau sự cố máy chủ và thời gian ngừng hoạt động của mạng\n- Phân tích việc giới thiệu khái niệm và sự đóng góp của nó đối với sự ổn định của máy chủ\n\n[41:48](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2508) Thảo luận xử lý giao dịch trong hệ thống ABM\n\n- Giải thích cách xử lý giao dịch mem trong hệ thống ABM\n- Tác động của việc sử dụng các khung khác nhau trong việc thực hiện giao dịch\n\n[46:33](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2793) Cập nhật và chia sẻ kiến thức thông qua hệ thống mới\n\n- Giới thiệu hệ thống hỗ trợ chuyển giao kiến thức giữa các cá nhân\n- Sử dụng phép tính vectơ và khoảng cách cosine để cung cấp thông tin liên quan cho truy vấn của người dùng\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/01-1bj_DOO8?si=xyPFqtEkAxrE5490&amp;start=2768\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[48:14](https://www.youtube.com/watch?v=01-1bj_DOO8&t=2894) Dữ liệu đa phương thức có thể bao gồm hình ảnh, âm thanh, video và bảng biểu trong tệp PDF\n\n- Các kỹ thuật như dữ liệu đa phương thức giúp trích xuất và quản lý các loại dữ liệu đa dạng.\n- Các công cụ như thư viện Python có thể được sử dụng để trích xuất thông tin từ tài liệu và video.\n\n[51:18](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3078) Thảo luận cách sử dụng chatbot và hướng dẫn nhập dữ liệu để hiểu rõ hơn\n\n- Sử dụng các phương tiện trực quan như hình ảnh và biểu đồ ở định dạng PDF để nâng cao khả năng hiểu cho việc đào tạo chatbot\n- Hướng dẫn cách nhập dữ liệu để đảm bảo chatbot hiểu đúng thông tin\n\n[53:00](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3180) Sử dụng PR để cung cấp hình ảnh cần thiết cho việc hiểu dữ liệu\n\n- Sử dụng PR để yêu cầu và cung cấp hình ảnh có liên quan để hiểu dữ liệu.\n- Giải thích tầm quan trọng của việc giúp máy hiểu dữ liệu để giao tiếp hiệu quả.\n\n[56:47](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3407) Quản lý hồ sơ cũ và phản hồi\n\n- Thảo luận xử lý các ý kiến phản hồi và tham khảo hồ sơ cũ.\n- Khám phá các tùy chọn như lập chỉ mục lại hoặc tạo dữ liệu mới để theo dõi các thay đổi.\n\n[58:44](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3524) Thảo luận về các trường hợp thử nghiệm và đánh giá ứng dụng\n\n- Bao gồm việc tạo các trường hợp thử nghiệm và xác định tỷ lệ phần trăm đạt\n- Chủ đề bổ sung được đề cập: đánh giá một ứng dụng và độ tin cậy của các số liệu\n\n[1:02:35](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3755) Thảo luận về phát triển sự nghiệp và hoạt động nhóm\n\n- Khám phá các cơ hội phát triển như tư vấn hoặc quản lý dự án.\n- Đáp ứng nhu cầu ngày càng tăng về các nhóm hoàn chỉnh trong phân tích kinh doanh, quản lý dự án và công nghệ.\n- Khuyến khích nhóm áp dụng các kỹ thuật đã thảo luận và tham gia vào các sự kiện sắp tới.\n- Nhắc nhở về các hệ thống phần thưởng dành cho sự tham gia và đóng góp tích cực.\n- Mở phiên hỏi đáp cho các câu hỏi và đề xuất nhằm nâng cao hoạt động nhóm và các chủ đề nghiên cứu.\n\n[1:03:52](https://www.youtube.com/watch?v=01-1bj_DOO8&t=3832) Các cập nhật sắp tới\n\n- Đề cập đến các dự án đang thực hiện và sắp tới, bao gồm các cơ hội cho các thành viên trong nhóm đảm nhận thêm trách nhiệm.\n- Nhấn mạnh việc học tập liên tục và chia sẻ kiến thức trong nhóm để xử lý các lĩnh vực và lĩnh vực mới.\n- Kêu gọi các thành viên trong nhóm tham gia và đóng góp vào sự phát triển của nhóm và sự thành công của dự án.\n","title":"OGIF Office Hours #12 - Community June updates, Project progress, Go Weekly: Mastering Go Performance - eBPF and PGO Optimization Techniques, Multimodal in RAG (Retrieval Augmented Generation)","short_title":"#12 June updates, Go Performance, eBPF, PGO, Multimodal RAG","description":"In June community call, we kicked off with an introduction to the themes for knowledge reinforcement. We provide a summary of recent activities and topics, including blockchain, optimization, and news updates. Weekly Go updates cover optimization techniques, followed by an introduction to Solana blockchain concepts. The session concludes with a demonstration on handling multimodal data using LangChain.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Mon Jul 08 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/12-20240628.md","slugArray":["updates","ogif","12-20240628"]},{"content":"\n57 minutes\n\nRecorded July 08, 2024\n\n\n**Short Summary for [Office Hours: How to effectively chat with ChatGPT, Understanding LLM Feedback, and more](https://www.youtube.com/watch?v=fwkklrYeCqo)**\n\n[00:03](https://www.youtube.com/watch?v=fwkklrYeCqo&t=3) Discussion on new programming language compared to Go\n\n[04:05](https://www.youtube.com/watch?v=fwkklrYeCqo&t=245) Introduction to available iterators in Go with next method\n\n[09:59](https://www.youtube.com/watch?v=fwkklrYeCqo&t=599) Understanding functions and logic in programming\n\n[13:06](https://www.youtube.com/watch?v=fwkklrYeCqo&t=786) Discussing the impact of using specific packages in code development\n\n[19:23](https://www.youtube.com/watch?v=fwkklrYeCqo&t=1163) Explaining the importance of 'O(nk)' as the maximum number of digits.\n\n[21:50](https://www.youtube.com/watch?v=fwkklrYeCqo&t=1310) Discussion on comparing and analyzing numbers\n\n[26:46](https://www.youtube.com/watch?v=fwkklrYeCqo&t=1606) Importance of feedback in improving ChatGPT's responses\n\n[29:41](https://www.youtube.com/watch?v=fwkklrYeCqo&t=1781) Understanding LLM Feedback and User Behaviors\n\n[35:23](https://www.youtube.com/watch?v=fwkklrYeCqo&t=2123) Discussing feedback mechanism in dataset creation\n\n[38:55](https://www.youtube.com/watch?v=fwkklrYeCqo&t=2335) Using ChatGPT effectively\n\n[45:47](https://www.youtube.com/watch?v=fwkklrYeCqo&t=2747) Understanding the importance of specific terminology in effective communication\n\n[48:18](https://www.youtube.com/watch?v=fwkklrYeCqo&t=2898) Writing clear examples and providing detailed instructions\n\n[53:58](https://www.youtube.com/watch?v=fwkklrYeCqo&t=3238) Importance of providing context and personalization\n\n---\n\n**Detailed Summary**\n\n[00:03](https://www.youtube.com/watch?v=fwkklrYeCqo&t=3) Discussion on new programming language compared to Go\n\n- Overview of the new language similar to Go, called Odin, created by a known figure\n- Exploration of Go's limitations with for Range function lacking generic way for user-written types\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fwkklrYeCqo?si=YtY-bo-xWv_54h03&amp;start=154\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[04:05](https://www.youtube.com/watch?v=fwkklrYeCqo&t=245) Introduction to available iterators in Go with next method\n\n- Discussion about using the next method to iterate through frames and check for presence using a lazy Bull\n- Overview of proposed iterate package in Go with two types x and x 2 for key-value pair sequences\n\n[09:59](https://www.youtube.com/watch?v=fwkklrYeCqo&t=599) Understanding functions and logic in programming\n\n- Demonstrating ways to print values and manipulate logic in programming functions\n- Discussions around iterating through different types and internal structures in programming\n\n[13:06](https://www.youtube.com/watch?v=fwkklrYeCqo&t=786) Discussing the impact of using specific packages in code development\n\n- Talking about the potential impact on existing code and packages if changes are made\n- Exploring the use of generators and iterators in relation to production code\n\n[14:39](https://www.youtube.com/live/fwkklrYeCqo?si=m75GNIMzoD3a6UJv&t=878) Explanation and demo of Radix Sort and its efficiency\n\n- Introduction to the Radix Sort algorithm and its benefits over other sorting algorithms.\n- Detailed step-by-step walkthrough on how the Radix Sort works, including how it sorts digits from least significant to most significant.\n- Time and space complexity analysis of Radix Sort - generally O(nk) with n being number of items and k being the number of digits.\n- Explanation on handling specific cases such as floating-point numbers and negative numbers in Radix Sort.\n\n[19:23](https://www.youtube.com/watch?v=fwkklrYeCqo&t=1163) Explaining the importance of 'O(nk)' as the maximum number of digits.\n\n- Discussing the implications of 'O(nk)' when dealing with large numbers and complexity.\n- Explaining the application of stable sort in sorting integers and strings efficiently.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fwkklrYeCqo?si=ubOY7DwNP7yzWpH9&amp;start=906\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[21:50](https://www.youtube.com/watch?v=fwkklrYeCqo&t=1310) Discussion on comparing and analyzing numbers\n\n- Explanation of the maximum number of digits of a number and examples\n- Comparison of effectiveness of algorithms in handling large numbers\n\n[26:46](https://www.youtube.com/watch?v=fwkklrYeCqo&t=1606) Importance of feedback in improving ChatGPT's responses\n\n- Feedback helps in avoiding hallucinations and improving data accuracy\n- Feedback from humans leads to fine-tuning for better model responses\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fwkklrYeCqo?si=LnwEvkirP57Tcz-1&amp;start=1666\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[29:41](https://www.youtube.com/watch?v=fwkklrYeCqo&t=1781) Understanding LLM Feedback and User Behaviors\n\n- Regenerate feature allows for creating new responses if initial ones feel inappropriate.\n- User feedback collection involves manual implicit feedback and database design for storing feedback.\n\n[35:23](https://www.youtube.com/watch?v=fwkklrYeCqo&t=2123) Discussing feedback mechanism in dataset creation\n\n- Importance of clear feedback for dataset creation\n- Explanation of why human feedback is essential to improve chatbot models, reducing hallucinations and irrelevant responses\n- Details on implicit and explicit feedback types, including regenerating responses, double-checking facts, stopping generation, liking/disliking, and rating responses.\n- Database design for storing feedback data, ensuring the feedback is stored with relevant context and user information.\n- Consideration of different perspectives in evaluating feedback\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fwkklrYeCqo?si=w5Oxcx5Im2oAVa92&amp;start=2103\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[38:55](https://www.youtube.com/watch?v=fwkklrYeCqo&t=2335) Using ChatGPT effectively\n\n- Utilize ChatGPT for part of essay writing and document generation to save time.\n- Understand the input process output model and the importance of providing quality input for better output.\n\n[45:47](https://www.youtube.com/watch?v=fwkklrYeCqo&t=2747) Understanding the importance of specific terminology in effective communication\n\n- Explaining the significance of terms like 'prompt' and 'personal statement' in communication context\n- Discussion on creating effective prompts for ChatGPT by providing context, specifying the role of both the prompt creator and the expected reader, and including sample outputs.\n- Detailing the need for context, direction, and reader specificity in communication for different audiences\n\n[48:18](https://www.youtube.com/watch?v=fwkklrYeCqo&t=2898) Writing clear examples and providing detailed instructions\n\n- Examples on how detailed and clear prompts lead to better and more useful responses from ChatGPT.\n- Providing clear and detailed samples for others to follow\n- Ensuring that tasks are solved in a detailed and effective way\n- Tips on evaluating the responses and iterating on prompts to refine outputs for specific needs.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fwkklrYeCqo?si=E0gvG4_4xXJ0FCUT&amp;start=2832\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[53:58](https://www.youtube.com/watch?v=fwkklrYeCqo&t=3238) Importance of providing context and personalization\n\n- Context and personalization are essential for effective communication.\n- A template is available for editing and providing context.\n\n[55:09](https://www.youtube.com/live/fwkklrYeCqo?si=7gXV0s8_M7tnf1X1&t=3306) Conclusion and open Q&A session\n\n- Summary of key takeaways from all the discussions.\n- Participants ask questions and presenters provide additional clarifications on discussed topics.\n- Encouragement to apply discussed techniques and feedback mechanisms in real-world projects.\n\n---\n\n**Tóm tắt ngắn nội dung**\n\n[00:03](https://www.youtube.com/watch?v=fwkklrYeCqo&t=3) Thảo luận về ngôn ngữ lập trình mới so với Go\n\n[04:05](https://www.youtube.com/watch?v=fwkklrYeCqo&t=245) Giới thiệu về các trình vòng lặp có sẵn trong Go với phương thức tiếp theo\n\n[09:59](https://www.youtube.com/watch?v=fwkklrYeCqo&t=599) Tìm hiểu hàm và logic trong lập trình\n\n[13:06](https://www.youtube.com/watch?v=fwkklrYeCqo&t=786) Thảo luận về tác động của việc sử dụng các gói cụ thể trong phát triển mã\n\n[19:23](https://www.youtube.com/watch?v=fwkklrYeCqo&t=1163) Giải thích tầm quan trọng của 'O(nk)' là số chữ số tối đa.\n\n[21:50](https://www.youtube.com/watch?v=fwkklrYeCqo&t=1310) Thảo luận về so sánh và phân tích các con số\n\n[26:46](https://www.youtube.com/watch?v=fwkklrYeCqo&t=1606) Tầm quan trọng của phản hồi trong việc cải thiện phản hồi của ChatGPT\n\n[29:41](https://www.youtube.com/watch?v=fwkklrYeCqo&t=1781) Hiểu phản hồi LLM và hành vi người dùng\n\n[35:23](https://www.youtube.com/watch?v=fwkklrYeCqo&t=2123) Thảo luận về cơ chế phản hồi trong tạo tập dữ liệu\n\n[38:55](https://www.youtube.com/watch?v=fwkklrYeCqo&t=2335) Sử dụng ChatGPT hiệu quả\n\n[45:47](https://www.youtube.com/watch?v=fwkklrYeCqo&t=2747) Hiểu tầm quan trọng của thuật ngữ cụ thể trong giao tiếp hiệu quả\n\n[48:18](https://www.youtube.com/watch?v=fwkklrYeCqo&t=2898) Viết ví dụ rõ ràng và cung cấp hướng dẫn chi tiết\n\n[53:58](https://www.youtube.com/watch?v=fwkklrYeCqo&t=3238) Tầm quan trọng của việc cung cấp bối cảnh và cá nhân hóa\n\n---\n**Tóm tắt chi tiết**\n\n[00:03](https://www.youtube.com/watch?v=fwkklrYeCqo&t=3) Thảo luận về ngôn ngữ lập trình mới so với Go\n\n- Tổng quan về ngôn ngữ mới tương tự Go, gọi là Odin, được tạo bởi một nhân vật nổi tiếng\n- Khám phá những hạn chế của Go với hàm for Range thiếu cách chung cho các kiểu do người dùng viết\n\n[04:05](https://www.youtube.com/watch?v=fwkklrYeCqo&t=245) Giới thiệu về các iterator có sẵn trong Go với phương pháp next\n\n- Thảo luận về việc sử dụng phương pháp next để lặp qua các khung và kiểm tra sự hiện diện bằng lazy Bull\n- Tổng quan về gói iterate đề xuất trong Go với hai kiểu x và x 2 cho các chuỗi cặp key-value\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fwkklrYeCqo?si=ETXS72nNKU8MyYu9&amp;start=314\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[09:59](https://www.youtube.com/watch?v=fwkklrYeCqo&t=599) Hiểu về các hàm và logic trong lập trình\n\n- Minh họa cách in các giá trị và thao tác logic trong các hàm lập trình\n- Thảo luận về việc lặp qua các loại khác nhau và cấu trúc nội bộ trong lập trình\n\n[13:06](https://www.youtube.com/watch?v=fwkklrYeCqo&t=786) Thảo luận về tác động của việc sử dụng các gói cụ thể trong phát triển mã\n\n- Nói về tác động tiềm năng lên mã hiện có và các gói nếu có sự thay đổi\n- Khám phá việc sử dụng các generator và iterator liên quan đến mã sản xuất\n\n[14:39](https://www.youtube.com/live/fwkklrYeCqo?si=m75GNIMzoD3a6UJv&t=878) Giải thích và demo thuật toán Radix Sort và hiệu quả của nó\n\n- Giới thiệu thuật toán Radix Sort và lợi ích của nó so với các thuật toán sắp xếp khác\n- Hướng dẫn từng bước cách hoạt động của Radix Sort, bao gồm cách sắp xếp các chữ số từ ít quan trọng nhất đến quan trọng nhất\n- Phân tích thời gian và không gian của Radix Sort - thường là O(nk) với n là số mục và k là số chữ số\n- Giải thích cách xử lý các trường hợp cụ thể như số dấu phẩy động và số âm trong Radix Sort\n\n[19:23](https://www.youtube.com/watch?v=fwkklrYeCqo&t=1163) Giải thích tầm quan trọng của 'O(nk)' là số chữ số tối đa\n\n- Thảo luận về những tác động của 'O(nk)' khi xử lý các số lớn và độ phức tạp\n- Giải thích ứng dụng của sắp xếp ổn định trong việc sắp xếp số nguyên và chuỗi hiệu quả\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fwkklrYeCqo?si=v5hG8I20XnHXLipk&amp;start=1084\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[21:50](https://www.youtube.com/watch?v=fwkklrYeCqo&t=1310) Thảo luận về việc so sánh và phân tích các con số\n\n- Giải thích số chữ số tối đa của một số và ví dụ\n- So sánh hiệu quả của các thuật toán trong việc xử lý các số lớn\n\n[26:46](https://www.youtube.com/watch?v=fwkklrYeCqo&t=1606) Tầm quan trọng của phản hồi trong việc cải thiện phản hồi của ChatGPT\n\n- Phản hồi giúp tránh các ảo giác và cải thiện độ chính xác của dữ liệu\n- Phản hồi từ con người dẫn đến việc tinh chỉnh để có các phản hồi tốt hơn từ mô hình\n\n[29:41](https://www.youtube.com/watch?v=fwkklrYeCqo&t=1781) Hiểu về phản hồi của LLM và hành vi người dùng\n\n- Tính năng tái tạo cho phép tạo các phản hồi mới nếu những phản hồi ban đầu không phù hợp\n- Thu thập phản hồi của người dùng liên quan đến phản hồi ngầm định và thiết kế cơ sở dữ liệu để lưu trữ phản hồi\n\n[35:23](https://www.youtube.com/watch?v=fwkklrYeCqo&t=2123) Thảo luận về cơ chế phản hồi trong việc tạo dataset\n\n- Tầm quan trọng của phản hồi rõ ràng trong việc tạo dataset\n- Giải thích lý do phản hồi của con người là cần thiết để cải thiện các mô hình chatbot, giảm các ảo giác và phản hồi không liên quan\n- Chi tiết về các loại phản hồi ngầm định và rõ ràng, bao gồm tái tạo phản hồi, kiểm tra lại các sự thật, dừng tạo phản hồi, thích/không thích và đánh giá phản hồi\n- Thiết kế cơ sở dữ liệu để lưu trữ dữ liệu phản hồi, đảm bảo phản hồi được lưu trữ với ngữ cảnh và thông tin người dùng liên quan\n- Cân nhắc các quan điểm khác nhau trong việc đánh giá phản hồi\n\n[38:55](https://www.youtube.com/watch?v=fwkklrYeCqo&t=2335) Sử dụng ChatGPT hiệu quả\n\n- Sử dụng ChatGPT cho một phần viết tiểu luận và tạo tài liệu để tiết kiệm thời gian\n- Hiểu quy trình đầu vào đầu ra và tầm quan trọng của việc cung cấp đầu vào chất lượng để có đầu ra tốt hơn\n\n[45:47](https://www.youtube.com/watch?v=fwkklrYeCqo&t=2747) Hiểu về tầm quan trọng của thuật ngữ cụ thể trong giao tiếp hiệu quả\n\n- Giải thích tầm quan trọng của các thuật ngữ như 'prompt' và 'personal statement' trong ngữ cảnh giao tiếp\n- Thảo luận về việc tạo các prompt hiệu quả cho ChatGPT bằng cách cung cấp ngữ cảnh, xác định vai trò của người tạo prompt và người đọc mong đợi, và bao gồm các mẫu đầu ra\n- Chi tiết về sự cần thiết của ngữ cảnh, hướng dẫn và cụ thể về người đọc trong giao tiếp cho các đối tượng khác nhau\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fwkklrYeCqo?si=PkGNNwCi6ljglmIF&amp;start=2486\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[48:18](https://www.youtube.com/watch?v=fwkklrYeCqo&t=2898) Viết ví dụ rõ ràng và cung cấp hướng dẫn chi tiết\n\n- Ví dụ về cách các prompt rõ ràng và chi tiết dẫn đến các phản hồi tốt hơn và hữu ích hơn từ ChatGPT\n- Cung cấp các mẫu rõ ràng và chi tiết để người khác làm theo\n- Đảm bảo rằng các nhiệm vụ được giải quyết một cách chi tiết và hiệu quả\n- Mẹo đánh giá các phản hồi và điều chỉnh các prompt để tinh chỉnh\n\n[53:58](https://www.youtube.com/watch?v=fwkklrYeCqo&t=3238) Tầm quan trọng của việc cung cấp ngữ cảnh và cá nhân hóa\n\n- Ngữ cảnh và cá nhân hóa là rất cần thiết cho giao tiếp hiệu quả.\n- Có sẵn một mẫu để chỉnh sửa và cung cấp ngữ cảnh.\n\n[55:09](https://www.youtube.com/live/fwkklrYeCqo?si=7gXV0s8_M7tnf1X1&t=3306) Kết luận và phiên hỏi đáp mở\n\n- Tóm tắt những điểm chính từ tất cả các cuộc thảo luận.\n- Các người tham gia đặt câu hỏi và người thuyết trình cung cấp các giải thích bổ sung về các chủ đề đã thảo luận.\n- Khuyến khích áp dụng các kỹ thuật và cơ chế phản hồi đã thảo luận vào các dự án thực tế\n","title":"OGIF Office Hours #13 - Go Weekly updates, Radix Sort, Human Feedback Mechanism, and effective ChatGPT usage","short_title":"#13 Go Weekly updates, Radix Sort, Human Feedback Mechanism, and effective ChatGPT usage","description":"This week's OGIF covers key topics including Go Weekly updates, Radix Sort, Human Feedback Mechanism, and effective ChatGPT usage. We discuss Go iterators and the latest features in Go 1.23, followed by a demonstration of Radix Sort's efficiency. The session also explains the Human Feedback Mechanism for improving Chatbot models and wraps up with best practices for using ChatGPT effectively.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Wed Jul 10 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/13-20240705.md","slugArray":["updates","ogif","13-20240705"]},{"content":"\n**Short Summary**\n\n[00:03](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3) Discussion on work distribution and task delegation\n\n[08:52](https://www.youtube.com/watch?v=DQFDU2rFObU&t=532) The need for increased ICY for writing articles\n\n[15:50](https://www.youtube.com/watch?v=DQFDU2rFObU&t=950) Discussion on product nature and user participation\n\n[18:59](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1139) Choosing the right programming language for a startup\n\n[23:40](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1420) Enterprise companies adopting new technology\n\n[25:57](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1557) Discussing team orientation and skill development\n\n[30:37](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1837) Discussion on the future of concurrency language\n\n[33:15](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1995) Articles on generic collection types in Go and RC's tooling\n\n[38:03](https://www.youtube.com/watch?v=DQFDU2rFObU&t=2283) Combining types to satisfy compiler errors\n\n[40:24](https://www.youtube.com/watch?v=DQFDU2rFObU&t=2424) Introduction to the Dolt and its use cases\n\n[45:48](https://www.youtube.com/watch?v=DQFDU2rFObU&t=2748) Creating an OGIF summary using a chatbot and transcription\n\n[49:07](https://www.youtube.com/watch?v=DQFDU2rFObU&t=2947) Using workflow for Admin side chat organization\n\n[55:12](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3312) Discussion on pricing strategy and pricing models\n\n[57:45](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3465) Pricing strategy crucial for product success\n\n[1:02:59](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3779) Pricing models and selling strategies\n\n[1:05:26](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3926) Three pricing models explained\n\n[1:11:00](https://www.youtube.com/watch?v=DQFDU2rFObU&t=4260) Pricing models change depending on the project\n\n[1:13:48](https://www.youtube.com/watch?v=DQFDU2rFObU&t=4428) Implementing the floor and team readiness\n\n[1:18:46](https://www.youtube.com/watch?v=DQFDU2rFObU&t=4726) Choosing the right system for a software solution is crucial for adaptability and scalability\n\n[1:21:38](https://www.youtube.com/watch?v=DQFDU2rFObU&t=4898) Discussion on setting up and product team roles\n\n[1:27:00](https://www.youtube.com/watch?v=DQFDU2rFObU&t=5220) Discussion about designing and collaboration\n\n[1:29:57](https://www.youtube.com/watch?v=DQFDU2rFObU&t=5397) Discussing the system design and implementation for Minh Luu\n\n---\n\n**Detailed Summary**\n\n[00:03](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3) Discussion on work distribution and task delegation\n\n- Sharing responsibilities and ensuring tasks are completed efficiently\n- Mentions about upcoming events and content updates within the community\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/DQFDU2rFObU?si=Sf7_SQGlY2HWev-p&amp;start=4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[08:52](https://www.youtube.com/watch?v=DQFDU2rFObU&t=532) The need for increased ICY for writing articles\n\n- Articles require more knowledge synthesis and writing effort to meet standards\n- Discussion about sharing and commenting on articles and the process of releasing comments\n- Emphasis on maintaining high-standard content and rewards for engaging and high-quality content.\n\n[15:50](https://www.youtube.com/watch?v=DQFDU2rFObU&t=950) Discussion on product nature and user participation\n\n- Mentions of 10 users for Memo and 19 users for ICY\n- Conversation about distributing links and testing versions\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/DQFDU2rFObU?si=i_0Zc405-GsSECPC&amp;start=898\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[18:59](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1139) Choosing the right programming language for a startup\n\n- The speaker initially chose Elixir due to its speed and effectiveness in building MVPs and web systems\n- The speaker's team continues to use Elixir as the main language, but there are concerns about its long-term viability in the changing market\n\n[23:40](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1420) Enterprise companies adopting new technology\n\n- Significant history of from 6 to 7 years for our team\n- Integration with payment system and management system\n\n[25:57](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1557) Discussing team orientation and skill development\n\n- Discussing specific team members Hieu Vu and Cuong's potential paths\n- Highlighting the importance of disseminating related topics to the team\n\n[30:37](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1837) Discussion on the future concurrency language\n\n- Many people still believe in the future of concurrency language\n- Contrasting the story of concurrency language with other languages like Java\n\n[33:15](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1995) Articles on generic collection types in Go and RC's tooling\n\n- Discusses Go's current support for generic collection types and the correct way to write them\n- Explains the purpose and implementation of a sortable type using generics in Go\n- Analysis of generics in Go and how it's being implemented and used in collection types\n- A concise look into different challenges and considerations when working with generics in Go.\n- Examples and code snippets demonstrating the usage of generics and interface limitations\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/DQFDU2rFObU?si=Cmv5I02R2Tk1Kgtc&amp;start=2130\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[38:03](https://www.youtube.com/watch?v=DQFDU2rFObU&t=2283) Combining types to satisfy compiler errors\n\n- Combining sortable constraint types for broader satisfaction of slides and maps.\n- Difficulty in using due to lack of familiarity and access to resources.\n\n[40:24](https://www.youtube.com/watch?v=DQFDU2rFObU&t=2424) Introduction to the Dolt and its use-cases\n\n- Dolt is a database with version control used by big companies, game developers, and other system guys\n- The process of using Dolt involves creating branches, making updates, and seeking approval for changes\n\n[45:48](https://www.youtube.com/watch?v=DQFDU2rFObU&t=2748) Creating an OGIF summary using a chatbot and transcription\n\n- Introduction to a tool used for auto-generating summary transcriptions from YouTube videos\n- The process involves using API calls and structuring the transcriptions for better ease of use and review\n- Tool demo showing how it simplifies content summarization and allows for streamlined content creation in OGIF (Organizational Group Information Flow)\n- The process involves transcribing and rearranging the content automatically\n- Plans to improve the process using engineering and adding more steps in the future\n\n[49:07](https://www.youtube.com/watch?v=DQFDU2rFObU&t=2947) Using workflow for Admin side chat organization\n\n- The workflow involves adding final steps to make the chat organization neater\n- Multiple functions like iteration and link processing are available for efficient reporting\n\n[55:12](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3312) Discussion on pricing strategy and pricing models\n\n- Various ways to choose a price for a product in pricing strategy\n- Factors to consider and effects of pricing on profit and market PR in pricing models\n\n[57:45](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3465) Pricing strategy crucial for product success\n\n- Pricing strategies can impact profitability - selling too cheap or overpricing\n- Ignoring the market leads to fading away - adapt to market changes for success\n\n[1:02:59](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3779) Pricing models and selling strategies\n\n- Products will be sold in packs, with different pricing for bulk purchases\n- Various pricing models are available such as flat fee, time-based, and custom pricing\n\n[1:05:26](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3926) Three pricing models explained\n\n- Each tier has its own price level based on the number of units sold\n- Volume pricing is based on the total volume and counts as one unit for the whole volume\n\n[1:11:00](https://www.youtube.com/watch?v=DQFDU2rFObU&t=4260) Pricing models changed for the project\n\n- The original pitching set was based on user groups and team members\n- Pricing strategy and model optimized based on business requirements\n\n[1:13:48](https://www.youtube.com/watch?v=DQFDU2rFObU&t=4428) Implementing the floor and team readiness\n\n- Discussion on stress in implementing the floor\n- Considering the team's readiness for the task\n\n[1:18:46](https://www.youtube.com/watch?v=DQFDU2rFObU&t=4726) Choosing the right system for a software solution is crucial for adaptability and scalability\n\n- Considering potential scenarios like company disbandment can help in making a wise system selection\n- Software architects need to have a structured approach to solve complex problems involving system assembly and disassembly\n\n[1:21:38](https://www.youtube.com/watch?v=DQFDU2rFObU&t=4898) Discussion on setting up and product team roles\n\n- Emphasis on the setup team coming up with ideas\n- Description of the roles of the PM person in the product team\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/DQFDU2rFObU?si=RKuY_aUFEU9fFPkM&amp;start=4916\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:27:00](https://www.youtube.com/watch?v=DQFDU2rFObU&t=5220) Discussion about designing and collaboration\n\n- The speaker talks about designing and working with Dune\n- They also discuss contacting Hieu Vu for collaboration and the challenges of drawing on paper\n\n[1:29:57](https://www.youtube.com/watch?v=DQFDU2rFObU&t=5397) Discussing the system design and implementation for Minh Luu\n\n- The team deliberates on the system design and whether Minh Luu can handle it\n- The discussion also includes the components of the trading system like order book and market liquidity\n\n[01:32:34](https://www.youtube.com/live/DQFDU2rFObU&t=5554) Planning for the next tasks and discussing specific projects with team members\n\n- Discussion on assigning and planning upcoming tasks and projects for team members\n- Guidance on focusing on Solution Architecture roles and how to design and present technical solutions\n- Mention of evaluating different SaaS (Software as a Service) models and creating a detailed C4 model (Context, Container, Component, Code) for better understanding and efficiency in project design\n- Team members are given project titles like pricing systems, notification systems, etc., with an emphasis on understanding through practical application and deeper architectural analysis\n\n---\n\n**Tóm tắt ngắn nội dung**\n\n[00:03](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3) Thảo luận về phân công công việc và phân công nhiệm vụ\n\n[08:52](https://www.youtube.com/watch?v=DQFDU2rFObU&t=532) Nhu cầu tăng ICY khi viết bài\n\n[15:50](https://www.youtube.com/watch?v=DQFDU2rFObU&t=950) Thảo luận về bản chất sản phẩm và sự tham gia của người dùng\n\n[18:59](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1139) Lựa chọn ngôn ngữ lập trình phù hợp cho khởi nghiệp\n\n[23:40](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1420) Doanh nghiệp áp dụng công nghệ mới\n\n[25:57](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1557) Thảo luận về định hướng nhóm và phát triển kỹ năng\n\n[30:37](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1837) Thảo luận về tương lai của ICY\n\n[33:15](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1995) Các bài viết về các loại bộ sưu tập chung trong công cụ của Go và RC\n\n[38:03](https://www.youtube.com/watch?v=DQFDU2rFObU&t=2283) Kết hợp các loại để đáp ứng lỗi trình biên dịch\n\n[40:24](https://www.youtube.com/watch?v=DQFDU2rFObU&t=2424) Giới thiệu về Dolt và các ứng dụng của nó\n\n[45:48](https://www.youtube.com/watch?v=DQFDU2rFObU&t=2748) Tạo bản tóm tắt OGIF bằng chatbot và phiên âm\n\n[49:07](https://www.youtube.com/watch?v=DQFDU2rFObU&t=2947) Sử dụng quy trình làm việc cho tổ chức trò chuyện bên Quản trị viên\n\n[55:12](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3312) Thảo luận về chiến lược định giá và mô hình định giá\n\n[57:45](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3465) Chiến lược giá quyết định sự thành công của sản phẩm\n\n[1:02:59](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3779) Mô hình định giá và chiến lược bán hàng\n\n[1:05:26](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3926) Ba mô hình định giá được giải thích\n\n[1:11:00](https://www.youtube.com/watch?v=DQFDU2rFObU&t=4260) Mô hình định giá đã thay đổi cho dự án Ving\n\n[1:13:48](https://www.youtube.com/watch?v=DQFDU2rFObU&t=4428) Triển khai sàn và sự sẵn sàng của đội\n\n[1:18:46](https://www.youtube.com/watch?v=DQFDU2rFObU&t=4726) Việc chọn hệ thống phù hợp cho giải pháp phần mềm là rất quan trọng đối với khả năng thích ứng và khả năng mở rộng.\n\n[1:21:38](https://www.youtube.com/watch?v=DQFDU2rFObU&t=4898) Thảo luận về việc thành lập và vai trò của nhóm sản phẩm.\n\n[1:27:00](https://www.youtube.com/watch?v=DQFDU2rFObU&t=5220) Thảo luận về thiết kế và hợp tác\n\n[1:29:57](https://www.youtube.com/watch?v=DQFDU2rFObU&t=5397) Thảo luận về thiết kế và triển khai hệ thống cho Minh Lưu\n\n---\n\n**Tóm tắt chi tiết nội dung** \n\n[00:03](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3) Thảo luận về phân công công việc và phân công nhiệm vụ\n\n- Chia sẻ trách nhiệm và đảm bảo task được hoàn thành một cách hiệu quả\n- Điểm qua các sự kiện sắp tới và cập nhật nội dung trong cộng đồng\n\n[08:52](https://www.youtube.com/watch?v=DQFDU2rFObU&t=532) Nhu cầu tăng ICY khi viết bài\n\n- Bài viết đòi hỏi tổng hợp kiến thức và nỗ lực viết nhiều hơn để đạt chuẩn\n- Thảo luận về chia sẻ, bình luận bài viết và quy trình đưa ra bình luận\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/DQFDU2rFObU?si=v_LbNn5v0XP3LX0h&amp;start=595\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[15:50](https://www.youtube.com/watch?v=DQFDU2rFObU&t=950) Thảo luận về bản chất sản phẩm và sự tham gia của người dùng\n\n- Đề cập của 10 người dùng cho Bản ghi nhớ và 19 người dùng cho ICY\n- Hội thoại về phân phối link và phiên bản thử nghiệm\n\n[18:59](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1139) Lựa chọn ngôn ngữ lập trình phù hợp cho khởi nghiệp\n\n- Diễn giả ban đầu chọn Elixir do tốc độ và tính hiệu quả của nó trong việc xây dựng MVP và hệ thống web\n- Nhóm của diễn giả tiếp tục sử dụng Elixir làm ngôn ngữ chính, nhưng có những lo ngại về khả năng tồn tại lâu dài của nó trong thị trường đang thay đổi\n\n[23:40](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1420) Doanh nghiệp áp dụng công nghệ mới\n\n- Lịch sử của team\n- Tích hợp với hệ thống thanh toán và hệ thống quản lý\n\n[25:57](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1557) Thảo luận về định hướng nhóm và phát triển kỹ năng\n\n- Thảo luận cụ thể về con đường tiềm năng của Hiếu Vũ và Cường\n- Nhấn mạnh tầm quan trọng của việc phổ biến các chủ đề liên quan đến nhóm\n\n[30:37](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1837) Thảo luận về tương lai của ngôn ngữ concurency\n\n- Nhiều người vẫn tin vào tương lai của ngôn ngữ concurency\n- Đối chiếu câu chuyện của ngôn ngữ concurency với các ngôn ngữ khác như Java\n\n[33:15](https://www.youtube.com/watch?v=DQFDU2rFObU&t=1995) Các bài viết về các loại bộ sưu tập chung trong công cụ của Go và RC\n\n- Thảo luận về sự hỗ trợ hiện tại của Go dành cho các loại bộ sưu tập chung và cách viết chúng chính xác\n- Giải thích mục đích và cách triển khai loại có thể sắp xếp bằng cách sử dụng generics trong Go\n\n[38:03](https://www.youtube.com/watch?v=DQFDU2rFObU&t=2283) Kết hợp các loại để đáp ứng lỗi trình biên dịch\n\n- Kết hợp các loại ràng buộc có thể sắp xếp để đáp ứng rộng hơn các trang trình bày và bản đồ\n- Khó khăn trong việc sử dụng do chưa quen và chưa tiếp cận được các nguồn tài nguyên\n\n[40:24](https://www.youtube.com/watch?v=DQFDU2rFObU&t=2424) Giới thiệu về Dolt và các ứng dụng của nó\n\n- Giới thiệu về Dolt - một loại database có version control được nhiều công ty lớn, nhà phát triển game sử dụng. Anh em cũng nói về quy trình tạo branch, cập nhật, và xin duyệt thay đổi\n\n[45:48](https://www.youtube.com/watch?v=DQFDU2rFObU&t=2748) Tạo bản tóm tắt OGIF bằng chatbot và phiên âm\n\n- Quá trình này bao gồm việc sao chép và sắp xếp lại nội dung một cách tự động\n- Có kế hoạch cải thiện quy trình sử dụng kỹ thuật và bổ sung thêm nhiều bước hơn trong tương lai\n\n[49:07](https://www.youtube.com/watch?v=DQFDU2rFObU&t=2947) Sử dụng quy trình làm việc cho tổ chức trò chuyện bên Quản trị viên\n\n- Quy trình làm việc bao gồm việc thêm các bước cuối cùng để tổ chức cuộc trò chuyện gọn gàng hơn\n- Nhiều chức năng như lặp lại và xử lý liên kết có sẵn để báo cáo hiệu quả\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/DQFDU2rFObU?si=1ckwCQo_99zj99Qm&amp;start=2396\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[55:12](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3312) Thảo luận về chiến lược định giá và mô hình định giá\n\n- Nhiều cách lựa chọn giá cho sản phẩm trong chiến lược giá\n- Các yếu tố cần xem xét và ảnh hưởng của việc định giá đến lợi nhuận và PR thị trường trong các mô hình định giá\n\n[57:45](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3465) Chiến lược giá quyết định sự thành công của sản phẩm\n\n- Chiến lược định giá có thể ảnh hưởng đến lợi nhuận - bán quá rẻ hoặc định giá quá cao\n- Bỏ qua thị trường dẫn đến lụi tàn - thích ứng với sự thay đổi của thị trường để thành công\n\n[1:02:59](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3779) Mô hình định giá và chiến lược bán hàng\n\n- Sản phẩm sẽ được bán theo gói, mua càng nhiều giá càng ưu đãi\n- Có nhiều mô hình định giá khác nhau như định giá cố định, định giá theo thời gian và định giá tùy chỉnh cho khách hàng lựa chọn\n\n[1:05:26](https://www.youtube.com/watch?v=DQFDU2rFObU&t=3926) Ba mô hình định giá được giải thích\n\n- Mỗi bậc có mức giá riêng dựa trên số lượng sản phẩm bán ra\n- Định giá theo số lượng dựa trên tổng số lượng và được tính là một đơn vị cho toàn bộ số lượng\n\n[1:11:00](https://www.youtube.com/watch?v=DQFDU2rFObU&t=4260) Mô hình định giá đã thay đổi cho dự án Ving\n\n- Bộ quảng cáo chiêu hàng ban đầu dựa trên nhóm người dùng và thành viên trong nhóm\n- Chiến lược và mô hình định giá được tối ưu hóa dựa trên yêu cầu kinh doanh\n\n[1:13:48](https://www.youtube.com/watch?v=DQFDU2rFObU&t=4428) Triển khai sàn và sự sẵn sàng của đội\n\n- Thảo luận về áp lực khi triển khai sàn\n- Xem xét sự sẵn sàng của đội cho nhiệm vụ\n\n[1:18:46](https://www.youtube.com/watch?v=DQFDU2rFObU&t=4726) Việc chọn hệ thống phù hợp cho giải pháp phần mềm là rất quan trọng đối với khả năng thích ứng và khả năng mở rộng\n\n- Việc xem xét các tình huống tiềm ẩn như giải thể công ty có thể giúp đưa ra lựa chọn hệ thống khôn ngoan\n- Kiến trúc sư phần mềm cần có cách tiếp cận có cấu trúc để giải quyết các vấn đề phức tạp liên quan đến lắp ráp và tháo dỡ hệ thống\n\n[1:21:38](https://www.youtube.com/watch?v=DQFDU2rFObU&t=4898) Thảo luận về việc thành lập và vai trò của nhóm sản phẩm\n\n- Nhấn mạnh vai trò của team setup trong việc lên ý tưởng\n- Vai trò của PM trong nhóm sản phẩm\n\n[1:27:00](https://www.youtube.com/watch?v=DQFDU2rFObU&t=5220) Thảo luận về thiết kế và hợp tác\n\n- Về việc thiết kế và làm việc với một người khác tên là Dune\n- Họ cũng thảo luận về việc liên hệ với Hiếu Vũ để hợp tác và những thách thức khi vẽ trên giấy\n\n[1:29:57](https://www.youtube.com/watch?v=DQFDU2rFObU&t=5397) Thảo luận về thiết kế và triển khai hệ thống cho Minh Lưu\n\n- Nhóm thảo luận về thiết kế hệ thống và liệu Minh Lưu có thể xử lý được không\n- Cuộc thảo luận cũng bao gồm các thành phần của hệ thống giao dịch như sổ lệnh và tính thanh khoản của thị trường\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/DQFDU2rFObU?si=TFRtY4mYkfJ03cpJ&amp;start=4892\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[01:32:34](https://www.youtube.com/live/DQFDU2rFObU&t=5554) Lên kế hoạch cho các nhiệm vụ tiếp theo và thảo luận về các dự án cụ thể với các thành viên trong đội\n\n- Thảo luận về việc phân công và lên kế hoạch cho các nhiệm vụ và dự án sắp tới cho các thành viên trong đội\n- Hướng dẫn tập trung vào vai trò của Kiến trúc Giải pháp và cách thiết kế và trình bày các giải pháp kỹ thuật\n- Đề cập đến việc đánh giá các mô hình SaaS (Phần mềm như một dịch vụ) khác nhau và tạo ra mô hình C4 chi tiết (Bối cảnh, Container, Thành phần, Mã) để hiểu rõ hơn và hiệu quả hơn trong thiết kế dự án\n- Các thành viên trong đội được giao các dự án như hệ thống định giá, hệ thống thông báo, v.v., với nhấn mạnh vào việc hiểu thông qua thực hành thực tế và phân tích kiến trúc sâu hơn\n","title":"OGIF Office Hours #14 - Generic Collections, Pricing Models, and OGIF Summarizer","short_title":"#14 Generic Collections, Pricing Models, and OGIF Summarizer","description":"In our fourteenth covers work distribution, enhanced article writing, product development, and strategic pricing models. It also discusses generics in Go, Dolt for database version control, and an automated tool for OGIF summaries, offering insights for developers and project managers.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Tue Jul 16 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/14-20240712.md","slugArray":["updates","ogif","14-20240712"]},{"content":"\n91 minutes\n\n**Short Summary**\n\n[00:03](https://www.youtube.com/watch?v=fYEafaivExc&t=3) Discussion on team activities and work progress\n\n[16:26](https://www.youtube.com/watch?v=fYEafaivExc&t=986) Discussing tools for code completion and considerations for users and problems\n\n[21:21](https://www.youtube.com/watch?v=fYEafaivExc&t=1281) Comparing GPT-4 with Claude and Open AI\n\n[23:54](https://www.youtube.com/watch?v=fYEafaivExc&t=1434) Comparison between Supermaven and Transformer model in AI\n\n[30:47](https://www.youtube.com/watch?v=fYEafaivExc&t=1847) Discussion on running AI locally vs. using cloud solutions\n\n[33:41](https://www.youtube.com/watch?v=fYEafaivExc&t=2021) Discussing the architecture challenges and benefits of building an AI Supervisor\n\n[39:47](https://www.youtube.com/watch?v=fYEafaivExc&t=2387) Architecting AI supervisors for database interactions\n\n[42:40](https://www.youtube.com/watch?v=fYEafaivExc&t=2560) Advantages of Architecting AI Supervisors\n\n[47:39](https://www.youtube.com/watch?v=fYEafaivExc&t=2859) Using examples to generate accurate sentences and ensuring compliance with regulations\n\n[50:32](https://www.youtube.com/watch?v=fYEafaivExc&t=3032) Architecting AI supervisors for efficient task management\n\n[59:39](https://www.youtube.com/watch?v=fYEafaivExc&t=3579) Discussion on local-first software and its comparison with normal web apps\n\n[1:02:40](https://www.youtube.com/watch?v=fYEafaivExc&t=3760) Local-first software shifts roles of frontend and backend\n\n[1:08:30](https://www.youtube.com/watch?v=fYEafaivExc&t=4110) Overview of Local-First software architecture\n\n[1:10:49](https://www.youtube.com/watch?v=fYEafaivExc&t=4249) Conflict-free data storage and resolution\n\n[1:15:55](https://www.youtube.com/watch?v=fYEafaivExc&t=4555) SDK supports local-first applications\n\n[1:18:23](https://www.youtube.com/watch?v=fYEafaivExc&t=4703) Benefits of Local-First Software Development\n\n[1:23:01](https://www.youtube.com/watch?v=fYEafaivExc&t=4981) Distributing data and managing workflow\n\n[1:26:23](https://www.youtube.com/watch?v=fYEafaivExc&t=5183) Summary of new features and team contributions\n\n[01:30:00](https://www.youtube.com/live/fYEafaivExc&t=5400) Discussing different platforms for sharing information sources\n\n---\n\n**Detailed Summary**\n\n[00:03](https://www.youtube.com/watch?v=fYEafaivExc&t=3) Discussion on team activities and work progress\n\n- Team discussing ongoing projects and working remotely or in the office\n- Sharing updates and plans for new product releases\n\n[16:26](https://www.youtube.com/watch?v=fYEafaivExc&t=986) Discussing tools for code completion and considerations for users and problems\n\n- Comparison of different AI completion tools: GitHub Copilot, Continue, Codeium, Cursor, Supermaven\n- Supermaven claimed to have the lowest latency at 250ms\n- Considering user preferences for accuracy and speed in code completion, and the challenges of implementing such tools\n- Discussion on accuracy and understanding of code context\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fYEafaivExc?si=pK-7qiP3BzIZKGVd&amp;start=989\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[21:21](https://www.youtube.com/watch?v=fYEafaivExc&t=1281) Comparing GPT-4 with Claude and Open AI\n\n- GPT-4 has better composition and lower latency than Claude but lags in AG compared to Toan\n- Introducing a new feature similar to C allowing configuration and use of OpenAI's API\n\n[23:54](https://www.youtube.com/watch?v=fYEafaivExc&t=1434) Comparison between Supermaven and Transformer model in AI\n\n- Supermaven offers more TC Window columns compared to the Transformer model for enhanced code completion\n- The Supermaven is optimized for stronger performance in C coding with around 300,000 Token context Window when compared with Copilot’s 30,000 Token\n\n[30:47](https://www.youtube.com/watch?v=fYEafaivExc&t=1847) Discussion on running AI locally vs. using cloud solutions\n\n- Local AI supervision is feasible with a maximum RAM of 16 GB; opt for the cloud with 8 GB\n- Considerations on task requirements for choosing between local vs. cloud solutions\n\n[33:41](https://www.youtube.com/watch?v=fYEafaivExc&t=2021) Discussing the architecture challenges and benefits of building an AI Supervisor\n\n- Explaining the concept of Ent and Mul in the architecture\n- Detailing the structure and functionality of Agent in the framework\n\n[39:47](https://www.youtube.com/watch?v=fYEafaivExc&t=2387) Architecting AI supervisors for database interactions\n\n- The app is built using Up and Upgraft L framework for creating agents and workflows for multiple VOs to collaborate effectively\n- Explanation of the workflow and interaction between agents\n- The three main components are SQL, Semantic, and Supervisor, which coordinate the tasks, analyze questions, and interact with databases and agents\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fYEafaivExc?si=0Ll0BZ8wasfgGeTP&amp;start=2388\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[42:40](https://www.youtube.com/watch?v=fYEafaivExc&t=2560) Advantages of Architecting AI Supervisors\n\n- The design allows for easy maintenance and the addition of features with fixed agent tasks\n- Enhances user experience by providing semantic answers and overcoming challenges like unclear questions and security concerns\n\n[47:39](https://www.youtube.com/watch?v=fYEafaivExc&t=2859) Using examples to generate accurate sentences and ensuring compliance with regulations\n\n- Generating sentences based on specific examples for accuracy\n- Developing a mechanism to ensure compliance with regulations\n\n[50:32](https://www.youtube.com/watch?v=fYEafaivExc&t=3032) Architecting AI supervisors for efficient task management\n\n- Explained the process of utilizing database results to restore a running state\n- Detailed the role of Supervisor in managing agent states and tasks efficiently\n\n[59:39](https://www.youtube.com/watch?v=fYEafaivExc&t=3579) Discussion on local-first software and its comparison with normal web apps\n\n- Explanation of Local-First and Offline-First Software Concepts\n- Local-First software is a way to build software that focuses on offline usability and data autonomy\n- Comparison with normal web apps involves separating frontend and backend, with the backend storing the database and the server part communicating with the web app\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fYEafaivExc?si=2djEtQtrZODWnSxo&amp;start=3582\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:02:40](https://www.youtube.com/watch?v=fYEafaivExc&t=3760) Local-First software shifts roles of frontend and backend\n\n- Local-First software architecture involves shifting and changing the roles of the frontend and backend\n- Local-First web apps save and export data directly from the local database located in the browser or on the user's computer\n\n[01:01:20](https://www.youtube.com/live/fYEafaivExc&t=3680) Tools and libraries for Local-First development\n\n- Introduction to RxDB and DexieJS as potential solutions\n- Brief overview of their features and use cases\n\n[1:08:30](https://www.youtube.com/watch?v=fYEafaivExc&t=4110) Overview of Local-First software architecture\n\n- Local-First software ensures real collaboration and basic infrastructure for applications\n- The architecture involves local databases for clients, backend servers, and remote databases for data synchronization\n\n[1:10:49](https://www.youtube.com/watch?v=fYEafaivExc&t=4249) Conflict-free data storage and resolution\n\n- Explanation of Conflict-free Replicated Data Types (CRDTs)\n- The conflict-free data type is a type of data storage that ensures no conflicts in the final result of the resolver\n- Using CRDT to resolve multiple updates in real collaboration is crucial\n\n[1:15:55](https://www.youtube.com/watch?v=fYEafaivExc&t=4555) SDK supports local-first applications\n\n- Uses IndexDB and local storage\n- Explanation of data synchronization between clients and server\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fYEafaivExc?si=M08lMhchEMYGW4Tt&amp;start=3919\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[01:16:00](https://www.youtube.com/live/fYEafaivExc&t=4560) Challenges and considerations in Local-First implementation\n\n- Handling data conflicts and synchronization\n- Managing storage limitations on client devices\n\n[1:18:23](https://www.youtube.com/watch?v=fYEafaivExc&t=4703) Benefits of Local-First Software Development\n\n- Real-time collaboration feature in apps like Line or Figma using Local-First principles\n- Benefits in terms of responsiveness and offline capabilities\n- Enhanced security due to decentralized database structure\n\n[01:21:20](https://www.youtube.com/live/fYEafaivExc&t=4880) Future of Local-First development\n\n- Potential improvements and wider adoption of Local-First principles\n- Discussion on balancing between Local-First and traditional architectures\n\n[1:23:01](https://www.youtube.com/watch?v=fYEafaivExc&t=4981) Distributing data and managing workflow\n\n- Discussion on authority allocation towards the backend server for data management\n- Explanation of team recording process and task distribution\n\n[01:25:40](https://www.youtube.com/live/fYEafaivExc?si=d5B8KrPTWomyHjbN&t=5109) Discussing different platforms for sharing information sources\n\n- Various platforms are mentioned, such as Reddit, Lobster, and tech news, for sharing information sources\n- Details were shared on how to access and make use of the platforms mentioned\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fYEafaivExc?si=v3wEOmLVQtujr_7b&amp;start=5217\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[01:31:20](https://www.youtube.com/live/fYEafaivExc&t=5480) Demonstration of new Discord bots\n\n- Showcase of bots aggregating news from various tech sources\n- Explanation of bot functionality and customization options\n\n[01:36:00](https://www.youtube.com/live/fYEafaivExc&t=5760) Closing remarks and future plans\n\n- Encouragement for team members to use and provide feedback on new tools\n- Brief discussion on upcoming features and improvements\n\n---\n\n**Tóm tắt ngắn nội dung**\n\n[00:03](https://www.youtube.com/watch?v=fYEafaivExc&t=3) Thảo luận về hoạt động nhóm và tiến độ công việc\n\n[16:26](https://www.youtube.com/watch?v=fYEafaivExc&t=986) Thảo luận về các công cụ hoàn thành mã và các cân nhắc cho người dùng và vấn đề\n\n[21:21](https://www.youtube.com/watch?v=fYEafaivExc&t=1281) So sánh GPT-4 với Claude và Open AI\n\n[23:54](https://www.youtube.com/watch?v=fYEafaivExc&t=1434) So sánh giữa Supermaven và mô hình Transformer trong AI\n\n[30:47](https://www.youtube.com/watch?v=fYEafaivExc&t=1847) Thảo luận về việc chạy AI cục bộ so với sử dụng giải pháp đám mây\n\n[33:41](https://www.youtube.com/watch?v=fYEafaivExc&t=2021) Thảo luận về những thách thức và lợi ích của việc xây dựng một Giám sát AI\n\n[39:47](https://www.youtube.com/watch?v=fYEafaivExc&t=2387) Kiến trúc Giám sát AI cho các tương tác cơ sở dữ liệu\n\n[42:40](https://www.youtube.com/watch?v=fYEafaivExc&t=2560) Lợi ích của Kiến trúc Giám sát AI\n\n[47:39](https://www.youtube.com/watch?v=fYEafaivExc&t=2859) Sử dụng ví dụ để tạo ra các câu chính xác và đảm bảo tuân thủ quy định\n\n[50:32](https://www.youtube.com/watch?v=fYEafaivExc&t=3032) Kiến trúc Giám sát AI cho quản lý công việc hiệu quả\n\n[59:39](https://www.youtube.com/watch?v=fYEafaivExc&t=3579) Thảo luận về phần mềm local-first và so sánh với ứng dụng web thông thường\n\n[1:02:40](https://www.youtube.com/watch?v=fYEafaivExc&t=3760) Phần mềm local-first thay đổi vai trò của frontend và backend\n\n[1:08:30](https://www.youtube.com/watch?v=fYEafaivExc&t=4110) Tổng quan về kiến trúc phần mềm Local-First\n\n[1:10:49](https://www.youtube.com/watch?v=fYEafaivExc&t=4249) Lưu trữ dữ liệu không xung đột và giải quyết xung đột\n\n[1:15:55](https://www.youtube.com/watch?v=fYEafaivExc&t=4555) SDK hỗ trợ các ứng dụng local-first\n\n[1:18:23](https://www.youtube.com/watch?v=fYEafaivExc&t=4703) Lợi ích của Phát triển Phần mềm Local-First\n\n[1:23:01](https://www.youtube.com/watch?v=fYEafaivExc&t=4981) Phân phối dữ liệu và quản lý quy trình làm việc\n\n[1:26:23](https://www.youtube.com/watch?v=fYEafaivExc&t=5183) Tóm tắt các tính năng mới và đóng góp của đội ngũ\n\n[01:30:00](https://www.youtube.com/live/fYEafaivExc&t=5400) Thảo luận về các nền tảng khác nhau để chia sẻ nguồn thông tin\n\n---\n\n**Tóm tắt chi tiết nội dung** \n\n[00:03](https://www.youtube.com/watch?v=fYEafaivExc&t=3) Thảo luận về hoạt động nhóm và tiến độ công việc\n\n- Nhóm thảo luận về các dự án đang tiến hành và làm việc từ xa hoặc tại văn phòng\n- Chia sẻ cập nhật và kế hoạch cho các sản phẩm mới\n\n[16:26](https://www.youtube.com/watch?v=fYEafaivExc&t=986) Thảo luận về các công cụ hoàn thành mã và các cân nhắc cho người dùng và vấn đề\n\n- So sánh các công cụ hoàn thành mã AI khác nhau: GitHub Copilot, Continue, Codeium, Cursor, Supermaven\n- Supermaven được cho là có độ trễ thấp nhất ở mức 250ms\n- Cân nhắc sở thích của người dùng về độ chính xác và tốc độ hoàn thành mã, và những thách thức của việc triển khai các công cụ này\n- Thảo luận về độ chính xác và hiểu ngữ cảnh mã\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fYEafaivExc?si=whY-W0LrovgFUdgF&amp;start=1100\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[21:21](https://www.youtube.com/watch?v=fYEafaivExc&t=1281) So sánh GPT-4 với Claude và Open AI\n\n- GPT-4 có khả năng sáng tác tốt hơn và độ trễ thấp hơn so với Claude nhưng kém hơn về AG so với Toan\n- Giới thiệu một tính năng mới tương tự như C cho phép cấu hình và sử dụng API của OpenAI\n\n[23:54](https://www.youtube.com/watch?v=fYEafaivExc&t=1434) So sánh giữa Supermaven và mô hình Transformer trong AI\n\n- Supermaven cung cấp nhiều cột TC Window hơn so với mô hình Transformer để hoàn thành mã tốt hơn\n- Supermaven được tối ưu hóa cho hiệu suất mạnh hơn trong lập trình C với khoảng 300,000 Token context Window so với Copilot chỉ có 30,000 Token\n\n[30:47](https://www.youtube.com/watch?v=fYEafaivExc&t=1847) Thảo luận về việc chạy AI cục bộ so với sử dụng giải pháp đám mây\n\n- Giám sát AI cục bộ khả thi với RAM tối đa 16 GB; chọn đám mây với 8 GB\n- Cân nhắc yêu cầu nhiệm vụ để chọn giữa giải pháp cục bộ và đám mây\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fYEafaivExc?si=yWtWQPcnFS8vKNGv&amp;start=1795\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[33:41](https://www.youtube.com/watch?v=fYEafaivExc&t=2021) Thảo luận về những thách thức và lợi ích của việc xây dựng một Giám sát AI\n\n- Giải thích khái niệm Ent và Mul trong kiến trúc\n- Chi tiết cấu trúc và chức năng của Agent trong khung làm việc\n\n[39:47](https://www.youtube.com/watch?v=fYEafaivExc&t=2387) Kiến trúc Giám sát AI cho các tương tác cơ sở dữ liệu\n\n- Ứng dụng được xây dựng sử dụng khung Up và Upgraft L để tạo ra các agent và quy trình làm việc cho nhiều VOs hợp tác hiệu quả\n- Giải thích quy trình làm việc và tương tác giữa các agent\n- Ba thành phần chính là SQL, Semantic và Supervisor, phối hợp các nhiệm vụ, phân tích câu hỏi và tương tác với cơ sở dữ liệu và agent\n\n[42:40](https://www.youtube.com/watch?v=fYEafaivExc&t=2560) Lợi ích của Kiến trúc Giám sát AI\n\n- Thiết kế cho phép dễ bảo trì và thêm các tính năng với nhiệm vụ agent cố định\n- Cải thiện trải nghiệm người dùng bằng cách cung cấp câu trả lời ngữ nghĩa và khắc phục các thách thức như câu hỏi không rõ ràng và vấn đề bảo mật\n\n[47:39](https://www.youtube.com/watch?v=fYEafaivExc&t=2859) Sử dụng ví dụ để tạo ra các câu chính xác và đảm bảo tuân thủ quy định\n\n- Tạo ra các câu dựa trên các ví dụ cụ thể để đạt độ chính xác\n- Phát triển cơ chế đảm bảo tuân thủ quy định\n\n[50:32](https://www.youtube.com/watch?v=fYEafaivExc&t=3032) Kiến trúc Giám sát AI cho quản lý công việc hiệu quả\n\n- Giải thích quy trình sử dụng kết quả cơ sở dữ liệu để khôi phục trạng thái hoạt động\n- Chi tiết vai trò của Supervisor trong việc quản lý trạng thái và nhiệm vụ của agent một cách hiệu quả\n\n[59:39](https://www.youtube.com/watch?v=fYEafaivExc&t=3579) Thảo luận về phần mềm local-first và so sánh với ứng dụng web thông thường\n\n- Giải thích về các khái niệm Phần mềm Local-First và Offline-First\n- Phần mềm Local-First là cách xây dựng phần mềm tập trung vào khả năng sử dụng offline và quyền tự chủ dữ liệu\n- So sánh với các ứng dụng web thông thường liên quan đến việc tách biệt frontend và backend, với backend lưu trữ cơ sở dữ liệu và phần máy chủ giao tiếp với ứng dụng web\n\n[1:02:40](https://www.youtube.com/watch?v=fYEafaivExc&t=3760) Phần mềm Local-First thay đổi vai trò của frontend và backend\n\n- Kiến trúc phần mềm Local-First liên quan đến việc thay đổi và chuyển vai trò của frontend và backend\n- Ứng dụng web Local-First lưu trữ và xuất dữ liệu trực tiếp từ cơ sở dữ liệu cục bộ nằm trong trình duyệt hoặc trên máy tính của người dùng\n\n[01:01:20](https://www.youtube.com/live/fYEafaivExc&t=3680) Công cụ và thư viện cho phát triển Local-First\n\n- Giới thiệu về RxDB và DexieJS như là các giải pháp tiềm năng\n- Tổng quan ngắn gọn về các tính năng và trường hợp sử dụng của chúng\n\n[1:08:30](https://www.youtube.com/watch?v=fYEafaivExc&t=4110) Tổng quan về kiến trúc phần mềm Local-First\n\n- Phần mềm Local-First đảm bảo sự hợp tác thực sự và cơ sở hạ tầng cơ bản cho các ứng dụng\n- Kiến trúc bao gồm các cơ sở dữ liệu cục bộ cho khách hàng, máy chủ backend và cơ sở dữ liệu từ xa để đồng bộ hóa dữ liệu\n\n[1:10:49](https://www.youtube.com/watch?v=fYEafaivExc&t=4249) Lưu trữ dữ liệu không xung đột và giải quyết xung đột\n\n- Giải thích về các loại Dữ liệu sao chép không xung đột (CRDTs)\n- Loại dữ liệu không xung đột là một loại lưu trữ dữ liệu đảm bảo không có xung đột trong kết quả cuối cùng của bộ giải quyết\n- Sử dụng CRDT để giải quyết nhiều bản cập nhật trong hợp tác thực sự là rất quan trọng\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fYEafaivExc?si=qQhlkMg6rhDr-XdH&amp;start=4193\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:15:55](https://www.youtube.com/watch?v=fYEafaivExc&t=4555) SDK hỗ trợ các ứng dụng local-first\n\n- Sử dụng IndexDB và lưu trữ cục bộ\n- Giải thích về đồng bộ hóa dữ liệu giữa các khách hàng và máy chủ\n\n[01:16:00](https://www.youtube.com/live/fYEafaivExc&t=4560) Thách thức và cân nhắc trong triển khai Local-First\n\n- Xử lý các xung đột dữ liệu và đồng bộ hóa\n- Quản lý các giới hạn lưu trữ trên các thiết bị của khách hàng\n\n[1:18:23](https://www.youtube.com/watch?v=fYEafaivExc&t=4703) Lợi ích của phát triển phần mềm Local-First\n\n- Tính năng hợp tác thời gian thực trong các ứng dụng như Line hoặc Figma sử dụng nguyên tắc Local-First\n- Lợi ích về độ phản hồi và khả năng hoạt động ngoại tuyến\n- Tăng cường bảo mật nhờ cấu trúc cơ sở dữ liệu phân tán\n\n[01:21:20](https://www.youtube.com/live/fYEafaivExc&t=4880) Tương lai của phát triển Local-First\n\n- Các cải tiến tiềm năng và sự chấp nhận rộng rãi hơn của các nguyên tắc Local-First\n- Thảo luận về việc cân bằng giữa Local-First và các kiến trúc truyền thống\n\n[1:23:01](https://www.youtube.com/watch?v=fYEafaivExc&t=4981) Phân phối dữ liệu và quản lý quy trình làm việc\n\n- Thảo luận về việc phân quyền cho máy chủ backend để quản lý dữ liệu\n- Giải thích quy trình ghi âm của đội và phân phối công việc\n\n[01:25:40](https://www.youtube.com/live/fYEafaivExc?si=d5B8KrPTWomyHjbN&t=5109) Thảo luận về các nền tảng chia sẻ nguồn thông tin khác nhau\n\n- Đề cập đến các nền tảng như Reddit, Lobster và tin tức công nghệ để chia sẻ nguồn thông tin\n- Chia sẻ chi tiết về cách truy cập và sử dụng các nền tảng được đề cập\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fYEafaivExc?si=fZbgtpcRdP8Lv6V7&amp;start=5235\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[01:31:20](https://www.youtube.com/live/fYEafaivExc&t=5480) Trình diễn các bot Discord mới\n\n- Trình bày các bot tổng hợp tin tức từ nhiều nguồn công nghệ khác nhau\n- Giải thích về chức năng của bot và các tùy chọn tùy chỉnh\n\n[01:36:00](https://www.youtube.com/live/fYEafaivExc&t=5760) Lời kết và kế hoạch tương lai\n\n- Khuyến khích các thành viên trong đội sử dụng và đưa ra phản hồi về các công cụ mới\n- Thảo luận ngắn gọn về các tính năng và cải tiến sắp tới của gpt 4o\n","title":"OGIF Office Hours #15 - Architecting AI supervisors, Local-first software, AI code completion overview and crawl list bot command","short_title":"#15 AI Supervisors, Local-first Software, Code Completion, Bot Commands","description":"In our fifteenth community discussion, we focus on Architecting AI Supervisors, Local-First Software and Crawl list command. Topics include an overview of ongoing projects, a detailed look at various code completion tools, and a demonstration of the Supervisor architecture. Additionally, we'll review the local-first software paradigm and conclude with a summary of new features and team contributions.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Mon Jul 22 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/15-20240719.md","slugArray":["updates","ogif","15-20240719"]},{"content":"\n94 minutes\n\n**Short Summary**\n\n[00:03](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3) Discussion on upcoming topics and recent events.\n\n[14:23](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=863) Discussion about ICY distribution and salary plans\n\n[22:14](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=1334) New trends in Go programming and ethical hacking\n\n[24:41](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=1481) Optimizing HTTP requests for faster execution\n\n[29:44](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=1784) Discusses deploying an auto scroller and handling code\n\n[32:17](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=1937) Discussion on using Go for functions and app development\n\n[38:19](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=2299) AI technology has potential in creating media content.\n\n[40:15](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=2415) Develop wisdom and compassion, live in harmony with technology, and stay connected to nature and others.\n\n[45:04](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=2704) Discussing AI voice translation and commentary tools\n\n[47:51](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=2871) Discussion on the cost and potential issues with AI voice impersonation services.\n\n[53:53](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3233) Data transformation process using APIs and smart contracts.\n\n[56:31](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3391) The algorithm is used for indexing and mapping data.\n\n[1:02:27](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3747) Comparing mapping techniques and their impact on user experience\n\n[1:05:18](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3918) Introduction to a powerful tool for retrieving and processing data via API.\n\n[1:10:29](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=4229) Designing a comprehensive system for software services\n\n[1:13:45](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=4425) Discussing data ranking and AI applications\n\n[1:19:37](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=4777) Using Lom for re-ranking can improve search results\n\n[1:22:15](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=4935) Explanation of Ranking and Formula Calculation\n\n[1:27:26](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=5246) Reranking and AI Voice\n\n[1:29:45](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=5385) The importance of evaluating and adjusting AI algorithms for accuracy\n\n---\n\n**Detailed Summary**\n\n[00:03](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3) Discussion on upcoming topics and recent events.\n\n- Introduction of attendees and discussion of next week's product launch.\n- Review of recent statistics and analysis of previous week's activities.\n\n[14:23](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=863) Discussion about ICY distribution and salary plans\n\n- Overview of current ICY standings and historical transactions.\n- Noting significant contributors and recognizing community engagement.\n- Mention of specific tasks and goals for the upcoming week.\n- Overview of metrics involving ICY distribution and user platform activity.\n- Discussion about implementing a new salary plan and supporting a new project.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/yEboOPUZ2wE?si=vRjEaLZW0RmxF0rF&amp;start=1124\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[22:14](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=1334) New trends in Go programming and ethical hacking\n\n- The trend of articles focuses on testing Go 1.2 1.23, rank and generic functions, emx articles, and the new Go profiler.\n- The top ethical hacker in Poland tried sending 500 requests to 25 million hosts using Go, finding it simple and efficient.\n\n[24:41](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=1481) Optimizing HTTP requests for faster execution\n\n- The process involves resolving DNS, creating TCP connections, preparing requests, and processing responses.\n- To reduce time, spreading requests across multiple servers and choosing faster libraries like phast HTTP are recommended.\n\n[29:44](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=1784) Discusses deploying an auto scroller and handling code\n\n- Auto scroller can be adjusted from 0 to 60 based on time of insertion, with effective results reported\n- Data can be sent within 2 hours, up to 60 points at 100-400 requests per second; detailed results pending visible\n\n[32:17](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=1937) Discussion on using Go for functions and app development\n\n- Exploring the limitations and challenges of using Go for app development\n- Considering the integration of Go with web views and mobile development\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/yEboOPUZ2wE?si=JMbdUW3d1A8Fxfao&amp;start=1950\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[38:19](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=2299) AI technology has potential in creating media content.\n\n- Introduction to Eleven Labs and their AI-powered voice synthesis capabilities.\n- Demonstration of creating natural-sounding synthetic voices using Eleven Labs' platform.\n- The conversation is purely fictitious, created to illustrate the potential of AI.\n- Basic ethical principles and mindfulness are important in developing and using AI.\n\n[40:15](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=2415) Develop wisdom and compassion, live in harmony with technology, and stay connected to nature and others.\n\n- Personal development through wisdom and compassion.\n- Utilize technology for personal growth and helping others while staying connected to nature and each other.\n- Use cases for AI-generated voices in various content creation scenarios.\n- Examples of dialog generation and live synthesis of text to speech in multiple languages.\n\n[45:04](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=2704) Discussing AI voice translation and commentary tools\n\n- Exploring ways to improve voice translation accuracy and efficiency\n- Integrating real-time translation features with different voices for better user experience\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/yEboOPUZ2wE?si=ufHKJQpHE5u6QBQ2&amp;start=2486\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[47:51](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=2871) Discussion on the cost and potential issues with AI voice impersonation services.\n\n- Usage of AI voice impersonation services can cost around 30 dollars for 2 hours, but some services may charge 50 dollars with poor response.\n- Impersonation of voices can lead to misinformation and potential epidemic, citing an example of using it to copy audio clips of cursing.\n\n[53:53](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3233) Data transformation process using APIs and smart contracts.\n\n- Raw data is transformed using an API file to interact with smart contracts.\n- The system supports decoding famous protocols and provides a spellbook for user data management.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/yEboOPUZ2wE?si=ZNySuOHg7S3jop8M&amp;start=3076\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[56:31](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3391) The algorithm is used for indexing and mapping data.\n\n- The algorithm indexes the data and continuously updates the mappings.\n- It is used for retrieving and organizing specific information.\n\n[1:02:27](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3747) Comparing mapping techniques and their impact on user experience\n\n- Detailed walkthrough of using Eleven Labs' tools to create synthetic voices.\n- Explanation of the process, including text-to-speech conversion and voice customization.\n- One mapping technique focuses on the semantic layer, while the other focuses on fields that make more sense to the user.\n- The mapping technique automatically updates and adds versions based on user demand and contributes to creating a spellbook for user retrieval.\n\n[1:05:18](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3918) Introduction to a powerful tool for retrieving and processing data via API.\n\n- Demonstration of calling an API to retrieve addresses using Discord names.\n- Comparison of this tool with traditional indexers and advantages of flexibility and data retrieval capabilities.\n\n[1:10:29](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=4229) Designing a comprehensive system for software services\n\n- The system will cover all modules, including big data and GB\n- Supports direct deod and event loog, and has powerful query capabilities\n\n[1:13:45](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=4425) Discussing data ranking and AI applications\n\n- Exploration of using AI for writing market data and synthesizing information\n- Explanation of data types and attributes affecting data accuracy\n\n[1:19:37](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=4777) Using Lom for re-ranking can improve search results\n\n- Lom helps to calculate points for improving search queries\n- Combining re-ranking with other methods can enhance query results\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/yEboOPUZ2wE?si=1oGoeibK9_jy6CXi&amp;start=4593\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:22:15](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=4935) Explanation of Ranking and Formula Calculation\n\n- Discussion on the mathematical process behind ranking and synthesizing multiple lists\n- Explanation of the formula used to calculate the ranking score and the steps involved\n\n[1:27:26](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=5246) Reranking and AI Voice\n\n- Discussing the process of relying on a trained model to re-rank documents using AI.\n- Exploring the use of available methods for ranking and discussing their accuracy compared to existing F Model.\n\n[1:29:45](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=5385) The importance of evaluating and adjusting AI algorithms for accuracy\n\n- Discussion about using F score or similar methods to evaluate and adjust algorithms until they yield the highest score\n- Importance of human intervention and assessment in determining the accuracy of AI algorithms\n\n---\n\n**Tóm tắt ngắn nội dung**\n\n[00:03](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3) Thảo luận về các chủ đề sắp tới và các sự kiện gần đây.\n\n[14:23](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=863) Thảo luận về phân phối ICY và kế hoạch phát thưởng\n\n[22:14](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=1334) Xu hướng mới trong lập trình Go \n\n[24:41](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=1481) Tối ưu hóa các yêu cầu HTTP để thực thi nhanh hơn\n\n[29:44](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=1784) Thảo luận về việc triển khai trình cuộn tự động và mã xử lý\n\n[32:17](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=1937) Thảo luận về việc sử dụng Go cho các chức năng và phát triển ứng dụng\n\n[38:19](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=2299) Công nghệ AI có tiềm năng trong việc tạo ra nội dung truyền thông.\n\n[40:15](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=2415) Phát triển trí tuệ và lòng trắc ẩn, sống hòa hợp với công nghệ và luôn kết nối với thiên nhiên và những người khác.\n\n[45:04](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=2704) Thảo luận về công cụ dịch giọng nói và bình luận AI\n\n[47:51](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=2871) Thảo luận về chi phí và các vấn đề tiềm ẩn với dịch vụ mạo danh giọng nói AI.\n\n[53:53](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3233) Quá trình chuyển đổi dữ liệu bằng API và hợp đồng thông minh.\n\n[56:31](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3391) Thuật toán được sử dụng để lập chỉ mục và ánh xạ dữ liệu.\n\n[1:02:27](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3747) So sánh các kỹ thuật lập bản đồ và tác động của chúng đến trải nghiệm người dùng\n\n[1:05:18](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3918) Giới thiệu một công cụ mạnh mẽ để truy xuất và xử lý dữ liệu qua API.\n\n[1:10:29](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=4229) Thiết kế hệ thống toàn diện cho các dịch vụ phần mềm\n\n[1:13:45](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=4425) Thảo luận về xếp hạng dữ liệu và ứng dụng AI\n\n[1:19:37](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=4777) Sử dụng Lom để xếp hạng lại có thể cải thiện kết quả tìm kiếm\n\n[1:22:15](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=4935) Giải thích về xếp hạng và tính toán công thức\n\n[1:27:26](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=5246) Sắp xếp lại và giọng nói AI\n\n[1:29:45](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=5385) Tầm quan trọng của việc đánh giá và điều chỉnh thuật toán AI cho chính xác\n\n---\n\n[00:03](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3) Thảo luận về các chủ đề sắp tới và các sự kiện gần đây.\n\n- Giới thiệu khách tham dự và thảo luận về buổi ra mắt sản phẩm tuần tới.\n- Xem xét số liệu thống kê gần đây và phân tích các hoạt động của tuần trước.\n\n[14:23](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=863) Thảo luận về phân phối ICY và kế hoạch reward\n\n- Cuộc trò chuyện bao gồm các chi tiết về phân phối IC và các chi phí liên quan.\n- Thảo luận về việc thực hiện kế hoạch tiền lương mới và hỗ trợ một dự án mới.\n\n[22:14](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=1334) Xu hướng mới trong lập trình Go \n\n- Xu hướng của các bài viết tập trung vào thử nghiệm Go 1.2 1.23, các chức năng xếp hạng và chung, các bài viết về emx và trình lược tả Go mới.\n- Hacker đạo đức hàng đầu ở Ba Lan đã thử gửi 500 yêu cầu tới 25 triệu máy chủ bằng Go, nhận thấy việc này đơn giản và hiệu quả.\n\n[24:41](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=1481) Tối ưu hóa các yêu cầu HTTP để thực thi nhanh hơn\n\n- Quá trình này bao gồm việc phân giải DNS, tạo kết nối TCP, chuẩn bị yêu cầu và xử lý phản hồi.\n- Để giảm thời gian, nên phân bổ các yêu cầu trên nhiều máy chủ và chọn các thư viện nhanh hơn như phast http.\n\n[29:44](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=1784) Thảo luận về việc triển khai trình cuộn tự động và mã xử lý\n\n- Thanh cuộn tự động có thể được điều chỉnh từ 0 đến 60 dựa trên thời gian chèn, với kết quả hiệu quả được báo cáo\n- Dữ liệu có thể được gửi trong vòng 2 giờ, lên tới 60 điểm với tốc độ 100-400 yêu cầu mỗi giây; kết quả chi tiết đang chờ hiển thị\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/yEboOPUZ2wE?si=EqqbTisjVPVTo1Q6&amp;start=1715\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[32:17](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=1937) Thảo luận về việc sử dụng Go cho các chức năng và phát triển ứng dụng\n\n- Khám phá những hạn chế và thách thức của việc sử dụng Go để phát triển ứng dụng\n- Xem xét việc tích hợp Go với lượt xem web và phát triển trên thiết bị di động\n\n[38:19](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=2299) Công nghệ AI có tiềm năng trong việc tạo ra nội dung truyền thông.\n\n- Cuộc trò chuyện hoàn toàn là hư cấu, được tạo ra để minh họa tiềm năng của AI.\n- Các nguyên tắc đạo đức cơ bản và chánh niệm rất quan trọng trong việc phát triển và sử dụng AI.\n\n[40:15](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=2415) Phát triển trí tuệ và lòng trắc ẩn, sống hòa hợp với công nghệ và luôn kết nối với thiên nhiên và những người khác.\n\n- Phát triển cá nhân thông qua trí tuệ và lòng từ bi.\n- Sử dụng công nghệ để phát triển cá nhân và giúp đỡ người khác trong khi vẫn kết nối với thiên nhiên và với nhau.\n\n[45:04](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=2704) Thảo luận về công cụ dịch giọng nói và bình luận AI\n\n- Khám phá các cách để cải thiện độ chính xác và hiệu quả của bản dịch giọng nói\n- Tích hợp tính năng dịch thời gian thực với nhiều giọng nói khác nhau để mang lại trải nghiệm tốt hơn cho người dùng\n\n[47:51](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=2871) Thảo luận về chi phí và các vấn đề tiềm ẩn với dịch vụ mạo danh giọng nói AI.\n\n- Việc sử dụng dịch vụ mạo danh giọng nói AI có thể tốn khoảng 30 đô la trong 2 giờ, nhưng một số dịch vụ có thể tính phí 50 đô la nếu phản hồi kém.\n- Việc mạo danh giọng nói có thể dẫn đến thông tin sai lệch và tiềm ẩn dịch bệnh, trích dẫn một ví dụ về việc sử dụng nó để sao chép các đoạn âm thanh chửi bới.\n\n[53:53](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3233) Quá trình chuyển đổi dữ liệu bằng API và hợp đồng thông minh.\n\n- Dữ liệu thô được chuyển đổi bằng tệp API để tương tác với hợp đồng thông minh.\n- Hệ thống hỗ trợ giải mã các giao thức nổi tiếng và cung cấp sổ chính tả để quản lý dữ liệu người dùng.\n\n[56:31](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3391) Thuật toán được sử dụng để lập chỉ mục và ánh xạ dữ liệu.\n\n- Thuật toán lập chỉ mục dữ liệu và liên tục cập nhật ánh xạ.\n- Nó được sử dụng để lấy và tổ chức thông tin cụ thể.\n\n[1:02:27](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3747) So sánh các kỹ thuật lập bản đồ và tác động của chúng đến trải nghiệm người dùng\n\n- Một kỹ thuật ánh xạ tập trung vào lớp ngữ nghĩa, trong khi kỹ thuật kia tập trung vào các trường có ý nghĩa hơn đối với người dùng.\n- Kỹ thuật ánh xạ tự động cập nhật và bổ sung các phiên bản dựa trên nhu cầu của người dùng và góp phần tạo ra một cuốn sách chính tả để người dùng truy xuất.\n\n[1:05:18](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=3918) Giới thiệu một công cụ mạnh mẽ để truy xuất và xử lý dữ liệu qua API.\n\n- Trình diễn cách gọi API để truy xuất địa chỉ bằng tên Discord.\n- So sánh công cụ này với các công cụ lập chỉ mục truyền thống và ưu điểm về tính linh hoạt và khả năng truy xuất dữ liệu.\n\n[1:10:29](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=4229) Thiết kế hệ thống toàn diện cho các dịch vụ phần mềm\n\n- Hệ thống sẽ bao gồm tất cả các mô-đun, bao gồm dữ liệu lớn và GB\n- Hỗ trợ ghi nhật ký sự kiện và ghi trực tiếp, đồng thời có khả năng truy vấn mạnh mẽ\n\n[1:13:45](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=4425) Thảo luận về xếp hạng dữ liệu và ứng dụng AI\n\n- Thăm dò sử dụng AI để ghi dữ liệu thị trường và tổng hợp thông tin\n- Giải thích về các loại dữ liệu và thuộc tính ảnh hưởng đến độ chính xác của dữ liệu\n\n[1:19:37](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=4777) Sử dụng Lom để xếp hạng lại có thể cải thiện kết quả tìm kiếm\n\n- Lom giúp tính điểm để cải thiện truy vấn tìm kiếm\n- Kết hợp xếp hạng lại với các phương pháp khác có thể nâng cao kết quả truy vấn\n\n[1:22:15](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=4935) Giải thích về xếp hạng và tính toán công thức\n\n- Thảo luận về quy trình toán học đằng sau việc xếp hạng và tổng hợp nhiều danh sách\n- Giải thích công thức tính điểm xếp hạng và các bước thực hiện\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/yEboOPUZ2wE?si=RpK5V8L-aYNxIza_&amp;start=4759\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:27:26](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=5246) Sắp xếp lại và giọng nói AI\n\n- Thảo luận về quá trình dựa vào mô hình đã được huấn luyện để sắp xếp lại tài liệu bằng AI.\n- Khám phá việc sử dụng các phương pháp có sẵn để xếp hạng và thảo luận về độ chính xác của chúng so với Mô hình F hiện có.\n\n[1:29:45](https://www.youtube.com/watch?v=yEboOPUZ2wE&t=5385) Tầm quan trọng của việc đánh giá và điều chỉnh thuật toán AI cho chính xác\n\n- Thảo luận về việc sử dụng điểm F hoặc các phương pháp tương tự để đánh giá và điều chỉnh thuật toán cho đến khi đạt điểm cao nhất\n- Tầm quan trọng của sự can thiệp và đánh giá của con người trong việc xác định độ chính xác của thuật toán AI\n","title":"OGIF Office Hours #16 - Golang weekly #4, TIL in Dune's query, AI voice clone demo and Re-ranking in RAG system.","short_title":"#16 Go weekly, Dune query, AI voice clone, RAG re-ranking","description":"Our sixteenth office hours community discussion will cover a range of topics including Golang commentary updates, insights on TIL in Dune's query, a demo of AI voice cloning, and advancements in re-ranking within the RAG system. Join us for an engaging session designed to promote collaborative learning and growth among our members.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Mon Jul 29 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/16-20240726.md","slugArray":["updates","ogif","16-20240726"]},{"content":"\n94 minutes\n\n**Short Summary for Community Call July**\n\n[00:04](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=4) Discussion on the current state of technology investment in Vietnam\n\n[02:42](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=162) Overview of Vietnam's investment landscape and key players\n\n[11:08](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=668) Consulting and market strength assessment\n\n[16:35](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=995) Introduction of a new referral and commission model for the team\n\n[19:19](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=1159) Focus on software automation in team building for sustainability\n\n[27:05](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=1625) Introducing the Ring Model for consulting work\n\n[31:42](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=1902) Managing and adjusting work hours for sustainability\n\n[34:01](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=2041) Understanding system design and consulting in comparison to other industries\n\n[47:56](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=2876) Presentation on C4 model for subscription systems\n\n[55:54](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=3354) Discussing system design and main flow types in a payment system\n\n[58:33](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=3513) Discussing system design and database usage\n\n[1:05:30](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=3930) Interview with Hieu about his experience living in the US\n\n[1:08:02](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=4082) Discussion on navigating the job market in Vietnam\n\n[1:15:56](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=4556) Focus on software development and system design and wrap-up and plans for next week's meeting\n\n---\n\n**Detailed Summary**\n\n[00:04](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=4) Discussion on technology investment trends in Vietnam\n\n- Vietnam's investment decline is much less severe compared to the world's 35% decline.\n- Investment in Vietnam's technology sector decreased by 17% compared to previous years\n- Vietnam still ranks third in technology investment in Southeast Asia, behind Singapore and Indonesia\n- Healthcare and education sectors are receiving increased investment\n\n[02:42](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=162) Overview of Vietnam's investment landscape and key players\n\n- Payment and retail sectors saw a significant decrease in investment\n- E-commerce and payment-related investments have declined\n- Vietnam is still third in investment rankings, with significant investment from VCs\n- Key players like venture are actively investing in startups, particularly in fintech and generative startups\n- Healthcare and education sectors are experiencing growth in investment\n\n[07:59](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=479) Importance of effort before expecting results\n\n- Users need to put in effort before expecting financial gains from a solution\n- Consulting is challenging and requires following a clear path\n- Discussion on the growing interest in AI and generative AI startups in Southeast Asia\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/R2DS-nyo_jI?si=q9LRr4x3KJQDwkQW&amp;start=93\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[11:08](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=668) Consulting and market strength assessment\n\n- Consultants can assess market strength and share experiences with others.\n- Traditional markets and crypto markets differ in resources and promises made to investors.\n\n[16:35](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=995) Introduction of a new referral and commission model\n\n- Explanation of the team's referral system and commission structure\n- Discussion on how commissions are calculated and distributed among team members\n- Exploring how individuals receive a small part of the commission based on introductions\n- Introduction of a new layer in the referral system for indirect referrals\n- Highlights the gradual updates in the commission mechanism and future software development\n\n[19:19](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=1159) Focus on software automation in team building for sustainability\n\n- Discussion on the importance of software in automation and building strong teams\n- Emphasis on equal distribution of cash flow among team members for sustainability\n\n[24:47](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=1487) Challenges of creating software without proper guidance\n\n- There is a lack of qualified advisors for product creation.\n- Distinguishing between coding and software development is crucial.\n\n[27:05](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=1625) Explanation of the Ring Model for consulting work\n\n- Discussion on the importance of tracking time and effort in consulting projects\n- Ring Model is emerging as a key approach for consulting in agencies and companies.\n- Introduction of timesheet systems and project management practices\n- Under the Ring Model, consultants handle end-to-end solutions for clients, requiring a high level of responsibility and flexibility.\n- Explanation of how the Ring Model affects sales targets and performance evaluation\n\n[31:42](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=1902) Managing and adjusting work hours for sustainability\n\n- Discussion about managing and strictly adjusting the number of work hours on a weekly or monthly basis.\n- Consideration of work hour promises and flexibility, as well as the challenges of unpredictable project requirements.\n\n[34:01](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=2041) Understanding system design and consulting in comparison to other industries\n\n- System design and consulting can be understood better by referring to older industries like accounting and law.\n- Effort put into research and problem-solving should be recognized and valued in the consulting field.\n\n[38:59](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=2339) Introduction to a tool with potential system design capabilities\n\n- The tool is fast, capable of fixing issues, and can handle various tasks efficiently\n- There is potential for future improvements and developments to make it more user-friendly and production-ready\n\n[41:35](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=2495) Discussion on Java as a standard language for the enterprise\n\n- Java was discussed as the standard language choice for the enterprise, seeking comments on its relevance\n- Comparison with older times when Java was more prevalent and experienced users were easier to find\n\n[47:56](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=2876) Presentation on C4 model for subscription systems\n\n- Overview of the high-level diagram for a subscription system similar to Notion\n- Explanation of the C1, C2, and C3 levels of the C4 model\n- Discussion on various components such as third-party payment services, customer management, payment services, and notification systems\n- Detailing the subscription plan configuration and management, including user overrides\n\n[50:46](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=3046) Implementing payment gateway and service handling\n\n- Module for updating card or payment method format and invoice creation\n- Utilization of database, logs, and payment service proxy for gateway communication\n\n[55:54](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=3354) Discussing system design and main flow types in a payment system\n\n- Exploring how design changes from monthly to annual subscriptions\n- Considering the use of C4 Spec API for developer reference\n\n[58:33](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=3513) Discussing system design and database usage\n\n- Redesigning a system based on official sources and personal ideas\n- Comparing progress and planning for future follow-ups\n- Feedback and discussion on the C4 model presentation\n- Suggestions for improving the presentation and adding more detail\n- Discussion on the importance of showing specific flows and use cases in the design\n\n[1:05:30](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=3930) Interview with Hieu about his experience living in the US\n\n- Discussion on weather differences and adaptation to the new environment\n- Explanation of the process for obtaining necessary documents and licenses in the US\n- Insights into the job market and salary expectations for software engineers in the US\n\n[1:08:02](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=4082) Discussion on navigating the job market in Vietnam\n\n- Questions and answers about life in the US\n- Insights into the cost of living and comparisons with Vietnam\n- Brief mention of Hieu's birthday celebration in the US\n- Process of obtaining necessary documents like a social network, Green card, and bank accounts for job requirements.\n\n[1:13:27](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=4407) Wrap-up and plans for next week's meeting\n\n- Team project report compilation process was discussed\n- Scheduling presentations for the next meeting\n- Discussion on focusing on learning new technologies and skills\n- Team compiles artifact projects and items into a report monthly for project evaluation\n- Encouragement for team members to engage in system design discussions and communities\n\n[1:15:56](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=4556) Final remarks and closing of the meeting\n\n- Reminder to join relevant online communities for system design discussions\n- Emphasis on the importance of detailed knowledge in software design\n- Importance of using resources now for future benefit\n- Discussion about the role of team members in the design process\n- Farewell and wishes for a good weekend\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/R2DS-nyo_jI?si=xE8RswAB755iPkHY&amp;start=3412\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n---\n\n[00:04](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=4) Thảo luận về tình hình đầu tư công nghệ hiện nay tại Việt Nam\n\n[02:42](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=162) Tổng quan về cảnh quan đầu tư và các nhà đầu tư chính tại Việt Nam\n\n[11:08](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=668) Tư vấn và đánh giá sức mạnh thị trường\n\n[16:35](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=995) Giới thiệu mô hình giới thiệu và hoa hồng mới cho đội ngũ\n\n[19:19](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=1159) Tập trung vào tự động hóa phần mềm trong xây dựng đội ngũ bền vững\n\n[27:05](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=1625) Giới thiệu mô hình Ring cho công việc tư vấn\n\n[31:42](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=1902) Quản lý và điều chỉnh giờ làm việc để bền vững\n\n[34:01](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=2041) Hiểu về thiết kế hệ thống và tư vấn so với các ngành công nghiệp khác\n\n[47:56](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=2876) Trình bày về mô hình C4 cho hệ thống đăng ký\n\n[55:54](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=3354) Thảo luận về thiết kế hệ thống và các loại luồng chính trong hệ thống thanh toán\n\n[58:33](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=3513) Thảo luận về thiết kế hệ thống và việc sử dụng cơ sở dữ liệu\n\n[1:05:30](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=3930) Phỏng vấn Hieu về trải nghiệm sống ở Mỹ\n\n[1:08:02](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=4082) Thảo luận về cách điều hướng thị trường việc làm ở Việt Nam\n\n[1:15:56](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=4556) Tập trung vào phát triển phần mềm và thiết kế hệ thống và kết thúc cuộc họp, lên kế hoạch cho cuộc họp tuần tới\n\n---\n[00:04](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=4) Thảo luận về xu hướng đầu tư công nghệ tại Việt Nam\n- Sự suy giảm đầu tư của Việt Nam ít nghiêm trọng hơn nhiều so với mức giảm 35% của thế giới.\n- Đầu tư vào lĩnh vực công nghệ tại Việt Nam giảm 17% so với các năm trước.\n- Việt Nam vẫn đứng thứ ba về đầu tư công nghệ ở Đông Nam Á, sau Singapore và Indonesia.\n- Các lĩnh vực y tế và giáo dục đang nhận được đầu tư tăng lên.\n\n[02:42](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=162) Tổng quan về cảnh quan đầu tư của Việt Nam và những người chơi chính\n\n- Các lĩnh vực thanh toán và bán lẻ đã thấy sự giảm đáng kể trong đầu tư.\n- Đầu tư liên quan đến thương mại điện tử và thanh toán đã giảm.\n- Việt Nam vẫn đứng thứ ba trong bảng xếp hạng đầu tư, với đầu tư đáng kể từ các quỹ VC.\n- Các nhà đầu tư chủ chốt như venture đang tích cực đầu tư vào các startup, đặc biệt là trong lĩnh vực fintech và generative startups.\n- Các lĩnh vực y tế và giáo dục đang trải qua sự tăng trưởng trong đầu tư.\n\n[07:59](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=479) Tầm quan trọng của nỗ lực trước khi mong đợi kết quả\n\n- Người dùng cần phải nỗ lực trước khi mong đợi lợi nhuận tài chính từ một giải pháp.\n- Tư vấn là một thách thức và yêu cầu tuân theo một lộ trình rõ ràng.\n- Thảo luận về sự quan tâm ngày càng tăng đối với AI và các startup về AI generative ở Đông Nam Á.\n\n[11:08](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=668) Tư vấn và đánh giá sức mạnh thị trường\n\n- Các nhà tư vấn có thể đánh giá sức mạnh thị trường và chia sẻ kinh nghiệm với người khác.\n- Các thị trường truyền thống và thị trường tiền điện tử khác nhau về tài nguyên và những lời hứa với nhà đầu tư.\n\n[16:35](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=995) Giới thiệu mô hình giới thiệu và hoa hồng mới\n\n- Giải thích về hệ thống giới thiệu của đội ngũ và cơ cấu hoa hồng.\n- Thảo luận về cách tính toán và phân phối hoa hồng giữa các thành viên trong đội.\n- Khám phá cách cá nhân nhận được một phần nhỏ của hoa hồng dựa trên các giới thiệu.\n- Giới thiệu một lớp mới trong hệ thống giới thiệu cho các giới thiệu gián tiếp.\n- Nêu bật các cập nhật dần dần trong cơ chế hoa hồng và phát triển phần mềm trong tương lai.\n\n[19:19](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=1159) Tập trung vào tự động hóa phần mềm trong xây dựng đội ngũ bền vững\n\n- Thảo luận về tầm quan trọng của phần mềm trong tự động hóa và xây dựng đội ngũ mạnh mẽ.\n- Nhấn mạnh vào việc phân phối dòng tiền đồng đều giữa các thành viên trong đội để bền vững.\n\n[24:47](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=1487) Thách thức của việc tạo phần mềm mà không có hướng dẫn phù hợp\n\n- Thiếu các cố vấn đủ năng lực để tạo sản phẩm.\n- Việc phân biệt giữa mã hóa và phát triển phần mềm là điều cần thiết.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/R2DS-nyo_jI?si=Ytvw4AFT1s3auDU8&amp;start=1401\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[27:05](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=1625) Giải thích mô hình Ring cho công việc tư vấn\n\n- Thảo luận về tầm quan trọng của việc theo dõi thời gian và nỗ lực trong các dự án tư vấn.\n- Mô hình Ring đang nổi lên như một phương pháp chính cho tư vấn trong các cơ quan và công ty.\n- Giới thiệu hệ thống chấm công và thực hành quản lý dự án.\n- Theo mô hình Ring, các nhà tư vấn xử lý các giải pháp từ đầu đến cuối cho khách hàng, đòi hỏi mức độ trách nhiệm và linh hoạt cao.\n- Giải thích cách mô hình Ring ảnh hưởng đến các mục tiêu doanh số và đánh giá hiệu suất.\n\n[31:42](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=1902) Quản lý và điều chỉnh giờ làm việc để bền vững\n\n- Thảo luận về việc quản lý và điều chỉnh chặt chẽ số giờ làm việc hàng tuần hoặc hàng tháng.\n- Xem xét các lời hứa về giờ làm việc và sự linh hoạt, cũng như các thách thức của yêu cầu dự án không lường trước.\n\n[34:01](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=2041) Hiểu về thiết kế hệ thống và tư vấn so với các ngành công nghiệp khác\n\n- Thiết kế hệ thống và tư vấn có thể được hiểu rõ hơn bằng cách tham khảo các ngành công nghiệp cũ như kế toán và luật pháp.\n- Nỗ lực bỏ ra trong nghiên cứu và giải quyết vấn đề nên được công nhận và đánh giá cao trong lĩnh vực tư vấn.\n\n[38:59](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=2339) Giới thiệu công cụ với khả năng thiết kế hệ thống tiềm năng\n\n- Công cụ này nhanh, có khả năng sửa lỗi và có thể xử lý nhiều tác vụ một cách hiệu quả.\n- Có tiềm năng cho các cải tiến và phát triển trong tương lai để làm cho nó thân thiện với người dùng và sẵn sàng cho sản xuất.\n\n[41:35](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=2495) Thảo luận về Java như ngôn ngữ tiêu chuẩn cho doanh nghiệp\n\n- Java được thảo luận như là lựa chọn ngôn ngữ tiêu chuẩn cho doanh nghiệp, tìm kiếm ý kiến về sự liên quan của nó.\n- So sánh với những thời điểm trước đây khi Java phổ biến hơn và người dùng có kinh nghiệm dễ tìm hơn.\n\n[47:56](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=2876) Trình bày mô hình C4 cho hệ thống đăng ký\n\n- Tổng quan về sơ đồ cấp cao cho hệ thống đăng ký tương tự như Notion.\n- Giải thích về các cấp độ C1, C2, và C3 của mô hình C4.\n- Thảo luận về các thành phần như dịch vụ thanh toán của bên thứ ba, quản lý khách hàng, dịch vụ thanh toán và hệ thống thông báo.\n- Chi tiết cấu hình và quản lý gói đăng ký, bao gồm các tùy chọn người dùng.\n\n[50:46](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=3046) Triển khai cổng thanh toán và xử lý dịch vụ\n\n- Module cập nhật thẻ hoặc định dạng phương thức thanh toán và tạo hóa đơn.\n- Sử dụng cơ sở dữ liệu, nhật ký và proxy dịch vụ thanh toán để giao tiếp với cổng thanh toán.\n\n[55:54](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=3354) Thảo luận về thiết kế hệ thống và các loại luồng chính trong hệ thống thanh toán\n\n- Khám phá cách thay đổi thiết kế từ đăng ký hàng tháng sang hàng năm.\n- Xem xét việc sử dụng C4 Spec API để tham khảo cho các nhà phát triển.\n\n[58:33](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=3513) Thảo luận về thiết kế hệ thống và việc sử dụng cơ sở dữ liệu\n\n- Thiết kế lại hệ thống dựa trên các nguồn chính thức và ý tưởng cá nhân.\n- So sánh tiến trình và lập kế hoạch cho các theo dõi trong tương lai.\n- Phản hồi và thảo luận về bài trình bày mô hình C4.\n- Đề xuất cải thiện bài trình bày và thêm chi tiết.\n- Thảo luận về tầm quan trọng của việc hiển thị các luồng và trường hợp sử dụng cụ thể trong thiết kế.\n\n[1:05:30](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=3930) Phỏng vấn Hiếu về trải nghiệm sống ở Mỹ\n\n- Thảo luận về sự khác biệt thời tiết và thích nghi với môi trường mới.\n- Giải thích quy trình lấy các tài liệu và giấy phép cần thiết ở Mỹ.\n- Những hiểu biết về thị trường việc làm và kỳ vọng về lương cho các kỹ sư phần mềm ở Mỹ.\n\n[1:08:02](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=4082) Thảo luận về cách điều hướng thị trường việc làm ở Việt Nam\n\n- Hỏi và trả lời về cuộc sống ở Mỹ.\n- Những hiểu biết về chi phí sinh hoạt và so sánh với Việt Nam.\n- Đề cập ngắn gọn về sinh nhật của Hieu ở Mỹ.\n- Quy trình lấy các tài liệu cần thiết như mạng xã hội, thẻ xanh, và tài khoản ngân hàng cho yêu cầu công việc.\n\n[1:13:27](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=4407) Tổng kết và kế hoạch cho cuộc họp tuần tới\n\n- Thảo luận về quy trình tổng hợp báo cáo dự án của đội ngũ.\n- Lên lịch các bài thuyết trình cho cuộc họp tiếp theo.\n- Thảo luận về việc tập trung vào học các công nghệ và kỹ năng mới.\n- Đội ngũ tổng hợp các dự án hiện vật và mục vào báo cáo hàng tháng để đánh giá dự án.\n- Khuyến khích các thành viên trong đội tham gia vào các cuộc thảo luận và cộng đồng thiết kế hệ thống.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/R2DS-nyo_jI?si=gkUsPG5jodlhpFkP&amp;start=4388\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:15:56](https://www.youtube.com/watch?v=R2DS-nyo_jI&t=4556) Nhận xét cuối cùng và kết thúc cuộc họp\n\n- Nhắc nhở tham gia vào các cộng đồng trực tuyến liên quan đến thảo luận thiết kế hệ thống.\n- Nhấn mạnh tầm quan trọng của kiến thức chi tiết trong thiết kế phần mềm.\n- Tầm quan trọng của việc sử dụng các nguồn tài nguyên hiện có cho lợi ích tương lai.\n- Thảo luận về vai trò của các thành viên trong đội ngũ trong quá trình thiết kế.\n- Lời chào tạm biệt và chúc một cuối tuần tốt lành.\n","title":"OGIF Office Hours #17 - Community Call July, C4 Model, and Interview Life in the US","short_title":"#17 Community Call July, C4 Model, Interview Life in the US","description":"Join us for our seventeenth OGIF community call on Aug 2nd, where we'll discuss the current state of technology investment in Vietnam, introduce a new referral and commission model for the team, present the C4 model for subscription systems, and interview Hieu about his experience living in the US. We'll wrap up with plans for next week's meeting. This session will be guided by topics selected through community input, promoting a collaborative and insightful environment for all participants.\"","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Mon Aug 05 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/17-20240802.md","slugArray":["updates","ogif","17-20240802"]},{"content":"\n90 minutes\n\n**Short Summary**\n\n[00:03](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3) System design and consulting\n\n[15:16](https://www.youtube.com/watch?v=o3Bqal31XNk&t=916) Organizing team chat on Discord\n\n[18:54](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1134) Long-term topic value\n\n[20:23](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1223) Future system design presentations\n\n[25:19](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1519) Team progress and community involvement\n\n[32:35](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1955) Building a complete ecosystem\n\n[38:23](https://www.youtube.com/watch?v=o3Bqal31XNk&t=2303) Alpha configuration in computation\n\n[41:42](https://www.youtube.com/watch?v=o3Bqal31XNk&t=2502) Reciprocal Fusion with data sources\n\n[51:59](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3119) System design and automation\n\n[59:21](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3561) Introduction to generative UI\n\n[1:04:57](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3897) Chatbot system design\n\n[1:11:06](https://www.youtube.com/watch?v=o3Bqal31XNk&t=4266) Client-side vs. server-side rendering\n\n[1:21:27](https://www.youtube.com/watch?v=o3Bqal31XNk&t=4887) React in 2023 and Expo framework\n\n[1:26:12](https://www.youtube.com/watch?v=o3Bqal31XNk&t=5172) React Native challenges\n\n[1:28:03](https://www.youtube.com/watch?v=o3Bqal31XNk&t=5283) Content strategy for social networks\n\n---\n\n**Detailed Summary**\n\n[00:03](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3) Discussion on system design and consulting\n\n- Sharing insights on implementing system design concepts\n- Planning for future consulting sessions and topics\n\n[15:16](https://www.youtube.com/watch?v=o3Bqal31XNk&t=916) Organizing team chat knowledge on Discord into specific topics and content\n\n- Converting notes and in-depth Devbox posts into structured content focused on specific topics\n- Bien demoed a sample content from Debox, naming files, and section sizes to facilitate learning about Debox\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/o3Bqal31XNk?si=mqQ2cz8N6_VnR1pd&amp;start=1050\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[18:54](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1134) Discussion on the long-term value of the topic\n\n- This topic is similar to a textbook layout covering various subjects, serving as a recognized reward\n- This series will include topics like 200 ICY and other essential subjects for the group, which need to be structured into a comprehensive content map\n\n[20:23](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1223) Discussion on system design topics for future presentations\n\n- Collaborating on long-term topics with team members is crucial for easier presentations\n- Suggesting creating multiple discussion topics or answering specific questions to generate diverse content\n\n[23:40](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1420) Discussion on available resources and how to request them\n\n- Explaining the available quantity for claims within a given timeframe and the claim process\n- Exploring additional methods to request resources, such as through reports and building open requests\n\n[25:19](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1519) Discussion on team progress and community involvement\n\n- Emphasizing tracking progress through quantity and contributions\n- Using ICY for decentralized team activity and visibility\n\n[30:42](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1842) Building an ecosystem and core functionality\n\n- Code running on WebAssembly for fast performance\n- Supporting multiple GUI utilities with simple Java-like code\n\n[32:35](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1955) Discussion on building a complete ecosystem with multiple applications and access control\n\n- Examples of applications such as neural network model viewers, IDEs, and canvases with various features and support\n- Discussing the shift towards maintaining an open-source project with clean code practices\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/o3Bqal31XNk?si=nHUX8KYs1JUaPiNR&amp;start=1881\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[36:44](https://www.youtube.com/watch?v=o3Bqal31XNk&t=2204) Discussion on vector similarity and ranking using S and F models\n\n- Explaining how to use vector similarity for ranking and comparison\n- Using the V model to rank and sort vectors efficiently\n\n[38:23](https://www.youtube.com/watch?v=o3Bqal31XNk&t=2303) Alpha configuration to influence computation results\n\n- Adjusting Alpha values to prioritize certain outcomes over others\n- Describing the basic process of querying and ranking keywords for user input data\n\n[41:42](https://www.youtube.com/watch?v=o3Bqal31XNk&t=2502) Reciprocal Fusion working with different data sources\n\n- Analysis and ranking are required\n- Focusing on user behavior and metrics from both online and offline matrices\n\n[43:28](https://www.youtube.com/watch?v=o3Bqal31XNk&t=2608) Discussion on average accuracy of two parameters\n\n- Explaining the concept of accuracy in system design and real-world outcomes\n- Calculating the F1 score for precision and recall in system design\n\n[46:39](https://www.youtube.com/watch?v=o3Bqal31XNk&t=2799) Evaluating efficiency with less similar and simpler datasets\n\n- Less similarity in topics and simpler questions lead to higher efficiency\n- Studies on larger and more diverse datasets show greater efficiency\n\n[48:35](https://www.youtube.com/watch?v=o3Bqal31XNk&t=2915) Formula for calculating the effectiveness of two substances\n\n- This formula stems from the fact that two substances can exist in different fear categories\n- Analysis through fear categories helps calculate the substance's effectiveness\n\n[51:59](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3119) Discussion on system design and automation\n\n- Considering manual data processing versus automation\n- Implementation details and community acceptance\n\n[53:43](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3223) Discussion on accuracy and computation in system design\n\n- This process includes estimating data and evaluating accuracy levels\n- Using matrices and metrics to assess accuracy and monitor the system\n\n\n\n[57:10](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3430) The concept of vector addition and subtraction is very simple\n\n- Calculating vectors based on alpha values, such as multiplying by 0.7\n- Discussing testing and automation in system design\n\n[59:21](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3561) Introduction to generative UI\n\n- Defining and explaining the generative UI\n- Implementation details and community acceptance\n\n[53:43](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3223) Discussion on accuracy and computation in system design\n\n- This process includes estimating data and evaluating accuracy levels\n- Using matrices and metrics to assess accuracy and monitor the system\n\n[57:10](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3430) The concept of vector addition and subtraction is very simple\n\n- Calculating vectors based on alpha values, such as multiplying by 0.7\n- Discussing testing and automation in system design\n\n[59:21](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3561) Introduction to generative UI\n\n- Defining and explaining the generative UI agenda\n- Examples of popular solutions, general ideas, and demos introduced\n\n[1:03:18](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3798) Discussion on popular Vercel solutions for managing UI\n\n- Vercel uses server-side components to handle the flow\n- Creating graph components to pause for seamless updates\n\n[1:04:57](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3897) Fully documented system design for chatbots\n\n- System design documentation emphasizes using Go for chatbot development and general ideas/methods\n- The final section handles events, builds messages, and interacts with the frontend for display\n\n[1:09:02](https://www.youtube.com/watch?v=o3Bqal31XNk&t=4142) Discussion on system design and implementation details\n\n- Explaining how the system reacts to different events and inputs\n- Comparing event handling between different components\n\n[1:11:06](https://www.youtube.com/watch?v=o3Bqal31XNk&t=4266) Two ways to render data on the web: client-side rendering and server-side rendering\n\n- Client-side rendering: data is rendered on the client side, which can be controlled by the client agent\n- Server-side rendering: handling events and rendering directly on the server\n\n[1:15:27](https://www.youtube.com/watch?v=o3Bqal31XNk&t=4527) Using API data for movie search functionality\n\n- Events like 'when the tool starts' and 'when the tool ends' trigger actions\n- Updating the UI and sending messages based on tool events\n\n[1:17:22](https://www.youtube.com/watch?v=o3Bqal31XNk&t=4642) Discussion on system design and UI testing\n\n- Explaining the integration of testing and UI in the system design phase\n- Detailing the role of backend agents in rendering data for the UI\n\n[1:21:27](https://www.youtube.com/watch?v=o3Bqal31XNk&t=4887) The state of React in 2023\n\n- React server components remain a highlight with over 86% usage in web applications\n- Google's ability to index pages with heavy JavaScript like SPAs without affecting SEO\n\n[1:23:06](https://www.youtube.com/watch?v=o3Bqal31XNk&t=4986) Expo framework recommended for building, testing, and deploying applications\n\n- Expo offers a complete solution for building, testing, and deploying applications efficiently\n- The JavaScript ecosystem, including React and TypeScript, continues to evolve and is worth investing in\n\n[1:26:12](https://www.youtube.com/watch?v=o3Bqal31XNk&t=5172) Challenges of React Native compared to other frameworks\n\n- React Native lacks a dedicated mobile language, making competition difficult\n- Some developers use Turbo B tools to boost productivity\n\n[1:28:03](https://www.youtube.com/watch?v=o3Bqal31XNk&t=5283) Discussion on content push strategy to social networks\n\n- The importance of sharing content externally for feedback and visibility\n- Planning for future events like radio talks and guest invitations to engage the group\n\n---\n\n**Tóm tắt thảo luận chính**\n\n[00:03](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3) Thiết kế hệ thống và tư vấn\n\n[15:16](https://www.youtube.com/watch?v=o3Bqal31XNk&t=916) Tổ chức nội dung chat nhóm trên Discord\n\n[18:54](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1134) Giá trị lâu dài của các chủ đề\n\n[20:23](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1223) Các bài thuyết trình thiết kế hệ thống trong tương lai\n\n[25:19](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1519) Tiến độ nhóm và sự tham gia của cộng đồng\n\n[32:35](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1955) Xây dựng hệ sinh thái hoàn chỉnh\n\n[38:23](https://www.youtube.com/watch?v=o3Bqal31XNk&t=2303) Cấu hình Alpha trong tính toán\n\n[41:42](https://www.youtube.com/watch?v=o3Bqal31XNk&t=2502) Reciprocal Fusion với các nguồn dữ liệu\n\n[51:59](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3119) Thiết kế hệ thống và tự động hóa\n\n[59:21](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3561) Giới thiệu về UI tạo sinh\n\n[1:04:57](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3897) Thiết kế hệ thống chatbot\n\n[1:11:06](https://www.youtube.com/watch?v=o3Bqal31XNk&t=4266) Kết xuất phía máy khách và máy chủ\n\n[1:21:27](https://www.youtube.com/watch?v=o3Bqal31XNk&t=4887) Tình hình React năm 2023 và khung Expo\n\n[1:26:12](https://www.youtube.com/watch?v=o3Bqal31XNk&t=5172) Thách thức của React Native\n\n[1:28:03](https://www.youtube.com/watch?v=o3Bqal31XNk&t=5283) Chiến lược nội dung cho mạng xã hội\n\n---\n\nDetailed Summary\n\n[00:03](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3) Thảo luận về thiết kế hệ thống và tư vấn\n\n- Chia sẻ hiểu biết về việc triển khai các khái niệm thiết kế hệ thống\n- Lên kế hoạch cho các buổi tư vấn và chủ đề trong tương lai\n\n[15:16](https://www.youtube.com/watch?v=o3Bqal31XNk&t=916) Những kiến thức của team chat trên discord được tổ chức thành chủ đề và content cụ thể.\n\n- Content của các bài Devbox cho chuyên sâu hơn được đưa lên thành dạng mấy bài đề cập đến các chủ đề cụ thể.\n- Biên đã demo Map of content của Debox, đặt tên file và section size để phù hợp với việc học về Debox.\n\n[18:54](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1134) Thảo luận về giá trị lâu dài của chủ đề\n\n- Chủ đề này tương tự như bố cục của một cuốn sách giáo khoa bao gồm nhiều chủ đề khác nhau và đóng vai trò như một phần thưởng để được công nhận\n- Chuỗi bài này sẽ bao gồm các chủ đề như 200 ICY và các chủ đề cần thiết khác cho nhóm, cần được sắp xếp hợp lý thành một bản đồ nội dung toàn diện\n\n[20:23](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1223) Thảo luận về các chủ đề thiết kế hệ thống cho các bài thuyết trình trong tương lai\n\n- Việc hợp tác về các chủ đề dài hạn với các thành viên trong nhóm rất quan trọng để trình bày dễ dàng hơn.\n- Gợi ý tạo nhiều chủ đề thảo luận hoặc trả lời các câu hỏi cụ thể để tạo ra nhiều nội dung khác nhau\n\n[23:40](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1420) Thảo luận về các nguồn lực có sẵn và cách để yêu cầu chúng\n\n- Giải thích số lượng có sẵn để yêu cầu bồi thường trong một khoảng thời gian nhất định và quy trình yêu cầu bồi thường\n- Khám phá các phương pháp bổ sung để yêu cầu tài nguyên như thông qua báo cáo và xây dựng các yêu cầu mở\n\n[25:19](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1519) Thảo luận về tiến độ của nhóm và sự tham gia của cộng đồng\n\n- Nhấn mạnh việc theo dõi tiến độ thông qua số lượng và đóng góp\n- Sử dụng ICY cho hoạt động nhóm phi tập trung và khả năng hiển thị\n\n[30:42](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1842) Xây dựng hệ sinh thái và chức năng cốt lõi\n\n- Mã chạy trên web assembly để có hiệu suất nhanh\n- Hỗ trợ nhiều tiện ích GUI với mã đơn giản giống Java\n\n[32:35](https://www.youtube.com/watch?v=o3Bqal31XNk&t=1955) Thảo luận về việc xây dựng một hệ sinh thái đầy đủ với nhiều ứng dụng và kiểm soát truy cập\n\n- Nêu ví dụ về các ứng dụng như trình xem mô hình mạng nơ-ron, IDE và canvas với nhiều tính năng và hỗ trợ khác nhau\n- Nói về việc chuyển trọng tâm sang duy trì một dự án nguồn mở với các biện pháp thực hành mã sạch\n\n[36:44](https://www.youtube.com/watch?v=o3Bqal31XNk&t=2204) Thảo luận về sự tương đồng và xếp hạng vectơ bằng cách sử dụng mô hình S và F\n\n- Giải thích về cách sử dụng độ tương đồng của vectơ để xếp hạng và so sánh\n- Sử dụng Mô hình V để xếp hạng và sắp xếp các Vector một cách hiệu quả\n\n[38:23](https://www.youtube.com/watch?v=o3Bqal31XNk&t=2303) Cấu hình Alpha để tác động đến kết quả tính toán\n\n- Điều chỉnh giá trị Alpha để ưu tiên một số kết quả nhất định hơn các kết quả khác.\n- Mô tả quy trình cơ sở của việc truy vấn và xếp hạng từ khóa cho dữ liệu đầu vào của người dùng.\n\n[41:42](https://www.youtube.com/watch?v=o3Bqal31XNk&t=2502) Reciprocal Fusion làm việc với các căn cứ dữ liệu khác nhau\n\n- Cần có phân tích và xếp hạng\n- Tập trung vào behavior của người dùng và các chỉ số của các ma trận online và offline\n\n[43:28](https://www.youtube.com/watch?v=o3Bqal31XNk&t=2608) Thảo luận về độ chính xác trung bình của hai tham số\n\n- Giải thích khái niệm về độ chính xác trong thiết kế hệ thống và kết quả thực tế\n- Tính toán điểm F1 cho độ chính xác và khả năng thu hồi trong thiết kế hệ thống\n\n[46:39](https://www.youtube.com/watch?v=o3Bqal31XNk&t=2799) Đánh giá hiệu quả với các tập dữ liệu ít giống nhau và đơn giản hơn\n\n- Ít sự tương đồng về chủ đề và các câu hỏi đơn giản hơn dẫn đến hiệu quả cao hơn\n- Nghiên cứu trên các tập dữ liệu lớn hơn và đa dạng hơn cho thấy hiệu quả cao hơn\n\n[48:35](https://www.youtube.com/watch?v=o3Bqal31XNk&t=2915) Công thức tính hiệu quả của hai chất\n\n- Công thức này xuất phát từ việc hai chất có thể tồn tại trong nhiều thể loại sợ khác nhau\n- Phân tích qua các thể loại sợ, giúp tính toán được hiệu quả của chất\n\n[51:59](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3119) Thảo luận về thiết kế hệ thống và tự động hóa\n\n- Xem xét xử lý dữ liệu thủ công so với tự động\n- Chi tiết triển khai và sự chấp nhận của cộng đồng\n\n[53:43](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3223) Thảo luận về độ chính xác và tính toán trong thiết kế hệ thống\n\n- Quá trình này bao gồm việc tính toán dữ liệu dự kiến và đánh giá mức độ chính xác\n- Sử dụng ma trận và số liệu để đánh giá độ chính xác và giám sát hệ thống\n\n[57:10](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3430) Khái niệm cộng và trừ vectơ rất đơn giản.\n\n- Tính toán vectơ dựa trên giá trị alpha, chẳng hạn như nhân với 0,7.\n- Việc thử nghiệm và tự động hóa trong thiết kế hệ thống cũng đang được thảo luận.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/o3Bqal31XNk?si=nbQzic9y2cwrfcS9&amp;start=2681\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[59:21](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3561) Giới thiệu về UI tạo sinh\n\n- Định nghĩa và giải thích về chương trình nghị sự của UI tạo sinh\n- Ví dụ, các giải pháp phổ biến, ý tưởng chung và bản demo được giới thiệu\n\n[1:03:18](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3798) Thảo luận về giải pháp phổ biến Vercel để quản lý UI\n\n- Vercel sử dụng thành phần máy chủ để xử lý luồng\n- Tạo thành phần graap tạm dừng để cập nhật liền mạch\n\n[1:04:57](https://www.youtube.com/watch?v=o3Bqal31XNk&t=3897) Thiết kế hệ thống được ghi chép đầy đủ cho chatbot\n\n- Tài liệu thiết kế hệ thống nhấn mạnh việc sử dụng Go để phát triển chatbot và các ý tưởng/phương pháp chung\n- Phần cuối xử lý các sự kiện, xây dựng các thông điệp và tương tác với phần đầu để hiển thị\n\n[1:09:02](https://www.youtube.com/watch?v=o3Bqal31XNk&t=4142) Thảo luận về thiết kế hệ thống và chi tiết triển khai\n\n- Giải thích cách hệ thống phản ứng với các sự kiện và đầu vào khác nhau\n- So sánh việc xử lý các sự kiện giữa các thành phần khác nhau\n\n[1:11:06](https://www.youtube.com/watch?v=o3Bqal31XNk&t=4266) Hai cách để hiển thị dữ liệu trên web: hiển thị phía máy khách và hiển thị phía máy chủ\n\n- Kết xuất phía máy khách: kết xuất dữ liệu ở phía máy khách, có thể được kiểm soát bởi tác nhân của máy khách\n- Kết xuất phía máy chủ: xử lý các sự kiện và kết xuất trực tiếp trên máy chủ\n\n[1:15:27](https://www.youtube.com/watch?v=o3Bqal31XNk&t=4527) Sử dụng dữ liệu API cho chức năng tìm kiếm phim\n\n- Các sự kiện như 'khi công cụ bắt đầu' và 'khi công cụ kết thúc' kích hoạt hành động\n- Cập nhật UI và gửi tin nhắn dựa trên sự kiện công cụ\n\n[1:17:22](https://www.youtube.com/watch?v=o3Bqal31XNk&t=4642) Thảo luận về thiết kế hệ thống và thử nghiệm UI\n\n- Giải thích về sự tích hợp của thử nghiệm và UI trong giai đoạn thiết kế hệ thống\n- Chi tiết vai trò của các tác nhân phụ trợ trong việc kết xuất dữ liệu cho UI\n\n[1:21:27](https://www.youtube.com/watch?v=o3Bqal31XNk&t=4887) Tình hình React năm 2023\n\n- Thành phần máy chủ React vẫn là điểm nổi bật với hơn 86% lượt sử dụng trong các ứng dụng web.\n- Khả năng lập chỉ mục các trang có nhiều JavaScript như SPA của Google mà không ảnh hưởng đến SEO.\n\n[1:23:06](https://www.youtube.com/watch?v=o3Bqal31XNk&t=4986) Khung Expo được khuyến nghị để xây dựng, thử nghiệm và triển khai ứng dụng.\n\n- Expo cung cấp giải pháp hoàn chỉnh để xây dựng, thử nghiệm và triển khai ứng dụng một cách hiệu quả.\n- Hệ sinh thái JavaScript, bao gồm React và TypeScript, liên tục phát triển và đáng để đầu tư.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/o3Bqal31XNk?si=npXR4qiw7XjCZdWZ&amp;start=4954\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:26:12](https://www.youtube.com/watch?v=o3Bqal31XNk&t=5172) Những thách thức của React Native khi so sánh với các framework khác\n\n- React Native thiếu ngôn ngữ di động chuyên dụng khiến việc cạnh tranh trở nên khó khăn\n- Một số nhà phát triển sử dụng công cụ Turbo B để tăng năng suất\n\n[1:28:03](https://www.youtube.com/watch?v=o3Bqal31XNk&t=5283) Thảo luận về chiến lược đẩy nội dung lên mạng xã hội\n\n- Tầm quan trọng của việc chia sẻ nội dung ra bên ngoài để có phản hồi và khả năng hiển thị\n- Lên kế hoạch cho các sự kiện trong tương lai như các buổi nói chuyện trên radio và lời mời khách mời để thu hút nhóm\n","title":"OGIF Office Hours #18 - Golang weekly, Devbox MOC, Search retrieval in RAG, Generative UI, FE monthly #1","short_title":"#18 Go weekly, RAG, UI, FE updates","description":"OGIF 18 covers key discussions on Golang weekly #6, insights into search retrieval in RAG, advancements in generative UI, and the first edition of FE monthly. This edition provides valuable updates for developers and tech enthusiasts, offering a deep dive into the latest trends and techniques in software development.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Wed Aug 14 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/18-20240809.md","slugArray":["updates","ogif","18-20240809"]},{"content":"\n82 minutes\n\n### Topics & Highlights\n\n**00:00** - Introduction and Setup\n\nIntroduction to the session, checking attendance, and preparing for the recording.\n\n**00:06:00 - Go Programming and Common Pitfalls**\n\nDiscussion on the release of Go 1.23, covering key updates and common mistakes in Go, such as pass by value issues and range loop behavior.\n\n**00:17:06 - User Interface (UI) Design and Error Management**\n\nExploration of best practices in UI design, focusing on error management, user feedback, and improving user experience through clear communication and design choices.\n\n**00:39:05 - File Sharing System Design**\n\nDetailed presentation on the design and implementation of a file-sharing system, including database structure, permission handling, and file path logic.\n\n**00:47:44 - Query Optimization Strategies**\n\nStrategies for optimizing queries to achieve faster system performance.\n\n**01:00:17 - Dify AI Demo and Workflow Automation**\n\nDemonstration of Dify AI tools and workflow automation, showcasing how to integrate AI into system workflows and optimize processes using AI-powered agents.\n\n**01:12:16 - Summary and Concluding Thoughts**\n\nWrapping up the session with key takeaways and a final summary.\n\n---\n\n### Vietnamese transcript\n\n**00:00:00** - Anh Thành có ở đây không? Mọi người có nghe rõ không? Chắc là chưa, để kiểm tra lại xem. Alo, alo, mọi người nghe thấy chưa? OK rồi, restart lại phần này. Tuần này chúng ta sẽ tiếp tục chủ đề của tuần trước, có thể một số anh em chưa tham gia ngay được. Hiện tại thấy có hai team chuẩn bị vào, ai sẽ lên trước nhỉ? Sẵn sàng chưa?\n\n**00:06:00** - Mình đã record chưa nhỉ? Bật record lên nhé. OK rồi, mọi người cứ vào dần sau nhé. Để xem nào, mình có cần restart lại không? Không cần đâu, cứ tiếp tục thôi. Tuần trước có nói về Go 1.23 đã chính thức phát hành, mọi người nên xem qua các ghi chú của bản phát hành. Dù chúng ta đã giới thiệu về interactive note trước đó, nhưng xem qua bản đầy đủ cũng thấy có những chi tiết nhỏ đáng chú ý.\n\n**00:08:17** - Khi mọi người viết websocket trong Go, thường thì sẽ sử dụng Gorilla. Tuy nhiên, có một thư viện khác mà mình đã thử qua, nó có những tính năng đảm bảo tốt hơn, và không gặp nhiều vấn đề như Gorilla. Thư viện này có tuổi đời khá lâu, khoảng 5-6 năm rồi. Nhưng gần đây, do tác giả ban đầu không còn duy trì nó nữa, một nhóm mới đã tiếp nhận và tiếp tục phát triển. Nếu ai chưa thử thì có thể xem qua.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8qR8-2GxFgs?si=tcnbwSwNGF4qRDtY&amp;start=480\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**00:08:58** - Một số vấn đề thường gặp phải khi sử dụng Go, đặc biệt là với những người mới bắt đầu, có một số lỗi dễ mắc phải. Ví dụ, mình nhớ hồi mới làm intern, có một lần bị lỗi liên quan đến việc pass by value trong Go. Strings trong Go là pass by value, nên khi bạn thay đổi giá trị của một string trong một slice, nó sẽ không ảnh hưởng đến string ban đầu.\n\n**00:11:04** - Trong một vòng lặp range qua slice của các struct, nếu bạn muốn thay đổi giá trị của một field nào đó thì nó cũng sẽ không work như mong đợi, vì mỗi lần lặp qua range, nó tạo ra một bản copy của phần tử đó, nên khi bạn thay đổi giá trị thì chỉ thay đổi bản copy chứ không phải bản gốc.\n\n**00:11:43** - Để sửa lỗi này, bạn có thể sử dụng cách range qua index của array thay vì range qua từng phần tử. Điều này giúp bạn truy cập trực tiếp vào phần tử gốc của array và thay đổi giá trị một cách đúng đắn.\n\n**00:12:33** - Một ví dụ khác là khi bạn có một slice trong Go, và bạn muốn thao tác với một phần tử cụ thể. Ví dụ, bạn muốn thêm một giá trị vào một slice mới từ slice gốc, điều này có thể thay đổi cả slice gốc nếu không cẩn thận. Để tránh việc này, bạn có thể thêm một số vào cuối slice để chỉ định rằng slice mới này sẽ sử dụng một array khác làm backing store.\n\n**00:15:00** - Khi bạn sử dụng slice và muốn giữ nguyên giá trị của slice ban đầu, bạn cần cẩn thận với việc slice có thể chỉ đơn giản là tham chiếu đến cùng một array dưới lớp, dẫn đến việc thay đổi giá trị slice mới sẽ ảnh hưởng đến slice ban đầu.\n\n**00:17:06** - Việc quản lý lỗi trong thiết kế giao diện người dùng là rất quan trọng. Thay vì cố gắng làm cho người dùng không phạm lỗi, chúng ta nên tạo ra một giao diện thân thiện, cho phép họ hành động sai và sửa sai một cách dễ dàng. Việc thiết kế như vậy sẽ giúp cải thiện trải nghiệm người dùng.\n\n**00:18:07** - Một trong những cách để làm điều này là cung cấp cảnh báo và phản hồi ngay lập tức khi người dùng thực hiện hành động sai. Ví dụ, trong Shopify, họ đã thay đổi cách hiển thị trang chỉnh sửa sản phẩm để cảnh báo người dùng khi có thay đổi chưa lưu.\n\n**00:22:38** - Đôi khi việc cung cấp cho người dùng khả năng quay lại các bước trước đó có thể giúp họ cảm thấy thoải mái hơn khi sử dụng sản phẩm. Ví dụ, Google Drive cho phép bạn undo các hành động như xóa một file, giúp người dùng dễ dàng khôi phục lại những gì họ đã làm sai.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8qR8-2GxFgs?si=zAkhDl1Dxw7ny74S&amp;start=1328\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**00:27:43** - Một ví dụ khác là trong các sản phẩm xây dựng, chúng ta cần đảm bảo rằng mỗi hành động của người dùng đều có cảnh báo hoặc thông báo nếu có vấn đề xảy ra, để họ có thể xử lý kịp thời.\n\n**00:30:39** - Trong các ứng dụng như Twitter hay Discord, việc giới hạn số ký tự và cung cấp phản hồi ngay lập tức khi người dùng vượt quá giới hạn giúp họ dễ dàng điều chỉnh và tránh lỗi.\n\n**00:31:23** - Việc cung cấp hướng dẫn và ngăn chặn lỗi ngay từ đầu là rất quan trọng. Các ứng dụng phức tạp thường sử dụng tooltips hoặc hướng dẫn on-boarding để giúp người dùng hiểu rõ cách sử dụng.\n\n**00:32:54** - Khi thiết kế sản phẩm, chúng ta cần phải quan tâm không chỉ đến các trường hợp sử dụng thông thường mà còn cả các trường hợp lỗi để đảm bảo rằng trải nghiệm người dùng luôn được cải thiện.\n\n**00:35:52** - Khi làm việc với UI, chúng ta cần phải xác định rõ các trường hợp lỗi và thiết kế sao cho chúng dễ dàng xử lý. Điều này không chỉ giúp cải thiện trải nghiệm người dùng mà còn giúp giảm thiểu lỗi trong quá trình sử dụng sản phẩm.\n\n**00:38:20** - Khi triển khai các tính năng mới, chúng ta cần đảm bảo rằng dữ liệu cần thiết luôn được lưu trữ và có thể truy xuất lại khi cần thiết. Điều này sẽ giúp đảm bảo rằng hệ thống luôn hoạt động một cách ổn định và tin cậy.\n\n**00:39:05** - Để hệ thống hoạt động một cách hiệu quả, chúng ta cần phải cẩn thận với việc quản lý quyền truy cập và chia sẻ dữ liệu. Các tính năng như phân quyền và thiết lập mật khẩu cần được triển khai cẩn thận để đảm bảo rằng chỉ những người được ủy quyền mới có thể truy cập vào dữ liệu quan trọng.\n\n**00:41:28** - Được rồi, giờ mọi người nhìn thấy màn hình của em chưa? OK, thấy rồi nhé, tiếp tục với agenda thôi anh em ơi.\n\n**00:42:43** - Bài hôm nay em sẽ nói về việc thiết kế một hệ thống chia sẻ tệp tin (sharing file system). Hệ thống này sẽ không có nhiều điều mới mẻ, nhưng em hy vọng nếu ai đó từng làm các project tương tự thì có thể tiết kiệm thời gian tìm hiểu. Bài thuyết trình của em sẽ gồm ba phần. Phần đầu tiên là overview của hệ thống.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8qR8-2GxFgs?si=ZxjAsNn2mBJ__g8j&amp;start=2546\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**00:43:27** - Đây là sơ đồ Use Case của hệ thống. Nó bao gồm các chức năng cơ bản như xem (view), chỉnh sửa (edit), và tải lên (upload). Những chức năng này khá là đơn giản, nhưng yêu cầu đặt ra là phải tối ưu hóa các câu truy vấn (query) để hệ thống hoạt động nhanh nhất có thể. Các chức năng khác liên quan đến việc quản lý quyền truy cập (permission) và chia sẻ tệp tin (sharing). Phần này em sẽ chủ yếu nói về business logic và cách em thiết kế hệ thống như thế nào. Anh Thành chuyển qua trang tiếp theo giúp em.\n\n**00:44:17** - Phần hệ thống tệp tin (file system) này hướng đến cấu trúc cơ bản giống như các thư mục (folders) và tệp tin (files) mà mọi người xử lý hàng ngày trên máy tính của mình. Vì vậy, em sẽ đi nhanh qua phần này. Tiếp theo là thiết kế cơ sở dữ liệu (database design) của hệ thống.\n\n**00:45:01** - Đây là sơ đồ Entity Relationship (ER diagram) của hệ thống. Hệ thống này có cấu trúc cao nhất là workspace, chứa các người dùng (users) trong một nhóm. Mỗi user khi được tạo ra sẽ có một workspace riêng, và người dùng đó có thể mời thêm các thành viên (members) khác vào cùng làm việc trong workspace này. Tiếp theo là phần asset, bao gồm các tệp tin (files) và thư mục (folders). Các thông tin cơ bản của tệp tin sẽ bao gồm tên (name), URL, kích thước (size), trạng thái (status), và trạng thái ghim (pin). Đặc biệt là trường 'path' (đường dẫn tệp tin) trong asset, giúp quá trình query trở nên nhanh hơn. Phần này em sẽ giải thích kỹ hơn ở phần sau. Hai bảng còn lại liên quan đến việc xử lý logic chia sẻ tệp tin (sharing) và quyền truy cập (permission).\n\n**00:45:38** - Đây là phần logic cho đường dẫn tệp tin (file path). Đường dẫn tệp tin (file path) trong hệ thống được thiết kế để mang lại hiệu quả cao cho việc query hoặc xử lý các tác vụ liên quan đến tệp tin trong cơ sở dữ liệu. Ví dụ, nếu bạn muốn lấy phản hồi (feedback) cho một tài liệu có ID là d123, nó sẽ được tổng hợp từ tất cả các thư mục cha (parent directories) của nó như f789 và f123, nằm trong workspace w123. Nhờ vậy, bạn có thể dễ dàng lấy được tất cả các ID của các thư mục cha.\n\n**00:46:16** - Khi bạn muốn liệt kê (listing) các thư mục con (subdirectories) của một thư mục cụ thể, chẳng hạn như f123, bạn chỉ cần query các trường chứa thông tin về đường dẫn của nó (file path) có chứa f123 và workspace w123. Điều này làm cho việc liệt kê các thư mục con trở nên rất đơn giản và hiệu quả.\n\n**00:46:59** - Một trường hợp khác là khi bạn muốn di chuyển (move) một tệp tin, việc đầu tiên cần làm là liệt kê các thư mục mà tệp tin có thể được di chuyển đến. Các thư mục này phải đảm bảo không phải là con của chính tệp tin đó. Việc này được thực hiện bằng cách loại bỏ tất cả các thư mục mà trong đường dẫn của nó có chứa ID của tệp tin cần di chuyển. Ví dụ, nếu bạn muốn di chuyển tệp F11 từ folder 2 sang folder 1 với ID là f123, bạn cần loại bỏ tất cả các thư mục mà trong đường dẫn của nó có chứa ký tự f111.\n\n**00:47:44** - Sau khi di chuyển tệp tin, bạn chỉ cần cập nhật đường dẫn của nó từ đường dẫn cũ sang đường dẫn mới, và tất cả các thư mục con của nó cũng sẽ được cập nhật trong cùng một câu lệnh query duy nhất. Như em đã trình bày từ đầu, tất cả các câu truy vấn trong hệ thống này đều có độ phức tạp là O(1) hoặc O(2), giúp hệ thống hoạt động rất nhanh và tránh phải dùng transaction, tránh ảnh hưởng đến tốc độ của các câu truy vấn khác.\n\n**00:48:34** - Phần tiếp theo là về quyền truy cập (permission) và chia sẻ tệp tin (sharing). Phần này có ba chức năng chính: thiết lập quyền truy cập (Set permission) cho các thành viên trong hệ thống, chia sẻ tệp tin công khai (sharing public files) cho người dùng bên ngoài hệ thống, và thiết lập mật khẩu (set password) cho các tệp tin. Để em chuyển sang phần tiếp theo.\n\n**00:49:17** - Đây là sơ đồ cơ bản thể hiện quá trình khi một người dùng truy cập vào một tệp tin, hệ thống sẽ kiểm tra quyền truy cập (permission) của người dùng như thế nào. Đầu tiên, hệ thống sẽ kiểm tra quyền truy cập trực tiếp (direct permission) và quyền truy cập qua dự án (project permission). Quyền truy cập trực tiếp là những quyền được gán trực tiếp cho email của người dùng, ví dụ như quyền chỉnh sửa (edit) nếu người sở hữu (owner) của tệp tin đó đã gán cho email của người dùng quyền này. Nếu cả hai quyền này không thỏa mãn, hệ thống sẽ kiểm tra quyền truy cập công khai (public access).\n\n**00:50:03** - Việc kiểm tra quyền truy cập công khai (public access) ở đây có nghĩa là quyền truy cập của những người dùng như guest, tức là người dùng nằm ngoài hệ thống hoặc không thuộc workspace. Nếu người dùng này đăng nhập vào hệ thống, họ sẽ có quyền tương ứng với quyền công khai (public access) đã được thiết lập. Còn nếu tệp tin đó là công khai nhưng người dùng chưa đăng nhập, họ chỉ có quyền đọc (Read Only) mà không có quyền chỉnh sửa.\n\n**00:50:46** - Về mô hình dữ liệu (data model), hệ thống sẽ có hai bảng chính như em đã giới thiệu ở phần đầu: bảng `member_permission`, thể hiện quyền truy cập chung của tệp tin, và bảng `sub_permission`, thể hiện quyền truy cập cụ thể của một người dùng với email cụ thể. Bảng `member_permission` có mối quan hệ 1-1 với bảng `asset`, nghĩa là một tệp tin chỉ có một bộ quyền truy cập chính (main permission). Nó bao gồm các trường như `inherit` để cho biết quyền truy cập có được thừa hưởng từ thư mục cha hay không, `asset_id` để liên kết với bảng asset, `public_role` để chỉ định quyền công khai (public access), và `has_password` để xác định xem tệp tin có yêu cầu mật khẩu hay không.\n\n**00:52:16** - Khi tạo một tệp tin, hệ thống sẽ tạo một bộ quyền truy cập với thuộc tính `inherit` được thiết lập là `true`, tức là tệp tin này sẽ thừa hưởng tất cả các quyền truy cập từ thư mục cha của nó. Nếu có bất kỳ sự thay đổi nào về quyền truy cập, hệ thống sẽ loại bỏ thuộc tính `inherit` và tạo ra một bản ghi mới (record) trong bảng `sub_permission`.\n\n**00:54:10** - Về cơ bản, hệ thống hoạt động giống như các dịch vụ lưu trữ đám mây khác như Google Drive hay Notion. Tuy nhiên, điểm khác biệt ở đây là cách hệ thống xử lý các quyền truy cập đa tầng (multi-level permissions) một cách hiệu quả, tránh việc phải lặp lại các kiểm tra không cần thiết.\n\n**00:56:41** - Nếu có 10 thư mục, và thư mục thứ 10 là con của thư mục thứ nhất, thư mục thứ nhất có mật khẩu, thì cách kiểm tra mật khẩu của thư mục thứ 10 sẽ như thế nào? Đầu tiên, hệ thống sẽ kiểm tra quyền truy cập của thư mục thứ 10. Nếu quyền này được thừa hưởng từ thư mục cha, hệ thống sẽ tiếp tục kiểm tra thư mục cha gần nhất mà không thừa hưởng quyền truy cập từ các thư mục trên nữa. Nếu thư mục thứ 8 không thừa hưởng, quyền của thư mục thứ 10 sẽ phụ thuộc vào thư mục thứ 8. Nếu chỉ có thư mục thứ nhất là không thừa hưởng quyền truy cập, hệ thống sẽ kiểm tra trực tiếp trên thư mục thứ nhất.\n\n**00:59:34** - Đó là toàn bộ phần trình bày của em. Không biết mọi người có câu hỏi nào không? Nếu không, em xin cảm ơn mọi người đã lắng nghe.\n\n**00:57:20** - Ví dụ nhé, nếu thư mục thứ tám không có thuộc tính `inherit`, thì quyền của thư mục thứ mười sẽ phụ thuộc vào thư mục thứ tám. Nhưng nếu trường hợp của anh là chỉ có thư mục thứ nhất không có `inherit`, thì mình sẽ kiểm tra trực tiếp từ thư mục thứ nhất luôn. Ok, không biết anh em có gì cần thảo luận thêm về vấn đề này không? Để em kiểm tra lại xem có gì cần bổ sung không. Đúng rồi, để thực hiện điều này, hệ thống sẽ phải truy vấn ngược lại, từ các thư mục con lên các thư mục cha.\n\n**00:58:18** - Anh Hiếu, chắc anh chưa xem kỹ đoạn này, vì mấy cái này phải hiểu kỹ mới xử lý đúng được. Em có câu hỏi nào khác không? Thực ra tính năng mà Đạt vừa chia sẻ về việc chia sẻ tệp (sharing feature) khá giống với Notion hoặc Google Drive đúng không? Ừ, đúng vậy, bên VOT trước đây cũng đã từng làm một tính năng tương tự, nhưng phải xử lý đến hai hoặc ba tầng permission đúng không? Ừ, đúng rồi, rất phức tạp.\n\n**00:59:34** - Ok, mình còn mấy phút nữa để hẹn Tom demo nhanh cái workflow bên phía đi. Trong hai tháng vừa qua, team đã xây dựng một server đơn giản để test các workflow. Mục đích là để hình dung các quy trình có thể tối ưu như thế nào từ phía khách hàng, không chỉ riêng phía khách hàng mà team mình cũng có vài nhu cầu sử dụng AI nhưng chưa rõ cách tối ưu nó sao cho nhanh và gọn. Mình có thể dùng các giải pháp như Flowwise hoặc Airflow, nhưng chúng hơi phức tạp. Vì vậy, mình chọn LLM (Large Language Model) cho đơn giản hơn, mình sẽ xây dựng một agent hoặc một tool để xử lý.\n\n**01:00:17** - Nếu chúng ta thành công trong việc này, khi xây dựng các ứng dụng khác cho khách hàng hoặc app của mình, việc triển khai sẽ dễ dàng hơn. Giờ mình sẽ giới thiệu mọi người xem cái Memo chatbot mà bên Memo đang dùng. Thực sự thì bên Memo cũng có một chatbot kết nối với Dify, do mình lười code nên kết nối với nó để xử lý nhanh chóng hơn. Để xem nào, mạng bên Vân Phẳng dạo này cũng bị lag.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8qR8-2GxFgs?si=rSHJIdlRTNsdohGj&amp;start=3596\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**01:00:59** - Ok, thử lệnh \"get me the latest notes on Go\". Chatbot này sẽ theo một workflow giống như bên Eming xây dựng cho bên phía Tôn. Nó sẽ sử dụng mô hình AI để tạo câu lệnh SQL query, sau đó thực hiện truy vấn trên database. Mình có một file pre-setup để gọi query từ đấy và sau đó xuất kết quả ra dạng markdown. Mô hình (model) này không quá phức tạp, nhưng mình phải sử dụng một số kỹ thuật như prompt engineering, tức là kỹ thuật đưa đủ ngữ cảnh (context) và thông tin cho AI để nó trả lời đúng theo ý mình.\n\n**01:01:49** - Khi bạn thiết kế workflow như vậy, mục đích là làm sao cho nó chạy một cách trơn tru. Có hai cách: một là bạn phải code hành động (actions) đằng sau các function, hoặc là bạn phải làm prompt engineering để hướng dẫn AI tạo query SQL chính xác. Cái trick này hay dùng khi làm prototype hoặc làm nhanh cho khách hàng. Mình thiết lập server để mô hình AI tự suy luận cách query SQL, sau đó gửi kết quả trả về chatbot.\n\n**01:03:20** - Thực sự là phần “magic” của nó nằm ở chỗ mô tả (description) của các function call, nó chứa thông tin về các bảng (tables) trong Memo. Nếu không có phần này, khi mình chạy lệnh, AI không biết cần query bảng nào, dẫn đến lỗi. Đây là lý do tại sao prompt engineering rất quan trọng trong việc đảm bảo rằng AI nhận được đúng thông tin và tạo ra kết quả chính xác.\n\n**01:04:47** - Nếu mình thử chạy lại chatbot Memo mà không có description đúng, nó sẽ tạo ra một lỗi vì không biết bảng nào cần query. Trong trường hợp này, trick mà mình hay dùng cho prototype hoặc khi làm việc nhanh với khách hàng sẽ rất hữu ích. Những gì bạn có thể làm với AI gần như không giới hạn, miễn là bạn hiểu rõ cách làm prompt engineering.\n\n**01:05:31** - Ví dụ, bạn có thể thay đổi description để AI không query một cơ sở dữ liệu cụ thể nào đó, mà có thể là một bảng khác, hoặc một nguồn khác. Điều này thực sự là một lợi thế khi bạn cần tích hợp nhiều hệ thống hoặc xử lý nhiều loại dữ liệu khác nhau. Anh Hơn có nói rằng mình có nhiều trò hay ho, nhưng thực ra đó chỉ là các helper tools để hỗ trợ việc xây dựng ứng dụng AI. Trên server local, mình có thể chạy một số tool để dịch văn bản hoặc tạo các truy vấn SQL.\n\n**01:07:18** - Ví dụ, nếu mình cần một chatbot để trả lời các truy vấn SQL, miễn là mình có một database và một sơ đồ schema rõ ràng, mình có thể yêu cầu AI query các ghi chú mới nhất trong Memo. Một số truy vấn phức tạp có thể rất khó làm bằng tay, nhưng với việc sử dụng AI, mình có thể nhập đủ context và để AI xử lý phần còn lại.\n\n**01:09:55** - Những gì chúng ta làm với Dify chủ yếu là sắp xếp các assistant hoặc code các chức năng đơn giản như agent workflow. Đây chủ yếu là việc gọi function, nhưng khi làm việc phức tạp hơn, mô hình AI vẫn có thể xử lý tốt. Ví dụ, mình đã từng xây dựng một mô hình đơn giản để báo cáo, và Dify chỉ là một nền tảng để mình code những chức năng này.\n\n**01:11:27** - Nếu bạn có một server LLM hoặc một server API tương thích với OpenAI, bạn có thể tích hợp nó vào hệ thống của mình. Sau đó, bạn có thể thêm các module hoặc các chức năng mới vào nền tảng này. Điều này cho phép bạn tạo ra các ứng dụng AI phức tạp mà không cần phải xây dựng mọi thứ từ đầu.\n\n**01:12:16** - Dify có thể được so sánh với một công cụ code AI, nhưng mình không sử dụng code trực tiếp mà chủ yếu sử dụng các chức năng mà nền tảng cung cấp để tạo chatbot hoặc agent. Bạn có thể cấu hình các system prompt và tạo các agent để xử lý các tác vụ cụ thể. Dify giúp bạn tổ chức lại công việc này mà không cần phải rời khỏi nền tảng hoặc dùng các công cụ bên ngoài như OpenAI hoặc Anthropic.\n\n**01:13:13** - Nó cũng cho phép bạn thêm các tài liệu như PDF hoặc text để cung cấp kiến thức cho AI. Ví dụ, nếu bạn có kiến thức nội bộ trong công ty, bạn có thể upload và index nó để AI có thể hiểu và trả lời chính xác hơn. Một số chức năng như Google Search hoặc Doo có sẵn, bạn có thể dùng chúng để tìm kiếm trên internet và tương tác với AI.\n\n**01:13:13** - Nó cũng cho phép bạn thêm các tài liệu như PDF hoặc text để cung cấp kiến thức cho AI. Ví dụ, nếu bạn có kiến thức nội bộ trong công ty, bạn có thể upload và index nó để AI có thể hiểu và trả lời chính xác hơn. Một số chức năng như Google Search hoặc Doo có sẵn, bạn có thể dùng chúng để tìm kiếm trên internet và tương tác với AI.\n\n**01:14:49** - Một ví dụ khác là sử dụng công cụ Tally để tìm kiếm thông tin về Paris Olympics, nó sẽ thực hiện tìm kiếm trên internet và trả về kết quả qua API. Các workflow cũng được xây dựng như một sơ đồ, cho phép bạn hình dung cách thức hoạt động của toàn bộ hệ thống.\n\n**01:15:45** - Mình biết việc giới thiệu như vậy có hơi phức tạp, nhưng ý tưởng chính là Dify cho phép bạn tổ chức và sử dụng các công cụ AI một cách hiệu quả. Một số tool có sẵn trong Dify là hot code, không thể tùy chỉnh nhiều, nhưng bạn có thể tự tạo các custom tools theo nhu cầu của mình.\n\n**01:16:28** - Mình có tạo ra một vài tool riêng và cũng có các tool sẵn trên nền tảng, tất cả đều là workflow được chuyển đổi thành các yêu cầu API. Bạn có thể tạo các yêu cầu như vậy để tương tác với nền tảng Dify, ví dụ như tạo logo hoặc thực hiện các yêu cầu URL.\n\n**01:17:26** - Bạn có thể đặt API key của mình trong các yêu cầu này và sử dụng chúng để thực hiện các tác vụ như tìm kiếm, tạo các tác vụ mới hoặc tương tác với API bên ngoài. Điều này giúp bạn tạo ra các ứng dụng tùy chỉnh mà không cần phải viết code quá nhiều.\n\n**01:18:09** - Ví dụ, anh Quang đã triển khai việc tạo pull request (PR) tự động cho Playground dựa trên các agent mà chúng ta đã thiết lập. Chúng ta có thể tương tác với agent qua API để thực hiện các tác vụ phức tạp hơn, và việc này có thể giúp tối ưu hóa quy trình làm việc.\n\n**01:19:07** - Mọi người có câu hỏi gì không? Nếu không thì mình sẽ dừng lại ở đây. Mình nghĩ chắc buổi hôm nay vậy là đủ rồi, để dành phần tiếp theo cho các buổi sau.\n\n---\n\n### English Transcript\n\n**00:00:00** - Is Anh Thành here? Can everyone hear clearly? Maybe not, let me check again. Hello, hello, can you hear me now? OK, let's restart this section. This week, we'll continue the topic from last week, as some people might not have joined right away. I see two teams getting ready to join, who will go first? Are you ready?\n\n**00:06:00** - Have we started recording? Please turn on the recording. OK, let's continue, people can join as we go. Let me see, do we need to restart? No need, just keep going. Last week, we talked about Go 1.23, which has officially been released. Everyone should check out the release notes. Although we previously introduced the interactive notes, reviewing the full release notes reveals some small but noteworthy details.\n\n**00:08:17** - When writing WebSocket in Go, people usually use Gorilla. However, there's another library I've tried, which offers better guarantees and avoids some of the issues encountered with Gorilla. This library has been around for quite some time, about 5-6 years. But recently, as the original author stopped maintaining it, a new team has taken over and continued its development. If you haven't tried it, you might want to take a look.\n\n**00:08:58** - There are some common issues when using Go, especially for beginners, that can easily lead to mistakes. For example, I remember when I was an intern, I encountered an issue related to pass by value in Go. Strings in Go are passed by value, so when you modify the value of a string in a slice, it won’t affect the original string.\n\n**00:11:04** - In a loop that ranges over a slice of structs, if you want to modify a field value, it won't work as expected because each iteration of the range creates a copy of the element. So, when you change the value, you're only modifying the copy, not the original.\n\n**00:11:43** - To fix this, you can range over the index of the array instead of the elements. This allows you to access the original element of the array and modify its value correctly.\n\n**00:12:33** - Another example is when you have a slice in Go and want to manipulate a specific element. For instance, if you want to add a value to a new slice from the original slice, this could change the original slice if you're not careful. To avoid this, you can append a value to the end of the new slice to specify that this new slice will use a different array as the backing store.\n\n**00:15:00** - When using slices and wanting to keep the original slice intact, you need to be careful because a slice can simply reference the same underlying array, leading to changes in the new slice affecting the original slice.\n\n**00:17:06** - Error management in user interface design is critical. Instead of trying to prevent users from making mistakes, we should create a user-friendly interface that allows them to make mistakes and easily correct them. Such a design approach will enhance the user experience.\n\n**00:18:07** - One way to achieve this is by providing immediate warnings and feedback when users make a mistake. For example, in Shopify, they changed the product edit page to warn users when there are unsaved changes.\n\n**00:22:38** - Sometimes, giving users the ability to revert to previous steps can make them feel more comfortable using the product. For instance, Google Drive allows you to undo actions like deleting a file, making it easy for users to recover what they’ve done wrong.\n\n**00:27:43** - Another example is in construction-related products; we need to ensure that each user action triggers a warning or notification if there's an issue, allowing them to address it promptly.\n\n**00:30:39** - In applications like Twitter or Discord, limiting the character count and providing instant feedback when users exceed the limit helps them adjust and avoid mistakes.\n\n**00:31:23** - Providing guidance and preventing errors from the start is crucial. Complex applications often use tooltips or onboarding guides to help users understand how to use them correctly.\n\n**00:32:54** - When designing products, we need to consider not only the usual use cases but also error scenarios to ensure that the user experience is consistently improved.\n\n**00:35:52** - When working on UI, we need to clearly identify error cases and design them to be easily handled. This not only improves the user experience but also minimizes errors during product use.\n\n**00:38:20** - When deploying new features, we need to ensure that the necessary data is always stored and can be retrieved when needed. This will help ensure that the system operates reliably and stably.\n\n**00:39:05** - For the system to operate efficiently, we need to be careful with access management and data sharing. Features like permissions and password settings should be carefully implemented to ensure that only authorized users can access critical data.\n\n**00:41:28** - I think we should just reset everything. I've already sent that file to everyone; let me share my screen, Tom, could you check the screen for me? I’ve tried everything, but I can’t log in through the web anymore. If it still doesn’t work, I'll completely log out of the web. OK, now can everyone see my screen? Great, let's move on with the agenda.\n\n**00:42:43** - Today, I’ll talk about designing a sharing file system. This system might not have many new things, but I hope if anyone has worked on similar projects, they can save time in researching. My presentation will have three parts. The first part is the system overview.\n\n**00:43:27** - Here’s the Use Case diagram of the system. It includes basic functions like view, edit, and upload. These functions are quite simple, but the requirement is to optimize queries to make the system as fast as possible. Other functions related to permission and sharing will be covered in this part, focusing on the business logic and how I designed the system. Anh Thành, please move to the next slide.\n\n**00:44:17** - The file system part of this system aims for a basic structure similar to the folders and files that people handle daily on their computers. So, I will go through this part quickly. Next is the database design of the system.\n\n**00:45:01** - Here is the Entity Relationship (ER) diagram of the system. The highest structure in this system is the workspace, which contains users within a group. Each user, when created, will have their workspace, and that user can invite other members to work together in this workspace. Next are the assets, including files and folders. The basic information of a file will include its name, URL, size, status, and pin status. A special field is the ‘path’ in the asset, which helps make the query process faster. I will explain this further in the next part. The other two tables are related to handling the logic of sharing and permissions.\n\n**00:45:38** - This is the logic for file paths. The file path in the system is designed to be highly efficient for querying or handling tasks related to files in the database. For example, if you want to get feedback for a document with ID d123, it will be aggregated from all its parent directories like. \n\n**00:45:38** - This is the logic for file paths. The file path in the system is designed to be highly efficient for querying or handling tasks related to files in the database. For example, if you want to get feedback for a document with ID d123, it will be aggregated from all its parent directories like f789 and f123, located in workspace w123. This way, you can easily retrieve all the IDs of the parent directories.\n\n**00:46:16** - When you want to list the subdirectories of a specific directory, such as f123, you just need to query the fields containing its file path, including f123 and workspace w123. This makes listing subdirectories very simple and efficient.\n\n**00:46:59** - Another case is when you want to move a file. The first step is to list the directories where the file can be moved. These directories must ensure that they are not subdirectories of the file itself. This can be done by removing all directories whose path contains the ID of the file to be moved. For example, if you want to move file F11 from folder 2 to folder 1 with ID f123, you need to remove all directories whose path contains the character f111.\n\n**00:47:44** - After moving the file, you just need to update its path from the old path to the new path, and all its subdirectories will also be updated in a single query. As I’ve explained from the beginning, all queries in this system are of complexity O(1) or O(2), helping the system run very quickly and avoiding the need for transactions, which could affect the speed of other queries.\n\n**00:48:34** - The next part is about permissions and file sharing. This part has three main features: setting permissions for members within the system, sharing public files with users outside the system, and setting passwords for files. Let me move to the next section.\n\n**00:49:17** - Here is a basic diagram showing the process when a user accesses a file and how the system checks the user’s permissions. First, the system will check direct permissions and project permissions. Direct access refers to permissions directly assigned to the user’s email, such as edit rights if the file’s owner has granted that permission to the user. If neither of these permissions is satisfied, the system will check public access.\n\n**00:50:03** - Checking public access here means the access rights of users like guests, i.e., users outside the system or not part of the workspace. If these users log into the system, they will have the corresponding public access rights. However, if the file is public but the user has not logged in, they will only have read-only access, without the ability to edit.\n\n**00:50:46** - Regarding the data model, the system will have two main tables as I introduced earlier: the `member_permission` table, which represents the general access rights of a file, and the `sub_permission` table, which represents the specific access rights of a user with a specific email. The `member_permission` table has a 1-to-1 relationship with the `asset` table, meaning that a file only has one main permission set. It includes fields like `inherit` to indicate whether the access rights are inherited from the parent directory, `asset_id` to link with the asset table, `public_role` to specify public access rights, and `has_password` to determine whether the file requires a password.\n\n**00:52:16** - When creating a file, the system will generate an access set with the `inherit` attribute set to `true`, meaning this file will inherit all access rights from its parent directory. If there is any change in access rights, the system will remove the `inherit` attribute and create a new record in the `sub_permission` table.\n\n**00:54:10** - Essentially, the system operates similarly to other cloud storage services like Google Drive or Notion. However, the difference here is how the system handles multi-level permissions efficiently, avoiding unnecessary repeated checks.\n\n**00:56:41** - If there are 10 directories, and the 10th directory is a subdirectory of the first directory, and the first directory has a password, how would you check the password for the 10th directory? First, the system will check the access rights of the 10th directory. If these rights are inherited from the parent directory, the system will continue checking the nearest parent directory that does not inherit rights from further up. If the 8th directory does not inherit, the rights of the 10th directory will depend on the 8th directory. If only the first directory does not inherit rights, the system will check directly on the first directory.\n\n**00:57:20** - For example, if the 8th directory does not have the `inherit` attribute, then the rights of the 10th directory will depend on the 8th directory. But if, in your case, only the first directory does not have `inherit`, then we’ll check directly from the first directory. OK, not sure if anyone has anything else to discuss about this issue? Let me check again to see if anything needs to be added. Yes, to perform this, the system will have to query backward, from the subdirectories to the parent directories.\n\n**00:58:18** - Anh Hiếu, you probably haven’t looked at this section carefully because you need to understand it well to handle it correctly. Do you have any other questions? Actually, the sharing feature that Đạt just shared is quite similar to Notion or Google Drive, right? Yes, exactly, VOT also developed a similar feature before, but it had to handle two or three layers of permissions, right? Yes, correct, very complex.\n\n**00:59:34** - OK, we have a few minutes left to schedule a quick demo with Tom for the workflow on the other side. Over the past two months, the team has built a simple server to test workflows. The goal is to visualize how processes can be optimized from the customer’s side, not just from our side; our team also has some needs to use AI but isn’t sure how to optimize it for speed and efficiency. We could use solutions like Flowwise or Airflow, but they’re a bit complex. That’s why I chose LLM (Large Language Model) for simplicity; I’ll build an agent or a tool to handle it.\n\n**01:00:17** - If we succeed in this, when building other applications for customers or our app, implementation will be easier. Now I’ll introduce you to the Memo chatbot that Memo is using. Honestly, Memo also has a chatbot connected to Diffy; since I’m lazy to code, I connected it to handle things more quickly. Let’s see, the network has been lagging recently.\n\n**01:00:59** - OK, try the command “get me the latest notes on Go.” This chatbot will follow a workflow similar to what Eming built for Tôn. It will use an AI model to create SQL query commands, then execute the queries on the database. I have a pre-setup file to call the query from there and then output the results in markdown format. The model isn’t too complex, but I have to use some techniques like prompt engineering, which is the technique of providing enough context and information to the AI so that it responds exactly as I intend. \n\n**01:01:49** - When designing a workflow like this, the goal is to make it run smoothly. There are two ways: either you code the actions behind the functions, or you do prompt engineering to guide the AI in creating the correct SQL queries. This trick is often used when prototyping or quickly developing for customers. I set up the server for the AI model to infer how to query SQL, then return the results to the chatbot.\n\n**01:03:20** - The real “magic” of it lies in the description of the function calls, which contain information about the tables in Memo. Without this, when I run the command, the AI wouldn’t know which table to query, leading to errors. That’s why prompt engineering is so important in ensuring that the AI gets the correct information and produces the right results.\n\n**01:04:47** - If I try to rerun the Memo chatbot without the correct description, it will create an error because it doesn’t know which table to query. In this case, the trick I often use for prototyping or working quickly with customers becomes very useful. What you can do with AI is almost limitless as long as you understand how to do prompt engineering.\n\n**01:05:31** - For example, you can change the description so that the AI doesn’t query a specific database but another table or source. This is really advantageous when you need to integrate multiple systems or handle different types of data. Anh Hơn mentioned that we have many neat tricks, but in reality, these are just helper tools to support building AI applications. On a local server, I can run some tools to translate text or create SQL queries.\n\n**01:07:18** - For example, if I need a chatbot to respond to SQL queries, as long as I have a database and a clear schema, I can have the AI query the latest notes in Memo. Some complex queries can be very difficult to do manually, but with AI, I can input enough context and let the AI handle the rest.\n\n**01:09:55** - What we do with Dify is mainly to organize assistants or code simple functions like agent workflows. This mainly involves calling functions, but when doing more complex work, the AI model can still handle it well. For instance, I’ve built a simple reporting model before, and Dify is just a platform for me to code these functions.\n\n**01:11:27** - If you have an LLM server or an API server compatible with OpenAI, you can integrate it into your system. Then, you can add modules or new features to this platform. This allows you to create complex AI applications without having to build everything from scratch.\n\n**01:12:16** - Dify can be compared to an AI coding tool, but I don’t use direct code; instead, I mainly use the functions provided by the platform to create chatbots or agents. You can configure system prompts and create agents to handle specific tasks. Dify helps you organize this work without having to leave the platform or use external tools like OpenAI or Anthropic.\n\n**01:13:13** - It also allows you to add documents like PDFs or text to provide knowledge to the AI. For example, if you have internal knowledge within the company, you can upload and index it so that the AI can understand and respond more accurately. Some functions like Google Search or Doo are available, which you can use to search the internet and interact with the AI.\n\n**01:14:49** - Another example is using the Tally tool to search for information about the Paris Olympics; it will search the internet and return results via API. The workflows are also built like a diagram, allowing you to visualize how the entire system operates.\n\n**01:15:45** - I know this introduction might sound a bit complex, but the main idea is that Dify allows you to organize and use AI tools effectively. Some tools are pre-coded in Dify and can’t be customized much, but you can create custom tools according to your needs.\n\n**01:16:28** - I’ve created a few custom tools, and there are also tools available on the platform; all are workflows converted into API requests. You can create such requests to interact with the Dify platform, like generating a logo or making URL requests.\n\n**01:17:26** - You can place your API key in these requests and use them to perform tasks like searching, creating new tasks, or interacting with external APIs. This helps you create custom applications without having to write too much code.\n\n**01:18:09** - For example, Anh Quang has implemented automatic pull request (PR) creation for Playground based on the agents we’ve set up. We can interact with the agent via API to perform more complex tasks, and this can help optimize the workflow.\n\n**01:19:07** - Does anyone have any questions? If not, I’ll stop here. I think today’s session is enough, and we’ll save the rest for the next sessions.\n","title":"OGIF Office Hours #19 - Golang weekly, Designing for forgiveness, File sharing system design, Dify AI demo","short_title":"#19 Go weekly, UI design, File sharing, Dify AI","description":"OGIF 19 dives into essential topics including Go 1.23 updates, effective UI error handling, and a detailed Dify AI demo. We explore common Go pitfalls, best practices for database design, and strategies for optimizing queries. The session also features a practical demonstration of integrating AI into development workflows with Dify AI.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Thu Aug 22 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/19-20240821.md","slugArray":["updates","ogif","19-20240821"]},{"content":"\n79 minutes\nRecorded Apr 12, 2024\n\n## Summary\n\n1. **Technical Deep Dives**: **hnh** delved into the technical aspects of using **devbox as a Docker replacement** and why **NixOS** was a great choice. This discussion covered the benefits and potential applications of these technologies.\n\n2. **Community and Learning**: **Thanh** shared his journey of developing our **security standard**, providing insights into the learning process and the importance of security within our community.\n\n3. **Interactive Discussion**: We had an interactive discussion about **money/liquidity** and the **current state of the company**. This provided an opportunity for everyone to engage in real-time and understand the dynamics of our community and projects.\n\n4. **Future Plans and Strategies**: We aimed to make this a regular event where members could share their learnings within a 10-minute timeframe. This strategy was aimed at fostering knowledge sharing and strengthening our community.\n\n\n## Recordings\n\n**Security standards by @thanh**\n![](assets/2-ogif-office-hours-0412_0412-1_compressed.mp4)\n\n**Intro to Devcontainers by @hnh**:\n![](assets/2-ogif-office-hours-0412_0412-2_compressed.mp4)\n\n**Investment talk by @huytq**:\n![](assets/2-ogif-office-hours-0412_0412-3_compressed.mp4)\n\n**Liquidity talk by @han**:\n![](assets/2-ogif-office-hours-0412_0412-4_compressed.mp4)\n","title":"OGIF Office Hours #2: Devbox as the new Docker, Security Standards, and Understanding Liquidity","short_title":"#2 Devbox as the new Docker, Security Standards, and Understanding Liquidity","description":"Our second Office Hours. Join the community to exchange knowledge and insights on diverse topics, including Docker alternatives with Nix, security practices and origin stories of our standards, financial discussions on liquidity, company updates, and icy draws.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["monotykamary"],"date":"Fri Apr 26 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/2-20240412.md","slugArray":["updates","ogif","2-20240412"]},{"content":"\n97 minutes\n\n### Topics & Highlights\n\n**00:00 - Introduction and Setup**\n\nKickoff of the session with attendance check and agenda setup.\n\n**00:10:57 - Golang Commentary**\n\nDiscussion on Go 1.23, including Go Notebook, a Jupyter-like environment for Go, and performance optimization techniques.\n\n**00:17:54 - Modeling Dynamic Object Properties**\n\nAnalysis of structuring dynamic properties inspired by Notion, focusing on separating model and field data into distinct database tables.\n\n**00:40:11 - LLM Tracing**\n\nExploration of tracing and evaluating large language models (LLMs) with tools like phonic, ensuring outputs meet user expectations with metrics like latency and relevance.\n\n**01:18:34 - Tooling: Cursor AI Editor**\n\nIntroduction to Cursor AI, an AI-powered code editor offering advanced features for code generation and project context management.\n\n**01:36:07 - Summary and Concluding Thoughts**\n\nWrap-up of the session with key takeaways and final thoughts.\n\n---\n\n### Vietnamse Transcript \n\n**00:00** - Ok, chắc đủ rồi, bắt đầu nhé. Anh em khác chắc sẽ vào dần. Phát ơi, bắt đầu phần Go của em đi. Ok, mọi người nghe rõ chưa? Nghe rồi đúng không? Ok, vậy thì em sẽ bắt đầu như thế này. Đầu tiên là tuần này em có thấy một vài cái tool khá hay. Về tin tức thì cũng không có gì mới, chỉ có việc Go 1.23 đã release thôi. Đầu tiên là có cái Go Notebook, nó giống như thằng Jupyter mà mọi người biết, Jupyter là một công cụ đã ra mắt từ lâu bên Python, thường dùng cho mấy anh em hay làm machine learning hoặc data analysis. Bây giờ, Go cũng có một phiên bản tương tự, cho phép mình sử dụng Go ngay trong môi trường notebook như vậy. Mọi người có thể chạy nó local, thậm chí có thể build Docker container và chạy nó trong đó.\n\n**10:57** - Go Notebook cũng có một số tính năng như vẽ biểu đồ (widget plot), khá giống với Jupyter, thậm chí còn nhanh hơn khi build và chạy Go local. Em đã test thử và thấy khá nhanh, thậm chí nhanh hơn Jupyter luôn. Hồi trước em có thử Jupyter thì thấy nó khá chậm. Tool thứ hai là \"kuam\", một công cụ hỗ trợ cho anh em dùng bên Nexttop. Kuam có chức năng stream những file cấu hình (config) không cần thiết trong project. Bình thường, nếu không có kuam, khi list ra các config mà không được sử dụng hoặc không kết nối được, mình phải tự xóa bằng tay trong file. Còn với kuam, nó sẽ tự động loại bỏ những cấu hình không cần thiết đó cho mình, và cũng có tùy chọn để quyết định có lưu vào file config hay không.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/S_y5IrBhfNQ?si=ys80zw6NTvFBIotT&amp;start=620\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**11:44** - Tuần trước thì em có xem qua một số video từ bên UK, khá hay. Tình hình chung bên châu Âu, cộng đồng Go vẫn đang tập trung vào các vấn đề như testing performance, họ không chỉ đơn giản là đo đạc hiệu năng mà còn kiểm tra cách hệ thống hoạt động ra sao, có cả những đoạn liên quan đến CPU và GPU performance. Bên cạnh đó, có một bài về Software Design Complexity, bài này nói về việc thiết kế hệ thống sao cho đơn giản mà vẫn hiệu quả. Đối với những hệ thống lớn, cần nhiều component khác nhau, họ phải cân nhắc giữa độ phức tạp và hiệu quả của nó. Ý cuối cùng trong các bài này là về AI, nói chung, mấy bác Goer vẫn đang dùng AI ở mức cơ bản. Có một bài của một bác bên Microsoft cũng ok, nói về việc sử dụng AI để hỗ trợ code, nhưng cũng chỉ dừng lại ở mức cơ bản.\n\n**14:56** - Ok, anh em có câu hỏi gì cho phần review của Phát không? Có ai muốn hỏi gì không?\n\n**15:44** - À, về cái Oscar thì sao nhỉ? Tuần trước hay hai tuần trước mình có nói về nó rồi mà, còn nhớ không? Con Oscar và con Gasp, Oscar là một dự án lớn nha. Bài tuần trước có liên kết đến kiến trúc (architecture) của nó. Nó là một cái agent, giống như mấy cái của anh Tom làm, nhưng chủ yếu là bên Dr. By chỉ mới show cái architecture thôi, chưa chi tiết lắm. Để em kiếm lại rồi gửi link post lên sau. Còn code thì có, nhưng code của con Gasp thì không có public, nó nằm trong repo internal của Google, em sẽ gửi link sau nếu cần.\n\n**16:53** - Việc bên đó rồi, chắc sẽ viết xong sớm thôi. Em đang chuẩn bị viết một cái module hoặc một cái OS theo cách hướng dẫn đó, giống như cái anh đã nói, có lẽ sẽ hoàn thành vào tuần sau đúng không? Có gì cần thì anh em cứ sẵn sàng thôi. Em nghe nói Phát đang phải code vô kích đấy, hơi bất ngờ nhưng mà kiểu như mấy cái start thì cũng tạm ổn thôi. Ok, cảm ơn Phát nhé. Rồi, tiếp theo chúng ta sẽ đến với một chủ đề liên quan đến việc lập hồ sơ. Cái này em đã share với anh em trong team một lần rồi thì phải. Đây là liên quan đến việc tạo ra dynamic object trong project.\n\n**17:54** - Giống như bên Notion. Dạ, đúng rồi. Ok, đợi chút nhé. Cái này chắc bên đó làm được, để xem nào. Sẵn sàng chưa? Chắc là bên đó có thể lên production được rồi đúng không? Lên rồi, kiểu như mình đang dùng bản product thôi mà. Ok, vậy chắc để em chia sẻ màn hình cho mọi người xem. Mọi người thấy màn hình em chưa? Thấy rồi đúng không? Ok, chủ đề này là về việc mô hình hóa (modeling) các object động (dynamic objects). Về cơ bản, mục tiêu là chúng ta muốn tạo ra một object có khả năng mở rộng (extendable) như trong Notion, tức là có các field mà chúng ta có thể mở rộng hoặc thay đổi.\n\n**18:54** - Vậy làm sao để chúng ta có thể mô hình hóa (model) được điều này? Bên đây, em đã có một cái database setup sẵn. Khi bắt đầu, chúng em đã đưa ra hai quyết định quan trọng trong việc mô hình hóa (modeling) hệ thống này. Thứ nhất, bản thân model chính và các field của nó phải được tách ra thành hai bảng (table) riêng biệt. Điều này là cần thiết vì nếu chúng ta muốn mở rộng danh sách các thuộc tính (property), chúng ta cần lưu các field này trong một bảng riêng.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/S_y5IrBhfNQ?si=R079FoyaHgmzrKsO&amp;start=1118\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**19:44** - Ví dụ, giả sử chúng ta có một task, task này sẽ không chứa bất kỳ field nào trực tiếp. Thay vào đó, chúng ta sẽ có một bảng field riêng biệt. Trong bảng field này, sẽ có các thông tin như field type (kiểu dữ liệu của field), ví dụ như text, checkbox, hay select (multi-select). Tên (name) của field và các tùy chọn (option) của nó sẽ được lưu trữ trong một bảng riêng khác. Điều này cho phép chúng ta linh hoạt hơn trong việc thêm các option cho field một cách động (dynamic).\n\n**20:23** - Nếu mọi người nhìn vào thì sẽ thấy hiện tại task và field này không có mối quan hệ trực tiếp nào với nhau. Thay vì tạo ra một quan hệ (relationship) trực tiếp giữa task và field, chúng em đã chọn cách sử dụng một bảng trung gian là bảng value. Bảng value này đóng vai trò là cầu nối giữa task và danh sách các field. Điều đó có nghĩa là khi thêm một field vào task, chúng ta không thực sự thêm field đó trực tiếp vào task, mà là thêm một record (bản ghi) vào bảng value. Record này sẽ liên kết task với field tương ứng.\n\n**21:00** - Ở trong bảng value này, chúng em cũng đã mô hình hóa (model) theo kiểu linh hoạt bởi vì field type có rất nhiều dạng khác nhau như em đã nói: text, boolean, select, hay user. Mỗi loại value sẽ có một cột riêng biệt trong bảng value, ví dụ như cột dành cho text, cột dành cho boolean, cột dành cho select hay cột dành cho user. Điều này cho phép chúng ta linh hoạt hơn trong việc xử lý các loại dữ liệu khác nhau trong hệ thống của mình.\n\n**21:33** - Đối với mỗi loại giá trị (value) khác nhau như text, boolean, và các loại khác, tụi em đều tạo một cột (column) riêng biệt trong bảng value. Ví dụ, cột cho text, cột cho boolean, cột cho select, hay cột cho user. Điều này có nghĩa là mình cũng hoàn toàn có thể kết nối các giá trị này với các bảng khác trong database của mình. Đây là quyết định đầu tiên mà tụi em đưa ra khi thiết kế hệ thống này.\n\nTại sao tụi em lại không tạo mối quan hệ trực tiếp (direct relationship) giữa task và field? Lý do là vì tụi em muốn các field này hoạt động như một cấu hình toàn cầu (global configuration). Khi một field mới được tạo ra, tất cả các task có thể sử dụng lại field này mà không cần phải tạo ra một mối quan hệ chặt chẽ. Mối quan hệ giữa task và field sẽ rất lỏng lẻo và tất cả các thao tác đều được xử lý thông qua bảng value. Khi xóa một giá trị trong bảng value, field trong task tương ứng cũng sẽ biến mất, nhưng field đó vẫn tồn tại cho các task khác.\n\n**22:46** - Em nghĩ là vậy thôi. Ví dụ, nếu em tạo một task mới và muốn thêm một field select, khi em gõ chữ 'tag', hệ thống sẽ hiện lên các field đã tồn tại, và em có thể thêm field 'tag' đã tồn tại này vào task mới, đồng thời kế thừa luôn các option mà field này đã có. Nhìn chung thì hệ thống này cũng hoạt động khá nhanh.\n\n**23:32** - Còn về các thao tác khác thì sao? Ví dụ như trong Notion, nó sẽ có các thao tác như sorting (sắp xếp), filtering (lọc) các field. Do các field này được lưu trữ trong một bảng riêng (table riêng), nếu muốn sắp xếp (sort) thì chỉ cần thêm một cột sort order vào bảng field. Khi điều chỉnh sort order này, nó sẽ tự động cập nhật cho toàn bộ workspace. Thực tế, hiện tại hệ thống của em chưa có task cụ thể để thử nghiệm, nhưng em nghĩ rằng nó sẽ hoạt động cho toàn bộ workspace.\n\n**24:20** - Hiện tại, tụi em chưa nghĩ đến việc lưu sort order riêng cho từng task, vì điều này sẽ rất phức tạp. Sort order này hiện tại là toàn cục (global). Có một số thách thức khi sử dụng mô hình này, đó là lúc query, tụi em phải join rất nhiều bảng (tables) khác nhau và cần phải xử lý việc lọc (filter) và phân trang (pagination) các dữ liệu này. Với hạ tầng hiện tại của tụi em, sử dụng Prisma không thể xử lý được, nên tụi em phải viết raw SQL để thực hiện các truy vấn phức tạp này. Đây là một khó khăn lớn.\n\n**24:59** - Một vấn đề khác là khi làm việc cross-organization hoặc cross-workspace, như khi mời guest từ tổ chức khác vào, việc quản lý các field này, đặc biệt là liên quan đến quyền truy cập (permission), rất phức tạp. Các field này chỉ thuộc về một tổ chức cụ thể, nên khi mời guest vào, vấn đề quản lý quyền truy cập trở nên rất rối rắm. Khi tụi em thiết kế hệ thống này, chưa tính đến việc cross-space, nên hiện tại đang phải tìm cách giải quyết tạm thời để nó hoạt động. Tuy nhiên, đây vẫn là một vấn đề tồn tại trong hạ tầng hiện tại của dự án.\n\n**25:33** - Một vấn đề khác là giống như trong Notion, khi mình muốn di chuyển hoặc copy một trang từ bảng này sang bảng khác, bảng mới sẽ có một set property khác so với bảng gốc. Hiện tại, các field được lưu trữ ở cấp độ workspace hoặc organization, không phải ở cấp độ bảng (table). Điều này có nghĩa là các field này được dùng chung cho toàn bộ workspace.\n\n**26:08** - Một cách để giải quyết vấn đề này là chuyển đổi giữa các workspace trong cùng một organization, như trong Notion. Khi guest vào, họ vẫn có thể thấy các task trong workspace của họ và các task từ các workspace khác nếu chúng được chia sẻ chung. Tuy nhiên, vấn đề xuất hiện khi hệ thống chia sẻ cùng một set field cho nhiều workspace khác nhau trong cùng một organization, gây ra sự xung đột về quyền truy cập và quản lý.\n\n**26:51** - Các field này hiện đang được kết nối trực tiếp với tổ chức (organization) thay vì với workspace, cho nên các field này được sử dụng chung cho toàn bộ workspace. Có thể có cách giải quyết vấn đề này là cho phép người dùng chuyển đổi trực tiếp giữa các workspace, giống như trong Notion. Điều này có nghĩa là khi người dùng truy cập vào, về bản chất thì toàn bộ organization vẫn thuộc quyền quản lý của mình. Nhưng hiện tại, hệ thống đang cho phép guest truy cập vào và thấy tất cả các task trong tổ chức của họ, cũng như các task từ các tổ chức khác mà họ được mời tham gia. Điều này dẫn đến việc các dữ liệu bị chia sẻ chung giữa các tổ chức, gây ra sự xung đột.\n\n**27:31** - Nếu mình sử dụng cách tiếp cận riêng biệt thì sẽ không gặp vấn đề này. Nhưng thực chất, điều này bắt nguồn từ việc các task chỉ là một thực thể của hệ thống lịch (calendar entity), đúng không?\n\n**28:26** - So với các block trong Notion, thì các block của Notion được xây dựng dựa trên kiến trúc từ block lên (bottom-up architecture). Còn hệ thống này thì chỉ là một mô phỏng đơn giản (mockup) chứ không thực sự có liên quan nhiều đến block. Đây chỉ là một mô phỏng để hệ thống có thể hoạt động theo cách riêng của nó.\n\n**29:54** - Để hệ thống hoạt động một cách hợp lý, chúng ta cần đảm bảo rằng mối quan hệ giữa các field và các giá trị (value) là rõ ràng và không bị nhầm lẫn. Điều này bao gồm việc tránh các vòng lặp (loops) trong thiết kế dữ liệu. Một vòng lặp trong thiết kế chỉ nên tồn tại khi nó thực sự cần thiết để tối ưu hóa truy vấn (query) hoặc các tác vụ khác. Tuy nhiên, phải nhận thức được rằng vòng lặp này có thể dẫn đến nhiều khó khăn trong việc bảo trì và phát triển hệ thống. Khi người khác nhìn vào thiết kế này, họ cần phải hiểu được mục đích của vòng lặp là gì và nó không nên bị nhầm lẫn với các mục đích khác.\n\n**35:03** - Nếu mình muốn loại bỏ vòng lặp này, mình cần phải tái cấu trúc lại hệ thống để đảm bảo rằng các quan hệ trong hệ thống là minh bạch và dễ hiểu. Thực tế, đã có nhiều bài viết và thảo luận về chủ đề này, và mình sẽ cần phải nghiên cứu thêm để đưa ra quyết định cuối cùng.\n\n**35:51** - Một phần mình còn đang băn khoăn là nếu giữ vòng lặp như hiện tại, khi người dùng xóa một option của một field, thì tất cả các task đang sử dụng option này sẽ tự động được cập nhật và loại bỏ option đó khỏi database. Điều này có nghĩa là mình không cần phải thực hiện lại việc kiểm tra tính hợp lệ (revalidation) cho các task đó. Nếu giữ vòng lặp này, việc quản lý sẽ trở nên đơn giản hơn, nhưng nó có thể dẫn đến các vấn đề khác về lâu dài.\n\n**37:07** - Cần cân nhắc kỹ lưỡng xem liệu có nên giữ vòng lặp này hay không, hoặc nên tái cấu trúc lại để tránh các vấn đề phức tạp trong tương lai. Việc quyết định giữ vòng lặp hay loại bỏ nó có thể phụ thuộc vào cách mà hệ thống được sử dụng và quản lý. Nếu quyết định giữ vòng lặp, chúng ta cần đảm bảo rằng nó được thiết kế một cách rõ ràng và có thể dễ dàng quản lý và bảo trì.\n\n**39:03** - Một phần khác của buổi thảo luận hôm nay sẽ tập trung vào việc giới thiệu một số công cụ mới để theo dõi và kiểm tra hệ thống (tracing tools). Điều này rất cần thiết trong quá trình phát triển và bảo trì các phần mềm lớn, đặc biệt là khi chúng ta cần theo dõi từng bước hoạt động của hệ thống để đảm bảo mọi thứ diễn ra suôn sẻ.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/S_y5IrBhfNQ?si=z8OG5iFWwefkGDBj&amp;start=2388\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**40:11** - Khi phát triển một hệ thống sử dụng machine learning (ML), quá trình thường sẽ bao gồm các bước như lên ý tưởng, lựa chọn mô hình, tùy chỉnh (customization), sau đó là triển khai (deploy). Bước cuối cùng, giống như với phần mềm truyền thống, là giám sát (monitoring) và thu thập phản hồi (feedback) để cải tiến hệ thống. Đối với phần mềm truyền thống, sự khác biệt nằm ở chỗ chúng ta đã biết trước đầu ra (output) sẽ như thế nào và có thể xác định được nó dựa trên đầu vào (input). Tuy nhiên, đối với phần mềm tích hợp machine learning, kết quả đầu ra thường mang tính xác suất. Điều này có nghĩa là khi người dùng nhập liệu (input), kết quả trả về (output) có thể thay đổi tùy thuộc vào mô hình hoặc cấu hình mô hình mà chúng ta sử dụng. Vì vậy, việc theo dõi (tracing) trở nên cực kỳ quan trọng sau khi triển khai, để đảm bảo rằng các kết quả đầu ra của phần mềm đáp ứng được kỳ vọng của người dùng.\n\n**40:50** - Một điểm đặc trưng của hệ thống tích hợp ML là sự không chắc chắn trong kết quả đầu ra. Ví dụ, khi người dùng nhập liệu vào hệ thống, kết quả trả về có thể khác nhau tùy thuộc vào cách mô hình được tùy chỉnh (customized) hoặc cấu hình (tuned). Do đó, hệ thống theo dõi (tracing) cần phải giúp chúng ta hiểu rõ hơn về quá trình xử lý và xác định xem liệu các kết quả có đáp ứng kỳ vọng không, có vi phạm các quy tắc không, và liệu kết quả đó có liên quan (relevant) đến câu hỏi hay yêu cầu của người dùng hay không.\n\n**41:31** - Hệ thống theo dõi này có thể mở rộng hơn nữa bằng cách thêm vào các bước đánh giá (evaluating). Ví dụ, trong một kiến trúc hệ thống đã phát triển, quá trình xử lý dữ liệu sẽ đi qua nhiều bước, từ khi người dùng gửi yêu cầu, hệ thống tiếp nhận, xử lý qua các mô hình ML, rồi trả về kết quả. Trong quá trình này, mỗi bước có thể mang một tỷ lệ sai số nhất định. Vì vậy, chúng ta cần theo dõi từng bước để xác định được phần nào trong quá trình xử lý có vấn đề, chẳng hạn như kết quả trả về chậm hoặc không chính xác.\n\n**43:03** - Để thực hiện việc theo dõi này, hệ thống cần các chỉ số (metrics) cơ bản như độ trễ (latency), tỷ lệ lỗi (error rate), và thời gian phản hồi (execution time). Đối với các phần mềm truyền thống, các chỉ số này đã đủ để đánh giá hiệu suất hệ thống. Tuy nhiên, khi thêm vào yếu tố đánh giá (evaluating), chúng ta cần các chỉ số phức tạp hơn như độ chính xác (accuracy), độ liên quan (relevance), thiên vị (bias), hoặc mức độ rủi ro (risk). Những chỉ số này thường được đánh giá thông qua một mô hình khác, ví dụ như chúng ta có thể sử dụng một mô hình khác để đánh giá kết quả của GPT-4, xác định xem kết quả đó có liên quan hay chính xác không.\n\n**45:40** - Để minh họa, em đang sử dụng công cụ phonic để thực hiện việc theo dõi (tracing) cho hệ thống. Công cụ này có giao diện người dùng thân thiện và cho phép tích hợp dễ dàng với các mô hình ML như GPT-4. Em đã tạo một bộ chỉ mục (index) cho một file chứa các thông tin liên quan đến dự án và stakeholders. Sau đó, hệ thống sẽ sử dụng GPT-4 để trả lời các câu hỏi dựa trên dữ liệu này.\n\n**46:32** - Khi hệ thống đã được thiết lập và tải lên chỉ mục, em sẽ thử nghiệm với một số câu hỏi để kiểm tra phản hồi từ mô hình GPT-4. Các câu hỏi đơn giản nằm trong dữ liệu sẽ được mô hình xử lý tốt, nhưng các câu hỏi phức tạp hoặc không có trong dữ liệu sẽ không được mô hình trả lời đúng. Kết quả trả về sẽ được tổng hợp và đánh giá.\n\n**47:50** - Hệ thống sẽ chỉ đánh giá dựa trên các chỉ số cơ bản như độ trễ và số token đã sử dụng. Tuy nhiên, để có đánh giá chính xác hơn, em sẽ cấu hình thêm phần đánh giá (evaluating) bằng cách sử dụng một mô hình khác như GPT-4 hoặc Cloud 3.5. Khi mô hình khác này đánh giá, nó sẽ cung cấp cho mình các thông số chi tiết hơn như độ chính xác hay độ liên quan của các câu trả lời.\n\n**48:42** - Sau khi chạy thử, hệ thống sẽ cho phép chúng ta chọn những chỉ số nào cần theo dõi, như độ liên quan (relevance), độ chính xác (correctness), và độ độc hại (toxicity). Đa số các mô hình sẽ không trả lời các câu hỏi liên quan đến nội dung độc hại, nhưng hệ thống vẫn kiểm tra để đảm bảo an toàn.\n\n**49:28** - Kết quả đánh giá sẽ được hiển thị trên giao diện dưới dạng các ma trận (matrix). Mỗi câu trả lời sẽ được kiểm tra xem nó có chính xác không hay chỉ là dự đoán vô căn cứ từ mô hình. Những đánh giá này rất quan trọng trong việc cải thiện và tinh chỉnh các mô hình ML để đảm bảo chúng hoạt động hiệu quả và đáng tin cậy.\n\n**50:48** - Format của hệ thống sẽ hiển thị dữ liệu và yêu cầu trả về giá trị tương ứng. Sau đó, chúng ta có thể trực quan hóa (visualize) dữ liệu này. Hệ thống sẽ đánh giá xem dữ liệu trả về có liên quan (relevant) hay không. Ví dụ, có hai câu hỏi cuối trong thử nghiệm trước đó không có trong tài liệu. Do đó, hệ thống đánh giá rằng các câu trả lời này không liên quan. Cụ thể, câu hỏi về chiến lược giao dịch của trader không có trong tài liệu, vì vậy mô hình đánh giá xác định rằng câu trả lời của hệ thống là không liên quan.\n\n**51:34** - Khi hệ thống đánh giá các câu trả lời, nó sẽ xác định rằng các câu trả lời có liên quan đến tài liệu hay không. Ví dụ, mô hình đánh giá có thể xác định rằng câu trả lời của hệ thống là chính xác về mặt cú pháp, nhưng nếu nó không nằm trong tài liệu tham khảo, thì độ liên quan sẽ được đánh giá là không có. Điều này rất quan trọng để đảm bảo rằng hệ thống không chỉ cung cấp câu trả lời chính xác về mặt hình thức mà còn phải phù hợp với ngữ cảnh và tài liệu hiện có.\n\n**52:15** - Đánh giá liên quan đến việc xác định xem các thông tin trong tài liệu tham khảo có khớp với câu trả lời mà mô hình cung cấp hay không. Nếu thông tin không được tìm thấy trong tài liệu tham khảo, hệ thống sẽ đánh giá rằng câu trả lời không có độ liên quan (unrelated). Đây là một công cụ quan trọng để theo dõi (tracing) và đánh giá hệ thống sau khi triển khai.\n\n**53:14** - Sau khi triển khai, một trong những vấn đề quan trọng là đánh giá chất lượng của mô hình. Chúng ta có thể sử dụng một mô hình cao cấp hơn để đánh giá mô hình hiện tại hoặc sử dụng mô hình miễn phí hoặc tự huấn luyện. Đánh giá này có thể áp dụng cho cả các mô hình có sẵn (pre-trained models) hoặc các mô hình tự tùy chỉnh (custom models). Ví dụ, nếu mô hình chính của chúng ta không phải là GPT-4, chúng ta có thể sử dụng một mô hình khác để đánh giá chất lượng.\n\n**54:09** - Hệ thống đánh giá có thể được sử dụng để kiểm tra chất lượng của các mô hình ML hoặc cách chúng ta kết hợp (combine) các thành phần trong hệ thống. Điều này đảm bảo rằng đầu ra của hệ thống phù hợp và đáp ứng được yêu cầu của người dùng. Đánh giá này là một phần bổ sung (extra) nhưng rất quan trọng trong việc theo dõi và cải thiện hệ thống.\n\n**55:31** - Bản chất của hệ thống này vẫn là theo dõi (tracing) từng bước và debug khi cần thiết. Đối với các chỉ số cơ bản như độ trễ (latency), hệ thống sẽ theo dõi các thông số như thời gian thực hiện, lỗi, và kiểm tra từng bước để đảm bảo rằng hệ thống hoạt động đúng.\n\n**56:12** - Hệ thống này có thể rất hữu ích trong việc quản lý các truy vấn lớn, đặc biệt là khi cần đánh giá đầu ra của hàng loạt người dùng. Sau khi chạy các truy vấn, chúng ta có thể lọc các câu trả lời được đánh giá là có điểm số thấp và xử lý chúng để cải thiện hệ thống.\n\n**57:12** - Việc sử dụng các công cụ như tracing có thể tiêu tốn chi phí, đặc biệt là khi đánh giá nhiều truy vấn phức tạp. Các công cụ đánh giá này có thể sử dụng các mô hình phức tạp, dẫn đến chi phí cao. Tuy nhiên, việc theo dõi và đánh giá sau khi triển khai vẫn là cần thiết để đảm bảo hệ thống hoạt động hiệu quả.\n\n**58:51** - Các công cụ như vậy cho phép theo dõi và đánh giá toàn bộ quy trình xử lý của hệ thống. Chúng có thể giúp tính toán chi phí và xác định các bước nào trong quy trình xử lý cần cải thiện. Việc tích hợp các công cụ này có thể giúp theo dõi từng bước và đảm bảo rằng hệ thống hoạt động theo đúng cách mà chúng ta mong muốn.\n\n**01:03:21** - Việc triển khai hệ thống mới với các công cụ như debox có thể giúp quản lý các dịch vụ một cách dễ dàng mà không cần đến container hoặc Docker. Điều này có thể hữu ích trong việc tối ưu hóa hiệu suất và giảm tải hệ thống. Tuy nhiên, việc thiết lập và cấu hình ban đầu có thể gặp một số khó khăn, đặc biệt là khi cần tương thích với nhiều môi trường khác nhau.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/S_y5IrBhfNQ?si=sCTdtk_6L69pWZiK&amp;start=3736\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**01:05:58** - Việc quản lý hệ thống thông qua debox giúp đơn giản hóa quy trình, nhưng cũng có những thách thức nhất định như cần phải tùy chỉnh các gói cài đặt. Điều này đòi hỏi người dùng phải có kiến thức sâu về hệ thống và các gói phần mềm được sử dụng. Tuy nhiên, lợi ích của việc này là giảm bớt sự phụ thuộc vào Docker và cải thiện hiệu suất hệ thống.\n\n**01:08:07** - Cộng đồng sử dụng debox còn khá nhỏ, vì vậy việc tìm kiếm hỗ trợ có thể hơi khó khăn. Tuy nhiên, đối với các dự án nhỏ hoặc khi cần tối ưu hóa tài nguyên hệ thống, debox có thể là một giải pháp hữu hiệu. Chúng ta cần cân nhắc kỹ lưỡng trước khi áp dụng để đảm bảo rằng hệ thống sẽ hoạt động hiệu quả trong môi trường phát triển và triển khai.\n\n**01:17:10** - Có gì thêm không? Em clean up lại rồi, em chia lại cho mọi người. Hiện tại, em đang chạy chung tất cả các service lên cùng một lúc. Nếu muốn chạy từng cái riêng lẻ thì cũng được.\n\n**01:18:34** - Hôm nay, em sẽ demo một công cụ mới mà mọi người có thể đã nghe đến gần đây, đó là Cursor. Đây là một IDE mới nổi trong cộng đồng lập trình, và em thấy nó khá hữu ích. Cursor thực ra giống VS Code về mặt giao diện, nhưng điểm đặc biệt là nó có hai tính năng chính: một là \"comk\" - dùng để chỉnh sửa code, và hai là \"coml\" - dùng để chat và hỗ trợ phát triển trực tiếp.\n\n**01:18:34** Bây giờ em sẽ thử demo một số tính năng của nó. Ví dụ, với \"comk,\" em có thể yêu cầu Cursor tạo ra một tính năng mới. Giả sử, em muốn tạo một lệnh \"standup\" để tag tất cả mọi người trong một channel. Em sẽ yêu cầu nó tạo lệnh này với một số tùy chọn như thêm hoặc loại bỏ người mình muốn tag, hoặc chọn channel mà lệnh này sẽ được thực thi.\n\nCursor sẽ generate code dựa trên yêu cầu của mình, nhưng có một nhược điểm nhỏ là nó không tự động tạo file hay folder, mà mình phải tự tạo thủ công. Sau đó, mình mới có thể dùng code mà nó generate ra. Ở đây, nó đã generate ra một đoạn code, nhưng không theo cấu trúc project của em, vì vậy em cần phải chỉ định thêm ontext cho nó.\n\n**01:19:29** Mình có thể hỏi nó một số thứ về bối cảnh hiện tại. Ví dụ như mình đang cần tìm hiểu về một số khía cạnh của project, thì lúc chat, Cursor sẽ có hai tùy chọn: một là chat với AI trong môi trường tổng quát, hai là chat trong một context cụ thể của project. Điều này cho phép mình có được cái nhìn tổng quan về cấu trúc và cách thức hoạt động của project này.\n\nGiả sử mình muốn Cursor giúp mình triển khai một tính năng mới, ví dụ như tạo một lệnh mới trong bot Discord. Mình có thể yêu cầu nó tạo một lệnh \"standup\" để nhắc tất cả mọi người trong một kênh nhất định. Lệnh này sẽ có một số tùy chọn như cho phép thêm hoặc loại bỏ những người mà mình không muốn nhắc, hoặc chọn một kênh cụ thể để gửi thông báo.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/S_y5IrBhfNQ?si=NzvG59yE_qbbipPJ&amp;start=4731\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**01:21:01** Tuy nhiên, một nhược điểm của Cursor là nó không thể tự tạo file hay thư mục mới, mình phải tự tạo thủ công. Mặc dù vậy, Cursor  có thể generate code theo yêu cầu của mình. Nhưng đôi khi, code nó tạo ra không theo đúng cấu trúc của project mình. Nếu muốn nó bám sát hơn với context hiện tại, mình có thể import các file và thư mục liên quan vào để nó hiểu rõ hơn về cấu trúc project.\n\nCursor cũng cho phép mình import một số tài nguyên như file, thư mục, hoặc đoạn code cụ thể từ web hay các nguồn khác. Ví dụ, mình có thể yêu cầu nó sử dụng một thư mục có tên là \"commands\" và import các file liên quan vào đó. Khi đó, Cursor AI sẽ generate code và cấu trúc theo đúng format mà project mình đang sử dụng, như tạo ra các file `base`, `interface`, và `implementation` cho lệnh \"standup\" mới này.\n\n**01:23:25** Sau khi tạo xong code, nó còn chỉ mình cách cập nhật những phần khác của project như việc thêm lệnh mới vào giao diện của bot Discord. Thông thường, khi làm việc với Cursor, nó sẽ cung cấp những giải pháp cụ thể và chi tiết hơn, đặc biệt là khi mình có thể import các file mẫu có sẵn theo convention của project mình.\n\n**01:24:28** Ví dụ, mình có thể yêu cầu Cursor tạo một unit test cho một file cấu hình như `config.go`. Đây là một ví dụ đơn giản, sử dụng những unit test có sẵn của Go. Nếu mình muốn sử dụng thêm một thư viện khác hoặc thêm chi tiết vào phần test, mình có thể yêu cầu Cursor AI điều chỉnh theo ý mình.\n\nNếu project của mình đã có sẵn các file test theo một convention nhất định, mình có thể import các file đó vào để Cursor học theo, từ đó tạo ra các test cases chuẩn hơn. Điều này giúp mình tiết kiệm thời gian và đảm bảo các test cases tạo ra phù hợp với convention của team.\n\n**01:25:02** Nếu mình muốn thêm một tính năng phức tạp hơn, chẳng hạn như load dữ liệu từ một file JSON, Cursor có thể giúp mình cập nhật phần code để thực hiện điều này. Nó sẽ thêm phần code cần thiết vào trong file của mình, giúp tự động hóa các công việc lặp lại và giảm thiểu sai sót khi làm việc thủ công.\n\n**01:26:40** Mình có thể có câu hỏi rằng liệu Cursor có index toàn bộ code của mình lên server của họ hay không. Theo quảng cáo của họ, Cursor sẽ chạy hoàn toàn trên máy tính của mình, tạo ra một môi trường riêng để xử lý và index toàn bộ source code, không gửi dữ liệu lên server của họ trừ khi mình chọn sử dụng API key của họ.\n\n**01:27:56** Tuy nhiên, vẫn có một số lo ngại về việc dữ liệu có thể được gửi lên server của Cursor trong quá trình xử lý, đặc biệt khi mình sử dụng API key của họ thay vì key của chính mình. Dù vậy, nếu sử dụng key riêng, mình có thể kiểm soát dữ liệu của mình tốt hơn và biết được ai đang sử dụng nó.\n\n**01:29:03** Về giao diện, Cursor có vẻ tiện lợi hơn khi giúp mình import file và code từ nhiều nguồn khác nhau, điều này giúp cải thiện khả năng hiểu context của nó. Ví dụ, mình có thể import một project từ GitHub để Cursor AI học theo convention của project đó và generate code phù hợp hơn.\n\n**01:31:19** Em đã thử nghiệm việc import một project từ GitHub và yêu cầu Cursor AI chỉnh sửa code theo convention của project đó. Kết quả là nó hiểu và áp dụng các convention một cách khá hiệu quả, mặc dù đôi khi vẫn cần phải làm một số tinh chỉnh thủ công. Cursor AI có thể không chỉ generate code mà còn giúp quản lý và chỉnh sửa code một cách hiệu quả hơn.\n\n**01:33:16** Một điểm mạnh khác của Cursor là khả năng giúp mình import và làm việc với context nhanh chóng, đặc biệt hữu ích khi làm việc với các project lớn hoặc khi cần đảm bảo tính nhất quán trong codebase. Mặc dù vẫn có một số giới hạn, nhưng Cursor thực sự là một công cụ mạnh mẽ và đáng thử nghiệm trong quá trình phát triển phần mềm.\n\n**01:36:07** Tóm lại, Cursor không chỉ là một công cụ generate code mà còn giúp hiểu rõ và quản lý codebase lớn hiệu quả. Nó có thể thay thế hoặc bổ sung cho các công cụ khác như Codex hay GitHub Copilot trong các dự án đòi hỏi sự chính xác và khả năng hiểu sâu về context. Nếu có điều kiện, em khuyến khích mọi người nên thử nghiệm công cụ này để tận dụng tối đa các tính năng của nó.\n\n---\n\n### English Transcript\n\n**00:00** - Ok, that's probably enough, let's start. Others will join in gradually. Phat, go ahead with your Go section. Ok, can everyone hear me? You can hear me, right? Ok, so I'll start like this. First, this week I found a few interesting tools. As for news, there's nothing new, just the release of Go 1.23. First off, there's this Go Notebook, which is similar to Jupyter that you're all familiar with. Jupyter is a tool that has been around for a long time in Python, typically used for machine learning or data analysis. Now, Go also has a similar version that allows us to use Go within a notebook environment. You can run it locally or even build a Docker container and run it in there.\n\n**10:57** - Go Notebook also has some features like plotting (widget plot), quite similar to Jupyter, and it might even be faster when building and running Go locally. I’ve tested it and found it to be quite fast, even faster than Jupyter. I used to find Jupyter quite slow. The second tool is \"kuam,\" a tool that supports those using Nexttop. Kuam streams unnecessary configuration files (configs) in your project. Normally, without kuam, when listing out unused or unconnected configs, you'd have to manually delete them from the file. With kuam, it automatically removes those unnecessary configurations, and you have the option to decide whether to save this change to the config file or not.\n\n**14:56** - Ok, does anyone have any questions about Phat's review? Does anyone want to ask anything?\n\n**15:44** - Ah, about Oscar, how is that? We mentioned it last week or two weeks ago, do you remember? The Oscar and Gasp projects—Oscar is a big one. Last week's article linked to its architecture. It’s an agent, similar to what Tom has done, but mainly on Dr. By, where they only showed the architecture, not in detail. I'll find it and post the link later. There is code, but the Gasp code is not public; it's in Google's internal repo. I’ll send the link if needed.\n\n**16:53** - That work over there will probably be done soon. I'm preparing to write a module or an OS based on that guide, like you mentioned, and it should be ready by next week, right? If anything comes up, you guys should be ready. I heard Phat is coding quite a bit, which is a bit surprising, but it seems the start is quite stable. Ok, thanks, Phat. Alright, next, we'll move on to a topic related to creating dynamic objects in a project.\n\n**17:54** - Similar to Notion. Yes, that's right. Ok, wait a moment. This could probably be done over there, let's see. Are you ready? They should be able to go into production, right? They have already gone live, as we're using the product version. Ok, let me share my screen for everyone. Can you see my screen? You can, right? Ok, this topic is about modeling dynamic objects. Essentially, we want to create an object that is extendable, like in Notion, where you have fields that can be extended or modified.\n\n**18:54** - So how can we model this? Over here, I've set up a database. When we started, we made two important decisions in modeling this system. First, the main model itself and its fields need to be separated into two different tables. This is necessary because if we want to extend the list of properties, we need to store these fields in a separate table.\n\n**19:44** - For example, suppose we have a task, this task will not directly contain any fields. Instead, we will have a separate field table. In this field table, there will be information such as the field type (the data type of the field), for example, text, checkbox, or select (multi-select). The name of the field and its options will be stored in another separate table. This allows us to be more flexible in adding options to the field dynamically.\n\n**20:23** - If you look at it, you'll see that currently, the task and the field don’t have a direct relationship. Instead of creating a direct relationship between the task and the field, we chose to use an intermediate table called the value table. This value table acts as a bridge between the task and the list of fields. This means that when you add a field to a task, you’re not actually adding that field directly to the task, but rather adding a record to the value table. This record will link the task to the corresponding field.\n\n**21:00** - In this value table, we’ve also modeled it flexibly because field types can vary, as I mentioned: text, boolean, select, or user. Each value type has its own column in the value table, for example, a column for text, a column for boolean, a column for select, or a column for user. This gives us more flexibility in handling different data types in our system.\n\n**21:33** - For each different value type like text, boolean, and others, we created a separate column in the value table. For instance, a column for text, a column for boolean, a column for select, or a column for user. This means we can also connect these values to other tables in our database. This was the first decision we made when designing this system.\n\nWhy didn’t we create a direct relationship between the task and the field? The reason is that we wanted these fields to act as a global configuration. When a new field is created, all tasks can reuse this field without needing to create a tight relationship. The relationship between the task and the field will be very loose, and all operations are handled through the value table. When you delete a value in the value table, the corresponding field in the task will also disappear, but the field will still exist for other tasks.\n\n**22:46** - That’s about it. For example, if I create a new task and want to add a select field, when I type 'tag', the system will show the existing fields, and I can add this existing 'tag' field to the new task, inheriting all the options that this field already has. Overall, this system works quite quickly.\n\n**23:32** - What about other operations? For example, in Notion, you have operations like sorting and filtering fields. Since these fields are stored in a separate table, if you want to sort, you just need to add a sort order column to the field table. When you adjust this sort order, it will automatically update for the entire workspace. In practice, my system doesn't have a specific task to test this yet, but I think it will work across the entire workspace.\n\n**24:20** - Currently, we haven't considered saving a separate sort order for each task because that would be very complex. The sort order is currently global. There are some challenges when using this model, which is during queries, we have to join many different tables and deal with filtering and pagination of the data. With our current infrastructure, using Prisma cannot handle this, so we have to write raw SQL to execute these complex queries. This is a major difficulty.\n\n**24:59** - Another issue is when working cross-organization or cross-workspace, such as inviting guests from other organizations. Managing these fields, especially related to access permissions, is very complicated. These fields belong to a specific organization, so when inviting guests, managing access permissions becomes very tangled. When we designed this system, we didn’t account for cross-space, so now we're working around it to make it functional. However, this is still a problem in our current infrastructure.\n\n**25:33** - Another issue is similar to Notion, where when you want to move or copy a page from one table to another, the new table will have a different set of properties from the original table. Currently, the fields are stored at the workspace or organization level, not at the table level. This means that these fields are shared across the entire workspace.\n\n**26:08** - One way to solve this issue is by allowing users to switch directly between workspaces within the same organization, as in Notion. When a guest enters, they can still see tasks in their workspace and tasks from other workspaces if they are shared. However, the issue arises when the system shares the same set of fields for multiple workspaces within the same organization, causing conflicts in access and management.\n\n**26:51** - These fields are currently directly connected to the organization rather than the workspace, so these fields are shared across the entire workspace. There could be a solution to this by allowing users to switch directly between workspaces, like in Notion. This means that when users access it, the entire organization is still under their control. But currently, the system allows guests to enter and see all tasks within their organization and tasks from other organizations they’ve been invited to. This leads to data being shared across organizations, causing conflicts.\n\n**27:31** - If we use a separate approach, we won’t face this issue. But actually, this issue originates from the fact that tasks are just an entity of the calendar system, right?\n\n**28:26** - Compared to blocks in Notion, Notion's blocks are built on a bottom-up architecture. This system, however, is just a simple mockup and doesn’t have much relation to blocks. It's merely a mockup to make the system operate in its own way.\n\n**29:54** - To make the system operate reasonably, we need to ensure that the relationship between fields and values is clear and not confusing. This includes avoiding loops in data design. A loop in design should only exist if it is truly necessary to optimize queries or other tasks. However, we must be aware that this loop can lead to many difficulties in maintaining and developing the system. When others look at this design, they need to understand the purpose of the loop and not confuse it with other purposes.\n\n**35:51** - One part I’m still pondering is if we keep the loop as it is, when a user deletes an option of a field, all tasks using that option will automatically update and remove that option from the database. This means we won’t need to revalidate those tasks. If we keep this loop, management will become simpler, but it may lead to other issues in the long run.\n\n**37:07** - We need to carefully consider whether to keep this loop or restructure it to avoid future complexities. Deciding to keep or remove the loop may depend on how the system is used and managed. If we decide to keep the loop, we need to ensure that it’s designed clearly and can be easily managed and maintained.\n\n**39:03** - Another part of today’s discussion will focus on introducing some new tools for system tracing and monitoring. This is crucial in the development and maintenance of large software, especially when we need to monitor each step of the system's operation to ensure everything runs smoothly.\n\n**40:11** - When developing a system that uses machine learning (ML), the process usually involves steps like ideation, model selection, customization, and then deployment. The last step, like traditional software, is monitoring and gathering feedback to improve the system. For traditional software, the difference lies in that we already know what the output will be and can determine it based on the input. However, for software integrated with machine learning, the output is often probabilistic. This means that when a user inputs data, the output may vary depending on the model or model configuration we use. Therefore, tracing becomes extremely important after deployment to ensure that the software's outputs meet user expectations.\n\n**40:50** - A characteristic of ML-integrated systems is the uncertainty in the output. For example, when a user inputs data into the system, the output may vary depending on how the model is customized or tuned. Therefore, the tracing system needs to help us better understand the process and determine whether the outputs meet expectations, whether they violate any rules, and whether the outputs are relevant to the user’s questions or requests.\n\n**41:31** - This tracing system can be expanded further by adding evaluation steps. For example, in a developed system architecture, the data processing process will go through many steps, from when the user submits a request, the system receives it, processes it through ML models, and then returns the result. In this process, each step may carry a certain degree of error. Therefore, we need to trace each step to identify where in the processing chain there is an issue, such as the result being returned slowly or inaccurately.\n\n**43:03** - To perform this tracing, the system needs basic metrics like latency, error rate, and execution time. For traditional software, these metrics are sufficient to evaluate system performance. However, when adding the evaluation factor, we need more complex metrics like accuracy, relevance, bias, or risk. These metrics are often evaluated through another model. For example, we might use another model to evaluate the results of GPT-4 to determine if the results are relevant or accurate.\n\n**45:40** - To illustrate, I’m using a tool called phonic to perform tracing for the system. This tool has a user-friendly interface and allows easy integration with ML models like GPT-4. I’ve created an index for a file containing information related to the project and stakeholders. The system will then use GPT-4 to answer questions based on this data.\n\n**46:32** - Once the system is set up and the index is loaded, I will experiment with some questions to check the responses from the GPT-4 model. Simple questions within the data will be handled well by the model, but complex questions or those not found in the data will not be answered correctly. The results will be aggregated and evaluated.\n\n**47:50** - The system will only evaluate based on basic metrics like latency and the number of tokens used. However, for a more accurate assessment, I will configure additional evaluation by using another model, such as GPT-4 or Cloud 3.5. When this other model evaluates, it will provide more detailed metrics such as accuracy or relevance of the answers.\n\n**48:42** - After running the tests, the system will allow us to choose which metrics to monitor, such as relevance, correctness, and toxicity. Most models won’t answer questions related to toxic content, but the system still checks to ensure safety.\n\n**49:28** - The evaluation results will be displayed on the interface as matrices. Each answer will be checked to see if it is accurate or just a baseless guess from the model. These evaluations are crucial in improving and fine-tuning ML models to ensure they operate effectively and reliably.\n\n**50:48** - The system's format will display the data and require the corresponding value to be returned. Then, we can visualize this data. The system will evaluate whether the returned data is relevant. For example, there were two final questions in the previous test that were not in the document. Therefore, the system evaluates that these answers are not relevant. Specifically, the question about the trader's trading strategy was not in the document, so the evaluation model determined that the system's answer was irrelevant.\n\n**51:34** - When the system evaluates the answers, it will determine whether the answers are relevant to the document. For example, the evaluation model may determine that the system's answer is syntactically correct, but if it is not in the reference document, the relevance will be evaluated as none. This is crucial to ensure that the system not only provides correct answers in form but also fits the context and available documentation.\n\n**52:15** - Evaluation involves determining whether the information in the reference document matches the answer provided by the model. If the information is not found in the reference document, the system will evaluate that the answer is unrelated. This is an important tool for tracing and evaluating the system after deployment.\n\n**53:14** - After deployment, one of the key issues is evaluating the quality of the model. We can use a higher-level model to evaluate the current model or use a free or self-trained model. This evaluation can be applied to both pre-trained models and custom models. For example, if our main model is not GPT-4, we can use another model to evaluate the quality.\n\n**54:09** - The evaluation system can be used to check the quality of ML models or how we combine components in the system. This ensures that the system's output is appropriate and meets user requirements. This evaluation is an extra but very important part of tracing and improving the system.\n\n**55:31** - The essence of this system is still to trace each step and debug when necessary. For basic metrics like latency, the system will monitor parameters like execution time, errors, and check each step to ensure that the system operates correctly.\n\n**56:12** - This system can be very useful in managing large queries, especially when evaluating the output of a large number of users. After running the queries, we can filter out the answers that are rated as low and address them to improve the system.\n\n**57:12** - Using tools like tracing can incur costs, especially when evaluating many complex queries. These evaluation tools may use complex models, leading to high costs. However, tracing and evaluation after deployment are still necessary to ensure that the system operates efficiently.\n\n**58:51** - Tools like l smi allow for tracing and evaluating the entire system processing workflow. They can help calculate costs and identify which steps in the processing workflow need improvement. Integrating these tools can help trace each step and ensure that the system operates in the way we expect.\n\n**01:03:21** - Deploying a new system with tools like debox can help manage services easily without needing containers or Docker. This can be useful in optimizing performance and reducing system load. However, the initial setup and configuration can encounter some difficulties, especially when needing to be compatible with multiple environments.\n\n**01:05:58** - Managing the system through debox simplifies the process, but there are certain challenges, such as needing to customize installation packages. This requires users to have deep knowledge of the system and the software packages being used. However, the benefit is reducing reliance on Docker and improving system performance.\n\n**01:08:07** - The community using debox is still quite small, so finding support can be a bit difficult. However, for small projects or when needing to optimize system resources, debox can be an effective solution. We need to carefully consider before applying it to ensure that the system will operate efficiently in the development and deployment environment.\n\n**01:17:10** - Anything else? I cleaned up and shared it again for everyone. Currently, I’m running all the services together at once. If you want to run them individually, that’s also possible.\n\n**01:18:34** - Today, I will demo a new tool that you may have heard of recently, called Cursor. This is a new IDE that has been gaining popularity in the programming community, and I find it quite useful. Cursor actually resembles VS Code in terms of interface, but what sets it apart is its two main features: \"comk\" - used for code editing, and \"coml\" - used for chatting and direct development support.\n\n**01:18:34** Now, I will demo some of its features. For example, with \"comk,\" I can ask Cursor to create a new feature. Suppose I want to create a \"standup\" command to tag everyone in a channel. I can ask it to create this command with some options like adding or removing people I want to tag, or choosing the channel where this command will be executed.\n\nCursor will generate code based on my request, but one downside is that it cannot automatically create files or folders; I have to create them manually. After that, I can use the code it generates. Here, it generated a piece of code, but not according to the structure of my project, so I need to provide more context for it.\n\n**01:19:29** You can ask it about various aspects of the current project. For instance, if you need to understand certain parts of the project, when you chat, Cursor will give you two options: chat with the AI in a general environment, or chat within a specific project context. This allows you to get an overview of the structure and workings of this project.\n\nSuppose you want Cursor to help you implement a new feature, such as creating a new command in a Discord bot. You can ask it to create a \"standup\" command to remind everyone in a specific channel. This command will have several options, like allowing the addition or removal of people you don’t want to remind, or selecting a specific channel to send the notification to.\n\n**01:21:01** However, one drawback of Cursor is that it cannot automatically create new files or directories; you have to do it manually. Despite that, Cursor can generate code based on your request. But sometimes, the code it generates doesn’t follow the structure of your project. If you want it to stick more closely to the current context, you can import related files and directories to help it understand the project structure better.\n\nCursor also allows you to import resources like files, directories, or specific code snippets from the web or other sources. For example, you can ask it to use a folder named \"commands\" and import related files into it. Then, Cursor AI will generate code and structure it according to the format your project uses, such as creating `base`, `interface`, and `implementation` files for the new \"standup\" command.\n\n**01:23:25** After generating the code, it also guides you on how to update other parts of the project, like adding the new command to the Discord bot interface. Typically, when working with Cursor, it provides more specific and detailed solutions, especially when you can import existing sample files that follow your project’s conventions.\n\n**01:24:28** For example, you can ask Cursor to create a unit test for a configuration file like `config.go`. This is a simple example, using existing unit tests from Go. If you want to use an additional library or add details to the test, you can ask Cursor AI to adjust it according to your preferences.\n\nIf your project already has test files following a specific convention, you can import those files for Cursor to learn from, so it can create test cases that align with your team’s conventions. This helps save time and ensures that the generated test cases fit the team’s convention.\n\n**01:25:02** If you want to add a more complex feature, such as loading data from a JSON file, Cursor can help you update the code to implement this. It will add the necessary code to your file, automating repetitive tasks and minimizing errors when working manually.\n\n**01:26:40** You might have a question about whether Cursor indexes all your code to their server. According to their advertisement, Cursor runs entirely on your computer, creating a local environment to process and index all the source code, without sending data to their server unless you choose to use their API key.\n\n**01:27:56** However, there are still some concerns about whether data might be sent to Cursor’s server during processing, especially if you use their API key instead of your own. However, if you use your own key, you can better control your data and know who is using it.\n\n**01:29:03** In terms of the interface, Cursor seems more convenient as it helps you import files and code from various sources, improving its ability to understand the context. For example, you can import a project from GitHub for Cursor AI to learn the project’s conventions and generate more appropriate code.\n\n**01:31:19** I’ve experimented with importing a project from GitHub and asking Cursor AI to edit the code according to the project’s conventions. The result is that it understands and applies the conventions quite effectively, though some manual tweaks may still be needed. Cursor AI can not only generate code but also help manage and edit the code more efficiently.\n\n**01:33:16** Another strength of Cursor is its ability to help you quickly import and work with context, which is especially useful when working on large projects or when ensuring consistency across the codebase. While there are still some limitations, Cursor is indeed a powerful tool worth trying in software development.\n\n**01:36:07** In conclusion, Cursor is not just a code generator but also helps to understand and manage large codebases effectively. It can replace or complement other tools like Codex or GitHub Copilot in projects that require precision and deep context understanding. If possible, I encourage everyone to try this tool to take full advantage of its features.\n","title":"OGIF Office Hours #20 - Golang weekly, Modeling dynamic object properties, Devbox demo, LLM tracing, Cursor AI editor","short_title":"#20 Go weekly, Dynamic objects, Devbox, LLM tracing, Cursor AI","description":"Our latest OGIF session covers key topics such as Go 1.23 and the introduction of Go Notebook, dynamic object modeling inspired by Notion, advanced LLM tracing techniques, Devbox demo and a hands-on look at the Cursor AI code editor. By sharing weekly topics chosen through tags, we foster a collaborative learning environment for our community to grow.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Mon Aug 26 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/20-20240823.md","slugArray":["updates","ogif","20-20240823"]},{"content":"\n81 minutes\n\n### Topics & Highlights\n- Increasing community engagement and knowledge sharing:\n- Introduction of the DFG token and contribution recognition.\n- Focus on building an internet brand and improving team collaboration.\n- Market trends shifting towards AI and tech advancements.\n- Encouragement for small tool development and monetization.\n- Plans for future community initiatives and activities.\n- Insights on software development cost reduction through new technologies.\n\n---\n\n**Vietnamese transcript**\n\n**00:00** - Bắt đầu buổi họp\n\nOk, anh em đông đủ chưa? Thành ơi, nay muốn bắt đầu từ đâu? Anh em còn thiếu ai không? Hình như bên Thành có vấn đề với âm thanh rồi, nghe không rõ. Ok, vậy chắc là mọi người đã đủ rồi, mình bắt đầu nhé.\n\n**11:46** - Tóm tắt hoạt động tháng 8\n\nChào mọi người, quay trở lại với OGIF tuần này. Hôm nay chúng ta sẽ kết hợp với một số báo cáo về hoạt động tháng 8. Về cơ bản thì không có gì quá mới mẻ, ngoại trừ việc sau 3 tháng chạy thử nghiệm cơ chế ICY, chúng ta thấy các hoạt động thảo luận về kiến thức đang gia tăng theo kế hoạch, thậm chí còn vượt mục tiêu đề ra. Đây là một tín hiệu rất tích cực, và là điều mà anh cảm thấy có giá trị nhất hiện tại.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/vu0jI6rm8go?si=JQcjfgv_r0KiyFhg&amp;start=792\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**12:39** - Kết quả từ việc áp dụng ICY\n\nĐiều rõ ràng nhất mà chúng ta thấy được từ việc áp dụng ICY là cơ hội học hỏi và thảo luận mỗi thứ Sáu hàng tuần. Mọi người đều có cơ hội đưa ra các vấn đề và cùng nhau thảo luận, học hỏi từ nhau. Đó là kết quả rõ ràng nhất mà chúng ta có được từ tháng 8 này. Trong buổi họp trước, một bạn trong team có hỏi về token dfg của team mình, và hôm nay chúng ta sẽ bàn thêm về vấn đề này.\n\n**13:21** - Giới thiệu về Token dfg\n\nCụ thể, trong bản kế hoạch từ đầu năm của team, chúng ta mong muốn xây dựng một \"internet brand\" mạnh mẽ mà ai cũng có thể tự hào là một phần của nó. Token dfg này sẽ hoạt động giống như một loại cổ phiếu, nhưng chỉ dành riêng cho nội bộ. Để có được Token này trước năm 2020, mọi người phải xem nó như một dạng eop (Employee Ownership Program) nội bộ. Hiện nay, chúng ta đang chuyển đổi cơ chế ghi nhận đóng góp và chuẩn bị cho việc earn token này thông qua các hoạt động trong team.\n\n**14:10** - Kế hoạch phát triển Token dfg\n\nBan đầu, Token dfg hoạt động như một cổ phiếu riêng tư. Nhưng sau đó, chúng ta đã thông báo về việc mọi người có thể earn Token này qua các hoạt động đóng góp trong team. Trong khi team đang tiến hành các hoạt động theo kế hoạch, chúng ta cũng đang chuẩn bị để tất cả thành viên có thể earn Token này. Hiện tại, để earn được Token này, mọi người cần phải có đồng ICY và tham gia các hoạt động được liệt kê trong kênh earn ICY.\n\n**14:51** - Token dfg và quy trình ghi nhận đóng góp\n\nĐể có được token dfg trước năm 2020, nó được coi như một loại cổ phiếu nội bộ hoặc chương trình ESOP. Tuy nhiên, hiện tại chúng ta đã thiết lập quy trình ghi nhận đóng góp cho team. Việc này giúp các thành viên có thể earn token dfg thông qua việc đóng góp vào các hoạt động của team. Bước tiếp theo là anh em cần có đồng IC để có thể tham gia các hoạt động được liệt kê trong kênh earn IC.\n\n**15:35** - Đóng góp vào team\n\nMọi người có thể earn ICY bằng cách tham gia các hoạt động như research, chia sẻ kiến thức, hoặc tham gia trực tiếp vào các dự án. Những đóng góp này sẽ được ghi nhận và chuyển đổi thành ICY. Các hoạt động như rút tiền giúp người khác cũng có thể được xem là một cách để tích lũy ICY. Ngoài ra, một số thành viên cũng có thể sử dụng ICY thông qua cơ chế ứng lương.\n\n**16:45** - Phát triển brand\n\nViệc ghi nhận đóng góp và sở hữu token dfg sẽ giúp chúng ta xây dựng thương hiệu của team mạnh mẽ. Team đang thiết lập các cơ chế để mọi người có thể dễ dàng đóng góp và sở hữu một phần token của team. Các token này có thể được sử dụng trong các hoạt động nội bộ và có khả năng mở rộng ra bên ngoài thông qua quá trình staking. Đây là một bước quan trọng trong việc phát triển hệ thống quản trị phi tập trung (DFG).\n\n**19:08** - Thị trường và xu hướng AI\n\nTrong 3 tháng gần đây, chủ đề liên quan đến AI đang ngày càng được chú ý, với nhiều ứng dụng AI được giới thiệu và phát triển. Team chúng ta cũng đang chuyển dịch theo hướng này, với các hoạt động như demo AI tools, và những chủ đề liên quan đến sự dịch chuyển của thị trường công nghệ. Trong tháng 9, team sẽ công bố thêm các hướng dẫn chính thức liên quan đến việc phát triển các dự án AI nhỏ, tập trung vào việc giải quyết những vấn đề cụ thể và tối ưu hóa quy trình làm việc.\n\n**21:13** - Ảnh hưởng của AI đến chi phí phát triển phần mềm\n\nChi phí để phát triển phần mềm đang ngày càng giảm nhờ sự phát triển của AI. Các công ty sẽ không còn phải đầu tư quá nhiều vào các hoạt động thủ công, mà thay vào đó là tìm kiếm những người có khả năng sử dụng AI một cách hiệu quả. Sự thay đổi này sẽ tạo ra một thế hệ doanh nhân mới, những người có thể tận dụng AI để xây dựng các sản phẩm phần mềm nhanh chóng và hiệu quả hơn. Team chúng ta cũng đang chuyển dịch theo hướng này.\n\n**22:33** - Stream chính thức và các dự án open-source\n\nTrong tháng 9, team sẽ triển khai các dự án open-source nhỏ, tập trung vào việc giải quyết các vấn đề cụ thể thông qua các công cụ mạnh mẽ. Những ai tham gia vào các dự án này và có thể biến chúng thành sản phẩm hoàn chỉnh sẽ được ghi nhận và thưởng IC. Đây là một hướng đi mới nhằm khuyến khích các thành viên tạo ra những sản phẩm nhỏ nhưng sắc bén, góp phần vào sự phát triển của team.\n\n**23:57** - Tình hình tuyển dụng và layoff\n\nMặc dù có một số layoff trong thị trường công nghệ, nhưng nhu cầu tuyển dụng vẫn còn, đặc biệt là ở các công ty vừa và nhỏ, nơi họ đang thử nghiệm với các công nghệ mới. Nhiều công ty lớn vẫn đang tinh chỉnh lại bộ máy nhân sự của họ để thích nghi với sự dịch chuyển này. AI tiếp tục đóng vai trò quan trọng trong việc tối ưu hóa chi phí và quy trình phát triển phần mềm.\n\n**25:41** - Tình hình vận hành của team\n\nMột số dự án consulting đã bị tạm dừng do không còn phù hợp với thị trường, dẫn đến việc giảm bớt một số nguồn lực đầu tư. Tuy nhiên, đây là cơ hội để team chúng ta tập trung vào các dự án chiến lược hơn và xây dựng các case study giá trị. Hiện tại, hoạt động của team vẫn đang diễn ra suôn sẻ, và các dự án AI mới sẽ tiếp tục được triển khai trong thời gian tới.\n\n**26:20** - Phần trình bày OGIF\n\nChúng ta có ba bài trong buổi hôm nay. Bài thứ nhất là về phần Lego và phần tiếp theo là về MC với các khía cạnh liên quan đến enterprise. Bài thứ ba là tổng kết market report, liên quan đến AI mà chúng ta đã thảo luận. Bài cuối là phần chia sẻ của Tom về quy trình xử lý một prompt bằng AI, cách tạo ra một prompt hiệu quả hơn cho quá trình xử lý thông tin.\n\n**27:05** - Phân tích sâu về mindset khi làm developer\n\nHôm trước, Minh cloud đã chia sẻ phần liên quan đến việc xử lý dữ liệu từ góc nhìn của một user bình thường. Tuy nhiên, hôm nay chúng ta sẽ đi sâu hơn từ góc nhìn của một developer, đặc biệt là về mindset của các developer trong quá trình phát triển hệ thống.\n\n**27:51** - Quang Lê và portfolio của team\n\nTrong tuần qua, Quang Lê đã chuẩn bị một báo cáo tổng kết về portfolio của team, bao gồm việc tổng hợp thông tin từ các dự án khác nhau. Chúng ta sẽ xem qua các dự án này để có cái nhìn tổng quan về những gì đã thực hiện và những gì cần cải thiện.\n\n**30:03** - Tổng hợp dữ liệu và xuất bản báo cáo\n\nTrong quá trình tổng hợp, Quan đã sử dụng EOM và các công cụ khác để thu thập dữ liệu từ nhiều nguồn. Sau đó, thông tin được xuất thành các tệp PDF để dễ dàng chia sẻ và lưu trữ. Mọi thứ từ blockchain cho đến các dự án khác đều được tổng hợp lại.\n\n**31:25** - Sử dụng AI trong việc tổng hợp báo cáo\n\nQuan đã sử dụng các công cụ AI như GPT và Cloud để xử lý các tài liệu PDF và tạo ra một bản tóm tắt chi tiết cho từng dự án. Sau khi các tài liệu PDF được quét, AI sẽ trích xuất thông tin và tạo ra các báo cáo tổng kết dưới dạng case study.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/vu0jI6rm8go?si=DEn7qhrX369htqV7&amp;start=1897\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**35:11** - Tự động hóa quy trình tạo báo cáo\n\nBằng cách sử dụng các công cụ như Cloud và GPT, Quan đã tự động hóa phần lớn quy trình tạo báo cáo. Điều này giúp tiết kiệm thời gian và đảm bảo rằng các thông tin được thu thập và xử lý một cách chính xác. Việc tự động hóa còn cho phép dễ dàng cập nhật thông tin khi cần thiết.\n\n**37:31** - Trình bày case study\n\nCác case study từ các dự án đã được xử lý bằng AI và xuất thành báo cáo hoàn chỉnh. Quá trình này giúp chúng ta dễ dàng nắm bắt được những kỹ năng đã được phát triển qua từng dự án và những bước tiếp theo cần thực hiện.\n\n**38:13** - Quá trình xử lý dữ liệu và tổng hợp thông tin\n\nQuan đã mất khoảng hai tuần để hoàn thành việc tổng hợp và tạo báo cáo cho hơn mười dự án. Đây là một phương pháp hữu ích để theo dõi tiến trình của team và đánh giá các kỹ năng phát triển qua các dự án khác nhau.\n\n**39:15** - Prompt Engineering\n\nTom sẽ giải thích về prompt engineering và cách tạo ra các prompt để xử lý thông tin bằng AI. Trước đây, chúng ta đã làm điều này thủ công, nhưng hiện tại chúng ta sẽ sử dụng AI để tự động hóa quá trình này. Mục tiêu của bài hôm nay là tạo ra một prompt để tự động hóa quy trình xử lý dữ liệu từ hình ảnh hoặc hội thoại và trích xuất thông tin đặc biệt từ đó.\n\n**39:49** - Prompt cho việc tạo ra một JSON\n\nMục tiêu của JSON này là liên quan đến OSINT (Open Source Intelligence). Tôi sẽ sử dụng một bức ảnh làm input và dùng AI để đoán vị trí của nó. Phần này sẽ giải thích cách tạo hệ thống dựa trên input từ người dùng, bao gồm hình ảnh hoặc hội thoại, rồi trích xuất vị trí và các dữ liệu đặc biệt liên quan đến mục đích của nó. Ý tưởng ở đây là thu thập dữ liệu từ người dùng, sau đó sử dụng AI để tìm ra dữ liệu địa lý tương ứng từ ảnh hoặc hội thoại.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/vu0jI6rm8go?si=OekTXKuHnseLaI_3&amp;start=2316\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**41:21** - Sử dụng hệ thống prompt để tạo JSON\n\nTôi đã nhờ bên phía Cloack tạo giúp một prompt system. Quy trình này sẽ lặp lại nhiều lần để đảm bảo độ chính xác. Sau đó, tôi sao chép prompt và áp dụng lên các nền tảng như OpenAI để tiếp tục. Tôi chọn định dạng trả về là JSON và tiến hành với một bức ảnh. Mục tiêu là để AI đoán được vị trí từ bức ảnh và tạo ra một JSON object chứa các thông tin như liên kết Google Maps.\n\n**42:26** - Thử nghiệm với ảnh văn phòng\n\nChúng ta sẽ thử sử dụng một bức ảnh văn phòng để kiểm tra xem AI có thể đoán được vị trí không. Sau khi tải ảnh lên, tôi định dạng lại output và hy vọng nó sẽ trả về kết quả chính xác cùng với liên kết Google Maps. Trong trường hợp này, kết quả có vẻ đúng khi nó xác định tòa nhà trong ảnh.\n\n**43:21** - So sánh kết quả và suy luận vị trí\n\nTôi có thể so sánh JSON object được tạo ra và suy luận vị trí của bức ảnh này. AI đã phân tích hình ảnh và đưa ra vị trí chính xác từ các yếu tố hình ảnh trong bức ảnh đó. Đây là một cách sử dụng Cloack để xây dựng hệ thống map thông qua JSON, nhưng có thể mở rộng để output thêm các định dạng như SQL hoặc GraphQL.\n\n**44:18** - Tối ưu hóa hệ thống\n\nPhương pháp này giúp tôi dễ dàng định hướng cho AI và tạo ra prompt system một cách nhanh chóng. Mục tiêu của tôi là yêu cầu AI cung cấp vị trí dựa trên hình ảnh, nhưng kết quả đôi khi có thể không chính xác hoàn toàn nếu AI không có đủ dữ liệu tham khảo. Vì vậy, có thể cần phải chỉnh sửa lại prompt hoặc dùng các hình ảnh khác để thử nghiệm.\n\n**44:57** - Cải thiện accuracy của AI\n\nKhi thử các hình ảnh khác, tôi nhận ra rằng AI có thể gặp khó khăn trong việc xác định vị trí từ một số hình ảnh nhất định. Việc tối ưu hóa prompt system để AI hiểu đúng mục tiêu và trả về kết quả mong muốn là rất quan trọng. Chúng ta có thể cải thiện bằng cách cung cấp thông tin chi tiết hơn trong input hoặc cấu trúc lại cách AI hiểu dữ liệu đầu vào.\n\n**45:53** - Tạo prompt từ hình ảnh hoặc hội thoại\n\nMột ý tưởng khác là sử dụng hội thoại làm input thay vì hình ảnh. Chúng ta có thể yêu cầu AI xác định vị trí hoặc dữ liệu liên quan từ các hội thoại đó. Trong trường hợp này, AI sẽ phải dựa vào ngữ cảnh và thông tin từ cuộc trò chuyện để đưa ra kết quả. Tuy nhiên, điều này yêu cầu sự tùy chỉnh nhiều hơn cho prompt system.\n\n**46:50** - Độ chính xác khi sử dụng Cloack\n\nTôi nhận thấy rằng độ chính xác của Cloack trong việc xử lý input và trả về output liên quan đến không gian và thời gian là khá cao, gần 100%. Điều này cho thấy việc định nghĩa rõ ràng input, output và mục tiêu của hệ thống là rất quan trọng để AI hoạt động hiệu quả.\n\n**47:40** - Sử dụng prompt system cho các ví dụ khác\n\nNgoài việc sử dụng để đoán vị trí, prompt system có thể được áp dụng vào các bài toán khác như chuyển đổi query ngôn ngữ tự nhiên thành query ngôn ngữ lập trình. Đây là một ứng dụng khác của prompt system mà tôi sẽ demo tiếp theo, để AI có thể hiểu và xử lý các query một cách chính xác hơn.\n\n**48:27** - Ví dụ về việc sử dụng prompt system để tạo các prompt khác\n\nMột ví dụ khác là sử dụng prompt system để tạo ra các prompt mới, cải tiến từ các prompt cũ. Ví dụ, tôi có thể lấy một prompt hiện tại và yêu cầu AI cải thiện nó, tạo ra một output tốt hơn như chuyển từ output dạng text thành output dạng JSON. Điều này có thể hữu ích trong việc suy nghĩ hệ thống theo cách mà AI có thể xử lý tốt hơn.\n\n**50:33** - Cách AI xử lý dữ liệu từ prompt\n\nTôi đã thử nghiệm với một số prompt cũ và yêu cầu AI chuyển đổi nó thành prompt mới với cấu trúc tốt hơn. Trong quá trình này, AI có thể dựa vào dữ liệu từ các prompt trước để đưa ra một prompt phù hợp với mục tiêu mới. Điều này giúp chúng ta tạo ra các prompt hiệu quả hơn mà không cần phải viết lại từ đầu.\n\n**52:12** - Sử dụng AI để tối ưu hóa chatbot\n\nVí dụ, tôi có thể yêu cầu AI cải thiện prompt của một chatbot hiện tại để nó có thể tóm tắt thông tin tốt hơn. AI sẽ dựa trên prompt ban đầu và các output trước đó để tạo ra một prompt mới phù hợp với mục đích tối ưu hóa chatbot.\n\n**53:59** - Tự động hóa quy trình tạo prompt system\n\nSo với việc tạo prompt thủ công, sử dụng AI để tự động hóa quy trình này sẽ nhanh hơn và tiết kiệm thời gian hơn. Tuy nhiên, có thể vẫn cần phải chỉnh sửa thủ công để đảm bảo prompt system hoạt động đúng mục tiêu, đặc biệt là khi AI chưa được huấn luyện đầy đủ với các dữ liệu liên quan.\n\n**54:42** - So sánh dữ liệu và độ hiểu biết của AI\n\nTôi có thể so sánh dữ liệu mà AI trả về với kết quả mong đợi để đánh giá độ chính xác của prompt system. Nếu AI không hiểu đúng ngữ cảnh hoặc mục tiêu, có thể cần phải cung cấp thêm ví dụ hoặc điều chỉnh template để đạt được kết quả chính xác hơn.\n\n**55:37** - Sử dụng AI để giải thích quy trình\n\nMột ứng dụng khác là sử dụng AI để giải thích các bước trong quy trình phát triển. Ví dụ, AI có thể đọc mã nguồn hiện có và tạo ra một system prompt để giải thích quy trình làm việc hoặc các bước cần thiết để thực hiện một tính năng mới.\n\n**56:23** - Tự động hóa việc tạo system prompt cho các tính năng mới\n\nNếu tôi muốn thêm một tính năng mới vào một phần mềm hiện có, tôi có thể sử dụng AI để tạo một prompt system. AI có thể phân tích mã nguồn hiện có và gợi ý các thay đổi cần thiết để tích hợp tính năng mới. Điều này giúp tiết kiệm thời gian và đảm bảo rằng tính năng mới phù hợp với kiến trúc hệ thống.\n\n**57:04** - Áp dụng AI cho việc tích hợp giữa các hệ thống\n\nVí dụ, khi chuyển từ một hệ thống EVM sang một hệ thống khác có cấu trúc tương tự, tôi có thể sử dụng AI để tự động hóa quy trình tích hợp, từ đó giúp quá trình phát triển diễn ra nhanh hơn và hiệu quả hơn.\n\n**57:49** - Tạo prompt system cho việc phát triển tính năng mới\n\nTôi có thể yêu cầu AI tạo ra một system prompt để giải thích các bước cần thiết trong việc phát triển một tính năng mới, từ việc cập nhật file, interface đến việc tạo ra các component map hoặc package map.\n\n**58:32** - Ví dụ về việc tạo system prompt\n\nVí dụ, tôi có thể yêu cầu AI tạo một prompt system để giải thích cách thực hiện các bước cần thiết trong việc phát triển một tính năng mới. AI sẽ tạo ra một system prompt dựa trên các thông tin đầu vào và cung cấp các hướng dẫn chi tiết về các thay đổi cần thực hiện trong mã nguồn.\n\n**59:19** - Kết luận\n\nQuy trình sử dụng AI để tạo system prompt là một bước tiến lớn trong việc tự động hóa phát triển phần mềm. Tuy nhiên, cần phải có sự cân nhắc về cách huấn luyện AI để đảm bảo rằng nó có thể hiểu đúng ngữ cảnh và đưa ra các gợi ý phù hợp cho việc phát triển hệ thống.\n\n**01:00:18** Có ai hỏi gì thêm không? Chắc để tôi show cho anh em xem bản chất của một cái \"System BOM\" (Bill of Materials) và nó như thế nào thì nó mới được gọi là tốt. Thì một BOM tốt sẽ cần có những yếu tố gì, thành phần nào? Ví dụ như, theo kinh nghiệm thì nhiều khi nên \"fill SH\" (tạo Skeleton Structure) trước, rồi điền vài example cho dễ kiểm tra. Mọi người thấy đúng không? Thực tế thì để chuẩn bị một system prop cho enterprise, cần dựa trên dữ liệu rõ ràng để có bằng chứng giải thích cho client hiểu. Sau đó, mình có thể nhờ AI (Artificial Intelligence) để hỗ trợ tạo prop, rồi mình kiểm tra, test xem prop đó có ổn không. Nếu ổn thì mình mới đưa vào quy trình và cho auto luôn.\n\n**01:01:04** Thế là sẽ hình dung ra một mô hình (model) đánh giá từ góc nhìn của mình. Nó sẽ có chức năng so sánh và đánh giá rằng: \"À, cái này đúng rồi, cái này phù hợp\", chẳng hạn có tên gọi là \"Evaluator\". Câu hỏi của anh là làm sao mình biết cái System BOM này có đủ tiêu chuẩn không?\n\n**01:01:43** Ví dụ như em tạo một cái description và từ đó ra một \"System Y\", đúng không? Thì tiêu chí đánh giá sẽ là gì? Làm sao biết được nó hợp lý hay không?\n\n**01:02:28** Nếu muốn đánh giá về \"semantic\" (ngữ nghĩa), thì AI sẽ phải đánh giá về cấu trúc dữ liệu (JSON), và kiểm tra tính chính xác của dữ liệu đó. Nếu cần kiểm tra về cấu trúc (structure) của JSON, có thể dùng một công cụ kiểu \"Lexical Compiler\", để kiểm tra format có đúng không, prefix có chuẩn không. Có những công cụ để kiểm tra thêm, ngoài ngữ nghĩa thì còn phải đảm bảo dữ liệu trả về đầy đủ, chính xác. Ví dụ, nó trả lại dữ liệu nhưng chỉ đạt 80% hoặc 90%, mình có thể lập trình thêm một số bước để kiểm tra độ bao phủ của output bằng các phương pháp tìm kiếm từ khóa (Keyword Search).\n\n**01:03:45** Cuối cùng, mình so sánh output của AI với các tiêu chuẩn mà mình mong muốn như về cấu trúc, ngữ nghĩa hay định dạng. Nếu đạt yêu cầu, mình có thể tiếp tục sử dụng. Thành có hỏi làm sao để đánh giá semantic mà lại có thể chuẩn hóa (standardize) cách đo lường, đúng không?\n\n**01:04:31** Mình sẽ verify phần output chứ không chỉ xác nhận từng bước của system prop. Kiểu như mình xem qua rồi thấy ok thì mới chốt là cái BOM đó chuẩn.\n\n**01:06:26** Em xin điểm qua cái tuần này nha. Bài đầu tiên có tín hiệu khá khả quan là thằng Igo vừa tuần rồi đã ra bản mới, hỗ trợ Go 1.23 và có thêm các tính năng mới như `Range over function`. Đây là một compiler dành cho WebAssembly hoặc các microcontroller kiểu embedded. Rồi một tool khác nữa là `xcv`, một vector extension cho C, trước đây phát triển bởi cá nhân nhưng giờ thuộc Mozilla.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/vu0jI6rm8go?si=ouW-MLqxz8PQnYQL&amp;start=3978\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**01:07:54** Tiếp theo là tool permify, một authorization service lấy cảm hứng từ Google Z bar. Nó claim rằng abstract hóa hoàn toàn logic authorization ra khỏi codebase để dễ test và quản lý, đồng thời tương thích với các phương pháp như role-based, relation-based, và attribute-based authorization. Nó cũng có khả năng tích hợp với các vendor khác dễ dàng.\n\n**01:09:52** Ngoài ra, em vừa boost thêm một số content liên quan đến Go enterprise. Nội dung đang được cập nhật dần và sẽ giải thích lý do Java được chọn cho enterprise, và vì sao Go có thể thay thế được Java trong nhiều trường hợp enterprise hiện tại.\n\n**01:10:33** Mọi người cũng có thể input thêm vào channel, hiện tại chủ yếu đang cố gắng map các tiêu chí của Java và Go, đặc biệt là trong bối cảnh enterprise. Cũng sẽ cố gắng tổng hợp thêm các nguồn từ anh em để trả lời những câu hỏi như tại sao Go lại đang dần trở thành một lựa chọn thay thế cho Java trong các hệ thống lớn.\n\n**01:11:43** Phần này hướng đến việc làm rõ lý do Go được các enterprise chọn, cùng với các case study về những công ty đang chuyển từ Ruby qua Go. Dự kiến sẽ có nhiều ví dụ cụ thể để chứng minh tính khả thi và tính ổn định của Go trong bối cảnh enterprise.\n\n**01:12:23** Dự kiến sẽ có thêm nhiều case study từ các công ty lớn đã chuyển qua Go và lý do đằng sau sự thay đổi này, đặc biệt là khi so sánh về chi phí và hiệu quả giữa Java và Go trong các ứng dụng enterprise hiện đại.\n\n**01:14:23** Cuối cùng, tụi anh dự kiến sẽ phát triển cộng đồng Go lớn mạnh hơn bằng cách thu thập thêm những case study cụ thể và có thể giúp các công ty khác dễ dàng đưa ra quyết định chuyển sang Go.\n\n**01:15:11** Bài này về chuyện cổ vũ các bạn làm những tool nhỏ nhưng chất lượng, có thể phát triển để thành sản phẩm thương mại hóa. Trong tương lai, xu hướng solo developer sẽ càng phát triển mạnh hơn. Anh muốn hỗ trợ các bạn thông qua việc setup một lượng ICY để khuyến khích những sản phẩm sáng tạo, như Tuấn đang làm. Các bạn hoàn toàn có thể phát triển những tool nhỏ và thêm vài tính năng để hoàn thiện, từ đó tạo ra sản phẩm có thể kiếm tiền.\n\n**01:16:21** Cộng đồng Go cũng đang quay lại với các hoạt động mới. Mình sẽ triển khai mô hình “contribution and earn” như team mình đang làm. Huy sẽ phụ trách setup hệ thống này. Ngoài ra, mình cũng sẽ làm một đợt giveaway cho áo Go cũ và mới để thu hút thêm người tham gia cộng đồng. Đây là những bước để thúc đẩy phong trào lập trình Go trong cộng đồng.\n\n**01:17:01** Còn một phần nữa liên quan đến việc giảm chi phí sản xuất phần mềm. Hiện tại, các công nghệ EOM đang là trung tâm của việc này, như Tom đã demo cho team. Nếu chúng ta có thể nắm bắt kiến thức về những công nghệ này thì sẽ giúp đẩy nhanh quá trình code, xây dựng và phát hành sản phẩm. Điều này rất quan trọng với thời đại hiện nay.\n\n**01:17:46** Các chủ đề tiếp theo trong tháng chắc sẽ được Thành sắp xếp. Anh muốn tuyên dương team Debo vì vẫn đang theo dõi và hỗ trợ quá trình deploy dự án. Mong rằng các anh em test và chia sẻ trải nghiệm của mình, nhất là với những máy yếu để xem Debox có phù hợp không.\n\n**01:18:29** Còn về những phần khác, Tom đang tiếp tục pick up các phần về LLM và chia sẻ với toàn bộ team. Phần của Huy nhỏ và Tuấn cũng rất quan trọng, cả hai đang xử lý nhiều công việc nặng, nhưng kết quả vẫn khả quan.\n\n**01:20:51** Nếu trong quá trình xem có bài viết nào trên kênh tech mà mọi người muốn làm một buổi talk nhỏ, thì cứ đăng ký nhé, càng hoan nghênh. Đăng ký với Thành hay ping anh cũng được. Mình sẽ thoải mái trao đổi cùng mọi người.\n\n---\n\n**00:00** - Meeting begins\n\nOk, is everyone here? Thành, where do you want to start today? Is anyone missing? It seems like Thành is having some audio issues, can't hear clearly. Alright, looks like everyone is here, so let's begin.\n\n**11:46** - August activity summary\n\nHello everyone, welcome back to this week's OGIF. Today we'll also combine some reports on August activities. Basically, there's nothing too new, except after three months of trial running the ICY mechanism, we see that knowledge-sharing activities have been increasing as planned, even surpassing the set goals. This is a very positive sign, and it's what I find most valuable at the moment.\n\n**12:39** - Results from applying ICY\n\nThe clearest result we've seen from applying ICY is the opportunity for learning and discussion every Friday. Everyone has a chance to bring up issues and discuss them together, learning from each other. This is the clearest result we've gained from this August. In the last meeting, someone from the team asked about our team's token dfg, and today we'll discuss this further.\n\n**13:21** - Introduction to Token dfg\n\nSpecifically, in the team's plan from the beginning of the year, we aimed to build a strong \"internet brand\" that everyone can be proud to be part of. This dfg token will function similarly to a stock, but exclusively internal. To obtain this token before 2020, people had to view it as an internal employee ownership program (EOP). Currently, we are transitioning the mechanism for recording contributions and preparing for earning this token through team activities.\n\n**14:10** - dfg Token development plan\n\nInitially, the dfg token operated like a private stock. But later, we announced that people could earn this token through contributing to team activities. While the team is proceeding with planned activities, we're also preparing so that all members can earn this token. Currently, to earn this token, everyone needs to have ICY coins and participate in the activities listed in the earn ICY channel.\n\n**14:51** - dfg Token and contribution recording process\n\nBefore 2020, obtaining the dfg token was considered a form of internal stock or ESOP. However, we've now set up a contribution recording process for the team. This allows members to earn the dfg token through contributions to team activities. The next step is that everyone will need ICY coins to participate in the activities listed in the earn IC channel.\n\n**15:35** - Team contributions\n\nPeople can earn ICY by participating in activities like research, knowledge sharing, or directly joining projects. These contributions will be recorded and converted into ICY. Activities like cashing out to help others can also be seen as a way to accumulate ICY. Additionally, some members can use ICY through the salary advance mechanism.\n\n**16:45** - Brand development\n\nRecording contributions and owning dfg tokens will help us build the team’s brand more strongly. The team is establishing mechanisms to make it easier for everyone to contribute and own part of the team's token. These tokens can be used in internal activities and potentially extended outside through staking. This is an important step in developing the decentralized governance system (DFG).\n\n**19:08** - AI market trends\n\nIn the past three months, AI-related topics have garnered increasing attention, with many AI applications being introduced and developed. Our team is also shifting in this direction, with activities like AI tool demos and discussions about the technological market shift. In September, the team will announce more official guides related to developing small AI projects, focusing on solving specific problems and optimizing workflows.\n\n**21:13** - Impact of AI on software development costs\n\nThe cost of software development is steadily decreasing due to AI's development. Companies will no longer need to invest heavily in manual activities but instead look for people capable of effectively using AI. This shift will create a new generation of entrepreneurs who can leverage AI to build software products faster and more efficiently. Our team is also transitioning in this direction.\n\n**22:33** - Official streams and open-source projects\n\nIn September, the team will launch small open-source projects focusing on solving specific problems through powerful tools. Those who participate in these projects and can turn them into complete products will be recognized and rewarded with IC. This is a new direction encouraging members to create sharp, small products that contribute to the team’s development.\n\n**23:57** - Recruitment and layoffs\n\nAlthough there have been some layoffs in the tech market, recruitment demand still exists, particularly among small and medium-sized companies experimenting with new technologies. Many large companies are still refining their human resources to adapt to this shift. AI continues to play an important role in optimizing costs and software development processes.\n\n**25:41** - Team operations status\n\nSome consulting projects have been paused due to market misalignment, resulting in reduced investment in certain resources. However, this presents an opportunity for our team to focus on more strategic projects and build valuable case studies. Currently, the team’s operations are running smoothly, and new AI projects will continue to roll out in the near future.\n\n**26:20** - OGIF presentation\n\nWe have three presentations today. The first is about Lego, and the next is about MC with aspects related to enterprise. The third one is a market report summary concerning AI, which we’ve already discussed. The final presentation is Tom’s sharing about the process of handling a prompt using AI and how to create a more effective prompt for information processing.\n\n**27:05** - In-depth analysis of a developer's mindset\n\nLast time, Minh Cloud shared about data processing from a regular user's perspective. However, today we’ll dive deeper from a developer's perspective, especially regarding the mindset of developers during system development.\n\n**27:51** - Quang Lê and the team’s portfolio\n\nOver the past week, Quang Lê has prepared a summary report on the team's portfolio, including information gathered from various projects. We’ll review these projects to get an overview of what has been done and what needs improvement.\n\n**30:03** - Data aggregation and report publication\n\nDuring the aggregation process, Quang used EOM and other tools to collect data from multiple sources. The information was then exported into PDF files for easy sharing and storage. Everything from blockchain to other projects has been compiled.\n\n**31:25** - Using AI for report compilation\n\nQuan utilized AI tools like GPT and Cloud to process PDF documents and generate detailed summaries for each project. After scanning the PDFs, the AI extracted information and created comprehensive summary reports in the form of case studies.\n\n**35:11** - Automating the report creation process\n\nBy using tools like Cloud and GPT, Quan automated much of the report creation process. This saved time and ensured that the information was collected and processed accurately. Automation also made it easy to update the information whenever necessary.\n\n**37:31** - Presenting case studies\n\nThe case studies from various projects were processed by AI and turned into complete reports. This process helped us easily capture the skills developed through each project and identify the next steps that need to be taken.\n\n**38:13** - Data processing and information aggregation\n\nQuan spent approximately two weeks compiling and generating reports for over ten projects. This method is useful for tracking the team's progress and evaluating the skills developed across different projects.\n\n**39:15** - Prompt Engineering\n\nTom will explain prompt engineering and how to create prompts to process information using AI. Previously, we did this manually, but now we will use AI to automate the process. Today's goal is to create a prompt that automates the process of extracting specific information from images or conversations.\n\n**39:49** - Prompt for generating a JSON\n\nThe goal of this JSON relates to OSINT (Open Source Intelligence). I will use an image as input and employ AI to estimate its location. This section will explain how to build a system based on user input, including images or conversations, and then extract the location and specific data relevant to the task. The idea is to gather user data and use AI to find corresponding geographic data from the image or conversation.\n\n**41:21** - Using the prompt system to generate JSON\n\nI had Cloack create a prompt system for me. This process repeats several times to ensure accuracy. Then, I copied the prompt and applied it to platforms like OpenAI. I chose JSON as the output format and worked with an image. The goal is for AI to estimate the location from the image and generate a JSON object containing information such as a Google Maps link.\n\n**42:26** - Experimenting with an office photo\n\nWe will try using an office photo to see if AI can estimate the location. After uploading the image, I reformatted the output and hope it will return an accurate result along with a Google Maps link. In this case, the result seems correct as it identified the building in the photo.\n\n**43:21** - Comparing results and deducing the location\n\nI can compare the generated JSON object and deduce the location of the image. The AI analyzed the image and accurately identified the location based on visual elements in the photo. This is a way of using Cloack to build a mapping system through JSON, but it can be expanded to output formats like SQL or GraphQL.\n\n**44:18** - Optimizing the system\n\nThis method allows me to quickly guide the AI and create a prompt system. My goal is to have AI provide the location based on the image, but sometimes the results may not be entirely accurate if AI lacks enough reference data. Therefore, the prompt may need adjustments or other images used for testing.\n\n**44:57** - Improving AI accuracy\n\nWhen testing with other images, I noticed that AI may struggle to identify the location in certain images. Optimizing the prompt system so that AI correctly understands the goal and returns the desired result is crucial. We can improve this by providing more detailed input information or restructuring how AI interprets the data.\n\n**45:53** - Creating prompts from images or conversations\n\nAnother idea is to use conversations as input instead of images. We could ask AI to determine the location or relevant data from those conversations. In this case, AI would need to rely on the context and information from the conversation to produce the result. However, this requires more customization for the prompt system.\n\n**46:50** - Accuracy when using Cloack\n\nI found that Cloack’s accuracy in processing input and returning spatial and temporal output is quite high, nearly 100%. This demonstrates the importance of clearly defining the input, output, and goal for the system to make AI work efficiently.\n\n**47:40** - Using the prompt system for other examples\n\nBeyond guessing locations, the prompt system can be applied to other problems, such as converting natural language queries into programming language queries. This is another application of the prompt system that I will demo next, allowing AI to understand and process queries more accurately.\n\n**48:27** - Example of using the prompt system to create other prompts\n\nAnother example is using the prompt system to generate new prompts, improving on existing ones. For instance, I can take a current prompt and ask AI to enhance it, creating better output, such as converting from text output to JSON output. This can be helpful in thinking about the system in a way that AI can process better.\n\n**50:33** - How AI processes data from prompts\n\nI experimented with some old prompts and asked AI to transform them into new prompts with better structure. During this process, AI could rely on data from previous prompts to produce one that fits the new goal. This helps us create more effective prompts without having to rewrite them from scratch.\n\n**52:12** - Using AI to optimize chatbots\n\nFor example, I could ask AI to improve a chatbot's prompt so it can summarize information better. AI will base the new prompt on the original one and previous outputs to create a new prompt tailored to optimizing the chatbot.\n\n**53:59** - Automating the prompt system creation process\n\nCompared to manually creating prompts, using AI to automate this process is faster and more time-efficient. However, manual adjustments may still be necessary to ensure that the prompt system works toward the intended goal, especially when AI has not been fully trained with the relevant data.\n\n**54:42** - Comparing data and AI's understanding\n\nI can compare the data AI returns with the expected results to evaluate the prompt system's accuracy. If AI doesn't understand the context or goal correctly, we may need to provide more examples or adjust the template to achieve more accurate results.\n\n**55:37** - Using AI to explain processes\n\nAnother application is using AI to explain the steps in a development process. For example, AI can read existing source code and create a system prompt to explain the workflow or the necessary steps to implement a new feature.\n\n**56:23** - Automating system prompt creation for new features\n\nIf I want to add a new feature to existing software, I can use AI to create a prompt system. AI can analyze the existing code and suggest necessary changes to integrate the new feature. This saves time and ensures that the new feature fits the system architecture.\n\n**57:04** - Applying AI for system integration\n\nFor example, when migrating from one EVM-based system to another with a similar structure, I can use AI to automate the integration process, speeding up development and making it more efficient.\n\n**57:49** - Creating a prompt system for feature development\n\nI can ask AI to create a system prompt to explain the steps necessary for developing a new feature, from updating files and interfaces to creating component maps or package maps.\n\n**58:32** - Example of system prompt creation\n\nFor example, I can ask AI to create a prompt system explaining how to perform the necessary steps for developing a new feature. AI will generate a system prompt based on the input information and provide detailed instructions for changes to be made in the source code.\n\n**59:19** - Conclusion\n\nThe process of using AI to create system prompts is a significant step forward in automating software development. However, careful consideration is required when training AI to ensure it understands the context and provides suitable suggestions for system development.\n\n**01:00:18** Does anyone have any additional questions? Let me show you the essence of a \"System BOM\" (Bill of Materials) and what makes a good one. A good BOM needs certain elements and components. For example, based on my experience, it’s often good to \"fill SH\" (create a Skeleton Structure) first, then add a few examples to make it easier to verify. Does that sound right? In practice, preparing a system prop for enterprise requires clear data to provide evidence that explains it to the client. Afterward, we can ask AI (Artificial Intelligence) to help create the prop, then we test it to see if it’s solid. If it’s good, we integrate it into the process and automate it.\n\n**01:01:04** So, we can envision a model from our perspective. It will have a function that compares and evaluates, saying, \"Ah, this is correct, this is appropriate,\" which we might call an \"Evaluator.\" The question is, how do we know if the System BOM meets the standard?\n\n**01:01:43** For example, you create a description, and from that, you get a \"System Y,\" right? So what are the evaluation criteria? How do we know if it's reasonable or not?\n\n**01:02:28** If you want to evaluate the \"semantics,\" then AI will have to assess the data structure (JSON) and check the accuracy of that data. If you need to check the structure of the JSON, you can use a tool like a \"Lexical Compiler\" to verify if the format is correct, the prefixes are proper, etc. There are additional tools to ensure that beyond semantics, the data returned is complete and accurate. For instance, if it returns data that's only 80% or 90% accurate, you could program additional steps to check the output coverage using keyword search methods.\n\n**01:03:45** Finally, we compare AI's output to the standards we expect, whether for structure, semantics, or format. If it meets the requirements, we continue using it. Thành asked how we can evaluate the semantics while standardizing the measurement method, correct?\n\n**01:04:31** We’ll verify the output rather than just confirming each step of the system prop. It’s like reviewing it and, once we see it’s okay, then we can finalize that the BOM is standard.\n\n**01:06:26** Let me summarize this week’s highlights. The first notable point is that Igo released a new version last week, supporting Go 1.23 and adding new features like `Range over function`. This is a compiler for WebAssembly or embedded microcontroller types. Another tool is `xcv`, a vector extension for C, which was previously developed by an individual but now belongs to Mozilla.\n\n**01:07:54** Next is the tool Permify, an authorization service inspired by Google Z bar. It claims to completely abstract authorization logic out of the codebase, making it easier to test and manage, while also being compatible with methods like role-based, relation-based, and attribute-based authorization. It also integrates easily with other vendors.\n\n**01:09:52** Additionally, I just boosted some content related to Go enterprise. The content is being updated gradually and will explain why Java was chosen for enterprise and why Go can replace Java in many current enterprise cases.\n\n**01:10:33** Everyone can also input into the channel; right now, we're mainly trying to map the criteria between Java and Go, especially in the enterprise context. We’ll also try to compile additional sources from the team to answer questions like why Go is increasingly becoming a replacement for Java in large systems.\n\n**01:11:43** This section aims to clarify why Go is being chosen by enterprises, along with case studies of companies transitioning from Ruby to Go. More examples will be provided to demonstrate the feasibility and stability of Go in enterprise applications.\n\n**01:12:23** We plan to add more case studies from large companies that have switched to Go and the reasons behind this change, particularly when comparing costs and efficiency between Java and Go in modern enterprise applications.\n\n**01:14:23** Lastly, we aim to grow the Go community by gathering specific case studies that can help other companies easily decide to transition to Go.\n\n**01:15:11** This talk is about encouraging people to create small but quality tools that can be developed into commercial products. In the future, the trend of solo developers will grow even stronger. I want to support these efforts by setting up an amount of ICY to encourage creative products, like what Tuấn is working on. You can develop small tools, add some features to perfect them, and create products that can generate revenue.\n\n**01:16:21** The Go community is also reviving with new activities. We will implement the \"contribution and earn\" model, like what our team is doing. Huy will be in charge of setting up this system. Additionally, we’ll conduct a giveaway for old and new Go shirts to attract more participants to the community. These are steps to promote Go programming within the community.\n\n**01:17:01** One more point related to reducing software production costs: currently, EOM technologies are at the center of this, as Tom has demonstrated to the team. If we can grasp the knowledge of these technologies, it will help accelerate the coding, building, and product release processes. This is very important in today’s age.\n\n**01:17:46** The upcoming topics for the month will likely be arranged by Thành. I want to comment the team for continuing to monitor and support the project deployment process. I hope everyone tests and shares their experiences, especially those with low-powered machines, to see if Devbox is suitable.\n\n**01:18:29** As for other parts, Tô is continuing to pick up sections about AMOM and sharing them with the whole team. Huy and Tuấn’s parts are also very important, both handling heavy workloads, but the results are still promising.\n\n**01:20:51** If there’s an article on the tech channel that anyone wants to do a small talk about, feel free to sign up, you're more than welcome. Register with Thành or ping me. We’ll be happy to discuss everything with everyone.\n","title":"OGIF Office Hours #21 - Community engagement, Go weekly, Journey of thought for prompt engineering","short_title":"#21 Community engagement, Go weekly, Journey of thought for prompt engineering","description":"Our latest community discussion covers key topics such as increasing community engagement, the introduction of the DFG token for contribution recognition, building an internet brand, and market trends toward AI and tech advancements. We’ll also explore small tool development for monetization and insights on reducing software development costs with new technologies. Join us to learn more about upcoming initiatives and activities.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Thu Sep 05 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/21-20240830.md","slugArray":["updates","ogif","21-20240830"]},{"content":"\n100 minutes\n\n### Topics & Highlights\n- Office improvements announced for remote working.\n- Market report shared with project updates.\n- Live demo on software research and development.\n- Emphasis on team collaboration and social connections.\n- New AI tools showcased for enhanced productivity.\n- Discussion on Go programming updates and features.\n- Audience engagement encouraged throughout the session.\n\n---\n\n**Vietnamese Transcript**\n\n**00:00** Đây rồi, còn thêm ai nữa không? Vậy là hôm nay mình có ba tiết mục. Đầu tiên là market report của Thành, sau đó là phần phát triển, chắc sẽ nhanh thôi. Phần còn lại dành cho Tôm. Đấy, vẫn còn nhiều thời gian quá. Bài của Mỹ cũng nhiều, để không thì Mỹ post luôn, rồi anh em xem sau nhé. Mỹ ơi, em post bài của mình chưa? Mọi người có thấy màn hình chưa? Dạ, tiếng hơi nhỏ à? Đợi chút để mình lấy phone ra. Giờ mình bắt đầu nhé. Phần đầu tiên là về communities. \n\n**17:39** Ngoài các con số tuần trước, chắc anh sẽ đi qua một số điểm tin. Thông tin quan trọng là từ tuần sau, team mình sẽ bắt đầu triển khai hai việc. Thứ nhất là enable hybrid working. Tí nữa anh sẽ gửi link chi tiết, nhưng hiện tại thì chủ yếu vẫn là work through một chút. Office sẽ được cải tiến dành cho những bạn cảm thấy làm việc tại nhà hơi ồn, hoặc không tập trung được. \n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/wED1g78PEn0?si=Ne0XOi-_aDTNzuST&amp;start=1087\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**18:31** Hiện tại Office của mình có khoảng năm người đang sử dụng, vẫn còn trống khoảng mười chỗ nữa. Khi mọi người lên đây, mình sẽ được cover chi phí sử dụng Apple Studio Display, ghế Herman Miller cũng đã được trang bị đầy đủ. Nếu anh em chưa biết thì có thể Google để hiểu rõ về ghế này. Phòng họp và một số trang thiết bị khác trong Office cũng đã được cải tiến đáng kể. Những bạn nào cảm thấy ở nhà chán hoặc không thoải mái, có thể cân nhắc đến Office làm việc một hai ngày trong tuần. Điều này là optional, không bắt buộc.\n\n**19:48** Nhưng team mong muốn mọi người bắt đầu điều chỉnh công việc, để nó mang lại những lợi ích thiết yếu cho việc làm việc chung tại văn phòng. Tăng cường các mối quan hệ xã hội, đặc biệt trong giai đoạn này khi lượng kiến thức và nghiên cứu cần xử lý rất lớn. Việc làm chung với nhau sẽ giúp đẩy nhanh tiến độ, nhất là khi chúng ta đang ở giai đoạn cuối các dự án.\n\n**20:28** Ngoài ra, tất cả chi phí về parking và bữa ăn tối sẽ được hỗ trợ. Đây là thông báo chính mà tí nữa Mỹ sẽ viết thông báo chi tiết cho tất cả mọi người. Đó là thông báo đầu tiên, và anh nghĩ mọi người sẽ quan tâm đến nó. Thông báo thứ hai là về việc test thử một tính năng mới: Daily check-in. Nếu ai tham gia Daily check-in, trong hai tuần đầu tiên, mỗi khi check-in sẽ được thưởng khoảng từ 3 đến 5 ICY.\n\n**22:29** Đúng rồi, mọi người sẽ nhận được ICY mỗi ngày. Nhưng trong giai đoạn ban đầu, tụi anh sẽ chạy thử nghiệm trong khoảng hai tuần để xem tính năng này hoạt động như thế nào. Vì số lượng chỗ trong Office có giới hạn, nên anh sẽ ưu tiên cho những ai bắt đầu hybrid working và còn dư chỗ thì sẽ chuyển dần remote. Để cải tiến chất lượng làm việc tại Office, tụi anh đang cố gắng update Office lên mức tốt nhất có thể.\n\n**23:24** Vì thực tế là số chỗ trong Office có hạn, nên ưu tiên là khuyến khích những ai muốn lên Office vài ngày mỗi tuần, nếu cảm thấy làm việc tại nhà không hiệu quả. Và nếu sau một hai tuần mọi người thấy thích nghi tốt, thì có thể personalization góc làm việc riêng của mình, mang những món đồ cá nhân lên để tạo cảm giác thoải mái hơn.\n\n**24:04** Team Hà Nội thì check-in ở đâu? Ừ, anh cũng mang tủ cá nhân và vài món đồ Lego của con lên Office luôn rồi. Đấy là hai thông báo chính. Hy vọng mọi người sẽ cân nhắc và bắt đầu thử nghiệm. Tụi anh đang cố gắng khôi phục lại văn hóa làm việc vật lý, với những ngày hybrid working như 1-2 ngày/tuần tùy vào trạng thái tâm lý và sự thoải mái của mỗi người.\n\n**25:15** Rồi, mọi người sẽ thấy rằng việc lên văn phòng sẽ giúp có nhiều kết nối cá nhân hơn. Có thể đi làm nửa ngày hoặc cả ngày cũng được, tùy vào tình hình của mọi người. Ok, vậy là xong phần quan trọng rồi nhé. Giờ anh sẽ chuyển sân khấu lại cho Thành để tiếp tục phần market report.\n\n**26:08** Bây giờ, chúng ta sẽ đi qua những bài viết đáng chú ý trong tuần qua. Top 20 bài đã được đọc và chuyển từ DynamoDB sang MySQL, và có một bài viết khá hay về Neil, hỗ trợ cho bài nghiên cứu về Debox. Hôm qua mọi người có thảo luận khá sôi nổi về Debox trên kênh chat của team tech. Nội dung thảo luận đã được ghi lại, mọi người có thể vào xem. Nhưng có một số điểm chưa rõ về Debox, nó chỉ là một môi trường development box, không phải là môi trường deployment như container.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/wED1g78PEn0?si=YvI91WKNTGQxoUP7&amp;start=1965\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**27:11** Debox chỉ là một box cho môi trường development thôi, nó không phải là môi trường deployment như container. Về cơ bản, chúng ta vẫn sẽ cần cả hai môi trường này vì chúng không thay thế cho nhau. Trên môi trường development, đặc biệt là đối với những người sử dụng máy M1, thì Debox sẽ cài một layer VM trên máy M1 để có thể chạy container. Điều này là do Debox không thể chạy native trên M1 mà phải qua một lớp trung gian là VM. Giải pháp mà NX team đang sử dụng là Linux trên VM, và nó được cài đặt trực tiếp trên máy, không có tầng trung gian giữa như các hệ thống khác. Đó là lý do tại sao hệ thống này hoạt động tốt trên các máy M1.\n\n**27:47** Bài tiếp theo nói về Accessibility Design trong quá trình sử dụng Figma. Link bài này có vẻ bị sai hết rồi, Huy ơi. Nếu Huy có ở đây thì xem lại và sửa giúp phần link cho đúng nhé. Em có thể post lại đường link của những người đã đăng bài trước đó để mọi người tiện theo dõi. Hình như có ba cái link bị sai rồi, em sửa lại nhé.\n\n**29:12** Còn về YouTube thì không có, nhưng Discord thì có. Đúng rồi, React 19 và hệ thống log cho developer bằng Go đã được đăng ký. Cái này là hệ thống log system viết bằng Go, có tích hợp với Relay App. Hôm qua đã có một bạn đăng ký thử, nhưng có vẻ là nhầm link. Sáng hôm qua có một bạn post về Data Engineering cho Python, nhưng đây là giải pháp dành cho thay thế Python thôi. Còn hệ thống của anh thì vẫn đang sử dụng Shell Script, không phải Python.\n\n**30:38** Inno cũng có một bài rất hay về bản quyền của OpenAI. Đây là tin tức trong tuần qua, mọi người có thể xem qua các bài báo cáo của Tom. Những bài báo cáo của Tô đã tổng hợp lại nhiều thông tin quan trọng trong tuần này. Ba người đã đăng link lại rồi, Tô có thể giúp post lại các bài đó không? Những bài đó đều nằm trên Facebook của chúng ta. Mọi người có thể vào xem lại, và kéo view cho các bài đó để giúp tăng tương tác. Đặc biệt, bài của Huy mới post hôm qua có hình ảnh rất đẹp và gọn gàng hơn rất nhiều so với trước.\n\n**32:48** Để mình xem mọi người đã thấy màn hình chưa? Tuần này cũng không có quá nhiều thông tin, chỉ có hai bài chính thôi. Bài đầu tiên là Script, đây là một tool cho phép viết các script trong chương trình Go. Cách sử dụng nó cũng khá đơn giản, ví dụ như đọc một file thành chuỗi (string), hay đếm các dòng khớp với một mẫu nào đó. Thậm chí chúng ta có thể nhúng (embed) các hàm Go vào trong nó luôn. Công cụ này khá là mới, và nó cung cấp rất nhiều tính năng tùy chỉnh. Có thể gọi request HTTP, hoặc thậm chí là custom các hàm của chính mình.\n\n**33:40** Ví dụ như đoạn script bên dưới cho phép đọc một file và đếm các dòng khớp với một chuỗi ký tự nhất định. Ngoài ra, nó còn hỗ trợ việc nhúng các function của Go vào trong script đó. Đây là một công cụ mới, giống như công cụ Jam mà mọi người đã biết trước đây, nhưng Jam chỉ là công cụ cho việc viết các shell script đơn giản. Còn công cụ này không tập trung vào UI, nó chỉ chủ yếu là API.\n\n**34:28** Công cụ thứ hai là về Go CH, bắt đầu từ bản 1.23, chúng ta có thể bật hoặc tắt (toggle) telemetry. Telemetry là việc thu thập dữ liệu sử dụng của ứng dụng, ví dụ như app của chúng ta đang hoạt động thế nào, có bị crash hay không. Dữ liệu này sẽ được gửi về cho team Go, để họ có thể theo dõi và cải thiện. Nếu mọi người follow kênh Slack của Go thì có thể thấy một số lỗi được phát hiện nhờ vào telemetry này. Với bản 1.23, chúng ta có thể tắt nó đi hoặc giữ mặc định là chỉ gửi dữ liệu local, không gửi lên server.\n\n**35:08** Nếu mọi người tham gia kênh Slack của Go thì sẽ thấy rằng có một số lỗi đã được pop-up nhờ vào dữ liệu từ telemetry này. Do đó, từ bản 1.23 trở đi, mọi người có thể bật hoặc tắt nó, hoặc nếu không muốn gửi dữ liệu đi, có thể chỉ giữ lại ở chế độ local. Bài này của tuần này chỉ có vậy thôi.\n\n**35:54** Phát có một câu hỏi, cái code này có phải là hệ thống mà Huy đã set up cho mấy dự án của mình không? Em không biết nữa. Cái Huy set up là gì vậy, có phải là hệ thống error reporting không? Ừ, đúng rồi, error reporting. Nhưng hệ thống error bot này là một công cụ của Go team, nó sẽ gửi các báo cáo lỗi thẳng về cho team Go. Mục đích chính là để cải thiện Go, xem xem nó có lỗi gì hay không.\n\n**36:36** Nó bắt được các bug trong ngôn ngữ lập trình Go, đặc biệt là khi chương trình bị crash hoặc khi các công cụ bên ngoài như Go Please hay Go RoboCheck gặp lỗi. Nó sẽ gửi báo cáo lỗi về cho team Go để họ có thể nắm bắt và sửa lỗi. Hệ thống này chỉ là một tool cho team Go, nó không phải là công cụ chung để mọi người dùng đâu.\n\n**37:24** Phát có hỏi rằng có nên enable (kích hoạt) hệ thống này không? Nếu kích hoạt, chúng ta sẽ gửi một lượng dữ liệu nhỏ về cho server của Go. Tuy nhiên, em nghĩ lượng dữ liệu này rất nhỏ, chỉ là các file về hiệu suất hoạt động thôi. Nó cũng sẽ tích hợp với hệ thống profile guided optimization của Go mà em đã nói lần trước. Những dữ liệu này sẽ giúp cải thiện hiệu suất của ứng dụng mà không tốn quá nhiều chi phí.\n\n**38:08** Phần dữ liệu này chủ yếu là file hiệu suất, thường chỉ là một vài file nhỏ thôi. Nếu mọi người không muốn gửi dữ liệu đi, có thể tắt hoàn toàn hệ thống telemetry này. Trong môi trường production, chúng ta có thể set nó ở chế độ local để không gửi gì cả.\n\n**38:51** Hệ thống profile mà Phát nói lần trước là build một lần và sau đó đo lại hiệu suất trong những lần build sau. Nó sẽ kiểm tra xem hiệu suất cải thiện như thế nào so với lần build trước. Cảm ơn Phát đã chia sẻ thông tin. Hằng có thể tổng hợp lại những phần báo cáo của tháng trước không? Nhất là những phần quan trọng về hiệu suất của hệ thống trong tháng vừa rồi.\n\n**40:10** Mọi người có thể thấy rằng lượng thông tin khá lớn, nhưng chắc là mọi người cũng đã nắm được. Hệ thống Wind mới cũng đã có một số cải tiến đáng kể. Còn về vấn đề lỗi thì chắc là sẽ phải xử lý thêm. Cái của Quân Lê đã hoàn thành chưa? Đúng rồi, đã thấy rồi, nhưng hình như còn thiếu một số file cuối cùng. Hằng có thể tổng hợp lại cho team để hoàn thành báo cáo không?\n\n**41:43** Nhìn vào những công cụ AI mới trong tháng vừa rồi, có một số sự phát triển đáng chú ý, đặc biệt là công cụ CR 3.5 và Sonnet. Trước đây, chúng ta đã thấy demo về chức năng của chúng, nhưng bây giờ chúng đã đi vào thực tế, không chỉ là demo nữa. Một số team đã bắt đầu sử dụng chúng để phát triển ứng dụng. Công cụ CR 3.5 Sonnet này cũng đã được Amazon thử nghiệm cho việc nâng cấp hệ thống Java lên phiên bản mới hơn.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/wED1g78PEn0?si=B7F-sKuHfX5_3AcW&amp;start=2461\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**43:12** Theo một báo cáo chưa xác thực, công cụ này có thể xử lý khoảng 80-90% công việc trong quá trình nâng cấp hệ thống, và chi phí tiết kiệm được là khá lớn. Đây là một dấu hiệu cho thấy các công cụ AI đã bắt đầu tham gia vào quá trình phát triển phần mềm một cách thực tế hơn. Ngoài ra, các chatbot hay công cụ AI khác cũng đang có xu hướng thêm những chức năng như artifact, cho phép chúng compile các đoạn mã nhận từ người dùng và tạo ra các mini app trong môi trường chat.\n\n**44:42** Ví dụ, với CR 3.5 Sonnet, có một form cho phép người dùng tính toán chi phí xây dựng, và khi nhập dữ liệu vào, hệ thống sẽ generate ra một đoạn mã HTML và tạo ra một ứng dụng web nhỏ để xử lý dữ liệu đó. Trước đây, việc này chỉ liên quan đến UI, nhưng bây giờ nó đã phát triển thành khả năng tạo ra các ứng dụng mini ngay trong giao diện chat. Tô có thể demo đoạn này cho mọi người xem sau.\n\n**45:28** Bên cạnh đó, hệ thống ping của Cross cũng đang được phát triển, giúp tiết kiệm tài nguyên bằng cách giảm bớt việc request lại phần code đã submit trước đó. Chức năng này giúp giảm độ trễ (latency) và cải thiện tốc độ xử lý.\n\n**46:16** Một điểm đáng chú ý khác là model TT4 của OpenAI đã bắt đầu hỗ trợ chức năng sure output, đảm bảo rằng output cuối cùng luôn đúng với schema đã định trước. Trước đây, việc này phụ thuộc rất nhiều vào việc định nghĩa schema từ đầu, nhưng bây giờ hệ thống sẽ tự động kiểm tra và đảm bảo rằng output cuối cùng luôn đúng. Điều này rất hữu ích trong những hệ thống phụ thuộc nhiều vào schema và có tỷ lệ lỗi cao.\n\n**47:31**  Ví dụ như ở đây, nếu mình phát triển một ứng dụng mà kiểu dạng như vậy, nó sẽ liên quan đến rất nhiều yếu tố, như là phải kiểm tra chính xác các phần tử selector trong source. Chẳng hạn như mình phải input đúng selector của nó là gì, selector của link này ra sao, title của link này là gì. Để mà có thể scan đúng được tất cả các link đó. Thực ra mỗi trang web sẽ có một cấu trúc khác nhau, làm sao để có một giải pháp tổng thể? Thực tế, AI có thể giúp mình hiểu được cấu trúc HTML của trang web đó, hiểu được cách nó bố trí các phần tử. Và đây là một công cụ nhỏ nhỏ, hỗ trợ việc này. Nhưng mà mình sẽ cần phải đảm bảo rằng output cuối cùng của nó luôn luôn là danh sách các link mà mình scan được.\n\nHồi trước, để làm được việc này thì sẽ cần rất nhiều bước liên quan đến việc ping các thứ. Nhưng bây giờ, với AI, chúng ta có thể define sẵn schema ở đây. Trong Visual Studio Code chẳng hạn, anh em có thể định nghĩa schema trước, và đảm bảo rằng output cuối cùng sẽ luôn luôn có đầy đủ title, luôn có đầy đủ link, và luôn có phần mô tả (description). Điều này sẽ đảm bảo rằng khi chúng ta quét các link, mọi thứ sẽ chính xác. Đây là một ví dụ về output khi chúng ta quét các link từ Lobs, hoặc một trang web tương tự.\n\n**48:44** Điều này là một update khá quan trọng trong giai đoạn vừa qua mà mọi người nên biết. Ngoài ra, DVT4 cũng hỗ trợ việc tinh chỉnh file, tức là chúng ta có thể fine-tune model dựa trên dữ liệu cá nhân. Điều này rất hữu ích khi mình muốn train AI trên các bộ dữ liệu riêng của mình để phục vụ cho mục đích cụ thể nào đó. Hiện tại, tính năng này đã được cung cấp và có thể sử dụng. Bên cạnh đó, có thêm một module mới liên quan đến việc xử lý hình ảnh (image processing) cũng như flagging, và một số tính năng khác, chắc là mọi người đã xem qua rồi.\n\n**49:27** Ngoài ra, còn có một cập nhật liên quan đến phần UI, hiện tại team mình đang rất hứng thú với công cụ V0. Đây là một tool mới, giúp generate ra các phần UI dựa trên prompt (lời nhắc). Kết quả ban đầu từ tool này khá là sát với kỳ vọng của team mình. Nhiều team đã bắt đầu sử dụng nó để build các mini app. Điều đáng chú ý là V0 hiện đang được train với hai framework chính, đó là Svelte và TailwindCSS. Công cụ này đã có trên thị trường một thời gian rồi, và team mình đã dùng nó khoảng một năm nay. Các team khác cũng đã bắt đầu tích hợp nó vào quy trình của họ.\n\n**50:22** V0 có ưu điểm là kích thước thư viện rất nhỏ. Nó dựa trên Svelte UI và kết hợp với TailwindCSS, nên việc tùy chỉnh UI và các component rất dễ dàng. Sự kết hợp giữa hai công nghệ này đã giúp V0 trở thành một lựa chọn rất được ưa chuộng trong việc prototyping (tạo mẫu) các component UI. Chúng ta kỳ vọng rằng trong tương lai gần, V0 sẽ chiếm lĩnh thị phần của các thư viện lớn như Material UI hay Ant Design.\n\n**51:10** Trong tháng vừa rồi, có một số cập nhật như vậy về công cụ và các tính năng mới. Không biết mọi người có câu hỏi nào không? Về tổng thể, tháng này các bản tin vẫn chủ yếu xoay quanh những chủ đề tactical (chiến thuật) về việc nâng cấp hệ thống và các công cụ đang trending mà các bên lớn như Amazon và Google đang phát triển. Hiện tại thì chưa có nhiều tin tức về các sản phẩm mới hay công nghệ hoàn toàn đột phá, nhưng chúng ta cũng đã thấy những bước tiến nhất định.\n\n**51:59** Những tin tức gần đây bắt đầu có dấu hiệu về sự tích hợp sâu hơn của các hệ thống AI vào ứng dụng thực tế. Ví dụ như Apple đang tích hợp trực tiếp các công cụ AI vào hệ thống, hoặc Amazon đã gỡ bỏ Alexa để thay thế bằng AI cloud-based (dựa trên đám mây). Không biết sắp tới sẽ có những thay đổi như thế nào, nhưng xu hướng rõ ràng là các doanh nghiệp lớn đang dần dần đưa AI vào quy trình của họ một cách toàn diện hơn.\n\n**53:01** Ngày hôm qua, khi team mình kiểm tra email, Google cũng đã gửi thông báo về việc muốn enable AI cho team này hay không. Họ đang cung cấp dịch vụ với mức giá khoảng 15 đô la/người, có những gói giá khác nhau nhưng nhìn chung là khá đắt. Mình thì chỉ xài AI ở mức độ vừa phải thôi, không quá nhiều.\n\n**53:49** Tuy nhiên, chúng ta có thể mong đợi rằng giá của các dịch vụ AI sẽ giảm dần theo thời gian, giống như lần trước có một bài báo cáo cho thấy chi phí sử dụng GPT-3.5 năm ngoái là khoảng 32 đô la, nhưng năm nay khi sử dụng GPT-4 thì giá đã giảm gần một nửa. Số lượng token (đơn vị tính toán) cũng ngày càng tăng, dẫn đến việc giá thành giảm xuống. Có lẽ trong tương lai gần, những phương pháp cũ như RNN (Recurrent Neural Networks) sẽ dần trở nên lỗi thời, và AI sẽ ngày càng phổ cập hơn.\n\n**54:34** Bên phía Tony Dinh cũng đang phát triển một hệ thống tương tự với công cụ mà chúng ta đang dùng, nhưng tốc độ của họ không nhanh bằng, nên khả năng họ sẽ không cạnh tranh nổi. Họ đang bán một công cụ tên là TimingMind, một hệ thống giúp các doanh nghiệp tự sử dụng dữ liệu của mình để phát triển các công cụ AI nội bộ. Mục tiêu của họ là đưa toàn bộ hệ thống Office, các công cụ làm việc, và các dịch vụ hỗ trợ đi kèm với AI.\n\n**55:44** Điều thú vị là hiện tại, họ đang chạy đua với tốc độ phổ cập AI, bán ra thị trường những gì có thể bán ngay bây giờ. Về lâu dài, AI sẽ trở thành một phần không thể thiếu trong các sản phẩm phần mềm, giống như ngành công nghiệp phần mềm thông thường, với những yêu cầu ngày càng cao về chi phí, hiệu suất và dịch vụ khách hàng.\n\n**56:48** Team Google cũng có một dịch vụ hỗ trợ khách hàng rất chuyên nghiệp, họ dùng cả AI để tương tác với khách hàng. Khá ấn tượng khi họ sử dụng AI của chính họ để làm việc này, và kết quả là rất trơn tru, không khác gì nói chuyện với một người thật. Được rồi, chúng ta sẽ xin cái link kia để mọi người có thể xem và tiếp tục thảo luận.\n\n**57:37** chắc nhờ Phát lên pair program với em. Thật sự là hôm nay mình sẽ làm một cái workflow chung với Phát. Thật sự thì em gần như làm hết, nhưng sẽ đưa ra một cái hướng suy nghĩ về lập trình cái app kiểu này. Bên phía anh Thành cũng có đề cập rằng mình muốn tạo ra nhiều cái app viết trên cloud, mình có thể viết ra rất nhiều app khá là xịn đấy. Hôm nay thì mình sẽ chơi Dify, nghĩa là hôm nay sẽ có một cái Plan và Plan là thay thế Phát, tự cho mọi người viết được app kiểu như vậy.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/wED1g78PEn0?si=-WbmpDSPizo0PBRS&amp;start=3501\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**58:23** Go commentary, thì ban đầu bên phía em sẽ có một cái Plan là tạo system prompt nhờ AI, tạo system prompt thêm và gán input. Input ở đây là link, output là bài viết và note. Ở đây thì cần thiết một cái agent để lấy link, sau đó là từ cái này thì sẽ summarize link, format lại, note lại. Đây là suy nghĩ từ bên phía em trước khi bắt đầu đoạn work. Mình sẽ chơi luôn, cho mọi người nhìn lại cái cấu trúc này. Tức là làm một cái bài Go commentary hả? Dạ, đúng rồi. Copy toàn bộ cái này luôn, tức là làm Go commentary thay cho Phát. Yeah, thì thay thế được mà.\n\n**59:22** Mình sẽ cần AI để tạo ra system prompt như vậy. Em đã tạo một chatbot, đúng ra là có thể dùng CL nhưng mình đang dùng library chat để tạo cho AI Club rồi. Hôm nay thì nó sẽ là: \"Help me create a system prompt to format note in Markdown format with the following style...\" Sau đó, code của phần này sẽ lấy input là một loạt các link và những commentary. Mong muốn output sẽ là một bài viết Markdown với các note về code, những nugget kiến thức, và một loạt các điểm mà chúng ta có thể rút ra từ những thay đổi. Mục đích của note này là để tìm hiểu những điều mới về Go và tổng hợp các tin tức xung quanh nó. Hãy viết system prompt riêng biệt để tạo ra bài viết như vậy.\n\n**01:00:38** Ok, đoạn này là mô tả input là gì, output là gì, mục đích là gì. Cuối cùng là tạo prompt cho nó đúng không? Dạ, đúng rồi. Được rồi. Có Phát ở đây luôn à? Hay đấy. Ok, thử xem có nghĩ ra gì chưa... Chưa kỹ lắm, nhưng không sao. Mình có một cái system prompt đó là mình sẽ tạo một cái agent thực sự. Mình có thể tạo ra một workflow hoặc là chat flow, đơn giản hóa là mình muốn một cái tool cho Go để thay thế Phát, một agent để thay thế Phát. Tạm biệt Phát nhé. Ok, sau đó mình sẽ có tool rồi.\n\n**01:01:53** Mình đã cài đặt sẵn một số tool cho team, bên phía anh Thành cũng có mention về GReader, đây là một cái tool giúp mình lấy thông tin từ mạng. Mình có tool này rồi, chắc mình sẽ lấy thông tin và chơi CL luôn, cho xịn. Được rồi, publish tạm trước đã, sau đó mình sẽ kéo các link vào. Chơi link của commentary mới nhất đi, commentary mới nhất là gì nhỉ? Đây rồi, ba cái CC này đúng không? Đang dùng GReader đúng không T? Dạ, GReader là tool kéo thông tin từ mạng, nhưng mà cái prompt để em điều khiển nó là gì? Hay là chỉ cần quăng link vào?\n\n**01:02:52** Prompt là nhờ AI tạo cho mình rồi, như hồi nãy đúng không? Dạ, đúng rồi. Output là format bài viết của Phát, bao gồm nội dung cần thiết, code cần thiết, chi tiết đầy đủ, và có cả kết luận nữa. Cái này còn sâu hơn vì Phát thường không viết kết luận, nhưng mình có thể hình dung rằng AI agent sẽ lấy thông tin từ mạng, script nó, rồi đưa vào context của AI. Sau đó, AI sẽ dùng system prompt để tạo ra bài viết của Phát. Xem cái format này có giống không?\n\n**01:04:00** So sánh thử xem.  Nhưng mình sẽ bỏ phần trên đi. Anh thử bật toc preview lên, xem nội dung nào ok. Có vẻ nội dung hơi nhiều quá, chắc phải lược bớt. Nếu muốn đi sâu hơn về code thì có thể nhờ AI chỉnh sửa code luôn. Ví dụ như đưa cái output đó cho chatbot. Đây là một ví dụ về output từ system prompt, thử làm cho nó ngắn gọn hơn, tập trung vào những điểm chính liên quan đến code.\n\n**01:06:02** Chắc là hiểu sai prompt rồi. Không sao, dùng lại và recreate system prompt với những ý định đó. Thử lại lần nữa, giới thiệu lại cái link đó. Đây rồi, quá dễ, không tưởng tượng là bài của Phát dễ replicate như vậy. Ok, chắc bỏ cái này đi. Đọc thử xem nội dung thế nào. Nhưng chắc cần chỉnh sửa thêm. Hiện tại nó cover chính về telemetry, nhưng cái code kia chắc phải đi sâu hơn chút. Nhưng idea thì nó là như vậy thôi.\n\n**01:08:26** Cách làm là từ cái plan của mình, có input, có mục đích của output là gì, và output mình muốn gần giống thế nào. Sau đó nhờ AI nó tự suy ra. Nó tạo ra bài viết giống bài của Phát. Thử thêm một câu nữa: Với kiểu này, anh muốn xài cái tone của thằng David Ruby. Đúng rồi, lấy danh sách các bài viết mới nhất của David Ruby, dùng phong cách viết technical của anh ta để viết lại phần commentary, xem thử output như thế nào.\n\n**01:09:07** Đúng rồi, lấy luôn. Có thể nó sẽ nhiều hơn một chút, anh không biết bài nào chuẩn nữa. Ok, chờ luôn. Hoàn hảo rồi, bây giờ tối ưu hóa tone cho nó giống David Ruby. Đây là một ví dụ bài viết với tone của anh ta. Update system prompt để refactor lại giọng văn của David. Đây rồi, easy, game này dễ rồi. Thử làm lại xem nào. Hình như bài viết hơi bị bớt đi chút.\n\n**01:11:55** Thỉnh thoảng nó có stop character xuất hiện. Chắc bị bug rồi. Nó biết là mình copy của người khác nên có thể liên quan đến copyright. Đây, bài này nói cái gì vậy? Ai biết đâu, thử mở xem. Chắc bị lỗi format, nhưng không sao, cứ chơi luôn. Ok, bỏ cái này đi, bật preview luôn. Gần xong rồi, nhưng chắc cần điều chỉnh thêm. Ok, phần này không có mấy keyword của David, có vẻ nó hơi đi chệch, nhưng không sao.\n\n**01:13:34** Chắc do CL nó có filter keyword để tránh vi phạm bản quyền. Nó bỏ bớt một số keyword, nên chỉ nghe hơi giống thôi, chứ không hoàn toàn. Vấn đề này chắc không phải do thiếu sample mà là do system của CL nó xử lý khác. Đúng rồi, thôi bỏ qua cái này đi, cứ up cái mới. Sau đó cho một đoạn kết luận để xem.\n\n**01:17:31** Ý tưởng là nếu có một agent có thể quét toàn bộ code, tới cuối tuần mình sẽ không cần viết báo cáo nữa. Ai đó chỉ cần review và thêm vào vài điểm thôi, rồi gửi báo cáo cho team. Như vậy dễ hơn rất nhiều. Thử với một hai iteration nữa thì chắc là ổn rồi. Xem lại một lần nữa xem. Đây, phần giữa có vẻ ok hơn. Nhìn vào bài này khá dễ đọc đúng không?\n\n**01:18:37** Đúng rồi, tầm 85-90% giống với phong cách của David rồi. Chắc thêm một hai bài sample nữa thì sẽ ra được system prompt tốt. Ý tưởng là như vậy thôi, cuối cùng mình có thể sử dụng nó để tạo ra các bài viết mà không cần chỉnh sửa nhiều. Trước đây, OGIF community call không quan tâm nhiều đến system prompt, mà chủ yếu quan tâm đến output thôi. Vậy thì mình cứ chơi với output, đảm bảo nó đúng là được. Output ra thế nào thì kiểm tra cho đến khi nào mình thấy nó giống thì thôi.\n\n**01:19:16** Chắc là mất khoảng 70-90% thì sẽ đạt. Vậy thì cứ clone lại giọng văn của Phát, xem thử agent có thể quét các bài viết mới nhất không. Nếu có thể chọn được đúng link phản ánh được hướng đi của thị trường, thì có thể tạo ra một cơ sở dữ liệu khác để theo dõi các thay đổi.\n\n**01:20:11** Cái này mình có thể làm với API, gắn trên Dify. Thực ra mình đã tạo API rồi, bên phía Dify là một cái tool để kéo thông tin từ các link thú vị. Sau đó mình lọc các thứ liên quan đến Go, gửi link đó cho AI agent để nó viết lại. Cuối cùng nhờ Phát review, thêm ảnh là xong. Thực ra mình có thể nhờ AI tìm ảnh và so sánh xem có ổn không, nếu ổn thì để trên bài luôn. Step đó hơi rườm rà nhưng làm được. Ok, chắc để sau. Khi làm xong rồi thì Phát không cần viết Go commentary nữa, chỉ cần quản lý thôi.\n\n**01:21:29** Nếu vậy thì tuần sau mình thử tiếp nhé. Hoặc là thử viết một agent để load bài viết hàng tuần cho team, tiết kiệm thời gian viết báo cáo.\n\n**01:22:18** Nếu mình feed đầy đủ context cho nó thì nó sẽ giữ được format consistent và output sẽ đúng yêu cầu. Thử với dự án thật, lấy thông tin từ Discord, quản lý task và cả những phần thảo luận. Được không?\n\n**01:24:01** Dễ mà, lần trước em đã giải thích về Spatio-temporal reasoning rồi. Cái này liên quan đến không gian và thời gian trong dự án thôi. Chắc là không cần standup meeting nữa. Tuần sau thử nhé, mình sẽ test thử với toàn bộ hệ thống của team.\n\n**01:25:09** Ok, có vẻ không ai có câu hỏi gì thêm. Nếu mình hoàn thiện được cái này thì có thể tự động hóa được nhiều thứ hơn nữa, ngồi thiết kế thôi, agent sẽ chạy. Mọi người cứ thế mà nhận đề bài.\n\n**01:26:05** Thầy vừa hỏi về con CloudZ system prompt thông qua một vài giao diện UI. So sánh giữa lib chat và tool này. Thực ra giống nhau thôi, prop kỹ thì input output giống nhau, chỉ khác là một cái chạy trên cloud, một cái trên local.\n\n**01:26:05 N**ói chung là hơi giống nhau thôi, vì nếu nó giống nhau là do mình prop rất kỹ, mình prop kỹ về input, output. À đâu rồi, input, output và mục đích của cái output là gì thôi. Vì sao bên phía một số người online thấy AI có vẻ \"ngu,\" nhưng thực sự là em chưa bao giờ thấy nó ngu cả, bởi vì prompt mà em đưa cho bên phía Cloud nó đầy đủ hết. Miễn là mình có thông tin đầy đủ thì dù mình để trên cloud hay trên console, hoặc trên lib chat, nó cũng như nhau thôi.\n\n**01:26:41** Ý tôi là mấy anh em khác thấy AI ngu là do prompt của họ chưa tốt thôi đúng không? Dạ dạ. Anh Văn có một điểm là iOS 8.0 mới được, nhưng mà sử dụng GPT-4 thì sao, có ổn hơn không? Tí nữa trong đề xuất, nó có chuyện zoom ấy. GPT-4 thì em có thử rồi, nếu nói về nội dung viết bài thì được, nhưng liên quan đến deduction, toán học, hoặc category series thì nó không tốt bằng. Không biết tại sao, chắc là không được train kỹ về lý thuyết toán học, kiểu như Theory of Mathematics, nó không có đủ thông tin.\n\n**01:27:35** Những ai đam mê toán sẽ biết ngay là GPT-4 không có nhiều dữ liệu về đó. Hiểu sơ sơ vậy thôi, nhưng thiếu data đó thì khi tạo system prompt liên quan đến toán học kỹ hơn, nó không làm được. Nhưng CL thì lại xịn hơn ở chỗ đó. Ok, Thành ơi, vậy thật ra bây giờ là làm sao để trong thời đại mà ai cũng có thể sử dụng AI dễ dàng, mình phải biết cách build cái set agent của mình trước. Tất cả anh em nào có khả năng build agent thì dễ rồi, nhưng dùng cái đó để làm tiếp, để maintain nó và áp dụng vào bài toán thì mới là cái chính.\n\n**01:28:14** Trong ngắn hạn, đó là cái mà mình nên làm trước khi các team khác đuổi kịp. Nghe như bây giờ, automation nhanh lắm, kiểu visual hết trên mấy tool như Defile. Nhưng về khía cạnh công ty, các công ty khác vẫn còn làm manual nhiều lắm. Nếu anh em mình thành power user của hệ thống này, mình có set agent để điều khiển thì sẽ di chuyển rất nhanh và chi phí ship software ra sẽ thấp hơn rất nhiều. \n\n**01:29:00** Ừ, để tí nữa tôi mua. Nhưng mà anh Tom quăng lên cái là chá rồi mà? Dạ, dạ. Cái này thì dùng tài khoản của em, em có setup sẵn tài khoản tạm cho team rồi. Nếu team dùng nhiều hơn thì sẽ mở rộng thêm. Không sao đâu. \n\n**01:29:42** Nhưng nếu dùng cái này cho team mình thì tốt quá. Phải build set agent của mình cho các công việc hiện tại, rồi từ từ biến mọi người thành power user. Sau đó là ship những cái software khác có thời gian đào tạo thêm. Dạ, đúng là lộ trình phù hợp để nâng cấp team. Dạ dạ.\n\n**01:30:37** Nhưng ví dụ, ngoài chuyện làm cho dự án thì mình cũng có thể optimize mấy cái kiểu chỉnh sửa bên phía chat hoặc bên phía open source. Nhờ AI sẽ làm hết. Đây là AI 100%, chạy trên cloud. Còn description thì mình không rõ lắm. Cái này là feature mới à? Feature mới này liên quan đến artifact. Hiện tại bên lib chat không hỗ trợ artifact. Ví dụ như mình share link này, share link của một cái code hoặc dự án, mở Private tab thì nó sẽ hiện artifact cho mình xem. Nhưng nhiều loại file thì phải hỗ trợ từng loại một.\n\n**01:31:20** Cái này có code sẵn, dựa trên bài toán của ông đó. Lúc nó chạy Python hoặc React thì sẽ highlight và preview tương tự. Em có làm demo từ lúc không biết gì hết, xong rồi mất bao lâu để làm xong? Tóm lại là bao lâu? Ờ, một tiếng thôi, không đùa đâu. Một tiếng từ lúc đọc spec, hiểu code, sau đó chỉnh sửa design, sửa code và phần backend còn lại. Tổng cộng khoảng 2 đô, dưới 3 đô thôi.\n\n**01:33:10** Cái này phải build ra một cái docker container, sau đó deploy trên server. Build lâu hơn code luôn. Vậy là chỉ mất 2 phút giới thiệu cái chatbot cho mọi người là đủ? Cần invite mọi người vào luôn nhỉ. Dạ, dạ. Anh coi phần của team rồi cấp tài khoản cho team là xong. Chắc em sẽ giải thích về lib chat: nó là clone của GPT nhưng cho phép mình chọn model, hiện tại hỗ trợ API của OpenAI và Anthropic. Nếu muốn dùng model hack thì cứ gắn API key vào thôi. Mình có UI để tương tác với chatbot, dùng cả file R và PDF.\n\n**01:34:40** Sau này sẽ mở rộng cho team để track progress, kỹ năng lập trình AI, viết prompt. Cái này thực sự giúp cho việc lập trình nhanh hơn, có thể nhờ AI code luôn, nói chuyện với AI và nó hiểu ý mình, code hộ mình. Điểm hay của lib chat là có thể share link, ví dụ như mình đã nói ở trên. Ban đầu dùng Cloud nhưng Cloud không cho share link, nên ít nhất lib chat đảm bảo điều này. Cộng đồng lib chat cũng đã bắt đầu thừa nhận và pickup rồi. Star của dự án này bao nhiêu?\n\n**01:35:52** Cũng lâu rồi, con này chỉ là UI thôi. Cộng đồng ngoài Danny còn có Cris và một vài người khác. Nhưng gọi là cộng đồng thì hơi quá, chỉ là một nhóm đam mê thôi. Còn ai làm giống thế này không, để mình đảm bảo là quen rồi thì có thể tự triển khai được luôn? Có lẽ là l chat có nhiều hơn, nhưng lớn nhất vẫn là l chat và lib chat.\n\n**01:36:38** Vậy sao tôi không thấy con này nổi tiếng nhỉ? Nó double star à? Đúng rồi, nhưng chưa deploy rộng vì cần nhiều server, mà nhiều server thì nhiều tiền. Nên chi phí đó cứ claim cho anh Quang là được rồi. Ok, thử đi, có vẻ sẽ nhận được nhiều sự công nhận hơn. Về lâu dài thì có lợi đúng không? Dạ, đúng rồi. Nếu dùng để quản lý PDF thì cũng tốt, hoặc muốn xem artifact thì chuyển qua libre chat. Ok rồi, anh em còn có câu hỏi gì không?\n\n**01:38:33** Chắc không hỏi gì nữa. Tô với cả team chắc sẽ test lại để xem con này chạy tới mức nào. Mình sẽ tranh thủ tuần sau test với team để mọi người quen tay. Dự án khác có data source khác nhau, nên có thể sẽ phải tích hợp nhiều hệ thống như Slack, Notion, hoặc Jira, mỗi nơi một kiểu.\n\n**01:39:22** Notion với Slack thì dễ nhất, còn Jira thì hơi khó vì API của nó chưa tốt lắm. Chưa kể là thông tin dự án thì hay bị phụ thuộc vào PM, cũng khó để tóm tắt lại tất cả. Nhưng đủ thông tin rồi thì chắc không cần thêm gì nhiều nữa. Rồi, ok. Chắc mình kết thúc ở đây nhé. Hôm nay rất thú vị. Ok, cảm ơn Tom và mọi người. Hẹn gặp lại phần sau nhé!\n\n---\n\n**English Transcript**\n\n**00:00** Alright, everyone is here, do we need anyone else, Tom? Anyone else to join? Can’t hear you. Ah, yeah, I’ll team up with Phát later on this. But do we need anyone else from the audience? Do we? It depends, we don’t really need anyone besides the people in the AI Club. Okay, so we’re good? We’re good, let’s gather everyone slowly and wait a bit more.\n\n**15:44** So today, we have three main topics. First, the market report from Thành, then Phát’s part, which should be quick. The remaining time is for Tom. Looks like we still have plenty of time. Mỹ also has a lot to share, so if we run out of time, just post your stuff, Mỹ, and everyone can check it later. Mỹ, have you posted yet? Can everyone see the screen? Yeah, is the sound a bit low? Hang on, let me grab my phone. Hello, can you hear me now? Okay, we’re good now. Let’s get started. The first part is about BT.\n\n**17:39** Aside from last week’s numbers, I’ll go through some key updates. First, starting next week, our team will implement two things. First, we’re enabling hybrid working. I’ll send a detailed link later, but right now, it’s mainly a walkthrough. The office has been revamped for those who find working from home too noisy or distracting. After the renovation…\n\n**18:31** Currently, there are about five people using the office, and there’s space for about ten more. When you come here, we’ll cover the cost of using the Apple Studio Display, and we’ve fully equipped the office with Herman Miller chairs. If you’re unfamiliar with these chairs, you can Google them to learn more. Meeting rooms and other facilities have also been significantly improved. If anyone feels bored or uncomfortable working at home, they can consider coming to the office to work for one or two days a week. This is optional, not mandatory.\n\n**19:48** But the team hopes everyone starts adjusting their work to gain essential benefits from working together at the office. This will help strengthen social relationships, especially during this period when there’s a large volume of knowledge and research to process. Working together will help speed things up, particularly as we approach the final stages of projects.\n\n**20:28** Additionally, all parking and dinner costs will be covered. This is the main announcement, and Mỹ will write up a detailed notice for everyone soon. That’s the first announcement, and I think it’s something everyone will be interested in. The second announcement is about testing a new feature: Daily check-in. For those participating in Daily check-in, during the first two weeks, each check-in will reward you with about 3 to 5 ICY.\n\n**22:29** That’s right, you’ll earn ICY daily. But in the initial phase, we’ll run it as a two-week trial to see how the feature works. Since office space is limited, we’ll prioritize those starting hybrid working, and if there’s leftover space, we’ll transition more people to remote work. We’re trying to bring the office environment to its best possible state for productivity.\n\n**23:24** Because, in reality, office space is limited, the priority is encouraging those who want to come to the office a few days a week if they find working from home ineffective. If, after one or two weeks, everyone feels it’s working well, you can personalize your workspace, bringing personal items to make it more comfortable.\n\n**24:04** Where does the Hanoi team check-in? Yeah, I’ve already brought my personal cabinet and some Lego sets from my kid to the office. So those are the two main announcements. Hopefully, everyone will consider and start testing it out. We’re trying to restore the physical working culture, with hybrid working days of 1-2 days a week depending on how everyone feels.\n\n**25:15** Everyone will find that coming to the office will help foster more personal connections. You can come for half a day or a full day, depending on how you feel. Okay, that wraps up the important stuff. Now, I’ll hand the stage over to Thành to continue with the market report.\n\n**26:08** Now, let’s go over some noteworthy articles from the past week. The top 20 articles our team read include the transition from DynamoDB to MySQL, and there was an interesting article about Neil that supported the research on Debox. Yesterday, people were discussing Debox quite actively on the team tech channel. The discussion was recorded, and you can check it out. But some points about Debox were unclear—it’s just a development box environment, not a deployment environment like containers.\n\n**27:11** Debox is just a box for development environments, not for deployment like containers. In essence, we still need both environments because they don’t replace each other. On development environments, especially for M1 users, Debox installs a VM layer on the M1 machine to run the container. This is because Debox can’t run natively on M1, so it needs a VM as an intermediary layer. The solution NX team uses is Linux on VM, installed directly on the machine without a middle layer like other systems. That’s why this system works well on M1 machines.\n\n**27:47** The next article is about Accessibility Design in Figma. The links for this article seem to be broken, Huy, can you check and fix them? Could you repost the correct links for the articles that people posted earlier? It looks like three links are broken, please fix those.\n\n**29:12** As for YouTube, we don’t have any updates, but we do have updates on Discord. That’s right, React 19 and a logging system written in Go have been registered. This logging system is integrated with Relay App. Yesterday, someone registered for a demo, but it seems like they used the wrong link. Someone also posted about Data Engineering for Python, but that’s more of a replacement for Python. My system still uses Shell Script, not Python.\n\n**30:38** Inno also posted a good article about OpenAI and copyright. That’s the news for the past week, and everyone can check out Tom’s reports. Tom’s reports have gathered a lot of key information this week. Three people have reposted links already—Tom, can you help post those articles again? They’re on our Facebook page. Everyone can check them out and increase engagement. Especially, the article Huy posted yesterday had some very neat and clean images, much more refined than before.\n\n**32:48** Let’s see, can everyone see the screen? This week doesn’t have too much going on, only two main articles. The first one is about Script, a tool that allows you to write scripts in your Go program. It’s pretty straightforward to use, for example, you can read a file as a string, or count the lines that match a pattern. You can even embed Go functions into it. This tool is pretty new, and it offers a lot of customization features. You can make HTTP requests, or even customize your own functions.\n\n**33:40** For example, the script below allows you to read a file and count the lines that match a certain string. Additionally, it supports embedding Go functions into the script. This is a new tool, similar to the Jam tool that some of you may know, but Jam is more for writing simple shell scripts. This tool doesn’t focus on UI, it’s mostly API-based.\n\n**34:28** The second tool is about Go CH. Starting from version 1.23, you can toggle telemetry on or off. Telemetry is about collecting usage data from the app, for example, how the app is running, whether it crashes, etc. This data is sent to the Go team so they can monitor and improve Go. If you follow Go’s Slack channel, you may have seen some errors that were detected thanks to telemetry. With version 1.23, you can turn it off completely, or just leave it in local mode where it doesn’t send anything to the server.\n\n**35:08** If you’re in Go’s Slack channel, you’ll see that some errors have popped up thanks to the telemetry data. So starting from version 1.23, you can toggle it on or off, or keep it in local mode if you don’t want to send data out. That’s about it for this week’s article.\n\n**35:54** Phát had a question: is this code the system that Huy set up for our projects? I don’t know. Is it the error reporting system? Yeah, error reporting. But this error bot is a tool by the Go team, it sends error reports directly to the Go team. The main purpose is just to improve Go by detecting any issues.\n\n**36:36** It captures bugs in the Go programming language, especially when the program crashes or when external tools like Go Please or Go RoboCheck encounter errors. It sends the error report directly to the Go team so they can catch and fix it. This system is just a tool for the Go team, it’s not a general-purpose tool for everyone to use.\n\n**37:24** Phát asked whether we should enable this system. If enabled, we’ll be sending a small amount of data to the Go servers. However, I think it’s very small, just performance files. It also integrates with the profile-guided optimization system in Go that I mentioned last time. These files help improve the app’s performance without costing much.\n\n**38:08** This data is mainly performance files, usually just a few files. If you don’t want to send any data, you can turn telemetry off completely. In production environments, we can set it to local mode so that nothing is sent out.\n\n**38:51** The profile system that Phát mentioned last time is built once, and then it measures performance in subsequent builds. It checks how performance improves compared to the previous build. Thanks, Phát, for sharing that. Hằng, can you summarize the reports from last month, especially the key parts about system performance over the past month?\n\n**40:10** Everyone can see that there’s quite a lot of information, but I think everyone has already grasped it. The new Wind system also has some significant improvements. As for errors, we’ll need to address those further. Has Quân Lê finished his part? Yes, it’s done, but I think we’re still missing some of the final files. Hằng, can you gather everything for the team to complete the report?\n\n**41:43** Looking at the new AI tools this past month, there’s been some notable development, especially with tools like CR 3.5 and Sonnet. We’ve seen demos of their functionality before, but now they’ve gone beyond just demos. Some teams have started using them to develop apps. The CR 3.5 Sonnet tool was also tested by Amazon for upgrading Java systems to newer versions.\n\n**43:12** According to an unverified report, this tool can handle about 80-90% of the work in upgrading systems, with significant cost savings. This is a sign that AI tools are starting to participate in software development more practically. Additionally, chatbots and other AI tools are now adding artifact-like features, allowing them to compile code snippets from user input and generate mini apps within chat environments.\n\n**44:42** For example, with CR 3.5 Sonnet, there’s a form that allows users to calculate building costs. When data is input, the system generates an HTML snippet and creates a small web app to process the data. In the past, this was purely UI-related, but now it’s evolved into the ability to generate mini apps directly within the chat interface. Tô might be able to demo this for everyone later.\n\n**45:28** Additionally, the ping system from Cross is being developed to save resources by reducing the need to re-request code that’s already been submitted. This feature helps reduce latency and improves processing speed.\n\n**46:16** Another notable point is that OpenAI’s TT4 model now supports sure output, ensuring that the final output always conforms to the pre-defined schema. Previously, this depended a lot on how well the schema was defined, but now the system automatically checks and ensures that the final output is always correct. This is especially useful for systems that rely heavily on schemas and have a high error rate.\n\n**47:31** For example, if we were developing an app like this, it would involve a lot of factors, like checking the correct selectors in the source. For instance, we need to input the correct selector for a link, know what its title is, and what its link is. To scan all the links correctly. Each website has a different structure, so how do we have a general solution? In reality, AI can help us understand the HTML structure of that website, understand how it organizes elements. And here’s a small tool to help with that. But we’ll need to ensure that the final output is always a list of links we’ve scanned.\n\nIn the past, doing this required many steps related to pinging. But now, with AI, we can define the schema in advance. In Visual Studio Code, for example, we can define the schema first, and ensure that the final output always includes the title, the link, and the description. This ensures that when we scan the links, everything will be correct. This is an example of the output when we scan links from Lobs or a similar website.\n\n**48:44** This is a fairly important update from the past period that everyone should know about. Additionally, DVT4 now supports fine-tuning files, meaning we can fine-tune models based on our own personal data. This is useful when we want to train AI on our specific data for certain purposes. This feature is now available and can be used. There’s also a new module related to image processing and flagging, and some other features that I’m sure everyone has seen.\n\n**49:27** Furthermore, there’s an update related to the UI, and our team is very excited about the V0 tool. This is a new tool that helps generate UI based on prompts. The initial results from this tool are very close to what we expected. Many teams have started using it to build mini apps. What’s worth noting is that V0 is currently being trained with two main frameworks, Svelte and TailwindCSS. This tool has been on the market for a while now, and our team has been using it for about a year. Other teams have also started integrating it into their processes.\n\n**50:22** V0 has the advantage of having a very small library size. It’s based on Svelte UI and combined with TailwindCSS, so customizing the UI and components is very easy. The combination of these two technologies has made V0 a very popular choice for prototyping UI components. We expect that in the near future, V0 will take over the market share from major libraries like Material UI or Ant Design.\n\n**51:10** Over the past month, there have been a few updates like that regarding tools and new features. Does anyone have any questions? In general, this month’s updates mostly revolve around tactical topics related to system upgrades and trending tools that big players like Amazon and Google are developing. So far, there haven’t been many updates about completely breakthrough products or technologies, but we’ve seen some progress.\n\n**51:59** Recent news has started to show signs of deeper integration of AI systems into real applications. For example, Apple is integrating AI tools directly into their systems, and Amazon has removed Alexa to replace it with cloud-based AI. We don’t know what changes will come next, but the trend is clear that major companies are gradually incorporating AI into their processes comprehensively.\n\n**53:01** Yesterday, when our team checked the email, Google also sent a notice asking if we wanted to enable AI for our team. They’re offering a service at around $15 per user, with various pricing tiers, but it’s quite expensive. We only use AI moderately, nothing too extensive.\n\n**53:49** However, we can expect that AI service prices will decrease over time, similar to how last year, the cost of using GPT-3.5 was around $32, but this year, using GPT-4, the price has dropped by nearly half. The number of tokens is also increasing, leading to a decrease in cost. Perhaps in the near future, older methods like RNN (Recurrent Neural Networks) will become outdated, and AI will become more widespread.\n\n**54:34** Tony Dinh’s team is also developing a system similar to the tool we’re using, but their speed isn’t as fast, so they probably won’t be able to compete. They’re selling a tool called TimingMind, a system that helps businesses use their own data to develop internal AI tools. Their goal is to integrate entire Office systems, work tools, and support services with AI.\n\n**55:44** What’s interesting is that they’re racing to spread AI as quickly as possible, selling what they can sell right now. In the long run, AI will become an integral part of software products, just like the traditional software industry, with increasing demands for cost efficiency, performance, and customer service.\n\n**56:48** Google’s team also has a very professional customer support service, using their own AI to interact with customers. It’s pretty impressive how they use their AI for this, and the result is very smooth, almost like talking to a real person. Alright, we’ll get the link for everyone to check and continue the discussion.\n\n**57:37** Let’s have Phát join for pair programming with me. Today, we’ll create a workflow together. Honestly, I’ll be doing most of it, but I’ll give you a direction for how to think about programming this kind of app. Thành also mentioned that we want to create many apps written on the cloud; we can write many pretty cool apps like this. Today, we’re going to use Diffy. The plan today is to replace Phát with an AI agent that allows everyone to write apps like this themselves.\n\n**58:23** Go commentary, initially, I have a plan to create a system prompt using AI, a system prompt with input as a link and output as a write-up and notes. We need an agent to fetch the link, summarize it, format it, and note it down. This is my thinking before starting the work. Let’s get to it, so everyone can see how this works. So we’re doing a Go commentary? Yes, exactly. Copy the entire thing, and let AI do it instead of Phát. Yeah, it can totally replace him.\n\n**59:22** We’ll need AI to create that system prompt. I’ve created a chatbot, and we could use CL, but I’m using a library chat to create it for the AI Club. Today, it’ll be: “Help me create a system prompt to format notes in Markdown format with the following style...” After that, the code for this will take input as a series of links and commentary. The expected output will be a Markdown article with notes on code, nuggets of knowledge, and a series of points we can extract from the changes. The purpose of this note is to discover new things about Go and consolidate news around it. Write your system prompt separately to create the article like this.\n\n**01:00:38** Okay, this part is about describing the input, output, and purpose. Finally, it’s about creating the prompt, right? Yeah, that’s right. Got it. Is Phát here? Cool. Okay, let’s see if we’ve come up with something... not super refined yet, but no problem. We have a system prompt where we’ll create a real agent. We can create a workflow or a chat flow, simplifying things to where we want a tool for Go to replace Phát, an agent to replace him. [Laughs] Goodbye, Phát. Okay, after that, we’ll have the tool.\n\n**01:01:53**  I’ve already installed some tools for the team, Thành also mentioned GReader, which is a tool for fetching information from the network. We’ve got this tool, so we’ll grab the info and use CL for the cool stuff. Okay, publish it first, then pull the links in. Let’s use the latest commentary link, what’s the latest commentary? Here we go, these three CCs, right? You’re using GReader, right T? Yeah, GReader is the tool for fetching info from the network, but what’s the prompt to control it? Or do you just throw the link in?\n\n**01:02:52** The prompt was created by AI, right? Like we said earlier? Yeah, exactly. The output is to format Phát’s article, including the necessary content, the necessary code, full details, and even a conclusion. This is actually deeper because Phát doesn’t usually write conclusions, but we can imagine that the AI agent will fetch info from the network, script it, then give it to AI’s context. After that, the AI will use the system prompt to create Phát’s article. Let’s see if the format looks right.\n\n**01:04:00** Let’s compare. We’ll leave the top part out. Turn on toc preview, let’s see which content looks good. The content seems a bit too much, we’ll probably have to trim it. If we want to go deeper into the code, we can ask AI to adjust the code directly. For example, give that output to the chatbot. Here’s an example of output from the system prompt, let’s make it more concise, focusing on the key areas related to the code.\n\n**01:06:02** I think it misunderstood the prompt, but no worries. Use this and recreate the system prompt with these intentions. Let’s try again, introduce that link again. Here it is, too easy, I can’t believe Phát’s article is this easy to replicate. Okay, let’s cut this part. Read through it, see how it is. We probably need some more adjustments. Right now, it mainly covers telemetry, but the code might need a bit more depth. But the idea is there.\n\n**01:08:26** The way to do it is from our plan: we have input, we have the purpose of the output, and we have the output we want it to resemble. Then ask AI to figure it out. It’ll generate an article similar to Phát’s. Let’s add another sentence: with this kind of style, I want to use David Ruby’s tone. That’s right, let’s get the latest articles by David Ruby, and use his technical writing style to rewrite the commentary and see what the output looks like.\n\n**01:09:07** That’s right, let’s do it. It might take a bit more content, but I’m not sure which article is the best example. Okay, let’s wait. Perfect, now optimize the tone to match David Ruby. Here’s an example article with his tone. Update the system prompt to refactor the voice of David. This is easy, this is a piece of cake. Try it again. Looks like the article is slightly truncated though.\n\n**01:11:55** Sometimes it has stop characters. Probably a bug. It knows we copied someone else’s work, so there could be copyright issues. Here, what is this article saying? Who knows? Let’s open it. Looks like a format error, but no worries, let’s go ahead anyway. Okay, remove this, publish the preview. Almost done, but we’ll probably need some more adjustments. Okay, this part doesn’t have the key phrases from David, it’s a bit off, but that’s alright.\n\n**01:13:34** Maybe because CL has a filter to avoid copyright violations, it strips out some keywords, so it only sounds somewhat similar, not fully. This issue isn’t due to a lack of samples, it’s because CL handles things differently. Exactly, let’s move on from this, just upload the new version. Then we’ll add a conclusion.\n\n**01:17:31** The idea is, if we have an agent that can scan the entire codebase, by the end of the week, we won’t even need to write reports anymore. Someone will just review it and add a few points, then send the report to the team. It makes things much easier. Try with one or two more iterations and it should be fine. Let’s review it one more time. The middle part looks good. This looks pretty readable, right?\n\n**01:18:37** Yeah, it’s about 85-90% close to David’s style. A couple more sample articles and we’ll have a really good system prompt. That’s the idea, in the end, we can use it to create articles without much editing. Before, in OGIF community calls, we didn’t care much about the system prompt, just the output. So we’ll keep focusing on the output and make sure it’s correct. We’ll check the output until it matches what we want.\n\n**01:19:16** Probably 70-90% completion, then it’ll be good. Let’s clone Phát’s tone, and see if the agent can scan the latest articles. If it can choose the right links that reflect market trends, we can create a separate database to track changes.\n\n**01:20:11** We can do this with an API, using Dify. I’ve already created an API, Dify is a tool for pulling info from interesting links. Then we filter the relevant parts about Go, send the link to the AI agent to rewrite it. Finally, Phát can review it and add images. Actually, we can ask AI to find images, compare them to see if they fit, and if they do, we can publish them directly. That step is a bit tedious, but doable. Okay, let’s leave that for later. Once this is done, Phát won’t need to write Go commentary anymore, just manage it.\n\n**01:21:29** If that’s the case, next week we can try it out. Or we could try writing an agent to load weekly articles for the team, saving time on writing reports.\n\n**01:22:18** If we feed it the full context, it’ll keep the output consistent and correct. Let’s try it with a real project, pulling info from Discord, task management, and discussions. Sound good?\n\n**01:24:01** Easy, last time I explained about Spatio-temporal reasoning, right? This is just about space and time in the project. We probably don’t even need standup meetings anymore. Let’s test it next week with the entire system.\n\n**01:25:09** Okay, seems like no one has any more questions. If we get this done, we can automate a lot more, just sit and design, let the agent run. Everyone can just get the tasks.\n\n**01:26:05** The professor just asked about the CloudZ system prompt through a UI. Comparing between lib chat and this tool. They’re pretty much the same. If you write a detailed prompt with input, output, and the purpose of the output, it’ll work the same whether on the cloud, local, or in libre chat.\n\n**01:26:05** In general, they’re pretty similar, because if they’re the same, it’s because we write a very detailed prompt. I prop the input, output, and the purpose of the output thoroughly. That’s why some people online think AI is \"dumb,\" but I’ve never seen it act dumb because the prompt I give to Cloud is always complete. As long as we give it enough information, it doesn’t matter if it’s on the cloud, console, or lib chat, it works the same.\n\n**01:26:41** What I mean is, when people say AI is dumb, it’s because their prompt isn’t good enough, right? Exactly. You mentioned something about iOS 8.0, but using GPT-4, is it better? Yeah, later on, it comes up in proposals, there’s something about zooming. GPT-4, I’ve tried it out. For content writing, it’s decent, but when it comes to deduction, math, or category series, it’s not as good. Not sure why, maybe it’s not trained on Theory of Mathematics or anything like that, it just doesn’t have enough information.\n\n**01:27:35** Those who are into math will know that GPT-4 doesn’t have enough data about that. It understands it a little, but without that data, it can’t create a proper system prompt for more complex math problems. But CL is much better in that aspect. Okay, Thành, so now the goal is for everyone to be able to use AI easily. We need to know how to build our set of agents first. Everyone who can build agents will find it easy, but using that to keep going, to maintain and apply it to real problems, is the main thing.\n\n**01:27:35** Those who are into math will know that GPT-4 doesn’t have enough data about that. It understands it a little, but without that data, it can’t create a proper system prompt for more complex math problems. But CL is much better in that aspect. Okay, Thành, so now the goal is for everyone to be able to use AI easily. We need to know how to build our set of agents first. Everyone who can build agents will find it easy, but using that to keep going, to maintain and apply it to real problems, is the main thing.\n\n**01:28:14** In the short term, that’s what we need to do before other teams catch up. Hearing how fast automation is now, everything is visualized on tools like Defile. But from a business perspective, many companies still do things manually. If our team becomes power users of this system, and we have agents to control, we’ll move very quickly, and the cost of shipping software will be much lower. Right? Buy a Protot team account.\n\n**01:29:00** Yeah, I’ll get it later. But Tom already threw it up, right? Yeah, yeah. I’ve set up an account for the team already, it’s just temporary. If the team uses more, we’ll expand it. No worries. You should rest, don’t worry about it, Bi. You’re overthinking.\n\n**01:29:42** But if we use this for our team, it’s perfect. We have to build our set of agents for the current tasks, then gradually turn everyone into power users. After that, we’ll ship other software with more time to train. Yeah, this is the right roadmap for upgrading the team. Absolutely.\n\n**01:30:37** But for example, beyond just working on projects, we could also optimize edits on chat or open source. AI will handle all of it. This is 100% AI, running on the cloud. As for the description, I’m not sure. Is this a new feature? The new feature is related to artifacts. Right now, lib chat doesn’t support artifacts. For example, you share this link, share a link of some code or project, open it in a private tab, and it will show the artifact. But for many types of files, it will need to support them one by one.\n\n**01:31:20** This already has code, based on someone else’s problem. When it runs Python or React, it will highlight and preview similarly. I did a demo from when I didn’t know anything, and how long did it take to finish? How long did it take in total? About an hour, no joke. One hour from reading the spec, understanding the code, then adjusting the design, fixing the code, and the backend. In total, it was 2-3 dollars.\n\n**01:33:10** I had to build a docker container and deploy it on a server. The build process took longer than the coding. So it only took 2 minutes to introduce the chatbot to everyone? We should invite everyone to join now. Yeah, I’ll give the team access later. Let me explain lib chat: it’s a GPT clone but allows us to choose the model. Currently, it supports OpenAI and Anthropic APIs. If you want to use model hacks, just connect your API key. We have a UI to interact with the chatbot, and we can use R and PDF files as well.\n\n**01:34:40** Later, we’ll expand it for the team to track progress, AI programming skills, and writing prompts. This really helps with programming speed, you can even ask AI to code for you, talk to it, and it understands your needs, codes everything for you. The nice thing about lib chat is you can share links, like I mentioned earlier. Initially, we used Cloud, but Cloud didn’t allow link sharing, so at least lib chat ensures this. The lib chat community has already started picking it up and acknowledging it. How many stars does this project have?\n\n**01:35:52** It’s been a while, this is just a UI project. Outside of Danny, there’s Cris and a few others. But calling it a community is a bit of a stretch, it’s more of a passionate group. Does anyone else do something similar so that when we get familiar with it, we can clone it ourselves? Maybe l chat has more, but the biggest ones are l chat and libre chat.\n\n**01:36:38** So why haven’t I heard more about this? It’s double-starred? Yeah, but it hasn’t been deployed much because it needs more servers, and more servers mean more money. So I’ll claim the cost for you. Okay, give it a try, it looks like it’ll gain more recognition. In the long run, it’ll be beneficial, right? Yeah, definitely. If you’re managing PDFs, it’s great, or if you want to view artifacts, switch to lib chat. Okay, got it. Does anyone else have any more questions?\n\n**01:38:33** Looks like no more questions. Tom and the team will probably test this to see how far it can go. We’ll make sure to test it with the team next week, to get everyone familiar. Other projects have different data sources, so we’ll likely need to integrate multiple systems like Slack, Notion, or Jira, each with its own setup.\n\n**01:39:22** Notion and Slack are the easiest, Jira is a bit more difficult since its API isn’t great. Not to mention, project information tends to rely on the PM, so it’s hard to summarize everything. But once we have enough information, we shouldn’t need much more. Alright, okay. Let’s wrap it up here. Today was really interesting. Okay, thanks Tom and everyone. See you next time.\n","title":"OGIF Office Hours #22 - Hybrid working, Tech market report, Go commentary weekly, AI demo for Go weekly content production.","short_title":"#22 Hybrid work, Tech report, Go weekly, AI demo","description":"In OGIF 22, we talked about Devbox progress, GReader updates, and using libre chat for artifact management. We also cover optimizing AI system prompts, Go commentary, and key market trends. Plus, we discuss how hybrid work can boost team collaboration and productivity. It’s all about practical tips and knowledge sharing to keep everyone up to speed.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Mon Sep 09 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/22-20240906.md","slugArray":["updates","ogif","22-20240906"]},{"content":"\n85 minutes\n\n### Highlights and Topics\n1. **Financial Report & Golang Weekly**:\n    - Financial performance for August.\n    - Updates on Golang blog and survey responses.\n2. **Go in Enterprises**:\n    - Discussion on Go's readiness for large enterprises, comparison with Java and C++.\n    - Challenges and benefits of transitioning to Go in enterprise environments.\n3. **Technology Trends & Updates**:\n    - React 19 AC, Next.js updates, and new optimizations.\n    - Comparison between CSS Grid and Flexbox, updates on JavaScript and form-building tools like fity.\n4. **Team Productivity Enhancements**:\n    - Using mixture agents and EOM (large language models) to optimize learning and knowledge discovery.\n    - Demoing mixture agent in real-world scenarios like learning Chinese and RP trading.\n5. **AI-Driven Solutions**:\n    - Automation using AI comments and system prompts to improve workflows.\n    - Introduction of check-in features for team hybrid work environments.\n6. **Upcoming Tests and Team Building**:\n    - Design of AI and tool usage tests for the team to enhance efficiency\n    - Plans for team outings and return to office support.\n\n---\n\n**Vietnamese Transcript**\n\n**07:25** Anh Thành có nói được không nhỉ? Nghe được không? À, nghe được rồi. Ok, ok.\" \"Có nhận feedback từ Discord rồi. Chờ tí nữa nhé.\n\n**10:28** Hôm nay có review qua mấy số liệu không?\n\n**11:39** Hay là bắt đầu luôn nhỉ? Ok, rồi. Chắc là mở đầu có hai bài báo cáo: một là báo cáo tài chính của tháng 8 vừa rồi, chắc là mình sẽ phát Go Lang Weekly luôn. Sau đó, chắc là mình có một bài liên quan đến ‘stay-ma’ của Go đúng không? Anh em tranh thủ nhé, để tí nữa tổng hợp lại. Bài này em có chỉnh lại, nó hơi dài dòng, hơi nhiều chữ, em đã chỉnh sửa và check lại một chút.\n\n**12:46** Bài tuần vừa rồi thì bên core team đã gửi một khảo sát cho mọi người. Ai có feedback gì về cách sử dụng Go, cảm thấy có những thách thức gì khi xài Go, có thấy khó chịu hay có điều gì muốn đề xuất, thì có thể gửi vào link đã đính kèm ở đây nhé. Bài thứ hai cũng theo xu thế, nó ra một bài trên blog của Golang luôn. Bài này hướng dẫn cách build power app. Bên Google có hướng dẫn cách build app, sử dụng con Gin thôi, không có gì đặc biệt. Đây là phần code kiểu phần run server của họ. Mình có link đầy đủ cho mọi người xem code chi tiết. Mình nghĩ là sử dụng cũng ổn thôi. \n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/jcn5nn5GPS8?si=9aUk4HoTHhWTdFnv&amp;start=723\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**13:28** Bên cạnh đó, Go cũng ra mắt ZenKit, gần như y hệt Langchain, nhưng của Google. Cái này ra mắt giữa tháng 7, mọi người có thể xem qua. Ví dụ như có các interface vector store mà mình có thể sử dụng, như add document hoặc similarity search.\n\n**14:22** Bài tiếp theo có lẽ sẽ dành cho những ai hứng thú với Erlang hay Langchain. Framework này mới ra bản mới và gần như đã có đầy đủ các tính năng. Bên Alan đang cố gắng map qua và gần như xong rồi, họ claim là đã sẵn sàng cho production. Cách chạy của nó kiểu như thế này. Mình có check qua issue list của nó, không có gì phức tạp, tính năng của nó gần như đã ready hết rồi. Dự đoán rằng framework này sẽ phát triển mạnh.\n\n**15:22** Đó, chắc vậy thôi. À, anh có câu hỏi gì không? Ừ, hôm trước anh em có làm một bài về phần enterprise, chắc mình tranh thủ điểm qua luôn nhé. Bởi vì mình sẽ không có nhiều thời gian cho phần đó. Thắng có hỗ trợ em làm bài này, đúng không Thắng?\n\n**16:23** Thắng có chia sẻ và giúp em viết phần này. Có một số bài trước em đã giới thiệu qua với mọi người về việc Go đã mature như thế nào. Nó đã sẵn sàng để các doanh nghiệp lớn lựa chọn. Nhưng để thay thế hẳn thì chưa được, bởi vì một số doanh nghiệp lớn vẫn đang dùng Java. Việc chuyển đổi có thể có chi phí quá lớn để hoàn toàn bỏ Java. Nhưng đối với các doanh nghiệp mới hoặc những enterprise muốn chuyển đổi, Go là lựa chọn thích hợp.\n\n**17:26** Bài này sẽ trả lời các câu hỏi như thế nào là một enterprise standard language? Tại sao nên dùng Go trong enterprise? Và hiện tại, có những công ty lớn nào đang sử dụng Go. Đây là những bài viết sau, ví dụ như bài tại sao các doanh nghiệp lớn lại chọn Go.\n\n**18:17** Ok, để em điểm qua nội dung nhé. Java được phát triển từ thời Sun Microsystems, với đặc điểm là viết một lần và chạy mọi nơi, vì vậy nó rất ổn định và có đầy đủ tính năng hỗ trợ. Các doanh nghiệp khi chọn ngôn ngữ lập trình thường xem xét tính năng và độ ổn định. Java Enterprise, trước đây gọi là Java EE, nay là Jakarta EE, hỗ trợ synchronous và asynchronous messaging, các định dạng như XML, JSON, và Protocol Buffers.\n\n**19:11** Ngoài ra, doanh nghiệp thường so sánh Java với C++, vì C++ phức tạp hơn do phải quản lý bộ nhớ nhiều. Trong khi đó, Java có garbage collector giúp lo việc quản lý bộ nhớ, nên người dùng không cần quan tâm nhiều, chỉ tập trung vào việc triển khai (implementation) thôi. Hơn nữa, Java có một hệ sinh thái lớn, hỗ trợ gần như đầy đủ tất cả các thư viện và công cụ framework.\n\n**20:15** Vậy, cái lợi của Java Enterprise là so sánh với C++? Đúng rồi, vào thời đó thì C++ còn phổ biến, nhưng C đã quá cũ, tầm 20-40 năm rồi. Những doanh nghiệp cũ dùng COBOL, sau đó chuyển qua C++, và cũng có một số doanh nghiệp chọn C# của Microsoft. Nhưng cộng đồng lập trình thấy rằng C++ có một giai đoạn ổn định hơn nhiều. \n\n**21:02** C# giống như là một hệ sinh thái riêng của Microsoft. Còn C++ thì được cộng đồng lập trình enterprise đón nhận rộng rãi hơn. Tuy không phải ai cũng sử dụng, nhưng khi nhắc đến ngôn ngữ lập trình enterprise, chỉ có Java và C++ là được đề cập nhiều nhất.\n\n**22:14** Câu hỏi tiếp theo là tại sao Go lại là lựa chọn cho doanh nghiệp? Và những công ty nào đang sử dụng Go? Cái chính là khi làm bài này, anh nghĩ mấy anh em nên đặt mục tiêu là xác định rõ ràng tại sao Java nó thắng được, đúng không? Java nó thắng được với thằng C# và C++. Hiện tại, anh muốn tìm lý do để thuyết phục một người đang sử dụng Java chuyển sang Go. Phải có lý do cụ thể. Trong những bài mà mấy anh em đang làm, hãy tập trung vào điểm đó nhé, cần tìm ra lý do.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/jcn5nn5GPS8?si=mCE2JfLQlyLc_o1O&amp;start=1367\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**23:13** Lý do mà hiện tại có thể Go đã giải quyết hết tất cả những vấn đề của Java. Có thể Go mạnh hơn Java về mặt nào đó, hoặc vì những lý do mà bây giờ nên chuyển sang Go. Có thể thêm case study cho việc này. Dạ, chắc là mục tiêu là vậy. Nếu mấy em làm tiếp, nên cân nhắc mỗi bài như một câu hỏi thô, và trả lời mỗi câu hỏi đó với lý do thuyết phục. Đồng thời, có khả năng biến nó thành một slide để trình bày. Kiểu như bài đầu tiên, xem thử tuần sau post lên cộng đồng, nhóm Golang xem như thế nào.\n\n**24:05** Xem coi mọi người đánh giá thế nào nhé. Ok rồi, phá dạ hết rồi. Tiếp theo, mình đi nhanh qua tình hình của Thắng. Tháng vừa rồi anh em tội lắm. Mọi người thấy Thắng đâu chưa? Chắc phải vào lại máy, chắc chơi máy Windows lâu quá.\n\n**25:26** Máy bị treo luôn, đứng Discord ở trên Windows nó hay bị lag hơn Mac đúng không? Mac ngon hơn hẳn.Ok, ơi, không nghe tiếng rồi. Ok, nghe rõ rồi, ngon rồi. Vậy thì tiếp tục.\n\n**26:31** Bài report tháng này cũng tương tự như tháng trước thôi, một số bài không hẳn là mới nhưng em đã tổng hợp lại những gì em thấy có liên quan. Để em điểm nhanh qua nhé. Em mở sẵn rồi, mình đi qua hết cái này rồi xong luôn. Đầu tiên là về React 19 AC. Nó đã ra mắt từ tháng 4, nhưng đến tháng trước mới có báo cáo đầy đủ. Cơ bản là vẫn là tập trung vào việc hỗ trợ server components và một số cải tiến trong việc quản lý script bất đồng bộ (asynchronous script). Đây là một lời nhắc nhở thân thiện cho những bạn nào chưa đọc thì có thể xem thử.\n\n**27:17** Cá nhân em thấy React càng ngày càng rối, nên em sẽ tạm tránh xa phiên bản 19 này. Ý là, React có một số hooks mới, nhưng cảm giác như mình dùng những hooks có sẵn cũng được rồi. Nhưng họ lại đóng gói lại (wrap) và tạo ra thêm các utility hooks mới. Em nghĩ nó cũng ok, nhưng vấn đề là nền tảng như React đang ngày càng trở nên phức tạp, và em cảm thấy nó không còn ý nghĩa nhiều lắm nữa. Bởi vì ban đầu nó chỉ là một công cụ xây dựng đơn giản, nhưng giờ họ cứ cố thêm vào những thứ mà em thấy hơi dư thừa.\n\n**27:55** Tiếp theo là về thằng Next 15. Cảm nhận của em với thằng này cũng tương tự. Next 15 phiên bản AC này cũng hỗ trợ React 19 AC với một số cải tiến. Cái em thấy hay là vụ React compiler. Cái này giống như một bước tối ưu, giúp React tối ưu code của mình. Mình có thể bỏ đi các hooks như `useMemo`, `useCallback`, các hooks mà gần như 90% người dùng React đều phải sử dụng. Bây giờ, với tính năng mới này thì không cần nữa.\n\n**28:39** Cái này thì hay, nhưng vấn đề là những thứ khác, đặc biệt là `app router` của Next.js, em có nói chuyện với anh Thành rồi, hình như anh ấy cũng chán Next lắm. Em cảm giác, em đọc phần bình luận thì thấy cộng đồng cũng bối rối, tuần nào cũng có người hỏi là có cần sử dụng không. Stack hiện tại của họ thì vẫn ổn, nhưng React và Next.js ngày càng trở nên phức tạp. Điều này giống như việc OpenAI chuyển từ Next.js về Remix. Cảm giác thị trường đang dần dịch chuyển.\n\n**29:17** Giống như chuyện OpenAI chuyển từ Next về Remix vậy. Cảm giác chung của cộng đồng là họ đang chuyển dần sang những giải pháp khác hiệu quả hơn. Nest với Next.js vẫn ok, nhưng cá nhân em thấy nó ngày càng phức tạp, đặc biệt là `app router`. Gần như từ khi ra mắt Next 10, 12, 13, em chưa xài nhiều. Dù nó là stack chính, nhưng có vẻ nó cũng không còn là `main stack` nữa\n\n**29:56** Về `main stack` của Next.js, nó vẫn là `main stack`, kiểu vậy. Liên quan một chút với thằng Vercel (`v0`), video này khá ổn. Nó demo về sức mạnh của Vercel, kết hợp với thằng `shadcn`. `shadcn` này là một thư viện UI được build bằng Tailwind. Bên Vercel, nó có một component thiết kế cho phép import một giây vào `v0` để build, điều này khá thú vị. Em vẫn chưa có thời gian `playground` với nó, nhưng nhìn video demo thì thấy build game, build form, build 3D bằng Three.js khá thú vị.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/jcn5nn5GPS8?si=iHD3YYKBnkB7jlKb&amp;start=1707\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**30:48** Video đó khá ấn tượng, nên em quan tâm đến Vercel. Ok, tiếp theo là JavaScript. Đây là một vấn đề mà em thấy rất liên quan đến em, dù hiện tại nó chỉ đang ở giai đoạn đề xuất (`proposal`). Đó là việc xử lý ngày tháng (`date`) trong JavaScript. Chắc chắn ai làm front-end và phải xử lý ngày, đặc biệt là xử lý `time zone`, sẽ thấy vấn đề này rất phức tạp. Đề xuất này hứa hẹn sẽ giải quyết được vấn đề đó. Hi vọng không biết khi nào nó release, nhưng đây là một đề xuất đáng mong đợi.\n\n**31:32** Một cái khác, em đang chia sẻ đúng màn hình không vậy? Anh có thấy màn hình không? Màn hình bên em vẫn hoạt động bình thường, nhưng màn hình bên anh có vẻ bị đứng nguyên một vị trí. Ok, em mới chia sẻ lại, có thấy chưa? Để em giảm độ phân giải xuống còn 700p. Ok, tiếp theo là về CSS. Cái này em nghĩ nó có từ lâu rồi, nhưng tháng trước em mới đọc được một bài viết về nó. Bài này em đã đưa vào báo cáo. Đó là một hướng dẫn tương tác (`interactive tutorial`) về cách sử dụng CSS Grid thay vì Flexbox. Khi đọc bài này, em nhớ tới một chuyện vui về CSS.\n\n**32:35** Chuyện vui là về CSS3. Bây giờ, khi đi phỏng vấn tuyển dụng, họ vẫn đề cập đến HTML5 và CSS3, nhưng thật ra CSS3 đã ra mắt hơn chục năm rồi. Hiện tại, họ đang nói đến CSS4, có vẻ đã vài năm rồi. CSS5 hiện nay cũng đang trong quá trình phát triển với một số `proposal`. Nhưng không hiểu sao cộng đồng dev vẫn quen gọi là CSS3. Giống như với thằng `Grid`, nó cũng đã ra mắt từ lâu, nhưng không phải tất cả các trình duyệt (`browser`) đều hỗ trợ đầy đủ ngay từ đầu.\n\n**33:17** CSS Grid đã ra mắt từ lâu và bây giờ gần như tất cả các trình duyệt đều hỗ trợ nó. Mọi người nên xem xét việc dừng sử dụng Flexbox và chuyển sang CSS Grid. Ok, tiếp theo là một chuyên mục khác – 'Mỗi Tuần Một Web'. Thằng `rb` vừa ra version 1.0, và như mọi khi, họ so sánh tốc độ nhanh hơn `WebP`. `WebP` vốn đã nhanh, nhưng giờ `rb` có vẻ còn nhanh hơn. Mọi người có thể xem xét thử `rb`.\n\n**34:42** \"Một cái khác là thằng `fity`, em tình cờ phát hiện ra. Nó cho phép build form bằng JSON, điều này thú vị vì nó khá khớp với suy nghĩ của em. Giống như dự án đầu tiên em làm với khách hàng Malaysia, kiểu như `chợ tốt` bên đó. `Muda` cũng sử dụng `buf` bằng JSON để đưa ra các `schema`, sau đó render ra form. Cảm giác rất thú vị.\n\n**35:30** Còn một cái khác là thằng `i18n`, nó là một cộng đồng hướng đến việc `clean up`, `fit up`, và `level up`. Họ đi tìm những thư viện như `Lodash` để dọn dẹp và tối ưu chúng, tạo ra những phiên bản thay thế nhẹ hơn, sạch hơn. Cộng đồng này đã tạo ra khá nhiều thứ rồi. Em thấy mục tiêu của nhóm này rất hay. Nhưng thực ra, em chưa sử dụng các công cụ họ build ra.\"\n\n**36:13** Ok, kết thúc với một bài ngắn về 'Top Programming Languages'. Đây có lẽ sẽ khiến mọi người hứng thú – top các ngôn ngữ lập trình trong năm 2024. Em sẽ xem qua. Ok, từ trên xuống dưới thì Python vẫn đứng đầu. Em không biết họ đánh giá kiểu gì, nhưng Python đứng đầu, rồi tới Java, rồi JavaScript. C++, TypeScript cũng nằm trong danh sách. Em không rõ họ thu thập dữ liệu kiểu gì, vì họ không nêu rõ, nhưng có vẻ như với các công việc lập trình, SQL, Python, Java, TypeScript vẫn ổn. Em nghĩ vậy.\n\n**37:07** Đó là những gì em thu thập được từ tháng trước. Ok, bây giờ nói về `a scraper`. Ừ, `a scraper` thì khoảng 2-3 ngày nữa sẽ có một bài giữa tháng. Em sẽ cố gắng mỗi hai tuần ra một bài. Còn `a scraper` thì chắc là mỗi hai tuần một bài. Nếu kéo dài đến một tháng, cảm giác bị miss mất khá nhiều thông tin vì nhiều quá, nên có thể mỗi ngày sẽ phải làm một ít. Cả frontend và backend đều như vậy mà, đúng không? Ok rồi.\n\n**38:11** Ủa, LP, cái bài kia em làm xong chưa? Cái gì dính tới Thới á, em làm xong cái đó chưa? Ừ, chưa hả? Anh cũng chưa wrap up nữa. Con bot thì đã crawl được rồi, nhưng cần chuyển thêm một cái server backend để làm Discord bot. Cái đó em chưa làm, nhưng con bot thì chạy được rồi.\"\n\n**38:55** Trước khi Tôm tiếp quản, anh có một vài thông báo. Đầu tiên, tuần vừa rồi mình có triển khai một vài thông tin. Liên quan đến việc `adopt` EOM để tăng năng suất cho team, anh đã post lên một `initiative`. Nếu anh em có thể phát triển hoặc sử dụng `cilus` ở một mức độ nhất định, thì sẽ có reward ICY cho mọi người. Danh sách việc cần làm sẽ nằm trên `workland` của mình, nhìn sơ qua cũng dễ hiểu.\n\n**39:44** Ví dụ như bài của TnT, đó là một bài liên quan đến `concept` này. Anh ấy đã làm một bài về việc học tiếng Tây Ban Nha. Mặc dù nó không liên quan lắm, nhưng anh ấy đã demo con bot đó cho mọi người xem. Anh kỳ vọng rằng mọi người sẽ làm quen với việc đặt câu hỏi cho AI theo dạng `system prompt`, sau đó thực hiện triển khai (`deployment`). Những bài của 4C đã làm xong hết rồi. Cách triển khai (`prompt`) như thế nào, anh em có thể coi và `run` chính xác như vậy.\n\n**40:31** Còn những phần khác thì sẽ xem xét thêm. Phần của Pish tuần trước nằm ở đây, show nhanh qua nhé. Điều mà mọi người thấy là kết quả của quá trình làm cái `script` mà T đã làm. Toàn bộ quá trình `prompt` để tạo ra kết quả này kéo dài khoảng vài giây, bao gồm các thông tin cần thiết và sau đó `spore` ra một `system prompt`, đưa lên trên cái `defile` này để mọi người sử dụng. Bên đây là nơi để xài, con `defile` này có thể `trip` ra thành `API`, và nếu anh em muốn sử dụng, có thể gọi trực tiếp `API` như một `serverless function`. Gọi API và nó sẽ trả về kết quả, sau đó mình chỉ cần đưa vào trong Discord hoặc các giao diện khác.\n\n**41:13** Ví dụ như bài này, nó sẽ ghép với cái ngữ cảnh (`context`) trong môi trường làm việc. Khi đưa ra một `topic`, nó sẽ sinh ra một dạng `syntax` để `insert`. Một bên là so sánh hai loại câu hoặc hai ngôn ngữ, và nó đưa ra hai hoặc ba phản hồi (`response`) có thể đến từ đồng nghiệp. Sau đó, mình có thể trả lời tiếp theo như thế nào. Đồng thời, nó cũng sẽ gợi ý một số kiến thức (`knowledge`) mà mình có thể `pick up` từ cuộc hội thoại.\n\n**42:17** Rồi đây, mọi người đang thấy trên màn hình đó là phần `system prompt` và `output`. Trong cái bảng mà anh yêu cầu thì cần nhiều hơn một chút. Để theo dõi quá trình học hỏi của mọi người, sẽ cần `problock` thêm nữa. Nếu anh em không có `cilus`, không có `ChatGPT`, có thể request để dùng chung với team mình. Trên đây team đã load sẵn các key rồi, cứ lấy và xài thôi, không vấn đề gì.\"\n\n**43:04** Ví dụ nhé, gần như toàn bộ góc nhìn của tụi anh ở giai đoạn hiện tại là ở mức cơ bản nhất, team mình cần hiểu cách sử dụng mấy công cụ AI này như một phần của công việc hằng ngày. Trước đây, khoảng hai năm, team mình đã sử dụng rồi nhưng cách đặt câu hỏi, cách khai thác thông tin từ các mô hình dữ liệu lớn (`large data models`) không hiệu quả lắm. Anh đã chia sẻ tài khoản `ChatGPT` với vài anh em trong team, và qua quan sát hiện tại, cách sử dụng vẫn chưa tối ưu.\n\n**43:41** Đây chính là lý do để mình làm thêm bài tập này. Giai đoạn này cần mọi người làm thử, học cách build các `cot`, sau này mình sẽ có công cụ cần thiết giúp ích cho công việc. Mỗi `to-do` trên đây tương đương với góc nhìn của mình là nó sẽ trở thành một công cụ `cilus` cho cá nhân hoặc team để giúp tăng tốc độ làm việc. Từ việc viết `doc`, `breakdown` công việc, hỗ trợ viết `requirement ticket`, biết cách chọn ngay `chai` (`API`) ra sao từ các `context` đưa vào.\n\n**44:32** Đó là điều đầu tiên mà anh em cần để ý. Nhắc lại cho tuần vừa rồi, team mình đã bàn tiếp về chuyện đi chơi. Hiện tại, Huy Nguyễn đang chuẩn bị được bao nhiêu phần trăm rồi? Huy Nguyễn, theo ước lượng của em, chuẩn bị tới đâu rồi?\n\n**45:35** Tuyệt vời. Ok, phần đó hoàn thành. Chính sách hỗ trợ cho mọi người sẽ có thay đổi một chút. Vì hiện tại ngân sách có vẻ hơi lớn, đang tăng lên khoảng 500-600 trên đầu người, hơi nhiều so với tình hình hiện tại. Nên sẽ có một số điều kiện kèm theo. Có hai điều chính: một là những gì đã nói trong việc sử dụng mô hình ngôn ngữ lớn, mấy anh em sẽ cần phải vượt qua một bài test do team soạn ra.\n\n**46:14** Thật ra, bây giờ mình thấy có sự chênh lệch lớn giữa các bạn đã biết sử dụng `tools` và những bạn chưa biết. Rõ ràng là có một sự khác biệt rất lớn. Nó không hoàn toàn là 100%, nhưng khoảng 60-70% thôi. Những bài toán lớn, phức tạp hơn thì khó, nhưng kỹ năng cần thiết thì mình vẫn thấy được. Vì thế, nếu bây giờ không học thì sau này sẽ rất khó để có thể cạnh tranh với những người khác trong team, những bạn đã thành thạo `tools` rồi.\n\n**47:01** Vậy nên, đây là yêu cầu cần thiết. Có gì Tôm với Huy Nguyễn sẽ cùng đứng ra thiết kế bài test này nhé. Bắt đầu nghĩ về việc đó giúp anh. Vì với các vai trò khác nhau trong team, sẽ có những bài tập phù hợp, nhưng điều kiện chung là phải hiểu được cách mô hình ngôn ngữ lớn hoạt động như thế nào, không nhất thiết phải hiểu chi tiết về `dataset`, nhưng cần biết cách sử dụng các công cụ như thế nào, tự `setup` được và dùng nó để tăng tốc công việc.\n\n**47:51** Việc này là việc số hai. Huy Nguyễn với Tom sẽ giúp đỡ để hoàn thành bài test này nhé. Mấy bạn vượt qua được bài test này thì sẽ thoải mái hơn, không bị áp lực khi làm việc nữa. Theo kế hoạch, mình dự tính tới tháng 12 phải xong đúng không? Còn khoảng 2-3 tháng để anh em ôn tập và bắt đầu làm. Đây sẽ là tiêu chuẩn mới cho team mình. \n\n**48:37** Chuyện thứ ba liên quan tới việc planning cho Team Building. Team mình cũng đã thảo luận tuần trước về việc quay lại văn phòng làm việc hybrid. Mình sẽ bắt đầu hỗ trợ mọi người lên văn phòng để tạo sự kết nối tốt hơn. Một số bạn đã lên văn phòng rồi. Tôm cũng đang hỗ trợ lên văn phòng để xem anh em nào muốn 'make up' công việc thì tới văn phòng nhé. Cái `AIClub` mà Tom đang lead, bây giờ đã được chuyển thành một channel trong team rồi, nhưng chỉ invite các bạn vào với một số điều kiện nhất định.\n\n**49:22** Anh cảm giác rằng ai đã sẵn sàng học và đặt câu hỏi hợp lý liên quan thì sẽ được mời vào nhóm này thôi. Hiện tại, có một số bạn đang xem qua rồi. Chiều nay vừa tạo, bắt đầu chuyển dần dần. Việc này cũng liên quan tới chuyện thay đổi mật khẩu, lỡ có show trên stream rồi. Trong vòng tuần tới, kỳ vọng là mọi người sẽ dành thời gian lên văn phòng một đến hai ngày. Nếu thấy ở nhà không tập trung hoặc phải tương tác nhiều với gia đình, không sát được công việc, thì cứ lên văn phòng làm việc một đến hai ngày.\n\n**50:08** Khi anh em `check-in`, Tôm và Vi nhỏ đã làm tính năng `check-in` ở văn phòng. Nếu các bạn kết nối với Wi-Fi ở văn phòng, hệ thống sẽ nhận diện và gửi thông báo `bot` vào `channel` lobby. Cái này hơi spam một xíu nhưng sẽ được tinh chỉnh lại. Sau đó, team sẽ hỗ trợ tiền gửi xe và có thêm phần thưởng `IC`, khoảng 5 IC, kèm theo chuyện ăn trưa này nọ, team sẽ `subsidize` luôn. Đó là ba thông báo lớn nhất trong tuần qua, liên quan đến `benefit` của mọi người. Anh em để ý nhé.\n\n**51:10** Rồi, giờ chắc nhường lại sân khấu cho Thành để tiếp tục với chủ đề nhé. Chủ đề của bạn Hiếu tuần trước chắc để tuần sau hẹn Hiếu vậy. Tuần trước Hiếu có chủ đề về `database reference` và vấn đề `circular reference`. Ok, để em làm luôn nhé, quất luôn. Hôm nay sẽ hơi chia sẻ về AI Comment mà mình đã làm cho team. Thực tế, AI Comment mình cũng dùng phương pháp giống như làm cho `Prompt` hoặc `Completion`, chỉ khác là mình sẽ làm thế nào để có `input` và `output` cụ thể.\n\n**51:58** Nó sẽ trở thành một `chatbot` đơn giản thôi. Trong con bot này, nó sẽ copy lại những thứ từ trước, như `output` từ `sunbot`. Nó sẽ lấy `base case` từ `sunbot` luôn. Các `switch case` liên quan đến câu hỏi về `Memo`, ví dụ như mình hỏi 'What are the latest notes?', thì nó sẽ dựa trên các câu lệnh đã được `instruct` sẵn để tìm kiếm và trả lời. Hoặc nó có thể `query` phía dưới cho team mình. Không có gì phức tạp, cứ xem như ba cái `output` cơ bản, mỗi cái sẽ cung cấp các kết quả cần thiết.\n\n**52:44** Giới thiệu là vậy, giải pháp cho những ai sợ đặt câu hỏi ngu và bị trừ lương thì đây là câu trả lời – một `auto-solution`. Cái này sẽ tự động hết cho mọi người. Mình làm một `agent` để tự động hóa quá trình này. Đây cũng là phương pháp mà OpenAI đã sử dụng, gọi là `mixture of agents`. Mỗi `agent` sẽ tự nói chuyện với chính nó để hiểu rõ hơn nhu cầu của mình, sau đó đưa ra các kết quả mà mình mong muốn. Đối với mỗi câu hỏi, nếu không có `input`, cứ để AI suy luận hết. Không cần phải `prompt` phức tạp.\n\n**53:27** Nếu không có `output`, để AI tự suy luận. Mục tiêu của `output` là gì? Để AI tự suy nghĩ, xem cần những thông tin gì liên quan, có thể về công nghệ, y tế, hoặc bất kỳ lĩnh vực nào khác. AI sẽ tự hiểu, không cần phải đặt `prompt` quá phức tạp. Có một số mẫu mình sẽ thử cho mọi người dễ hình dung. Ví dụ: 'How to learn Chinese'. Dù mình nhập câu này vào ChatGPT hoặc Club, đôi khi nó sẽ đưa ra câu trả lời đúng, đôi khi thì không, vì nó không hiểu hết ý của mình.\n\n**54:04** Nếu mình nói là mình muốn học tiếng Trung để liên quan đến thi đấu hoặc những thứ đặc biệt như HSK, thì `OpenAI` có thể đưa ra câu trả lời chính xác hơn, chuyên sâu hơn. Đúng là mình có thể copy dễ dàng, nhưng quá trình này có thể gồm một đến ba bước để AI tự suy luận (`reason`). Nó sẽ suy đoán từ những gì người dùng dự định (`intent`). Cái này có thể copy qua `mixture of agents` để sử dụng hiệu quả hơn.\n\n**54:45** Mixture agent này sẽ hoạt động luôn. Mình có một cái LCK sẵn rồi nhé. Ok, một cái mới là `how to learn Chinese`. Đợi chút, để giải thích lại một chút cho mấy anh em đang chưa hiểu rõ. Đây là bài toán trong tuần vừa rồi mà tụi mình gặp. Việc đặt câu hỏi cho AI sẽ quyết định đến việc mình nhận được phản hồi (`response`) gì và tốc độ tiếp thu kiến thức mới của mình sẽ như thế nào. Đó là bài toán tụi mình gặp phải. Đề bài là như thế này: khi có một chủ đề mới, mình sẽ phải tiếp cận và tìm hiểu nó.\n\n**55:30** Trước đây, mọi người thường sẽ lên Google để tìm kiếm thông tin, rồi tổng hợp lại, sau đó ghi nhận vào tài liệu của mình. Nhưng trong khoảng hai năm trở lại đây, cách làm đó đã thay đổi. Mọi người không còn tìm kiếm kiến thức qua Google nữa mà chuyển qua hỏi các mô hình ngôn ngữ lớn (`EOM`). Tuy nhiên, việc tìm kiếm thông tin đơn giản qua EOM có thể không đưa ra câu trả lời chất lượng cao, và sẽ rất lâu để mình có thể hiểu được các kiến thức cốt lõi của một chủ đề mới.\n\n**55:59** Ví dụ như việc tập Dream thì sẽ có những thứ như các chỉ số (`metrics`) đo sự thay đổi của cơ thể. Hay ví dụ như học Chà ni (Chinese), sẽ có một số kiến thức chính mà mình cần biết. Vậy làm sao để từ không biết gì (`zero knowledge`) mình có thể học hết những thứ đó? Đây chính là quá trình mà con O1 của ChatGPT đã giới thiệu ngày hôm qua. Tom đã trải qua quá trình suy nghĩ và thực hiện phần này, và hôm nay Tom sẽ demo lại cách mà quá trình này hoạt động, cùng với việc Tom đã triển khai nó cho team mình luôn. Team có thể sử dụng hiệu quả hơn.\n\n**56:36** Dạ, đúng rồi. Ok, để chia sẻ luôn phần `How to learn Chinese`. Đối với mình, khi tìm kiếm, mình đang muốn tìm các `keyword` liên quan đến thi đấu hoặc các `keyword` đặc biệt, như cách viết ký tự (`radical`) hoặc thứ tự sắp xếp (`stroke order`). Mixture agent này sẽ suy ra tất cả những điều đó. Nó hiểu rằng mình muốn tìm hiểu về điều gì và cần gì. Nó sẽ trả lời đầy đủ, có thể hơi thừa, nhưng thừa còn hơn là thiếu. Có cả code luôn, dễ hiểu mà.\n\n**57:18** Ưu điểm của phương pháp này là mình có thể đi sâu hơn nữa, ví dụ như HSK6 chẳng hạn. Không biết HSK6 là gì và muốn đạt điểm bao nhiêu? Nó sẽ suy ra tất cả từ lịch sử cuộc hội thoại của mình. Nếu mình muốn học tiếng Trung để thi HSK6, nó sẽ giải thích và đưa ra cả một kế hoạch (`regimen`) học cho mình luôn. Đây là một phương pháp rất tốt nếu như mình không rành về việc viết prompt và không muốn bị trừ lương vì viết prompt sai.\n\n**58:11** Mixture agent này sâu và có thể hơi thừa, nhưng nó cho phép mình chính xác hơn. Khi Together AI thiết kế `inference engine`, họ nhận thấy rằng `response` của các mô hình ngôn ngữ lớn (`LLM`) rất nhanh. Nên họ đã nghĩ tại sao không cho nhiều mô hình ngôn ngữ chạy cùng một lúc và sau đó đồng bộ thông tin lại cho AI đưa ra câu trả lời chính xác hơn?\n\n**58:55** Thực ra, bên Together AI và một đội ngũ khác chỉ dùng mô hình Lama thôi mà họ cũng đánh bại được GPT-4. Điều kiện là mình phải cung cấp đủ thông tin cho AI để nó suy luận. Nó cần biết `input`, `output`, toán học, hóa học, hoặc bất kỳ lĩnh vực nào. Mình sẽ nhập tất cả những điều đó vào đây. Thiết kế của mixture agent khá đơn giản. Nó sẽ có một `system prompt` liên quan đến `reasoning` để AI suy luận những thứ liên quan đến toán, hóa học, và nó sẽ kéo những từ khóa (`keyword`) quan trọng ra để trả lời.\n\n**59:37** Ví dụ, nếu muốn học tiếng Trung, `input` của mình là tiếng Anh vì mình trả lời bằng tiếng Anh. `Output` là phương pháp học tiếng Trung, sau đó có một `aggregator` sẽ sắp xếp lại toàn bộ thông tin này. Nó sẽ đưa ra một câu trả lời rất thông minh. Phần nặng nhất là ở đoạn này, nhưng mình có thể thêm một `layer` nữa, một tầng khác cho `conclusion`, hoặc cho `adapt`, hoặc thêm một tầng cho các thông tin kỹ thuật (`technical context`). Nó sẽ lấy `context` từ ba tầng đó. Nếu muốn biết từ đầu đến cuối nó hoạt động như thế nào, thì mình có thể vận hành theo ví dụ như học tiếng Tây Ban Nha chẳng hạn.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/jcn5nn5GPS8?si=Z93MIuCm63-wq-jm&amp;start=3215\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**1:00:10** Em lấy chủ đề là về RP trading đi. What is to learn? Ok, trong team mình có người có hiểu biết để kiểm tra xem câu trả lời có đúng không. Hoặc mình có thể chọn chủ đề liên quan đến RP trading, ví dụ What is to learn?. Trong team mình sẽ có người có hiểu biết để xem thử câu trả lời có đúng không. Ok, ai thử xem nào.\n\nMixture agent này sẽ hoạt động luôn. Mình có một cái LCK đấy luôn. Ok, một cái mới đó là how to learn Chinese. Đợi một chút, cái bài này để giải thích lại cho mấy anh em đang hiểu một xíu nhé. Đây là bài toán trong tuần vừa rồi khi anh em ngồi với nhau. Việc đặt câu hỏi cho AI sẽ quyết định đến việc mình nhận được phản hồi như thế nào và sau đó là tốc độ hấp thụ kiến thức mới của mình sẽ ra sao. Đó là bài toán mà trong tuần vừa rồi tụi mình gặp.\n\n**1:00:45** Khi gặp một chủ đề mới, trước đây mọi người thường dùng Google Search để tìm kiếm thông tin. Sau đó, mình sẽ tổng hợp lại và ghi chép vào tài liệu. Nhưng trong hai năm gần đây, mình không làm vậy nữa. Thay vì dùng Google để tìm kiếm kiến thức, bây giờ mọi người đặt câu hỏi trực tiếp cho các mô hình ngôn ngữ lớn. Tuy nhiên, khi chỉ đơn giản hỏi AI thì kết quả trả về không luôn đúng chất lượng, và đôi khi rất lâu mình mới hiểu được những điểm quan trọng nhất của một chủ đề mới.\n\n**1:01:18** Dụ như về tập Dream, nó sẽ có những chỉ số để đo lường sự thay đổi của cơ thể. Hay như học Tiếng Trung, sẽ có một số khái niệm quan trọng mà mình phải biết. Vậy làm thế nào để mình từ con số 0 có thể nắm bắt được hết những khái niệm đó? Toàn bộ quá trình này là thứ mà tối qua con o1 của ChatGPT đã giới thiệu cho mình.\n\n**1:01:48** Tom đã trải qua cả quá trình đó và sẽ demo lại cho các anh em về cách thực hiện nó. Tôm cũng đã triển khai để team mình có thể sử dụng hiệu quả hơn.\n\n**1:02:43** Có vẻ là có nhiều từ khóa hơn khi đi hỏi từ từ. Với một người không biết gì hết thì nó sẽ không đưa ra nhiều từ khóa như vậy, không nhắc đến mấy cái de, C, hay những thứ tương tự. Chắc phải thử xem CL nó sẽ như thế nào chứ không phải là o1. Em có review không? Để em tạo cái thử. Chắc phải đợi API, nó không có stream. Có lẽ do họ dùng mix agent nên hơi khó để chạy, chỉ có thể tạm chạy trên KP thôi. Hiểu bên kia, nó có diễn giải ở giữa.\n\n**1:03:48** Đúng rồi, thử mở rộng xem mấy cái clip sáng nay, thấy review rồi. Nhìn cũng hợp lý nhỉ, y chang vậy. o1 ở nhà cũng rẻ hơn đấy, o1 ở nhà rồi. Đây là một cái demo về việc có một cái coin giúp quá trình khám phá kiến thức nhanh hơn. Thử hỏi về chuyện tập tay, \"tập taichi?\", xem nó trả lời như thế nào.\n\n**1:04:51** Em gợi ý đủ các kỹ thuật cần thiết không? Có gì không nghe rõ à? Tập CIC trên Discord à? CIC là gì? How to CIC? Ok, thông minh phết nhỉ, nó đưa ra hết mấy cái động tác luôn. Ok, để thử CGR nữa. Wow, nó biết đấy, nó biết đấy. Ừ, ok. Piano thì sao? Đúng rồi, hồi chiều mới hỏi về piano. Thử thử đi.\n\n**1:05:56** Ok, chơi học piano, học viên? Đúng rồi, học viên. Đội mình có ai học nhạc không để kiểm chứng xem. Em thấy số lượng từ khóa về piano nhiều hơn bình thường, dễ để khám phá thêm. Ok, chắc cũng được. Nếu xem history về piano thì sao? Chắc họ cũng bao gồm reg, jazz và những thứ tương tự thôi.\n\n**1:07:01** Ok, nhìn có vẻ ổn. Đúng là có Suzuki Method và những thứ tương tự. Dễ quá! Ông o1 ở nhà xịn đấy. Học piano thì không chỉ có kiến thức mà còn cần thực hành nữa. Phải có thực hành. Thực hành thì tự đi luyện, không thể chỉ ngồi tập trên giấy được. Đang tự luyện, đang học cái gì rồi.\n\n**1:08:05** Ok, chắc là xong một bài. Còn bài nào nữa đáng để VPF không? Cái HC thì đừng bàn nữa, cái prompt em làm cho mixture of agent này đều dùng AI để tạo, không cần viết tay. Đây là quy trình của em: lấy bài đã viết và chuyển thành mixture agent với bốn system prompts: một cái cho reasoning, một cái cho phân biệt input, một cái cho phân biệt output, và cuối cùng là tổng kết.\n\n**1:09:10** Quá trình build là như vậy. Sau đó mình chỉnh sửa từng cái note. Nếu muốn thêm note, chỉ cần thêm system prompt. Nếu muốn chỉnh sửa system prompt, chỉ cần thêm vào. Thực ra, có một system prompt riêng để xử lý câu hỏi logic và tư duy phản biện, nên cũng có một cái riêng cho cái này luôn.\n\n**1:09:55** Cái này chắc để sau, o1 thông minh quá đôi khi người ta không tin. Nếu vậy, bài tiếp theo có thể là làm thế nào để demo một workflow mà mọi người không cần phải code nữa. Mới làm xong cái Office Checking cho team, thực sự không có gì khó cả. Cái này dễ, chỉ cần setup khoảng 10 phút.\n\n**1:10:45** Giờ thì mình cần làm một cái feature, và ngồi trong cái team đó để thực hiện. Cả hai đều là backend, không phải driver, chỉ để AI nó chạy thôi. Có thể dễ dàng setup trong 10 phút không? Ok, thử xem, nhưng cần hơn 10 phút để hoàn thành.\n\n**1:11:49** Để xem, em sẽ lên kế hoạch. Buổi sau, chọn một dự án thật, ví dụ submit một bài báo cáo cho bên for. Lần trước không đủ thời gian để làm, lần này sẽ muốn hands-on hơn. Hãy chọn một dự án khác, coding hiện tại vẫn phải làm bằng tay nhiều, cần tự chỉnh sửa convention.\n\n**1:13:36** Ý là, tự hiểu feature của repo, rồi viết một đoạn code để thực hiện luôn. Giống như làm open source vậy. Sau đó, đi sâu hơn về chiến thuật. Sẽ setup thêm một bản check-in, và cho phép mọi người demo luôn.\n\n**1:14:57** Chọn Go, lấy một cái thư viện, sau đó copy context, để AI tự hiểu cách sử dụng. Khi AI đã hiểu hết, nó sẽ tạo context và giúp tự động document. Sau đó, AI sẽ hiểu function và message, chỉ cần đưa vào input/output.\n\n**1:15:56** Ok, hẹn tuần sau nhé. Mình sẽ chọn một dự án, để team ngồi lại với nhau. Ai cũng sẽ cần làm một script hoặc docker để chạy lên được. Nghệ nhân chọn dự án mà mình chưa biết để thử nghiệm từ đầu. Workflows sẽ cho phép mọi người so sánh cách làm việc với AI.\n\n**1:17:15** Ok, tạm thời là vậy. Hẹn gặp lại mọi người vào thứ tư tuần sau nhé. Mình sẽ hoàn thành các bước còn lại và chuẩn bị cho bài test.\n\n**1:18:05** Hy vọng tháng sau, tất cả anh em sẽ thành thạo các kỹ thuật này. Chúng ta sẽ tăng hiệu suất công việc. Có ai có câu hỏi gì không?\n\n**1:19:44** Ok, vậy nhé, test lại cái workflow. Nếu không còn gì thì hẹn gặp mọi người vào tuần sau nhé. Chúc cuối tuần vui vẻ!\n\n**1:20:46** Đội Phúc hỏi về một bài báo cáo bên team, có thể sắp xếp buổi giao lưu giữa hai team để học hỏi kinh nghiệm về open source và data sản phẩm. Hy vọng buổi OGIF tiếp theo sẽ hiệu quả hơn.\n\n**1:21:29** Hy vọng từ đây đến khi đó, mọi người sẽ nắm được toàn bộ quy trình và không còn phải làm mọi thứ thủ công nữa. Nếu không còn gì nữa thì happy weekend. Chào mừng thêm một thành viên mới lên chức nhé! Chúc mừng nhé.\n\n---\n\n**English Transcript**\n\n**07:25** Can you hear me, Thành? Can you hear me? Ah, I can hear you now. Ok, ok. I received feedback from Discord. Please wait a bit longer.\n\n**10:28** Did we review some figures today?\n\n**11:39** Or should we start right away? Ok, sure. Let’s begin with two reports: first, the financial report for August, and then I’ll present Go Lang Weekly. After that, we have an article related to Go’s “stamina,” right? Let’s move quickly so we can summarize later. I’ve edited the article a bit—it was too lengthy and wordy, so I’ve revised and checked it again.\n\n**12:46** Last week, the core team sent out a survey to everyone. If anyone has feedback about using Go, any challenges, frustrations, or suggestions, feel free to send them through the link attached here. The second article is on the same trend, published on Golang’s blog. This article provides guidance on building a power app. Google has a guide on building an app using Gin only, nothing too special. This is their code, like their server-side run code. We have the full link so everyone can check the detailed code. I think it's pretty usable.\n\n**13:28** Additionally, Go has introduced ZenKit, which is almost identical to Langchain but from Google. It was launched in mid-July. You can take a look. For example, there are vector store interfaces that we can use, like adding documents or similarity search.\n\n**14:22** The next article may interest those into Erlang or Langchain. This framework just released a new version and almost has all the features. Alan is working hard to map it over, and it's almost done. They claim it’s ready for production. Here’s how it runs. I checked the issue list, and there’s nothing complicated. Most of the features are ready. I predict this framework will grow strongly.\n\n**15:22** That’s about it. Do you have any questions? Oh, last time, we worked on an enterprise article, right? Let’s quickly go over it since we won’t have much time for that. Thắng helped me with this article, didn’t you, Thắng?\n\n**16:23** Thắng shared and helped me write this part. There were a few previous articles where I introduced how Go has matured. It's ready for large enterprises to adopt, but it hasn’t fully replaced other languages yet. Some large enterprises still use Java. Switching fully to Go might be too costly. But for new enterprises or those looking to transition, Go is a suitable choice.\n\n**17:26** This article addresses questions like what defines an enterprise standard language, why Go should be used in the enterprise, and which big companies are using Go. These are the follow-up articles, for example, why large enterprises choose Go.\n\n**18:17** Ok, let me summarize the content. Java was developed during the Sun Microsystems era, known for the “write once, run anywhere” philosophy. It’s stable and has full feature support. When enterprises choose a programming language, they typically consider stability and features. Java Enterprise, previously called Java EE, now Jakarta EE, supports synchronous and asynchronous messaging, and formats like XML, JSON, and Protocol Buffers.\n\n**19:11** Moreover, enterprises usually compare Java to C++ because C++ is more complex, requiring manual memory management. Meanwhile, Java has a garbage collector that handles memory management, so users can focus solely on implementation. Furthermore, Java has a large ecosystem, with nearly complete support for all libraries and frameworks.\n\n**20:15** So, what’s the advantage of Java Enterprise compared to C++? At that time, C++ was still popular, but C was getting old—about 20-40 years old. Many older enterprises used COBOL, then switched to C++, while some opted for Microsoft’s C#. But the programming community found that C++ reached a more stable phase.\n\n**21:02** C# is like Microsoft’s own ecosystem. Meanwhile, C++ was more widely embraced by the enterprise programming community. Not everyone used it, but when it comes to enterprise programming languages, Java and C++ were mentioned the most.\n\n**22:14** The next question is why Go is the choice for enterprises and which companies are using Go. The key thing is, when working on this article, I think we should aim to clearly define why Java won, right? Java won against C# and C++. Right now, we need to find a reason to convince someone using Java to switch to Go. There must be a specific reason. In the articles you’re working on, focus on that point—find a reason.\n\n**23:13** The reason might be that Go has solved all of Java’s problems. Maybe Go is better than Java in some ways, or for some reason, now is the time to switch to Go. Maybe add a case study for that. Yes, that’s probably the goal. If you continue working on this, consider structuring each article as a rough question and answer each one with a convincing reason. Then, you can turn it into a slide presentation. Like the first article, try posting it to the Golang community next week and see how it goes.\n\n**24:05** Let’s see what the feedback is. Ok, let’s move on. Quickly go over Thắng’s status. Last month, Thắng had it rough. Have you seen Thắng? Maybe he needs to restart his machine, probably been on Windows for too long.\n\n**25:26** His computer froze. Discord on Windows tends to lag more than on Mac, right? Mac is much smoother. Ok, I can hear you now. Ok, clear now. Let’s continue.\n\n**26:31** This month’s report is similar to last month. Some articles aren’t new, but I’ve collected what I found relevant. Let me quickly go over it. I have everything ready, so let’s finish this. First up, React 19 AC. It was released back in April, but last month was when the full report came out. Basically, it still focuses on supporting server components and improving asynchronous script management. This is just a friendly reminder for those who haven’t read it yet to take a look.\n\n**27:17** Personally, I find React getting more complex, so I’m going to avoid version 19 for now. It’s like React has some new hooks, but it feels like we could have achieved the same with the existing hooks. But they’ve wrapped them up and created new utility hooks. I think it’s fine, but the problem is that a platform like React is becoming more and more complex, and I feel like it’s losing its original simplicity. Initially, it was just a simple building tool, but now they’re adding things that feel a bit unnecessary.\n\n**27:55** Next up, Next 15. My thoughts on this are similar. Next 15 AC also supports React 19 AC with some improvements. What I found interesting is the React compiler. It optimizes React code. You can skip using hooks like useMemo and useCallback, which nearly 90% of React users need to use. Now, with this new feature, you don’t need those hooks anymore.\n\n**28:39** This is cool, but the problem is other things, especially the app router of Next.js. I talked to Thành about it, and he seems fed up with Next.js too. I read through the comments, and the community seems confused. Every week, there’s someone asking whether it’s necessary. Their current stack is still fine, but both React and Next.js are getting more complicated. It’s like when OpenAI switched from Next.js to Remix. It feels like the market is shifting.\n\n**29:17** It’s similar to how OpenAI switched from Next.js to Remix. The community’s sentiment is shifting toward more efficient solutions. Next and Nest are still okay, but personally, I find them getting more complex, especially the app router. Since Next.js 10, 12, 13, I haven’t used it much. Even though it’s the main stack, it doesn’t seem to be the main stack anymore.\n\n**29:56** Speaking of the main stack of Next.js, it’s still the main stack, something like that. Related a bit to Vercel, the video is quite good. It demos the power of Vercel combined with shadcn. Shadcn is a UI library built with Tailwind. Vercel has a design component that allows you to import it into v0 to build, which is interesting. I haven’t had the chance to play around with it yet, but from the video demo, building games, forms, and 3D with Three.js looks interesting.\n\n**30:48** That video is impressive, so I’m interested in Vercel. Ok, next up is JavaScript. This is an issue I find very relevant, even though it’s still just a proposal. It’s about handling dates in JavaScript. Anyone doing front-end work and dealing with dates, especially time zones, knows this is a complicated problem. This proposal promises to fix that. Hopefully, it will be released soon. It’s something to look forward to.\n\n**31:32** Another thing—am I sharing the right screen? Can you see my screen? My screen is working fine, but on your side, it seems stuck in one position. Ok, I’ve re-shared it. Can you see now? Let me lower the resolution to 700p. Ok, next up is CSS. This has been around for a while, but I read an article about it last month. I included it in the report. It’s an interactive tutorial about using CSS Grid instead of Flexbox. When I read this, it reminded me of something funny about CSS.\n\n**32:35** The funny thing is about CSS3. Now, when you go for job interviews, they still mention HTML5 and CSS3, but CSS3 was released over a decade ago. They’re now talking about CSS4, which has been in development for a few years. CSS5 is currently in progress with some proposals. But for some reason, the dev community still refers to CSS3. It’s like with Grid, which was released long ago, but not all browsers supported it fully at first.\n\n**33:17** CSS Grid has been out for a while, and now almost all browsers fully support it. People should consider moving away from Flexbox and switching to CSS Grid. Ok, next up is another section—'A Web a Week.' rb just released version 1.0, and as always, they compare its speed with WebP. WebP is already fast, but now rb seems even faster. Everyone can check out rb.\n\n**34:42** Another one is fity, which I discovered by accident. It lets you build forms using JSON, which is interesting because it aligns with my thinking. It’s like the first project I did with a Malaysian client, something like their ‘chợ tốt’ there. Muda also uses buf with JSON to provide schema, which then renders the form. It’s a really interesting approach.\n\n**35:30** Another one is i18n, which is a community focused on clean up, fit up, and level up. They go around finding libraries like Lodash to clean them up and optimize them, creating lighter, cleaner alternatives. This community has built quite a few things already. I think the group’s goal is really cool, but I haven’t actually used the tools they’ve built yet.\n\n**36:13** Ok, let’s wrap up with a short article on 'Top Programming Languages.' This might interest people—the top programming languages of 2024. I’ll take a look. Ok, from top to bottom, Python is still number one. I don’t know how they rank it, but Python is at the top, followed by Java, and then JavaScript. C++, TypeScript are also on the list. I’m not sure how they’re collecting data since they didn’t explain, but for dev jobs, SQL, Python, Java, and TypeScript seem to be doing fine. That’s what I think.\n\n**37:07** That’s everything I’ve gathered from last month. Ok, now talking about a scraper. Yes, a scraper will have a mid-month post in 2-3 days. I’ll try to do one post every two weeks. If I stretch it out to a month, I feel like I’ll miss out on a lot of information since there’s too much, so maybe I’ll just work on a little bit every day. Both frontend and backend are like that, right? Ok.\n\n**38:11** Hey, LP, did you finish that article yet? The one related to Thới, have you finished that one? Oh, not yet? I haven’t wrapped up either. The bot has been able to crawl, but I still need to add a backend server for the Discord bot. I haven’t done that yet, but the bot is already running.\n\n**38:55** Before Tom takes over, I have a few announcements. First, last week we rolled out some updates. Related to adopting EOM to improve team productivity, I posted an initiative. If team members can develop or use cilus to a certain level, there will be ICY rewards for everyone. The task list will be on our workland, and it’s fairly easy to understand.\n\n**39:44** For example, TnT’s post, it’s an article related to this concept. He wrote an article on learning Spanish. It’s not directly related, but he demoed the bot for everyone last time. I expect that everyone will get used to asking AI using system prompts, then deploying. Most of 4C’s articles have been completed. How to prompt and execute is something everyone can review and run exactly like that.\n\n**40:31** As for the other parts, we’ll see what else needs to be done. Pish’s work from last week is here, let me show you quickly. What you’re seeing is the result of the process of creating the script that T did. The whole prompt process to get this result took just a few seconds, including all the necessary information, and then spored into a system prompt, which was uploaded to the defile for everyone to use. Over here is where you can use it. This defile can be tripped into an API, and if you want to use it, you can call the API like a serverless function. Call the API, and it will return the result. Then, you just need to input it into Discord or other interfaces.\n\n**41:13** For example, this post, it will link to the context in the working environment. When you input a topic, it will generate a syntax to insert. One side compares two types of sentences or languages and provides two or three possible responses from colleagues. After that, you can decide how to respond. It also suggests some knowledge that you can pick up from the conversation.\n\n**42:17** Right now, you’re seeing on the screen the system prompt and the output. In the table I requested, I need a bit more detail. To track everyone's learning process, I’ll need a problock. If you don’t have cilus or ChatGPT, you can request to use them with our team. We’ve already loaded some keys, so just take and use them, no problem.\n\n**43:04** For example, nearly the entire perspective we have right now is at the most basic level. Our team needs to understand how to use these AI tools as part of their daily work. About two years ago, our team already started using them, but the way of asking questions and extracting information from large data models wasn’t very effective. I shared my ChatGPT account with a few members of the team, and from my observation, the way it's being used isn’t optimized yet.\n\n**43:41** This is the reason we’re doing this exercise. At this stage, everyone needs to try and learn to build cot so that later we will have the necessary tools to assist our work. Each to-do on here corresponds to our perspective—it will become a cilus tool for individuals or the team to increase work speed. From writing docs to breaking down tasks to supporting writing requirement tickets, to knowing how to choose chai (API) from the context provided.\n\n**44:32** That’s the first thing everyone should pay attention to. A reminder from last week, we also talked about team outings. Right now, Huy Nguyễn is preparing. Huy Nguyễn, how far along are you, according to your estimate?\n\n**45:35** Awesome. Ok, that part is done. The support policy for everyone will have some adjustments. Right now, the budget seems a bit big—it’s rising to around 500-600 per person, which is a lot compared to the current situation. So there will be some conditions attached. Two main things: first is what we mentioned about using large language models, and team members will need to pass a test created by the team.\n\n**46:14** Actually, now I’m seeing a big difference between those who know how to use tools and those who don’t. It’s a very noticeable gap. It’s not completely 100%, but around 60-70%. For more complex problems, it’s hard, but we can still see the necessary skills. So, if we don’t learn now, it will be tough later to compete with others in the team, especially those who have already mastered the tools.\n\n**47:01** So, this is a required step. Tom and Huy Nguyễn will design the test. Start thinking about that for me. Since there are different roles in the team, there will be appropriate tasks, but the common requirement is to understand how large language models work. It’s not necessary to know all the details of the dataset, but we need to know how to use the tools, set them up, and use them to speed up our work.\n\n**47:51** That’s task number two. Huy Nguyễn and Tom will help design the test. Once you pass it, you’ll be more comfortable, not feeling stressed at work anymore. According to the plan, we’re aiming to finish by December, right? There are about 2-3 months left for everyone to study and get ready. This will be the new standard for our team.\n\n**48:37** The third issue relates to planning for team building. Last week, we discussed getting back to the office and hybrid work. We will begin supporting people to come back to the office to build better connections. Some have already started going back. Tom is also supporting the return to the office, so those who want to ‘make up’ their work can come to the office. The AI Club that Tom is leading has now been turned into a channel in the team, but invites are only sent under certain conditions.\n\n**49:22** I feel that whoever is ready to learn and ask reasonable questions will be invited to this group. A few people are already looking into it. It was just created this afternoon, so we’ll gradually transition people in. This is also related to the need to change passwords since they’ve been exposed on the stream. Over the next week, the expectation is that people will spend 1-2 days at the office. If staying at home feels too distracting or you need to interact with family too much and it’s hard to focus on work, just come to the office 1-2 days a week.\n\n**50:08** When people check in, Tom and Vi have set up the check-in feature at the office. If you connect to the office Wi-Fi, the system will recognize it and send a bot notification to the lobby channel. It’s a bit spammy now, but it will be fine-tuned. After that, the team will support parking fees and provide a bonus of around 5 IC along with lunch subsidies. These are the three main announcements for the past week regarding everyone’s benefits. Pay attention to that.\n\n**51:10** Now, I’ll hand the stage over to Thành to continue with the topic. Hiếu’s topic from last week can be postponed to next week. Hiếu had a topic on database references and circular references last week. Ok, I’ll do it now. Let’s go. Today, I’ll share about the AI Comment we created for the team. Actually, AI Comment uses the same method as building a prompt or completion—it’s just about how to get specific input and output.\n\n**51:58** It will become a simple chatbot. In this bot, it will copy the things from before, like the output from sunbot. It will take the base case from sunbot. The switch cases related to Memo questions, for example, if you ask ‘What are the latest notes?’, it will switch to the instructed commands to find and reply. Or it can query below for our team. Nothing complicated, just think of three basic outputs, each providing the necessary results.\n\n**52:44** That’s the introduction. For those worried about asking dumb questions and getting penalized, this is the solution—an auto-solution. This will automate everything for you. We create an agent to automate this process. This is also the method OpenAI uses, called mixture of agents. Each agent will talk to itself to better understand what you need, and then give you the desired results. For each question, if there’s no input, just let the AI infer everything. No need for complex prompts.\n\n**53:27** If there’s no output, let the AI infer that too. What’s the purpose of the output? Let the AI figure it out. See if it needs technical, medical, or any other related information. AI will know on its own, no need for a complex prompt. There are some templates I’ll try out for everyone to visualize. For example: ‘How to learn Chinese.’ Even if I input this into ChatGPT or Club, sometimes it gives the right answer, sometimes not, because it doesn’t fully understand what I mean.\n\n**54:04** If I say I want to learn Chinese for competition or something specific like HSK, OpenAI can give a more accurate and detailed response. Yes, I can easily copy that, but the process might take 1-3 steps for AI to reason it out. It will infer from what the user is trying to do. This can be copied to a mixture of agents for more effective use.\n\n**54:45** Mixture agent will run immediately. We’ve already set up an LCK for that. Ok, something new—‘how to learn Chinese.’ Wait a minute, let me explain a bit for those who are still confused. This is the problem we faced last week when we were sitting together. Asking questions to AI will determine what kind of response we get and how quickly we absorb new knowledge. That’s the problem we faced. The task is this: when there’s a new topic, we have to approach and learn it.\n\n**55:30** Before, people used to Google search for information, then compile it and record it into their documents. But in the last two years, that method has changed. People no longer search for knowledge through Google but instead ask large language models (EOM). However, simply asking an EOM might not yield high-quality answers, and it can take a long time to understand the core knowledge of a new topic.\n\n**55:59** For example, Dream training has metrics to measure body changes. Or, for example, learning Chinese, there are key pieces of knowledge you need to know. How do you go from zero knowledge to learning all that? This is the process that ChatGPT’s O1 introduced yesterday. Tom has gone through this process of thinking and implementation, and today, Tom will demo how it works and show how Tom has deployed it for our team. The team can use it more effectively.\n\n**56:36** Yes, that’s right. Ok, let’s move on to ‘How to learn Chinese.’ For me, when searching, I want to find keywords related to competition or specific keywords like radical or stroke order. Mixture agent will infer all of that. It knows what I want to learn and what I need. It will provide a full response—it might give too much information, but better too much than too little. There’s even code. It’s easy to understand.\n\n**57:18** The advantage of this method is that I can go even deeper, like with HSK6. Don’t know what HSK6 is or how to get a certain score? It will infer everything from the conversation history. If I want to learn Chinese to take HSK6, it will explain it all and even give me a study regimen. This is a great method if you’re not familiar with writing prompts and don’t want to be penalized for writing poor prompts.\n\n**58:11** Mixture agent is deep and may provide extra information, but it helps you be more precise. When Together AI designed the inference engine, they noticed that responses from large language models (LLMs) are really fast. So, they thought, why not run multiple LLMs simultaneously and then synchronize the information for AI to give a more accurate answer?\n\n**58:55** Actually, Together AI and another team only used the Lama model, and they beat GPT-4. The condition is that you need to provide enough information for AI to infer. It needs to know the input, the output, the math, chemistry, or whatever field. You’ll enter all of that here. The design of mixture agents is quite simple. It has a system prompt related to reasoning to help AI infer things related to math and chemistry. It will pull out important keywords to answer.\n\n**59:37** For example, if you want to learn Chinese, your input is in English because you responded in English. The output is the method to learn Chinese. Then, an aggregator will organize all this information and provide a very intelligent response. The heaviest part is here, but you can add another layer for conclusion, or for adaptation, or a technical layer. It will take context from those three layers. If you want to know how it operates from start to finish, you can run it as an example, like learning Spanish.\n\n**1:00:10** Let’s take a topic about RP trading. What is to learn? Ok, we have someone in the team who knows this. Or, we can choose a topic related to RP trading. For example, what is to learn? We have someone in the team who has insight into this to verify the answer. Ok, let’s see what it says.\n\nThis mixture agent will run immediately. We’ve already set up an LCK for that. Ok, something new—‘how to learn Chinese.’ Hold on, let me explain a bit for those who are still confused. This is the problem we faced last week when we were sitting together. Asking questions to AI will determine what kind of response we get and how quickly we absorb new knowledge. That’s the problem we faced.\n\n**1:00:45** When faced with a new topic, in the past, people used Google search to find information. Then, they would compile it and write it down in their documents. But in the last two years, we don’t do that anymore. Instead of using Google to search for knowledge, people now ask large language models. However, just simply asking AI doesn’t always give high-quality results, and sometimes it takes a long time to understand the key points of a new topic.\n\n**1:01:18** For example, in Dream training, there are metrics to measure body changes. Or in learning Chinese, there are some key concepts you need to know. So how do you go from zero knowledge to grasping all these concepts? The entire process is something that ChatGPT’s O1 introduced to me last night.\n\n**1:01:48** Tom has gone through this whole process and will demo it for everyone. Tom has also implemented it so our team can use it more effectively.\n\n**1:02:43** It seems there are more keywords when you ask step by step. For someone who knows nothing, it won’t give that many keywords, and it won’t mention de, C, or anything like that. Let’s try seeing what CL will do, not O1. Did you review it? Let me create a test. Probably have to wait for the API, it’s not streaming. Maybe because they’re using a mixture of agents, it’s hard to run, so it’s just running on KP for now. I understand, the other side has explanations in between.\n\n**1:03:48** That’s right, try expanding and see the clips this morning. I saw a review, looks legit, right? Looks just like that. O1 at home is cheaper too, O1 at home already. This is a demo of having a coin that helps the knowledge discovery process go faster. Let’s try asking about hand exercises, \"taichi exercises?\" and see how it responds.\n\n**1:04:51** Did you suggest all the necessary techniques? Is there anything unclear? Hand exercises on Discord? What’s CIC? How to CIC? Ok, pretty smart, huh? It even gives all the steps. Ok, let’s try CGR too. Wow, it knows, it knows. Ok, how about piano? Yes, we just asked about piano this afternoon. Let’s try that.\n\n**1:05:56** Ok, playing piano, a student? Yes, a student. Does anyone in our team play music to verify this? I see there are more keywords about piano than usual, easier to explore further. Ok, looks fine. If we look at piano history, what will it say? It probably includes reg, jazz, and things like that.\n\n**1:07:01** Ok, looks good. It even mentions Suzuki Method and similar things. Too easy! O1 at home is great. Learning piano doesn’t just require knowledge, you need practice too. You need practice. You can’t just learn on paper, you have to practice yourself. Currently practicing, studying something.\n\n**1:08:05** Ok, I think we’re done with this one. Any other lessons worth doing for VPF? The HC one, let’s not discuss that. The prompts I created for this mixture of agents were generated by AI, no need to write manually. Here’s my process: take the written piece and convert it into a mixture agent with four system prompts—one for reasoning, one for input identification, one for output identification, and finally a summary.\n\n**1:09:10** That’s the build process. After that, we’ll adjust each note. If we want to add a note, just add a system prompt. If we want to adjust the system prompt, just ask to add it in. In fact, there’s a separate system prompt for handling logical questions and critical thinking, so there’s one specifically for that too.\n\n**1:09:55** This one might be left for later, o1 is so smart that sometimes people don’t believe it. If that’s the case, the next task might be to demo a workflow where people don’t need to code anymore. I just finished the Office Checking for the team, honestly, there’s nothing hard about it. It’s easy, just need about 10 minutes to set it up.\n\n**1:10:45** Now we need to make a feature, and sit in the team to implement it. Both are backend, not drivers, just let AI run it. Can we set it up in 10 minutes? Ok, let’s try, but it might take more than 10 minutes to complete.\n\n**1:11:49** Let’s see, I’ll plan it out. Next session, pick a real project, for example, submitting a report for the for team. Last time, we didn’t have enough time to finish, this time we want to be more hands-on. Let’s pick a different project. Currently, coding still requires manual work and adjusting conventions.\n\n**1:13:36** Meaning, we need to understand the feature of the repo and then write a piece of code to execute it. It’s like doing open source. After that, go deeper into strategy. We’ll set up another check-in and let everyone demo it.\n\n**1:14:57** Pick Go, take a library, copy the context, and let AI understand how to use it. Once AI understands it fully, it will generate the context and help auto-document it. Then, AI will understand the function and message, just input/output it.\n\n**1:15:56** Ok, see you next week. We’ll pick a project so the team can sit together. Everyone will need to create a script or Docker to run it. The master artisan will pick a project that we don’t know yet to test it from scratch. The workflows will allow everyone to compare how to work with AI.\n\n**1:17:15** Ok, that’s about it. See you next Wednesday. We’ll finish the remaining steps and prepare for the test.\n\n**1:18:05** Hopefully next month, all team members will be proficient in these techniques. We’ll increase work efficiency. Any questions?\n\n**1:19:44** Ok, that’s it. Let’s test the workflow again. If there’s nothing else, see you all next week. Have a great weekend!\n\n**1:20:46** Phúc’s team asked about a report from their team, maybe we can arrange a meeting between the two teams to share experience on open source and product data. Hopefully, the next OGIF session will be more productive.\n\n**1:21:29** Hopefully, by then, everyone will fully understand the process and no longer have to do everything manually. If there’s nothing else, happy weekend. Welcome a new team member to their new role! Congratulations!\n","title":"OGIF Office Hours #23 - Go weekly, Frontend report, Hybrid working support, and AI mixture agent","short_title":"#23 Go weekly, FE report, Hybrid work, AI agents","description":"In OGIF Office Hour 23 covered a variety of topics, including updates on Golang Weekly and its use in enterprise environments, comparing Go with Java and C++. The session explored the latest trends in React 19 AC, Next.js, and CSS Grid, alongside new form-building tools. Additionally, the team discussed productivity enhancements using AI-driven solutions like mixture agents, while introducing upcoming tests and hybrid work support.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Mon Sep 16 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/23-20240913.md","slugArray":["updates","ogif","23-20240913"]},{"content":"\n85 minutes\n\n### Topics and Highlights\n- Live coding demo showcased data engineering techniques.\n- Introduced Agent Zero for automated data processing.\n- Demonstrated data cleaning and analysis using CSV files.\n- Generated infographics from backend technology data.\n- Figma to code conversion for UI components.\n- AI integration for automating repetitive tasks.\n- Discussed team collaboration and knowledge sharing.\n\n---\n\n**Vietnamese Transcript**\n\n**00:00** Ok, mọi người nghe rõ chưa? Chúng ta còn khoảng 12 phút nữa để Tom có thể demo live coding. Tuy nhiên, có lẽ sẽ không kịp hết phần này, nên mình sẽ chuẩn bị một phần demo về Data Engineering trước. Tom, bạn có thể bắt đầu được rồi đấy. Ok, chào mọi người, mình sẽ giới thiệu một phần demo liên quan đến Data Engineering. Phần này tập trung vào việc làm sạch dữ liệu với sự hỗ trợ của AI, để chúng ta có thể bắt đầu tiến hành phân tích dữ liệu hoặc chuẩn bị dữ liệu ban đầu.\n\n**04:37** Mình sẽ chia sẻ màn hình nhé. Không cần dùng Zoom đâu. Ok, mọi người thấy màn hình rồi chứ? Ok, mình sẽ giới thiệu về dataset mà chúng ta sẽ làm việc hôm nay. Thực sự thì có rất nhiều loại dữ liệu mà chúng ta có thể làm sạch bằng một công cụ gọi là Agent Zero. Hôm nay mình sẽ sử dụng một dạng dataset kiểu như là lấy thông tin từ một nguồn nhất định, và sau đó đưa ra một file CSV. Cái CSV này thực sự rất lộn xộn, như là nó sắp xếp kiểu từng phần từng phần vậy, và việc làm sạch từng phần đó là khá khó. Thực tế, họ chia ra từng trang web, từng phần nhỏ. Vậy làm thế nào để chúng ta có một bộ dataset hoặc một infographic tổng hợp hết tất cả thông tin trên một file? Mình sẽ demo điều này cho mọi người xem.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/lAk1QSl7qS0?si=o-UbAP-JNwGuSrpm&amp;start=347\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**06:22** Agent Zero là một công cụ AI Agent, và bạn chỉ cần nói với nó bằng ngôn ngữ tự nhiên, nó sẽ tự động viết code cho bạn. Ví dụ, vấn đề của mình nằm trong thư mục 'ph', thì mình sẽ chỉ nói với nó là: \"Look into the ph folder and help me process all of the CSV files. I want to do some data analysis to understand what backend technologies all of these sites are using and aggregate all of them.\" Có vẻ như UI bị lỗi một chút, nhưng mình đang muốn phân tích các công nghệ backend mà các trang web này đang sử dụng. Agent Zero sẽ dùng GPT-4 hoặc GPT-4 mini để thực hiện tất cả công việc này.\n\n**08:25** Nếu như nó gặp lỗi thì nó sẽ sửa lỗi đó thôi. Quy trình của Agent Zero có hai phần: một là nó sẽ chạy code, và phần còn lại là nó sẽ kiểm tra lại xem code đó chạy có ổn không. Ở đây, nó đã phát hiện ra lỗi rồi, nên nó sẽ tự động sửa lỗi đó cho mình. Hiện tại mình chỉ cần nói cho nó biết mục tiêu của mình là gì, và nó sẽ tự động viết code cho mình, từ đó mình có thể bắt đầu phân tích dữ liệu của những trang web mà mình đã tải về, chuyển đổi chúng thành các file CSV và làm sạch dữ liệu.\n\n**09:06** Giờ thì mình sẽ yêu cầu nó tạo ra một infographic để tổng hợp tất cả các công nghệ backend mà các trang web đang sử dụng. Mình muốn một cái hình ảnh trực quan để dễ dàng phân tích. Vậy nên, mình sẽ yêu cầu nó là \"Create me an infographic inside the 'ph' folder to aggregate all of the backend programming languages which are used across all CSV files.\" Sau đó nó sẽ tự động vẽ cho mình một biểu đồ bằng cách sử dụng thư viện matplotlib và xuất ra một hình ảnh PNG. Nếu nó gặp phải lỗi, nó sẽ tự động tải các thư viện cần thiết thông qua pip và tiếp tục quá trình. Quá trình này giúp tự động hóa hầu như tất cả những mong muốn của mình liên quan đến việc xử lý dữ liệu. Nó sẽ giữ lại tất cả những gì đã làm để mình có thể kiểm tra lại sau.\n\n**09:58** Hiện tại, mình không muốn xem từng file kết quả nên mình sẽ yêu cầu Agent Zero đưa toàn bộ output vào thư mục 'ph' để mình dễ dàng quản lý. Sau đó, nếu mình cần sử dụng lại sau này, mình chỉ cần quay lại thư mục đó thôi. Giả sử mình cần thực hiện thêm các bước xử lý khác thì nó cũng sẽ rất tiện lợi.\n\n**10:56** Bạn có thể thấy là với các bài toán như kiểu tạo một trình duyệt crawler, thực ra mình cũng có thể sử dụng cách tương tự để làm. Agent Zero sẽ đọc cấu trúc trang web, sau đó tải kết quả lên cho mình, và mình chỉ cần chỉ định các thẻ HTML, CSS mà mình muốn lấy dữ liệu từ đó. Thay vì phải tự viết code thủ công, giờ mình có thể nhờ nó làm luôn.\n\n**11:42** Ví dụ như trong trường hợp này, mình thấy cách dễ nhất là mình chỉ cần xóa một vài cái entry không cần thiết, sau đó thêm một vài dòng mới để làm sạch dữ liệu. Nếu mình muốn tạo một đoạn code cho việc phân tích dữ liệu hoặc chỉ đơn giản là mình muốn tải một video YouTube và lấy 10 giây đầu tiên của nó, thì Agent Zero cũng có thể giúp mình làm việc đó. Ví dụ nhé, mình sẽ thử sao chép URL của một video YouTube và yêu cầu nó \"Download this YouTube video and cut out the first 30 seconds of it.\" Agent Zero sẽ tự động code cho mình, sử dụng terminal, tải video xuống và cắt đúng 30 giây đầu tiên như yêu cầu.\n\n**12:37** Trong quá trình thực hiện, nó sẽ tự động sử dụng terminal, tải video xuống và cắt phần cần thiết. Tuy nhiên, đôi lúc nó sẽ gặp phải một vài vấn đề nhỏ, như việc chọn module backend nào để xử lý quá trình này, chẳng hạn như nó đang dùng GPT-4 mini. Bạn có thể thấy nó thực sự đang sử dụng nhiều công cụ khác nhau để đảm bảo hoàn thành tác vụ một cách chính xác.\n\n**13:41**  Có vẻ như nó đang gặp lỗi khi tải xuống hoặc cắt video. Lúc này, mình chỉ cần hướng dẫn lại cho nó một chút, hoặc yêu cầu nó xóa video đang tải về và thử lại. Đây là quá trình tự động hóa gần như hoàn toàn, và rất tiện lợi cho những tác vụ lặp đi lặp lại.\n\n**14:54** Vì đây là một video dài, nên có thể demo sẽ hơi chậm. Mình có thể thử lại với một video ngắn hơn để xem nó hoạt động như thế nào. Giờ mình sẽ copy lại URL của video ngắn hơn, và yêu cầu \"Download this YouTube video and get the first 30 seconds.\" Quá trình này đôi khi sẽ chạy hơi lâu, nên mình chỉ cần chờ đợi một chút, hệ thống AI sẽ xử lý và hoàn thành.\n\n**16:01** Có một số vấn đề nhỏ, ví dụ như phòng làm việc hiện tại của mình có thể không cho phép tải xuống YouTube video, nên quá trình sẽ chậm một chút. Nhưng về cơ bản, nếu bạn muốn làm những tác vụ như phân tích dữ liệu trên web, hoặc cần một công cụ auto agent để xử lý các tác vụ phức tạp, thì Agent Zero là một lựa chọn tuyệt vời.\n\n**17:43** Mình có thể tạo ra một auto agent để xử lý những trường hợp như thế này, ví dụ như việc tải video, phân tích dữ liệu, hoặc xử lý các tác vụ từ phía backend. Agent Zero sử dụng GPT-4 mini hoặc các mô hình khác tùy theo yêu cầu, và có thể thực hiện các tác vụ phức tạp một cách hiệu quả.\n\n**19:00** Đến đây, nếu bạn muốn đi sâu hơn về việc sử dụng Agent Zero để tạo ra code, hoặc tạo các infographic trực quan từ dữ liệu, bạn hoàn toàn có thể yêu cầu nó xuất ra các định dạng khác như CSV, JSON, hoặc thậm chí là biểu đồ dạng Parquet. Nếu dữ liệu của bạn quá lớn và không muốn sử dụng AI vì tốn token, bạn có thể tương tác với hệ thống thông qua các database như Dgraph DB hoặc các hệ thống khác. Agent Zero sẽ giúp bạn tạo ra các câu lệnh query cần thiết, và bạn có thể tương tác với cơ sở dữ liệu mà không cần phải tự viết code từ đầu.\n\n**20:09** Dữ liệu hoặc là Data Engineer, mình có thể yêu cầu nó viết cho dạng Pandas (Pandas DataFrame) chẳng hạn. Ồ, hình như nó bị chặn rồi thì phải [âm nhạc vang lên]. À, đúng rồi, chắc là do văn phòng này bị chặn rồi, vì vậy có thể nó không tải được từ mạng bên ngoài. Nhưng nếu mình muốn đi sâu hơn vào việc viết code hay tạo một infographic để mình có thể hình dung dữ liệu dễ hơn, thì mình có thể cho nó xuất ra một cái file CSV hoặc JSON. Điều tuyệt nhất là nó cũng có thể biên dịch dữ liệu sang định dạng Parquet nếu cần thiết.\n\n**21:13** Nếu mình có một bộ dữ liệu khá lớn và không muốn dùng AI để xử lý vì sẽ tốn nhiều token, thì mình có thể nhờ Agent Zero tạo ra code cho mình và nó sẽ sắp xếp dữ liệu thành các cấu trúc theo yêu cầu. Ví dụ như lúc đó mình có thể tương tác với một cơ sở dữ liệu như DgraphDB hoặc là bất kỳ dạng cơ sở dữ liệu nào, Agent Zero sẽ giúp mình query dữ liệu đó mà không cần phải viết quá nhiều code thủ công. Như vậy, mình có thể tương tác với dữ liệu mà không cần can thiệp trực tiếp nhiều.\n\n**22:04** Rồi, các bạn có câu hỏi gì cho phần này không? Nếu không thì chúng ta sẽ chuyển sang phần tiếp theo nhé. Ồ, mọi người thắc mắc là Agent Zero này khác gì với mấy cái Framework mà chúng ta đã từng show trước đây nhỉ? Thực ra, khác biệt ở chỗ Framework thì mình phải viết code rất nhiều. Còn với Agent Zero, mình không cần phải code bất kỳ thứ gì. Cụ thể là nó sẽ tự động tạo công cụ và xử lý các yêu cầu. Trong khi với các Framework thông thường, bạn phải tạo một Agent, thêm công cụ và thiết lập một Runner để nó có thể thực hiện các đầu ra từ công cụ đó. Agent Zero sẽ tự động tạo công cụ luôn, mình không phải làm gì cả. Để mình kiểm tra xem nó lưu dữ liệu ở đâu nhé.\n\n**22:44** Nó có một thư mục riêng bên trong Agent Zero, khi nó hoàn thành một tác vụ, nó sẽ lưu lại vào bộ nhớ của mình, cụ thể là trong SQLite. Bộ nhớ này sẽ lưu trữ tất cả các công cụ đã được tạo ra và các đoạn code liên quan. Ví dụ, nếu mình chưa có công cụ để tải xuống video từ YouTube, thì nó sẽ tự tạo ra. Nếu mình muốn đào dữ liệu từ Facebook chẳng hạn, nó cũng sẽ tự động tạo ra công cụ để làm việc đó. Và khi mình yêu cầu lại, nó sẽ dùng lại bộ nhớ Cache của công cụ đó. Thỉnh thoảng, nếu quá lâu không sử dụng, Cache có thể sẽ bị xóa, nhưng nói chung nó sẽ lưu lại cho mình. Nó hơi khác với Auto-GPT ngày xưa.\n\n**23:21** Trước đây, khi sử dụng Auto-GPT, nếu bạn muốn tạo ra một ứng dụng kiểu như để phục vụ phỏng vấn hoặc lấy thông tin từ web, bạn phải tạo một công cụ trước, viết code cụ thể cho từng tác vụ đó. Với Agent Zero, bạn không cần code gì cả, nó sẽ làm tất cả cho bạn. Như khi anh Ngọc Thành từng làm, anh ấy phải code tay mọi thứ, còn mình thì không cần làm gì cả và đã có kết quả rồi. Chính vì thế, môi trường và cách tiếp cận của Agent Zero là một công cụ tự động thực sự, không cần bạn phải can thiệp quá nhiều như các Framework khác.\n\n**24:05** Vậy cấu trúc kiến trúc của Agent Zero có gì đặc biệt so với các công cụ khác? Thực ra, mình thấy nó đặc biệt ở chỗ mình có thể dùng nó cho các tác vụ liên quan đến Data Analysis hoặc Data Engineering một cách rất đơn giản. Ví dụ, nếu bạn có một file MP3 và muốn lọc ra các âm thanh lạ, thì nó có thể giúp bạn thực hiện điều đó. Mình còn nhớ là khi có một file PDF lớn, mình cần chia nhỏ nó ra hoặc gom lại, Agent Zero cũng làm điều này rất tốt.\n\n**24:59** Tuy nhiên, nếu yêu cầu phức tạp hơn thì có lẽ nó chưa thực hiện một cách hoàn hảo, ví dụ như nếu mình muốn tạo một biểu đồ 3D Plot hoặc một Scale Plot thì nó sẽ hiểu nhưng chưa chính xác lắm. Vì vậy, Agent Zero chỉ đóng vai trò như một \"starting point,\" tức là một trợ lý Junior, và từ đó bạn sẽ tiếp tục hoàn thiện các tác vụ trên nền tảng này.\n\n**25:49** Ồ, mình vừa thấy có yêu cầu xử lý một file PDF tiếp theo. Ok, để thử xem nhé. Bạn muốn nó làm gì với file PDF này? Chuyển đổi sang Markdown à, hay bạn muốn nó tạo ra một file Altic? Điều này sẽ khá thú vị để xem khả năng xử lý của Agent Zero. Có vẻ bị chồng chéo (trùng lặp) dữ liệu hay sao ấy? Bây giờ mình sẽ thử tải xuống lại một lần nữa. Để nó tự tải xuống cho mình hoặc mình sẽ tự điều chỉnh menu này để nó tự động. Mình sẽ thử điều chỉnh thêm.\n\n**27:11** Được rồi, mình sẽ đặt tên cho thư mục là \"Fusion.\" Ok, để xem bên trong có gì không. Ồ, hình như có cái ảnh trong đó. Bây giờ yêu cầu Agent Zero trích xuất ảnh ra từ file PDF này. Bạn muốn lấy cái ảnh nào trước nhỉ? À, hình ảnh trước nhé. Được rồi. “Help me grab the images inside the Fusion PDF into a separate folder.” Ok, đây là những hình ảnh này rồi. Chúng đã được tách ra. Nhưng có vẻ nó đã biết cách cắt đúng vị trí.\n\n**29:25** Chắc chắn rồi, mình nghĩ nó đã lấy được hình ảnh đó từ thư viện (Library). Chúng ta cần phải tinh chỉnh lại một chút để chuyển đổi từ định dạng JPEG sang PNG. Nó sẽ loại bỏ được phần nền trong suốt nữa. Xong rồi, tất cả đã hoàn thành. Tuyệt vời, tuyệt vời, mọi thứ đều ổn định.\n\n**29:39** Bây giờ chúng ta mở thử file Preview xem sao, liệu có ổn định và chính xác không nhé. Thật sự là uy tín hơn, hơn là khi mình làm thủ công mà tốn rất nhiều thời gian. Nhờ có Agent Zero, mình đã không phải viết code từ đầu, nó đã làm tất cả cho mình rồi. Tuy nhiên, một nhược điểm là nếu có các đoạn bảng (table) trong file PDF thì nó sẽ chỉ trích xuất chúng dưới dạng hình ảnh thôi. Không thể giữ được format của bảng như trong file PDF gốc. Nhưng cũng tạm được, không vấn đề gì.\n\n**30:37** Ok, có ai có câu hỏi gì không? Nếu không có thì chúng ta sẽ chuyển sang phần tiếp theo nhé. Đối với bài demo về Data thì có lẽ chúng ta sẽ tiếp tục vào thứ tư, đúng không? Đây cũng chỉ là phần đầu của công việc liên quan đến Data Engineering thôi. Nếu muốn một bài demo chi tiết hơn và sâu hơn, chúng ta sẽ phải đi sâu vào các khái niệm như MapReduce, và những kỹ năng chuyên môn khác. Đó là những kỹ năng cơ bản của một Data Engineer. Vậy thứ tư chúng ta sẽ tiếp tục, phải không? Hình như có bạn Nam Bùi đã nhắc đến một bài trước đó liên quan đến việc tóm tắt sách hoặc đọc file PDF hay truyện gì đó đúng không nhỉ?\n\n**31:28** Nam Bùi, chuẩn bị lên giới thiệu một chút về tính năng AI của bên Figma nhé. Nam Bùi sẽ trình bày tiếp theo. Hôm nay, chúng ta còn có bạn Thông từ Holistic nữa, lát nữa mình sẽ mời bạn Thông lên để giao lưu và chia sẻ một chút.\n\n**32:07**  Phần của mình là về việc tạo ra code từ file Figma bằng cách sử dụng AI. Ok, mình sẽ bắt đầu luôn. Đây là màn hình Figma, mọi người thấy rõ chưa?\n\n**33:07** Đây là màn hình Figma của mình. Mình muốn chuyển một số thành phần (components) thành code và đảm bảo rằng nó có thể hoạt động đúng với các hành động cuối cùng (final action). Figma có một công cụ (tool) là \"Figma to Code,\" và mình sẽ chọn plugin này. Sau đó, mình sẽ dùng chức năng \"copy code,\" chọn tất cả các tùy chọn có sẵn và copy hết. Mình sẽ dán đoạn code này vào trong \"flow AI\" và bắt đầu chạy thử.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/lAk1QSl7qS0?si=AUJTYXNZZSAVCX5B&amp;start=2033\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**33:53** Hiện tại, mình không chắc code này có đúng hay không, nhưng mình sẽ chạy thử và thấy nó hoạt động khá ổn. Thế là mình muốn chia sẻ lại cho mọi người. Đây là giao diện UI mà nó tạo ra, nhưng vẫn chưa hoàn thiện. Mình sẽ tinh chỉnh lại một chút để nó hoạt động đúng. Giờ mình sẽ thiết lập các component cần thiết và cấu hình chúng.\n\n**36:11** Giả sử như mình sẽ thiết lập ngày tháng, hiện tại là ngày nào đó, nhưng mình sẽ đổi thành ngày mới cho phù hợp. Nó sẽ hiện thị chính xác ở đây. Giờ mình sẽ thực hiện bước tiếp theo để làm cho nó tương tác đúng với dữ liệu. Ví dụ như mình thiết lập để nó phản hồi chính xác với những giá trị mình đưa vào. Mình sẽ yêu cầu AI hoàn tất phần này.\n\n**39:39** Như vậy là mình đã thử với một component rồi. Bằng cách sử dụng công cụ này, mình có thể chuyển đổi thiết kế từ Figma sang code và dán vào trong \"flow AI\" để nó hoạt động. Mình đã thử nghiệm với một component và thấy khá ổn.\n\nNam, bạn đã thử phần animation chưa? Animation à? Chưa thử, nhưng đó là một vấn đề mà mình cũng muốn tìm hiểu. Trước đây, sau khi thiết kế UI xong, việc chuyển đổi các phần animation thường mất rất nhiều thời gian. Nếu có thể chuyển được cả animation một cách tự động thì sẽ rất tuyệt vời.\n\n**41:39** Dạ, thử làm việc với hướng đi đó nhé. Nếu như mình có thể convert đúng cái style hoặc chuyển đổi cả animation ở mức độ component, thì sẽ đẩy nhanh quá trình rất nhiều. Trước giờ, việc thiết kế thường phải dừng lại ở chỗ này, và chi phí cũng như thời gian cho đội ngũ ngồi làm phần đó là khá cao.\n\nDạ, ok. Em hiểu rồi. Em sẽ chuẩn bị cho lần demo sau.\n\nỪ, rồi ok. Chắc phần này mình tạm dừng ở đây trước đã, tranh thủ còn thời gian thì mời Thông lên chia sẻ một chút nhé. Thông, cái đề tài hôm qua mà bạn có gửi cho anh đó, bạn đã chuẩn bị kỹ chưa?\n\n**42:22** Ok, có Thông lên rồi. Để giới thiệu nhanh một chút, bạn Thông là một thành viên của team Holistic, và họ có một sản phẩm BI Dashboard rất nổi tiếng. Đây là một trong những team mà mình rất tôn trọng trong việc làm sản phẩm. Thông ơi, hôm qua anh thấy có trao đổi về một vài đề tài mà em đưa ra. Anh chưa có dịp giới thiệu lại với mọi người, nhưng anh thấy rằng đó có thể là một đề tài rất thú vị. Em có thể thử chia sẻ về nó được không?\n\nCó được không nhỉ? Thử xem lại một chút. Chắc bình thường là được thôi mà.\n\n**43:09** Ủa, bình thường không vấn đề gì đúng không? Ừm, kiểm tra lại thử xem nhé, có lẽ là vấn đề về permission (quyền truy cập). Để xem lại nào. Chắc trước giờ chưa từng kết nối với bạn bè trên đây bao giờ, không biết có vấn đề gì không. Theo lý thuyết thì phải kết nối được rồi. Để kiểm tra lại phần quyền truy cập nhé. Nếu đang ở chế độ \"newbie\" trên đây, thì có thể cần kết nối lại.\n\nRồi, thử kiểm tra lại quyền truy cập trên trình duyệt xem sao.\n\nThông ơi, nếu dùng trình duyệt Chrome hoặc Safari, thì phần quyền truy cập nằm ở đâu nhỉ? Nếu là Safari thì nó sẽ nằm gần ô tìm kiếm (search bar) đó. Còn nếu dùng Windows thì…\n\n**44:27** Mình cũng không chắc lắm nếu dùng Windows. Có ai biết không nhỉ? Dùng trình duyệt thì chắc là không phức tạp đâu, thường thì nó sẽ hỏi phần quyền truy cập thôi. Alo, alo? Ok, được rồi. Thông đã kết nối được rồi đó.\n\nTiếp tục câu chuyện nhé, mấy anh em trước đó có trao đổi với nhau và Thông hiện là thành viên của team Holistic. Chúng ta có nói chuyện về việc gặp gỡ, chia sẻ với nhau một lần. Hôm qua có trao đổi thêm một chút và Thông đã đề cập đến hai ba vấn đề mà team đang thử nghiệm. Mình không kỳ vọng nhiều lắm, nhưng nếu Thông có thể trình bày về các đề tài đó, thì chắc chắn sẽ rất thú vị. Đội Data Research (DR) của mình cũng đang khám phá những xu hướng hiện tại và những khả năng mới, và cũng muốn xem giới hạn của chúng ở đâu.\n\n**45:24** Nếu tiện thì Thông có thể chia sẻ thêm về các đề tài và cách ứng dụng AI hiện tại. Nếu có thể thì đề cập đến hai đề tài đó để anh em nghe thử xem, nếu hứng thú thì chúng ta có thể gặp gỡ và giao lưu thêm lần khác.\n\nỒ, Nam, lên tiếp tục đi nào.\n\nXin chào mọi người, cảm ơn anh đã giới thiệu. Thật ra, hôm nay team em cũng có một buổi chia sẻ, nên em đã kéo vài bạn qua đây cùng tham gia. Đa số là team Product đang ngồi nghe chung rồi. Ok, em chia sẻ luôn nhé.\n\n**46:02** Cảm ơn anh đã giới thiệu. Em và team em sẽ chia sẻ một chút về những bài toán mà tụi em đang làm. Thật ra, vì phần BI (Business Intelligence) rất rộng và cần nhiều kiến thức nền tảng, nên tụi em vẫn chưa tập trung nhiều vào AI. Chủ yếu là đang thử nghiệm một vài use case nhỏ để demo trước. Hiện tại tụi em đang có hai bài toán chính. Để dễ hiểu, em sẽ chia sẻ màn hình và nói thử xem mọi người hiểu được không.\n\nMọi người có nghe về tính năng Dashboard ESC chưa? Tụi em đang thử triển khai một tính năng lớn có tên là Dashboard ESC.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/lAk1QSl7qS0?si=SBLyM6MPgRgfAwUQ&amp;start=2918\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**47:31** Nếu mọi người có sử dụng BI (Business Intelligence), thì thường các công cụ BI chủ yếu là các công cụ GUI (Graphical User Interface) để kéo thả và tạo ra các biểu đồ trực quan, đúng không? Bên team em muốn đẩy nó xa hơn một chút, đó là khi tạo ra một dashboard, nó sẽ sinh ra code tương đương với giao diện UI. Tức là mình có thể tạo một dashboard bằng code hoặc bằng UI, và hai cái này sẽ tự động đồng bộ với nhau. Mục đích là để có thể lưu trữ tất cả các phân tích này trong một Git repository, thực hiện CI/CD, refactoring, và làm cho việc tạo dashboard và visualization trở nên có thể lập trình được (programmable). Thêm vào đó là tính tái sử dụng (reusability).\n\n**48:58** Vậy là cái mà anh em đang làm là chuyển đổi toàn bộ dashboard thành dạng code, đúng không? Tức là biến tất cả mọi thứ trên dashboard thành dạng văn bản (text) hết?\n\nĐúng rồi anh, chính xác là như vậy. Khi biến nó thành code, mình có thể thực hiện version control, đẩy lên Git, làm branching các kiểu luôn. Điều này cũng giúp nhiều team có thể cùng nhau phát triển, kiểm soát môi trường dev/prod tốt hơn. Đó chính là cách mà tụi em muốn áp dụng cho dự án này.\n\nKhi code được sinh ra từ UI, tụi em có thể dùng OpenAI để generate toàn bộ phần code này để tạo ra dashboard. Ví dụ như, ở trường hợp này, em sẽ dựa trên dataset đã được định nghĩa sẵn và từ đó sinh ra dashboard.\n\n**49:35** Không biết mọi người có thấy màn hình được không nhỉ? Bên anh vẫn thấy được bình thường nhé. Ok, ví dụ em tạo một dashboard mới ở đây. Em có một nút AI, bên trong đó là một con Bot mà tụi em đã tạo sẵn với những chỉ dẫn (instructions) rõ ràng. Tuy nhiên, tụi em cũng giới hạn quyền lựa chọn của người dùng để tránh việc trả lời sai câu hỏi. Để em thử chọn ví dụ \"User\" với nhóm \"City\" xem sao. Bên dưới, nó sẽ chạy một prompt để sinh ra code bên tay trái này.\n\nThật ra, ở giữa có một file JSON để xác định xem nó sinh ra phần tử code nào (code elements). Em không phải là Engineer trực tiếp làm phần này, nhưng nếu mọi người muốn biết rõ hơn, tụi em có thể nhờ kỹ sư của tụi em lên trình bày chi tiết. Hiện tại nó đang ở giai đoạn beta, nên thỉnh thoảng có lúc work, có lúc không. Lúc nãy nó hoạt động tốt, nhưng bây giờ có vẻ không được.\n\n**51:16** Nếu nó hoạt động bình thường, thì nó sẽ sinh ra hai filter ở đây và ba chart bên dưới. Điều này có nghĩa là từ UI, nó sẽ chuyển qua một lớp JSON rồi qua prompt, sau đó sinh ra giao diện UI cuối cùng. Cả quá trình đó đang cố gắng tự động hóa hoàn toàn.\n\nĐúng vậy, nó sẽ sinh ra các đoạn text, rồi tự động lựa chọn dimension và measure phù hợp để tạo ra kết quả bên phải này dựa trên một số quy tắc mà tụi em thiết lập. Nó sẽ tự động sinh ra tiêu đề (title), mô tả (description), và các thành phần khác. Giống như việc bạn show một artifact trên hệ thống CL vậy, nhưng ở đây là từ text biến thành UI.\n\n**51:58** Tất cả các thành phần UI là tụi em đã quy định trước, phải không? Đúng vậy, em không nhớ chính xác, nhưng nó dựa trên tổ hợp của số lượng dimension và measure. Mỗi measure sẽ kết hợp với một số dimension nhất định, ví dụ như một measure với ba dimension sẽ sinh ra khoảng sáu biểu đồ (chart). Mỗi dimension sẽ tạo ra hai biểu đồ.\n\nThật ra, tụi em cũng có option cho nó generate bất kỳ thứ gì, nhưng vì như vậy sẽ rất khó kiểm soát nên tụi em giới hạn lại, ví dụ như tạo ra một layout, một page với một bảng để hiển thị dimension và measure ở đây.\n\n**53:20** Hiện tại thì tụi em vẫn đang trong giai đoạn thử nghiệm (testing). Mức độ hoàn thiện về mặt user experience (UX) vẫn chưa được kiểm chứng. Ban đầu, hy vọng là việc sử dụng code generation bằng LLM (Large Language Model) sẽ tăng tốc độ cho team phát triển (development team). Ban đầu chỉ muốn gây ấn tượng (impress) thôi. Muốn cho mọi người thấy rằng việc này hoàn toàn có thể được thực hiện bởi AI.\n\nNếu nhìn xa hơn, chúng ta có thể mong muốn rằng đoạn code này sẽ được hoàn thiện và tối ưu hơn.\n\n**54:04** Khi sinh ra dữ liệu, nó nên có ý nghĩa hơn, phải có sự phù hợp và ngữ cảnh tốt hơn. Ví dụ như, nó có thể hiểu được rằng trong dataset này có những field nào liên quan để đưa ra các câu hỏi mà người dùng mong muốn. Để người dùng có thể nhập câu hỏi bằng ngôn ngữ tự nhiên, ví dụ như hỏi \"Doanh thu ở Việt Nam là bao nhiêu?\" thì nó sẽ tự động chọn field \"revenue\" và \"country\" là Việt Nam để tạo ra hai biểu đồ. Đó là hướng đi xa hơn trong tương lai, còn hiện tại thì nó vẫn còn khá cơ bản.\n\nĐiểm mạnh nhất của công cụ này là mọi thứ đều được chuyển thành code\n\n**54:38** Bên tay trái này là phần syntax của YAML mà em vừa đề cập, đúng không? Đây là phần Editor ở phía bên trái?\n\nĐúng rồi anh, chính xác.\n\nVậy hiện tại nó chưa ổn định là do phần chuyển đổi sang YAML chưa chính xác, phải không?\n\nĐúng rồi, việc nó có chính xác hay không phụ thuộc nhiều vào cách mình kiểm soát kỳ vọng và outcome (kết quả). Quan trọng nhất là cái prompt (hướng dẫn) mà mình viết và cung cấp cho AI.\n\n**55:22** Vậy hiện tại ai đang xây dựng các agent cho việc này? Là team Engineer hay team Product của em?\n\nHiện tại, cả team Engineer và team Product đều đang làm việc cùng nhau. Người trực tiếp viết các system prompts là một kỹ sư kết hợp với người bên Product. Product sẽ quản lý nhiều hơn về hành vi, tức là muốn nó hiển thị như thế nào, kết quả ra sao.\n\nỒ, hiểu rồi. Vậy là chất lượng phần output phụ thuộc vào người viết prompt đúng không?\n\nChính xác là vậy.\n\n**56:08** Vậy dự án này tiến triển đến bao nhiêu phần trăm rồi em?\n\nThực ra, ban đầu team em cũng chưa có kế hoạch gì quá cụ thể. Chủ yếu là đang thử nghiệm thôi, chưa thật sự đầu tư nhiều. Nếu muốn làm đến nơi đến chốn thì phải đầu tư thời gian và nguồn lực nhiều hơn. Nếu làm nửa chừng rồi không work, mọi người sẽ quay lại trách mình.\n\nÀ, vậy cái file YAML đó là đặc trưng của bên em hay là một dạng chuẩn?\n\nNó là do team em tạo ra, tụi em đã phát triển hai loại ngôn ngữ: một cái gọi là \"Modeling Language\" là YAML, và một cái là \"Query Language\" là AQL. Toàn bộ file này là YAML, nó sẽ khai báo các block (khối) cần thiết. AQL thì tương đương với SQL nhưng có một vài khác biệt về cú pháp và cách sử dụng.\n\n**56:53** Để em ví dụ AQL, nó giống như SQL nhưng có một vài phần khác biệt. Ví dụ ở đây... (Em chỉ phần code trên màn hình). Không biết mọi người có câu hỏi gì thêm không nhỉ?\n\nNgoài bài toán này ra, còn bài toán nào nữa không? Hôm trước em có nói về hai bài toán mà.\n\nDạ, tụi em có nhiều bài toán nhỏ lẻ, em chưa đi qua hết được. Nhưng có một bài toán khá lớn là ngôn ngữ AQL này. Dù tụi em đã có documentation (tài liệu hướng dẫn) đầy đủ, nhưng việc người dùng áp dụng ngôn ngữ này có một learning curve (độ khó khi học). Tụi em đang tìm cách làm sao để người dùng có thể học và sử dụng AQL dễ dàng hơn. Ví dụ như, liệu AI có thể tự động tạo ra các câu lệnh AQL dựa trên tài liệu mà tụi em cung cấp hay không?\n\n**57:59** Ồ, hiểu rồi, cái đó hoàn toàn khả thi nha. Nếu có đủ ví dụ, có thể dùng fine-tuning để hướng dẫn AI làm điều đó, đúng không?\n\nDạ, đúng vậy. Hiện tại tụi em đang tìm hiểu thêm. Em đang viết tài liệu hướng dẫn để người dùng hiểu được cách sử dụng AQL. Việc áp dụng AQL cũng hơi khó vì nó khác với mindset (cách suy nghĩ) của SQL. Trừ khi team Holistic đứng ở vị trí buộc người dùng phải sử dụng, sẽ khó để họ thay đổi cách suy nghĩ quen thuộc.\n\n**58:37** Dù AQL có nhiều tính năng mạnh mẽ hơn SQL, nhưng cần phải thay đổi mindset của người dùng. Đó là lý do việc áp dụng cũng có phần thử thách. Hiện tại, tụi em đang viết thêm các ví dụ, nhưng số lượng ví dụ hiện nay cũng chưa đủ nhiều.\n\nNếu ví dụ đủ nhiều, thì AI có thể học và tạo ra các câu lệnh chính xác hơn đúng không?\n\nĐúng rồi. Hiện tại, em đang cố gắng làm cho việc học ngôn ngữ AQL này trở nên dễ dàng hơn bằng cách sử dụng AI.\n\n**59:25** Nếu AI có thể chuyển đổi từ ngôn ngữ tự nhiên sang AQL thì chắc chắn sẽ tiết kiệm rất nhiều thời gian cho người dùng.\n\nDạ đúng rồi, nếu AI có thể chuyển đổi từ ngôn ngữ tự nhiên sang AQL thì sẽ không cần phải học cú pháp AQL nữa.\n\nVậy trong quá trình triển khai, nếu AI hỗ trợ được chuyển đổi từ câu hỏi tiếng Anh sang câu lệnh AQL, thì mình có thể bỏ qua phần trung gian phải không?\n\nChính xác anh, nếu AI có thể làm được điều đó, chúng ta có thể bỏ qua bước trung gian.\n\n**01:00:14** Nhưng nếu bỏ qua bước đó, liệu việc tạo ra một ngôn ngữ lập trình mới có còn cần thiết không?\n\nKhông hẳn là một Domain-Specific Language (DSL) đơn thuần, mà nó là một ngôn ngữ lập trình mới dành riêng cho việc truy vấn (query). Để nói rõ hơn, có lẽ nên nhờ một bạn khác trong team em trình bày thì sẽ chi tiết hơn.\n\n**01:00:54** Ví dụ, trong SQL, tính tái sử dụng (reusability) rất kém, khó để tạo ra các hàm (function) hoặc mô-đun (module) có tính linh hoạt. Nhưng với AQL, nó có đầy đủ các khái niệm như function, variable, và nhiều tính năng lập trình khác. Điều này giúp nó trở nên maintainable (dễ bảo trì) hơn, reusable (có tính tái sử dụng) hơn, và hoạt động ở một cấp độ cao hơn SQL.\n\nỒ, ok. Vậy ngoài hai bài toán này, team em còn bài toán nào khác nữa không?\n\n**01:01:36** Khi được áp dụng AI, thì giá trị thực sự của nó sẽ được thể hiện rõ hơn. Em nghĩ có hai bài toán chính ở đây. Thứ nhất là làm sao để tối ưu hóa trải nghiệm của người dùng (experience) bằng AI. Ví dụ như khi anh tạo một truy vấn (query), nó có thể đề xuất (suggest) cho anh xem là truy vấn đó có sai không, hoặc nên refactor (tái cấu trúc) như thế nào. Nó cũng có thể tự động thêm các mô tả (description) hoặc metadata để những người khác có thể dễ dàng khám phá hơn. Đây là bài toán liên quan đến việc cải thiện trải nghiệm của người dùng.\n\nBài toán thứ hai là bài toán về dịch vụ (service). Trong tương lai, làm sao để người dùng doanh nghiệp chỉ cần nhập một prompt mà có thể ra được kết quả mà không cần phải thông qua data analyst. Em nghĩ bài toán này cũng có rất nhiều người đang cố gắng giải quyết, nhưng nó vẫn có khá nhiều thách thức.\n\n**01:02:17** Ví dụ như, thay vì yêu cầu một analyst phải ngồi xây dựng dashboard, thì người dùng doanh nghiệp chỉ cần hỏi \"Revenue năm nay là bao nhiêu?\" là hệ thống tự động đưa ra kết quả mà không cần phải hiểu rõ dữ liệu hoặc cách truy vấn nó. Bài toán này nhiều đội ngũ về BI (Business Intelligence) đang cố gắng giải quyết.\n\nThách thức chính là làm sao đảm bảo dữ liệu chính xác (data accuracy), làm sao để truy vấn đúng những gì cần thiết. Ví dụ, cách tính doanh thu (revenue) có thể khác nhau giữa các công ty, và việc đảm bảo rằng người dùng này chỉ truy cập được vào dữ liệu của họ, không truy cập chéo (cross-access) sang dữ liệu của người khác cũng là một vấn đề.\n\n**01:02:52** Vậy các bạn Tom và Thành nghĩ sao? Vì team của mình cũng đang gặp những vấn đề tương tự.\n\nBên em thì thực ra cũng biết từ lâu là thị trường (market) hơi tương tự trong lĩnh vực của Prol, nhưng Prol không áp dụng được cho phân tích dữ liệu (analytics). Nếu có một giải pháp như vậy thì em nghĩ sẽ rất hay.\n\nCâu chuyện về việc sử dụng ngôn ngữ tự nhiên (natural language) để truy vấn SQL thì có nhược điểm là cần phải đi vào chi tiết về dimension (kích thước) và measure (chỉ số). Nhưng nếu trên ngôn ngữ truy vấn của em đã chia sẵn dimension rồi thì có thể tiết kiệm được nhiều bước hơn.\n\n**01:04:26** Thông, em nghĩ bài toán này có thể giải quyết một cách nghiêm túc không? Nếu có cơ hội thì chúng ta có thể ngồi lại một buổi khác để thảo luận sâu hơn.\n\nEm thấy nó có vẻ cũng khá dễ làm dựa trên những gì em đã trình bày. Ý anh là bài nào?\n\nBài đầu tiên là về việc viết Custom System Prompt. Đây là bài dễ nhất mà team đang làm nhiều. Bài thứ hai cần xem ví dụ có đủ hay không, và cần kiểm tra kỳ vọng nữa. Anh thấy bài này nếu làm tốt thì có thể bỏ qua bước học AQL và sử dụng ngôn ngữ tự nhiên để truy vấn.\n\n**01:05:07** Hiện tại, các bạn đang muốn dùng ngôn ngữ tự nhiên để sinh ra AQL thay vì đi thẳng qua SQL, đúng không?\n\nĐúng rồi. Nếu mà người dùng doanh nghiệp không cần phải học mà vẫn có thể truy vấn một cách tự nhiên, thì đoạn code AQL sẽ tự động chạy.\n\nĐúng rồi, mục tiêu là như vậy. Để chuyển từ việc yêu cầu một người làm analytics phải biết AQL, giờ đây người dùng doanh nghiệp bình thường có thể tự truy vấn và tạo ra dashboard (bảng điều khiển) của họ. Công cụ mà team đang xây dựng hướng đến mục đích này, phải không?\n\n**01:05:55** Đúng vậy. Nghe có vẻ hợp lý, nhưng cũng có nhiều thách thức nhỏ bên trong. Ví dụ như, khi một người dùng doanh nghiệp hỏi \"Active users của tháng này là bao nhiêu?\" thì việc làm sao để AI hiểu và trả lời chính xác vẫn còn là một bài toán.\n\n**01:06:33** Tháng này. Dạ, vấn đề là AI cần phải hiểu định nghĩa của \"active user\" vì mỗi nhóm, mỗi team có định nghĩa khác nhau. Cho nên, AI phải có khả năng hiểu đúng định nghĩa mà người dùng đang đề cập dựa trên dữ liệu hiện có trong dataset, trong modeling code của tụi em. Điều này tương đương với một bài toán mà team của anh cũng đang làm, đó là team đang có một bài toán về truy vấn thông tin du lịch.\n\nNghĩa là mỗi người dùng sẽ hỏi: \"Link booking của tôi đâu?\" hay \"Lịch trình của tôi đâu?\" Thì thông tin ngữ cảnh của người dùng đã được gói gọn trong hệ thống rồi. Nó chỉ là phần context đi kèm thôi, không phải là vấn đề chính. Vậy, mỗi hệ thống khi sử dụng giải pháp này đều bắt buộc phải bao gồm thông tin context đó, đúng không?\n\n**01:07:54** Dạ đúng rồi, bước tiếp theo là nếu muốn giải quyết bài toán này một cách nghiêm túc, thì cần phải sắp xếp lại để đảm bảo rằng yêu cầu và dữ liệu kèm theo được hiểu rõ ràng. Giờ mới nói chuyện với nhau khoảng 10 phút thôi, nên mới hiểu sơ sơ. Chi tiết thì còn cần phải xem xét thêm các luồng demo để đảm bảo nó hoạt động đúng như mong đợi. Có thể cần nhiều ví dụ hơn, kiểu như các bài test để mô phỏng quá trình làm việc thực tế.\n\nDạ đúng rồi, sau này nếu thấy thú vị thì có thể ngồi lại để hai team mình cùng nghiên cứu thêm.\n\n**01:08:33** Dạ, anh cứ báo em nếu cần sắp xếp. Hiện tại, ai đang định hướng cho phần này? Anh Huy ạ?\n\nThực ra là cả team đang cùng làm thôi, không chỉ riêng anh Huy. Nguyên cả team leadership đang cùng tham gia định hướng.\n\nVậy là team có nhiều co-founder?\n\nĐúng rồi, có 5 người lận.\n\nOk, vậy ngoài các bài toán này, còn có vấn đề nào khác mà em muốn chia sẻ không?\n\nThật ra, em cũng chưa chuẩn bị nhiều lắm, chỉ mới có được chừng đó thôi.\n\n**01:09:25** Tom với Thành, các anh còn câu hỏi nào về đề tài này không? Chắc là chưa đâu, để hôm nào setup một buổi khác rồi mình bàn tiếp.\n\nOk, cảm ơn Thông nhiều. Chúng ta còn đủ thời gian để tiếp tục bài của Thành hay là chuyển qua lịch trình khác?\n\nChắc là kịp bài ngắn của em đó, xem thử bài nào.\n\n**01:10:40** Mọi người thấy màn hình chưa? Bài này chủ yếu có mấy tools thôi. Em sẽ giới thiệu sơ qua về lý do tại sao em chọn những tools này.\n\nTool đầu tiên là K9s. K9s giống như một tool để xem community logs, và nhìn chung nó cũng dễ sử dụng, khá giống với `kubectl logs`. Cơ bản là liên hệ được với cluster rồi namespace, và nó trông đẹp hơn, có tính tương tác (interactive) cao hơn một chút. Nó có một số lệnh menu như thế này để chọn và xem, khá trực quan. Nếu ai thích xài `kubectl logs` thì có thể tiếp tục xài, còn nếu không thì có thể thử dùng cái này.\n\n**01:11:39** Tool thứ hai mà em thấy hay là HTTPie. HTTPie khá giống với `curl`, nhưng nó tốt hơn vì nó hỗ trợ rất nhiều tính năng mà `curl` hoặc những tool HTTP khác không có. Ví dụ như, HTTP/2, HTTP/3 by default đều có hỗ trợ, còn `curl` thì không. HTTPie cũng hỗ trợ nhiều tính năng khác nữa mà em không tiện liệt kê ở đây. Mọi người có thể tự tìm hiểu thêm.\n\n**01:13:12** Tool thứ ba là Bat. Bat là một tool để đọc file giống như `cat`, nhưng nó hỗ trợ thêm tính năng syntax highlighting trên terminal. Tool này hữu ích cho những ai thường xuyên làm việc trên terminal, đặc biệt là những người dùng Linux.\n\nEm nghĩ rằng mấy tool này chủ yếu dành cho những người thích sử dụng terminal-based app, kiểu như mình đang quay trở lại với việc sử dụng các ứng dụng trên terminal vậy. Ban đầu là từ CLI, chuyển qua GUI desktop app, rồi tới web app, và giờ là quay về terminal app.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/lAk1QSl7qS0?si=wlwOvmE6pIrFwH0A&amp;start=4410\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**01:13:54** Bây giờ, kiểu như là có quá nhiều công cụ GUI rồi, có vẻ như đã bão hòa. Thế nên mọi người quay lại làm những cái tool CLI (command-line interface) để cảm thấy nó mượt hơn, dễ sử dụng hơn. Có lẽ là như vậy.\n\nVừa rồi, em điểm qua các công cụ tuần trước, chỉ có vậy thôi. Còn công cụ này là `searx-lobster` à?\n\nDạ, cái nào cũng được anh. Ý là anh có thể đưa link nào cũng được, không nhất thiết phải dùng link này. Nếu muốn, thay vì mở web, anh có thể dùng trực tiếp qua đây.\n\nỒ, tính ra mấy ông dev giờ hết việc để làm rồi nhỉ?\n\n**01:14:36** Dạ đúng rồi. Tuần trước em cũng nói rồi, em có theo dõi một chút về câu chuyện này. Trong bài tuần trước, cách đây khoảng ba tuần, bên Golang cũng có một công cụ riêng, gọi là `genkit`. Mọi người có thể thử, nó khá dễ xài. Chỉ cần xài như những công cụ mà em vừa giới thiệu thôi. Chắc là nó mới xuất hiện, em cũng không rõ cộng đồng đang dùng như thế nào, nên phải đợi thêm thời gian để xem tình hình. Nếu mọi người muốn thử thì cứ thử, nó cũng dễ dùng.\n\nÝ là nếu anh muốn code thử cái phần API trên terminal thì có thể dùng tool này, đúng không?\n\n**01:15:20** Đúng rồi anh, nó gom lại từ nhiều công cụ khác thôi. Thực ra, công cụ này còn nhiều tính năng khác mà em không liệt kê hết. Chắc là phải đợi một thời gian nữa xem có thêm tính năng nào không. Hiện tại, Python vẫn là ngôn ngữ chủ đạo. Nó tương thích với mọi ngôn ngữ, miễn là có example thì nó sẽ chạy.\n\nỪ, đúng rồi. Ok, chắc là hết rồi. Cảm ơn mọi người.\n\nTheo lịch trình, team mình sẽ nghe thêm một phần nữa về việc làm Data Reprocessing mà Tom làm hồi nãy trong cái folder 'bx'. Nếu tuần sau có thời gian thì chúng ta sẽ đi sâu hơn vào phần này. Còn không thì chúng ta sẽ quay lại những bài trước mà ba team đã làm.\n\n**01:16:16** Nếu được thì mọi người nên xem trước trong tuần này, sau đó tuần sau chúng ta thử nghiệm một chút về YouTube transcription hoặc thử với Bin, một công cụ AI assistant đang dùng. Coi xem chúng ta có thể demo như thế nào và chia nhau tổng kết lại từng phần.\n\nNgoài ra, các bài toán về việc đưa dữ liệu vào, viết Custom Regex thì trước sau gì team mình cũng sẽ cần những tool để thực hiện. Nếu mọi người không có thời gian làm hoặc chưa kịp, thì cứ để cho team Linh ngồi làm và đẩy phần đó luôn. Chắc là tool gần nhất mình cần phát triển là một Project Reporter.\n\n**01:17:02** Reporter kiểu tổng hợp thông tin từ nhiều nguồn và tạo ra một báo cáo (report template) về tình trạng dự án. Cái này sẽ khá hữu ích trong việc theo dõi dự án, đúng không?\n\nĐúng rồi, em nghĩ vậy. Tom đang làm thêm một dự án là tạo comic script. Hôm trước mình có đề cập đến việc tạo một dự án tên là \"WM Comic,\" tập trung vào các chủ đề liên quan đến tài chính và công nghệ. Mỗi chủ đề sẽ có khoảng ba đến năm comic strips theo phong cách hài hước.\n\n**01:17:46** Tuần sau, Tom sẽ bắt đầu từ từ, có thể train một mô hình LoRA để vẽ mèo (cat drawing). Mục tiêu là những meme (grama) mà team mình thường thấy online sẽ được chuyển thành một comic strip giống như trang Monkey User hoặc XKCD. Nếu ai biết trang đó thì mình sẽ làm tương tự.\n\nTrên nền đó, mình sẽ vẽ nhân vật theo phong cách của riêng mình, và đây cũng là cách để team làm PR, truyền thông ra bên ngoài.\n\n**01:18:30** Vậy đó là kế hoạch cơ bản nhé. Ngoài ra, chắc mình sẽ điểm qua tình hình check-in của team mình sau khi kích hoạt lại việc đến văn phòng (office) một chút. Tuần trước, hay hai tuần trước gì đó, mình có nói về việc triển khai chiến dịch khuyến khích mọi người quay lại văn phòng.\n\nHiện nay, trang thiết bị cơ bản đã sẵn sàng, có khoảng ba bạn từ team Holistic đã quay lại văn phòng rồi. Bé Vi hôm trước cũng phỏng vấn trên Techy Story. Tình hình là các trang thiết bị đang dần được thiết lập lại.\n\n**01:19:21** Mình có một kênh trên Slack để kiểm tra xem ai check-in ở văn phòng và ai không có mặt ở đó. Có một vài bạn check-in nhưng lại không có mặt ở văn phòng. Kỳ vọng của mình là mọi người sẽ cố gắng dành nhiều thời gian tại văn phòng hơn trong thời gian tới, để chúng ta có thể phối hợp và chia sẻ thông tin hiệu quả hơn.\n\n**01:20:06** Hiện nay, về trang thiết bị thì đang trang bị cơ bản rồi, có khoảng ba bạn từ team Holistic cũng đến đây, giống như trước kia bé Vi có phỏng vấn trên Techy Story. Tình hình trang thiết bị cũng đã được khôi phục. Mình có một channel đang ẩn ở đây để theo dõi ai check-in vào văn phòng. Có một số bạn check-in nhưng thực tế không có mặt tại văn phòng, mọi người có thấy không?\n\nKỳ vọng là trong thời gian tới, anh hy vọng mọi người có thể lên văn phòng, ngồi cùng nhau nhiều hơn để trao đổi, chia sẻ công việc.\n\n**01:20:41** Nhất là về workflow, căn bản là trong giai đoạn này workflow khi xây dựng sản phẩm sẽ thay đổi rất nhiều. Việc ngồi cạnh nhau sẽ giúp chuyển giao kiến thức (knowledge transfer) nhanh hơn so với ngồi online. Hiện tại, mấy buổi họp online chỉ giúp show nhanh kết quả, còn quá trình tìm ra giải pháp thì khó chia sẻ hơn. Việc ngồi cùng nhau một hoặc hai ngày một tuần sẽ giúp mọi người nắm bắt nhanh hơn, đặc biệt là với Tom và những bạn đã có kinh nghiệm, sẽ hỗ trợ nhanh hơn rất nhiều. Anh vẫn hy vọng mọi người chủ động quay trở lại văn phòng nhé.\n\n**01:21:16** Channel check-in ở đây cũng có vài anh em check-in rồi. Mỗi tuần danh sách sẽ được post lại trong lobby để mọi người thấy, và đúng là danh sách này vẫn là những gương mặt cũ. Thật ra, cũng có thêm vài bạn mới, như bạn Cát, bạn Biên đã lên. Trước đây, Biên không hay lên văn phòng lắm, thường thì chỉ lên chơi thôi, chứ không phải lên làm việc. Nhưng bây giờ cũng bắt đầu xuất hiện những gương mặt quen thuộc hơn, đó là dấu hiệu tích cực.\n\nHy vọng mọi người có thể bắt đầu lại việc đến văn phòng một ngày trong tuần, tìm góc làm việc riêng của mình. Văn phòng hiện tại có thể chứa tối đa khoảng 12 người, không nhiều hơn. Mọi người cố gắng sắp xếp thời gian, đặc biệt trong giai đoạn này việc chuyển giao kiến thức là quan trọng nhất.\n\n**01:21:50** Anh muốn thúc đẩy việc này vì muốn chuyển giao kiến thức về AI/ML, ngồi cùng nhau sẽ tạo ra nhiều ý tưởng hơn. Việc chỉ ngồi xem tutorial trên mạng thì không thể nào có được sự hiệu quả như khi ngồi cạnh nhau. Nhìn Tom làm việc mới thấy được sự dã man, mình còn thích nữa huống chi anh em khác.\n\nVậy là về việc quay lại văn phòng, anh cũng muốn Tom tham gia. Tom thì có một số công việc khác nữa nên có thể lúc lên lúc không, nhưng anh hy vọng Tom sẽ dành thời gian lên văn phòng cùng anh em để chia sẻ kinh nghiệm, vì đó là cách học nghề nhanh nhất.\n\n**01:23:13** Ngoài ra, mỗi lần check-in thì mọi người sẽ nhận được 5 ICY. Nghe qua thì có vẻ không nhiều, nhưng khi cộng dồn thì số tiền này có thể dùng để trang trải tiền ăn uống mỗi tháng, có thể khoảng 3-4 triệu đồng, không ít đâu. Anh đã ngồi nhẩm tính rồi, những bạn trước giờ thường xuyên lên văn phòng sẽ được nhận khá nhiều.\n\nMỗi lần check-in, các bạn sẽ nhận ICY. Hiện nay, số ICY chưa được công bố ra ngoài vì sợ spam quá. Nhưng khi cộng dồn lại, số ICY này cũng đáng kể. Đây không phải là mục đích chính, nhưng sẽ là động lực khuyến khích mọi người lên văn phòng.\n\n**01:23:44** Tóm lại, trong đợt này nếu có vấn đề gì chính, thì đây là những điểm cần lưu ý. Ngoài ra, về việc liên quan đến Memo, kiến thức, hay chia sẻ thì Huy Nguyễn đang tổng kết xong đợt, nhưng chắc chưa đủ. Cũng phải xem lại xem như thế nào, có thể còn chưa xong.\n\nKỳ vọng là đến nửa năm sau sẽ có iPhone 16 để đổi thưởng, hoặc nhanh hơn là đổi MacBook, nhưng còn tùy vào sự đóng góp của mọi người. Về chính sách, team chỉ có thể đặt ra những chính sách như vậy, còn mọi người có hưởng ứng hay không thì tùy.\n\n**01:24:30** Nếu không có gì khác, thì hẹn gặp anh em vào thứ tư tuần sau nhé, để tiếp tục các phần còn lại. Nhớ là đừng quên check-in nhé. Ok, vậy là hết rồi. Nếu có vấn đề gì thắc mắc, mọi người cứ hỏi. Nếu không thì mình sẽ kết thúc ở đây.\n\nTạm biệt mọi người.\n\n---\n\n**English Transcript**\n\n**00:00** Okay, can you all hear me clearly? We have about 12 minutes left before Tom demonstrates some live coding, although we might not have enough time for a full live session. We’ll probably have a demo focusing on data engineering techniques. Alright, Tom, let’s start.\n\nLet me begin. Hello everyone, I’ll introduce a demo that I usually use. This demo is typically employed for data engineering, especially for preparing and cleaning data before analysis. In this step, we use AI to help clean the data and get ready for either data analysis or preparing the data itself.\n\n**04:37** Let me share my screen. There’s no need for everyone to use Zoom. Can you all see my screen now? Yes, okay, great. So, let’s begin by introducing the dataset we’ll be working with. There are many types of data we can clean using a tool called Agent Zero. Today, we’ll use a dataset that involves extracting information from some source, resulting in a CSV file.\n\nThe CSV data is quite raw, arranged in a basic columnar format extracted from a web player. They usually extract this data, indicating what technology they use, like jQuery or Next.js, and then arrange it in a format that's quite difficult to work with. The dataset is separated by web pages, making it challenging to begin with.\n\nOur goal is to transform it into a more comprehensive format, such as an infographic, or create a consolidated dataset with all the relevant data in a centralized manner. So, let’s move forward with this now.\n\n**05:41** Agent Zero is a tool that serves as an agent; I just need to tell it what to do, and it will write the code for me. For example, in this case, the problem lies in the `ph` folder. So, I’ll instruct it to “Look into the `ph` folder and help me process all the CSV files.” I want to analyze which backend technologies these sites are using.\n\n**06:22** Agent Zero is an AI agent tool, and you just need to communicate with it in natural language; it will automatically write the code for you. For example, if I have an issue with data located in the 'ph' folder, I simply tell it: \"Look into the ph folder and help me process all of the CSV files. I want to do some data analysis to understand what backend technologies all of these sites are using and aggregate all of them.\" It seems like the UI is a bit buggy at the moment, but my goal is to analyze which backend technologies these websites are using. Agent Zero will utilize GPT-4 or GPT-4 mini to handle all these tasks.\n\n**08:25** If it encounters any errors, it will automatically fix them. The process of Agent Zero consists of two parts: one part is running the code, and the other part is checking whether that code runs correctly. Here, it has already detected an error, so it will automatically correct it for me. At this stage, I just need to define my objective, and Agent Zero will write the code for me. From there, I can start analyzing the data from the websites I've downloaded, converting them into CSV files, and cleaning the data.\n\n**09:06** Now, I'll ask it to create an infographic to aggregate all the backend technologies used by the websites. I want a visual representation to make the analysis easier. Therefore, I instruct it: \"Create me an infographic inside the 'ph' folder to aggregate all of the backend programming languages which are used across all CSV files.\" Then it will automatically draw a chart using the Matplotlib library and export a PNG image for me. If it encounters any errors, it will automatically download the necessary libraries through pip and continue the process. This automation covers almost all my needs related to data processing. It will also keep all the work saved so that I can review it later.\n\n**09:58** Currently, I don't want to review each individual result file, so I'll ask Agent Zero to output everything into the 'ph' folder for easy management. Later, if I need to use it again, I just need to go back to that folder. This feature is quite convenient for any further processing steps I may need.\n\n**10:56** You can see that for tasks like creating a web crawler, I can also use a similar method. Agent Zero will read the website structure, upload the results, and all I need to do is specify the HTML and CSS tags I want to extract data from. Instead of writing the code manually, I can now have Agent Zero handle it for me.\n\n**11:42** For instance, in this case, the easiest way is for me to delete a few unnecessary entries and then add some new rows to clean the data. If I want to generate code for data analysis or simply download a YouTube video and extract the first 10 seconds of it, Agent Zero can handle that as well. For example, I'll copy the URL of a YouTube video and instruct it: \"Download this YouTube video and cut out the first 30 seconds of it.\" Agent Zero will automatically code the task, using the terminal to download the video and cut out the first 30 seconds as requested.\n\n**12:37** During this process, it will automatically utilize the terminal, download the video, and extract the required segment. However, sometimes it may face minor issues, such as choosing which backend module to use for this process; for instance, it might be using GPT-4 mini. As you can see, it's actually using various tools to ensure the task is completed accurately.\n\n**13:41** It seems that it's encountering an error when downloading or cutting the video. At this point, I only need to give it a bit more guidance or ask it to delete the current video download and try again. This process is almost fully automated and is extremely convenient for repetitive tasks.\n\n**14:54** Because this is a long video, the demo might be a bit slow. I can try again with a shorter video to see how it performs. Now I'll copy the URL of a shorter video and instruct: \"Download this YouTube video and get the first 30 seconds.\" This process might sometimes take a bit longer to run, but I just need to wait a bit, and the AI system will handle it and complete the task.\n\n**16:01** There are some minor issues, for example, the current office setup might not allow downloading YouTube videos, so the process might be a bit slow. But fundamentally, if you want to perform tasks such as web data analysis or need an auto agent to handle complex tasks, Agent Zero is an excellent choice.\n\n**17:43**\nI can create an auto agent to handle situations like this, for instance, downloading videos, data analysis, or processing backend tasks. Agent Zero utilizes GPT-4 mini or other models depending on the requirement and can perform complex tasks efficiently.\n\n**19:00** From here, if you want to delve deeper into using Agent Zero to generate code or create visual infographics from data, you can fully instruct it to export in different formats like CSV, JSON, or even Parquet charts. If your data is too large and you don’t want to use AI due to token costs, you can interact with the system through databases such as Dgraph DB or others. Agent Zero will assist in generating the necessary query commands, allowing you to interact with the database without having to write code from scratch.\n\n**20:09** For data or data engineering tasks, I can instruct it to generate code in Pandas (Pandas DataFrame), for example. Oh, it seems like it's being blocked now [music plays in the background]. Ah, that’s right, probably due to the office network restrictions, it might not be able to download from external networks. But if I want to go deeper into writing code or creating an infographic that helps visualize data more clearly, I can have it export a CSV or JSON file. The best part is that it can even compile the data into the Parquet format if needed.\n\n**21:13** If I have a relatively large dataset and don’t want to use AI to process it because it would consume too many tokens, I can ask Agent Zero to generate code for me, and it will organize the data into the required structures. For instance, I could interact with a database like DgraphDB or any other type of database, and Agent Zero will help me query the data without requiring much manual coding. This way, I can interact with the data without needing to intervene directly.\n\n**22:04** Alright, do you have any questions about this section? If not, we'll move on to the next part. Oh, someone asked how Agent Zero differs from the frameworks we’ve shown before? The main difference is that with a framework, you have to write a lot of code. With Agent Zero, you don't have to code anything. Specifically, it automatically creates the tools and handles the requests. In contrast, with traditional frameworks, you have to create an Agent, add the tools, and set up a Runner for it to execute the outputs from those tools. Agent Zero creates the tools automatically; you don’t have to do anything. Let me check where it stores the data.\n\n**22:44 I**t has a dedicated folder within Agent Zero, and when it completes a task, it saves it into its memory, specifically in SQLite. This memory stores all the tools that have been created and the related code snippets. For example, if I don't have a tool to download videos from YouTube, it will create one for me. If I want to scrape data from Facebook, it will also automatically generate a tool to handle that. And when I ask for it again, it will use the cached memory of that tool. Occasionally, if it hasn’t been used for a while, the cache might be cleared, but in general, it will retain the data for me. This is quite different from the old Auto-GPT.\n\n**23:21** In the past, when using Auto-GPT, if you wanted to create an application for interviews or extract information from the web, you had to create a tool first and write the specific code for each task. With Agent Zero, you don't need to code anything; it does everything for you. For instance, when Mr. Ngoc Thanh used to work on this, he had to code everything manually, while I didn’t have to do anything and still got the results. Therefore, the environment and approach of Agent Zero is truly an automated tool that doesn't require much intervention, unlike other frameworks.\n\n**24:05** So, what’s special about Agent Zero's architectural structure compared to other tools? In fact, what I find unique is that you can use it for data analysis or data engineering tasks very simply. For example, if you have an MP3 file and want to filter out unusual sounds, it can help you do that. I also remember when I had a large PDF file, and I needed to split it or merge it, Agent Zero performed this task very efficiently as well.\n\n**24:59** However, if the requirements are more complex, it might not perform perfectly. For example, if I want to create a 3D Plot or a Scale Plot, Agent Zero can understand but isn’t always accurate. Therefore, Agent Zero serves as more of a \"starting point,\" like a junior assistant, from which you’ll need to continue refining the tasks on this foundation.\n\n**25:49** Oh, I just saw a new request to process a PDF file. Okay, let’s try it out. What would you like it to do with the PDF file? Convert it to Markdown, or would you prefer it to create an Altic file? This will be interesting to see how Agent Zero handles it. It seems there might be some data overlap or duplication, doesn’t it? Let me try downloading it again. I can either let it download for me or adjust this menu manually for it to be automatic. I’ll make some further adjustments.\n\n**27:11** Alright, I’ll name the folder \"Fusion.\" Let’s check what’s inside. Oh, it looks like there are some images in there. Now I’ll instruct Agent Zero to extract the images from the PDF file. Which image do you want to extract first? Ah, let’s go with the images first, okay. \"Help me grab the images inside the Fusion PDF into a separate folder.\" Alright, here are the images, and they’ve been extracted. It seems like Agent Zero knew how to cut them out correctly.\n\n**29:25** It seems to have successfully extracted the images from the library. We need to fine-tune it a bit to convert them from JPEG to PNG format. This will also allow us to keep the transparency intact. Done, everything is completed. Great job, this is excellent.\n\n**29:39** Now, let’s open the Preview file and see if everything is stable and accurate. It’s honestly much more reliable than when I do it manually, which takes a lot of time. Thanks to Agent Zero, I didn’t have to write any code; it did everything for me. However, one drawback is that if there are tables in the PDF file, it will only extract them as images. It can’t maintain the original table format from the PDF. But still, it’s quite acceptable.\n\n**30:37** Okay, does anyone have any questions? If not, we’ll move on to the next section. As for the Data demo, I think we’ll continue on Wednesday, right? This is just the initial part of the work related to Data Engineering. If we want a more detailed and in-depth demo, we’ll need to dive into concepts like MapReduce and other specialized skills. These are the fundamental skills of a Data Engineer. So, we’ll continue on Wednesday, correct? I believe Nam Bui mentioned an earlier topic about summarizing books or reading PDF files or some kind of story, didn’t he?\n\n**31:28** Nam Bui, get ready to introduce a bit about the AI features of Figma on your side, alright? You’ll be presenting next. Today, we also have Thong from Holistic; later, I’ll invite Thong to join us for some sharing and interaction.\n\n**32:07** My segment will be about generating code from a Figma file using AI. Okay, I’ll start now. Here’s the Figma screen, can everyone see it clearly?\n\n**33:07** This is my Figma screen. I want to convert some components into code and ensure they work correctly with the final action. Figma has a tool called \"Figma to Code,\" and I’ll select this plugin. Then I’ll use the \"copy code\" function, choose all available options, and copy everything. I’ll paste this code into \"flow AI\" and start running it.\n\n**33:53** Currently, I’m not entirely sure if this code is correct, but I’ll run it and see that it works quite well. I wanted to share this with everyone. Here’s the UI interface it generated, although it’s not yet fully complete. I’ll tweak it a bit to make sure it works correctly. Now, I’ll set up the necessary components and configure them.\n\n**36:11** For example, if I set up the date, and currently it’s set to a specific date, I’ll change it to the new date to make it suitable. It will display accurately here. Now, I’ll proceed to the next step to make it interact correctly with the data. For instance, I’ll configure it to respond precisely to the values I input. I’ll instruct the AI to complete this part.\n\n**39:39** So, I’ve tried it with one component already. By using this tool, I can convert designs from Figma into code and paste it into \"flow AI\" to make it function. I tested it with one component, and it works quite well.\n\nNam, have you tried out the animation part yet? Animation? No, I haven’t tried that yet, but it’s something I want to explore. In the past, after completing the UI design, the step of converting animations usually took a lot of time. If we can automatically convert animations as well, that would be amazing.\n\n**41:39** Yes, let's try working with that direction. If we can accurately convert the style or transition the animation at the component level, it will speed up the process significantly. Up to now, the design work often stops at this stage, and the cost as well as the time required for the team to handle this part is quite high.\n\nOkay, I understand. I will prepare for the next demo session.\n\nAlright, let’s pause this segment here for now. Since we still have some time left, let's invite Thong to share a bit. Thong, have you prepared for the topic you sent me yesterday?\n\n**42:22** Okay, Thong is here. Let me quickly introduce him. Thong is a member of the Holistic team, and they have a very well-known BI (Business Intelligence) Dashboard product. It's one of the teams I highly respect in terms of product development. Thong, I noticed that yesterday you shared a couple of topics. I haven’t had a chance to introduce them to everyone yet, but I think they could be really interesting. Can you try sharing them with us?\n\nIs that possible? Let’s check again. It should work fine.\n\n**43:09** Oh, it seems to be working fine, right? Let’s check again, maybe it’s an issue with permissions. Let's take another look. I think it should connect without problems; I’ve never connected with friends here before, so I'm not sure if there might be any issues. In theory, it should work. Let’s review the access permissions. If you’re currently set as a \"newbie\" here, you might need to reconnect.\n\nOkay, let's check the browser permissions.\n\nThong, if you're using Chrome or Safari, where would the access permissions be located? If it's Safari, it should be near the search bar. If you're using Windows, then…\n\n**44:27** I’m not entirely sure about Windows. Does anyone know? When using a browser, it shouldn't be too complicated; usually, it prompts for access permissions. Hello, hello? Okay, it’s working now. Thong has successfully connected.\n\nLet’s continue the discussion. The team had talked before, and Thong is currently a member of Holistic. We previously mentioned having a chance to sit down and share with each other. Yesterday, we discussed a bit more, and Thong mentioned two or three issues that the team is currently experimenting with. I’m not expecting too much, but if Thong could present those topics, they would definitely be interesting. Our Data Research (DR) team is also exploring current trends and new possibilities, and we’d like to see where the limits are.\n\n**45:24** If it’s convenient, could you share more about those topics and how AI is being applied at the moment? Perhaps cover the two topics you mentioned earlier so that everyone can hear them. If there's enough interest, we could arrange another session to meet and explore further.\n\nOh, Nam, go ahead and continue.\n\nHello everyone, thank you for the introduction. In fact, my team also has a sharing session today, so I’ve brought a few team members here to join in. Most of the Product team is already here listening together. Okay, I’ll share now.\n\n**46:02** Thank you for the introduction. My team and I will share a bit about the projects we're working on. In reality, since the BI (Business Intelligence) domain is vast and requires a lot of foundational knowledge, we haven’t fully focused on AI yet. Primarily, we’re experimenting with a few small use cases for demo purposes. Currently, we have two main projects. To make it easier to understand, I’ll share my screen and explain; let’s see if everyone can follow along.\n\nHave you heard of the Dashboard ESC feature? We're trying to implement a major feature called Dashboard ESC.\n\n**47:31** If you've worked with BI (Business Intelligence), you'll know that most BI tools are primarily GUI (Graphical User Interface) tools for dragging and dropping to create visual dashboards, right? Our team wants to take it a bit further, meaning that when you create a dashboard, it automatically generates code that corresponds with the UI. This means you can create a dashboard either via code or through the UI, and both will be automatically synchronized. The goal is to be able to store all these analytics in a Git repository, perform CI/CD, do refactoring, and make the process of creating dashboards and visualizations programmable. Additionally, it enhances reusability.\n\n**48:58** So, what you’re working on is converting the entire dashboard into code, right? Essentially transforming everything on the dashboard into text format?\n\nYes, that's exactly right. When everything is converted into code, we can implement version control, push it to Git, and create branches. This also enables multiple teams to collaboratively develop and control both the development and production environments more effectively. That’s how we're applying this concept in our project.\n\nWhen the code is generated from the UI, we can use OpenAI to generate all of this code to create the dashboard. For example, in this case, I will rely on a pre-defined dataset and generate the dashboard from that.\n\n**49:35** Can everyone see the screen? From my side, it’s visible. Okay, let’s say I create a new dashboard here. I have an AI button that contains a bot we preconfigured with specific instructions. However, we’ve restricted user options to avoid incorrect responses. I’ll try selecting \"User\" and \"City\" as a group. It will then run a prompt to generate the code on the left side.\n\nActually, there’s an intermediate JSON file that determines which code elements are generated. I’m not the Engineer directly working on this, but if anyone wants more detailed information, we can have one of our engineers provide an in-depth explanation. Currently, it's in beta, so sometimes it works, and sometimes it doesn’t. Earlier it worked fine, but it seems to be having issues now.\n\n**51:16** If it functions correctly, it will generate two filters here and three charts below. This means that from the UI, it transitions through a JSON layer, then through a prompt, and finally generates the UI interface. The whole process is trying to be fully automated.\n\nYes, it will generate text and automatically select the appropriate dimensions and measures to produce the result on the right based on some rules we've established. It will generate titles, descriptions, and other elements automatically. It’s similar to how you show an artifact in the CL system, but here, it’s converting from text to UI.\n\n**51:58** All the UI components are pre-defined by your team, correct?\n\nThat’s right. I can’t recall all the details, but it’s based on combinations of dimensions and measures. For example, one measure with three dimensions will generate about six charts, with each dimension contributing two charts.\n\nIn reality, we have options that allow it to generate anything, but doing so makes it hard to control. Therefore, we limit it to generating a layout, a page, or a table to display the dimensions and measures here.\n\n**53:20** Currently, we’re still in the testing phase. The level of completion regarding user experience (UX) hasn’t been fully validated. Initially, we hope that using code generation with LLM (Large Language Model) will accelerate the development team’s progress. Initially, the goal was just to impress, to show that this could be done entirely by AI.\n\nIf we look further ahead, the hope is that the generated code will be more complete and optimized.\n\n**54:04** When generating data, it should be more meaningful, with better relevance and context. For example, it could identify which fields are related in a dataset to generate questions that users want. This way, users can input questions in natural language, like \"What’s the revenue in Vietnam?\" and it will automatically select the \"revenue\" and \"country\" fields to create two charts. That’s the direction we're aiming for in the future, but right now it’s still quite basic.\n\nThe most powerful aspect of this tool is that everything gets converted into code.\n\n**54:38** The syntax on the left-hand side is the YAML part you mentioned, right? Is this the editor on the left side?\n\nYes, that’s correct.\n\nSo, the current instability is due to the conversion into YAML not being accurate, is that right?\n\nExactly. Whether it’s accurate or not depends a lot on how we control expectations and outcomes. The most crucial part is the prompt we write and provide to the AI.\n**55:22** So, who is currently building the agents for this? Is it your Engineering or Product team?\n\nCurrently, both the Engineering and Product teams are working together. The person who writes the system prompts is an engineer working alongside someone from Product. The Product team will primarily manage the behavior, meaning how it should display and what the outcome should be.\n\nAh, I see. So the quality of the output depends on the person writing the prompt, correct?\n\nExactly.\n\n**56:08** So, how far along is your project in terms of progress?\n\nActually, in the beginning, our team didn’t have a very specific plan. We’re mostly experimenting at this stage and haven't invested a lot of time or resources yet. If we want to do it properly, we would need to invest more effort. If we stop halfway and it doesn’t work out, people might come back and criticize us.\n\nOh, so the YAML file, is that something unique to your team or is it a standard format?\n\nIt was developed by our team. We’ve created two types of languages: one is called the \"Modeling Language,\" which is YAML, and the other is the \"Query Language,\" which is AQL. This entire file is in YAML, and it declares the necessary blocks. AQL is somewhat equivalent to SQL but has a few differences in syntax and usage.\n\n**56:53** Let me give an example of AQL; it’s similar to SQL but with a few differences. For example, here... (I’m pointing to the code on the screen). Does anyone have any additional questions?\n\nBesides this project, do you have any other projects you’re working on? You mentioned two earlier.\n\nYes, we have many smaller projects, but I haven't gone through all of them yet. However, one significant challenge we're facing is with the AQL language itself. Even though we have comprehensive documentation, there’s a learning curve for users to adopt this language. We're exploring ways to make it easier for users to learn and use AQL. For example, can AI automatically generate AQL queries based on the documentation we've provided?\n\n**57:59** Ah, I see, that's entirely feasible. If there are enough examples, you could fine-tune the AI to do that, right?\n\nYes, exactly. We’re currently looking into that. I’m in the process of writing documentation to help users understand how to use AQL. The adoption of AQL can be challenging because it requires a different mindset compared to SQL. Unless Holistic is in a position where users are forced to use it, it will be tough to change their familiar way of thinking.\n\n**58:37** Even though AQL has more powerful features than SQL, it requires a shift in mindset, making it challenging to adopt. Right now, we're adding more examples, but the number of examples isn't sufficient yet.\n\nIf there are enough examples, the AI could learn and generate more accurate queries, right?\n\nYes, that’s correct. Currently, I’m trying to make learning AQL easier by leveraging AI.\n\n**59:25** If AI could translate from natural language to AQL, it would save users a lot of time.\n\nAbsolutely, if AI can handle the conversion from natural language to AQL, there would be no need to learn AQL syntax anymore.\n\nSo, during implementation, if AI can facilitate converting from English queries to AQL statements, can we bypass the intermediate step?\n\nExactly, if AI can do that, we can eliminate the intermediate step.\n\n**01:00:14** But if we skip that step, would creating a new programming language still be necessary?\n\nNot exactly—it’s not merely a Domain-Specific Language (DSL); it’s actually a new programming language dedicated to querying. To explain it better, I think it would be best if another team member could provide a more detailed presentation.\n\n**01:00:54** For example, in SQL, reusability is quite limited, and it’s challenging to create flexible functions or modules. But with AQL, it incorporates all the concepts like functions, variables, and other programming features. This makes it more maintainable, reusable, and operates at a higher level than SQL.\n\nOkay, got it. So, aside from these two projects, does your team have any other projects you're working on?\n\n**01:01:36** When AI is applied, its real value will become more apparent. I think there are two main challenges here. The first one is how to optimize the user experience using AI. For example, when you create a query, the AI can suggest whether the query is incorrect or needs refactoring. It can also automatically add descriptions or metadata so that others can explore it more easily. This is the problem related to enhancing the user experience.\n\nThe second challenge is a service-related problem. In the future, how can we enable business users to just enter a prompt and get results without needing to go through a data analyst? I think many people are trying to solve this problem, but there are still quite a few challenges.\n\n**01:02:17** For example, instead of needing an analyst to sit down and build a dashboard, business users could simply ask, \"What's the revenue this year?\" and the system will automatically provide the result without requiring them to understand the data or how to query it. Many teams in Business Intelligence (BI) are working to solve this problem.\n\nThe main challenge is ensuring data accuracy and making sure the queries are correct. For example, calculating revenue can vary from company to company, and ensuring that one user accesses only their own data without cross-accessing another’s is also a concern.\n\n**01:02:52** What do you think, Tom and Thanh? Our team is also dealing with similar issues.\n\nWell, on our side, we've known for a while that there is a similar market for Prol, but Prol isn’t suitable for analytics. Having a solution like this would be very beneficial.\n\nThe issue with using natural language to query SQL is that you often need to get into the details of dimensions and measures. However, if your query language already has dimensions pre-defined, you can save quite a few steps.\n\n**01:04:26** Thong, do you think this problem can be tackled seriously? If there’s an opportunity, maybe we could arrange another session to dive deeper.\n\nI think it seems quite doable based on what I’ve demonstrated. But which problem are you referring to?\n\nThe first one is about writing custom system prompts. That’s the easiest, and the team is working on it extensively. The second one requires checking if there are enough examples and testing expectations. I feel that if this is done well, we could bypass the step of learning AQL and instead use natural language for querying.\n\n**01:05:07** Currently, your team wants to generate AQL using natural language instead of going directly through SQL, correct?\n\nYes, exactly. If business users don't need to learn and can query naturally, then the AQL code will run automatically.\n\nRight, that’s the goal. Instead of requiring someone with analytics knowledge to understand AQL, now a regular business user can query and generate their own dashboard. That’s the tool your team is building, isn’t it?\n\n**01:05:55** Yes, that’s right. It sounds reasonable, but there are still a few small challenges. For instance, when a business user asks, \"What are the active users for this month?\" the AI needs to be able to understand and provide an accurate answer, which is still a challenge.\n\n**01:06:33** For this month? Yes, the issue is that AI needs to understand the definition of \"active user\" because each group or team may define it differently. So, the AI must be able to grasp the correct definition the user is referring to, based on the available data in the dataset and modeling code. This corresponds to a problem our team is also working on, which is querying travel information.\n\nThis means that every user will ask, \"Where's my booking link?\" or \"Where’s my itinerary?\" The user context is already encapsulated in the system, so it’s just an accompanying context and not the main issue. Every system that uses this solution has to include that context information, right?\n\n**01:07:54** Yes, exactly. The next step is if we want to tackle this problem seriously, we need to arrange things to ensure that the requirements and accompanying data are clearly understood. We've only been discussing this for about 10 minutes, so we only have a basic understanding. The details still need to be reviewed further, such as examining the demo flow to ensure it works as expected. We may need more examples, like test cases, to simulate real-world workflows.\n\nYes, that’s right. If we find it interesting later, both teams can come together and study it more.\n\n**01:08:33** Alright, let me know if you need to arrange anything. Currently, who’s leading this part? Is it Anh Huy?\n\nActually, the entire team is working on it, not just Anh Huy. The whole leadership team is involved in guiding it.\n\nOh, so there are many co-founders on your team?\n\nYes, there are five of them.\n\nOkay, apart from these challenges, is there anything else you'd like to share?\n\nNot really; I haven't prepared much yet—just up to this point so far.\n\n**01:09:25** Tom and Thanh, do you have any more questions about this topic? Probably not, so let's set up another session to discuss it further another time.\n\nOkay, thank you so much, Thông. Do we have enough time to continue with Thành's presentation, or should we move on to the next agenda item?\n\nI think we have enough time for a short presentation from me; let’s take a look at one of my topics.\n\n**01:10:40** Can everyone see my screen? This presentation mainly involves a few tools. I’ll briefly go over why I chose these tools.\n\nThe first tool is K9s. It’s like a tool for viewing community logs, and overall, it's quite easy to use—quite similar to `kubectl logs`. Basically, you just connect it to your cluster and namespace, and it has a more visually appealing, interactive interface. It offers some menu commands like these, making it very intuitive. If anyone prefers using `kubectl logs`, you can stick with that, but if not, you might want to try this out.\n\n**01:11:39** The second tool that I find useful is HTTPie. HTTPie is quite similar to `curl`, but it’s more advanced as it supports many features that `curl` or other HTTP tools don’t. For example, HTTPie supports HTTP/2 and HTTP/3 by default, while `curl` does not. There are many other features that HTTPie offers, but I won’t list them all here. You can explore it yourself.\n\n**01:13:12** The third tool is Bat. Bat is like `cat` for reading files, but it adds syntax highlighting support directly in the terminal. This tool is especially useful for those who frequently work on the terminal, especially Linux users.\n\nI think these tools are mainly intended for those who prefer using terminal-based apps. It's like we’re going back to using terminal applications again. We started with CLI, then moved to GUI desktop apps, then web apps, and now we’re returning to terminal apps.\n\n**01:13:54** Now, it seems like there are so many GUI tools available that it's becoming saturated. So people are turning back to CLI (command-line interface) tools because they feel smoother and easier to use. Maybe that’s why.\n\nThat’s all I have for the tools this week. Is this `searx-lobster`?\n\nYes, that’s one option, but you can use any link. It doesn't have to be this one. Instead of opening a web page, you can use it directly here.\n\nWow, developers really seem to be running out of things to do these days, huh?\n\n**01:14:36 Y**es, it does feel that way. Last week, I mentioned that I was following this trend a bit. About three weeks ago, in a previous session, Golang introduced its own tool called `genkit`. You can give it a try; it’s pretty straightforward. Just use it as you would with the tools I’ve just mentioned. It’s quite new, so I’m not sure how widely the community is using it yet. We’ll need more time to assess it. If you want to try it out, just go ahead.\n\nSo if I want to code the API part directly on the terminal, I can use this tool, right?\n\n**01:15:20** Yes, exactly. This tool consolidates several others into one. In fact, there are many more features that I haven’t covered. We’ll have to wait and see if more features are added later on. For now, Python is still the main language. It's language-agnostic, and as long as you have examples, it will run.\n\nYes, that’s true. Okay, I think that’s all. Thank you, everyone.\n\nAs per the schedule, our team will listen to another session on Data Reprocessing that Tom presented earlier using the 'bx' folder. If there’s time next week, we’ll delve deeper into this. Otherwise, we’ll return to the topics the three teams covered previously.\n\n**01:16:16** If possible, everyone should review it this week, so that next week we can experiment with YouTube transcription or try out Bin, the AI assistant we’re currently using. Let’s see how we can demo this and collectively summarize each part.\n\nAdditionally, for tasks involving data input and writing custom Regex, our team will eventually need such tools. If anyone doesn’t have the time to do it or isn’t ready, we can let Linh’s team handle it and move forward with that part. The closest tool we need to develop is a Project Reporter.\n\n**01:17:02** The Reporter is designed to aggregate information from multiple sources and generate a report template on project status. This would be quite helpful in project monitoring, right?\n\nYes, I think so. Tom is also working on another project, which involves creating a comic strip. We previously mentioned starting a project called \"WM Comic,\" focusing on finance and technology topics. Each topic will have about three to five comic strips in a humorous style.\n\n**01:17:46** Next week, Tom will gradually start, perhaps training a LoRA model to draw cats. The goal is to convert the memes (grama) that our team often sees online into a comic strip, similar to websites like Monkey User or XKCD. If anyone knows those sites, we’re aiming for something like that.\n\nOn that foundation, we’ll create our characters in our own style, which will be a way for the team to do PR and communication externally.\n\n**01:18:30** So that’s the basic plan. Besides that, I’ll quickly review our team’s check-in status after reactivating the office visits. Last week, or maybe two weeks ago, I mentioned the campaign to encourage everyone to return to the office.\n\nCurrently, the equipment setup is ready, and about three members from the Holistic team have already returned to the office. Vi also did an interview on Techy Story previously, and the office equipment is being set up again.\n\n**01:19:21** We have a Slack channel to track who checks in at the office and who isn't physically there. Some people check in but aren’t actually present in the office. My hope is that everyone will start spending more time in the office soon so that we can coordinate and share information more effectively.\n\n**01:20:06** Currently, about three members from the Holistic team are back in the office, similar to when Vi previously did the interview on Techy Story. The equipment setup is back in place. We have a hidden channel to monitor who checks in at the office. You can see that some people check in without being physically present.\n\nI hope everyone can make an effort to spend more time in the office to work and share knowledge together.\n\n**01:20:41** Especially regarding workflow, fundamentally, the workflow for building products will change during this period. Sitting together will facilitate faster knowledge transfer than working online. Currently, our online meetings only allow us to quickly show results, but sharing the process of finding solutions is more difficult. Sitting together for one or two days a week will help everyone catch up more quickly. Especially with Tom and those who have experience, they’ll be able to support everyone more effectively. I still hope everyone will proactively return to the office.\n\n**01:21:16** The check-in channel here already has a few members who have checked in. Every week, the list will be posted in the lobby for everyone to see, and, as expected, it’s still the usual faces. However, there are some new additions like Cat and Biên. Previously, Biên rarely came to the office—usually just to hang out, not to work. But now, familiar faces are starting to appear more frequently, which is a good sign.\n\nI hope everyone can start coming to the office at least one day a week, claiming your own workspace. Our office can host up to 12 people, no more. Please try to arrange your time, especially during this phase, as knowledge transfer is crucial.\n\n**01:21:50** I want to promote this because knowledge transfer, especially on AI/ML, will yield more insights when working together. Watching tutorials online doesn't quite have the same impact. Seeing Tom in action will be eye-opening, even I am impressed.\n\nSo that’s the update on returning to the office. I also want Tom to participate. Tom has other side projects, so his attendance might be sporadic, but I hope he can spend time in the office with everyone to share experiences, as that's the fastest way to learn.\n\n**01:23:13** Additionally, each check-in grants 5 ICY points. It might not seem like much, but accumulated, it can cover food expenses each month, which might be around 3-4 million VND—not insignificant. I’ve done some calculations, and those who frequently come to the office will receive quite a bit.\n\nEach time you check in, you receive ICY points. Currently, it’s not publicly posted to avoid spam, but once accumulated, it’s quite significant. This isn’t the main incentive, but it serves as a motivation for everyone to come to the office.\n\n**01:23:44** In summary, these are the main points to note for this period. Regarding memo-related topics, knowledge sharing, or other updates, Huy Nguyễn is finalizing the summaries, but they might not be complete yet. We'll have to see how it turns out.\n\nThe goal is that by mid-year, we might have enough points for an iPhone 16, or maybe even swap for a MacBook, but that depends on everyone’s contribution. As for policy, the team can only set up these incentives; it's up to everyone whether to participate.\n\n**01:24:30** If there’s nothing else, I’ll see everyone next Wednesday to continue with the rest. Don’t forget to check in via \"We.\" Okay, that’s all. If anyone has any questions, feel free to ask. If not, we’ll wrap up here.\n\nGoodbye everyone. \n","title":"OGIF Office Hours #24 - Go weekly, AI-Driven Workflows, Holistic Team AI Demo, and Figma to UI Component with Claude","short_title":"#24 Go weekly, AI workflows, Team AI demo, Figma-UI with Claude","description":"In our OGIF office hour 24 covers AI-driven workflows with Tom, a demo with the Holistic team, and Figma integration with Claude for UI components and Go commentary. Highlights include Agent Zero's data automation capabilities, Figma-to-code conversion, and the benefits of in-office collaboration for efficient knowledge transfer and AI/ML learning.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Mon Sep 23 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/24-20240920.md","slugArray":["updates","ogif","24-20240920"]},{"content":"\n85 minutes\n\n**Topics and Highlights**\n\n- **Hybrid Work & AI Focus**: Encouraging office visits, knowledge sharing, and AI/LLM projects with ICY rewards.\n- **OGIF & Tutorials**: Regular demos on Golang, AI, product design, and AI tools by Tom.\n- **Company Trip**: Planning a December trip to Penang.\n- **Product Design Insights**: Covered VUI, AR/VR, Modular Design, and AI tools for UX/UI.\n- **Golang & AI Tech**: Discussed register allocation, BBQV vector index, and GUI libraries.\n- **YouTube Transcription Tool**: Using Whisper API for transcripts.\n- **Newsletter Bot**: Collecting and scoring newsletter content with ChatGPT.\n- **AI Tool Integration**: Summarizing Discord/Twitter content using AI.\n- **Q&A & Wrap-up**: Technical issues, API use, and future demos.\n\n---\n\n**Vietnamese Transcript**\n\n**00:00** Hello mọi người, Ok chúng ta ổn rồi. Anh Thành đang nói phải không? Không nghe được, thử kiểm tra lại mic nhé.\n\n**00:20** Ok, đã nghe được rồi. Chắc đợi chị Ngọc lên một chút rồi bắt đầu nhé. Chủ yếu là vài vấn đề gần đây, chắc 70% thời gian sẽ dành để trao đổi về các vấn đề nội bộ của chúng ta.\n\n**00:40** Đã có 36 người tham gia, còn đợi ai nữa không? Nếu không, mình bắt đầu luôn nhé. Điểm qua nhanh một số việc trong tháng vừa rồi: Chúng ta đã quay trở lại với văn hóa hybrid, khuyến khích mọi người mỗi tuần sẽ lên văn phòng vài ngày.\n\n**06:47** Mục đích của việc lên văn phòng là để trao đổi kiến thức, học hỏi lẫn nhau một cách nhanh hơn so với làm việc online hoặc chỉ qua các buổi OGIF. Sau vài tuần triển khai chương trình này, thấy mọi người cũng khá hào hứng. Bên cạnh đó, có nhiều chính sách hỗ trợ cho việc lên văn phòng như khi check-in sẽ nhận được ICY, gửi xe cũng được ICY. Bên cạnh đó, phần ăn trưa của mọi người cũng sẽ được hỗ trợ.\n\n**07:20** Như mọi người cũng đã biết, định hướng của chúng ta là học và thực hiện các dự án liên quan đến AI và LLM càng nhiều càng tốt. Mình thấy các bạn khá hứng thú với những series hướng dẫn về prompting từ phía Tom hoặc những kiến thức mới. Thành, em chia sẻ thêm nhé.\n\n**07:58** Em thấy bình thường chúng ta có OGIF vào cuối thứ Sáu, nhưng giờ anh em đã bổ sung thêm buổi demo của Tom vào thứ Tư. Trong thời gian tới, dự kiến sẽ tiếp tục duy trì chu kỳ này trong khoảng 1-2 tháng nữa. Mục đích là để thúc đẩy việc sử dụng những công cụ AI, những automation tools cho công việc và học thêm các kỹ thuật liên quan đến ứng dụng.\n\n**08:40** Mọi người nên theo dõi để biết tình hình và cập nhật các công cụ hiện tại. Chủ yếu chúng ta sẽ học cách xây dựng (build-up), sử dụng các tool, như việc định nghĩa workflow, viết prompts sao cho đúng để áp dụng vào công việc coding hay các task liên quan đến development. Chắc là Tom sẽ phụ trách việc này và cập nhật kiến thức cho mọi người.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/V44ifsSx7k8?si=oBltKeqDthWiYYDK&amp;start=418\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**09:23** Ngoài ra, hiện tại chúng ta có một vài chính sách để khuyến khích mọi người tập trung vào AI/LLM nhiều hơn. Ví dụ, những hoạt động hay demo liên quan đến LLM từ tuần này, lượng reward ICY sẽ nhân 3 hoặc 4 lần, tùy vào chất lượng của bài viết hay output của mọi người. Đây là một sự khích lệ cho những ai quan tâm đến AI.\n\n**10:13** Về các mục tiêu cụ thể hơn, có lẽ đầu tuần sau sẽ có thông báo chi tiết về những thứ cần tập trung và các công cụ nào nên sử dụng. Tóm lại là vậy, tình hình chung là như vậy.\n\n**10:58** Ok, cảm ơn Thành. Như vậy, những hoạt động nghiên cứu liên quan đến AI sẽ được nhân 3 hoặc 4 lần reward. Có ai hỏi nếu spam link liên quan đến AI thì có được thêm ICY không? Chắc là mình sẽ xem xét thêm, mỗi ICY tương đương 1.5$.\n\n**11:56** Để nhắc lại cho mọi người, trong các buổi OGIF của chúng ta, ngoài các phần demo, sẽ luôn có những phần liên quan đến market commentary, cập nhật từ Go Weekly, AI, và sắp tới sẽ có thêm mảng product design.\n\n**12:47** Một thông báo cuối cùng, team ops đang sắp xếp cho chuyến company trip vào tháng 12 tới tại Penang, Malaysia. Thông tin chi tiết sẽ được chia sẻ trên kênh alert hoặc do Inno chia sẻ. Thành, còn gì nữa không hay Bảo muốn chia sẻ thêm gì với mọi người trước khi vào phần tiếp theo?\n\n**13:42** Không có gì thêm, anh chị em nhớ hoàn thành BP sớm nhé. Cung cấp thông tin qua Inno để chuẩn bị cho company trip. Rồi, Thành, mình chuyển tiếp qua phần OGIF thôi.\n\n**14:56** Hôm nay, mình dự định pick-up một vài demo về tool-building mà anh em đã làm trong đợt vừa rồi. Đầu tháng Bảo có phát động, nên hiện đang có một vài demo và commentary.\n\n**15:56** Đầu tiên, nhường diễn đàn cho bên phía design với phần của Nam Bùi. Nam ơi, em lên được chưa?\n\n**16:44** Dạ, em lên rồi. Hôm nay, em sẽ trình bày về chủ đề Product Design Commentary năm 2024 - phần 1. Em sẽ nói về các domain đang nổi, phổ biến và tương lai trong ngành Product Design. Đồng thời, em cũng đề cập đến những vấn đề đau đầu (pain points) mà các domain này gặp phải. Nếu team mình phát triển trong các mảng này, có thể dùng đó làm unique selling point.\n\n**16:56** Em sẽ đề cập đến 4 domain chính:\n\n1. VUI (Voice User Interface)\n2. AR/VR (Augmented/Virtual Reality)\n3. Modular Design Systems\n4. AI tools hỗ trợ quy trình UI/UX workflow.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/V44ifsSx7k8?si=DRpfCdpelj_z2GBM&amp;start=921\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**17:29** Đầu tiên, em nói về VUI. Hiện tại, VUI được ứng dụng nhiều trong ngành Smart Home, như điều khiển các thiết bị nhà thông minh, xe hơi thông minh. Dự đoán vào năm 2026, khoảng 50% dân số Mỹ sẽ sử dụng VUI trên các thiết bị của họ.\n\n**17:44** Ở Việt Nam, hiện FPT.AI đang là đơn vị mạnh nhất trong lĩnh vực này, với các ứng dụng như Kiki App tích hợp trong thiết bị ô tô để chỉ đường. Trên thế giới, các ứng dụng VUI phổ biến như Alexa của Amazon, Google Assistant, và Siri của Apple đang chiếm lĩnh thị trường.\n\n**17:44** Tổng hợp phản hồi từ người dùng, Alexa có ưu thế về NLP nhưng không mạnh về lập trình. Google Assistant tích hợp Google Search nên có kiến thức đa dạng nhưng không sâu. Siri là kém nhất trong ba, chủ yếu dùng Bing, nhưng giọng điệu của nó không được thân thiện lắm.\n\n**17:56** Chuyển qua PP (Predictive Programming), công nghệ này hiện chưa áp dụng nhiều cho tiếng Trung và tiếng Việt. Chủ yếu tập trung vào tiếng Anh và các ngôn ngữ phổ biến khác, do thiếu dữ liệu huấn luyện AI cho ngôn ngữ phức tạp. Nhưng trong tương lai, với sự phát triển về công nghệ và dữ liệu, em tin rằng PP sẽ trở nên phổ biến hơn với các ngôn ngữ này.\n\n**18:13** Về phần Predictive Programming (PP), công nghệ này hiện chưa áp dụng được rộng rãi cho các ngôn ngữ khác ngoài tiếng Anh. Những ngôn ngữ phức tạp như tiếng Trung hoặc tiếng Việt chưa được hỗ trợ tốt. Thường thì người sử dụng cần phải thành thạo tiếng Anh mới tận dụng hiệu quả được PP. Về mặt flexibility, PP hiện vẫn chưa đủ thông minh để hiểu mọi ngữ cảnh mà mình nói; nó chỉ hiểu được khi mình tuân theo đúng những mẫu câu lệnh đã được lập trình sẵn. Đây cũng là một điểm yếu cần được cải thiện trong tương lai.\n\n**19:00** Tiếp theo, em sẽ nói về lĩnh vực AR/VR (Augmented Reality/Virtual Reality). Lĩnh vực này hiện đang tập trung chủ yếu vào các ngành như e-commerce, bất động sản, giúp người dùng có thể trải nghiệm trực tiếp mà không cần phải đến tận nơi. Ví dụ, họ có thể xem trước căn nhà qua ứng dụng VR thay vì phải đến thăm trực tiếp. Năm 2019, giá trị thị trường của AR/VR chỉ khoảng 0,44 triệu tỷ đô, dự đoán đến năm 2024 sẽ đạt 1,73 tỷ đô, và có khả năng chạm mốc 40 tỷ đô vào năm 2027.\n\n**19:46** Tuy nhiên, nhiều doanh nghiệp đã thử ứng dụng AR/VR vào các website của họ, nhưng phần lớn đã rút lại do vấn đề hiệu suất không ổn định. Trong giai đoạn đầu năm 2023 đến cuối năm 2023, AR/VR được áp dụng rộng rãi, nhưng đến đầu năm 2024, nhiều doanh nghiệp bắt đầu rút khỏi website vì trải nghiệm người dùng kém, đặc biệt là khi người dùng truy cập mà gặp phải lag hoặc tốc độ tải chậm.\n\n**20:54** Điều này gây khó chịu cho người dùng, khiến họ nhanh chóng thoát khỏi trang web. Hơn nữa, chi phí để phát triển và duy trì AR/VR là rất cao, nên chỉ có những doanh nghiệp lớn, dư ngân sách mới đầu tư vào công nghệ này. Các doanh nghiệp vừa và nhỏ thường không muốn chi quá nhiều cho việc tích hợp AR/VR vào trang web của họ.\n\n**21:38** Phần tiếp theo là về Modular Data Systems, tập trung vào việc sử dụng các reusable design components giúp phối hợp hiệu quả giữa designer và developer. Hiện nay, trên thị trường có nhiều bộ design system phổ biến, kết hợp cả file UI Figma và các UI components hỗ trợ từ các thư viện.\n\n**22:17** Ví dụ phổ biến nhất là Ant Design System, tuy nhiên UI của Ant Design hiện đã hơi cũ. Ngoài ra, còn có các lựa chọn hiện đại hơn như Tailwind UI và Chakra UI. Cách phối hợp giữa designer và developer là cùng sử dụng một bộ file Figma từ thư viện, designer sẽ thiết kế dựa trên bộ đó, và developer sử dụng các component tương ứng để phát triển.\n\n**23:00** Ví dụ, nếu designer muốn làm một bảng (table), họ sẽ chọn component table trong Figma, còn developer sẽ sử dụng đúng component đó để xây dựng trong code. Điều này đảm bảo sự đồng nhất giữa thiết kế và việc triển khai, giúp giảm thiểu sai lệch giữa thiết kế và sản phẩm cuối cùng. Hiện tại, nhiều thư viện còn hỗ trợ responsive design, giúp developer không cần phải làm lại cho từng thiết bị khác nhau.\n\n**24:09** Đội ngũ của mình cũng có một team tên là Mochi đang phát triển bộ Design System riêng. Một vấn đề khi áp dụng các thư viện này là sản phẩm có thể thiếu đi sự độc đáo, dấu ấn riêng của từng ứng dụng. Ví dụ, 10 ứng dụng cùng sử dụng Ant Design thì giao diện sẽ rất giống nhau, không có sự khác biệt.\n\n**24:56** Do đó, designer và developer cần phải phối hợp rất chặt chẽ. Nếu designer muốn tùy chỉnh bất kỳ component nào trong Figma, họ cần thông báo ngay cho developer để cập nhật lại code tương ứng. Điều này đòi hỏi sự giao tiếp liên tục giữa hai bên để đảm bảo tính nhất quán trong suốt quá trình phát triển.\n\n**25:41** Về các công cụ AI hỗ trợ UX/UI, AI tools giúp chúng ta phân tích hành vi người dùng một cách chính xác và nhanh chóng. Về phần UI, AI có thể hỗ trợ tạo ra các components hoặc styles phù hợp với từng lĩnh vực khác nhau. Các công cụ như ChatGPT, Claude AI, và Midjourney đang làm rất tốt trong việc hỗ trợ nghiên cứu và phát triển UX/UI.\n\n**26:32** Hiện tại, về phần UI thì nó hỗ trợ phần lớn việc tạo ra các hình ảnh (image) nhưng không thể tạo ra được dạng vector hay pixel mà mình có thể chỉnh sửa được. Tuy nhiên, có một số công cụ đang cố gắng cải thiện, ví dụ như khi sử dụng công cụ Midjourney, mình có thể generate ra hình ảnh rồi đưa vào Figma, và hiện tại nó đã có khả năng copy ra thành các layout có auto layout của Figma luôn, giúp việc chỉnh sửa dễ dàng hơn.\n\n**27:24** Nhưng nhìn chung, output của AI về UI hiện tại chủ yếu vẫn chỉ ở dạng hình ảnh (image), rất hiếm khi có thể generate ra vector hoặc những component có thể sử dụng trực tiếp trong thiết kế. Đó là một điểm yếu và hạn chế của công nghệ AI hiện tại trong việc hỗ trợ thiết kế UI.\n\n**28:20** Đối với UX, em nhận thấy AI đang hỗ trợ tốt hơn rất nhiều. Ví dụ, khi mình nhận được một yêu cầu (requirement) ngắn gọn từ phía client, mình có thể thả vào ChatGPT để nó đưa ra một gợi ý về cấu trúc thông tin (info architecture) hoặc các giải pháp UX phù hợp. Thực tế là đôi khi em không nắm rõ hết các yêu cầu nhưng khi thả vào ChatGPT, nó lại cho ra những ý tưởng rất hữu ích, đáp ứng đúng nhu cầu của client.\n\n**28:55** Tuy nhiên, với UI, dù mình có sử dụng AI thì nó vẫn khó có thể tạo ra được những thiết kế đúng ý mình mong muốn. Ngay cả khi nó có thể tạo ra, thì output thường chỉ là dạng image, không phải là những file có thể sử dụng trực tiếp như Figma hay Sketch. Vì vậy, trong mảng UI, AI hiện tại vẫn còn nhiều hạn chế và cần được cải thiện thêm.\n\n**29:20** Anh có đồng ý với em không? Phần UX thì AI có vẻ đang làm tốt hơn UI.\n\n**29:45** Chính xác. Đặc biệt là khi mình làm việc với các yêu cầu dạng info architecture, AI thường cho ra các kết quả khá đúng và phù hợp, giúp tiết kiệm rất nhiều thời gian cho designer. Nhưng với UI, hiện tại vẫn cần có sự can thiệp của con người để đảm bảo tính thẩm mỹ và độ chính xác.\n\n**30:30** Nếu không còn câu hỏi nào khác, em xin phép kết thúc phần chia sẻ của mình. Rất cảm ơn mọi người đã lắng nghe và hy vọng mọi người có thể áp dụng được một vài điểm trong phần trình bày này vào công việc hàng ngày của mình.\n\n**31:00** Cảm ơn Nam Bùi về phần chia sẻ rất chi tiết và đầy đủ về Product Design Commentary 2024. Những insights về việc AI hỗ trợ UX/UI thực sự rất hữu ích và cung cấp cho team những góc nhìn mới về việc ứng dụng AI trong thiết kế. Hy vọng sẽ được nghe thêm nhiều bài chia sẻ thú vị từ bạn trong các buổi OGIF tiếp theo.\n\n**32:51 T**uần rồi em thấy có hai bài như thế này. Thực ra, còn một bài nữa liên quan đến GUI nhưng lát nữa em sẽ nói sau. Đầu tiên là bài về \"register allocation\" của Golang compiler. Bài này hơi phức tạp một chút nên em không thể đưa hết nội dung vào đây được. Chủ yếu là phía Go họ thực hiện việc register allocation thông qua bước SSA (Static Single Assignment).\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/V44ifsSx7k8?si=LMrFIMk9BdRppbOk&amp;start=2226\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\nMọi người có thể đọc tham khảo thêm ở trong link mà em đã bỏ vào đây. Nhưng nhìn chung, bài viết này tập trung vào quá trình tối ưu hóa việc compile bằng cách sử dụng SSA để quản lý register allocation.\n\n**37:43**  Để tổng kết lại, quá trình này giúp cải thiện thời gian compile của chương trình Golang. Cụ thể, nó tập trung vào việc tối ưu hóa hai bước chính là register allocation và stack allocation, từ đó giúp giảm khoảng 20% thời gian compile, đặc biệt hữu ích cho những ứng dụng Go có logic phức tạp hoặc những ứng dụng lớn.\n\nĐây là một bài viết rất chi tiết và kỹ lưỡng, được thực hiện bởi một trong những chuyên gia trong cộng đồng Rust. Bài viết này rất hữu ích cho những ai có quan tâm đến quá trình compiler hoặc muốn tìm hiểu sâu hơn về hiệu suất của Go.\n\n**38:17** Chuyển qua phần thứ hai liên quan đến lĩnh vực AI. Đó là một giải pháp mới có tên gọi BBQV, đây là một Vector Index được phát triển bởi một nhóm gọi là Dexa ở bên Mỹ. BBQV tập trung vào điểm mạnh chính của nó là \"scalable vector search.\" Điểm thú vị là BBQV không phải là giải pháp nhanh nhất, cũng không phải là giải pháp chính xác nhất, nhưng nó lại có khả năng build index cực kỳ nhanh so với các giải pháp khác. Xíu nữa em sẽ cho mọi người thấy biểu đồ mà nhóm tác giả của BBQV đã so sánh với các giải pháp ANN (Approximate Nearest Neighbor) khác.\n\n**39:13** Điều nổi bật của BBQV là khả năng build index với tốc độ rất nhanh, mặc dù carry time của nó chỉ nằm ở mức trung bình so với các giải pháp khác. Để so sánh cụ thể hơn, trên biểu đồ dưới đây, BBQV nằm ở khoảng giữa khi nói về carry time nhưng lại thuộc nhóm nhanh nhất về build time. Điều này là một điểm sáng khi triển khai BBQV trong các hệ thống AI có quy mô lớn, vì thời gian xây dựng index là rất quan trọng.\n\n**39:24** Ngoài ra, còn một bài nữa liên quan đến GUI trong Go. Mặc dù GUI trong Go không phải là một thế mạnh, em vẫn tìm thấy một số giải pháp GUI khá thú vị và muốn giới thiệu cho mọi người. Trong thời gian qua, cộng đồng Go đã cố gắng xây dựng các thư viện GUI có khả năng cạnh tranh với các giải pháp khác như Qt hay Electron. Tuy nhiên, phần lớn các giải pháp GUI này vẫn chưa thực sự hoàn thiện và thiếu tính năng so với những thư viện phổ biến từ các ngôn ngữ lập trình khác.\n\n**39:59** Đó là những gì mà bên team Dex đang dùng, Dex AI này đang xài cái đó, và nó cũng đã open-sourced rồi.\n\nBiểu đồ này cho thấy rằng BBQV có carry time không phải là nhanh nhất nhưng rất ổn định. Tuy nhiên, về mặt build time, BBQV là một trong những giải pháp nhanh nhất. Vì nó là kiểu \"selling point\" của nó, là để build một cái index thì xài thằng này là nhanh nhất.\n\nCòn về một bài nữa là GUI, mình không bỏ vào đây tại vì nhìn chung thì mình thấy bên Go GUI nó cũng hơi hạn chế. Nhưng mà mình kiếm được một thằng gọi là xịn nhất bên Go. Cái accessibility của nó, gallery của nó cũng đẹp, và nhìn chung là khá là mature. Mới đây có một ngôn ngữ mới tên là R, nó cũng viết bằng Go luôn, và nó cũng có một cái extension tích hợp với thằng GUI này. Nhìn chung nó trông như thế này thôi, ví dụ nó trông như thế này.\n\n**40:24** Ngoài ra, còn một bài nữa liên quan đến GUI trong Go. Mặc dù GUI trong Go không phải là một thế mạnh, em vẫn tìm thấy một số giải pháp GUI khá thú vị và muốn giới thiệu cho mọi người. Trong thời gian qua, cộng đồng Go đã cố gắng xây dựng các thư viện GUI có khả năng cạnh tranh với các giải pháp khác như Qt hay Electron. Tuy nhiên, phần lớn các giải pháp GUI này vẫn chưa thực sự hoàn thiện và thiếu tính năng so với những thư viện phổ biến từ các ngôn ngữ lập trình khác.\n\n**40:44** Hiện tại, team DEX AI bên mình đang sử dụng cái này. Nó là mã nguồn mở (open-source) nên rất tiện lợi khi tích hợp vào hệ thống của mình. Còn về mảng GUI, mình cũng tìm hiểu thêm về các thư viện (library) dành cho Go. Phải nói thật là GUI của Go vẫn còn khá hạn chế (tù túng), nhưng mình đã tìm được một thư viện gọi là Fyne. Đây là một trong những thư viện GUI tốt nhất hiện tại dành cho Go. Giao diện của nó (UI gallery) cũng rất đẹp và mature, nghĩa là nó đã khá hoàn thiện so với các thư viện khác.\n\n**41:45** Và gần đây, có một ngôn ngữ mới xuất hiện tên là Gio, cũng được viết bằng Go. Nó cung cấp một số extension có thể tích hợp trực tiếp với Fyne, tạo ra giao diện GUI như bạn thấy ở đây. Dường như xu hướng này đang phát triển khá nhanh trong cộng đồng Go. Về phần này, mình sẽ dừng ở đây để chuyển qua phần của Phát. Không biết Phát có muốn chia sẻ thêm không?\n\n**42:46** Ừm, theo quan sát của tôi thì thấy tên gọi BBQ đã trở nên phổ biến trong lĩnh vực vector database (vector DB). Nhiều dự án mới đều sử dụng BBQ vì tên nghe hay, nhưng thực ra các vector database như này đã vượt qua khái niệm đơn giản chỉ là dimensionality. Việc chọn vector DB nào phù hợp sẽ phụ thuộc nhiều vào yếu tố như hiệu năng và tính năng. BBQ tuy nghe vui, nhưng về tốc độ tìm kiếm (search speed) và hiệu quả tìm kiếm (recall), thì nó có thể không phải là nhanh nhất, nhưng vẫn đạt hiệu suất rất tốt. Nhanh nhất ở đây có lẽ phải kể đến thằng 'HNSW,' tuy nhiên BBQ vẫn là một sự lựa chọn ổn định.\n\n**44:03** Còn về các case study của những công ty lớn đang sử dụng Golang, chúng tôi đã thu thập được một số thông tin rất thú vị. Như đã đề cập, Google – đương nhiên không thể thiếu, vì họ là cha đẻ của Golang. Các doanh nghiệp lớn khác như Meta, Microsoft, và các công ty trong lĩnh vực tài chính như American Express, Monzo, và Paypal đều đã triển khai Go trong hệ thống của họ. Ở mảng streaming, Twitch cũng là một cái tên lớn đang sử dụng Go cho backend của mình. Trong mảng game, Riot Games cũng đã sử dụng Go trong một số dịch vụ. Tôi sẽ tiếp tục cập nhật thêm thông tin chi tiết về những case study này.\n\n**45:51** Đấy, bên bên bên bên Tom cái phần script chắc là thôi nhỉ, hơi basic hả? Ừ, cũng basic. Nếu còn thời gian thì demo nhanh được à. Rồi ok, thì mình nói về cái transcript YouTube. Thật ra là trước đó, trước đó team mình nó có một cái engine để xử lý cái phần này rồi, nhưng mà cái đó hình như bị hạn chế. Nó bị hạn chế bởi thời lượng 50 phút hay sao đó, nên mình mới viết lại một cái backend để process nó bằng cách sử dụng thằng Whisper API.\n\n**46:42** Thằng Whisper API này, nó có một cái gói free để transcribe audio. Một ngày nó cho phép mình transcribe khoảng 600 phút audio miễn phí, nhưng mỗi file chỉ có thể dài tối đa 2 tiếng. Mình tận dụng thằng Whisper API này để chuyển nội dung của video YouTube thành dạng văn bản. Quy trình cơ bản là khi mình đưa một link YouTube vào, hệ thống backend sẽ tự động tải về file video, sau đó chuyển đổi file đó thành định dạng MP3, rồi nén lại để kích thước file phù hợp với giới hạn của Whisper API (25MB mỗi file).\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/V44ifsSx7k8?si=ZHQ9rsOYdGBNBVNC&amp;start=2785\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\nThời gian nén và xử lý sẽ phụ thuộc vào độ dài của video gốc. Sau khi quá trình xử lý hoàn tất, hệ thống sẽ gửi từng đoạn audio đã nén lên Whisper API để tiến hành việc chuyển đổi từ âm thanh sang văn bản. Kết quả trả về từ API sẽ bao gồm thông tin chi tiết từng đoạn, từ thời gian bắt đầu đến kết thúc, và đoạn text tương ứng. Những đoạn này sau đó sẽ được combine lại và tiếp tục xử lý qua GPT-4 để tinh chỉnh, hiệu chỉnh câu chữ, đảm bảo văn bản đầu ra sát với ngôn ngữ gốc và chính xác hơn.\n\n**48:21** Dựa trên cái segment như vậy, mình combine nó lại rồi sử dụng GPT-4 để thực hiện việc hiệu chỉnh các tiểu tiết (tweak little details) ở đó. Thường thì tiếng Anh nó không bị sai gì hết. Nhưng mà tiếng Việt, nó lại có vấn đề với một số chỗ, ví dụ như ở miền Bắc, cách phát âm chữ dấu ngã thành dấu sắc, phát âm chữ 'r' thành 'd'. Khi mà ra được cái output như vậy, khi đọc thì nó sẽ bị sai về tay vô. Do đó, mình đưa cái content đó cho GPT-4 để nó chỉnh lại (correct) và kết quả là mình sẽ có một đoạn text hoàn chỉnh, đúng với bản gốc của video YouTube.\n\nSau khi ra được content như vậy, mình gửi lên cho D. Nó nhận được D này, cái app này nè, nó sử dụng một công cụ gọi tới cái backend hồi nãy và nó nhận được JSON như vậy. Từ đó, nó bật ra, và tiếp tục sử dụng một thư viện để render cái đoạn transcript như vậy. Nó trả về một đoạn nội dung như thế này, bao gồm full content.\n\n**49:55** Đó là cái mà mình đã làm được. Nếu mà mình sử dụng gói trả phí (subscription plan) của Whisper API luôn thì mình sẽ không bị giới hạn bởi việc cứ mỗi tiếng chỉ convert được khoảng hai tiếng audio. Tuy nhiên, có một giới hạn nữa là khi deploy lên server qua Heroku hay một số server khác, do quá trình xử lý audio này khá tốn thời gian, nên đôi khi gặp vấn đề timeout. Nhưng nếu mình chạy trực tiếp trên local thì mọi thứ sẽ mượt mà hơn rất nhiều.\n\nĐó là lý do tại sao mình sử dụng công cụ này ở bên phía project OIP. Có cái phần chỉnh sửa transcript mà anh em xem lại, không biết là đang dùng con này hay dùng cái gì khác?\n\nHiện tại, mình đang chỉnh lại config để sử dụng công cụ này cho phù hợp hơn. Cái của Tom hình như cũng đang bị đứt rồi hay sao ấy. Vì phần OGIF của mình hiện tại rất là dài, cũng hơn tiếng mấy, cho nên để process hết đoạn đó thì có thể cần phải cải thiện lại performance của công cụ này để nó có thể hoạt động tốt hơn.\n\n**50:40 H**iện tại mình đang dùng free API bên nào? Có ba cái workflow, hai cái là free API, một cái là của em, cái của em bị YouTube chặn rồi. Hình như nó không ổn định đúng không? Ừ, cũng có lúc ổn định lúc không, hai cái đều bị chặn hết rồi. Còn một cái API còn lại là Note GPT bên phía em Mỹ đang dùng, nhưng transcript dài thì cũng có khả năng bị crash thôi.\n\n**52:18** Ok, đúng rồi, lúc ổn định lúc không. Thực ra thì nếu video dưới 10 phút thì luôn work, còn bắt đầu dài hơn chút xíu thì còn tuỳ thuộc. Vấn đề là resources của server miễn phí, không biết là nó có reset được hay không. Còn nếu dài thì cứ đem cái source về local chạy là được hết.\n\n**53:35** Mọi người cũng thấy trên phần AI comment trên Discord, mình đã có một số script từ Twitter rồi. Thì bên phía cái quy trình mình đang làm là làm một cái API từ model Python script. Sau đó mình deploy nó luôn, mô hình này có một cơ chế cho phép mình deploy thẳng như là một cái API.\n\n**54:53** Sau đó mình sử dụng API này để script thông tin từ bên phía mình. Nó sẽ là một cái script chạy như vậy, nó là một cái function nằm trên container, chạy một browser đó, xem trong viewport và lấy các selector và thông tin từ text đó comp từ container của mình. Sau đó mình sẽ expose ra một cái POST request.\n\nPOST request này chỉ cần URL, ví dụ như mình lấy Twitter, hoặc lấy từ sc.com chẳng hạn.\n\n**55:39** Mình muốn script data này thì mình có thể test trực tiếp bên phía Postman request, nhưng với Dify, mình có thể test trực tiếp trên này luôn. Và cái hay nhất là khi mình test xong, mình có thể convert cái workflow từ Dify sang một cái function call, cái này có thể áp dụng trên một cái agent hoặc một cái gì đó riêng cho bên phía Dify nữa.\n\n**56:38 C**ái này có tích hợp bên phía Discord AI, cho nên có bạn nào muốn summarize lại từ Twitter thì chỉ cần post cái link vào, nó sẽ tự summarize. Hình như đang bị lag rồi. Chạy lại tiếp thử xem. Có vẻ như đang bị lag à? Nhưng cứ tưởng tượng là nó sẽ lấy được từ Twitter. Sau này sẽ dùng phương pháp này để script từ bên phía Facebook và bên phía Hoàng đang dùng phương pháp để upload một cái API qua mô hình để script và lấy dữ liệu từ Discord message.\n\n**57:53** Sở dĩ là khi mình gom lại thì Dify auto-convert thành một cái tool luôn. Bình thường mình có thể publish một cái app riêng, tương tác với nó. Hay hơn là mình tạo một cái workflow tool, nó sẽ sắp xếp như là một function call bên phía OpenAI.\n\n**58:37** Đây là cái Discord AI bot mọi người đang AI comment, mọi người đang dùng cho Discord của team mình. Hiện tại, nó có mấy cái tool mình tự làm như là Twitter script nằm ở trong này luôn. Một cái là lấy YouTube transcription của một dịch vụ bên phía tôi làm, một cái là query memo, nó là tooling mình làm để kéo data từ Memo của team mình. Còn lại là mấy cái tool có sẵn trên Dify. Lúc mình muốn add thì nó sẽ nằm ở trên cái list danh sách của workflow. Khi mình tạo workflow xong, sau đó deploy và configure nó, thì nó sẽ nằm hết ra ở trên này.\n\n**59:17** Thì chắc thử xem, \"What are the latest notes added to the doors?\" thì nó sẽ lấy Prompt Token ở trên description của tool và ở trên cái system prompt, nó sẽ biết là dùng tool nào cho phù hợp. Vậy là lấy data dựa vào hai yếu tố đúng không? Thứ nhất là cái system prompt của em, và thứ hai là cái description của tool. Dựa trên câu query ban đầu vào thì nó sẽ detect xem là nên sử dụng cái tool gì để process tiếp đúng không?\n\nDạ đúng rồi, nên ví dụ mình chọn cái này thì nó sẽ switch lại, xem cái nào phù hợp nhất, sau đó chạy cái tool cho mình. Sau đó nó có một cái agent chạy lấy data và gửi lại cho bên phía AI. Ở đây chắc là fail nhưng ý tưởng là như vậy thôi.\n\nOk, chắc phần của em xong rồi, chắc nhường lại cho người tiếp theo.\n\n**01:00:46 D**emo nhanh về itool để hỗ trợ làm memo, cái transcript hiện tại. Hiện tại là nó là dưới dạng một con Discord bot như thế này. Discord như thế này thì em đang host ở trên máy, tại vì server thì tốn tiền. Sẽ có hai cái command chính. Một cái là cái list, thì tính năng của nó đơn giản là nó sẽ có một cái account collect newsletter. Có nghĩa là cái data source của em là những cái newsletter email đó, em dùng một cái email để subscribe khoảng 100 chỗ, nhưng mà tất cả thì nó sẽ về thằng này. Và đơn giản là kiểu có email nào mới mà chưa đọc thì em cào về thôi.\n\nThì backend thì em build bằng Python. Cái app này thì kiểu 90% là xài core standard code.\n\n**01:02:55** Thì cái functionality của nó đơn giản là như thế này. Khi em cào về thì nó sẽ có một cái table article như thế này. Nó sẽ có một cái table article như vậy. Em sẽ lấy title, description cụ thể. Mấy cái này thì em dùng trên BeautifulSoup để lấy. Để sau em sẽ show sau. Nhưng mà về tính năng thì nó đơn giản kiểu vậy thôi.\n\nVí dụ như em muốn lấy bảy cái bài về một kiểu category. Ờ tất cả trong vòng bảy ngày. Em lấy tất cả những bài thuộc tất cả các category trong vòng bảy ngày. Đó thì nó sẽ trả ra vậy, presentation list kiểu như vậy.\n\nThì đây là cái feature đầu tiên là kiểu list ra những cái article mà em collect được từ bên phía email inbox thôi. Cái command thứ hai là \"lend draft cho memo\". Khi mà chạy, nó sẽ load lên kiểu như này.\n\n**01:03:33** Thì đây là cái feature đầu tiên là kiểu list ra những cái article mà em collect được từ bên phía cái email inbox thôi. Ờ một cái comment thứ hai là ờ lên draft cho Memo thì khi mà chạy á thì nó sẽ lên kiểu này. Ờ thì mấy cái như là mấy cái category, cái mấy cái main category mà giống như kiểu nếu mà mọi người có đọc mấy cái PR repo của em á thì mình chỉ có mấy cái kiểu mấy cái main stack của mình như thằng React hay là NestJS này thì nó sẽ wrap lên kiểu cũng giống như cái cấu trúc của bài Memo thôi.\n\n**01:04:14** Kiểu sẽ có 3 bài kiểu có điểm số cao nhất. Ờ rồi đây là sẽ năm bài, những cái bài relevant mà điểm số nó thấp hơn. Thì cái điểm số thì em có đánh theo kiểu nó là relevancy score. Kể vậy thì lúc mà em feed vào cho ChatGPT mini thì em sẽ yêu cầu con ChatGPT mini nó đánh, nó đánh score luôn. Ờ cụ thể cái prompt thì nó nằm ở đây. Đây là cái prompt cho ChatGPT mini kiểu vậy. Là ờ em sẽ cào hết cái email convert sang biotext giữ lại link rồi sau đó feed vô cho con ChatGPT mini với một list mấy cái criteria như thế này để cho\n\n**01:05:01** Nó đọc và nó extract, nó sẽ đánh relevancy score, nó extract article. Kiểu cái format nó giống kiểu ờ nó phải output format, cái format nó output à, dạ đây JSON array có title có description có link và cái danh sách criteria cùng với cái mớ relevancy score của nó thôi đó. Thì thì khi mà cào ra hết thì em bỏ vào cái database như vậy. Ờ cron job khi mà con bot này nó chạy á thì hiện tại em cron job cho nó chạy. Gọi sẽ có một cái job để nó chạy mỗi, nó chạy mỗi ngày thì sẽ vào lấy chỉ lấy những cái email mà chưa đọc thôi.\n\n**01:05:56** Cái thứ hai là kiểu dùng được ChatGPT Mini này là 3.5 Pro thì đang xài cũng miễn phí luôn. Thì thằng ChatGPT mini pro này nó đang cho phép mọi người lên xài miễn phí lấy API access token của nó, mỗi ngày nó sẽ cho 1 triệu token cứ muốn xài sao xài. Thì thấy cái này Ok. Ờ dạ một số cái vấn đề hiện tại với con bot này thì cái thứ nhất là\n\n**01:06:40** Một số vấn đề hiện tại với con bot này thì cái thứ nhất là em chưa có filter ra mấy cái quảng cáo. Em em lúc mà bắt filter ra mấy cái quảng cáo. Cái thứ hai là kiểu như tin rác khá là nhiều ở cái kiểu mấy cái newsletter, đôi khi nó nó include luôn những cái link như những cái description trên GitHub, những cái PR nào được merge. Cái kiểu có nhiều cái newsletter nó nó cũng khá là nhiều tin rác kiểu vậy. Em vẫn đang optimize cái prompt để cho nó relevant hơn cái use case của team mình thôi. Nhưng mà nói chung là về functionality thì hiện tại thì em nghĩ là ok rồi, giờ chỉ có\n\n**01:07:16** Nhưng mà nói chung là về functionality thì hiện tại thì em nghĩ là ok rồi, giờ chỉ có ****optimize cái prompt thôi, chắc là vậy với lại chắc optimize cái relevancy score. Ờ tại vì hiện tại xài free cho nên đang bị thiếu một cái bước là vào từng cái article để cào content đọc rồi mới đánh relevancy. Hiện tại là relevancy score nó đánh là nó đánh dựa trên cái description mà được cung cấp bên bên cái newsletter thôi. Cho nên nói chung nó vẫn củ chuối. Để coi sao để để tìm cái model nào mà nó free hoặc là chạy local đó cho nó chạy nó cào rồi nó đọc. Thế còn hiện tại thì ChatGPT mini 3.5 pro tới cào chừng 15 email là nó hết. Nó nó hết quota.\n\n**01:08:02** Mỗi ngày em chạy vô cào được mấy cái. Dạ thì chắc là game nó vậy thôi. Ok hôm trước anh có comment là cái vụ viết cái commentary về feature thì nó đang thiếu sao ta, mới chỉ đọc link với cả đọc title thì chưa đủ, phải vọc vào content vọc vào parse parse parse bên trong ấy ra. Nói chung là sẽ có thôi anh, chắc là chắc là sau cái này thì em sẽ tìm một cái model free local đó để nó handle cái vụ cào với lại parse content. Kiểu để đánh relevancy lúc đầu thật ra là lúc đầu là em xài vector cộng với similarity để match với lại\n\n**01:08:58** Kiểu để đánh relevancy lúc đầu thật ra là lúc đầu là em xài vector cộng với similarity để match với lại mấy cái category. Nhưng mà kiểu nó đánh đánh kiểu gì á em cũng không biết, do em set up sai hay sao. Tại vì cũng kêu con OpenAI nó generate embedding không à. Xong cái nó đánh cái kiểu gì mà kiểu không có match được cái article nào hết. Xong cái em mệt quá em kêu con ChatGPT làm luôn. Ừ ok rồi thì mấy anh em mấy anh em đang sort mấy cái link từ bên kia mấy cái stack khác ấy xem có tham khảo hay là crawl các thứ thì xem thử. Ừ Ok chắc test thêm. Còn về mặt hosting thì nếu mà cần thì thì nhắn Quang ấy. Hiện tại dừng này lên thôi mình mấy con bot\n\n**01:09:48** Hiện tại dừng này lên thôi mình mấy con bot của mình trên đó là hiện tại bây giờ có đang expose với webhook Discord bot không anh? Bảo em tạo cái có thể expose API ra ấy. Còn em em host một cái function nào đấy để run thì Discord nó hay xài, model còn không bảo bảo Quang host setup service host tự chọn host cho. Dạ à Quảng model cũng ok đấy model Ok free sao ấy. Ý là ở trên Discord phải nó đâu có cho mình host data đúng không anh? Tại vì hiện tại bây giờ là phải đi cào với lại lưu vào database mà. À đúng rồi nhỉ thấy cái tự setup rồi. Ừ anh chắc để em hoàn thiện hơn tí là cái gì em liên hệ anh Quang.\n\n**01:10:39** Nó chỉ là một cái bước nói là cái expose API để access data thôi còn anh em muốn lưu trữ hay là thành index các thứ gì thấy tự set up rồi ok. Ok bây giờ đang hỏi là có đâu rồi ta chạy rồi à. Bây giờ đang hỏi là có handle in-memory được không anh? Ờ nó nó nó nó. Ý là em em đang làm này là kiểu lưu về ý là batch với lại database, batch process ngay cái lúc mà cào á để lưu lại để mình cho requery thì những lần ý là mình chỉ cần cào dưới dưới. Dạ cron job thôi thì khi mà người ta query thì cái trả, cái phản hồi nó sẽ là realtime mình ý là nó trả, hồi nó nó\n\n**01:11:44** Cron job thôi thì khi mà người ta query thì cái trả, cái phản hồi nó sẽ là realtime mình ý là nó trả, hồi nó mình sẽ không cần phải, mình sẽ không cần phải làm mấy cái đó. Nếu như mà có làm in-memory này kia thì em nghĩ chắc chỉ thêm cái runtime inference thôi kiểu cho người ta query bằng ngôn ngữ tự nhiên chứ không có kiểu comment với param. Như hiện tại còn còn cái chuyện mà đi collect article thì em nghĩ em em nghĩ là vẫn nên cào rồi process rồi lưu trong database chứ chứ nếu không mỗi lần chạy đều phải cào mấy trăm article thì chết tiền à. Ủa hiện như thế nào ta? Crawl lại crawl lại được không ta? \n\n**01:12:44** Mình không set lại đâu. Thôi vì đây là một cái engineering solution nên là mình phải có cái gì cho dữ liệu back pressure thì phải cần storage. Nói chung là có cách là mình mình bơm thêm tiền thôi. Ừ trả tiền thì có nó run thôi ok rồi cảm ơn ạ. Ok check xem thử đi. Đang đang lúc này tin đang bảo là tuần sau là những cái buổi thứ tư thì hiện tại đang có cái cái cái này demo các thứ cũng đang còn tương đối đấy chắc là cũng phải 4, 5 bài nữa thì chắc mình schedule sang thứ tư rồi anh em demo sau đấy. Để tôi chấm điểm đánh giá luôn hả? Ok ý còn lại nếu không\n\n**01:13:55** Nếu không ai quất thêm mấy cái copilot còn lại thì mình sẽ làm hết đấy. Ăn hết tiền của mọi người đấy. Okay. Ơ mà chi phí đợt, tò mò tí chi phí đợt vừa rồi anh em chạy vẫn đang xài key của em đúng không hả Tô? Ờ có đúng chắc là mọi người không có tới 1 triệu token đâu vậy. Hả? Chưa tới. Chưa tới. Dạ chưa tới. Bao nhiêu đấy? Vậy hả? Giỏi ta thật! Anh em cũng test hết đấy không bằng không bằng em hoặc là đặt prompt clean deep đâu. Không bằng đâu. Ok nếu mà vẫn thì xài thử đi thôi. \n\n**01:15:08** Hẹn anh em thứ tư tuần sau. Chúc mọi người cuối tuần vui vẻ nhé. \n\n---\n\n**English Transcript**\n\n**00:00** Hello everyone, OK we're good now. Is that Thanh speaking? Can't hear you, please check your mic.\n\n**00:20** OK, we can hear you now. Let's wait for Ngoc to join for a bit before we start. We'll mainly discuss a few recent issues, probably 70% of the time will be spent on our internal matters.\n\n**00:40** We have 36 participants now, are we waiting for anyone else? If not, let's begin. Let's quickly go through some events from last month: We've returned to a hybrid work culture, encouraging everyone to come to the office a few days each week.\n\n**06:47** The purpose of coming to the office is to exchange knowledge and learn from each other more quickly compared to working online or just through OGIF sessions. After a few weeks of implementing this program, people seem quite enthusiastic. Additionally, there are several policies to support coming to the office, such as receiving ICY when checking in, and also for parking. Moreover, lunch for everyone will also be supported.\n\n**07:20** As you all know, our direction is to learn and implement as many AI and LLM-related projects as possible. I see that you're quite interested in the prompting tutorial series from Tom or new knowledge. Thanh, please share more.\n\n**07:58** I noticed that we usually have OGIF at the end of Friday, but now we've added Tom's demo session on Wednesday. In the coming time, we plan to maintain this cycle for about 1-2 more months. The purpose is to promote the use of AI tools, automation tools for work, and to learn more techniques related to applications.\n\n**08:40** Everyone should keep track to know the situation and update on current tools. Mainly, we'll learn how to build up, use tools, such as defining workflows, writing prompts correctly to apply to coding work or development-related tasks. Tom will probably be in charge of this and update knowledge for everyone.\n\n**09:23** In addition, we currently have a few policies to encourage people to focus more on AI/LLM. For example, activities or demos related to LLM from this week, the amount of ICY reward will be multiplied by 3 or 4 times, depending on the quality of the article or output. This is an encouragement for those interested in AI.\n\n**10:13** For more specific goals, perhaps early next week there will be a detailed announcement about what to focus on and which tools to use. That's it in summary, that's the general situation.\n\n**10:58** OK, thank you Thanh. So, AI-related research activities will receive 3 or 4 times the reward. Someone asked if spamming AI-related links would earn more ICY? We'll probably consider that further, each ICY is equivalent to $1.5.\n\n**11:56** To remind everyone, in our OGIF sessions, besides the demo parts, there will always be sections related to market commentary, updates from Go Weekly, AI, and soon we'll add a product design section.\n\n**12:47** One last announcement, the ops team is arranging for a company trip this December in Penang, Malaysia. Detailed information will be shared on the alert channel or by Inno. Thanh, is there anything else, or does Bao want to share anything more with everyone before we move on to the next part?\n\n**13:42** Nothing more, everyone remember to complete the BP early. Provide information through Inno to prepare for the company trip. Alright, Thanh, let's move on to the OGIF section.\n\n**14:56** Today, we plan to pick up a few demos about tool-building that you guys have done recently. Bao initiated it at the beginning of the month, so there are currently a few demos and commentaries.\n\n**15:56** First, let's give the floor to the design side with Nam Bui's part. Nam, are you ready?\n\n**16:44** Yes, I'm ready. Today, I'll present on the topic of Product Design Commentary for 2024 - Part 1. I'll talk about emerging, popular, and future domains in the Product Design industry. At the same time, I'll also mention the pain points that these domains face. If our team develops in these areas, we can use that as a unique selling point.\n\n**16:56** I'll cover 4 main domains:\n\n1. VUI (Voice User Interface)\n2. AR/VR (Augmented/Virtual Reality)\n3. Modular Design Systems\n4. AI tools supporting UI/UX workflow.\n\n**17:29** First, let's talk about VUI. Currently, VUI is widely applied in the Smart Home industry, such as controlling smart home devices, smart cars. It's predicted that by 2026, about 50% of the US population will use VUI on their devices.\n\n**17:44** In Vietnam, FPT.AI is currently the strongest in this field, with applications like Kiki App integrated into car devices for navigation. Worldwide, popular VUI applications like Amazon's Alexa, Google Assistant, and Apple's Siri are dominating the market.\n\n**17:44** Summarizing user feedback, Alexa has an advantage in NLP but is not strong in programming. Google Assistant integrates Google Search, so it has diverse but not deep knowledge. Siri is the weakest of the three, mainly using Bing, but its tone is not very friendly.\n\n**17:56** Moving on to PP (Predictive Programming), this technology is not yet widely applied to Chinese and Vietnamese. It mainly focuses on English and other popular languages, due to the lack of AI training data for complex languages. But in the future, with technological and data developments, I believe PP will become more popular with these languages.\n\n**18:13** Regarding Predictive Programming (PP), this technology is not yet widely applicable to languages other than English. Complex languages like Chinese or Vietnamese are not well supported. Usually, users need to be proficient in English to effectively utilize PP. In terms of flexibility, PP is not yet smart enough to understand every context we speak; it only understands when we follow exactly the pre-programmed command patterns. This is also a weakness that needs to be improved in the future.\n\n**19:00** Next, I'll talk about AR/VR (Augmented Reality/Virtual Reality). This field is currently focusing mainly on industries like e-commerce, real estate, helping users to experience directly without having to be physically present. For example, they can preview a house through a VR application instead of visiting in person. In 2019, the market value of AR/VR was only about $0.44 trillion, predicted to reach $1.73 trillion by 2024, and potentially hit $40 trillion by 2027.\n\n**19:46** However, many businesses have tried to apply AR/VR to their websites, but most have withdrawn due to unstable performance issues. From early 2023 to late 2023, AR/VR was widely applied, but by early 2024, many businesses started to withdraw from websites due to poor user experience, especially when users access and encounter lag or slow loading speeds.\n\n**20:54** This frustrates users, causing them to quickly leave the website. Moreover, the cost to develop and maintain AR/VR is very high, so only large businesses with surplus budgets can invest in this technology. Small and medium-sized businesses often don't want to spend too much on integrating AR/VR into their websites.\n\n**21:38** The next part is about Modular Data Systems, focusing on using reusable design components to help effectively coordinate between designers and developers. Currently, there are many popular design systems on the market, combining both Figma UI files and UI components supported by libraries.\n\n**22:17** The most popular example is the Ant Design System, however, the UI of Ant Design is now a bit outdated. In addition, there are more modern choices like Tailwind UI and Chakra UI. The way designers and developers collaborate is by using the same set of Figma files from the library, the designer will design based on that set, and the developer uses the corresponding components to develop.\n\n**23:00** For example, if a designer wants to create a table, they'll choose the table component in Figma, and the developer will use that exact component to build in code. This ensures consistency between design and implementation, helping to minimize discrepancies between the design and the final product. Currently, many libraries also support responsive design, helping developers avoid having to redo for different devices.\n\n**24:09** Our team also has a team called Mochi that's developing its own Design System. One issue when applying these libraries is that the product may lack uniqueness, the distinctive mark of each application. For example, if 10 applications use Ant Design, their interfaces will look very similar, with no differentiation.\n\n**24:56** Therefore, designers and developers need to coordinate very closely. If a designer wants to customize any component in Figma, they need to immediately notify the developer to update the corresponding code. This requires continuous communication between both sides to ensure consistency throughout the development process.\n\n**25:41** Regarding AI tools supporting UX/UI, AI tools help us analyze user behavior accurately and quickly. For UI, AI can help create components or styles suitable for different fields. Tools like ChatGPT, Claude AI, and Midjourney are doing very well in supporting UX/UI research and development.\n\n**26:32** Currently, for UI, it mostly supports creating images but can't create vector or pixel formats that we can edit. However, some tools are trying to improve this. For example, when using Midjourney, we can generate images and import them into Figma, and now it has the ability to copy them into layouts with Figma's auto layout, making editing easier.\n\n**27:24** But in general, AI's output for UI is still mainly in image format, rarely able to generate vectors or components that can be used directly in design. This is a weakness and limitation of current AI technology in supporting UI design.\n\n**28:20** For UX, I notice AI is supporting much better. For example, when we receive a brief requirement from the client, we can input it into ChatGPT to get a suggestion about information architecture or suitable UX solutions. In fact, sometimes I don't fully grasp all the requirements, but when I input them into ChatGPT, it provides very useful ideas that meet the client's needs.\n\n**28:55** However, with UI, even if we use AI, it's still difficult to create designs exactly as we want. Even if it can create them, the output is usually just in image format, not files that can be used directly like Figma or Sketch. Therefore, in the UI area, current AI still has many limitations and needs further improvement.\n\n**29:20** Do you agree with me? AI seems to be doing better with UX than UI.\n\n**29:45** Exactly. Especially when we work with information architecture requirements, AI often produces quite accurate and appropriate results, saving designers a lot of time. But with UI, human intervention is still needed to ensure aesthetics and accuracy.\n\n**30:30** If there are no other questions, I'd like to conclude my presentation. Thank you all for listening, and I hope you can apply some points from this presentation to your daily work.\n\n**31:00** Thank you, Nam Bui, for the very detailed and comprehensive presentation on Product Design Commentary 2024. The insights about AI supporting UX/UI are really useful and provide the team with new perspectives on applying AI in design. We hope to hear more interesting presentations from you in future OGIF sessions.\n\n**32:51** Last week, I saw two articles like this. Actually, there's another one related to GUI, but I'll talk about that later. First is the article about \"register allocation\" of the Golang compiler. This article is a bit complex, so I can't include all the content here. Mainly, Go implements register allocation through the SSA (Static Single Assignment) step.\n\nYou can read more in the link I've put here. But in general, this article focuses on the process of optimizing compilation using SSA to manage register allocation.\n\n**37:43** To summarize, this process helps improve the compile time of Golang programs. Specifically, it focuses on optimizing two main steps: register allocation and stack allocation, thereby helping to reduce compile time by about 20%, especially useful for Go applications with complex logic or large applications.\n\nThis is a very detailed and thorough article, written by one of the experts in the Rust community. This article is very useful for those interested in the compiler process or wanting to learn more about Go's performance.\n\n**38:17** Moving on to the second part related to AI. It's a new solution called BBQV, a Vector Index developed by a group called Dexa in the US. BBQV focuses on its main strength of \"scalable vector search.\" The interesting point is that BBQV is neither the fastest solution nor the most accurate, but it has the ability to build indexes extremely quickly compared to other solutions. In a moment, I'll show you the chart where the BBQV authors compared it with other ANN (Approximate Nearest Neighbor) solutions.\n\n**39:13** The outstanding feature of BBQV is its ability to build indexes very quickly, although its query time is only average compared to other solutions. To compare more specifically, on the chart below, BBQV is in the middle when it comes to query time but is among the fastest in build time. This is a bright spot when deploying BBQV in large-scale AI systems, as index building time is very important.\n\n**39:24** Additionally, there's another article related to GUI in Go. Although GUI in Go is not a strength, I still found some interesting GUI solutions and want to introduce them to everyone. Recently, the Go community has been trying to build GUI libraries that can compete with other solutions like Qt or Electron. However, most of these GUI solutions are still not really complete and lack features compared to popular libraries from other programming languages.\n\n**39:59** That's what the Dex team is using, Dex AI is using this, and it's also been open-sourced.\n\nThis chart shows that BBQV's query time is not the fastest but very stable. However, in terms of build time, BBQV is one of the fastest solutions. Because it's kind of its \"selling point\", to build an index, using this one is the fastest.\n\nAs for another article about GUI, we didn't include it here because generally, we see that Go GUI is somewhat limited. But we found one that's considered the best in Go. Its accessibility, its gallery is also beautiful, and overall it's quite mature. Recently, there's a new language called R, it's also written in Go, and it also has an extension integrated with this GUI. Overall it looks like this, for example it looks like this.\n\n**40:24** In addition, there's another topic related to GUI in Go. Although GUI is not a strong point in Go, I still found some interesting GUI solutions and want to introduce them to everyone. In recent times, the Go community has been trying to build GUI libraries that can compete with other solutions like Qt or Electron. However, most of these GUI solutions are still not fully developed and lack features compared to popular libraries from other programming languages.\n\n**40:44** Currently, our DEX AI team is using this. It's open-source, so it's very convenient to integrate into our system. As for the GUI aspect, I've also researched more about libraries for Go. To be honest, Go's GUI is still quite limited (constrained), but I found a library called Fyne. This is one of the best GUI libraries currently available for Go. Its interface (UI gallery) is also very beautiful and mature, meaning it's quite well-developed compared to other libraries.\n\n**41:45** And recently, a new language called Gio has emerged, also written in Go. It provides some extensions that can be directly integrated with Fyne, creating GUI interfaces as you see here. It seems this trend is developing quite rapidly in the Go community. For this part, I'll stop here to move on to Phat's section. I don't know if Phat wants to share more?\n\n**42:46** Um, from my observation, I've noticed that the name BBQ has become popular in the field of vector databases (vector DB). Many new projects use BBQ because the name sounds good, but in reality, vector databases like this have gone beyond the simple concept of dimensionality. Choosing which vector DB is suitable will depend a lot on factors like performance and features. Although BBQ sounds fun, in terms of search speed and recall efficiency, it may not be the fastest, but it still achieves very good performance. The fastest here might be 'HNSW,' however, BBQ is still a stable choice.\n\n**44:03** As for case studies of large companies using Golang, we have gathered some very interesting information. As mentioned, Google - of course, can't be missed, because they are the creators of Golang. Other big businesses like Meta, Microsoft, and companies in the financial sector like American Express, Monzo, and Paypal have all implemented Go in their systems. In the streaming sector, Twitch is also a big name using Go for their backend. In the gaming industry, Riot Games has also used Go in some of their services. I will continue to update more detailed information about these case studies.\n\n**45:51** There, on Tom's side, the script part is probably basic, right? Yes, it's quite basic. If there's time, we can quickly demo it. Okay, so let's talk about the YouTube transcript. Actually, before that, our team already had an engine to process this part, but it seemed to be limited. It was limited by a duration of 50 minutes or something, so I rewrote a backend to process it using the Whisper API.\n\n**46:42** This Whisper API has a free package for audio transcription. It allows us to transcribe about 600 minutes of audio for free per day, but each file can only be up to 2 hours long. We utilize this Whisper API to convert YouTube video content into text format. The basic process is when we input a YouTube link, the backend system automatically downloads the video file, then converts that file to MP3 format, and then compresses it to fit the file size limit of the Whisper API (25MB per file).\n\nThe compression and processing time will depend on the length of the original video. After the processing is complete, the system will send each compressed audio segment to the Whisper API to perform the conversion from audio to text. The results returned from the API will include detailed information for each segment, from start time to end time, and the corresponding text. These segments will then be combined and further processed through GPT-4 to refine and adjust the wording, ensuring the output text closely matches the original language and is more accurate.\n\n**48:21** Based on such segments, we combine them and use GPT-4 to tweak little details there. Usually, English doesn't have any errors. But for Vietnamese, it has issues with some parts, for example, in the North, pronouncing the falling tone as rising tone, pronouncing 'r' as 'd'. When we get such output, when reading, it will be incorrect. Therefore, we feed that content to GPT-4 for it to correct, and as a result, we'll have a complete text that matches the original YouTube video.\n\nAfter getting such content, we send it up to D. It receives this D, this app, it uses a tool to call the backend from earlier and it receives JSON like this. From there, it pops up, and continues to use a library to render the transcript like this. It returns a content section like this, including the full content.\n\n**49:55** That's what we've been able to do. If we use the subscription plan of Whisper API, we won't be limited by only being able to convert about two hours of audio every hour. However, there's another limitation when deploying to a server via Heroku or some other servers, because this audio processing is quite time-consuming, so sometimes there are timeout issues. But if we run directly on local, everything will be much smoother.\n\nThat's why we use this tool on the OIP project side. There's a part for editing transcripts that you guys review, I'm not sure if it's using this one or something else?\n\nCurrently, we're adjusting the config to use this tool more appropriately. Tom's part seems to be broken or something. Because our current OGIF part is very long, also over an hour, so to process that entire segment, we may need to improve the performance of this tool to make it work better.\n\n**50:40** Which free API are we currently using? There are three workflows, two are free APIs, one is mine, mine has been blocked by YouTube. It seems unstable, right? Yeah, it's stable sometimes and not at other times, both have been blocked. There's one API left, Note GPT, which My's side is using, but for long transcripts, it's also likely to crash.\n\n**52:18** Ok, that's right, sometimes it's stable, sometimes it's not. Actually, if the video is under 10 minutes, it always works, but once it gets a bit longer, it depends. The issue is with the resources on the free server; it's uncertain whether it can reset or not. But if it's long, you can just bring the source back and run it locally.\n\n**53:35** You all can see on the AI comment section on Discord, we've already got some scripts from Twitter. So, the process we're working on is creating an API from the Python model script. After that, we deploy it directly; this model has a mechanism that allows us to deploy it directly as an API.\n\n**54:53** We then use this API to script information from our side. It acts like a script running like this, a function on a container that runs a browser, looks into the viewport, and takes the selectors and text information from that container of ours. Then, we expose it as a POST request.\n\nThis POST request only needs a URL. For example, if we want to fetch data from Twitter, or take it from sc.com, for instance.\n\n**55:39** If we want to script this data, we can test it directly on the Postman request, but with Dify, we can test it directly on here. And the best part is, after testing, we can convert the workflow from Dify into a function call, which can be applied on an agent or something else specific for Dify.\n\n**56:38** This is integrated with Discord AI, so if anyone wants to summarize from Twitter, they just need to post the link, and it will automatically summarize it. It seems to be lagging now, though. Let's try running it again. It seems to be lagging, but just imagine that it's fetching from Twitter. Later, we'll use this method to script from Facebook, and Hoang is using this method to upload an API through a model to script and pull data from Discord messages.\n\n**57:53** This is when we consolidate it; Dify can auto-convert it into a tool. Normally, you can publish it as a standalone app and interact with it. What's better is that you create a workflow tool, and it will arrange it like a function call on the OpenAI side.\n\n**58:37** This is the Discord AI bot that everyone is using for AI comments within our team Discord. Currently, it has several tools we've made ourselves, like the Twitter script that's integrated here. Another is for obtaining YouTube transcriptions from a service that I made, and another is for querying memos, which is tooling I created to pull data from our team's Memo. The rest are tools available on Diffy. When you want to add a tool, it will be listed in the workflow list. After creating a workflow, deploying, and configuring it, it will all be displayed here.\n\n**59:17** Let’s try, “What are the latest notes added to the doors?” It will take the Prompt Token from the tool’s description and the system prompt to determine the most appropriate tool to use. So, it fetches data based on two factors, right? The first is your system prompt, and the second is the tool’s description. Based on the initial query input, it detects which tool should be used for the next process, right?\n\n**01:00:46** Quick demo of the tool to support memo creation, specifically the current transcript. Right now, it functions as a Discord bot like this. I'm hosting it on my machine because servers cost money. It has two main commands. One is the list command, and its functionality is simple—it has an account that collects newsletters. This means the data source consists of newsletter emails. I use an email to subscribe to about 100 different sources, but everything comes to this one. It's simple: any new email that hasn't been read yet, I scrape it.\n\nFor the backend, I built it using Python. This app is 90% standard core code.\n\n**01:02:55** The functionality is straightforward. When I scrape, it will create a table of articles like this. It creates a table with the title and description in detail. I use BeautifulSoup to extract these, which I'll show later. But in terms of functionality, it's pretty simple.\n\nFor example, if I want to retrieve seven articles from a specific category, all within seven days, I fetch all articles that belong to all categories within seven days. Then it returns in this kind of presentation list.\n\nThis is the first feature—listing the articles I’ve collected from the email inbox. The second command is “lend draft to memo.” When running it, it loads up like this.\n\n**01:03:33** This is the feature that lists the articles collected from the email inbox. Another command is “lend draft to memo,” which, when executed, loads like this. For instance, if you’ve read my GitHub repositories, we have a few main stacks like React or NestJS. It structures it similarly to a Memo article.\n\n**01:04:14** It provides three articles with the highest scores. Then there are five relevant articles with lower scores. The scoring is based on relevancy. When feeding it into ChatGPT mini, I ask it to score as well. The prompt is located here. This is the prompt for ChatGPT mini.\n\nI scrape all the emails, convert them to plain text, keep the link, then feed them to ChatGPT mini with a list of criteria like this.\n\n**01:05:01** It reads, extracts, and assigns a relevancy score, extracting articles. The format resembles a JSON array with the title, description, link, criteria list, and the relevancy score. After scraping everything, I store it in the database like this. A cron job is set to run every day, fetching only unread emails.\n\n**01:05:56** The second feature is using ChatGPT Mini 3.5 Pro, which is currently free. ChatGPT Mini Pro allows free API access tokens, giving 1 million tokens daily for free. So far, it works fine. Some issues with the bot are that I haven't filtered out ads yet, and there's quite a bit of spam in newsletters.\n\n**01:06:40** One of the current issues with this bot is that I haven't filtered out ads. The second issue is spam in newsletters; sometimes, it includes links like GitHub descriptions, merged PRs, etc. Some newsletters contain a lot of spam. I'm still optimizing the prompt to make it more relevant for our team's use case. Functionality-wise, it's okay for now; I just need to optimize the prompt.\n\n**01:07:16** Optimizing the prompt is the main focus, and I need to optimize the relevancy score. Because it's currently free, it lacks the step to scrape content from each article and read it before scoring relevancy. Currently, the relevancy score is based only on the description provided by the newsletter, which is still inadequate. I’ll look for a model that's free or runs locally to handle scraping and reading content. Currently, ChatGPT Mini 3.5 Pro can handle scraping about 15 emails before it reaches its quota.\n\n**01:08:02** Every day, I scrape only a few. As for future enhancements, I’ll try to find a free local model to handle scraping and parsing content. Initially, I used vectors and similarity to match categories, but the scoring setup was somehow wrong. The embeddings generated by OpenAI weren't matching any articles correctly, so I eventually let ChatGPT handle it.\n\n**01:08:58** Then the team can look at links from different stacks, consider references, or run their own tests. If hosting is needed, contact Quang. We have our bots running on our own servers.\n\n**01:09:48** If needed, you can expose APIs to Discord bots. I created one that can expose APIs, and you can host any function you need to run. Dify uses models or Quang hosts setup service; you choose what to host yourself. Dify's model is quite okay and free to use. It doesn't allow hosting data directly, so right now, we're scraping and saving into a database. You might need to set up the system yourself.\n\n**01:10:39** It’s just an extra step for exposing APIs for accessing data. You decide on storage or indexing. Okay, now they’re asking, can it handle in-memory? I’m doing batch processing immediately when scraping, saving for requery purposes later. When someone queries, the response is real-time; you won’t need to run multiple times.\n\n**01:11:44** Cron jobs handle data collection; for querying, in-memory or local runtime inference can be added to enable querying through natural language rather than with parameters. I believe content collection should be processed and stored in a database; otherwise, scraping hundreds of articles every time would be costly.\n\n**01:12:44** You can't avoid setting this up. As this is an engineering solution, storage is needed for data and backpressure. One option is adding more funding for it to run as required. Thanks. Let's check later; Wednesday's demo sessions have quite a lot already—maybe four to five more presentations. We might have to schedule for Wednesday.\n\n**01:13:55** If no one else wants to handle the remaining Copilot tasks, we’ll take them all. Eat up everyone's money! Out of curiosity, the recent expenses, are they still using my API key, Tô? Yes, I believe everyone hasn't reached 1 million tokens yet.\n\n**01:15:08** Anyway, see you all next Wednesday. Have a great weekend.\n","title":"OGIF Office Hours #25 - Team & Community updates, Hybrid culture, Product design commentary, AI Tooling Insights, Golang weekly","short_title":"#25 Team updates, Hybrid work, AI insights, Go weekly","description":"OGIF Office Hours 25 covers the latest insights on hybrid work culture, AI-driven tooling and workflows, Golang compiler optimizations, and AI-enhanced design strategies. Explore discussions on AR/VR trends, voice user interfaces, AI tools for UI/UX, predictive programming, and team demos showcasing AI integrations and Golang performance tweaks.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Mon Sep 30 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/25-20240927.md","slugArray":["updates","ogif","25-20240927"]},{"content":"\n### Topic highlights\n\n1. Nam Bui's presentation on product design:\n    - Introduction to the Sparkle icon and its use in AI applications.\n    - Sharing insights on onboarding new users for AI applications.\n2. Phat's share on Go weekly commentary:\n    - Introduction to \"Prep\", a tool for compile-time evaluation in Go.\n    - Overview of \"War Zero\", a database-compatible web assembly runtime.\n    - Discussion on the advantages and limitations of these tools.\n3. Hoang's presentation on chatbot evaluation:\n    - Introduction to a method for evaluating chatbots using simulated users and evaluators.\n    - Description of the setup and implementation of the evaluation process.\n4. Anh's case study on a stock trading application:\n    - Introduction to the research and redesign project for the Kafi stock trading app.\n    - Sharing the process of user research, problem analysis, and proposed solutions.\n    - Discussion on applying AI in the user research process.\n5. Important announcements from management:\n    - Request for everyone to write 2 essays and 1 practical assignment on AI:\n        - Essay 1: About company culture\n        - Essay 2: About AI applications in each person's field of work\n        - Assignment 3: Practical task (topic yet to be determined)\n    - These are conditions for the year-end trip and performance review.\n    - Submission deadline is before the 4th week of November.\n    - Emphasis on controlled use of AI in work processes.\n6. Updates on ongoing projects and research topics in the team:\n    - Discussion on topics such as multi-agent systems, knowledge routing, semantic projection, etc.\n    - Emphasis on the importance of understanding and applying new architectures in software development.\n7. Highlighting the importance of applying AI in work and the need for proactive learning to keep up with trends.\n8. Discussion about changes in the job market, especially for junior and mid-level positions.\n\n---\n\n**Vietnamese Transcript**\n\n**00:00** Hôm nay có một vài topic về Go commentary, ngoài ra thì sẽ có bài của Nam về phần product design commentary. Sau đấy thì sẽ có một vài phần liên quan đến evaluate chatbot và kỹ thuật để làm chatbot của Hoàng và Tom. Chắc là sẽ share anh em một tí về cái kiến trúc microservices, nếu còn thời gian thì có một bài case study về một cái project crypto finance của Anna. \n\n**08:47** Nam Bùi lên được, em chưa thấy Nam Bùi xong bài… Xong rồi thì em share màn hình nhé.\n\n**10:31** Rồi mọi người thấy màn hình chưa? Ok, chắc mọi người thấy rồi. Tiếp nối bài product design của tuần trước, tuần này em sẽ nói về hai bài, đầu tiên sẽ là về icon Sparkle. Đầu tiên thì icon Sparkle này thì chắc là cũng phổ biến, không biết mọi người có thấy icon này bao giờ chưa? Nếu có thì mọi người bấm phím 1 cho em với. Thì icon này nó sẽ thuộc dạng là… Ừ thì icon này thì hiện tại nó đang sử dụng cho tất cả các app, và hiện tại em sẽ muốn giới thiệu một vài cái app.\n\n**11:30** Đầu tiên là cái app Plane Finder này thì nó sẽ dùng icon này để hiện thị cho các bài viết mới của Plane Finder. Cái app thứ hai là app e-commerce chuyên bán quần áo mỹ phẩm Ulta, thì nó sẽ có một cái tính năng là discover, sử dụng icon Sparkle để show tính năng này. Tiếp theo thì chắc mọi người cũng quen thuộc hơn, đó là Google Meet, nó có tính năng remove background và thêm background khác vào, thì nó cũng sử dụng icon Sparkle này.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/AhehaT_PK84?si=QfcJA-sP6X9_eIL6&amp;start=659\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**12:14** Như vậy là mình có ba cái app đã sử dụng icon Sparkle, ngoài ra thì còn nhiều app khác nữa cũng đang sử dụng icon này. Sp icon này không chỉ sử dụng cho một tính năng nhất định mà nó rất phổ biến. Đến khi AI bắt đầu xuất hiện thì AI hiện tại cũng đang dùng icon này rất nhiều, ví dụ như Figma dùng cho icon generator.  Ngoài Figma thì còn có Miro, một app để vẽ diagram hay wireframe.\n\n**12:59** Một cái app nữa đó là Dovetail app, nó sử dụng icon này để generate lại các buổi họp. Hầu hết các app AI hiện tại đều đang sử dụng icon này. Và cuối cùng là ứng dụng Nylas, hiện tại Nylas sử dụng icon này làm giao diện chính của họ. Việc này làm cho người dùng khi thấy icon Sparkle sẽ liên tưởng đến các tính năng liên quan đến AI, vì icon Sparkle này đang trở thành biểu tượng của AI.\n\n**13:45** Trước khi em show các giao diện về AI, em có show một số ví dụ về việc sử dụng icon này cho những tính năng khác của các app khác, để chứng minh rằng icon Sparkle này không bị giới hạn chỉ cho một tính năng duy nhất mà nó có thể dùng cho nhiều tính năng khác nhau. Để sử dụng icon này hiệu quả, em nghĩ khi mình hover lên icon thì sẽ có tooltip để hiển thị tính năng cụ thể là gì, hoặc là show ra tên tính năng ở dưới icon luôn. Nhìn chung thì việc sử dụng icon Sparkle hay các icon dạng generic khác sẽ cần tooltip hoặc tên tính năng để user tránh bị nhầm lẫn.\n\n**14:31** Bây giờ em sẽ chuyển sang bài thứ hai, bài này sẽ nói về việc onboarding người dùng mới cho AI. Em sẽ tập trung so sánh các app với nhau để đưa ra những best practices cho việc onboarding người mới sử dụng AI hay vừa đăng nhập vào và khám phá một tool AI mới.\n\n**15:26** Ở đây thì có một app khá nổi tiếng ở Trung Quốc tên là SparekDesk. Khi người dùng vừa vào app, họ sẽ có một danh sách các câu hỏi và hướng dẫn để tìm hiểu về app này. Ngược lại thì ChatGPT không cần phải có danh sách câu hỏi này, mà người dùng có thể bắt đầu ngay bằng cách gõ câu hỏi của mình vào để kiểm tra khả năng của nó.\n\n**16:10** Thay vì cung cấp list câu hỏi hướng dẫn, người dùng thường bắt đầu với ChatGPT bằng cách hỏi ngay một câu như ‘Can you…’ để kiểm tra khả năng của AI này có thể làm được hay không. Cách này giúp việc onboarding với ChatGPT hiệu quả hơn so với các tài liệu hướng dẫn dài dòng.\n\n**17:09** Ví dụ tiếp theo là khi người dùng lên App Store, họ có thể thấy các danh mục như Productivity để hiển thị tính năng của app. Ví dụ ở bên trái là Productivity, bên phải là kết quả tìm kiếm và các tính năng của app. Điều này giúp người dùng dễ hiểu hơn về app trước khi họ tải về.\n\n**18:02** Nên là em nghĩ rằng với từng character thì nó sẽ tạo ra một câu hỏi khác nhau cho từng character, nên là người dùng sẽ bị khó hiểu và phải cân nhắc việc nên chọn cái nào. Còn phần mềm này thì nó chỉ có những hướng dẫn tool-tip ngắn gọn cho user, và không có những bước onboarding rườm rà như vậy. Thì cái ý ở đây là mình nên loại bỏ những cái step không cần thiết cho user, thay vì đưa quá nhiều bước hoặc quá nhiều thứ làm người dùng bị confused. Đây là ý cuối cùng.\n\n**18:58** Ví dụ như cái app bên trái đưa ra những câu hỏi chi tiết cụ thể cho người dùng, còn app bên phải thì lại đưa ra các câu hỏi chung chung, không liên quan đến một tình huống cụ thể nào. Theo em thì việc đưa ra câu hỏi chung chung sẽ hiệu quả hơn, vì những câu hỏi chi tiết quá sẽ không hữu ích cho người dùng, và thường thì những câu hỏi chi tiết quá sẽ không match với những gì người dùng mong muốn. Vì vậy em nghĩ là nó sẽ dư thừa trong quá trình onboarding user. Ngược lại, ChatGPT thì đưa ra những câu hỏi chung chung, và điều này sẽ có phần trăm cao hơn là nó phù hợp với mong muốn của người dùng.\n\n**19:44** Từ bốn cái ví dụ so sánh này, em rút ra: Thứ nhất, mình nên hạn chế đưa ra quá nhiều câu hỏi chi tiết cho user, thay vào đó, để họ tự do hỏi trực tiếp cái gì họ muốn. Thứ hai, mình nên đưa ra phạm vi tính năng rõ ràng ngay từ đầu, như dạng để set expectation cho user, thay vì để họ vào rồi không dùng được thì họ sẽ xóa ứng dụng. Thứ ba, mình cần bỏ đi những bước onboarding rườm rà không cần thiết và tối ưu hoá thời gian cho user. Cuối cùng, mình nên đưa ra những câu hỏi chung chung, thay vì những câu hỏi quá chi tiết.\n\n**20:33** Dạ rồi, em xong. Anh em có câu hỏi gì không thì comment lại phía dưới nhé. Nhưng mà anh thấy ở đây, thực ra việc so sánh như vậy thì anh có cảm giác những cái app này nó có target đến cùng một tác vụ không em? Tại vì thực ra kiểu cái case này, những câu hỏi mang tính specific có thể vẫn useful trong một số hoàn cảnh khác nhau. Chứ không phải lúc nào câu hỏi random cũng hợp lý, vì như kiểu ChatGPT là một tool chat general có thể làm nhiều thứ. Còn một số giao diện chat khác thì nó lại specific cho một tác vụ cụ thể thôi.\n\n**21:26** Nhưng cái mà em nói thì nó cũng thuộc dạng generic tool chat như ChatGPT, chứ không phải cho một tác vụ cụ thể. Đúng rồi, nên là em so sánh hai cái dạng generic tool chat với nhau thôi.\n\n**22:09** Dạ, thì đúng như anh nói, ví dụ như là một cái app cụ thể thì nó cần có những câu hỏi cụ thể hơn. Nhưng mà ở đây em chỉ so sánh hai cái dạng tool chat chung chung thôi.\n\n**23:07** Dạ. Đúng rồi, thắc mắc thêm không? Có gì hỏi tiếp nhé. Bây giờ thì chuyển qua topic tiếp theo. Topic lần này là hai bài viết về AI: một cái là sự hiểu lầm về Sparkle icon, và một cái là các best practice để onboarding user mới dùng AI. Anh em có câu hỏi gì về Sparkle icon không?\n\n**23:58** Thực ra thì bây giờ đa phần những cái app có AI thì đều có những kiểu như mic icon, các thứ tương tự. Nhìn vào là biết ngay là có AI chứ không nhầm lẫn được. Đồng ý. Còn phần onboarding thì anh thấy hơi cấn. Mục đích của việc onboarding là để giúp user bắt đầu với app và có điểm tựa để họ khám phá thêm, chứ không phải cho long-term user dùng. Onboarding này sẽ chỉ dùng cho user mới bắt đầu thôi.\n\n**25:10** Em có gửi một cái link để mọi người có thể đọc thêm sau. Bài đó em tóm tắt dựa trên các giao diện mới đang support AI hiện tại. Tháng này có nhiều app chat ra mắt với những feature và UI khá ngầu. Sáng nay, em thấy ChatGPT có thêm tính năng Canvas, mở ra pop-up để scroll artifact bên phía CR. Nếu mọi người hứng thú thì có thể tham khảo thêm. Ok, cảm ơn em. Được rồi, phát biểu tiếp nhé. Ok rồi anh, bye mọi người.\n\n**26:42** Dạ, thì tuần này em có được hai bài, thấy cũng ok, không có gì phức tạp lắm. Chủ yếu là những cái tool mới thôi. Bài đầu tiên đó là về thằng Prep. Thì Prep này nó là một cái tool để giúp compile-time evaluation. Nó là một cái tool để enable compile-time evaluation, giúp cho quá trình này xảy ra ngay tại compile-time thay vì tại runtime.\n\n**29:11** Thì mọi người hiểu compile-time evaluation là gì không nhỉ? Kiểu như bình thường khi mình viết code, những giá trị mà mình gán cho biến hoặc hàm thì nó sẽ được tính toán tại runtime, nhưng với thằng tool này, nó sẽ giúp chuyển những đoạn tính toán ở runtime thành compile-time. Việc này sẽ giúp boost performance lên một chút, đặc biệt trong các trường hợp cần tính toán nặng. Ví dụ, với những bài toán phức tạp như tính Fibonacci số lớn, nếu làm tại compile-time thì sẽ nhanh hơn nhiều so với tính tại runtime.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/AhehaT_PK84?si=1TdsiNLvEgAImu-g&amp;start=1751\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**29:42** Cách dùng cũng đơn giản thôi. Prep này, mình chỉ cần nhét những đoạn code cần evaluate tại compile-time vào trong hàm prep là được. Như mọi người thấy ở đây, ví dụ như tính toán Fibonacci. Đối với những con số nhỏ thì đơn giản, nhưng khi con số lớn lên thì tính toán sẽ lâu hơn. Nhưng khi dùng `prep`, những con số lớn sẽ được tính toán nhanh hơn nhiều. Ngoài ra, khi build, mình sẽ cần dùng một cái lệnh như thế này (chỉ vào màn hình), lệnh này là để run cái tool `prep` luôn tại compile-time.\n\n**30:25** Tuy nhiên, có một số giới hạn của thằng tool này. Thứ nhất, nó chỉ hỗ trợ các giá trị mà mình có thể xác định được tại compile-time, và những giá trị đó phải nằm trong cùng scope với hàm prep. Ngoài ra, không thể sử dụng tool này cho các thao tác IO vì nó là compile-time, không hợp lý để xử lý IO operations trong compile-time.\n\n**31:15** Zero này nó là một cái runtime library. Nó claim là nó database compatible, xài nó cũng đơn giản thôi. Mọi người cứ import vào rồi xài thôi. Ví dụ như đây là một cái ví dụ mà nó compatible với thằng database relational cơ bản, thì nó claim là nó sẽ free cho. Ok, mọi người cũng ngại import những cái thằng mà xài kiểu SD. Dạ chắc vậy. Mọi người có câu hỏi gì không? Ok, không có thì tiếp tục nhé.\n\n**32:18** Dạ đúng rồi, bài này em check là nó nằm khoảng 4 ngày trước đúng không ta? Anh thấy cái Go với lại kia khoảng 4 ngày trước. Dạ đúng rồi, trong tuần đó anh. Dạ, có thêm cái này hôm bữa nữa. Cái bài về lm power Go này mình chưa có điểm qua phải không? Phép có rồi mà anh, nhưng không nhớ rõ nó nằm ở kỳ mấy nữa. Để em search lại cái. Rồi trên đây nó có một số bài mà chắc team mình sẽ quan tâm, không biết nó như thế nào. Cái bài là bài này nè, trong nguyên cái dàn list á, có một cái list được thả up rất là nhiều. Khứa này nó dùng Go mà nó dev web, thì nó ra được khoảng đâu 22 cái note của nó về việc dùng Go để code web.\n\n**33:07** Thì bài này không biết em check chưa, nhưng cộng đồng nó up vote cái này rất là nhiều. Dạ chắc là anh. Nó kiểu như là mấy cái nốt mà thông qua mấy cái release version, nó thấy cái nào technote hữu ích thì nó up lên. Em nghĩ nhiều người sẽ nhìn thấy và quan tâm. Ok, giống như là anh thấy mấy cái bạn điểm qua version rất là cũ của Google luôn.\n\n**33:49** Dạ, đúng rồi. Sau đó nó check out mấy cái win, mấy cái gì đó hay ho của những cái version đó của Go. Ok, bài tổng hợp này là mới đúng không ta? Dạ đúng rồi, bài tổng hợp này mới. Ông này tự tổng hợp lại theo cái list của ổng thay vì lên awesome Go, ổng tự làm list. Xong rồi bên dưới thì bán khoá học. Ok, chắc là bài này cũng uy tín. Chắc lấy bài này track lại, hôm qua mới lấy cái bài cũ đăng lên lại. Anh thấy cộng đồng đang pick up dần, nếu khéo chắc sẽ track thêm.\n\n**34:32** Dạ, đúng rồi. Với lại anh Hiếu có xem cái bài này, vô tình em cũng đọc được. Ảnh bảo là bên Go có một cái repo để mọi người tham khảo, kiểu microservice cũng ok lắm, tên gì đó luôn. Để em search lại cái link rồi gửi cho mọi người nhé. \n\n**36:32 H**ôm nay em sẽ giới thiệu về một cái dự án em làm cách đây gần hai tháng. Đó là một bài liên kết với system AI. Khi mà cái task nó quá lớn, quá nhiều subtask, mọi người phải chia ra thành từng module riêng lẻ, thì sẽ có một con router ở giữa. Nó sẽ nhận request từ user, rồi phân chia tới từng module con. Bài này sẽ giới thiệu cách mà em evaluate cái system này.\n\n**37:10** Có một phương pháp mà team em đang làm là sẽ dùng một simulation con, gọi là simulated user, để tương tác với các module. Sau đó, sẽ có một con evaluator đánh giá thông qua cuộc hội thoại này dựa trên các tiêu chí mà mình tự định nghĩa. Ví dụ như em test thử một simulation cho một công ty hàng không, khách hàng muốn refund lại vé, thì mình tạo simulation cho khách hàng đó. Cuộc hội thoại hoàn toàn giữa các con AI với nhau, có thể thấy là mới vào sẽ có các lời chào hỏi, giới thiệu, request từ khách hàng, và AI sẽ gọi qua các module worker, làm việc với các module khác nhau. Sau đó, nó sẽ trả về kết quả cuối cùng và con evaluator sẽ đánh giá xem cuộc hội thoại này có đạt yêu cầu hay không.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/AhehaT_PK84?si=rIMEVKw521g2rZ_B&amp;start=2196\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**37:56** Ví dụ như em dùng một metric là binary thôi, 0 hoặc 1. 0 là user không được refund, 1 là user được refund. Sau đó, evaluator sẽ đánh giá dựa trên các tiêu chí mà mình đã đặt ra. Em có test thử một bộ sinh thái của Langchain để chạy thử, dùng OpenAI để chạy qua. Khi kết thúc, kết quả sẽ được đưa ra, và mình sẽ đánh giá xem các bước có đúng với mục tiêu hay không.\n\n**38:41** Đây là một ví dụ thành công. Simulation chạy qua, module ticket office xử lý và trả kết quả về cho user. Từ đó, mình có thể xem và đánh giá các bước trong quá trình này. Nếu cần, mình có thể optimize lại luồng hoặc workflow. Đây là một phương pháp để mọi người evaluate một chatbot hoặc một agent.\n\n**39:33** Mọi người có câu hỏi gì không? Đại loại là mình sẽ dùng một con agent hoặc multi-agent để simulate conversation với một con chatbot. Sau đó, evaluator sẽ đánh giá kết quả của toàn bộ cuộc hội thoại. Ví dụ như trong một test case, mọi người sẽ có những input mong muốn. Simulation user sẽ đưa những input đó vào cuộc hội thoại với chatbot, và khi hoàn tất, evaluator sẽ đánh giá xem kết quả có đạt yêu cầu không.\n\n**40:35** Ví dụ là mình dùng ba con agent tổng cộng. Một con simulation user, một con chatbot, và một con evaluator để đánh giá. Langchain hỗ trợ luôn cả việc xây dựng một graph để tổ chức các cuộc hội thoại. Ví dụ user tương tác với chatbot, và khi kết thúc, evaluator sẽ kiểm tra lại toàn bộ quá trình hội thoại. Mọi thứ đều có thể define trong evaluator, ví dụ như check số lượng tool đã sử dụng, hoặc xem có công cụ nào bị gọi hai lần hay không.\n\n**42:07** Giống như automation test case đúng không? Đúng rồi, mình define những test case, rồi assign các tag cho từng con agent. Ví dụ test này để pass, test kia để fail, có những tag khác nhau tuỳ vào từng tình huống. Đạt có nói về việc define expected output cuối cùng, và quá trình thì tự generate. Khi chạy qua các tool, nó sẽ kiểm tra xem tool có sử dụng đúng cách hay không, có chạy đúng số lượng tool đã định trước không.\n\n**43:25** Mọi thứ đều có thể define trong evaluator ở cuối cùng để kiểm tra. Giả sử mình muốn hard-code một bộ test case thì cũng được. Ý là mình define conversation để book một cái ticket chẳng hạn, rồi kiểm tra xem có đủ step để đến thành công không, có step nào dẫn đến fail không. Tất cả đều có thể định nghĩa sẵn.\n\n**44:05** Khi mình hard-code nguyên một luồng như vậy, mình có thể theo dõi từng bước. Nhưng với approach này, mọi thứ đều có thể tự chạy và kiểm tra theo quá trình. Mọi người có thể define những metric để đánh giá conversation, như correctness hay accuracy, để biết agent có hoạt động đúng không. Đây là một cách để chạy test toàn diện cho agent.\n\n**45:31** Còn một bài nữa mà em kết hợp chung với bài này. Mọi người thấy con agent sẽ xử lý như thế này, qua nhiều bước khác nhau trong quá trình hội thoại. Cái này lấy từ hai ví dụ collaboration trước, nhưng nó specific cho case của tụi mình. Cả quá trình sẽ được đánh giá qua ba architecture nhỏ kết hợp lại, với một con router đứng giữa. Router sẽ route request tới những con nhỏ hơn dựa vào yêu cầu của user, rồi sẽ trả về kết quả.\n\n**46:40** Đó là một cách để xử lý, mọi người có thể nhìn vào đây để thấy cách nó vận hành. Cả quá trình đều có thể được đánh giá qua từng bước. Nếu cần build một bộ test trong app thực tế, thì approach này vẫn có thể áp dụng.\n\n**47:50** Ok, tiếp theo Hoàng trả lại diễn đàn cho Tom. Hình như mấy cái bài của Tom đều đã đại khái xong hết rồi, đúng không Tom? Mới form một chút thôi, nhưng tôi phải chạy script để update lại mấy cái link ảnh ấy. Nó có vẻ hơi nhiều ảnh nhỉ. Ok, share tiếp về case study nhé.\n\n**49:39** Mọi người vào link Figma này để nhìn cho rõ nhé, xem màn hình thì nó bị bể. Được rồi, trước khi share, mình có cần phải sensor cái gì không ta? Có dính NDA gì không? Hay là bài này bình thường thôi? Không dính vấn đề gì cả, đây là một case study về dự án đầu tiên mà team designer bắt đầu áp dụng AI, chủ yếu hỗ trợ trong quá trình nghiên cứu UX.\n\n**50:36** Kafi thì Kafi là công ty hồi xưa. Trước đây nó có một tên khác, nhưng mà trước đây thì nó mờ nhạt trên thị trường. Sau cái năm 2022 thì nó có một cái chuyển đổi về nhân sự nên là nó đổi tên thành Kafi. Từ đó,  bắt đầu tái cơ cấu, và sau năm 2024 thì Kafi ghi nhận được một số lợi nhuận cao, kinh doanh vô cùng ấn tượng. Họ đã sử dụng nguồn lợi nhuận này để bắt đầu phát triển và nâng cấp hai ứng dụng là Kafi Trade và Kafi Wealth, với mục tiêu phát triển và mở rộng chiến lược kinh doanh và thị trường. Họ đã tìm đến bên Dwarves Foundation để đầu tư vào việc nghiên cứu người dùng và các công nghệ.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/AhehaT_PK84?si=d4w1jusl537bKAU5&amp;start=3015\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**51:30** Về thách thức chính của ứng dụng Kafi hiện tại, đó là trải nghiệm người dùng chưa đáp ứng được nhu cầu của một nhóm người dùng đa dạng. Tưởng tượng như một ứng dụng đầu tư, nhưng khi người dùng tiếp cận thì lại không đáp ứng đúng nhu cầu của họ. Điều này đặt ra một thách thức, từ đó Kafi bắt đầu nghiên cứu về trải nghiệm người dùng để đáp ứng nhiều nhu cầu khác nhau của khách hàng. Vì vậy, nhóm đã đặt ra câu hỏi là: \"Chúng ta phải làm gì tiếp theo?\" Mục tiêu chính là tạo ra một ứng dụng đáp ứng kỳ vọng và mang lại giá trị thực sự cho các nhà đầu tư.\n\n**52:19** Quá trình này không hề dễ dàng bởi vì nhóm không chỉ cải thiện một ứng dụng mà còn mang đến một triết lý, đó là xây dựng một công cụ có thể thay đổi cách mọi người tiếp cận với việc đầu tư. Ở đây, em chia quá trình nghiên cứu để hiểu người dùng thành ba giai đoạn: empathize (đồng cảm và hiểu nhu cầu người dùng), lập kế hoạch và thiết kế. Đầu tiên là empathize, trong giai đoạn này nhóm bắt đầu thực sự hiểu được những gì mà khách hàng mong muốn và kỳ vọng.\n\n**53:07** Ba câu hỏi chính mà nhóm muốn trả lời trong giai đoạn đầu của dự án là: Những khó khăn và pain point hiện tại của người dùng là gì? Họ thực sự muốn gì? Và họ cần gì? Sau đó nhóm tiến hành nghiên cứu chuyên sâu để bóc tách những vấn đề này. Trong đó có phương pháp kiểm tra khả năng sử dụng (usability testing). Ở đây, nhóm trực tiếp sử dụng ứng dụng để hiểu sâu và nắm bắt các chi tiết mà phương pháp khác khó phát hiện được, ví dụ như cảm xúc và suy nghĩ của người dùng khi tương tác với ứng dụng.\n\n**53:54** Ngoài ra, nhóm cũng điều tra các diễn đàn và cộng đồng như Reddit hoặc Facebook để nắm bắt hành vi và những yếu tố tiềm ẩn trong thị trường chứng khoán mà Kafi chưa kịp nắm bắt. Trong quá trình nghiên cứu, nhóm cũng sử dụng AI để nghiên cứu thị trường và phân tích đối thủ, sử dụng SWOT để hiểu rõ về sản phẩm hiện có trên thị trường, ví dụ như nghiên cứu điểm mạnh và điểm yếu của các sản phẩm đó.\n\n**55:29** Sau khi hoàn thành tất cả các nghiên cứu sơ cấp và thu thập dữ liệu, nhóm chuyển sang giai đoạn khái niệm hóa dự án. Giai đoạn này bao gồm việc phân tích thông tin đã thu thập và thực sự hiểu sâu về nó. Tiếp theo là giai đoạn lập kế hoạch dự án. Sau khi thu thập tất cả các dữ liệu sơ cấp từ đối thủ cạnh tranh, AI, và khảo sát, nhóm ưu tiên hình thành các chiến lược cho trải nghiệm người dùng thực tế.\n\n**56:18** Nhóm bắt đầu hiểu rõ về mong muốn và nhu cầu của khách hàng. Sau đó, nhóm phân loại thông tin thu thập được và sắp xếp chúng theo thứ tự ưu tiên. Nhóm trình bày các phát hiện này cho team Kafi để cùng hình thành các chiến lược dựa trên dữ liệu thực tế và đồng ý với các vấn đề đã được phát hiện. Tiếp theo là giai đoạn nghiên cứu thứ cấp, một giai đoạn nghiên cứu sâu hơn về chiến lược sản phẩm.\n\n**57:08** Có ba giai đoạn chính: xây dựng personas, mapping ưu tiên và pain point. Từ đó, nhóm sẽ hiểu rõ hơn về lộ trình sản phẩm và xác định các tính năng cần có trong phiên bản thứ hai. Sau đó, nhóm sẽ trình bày các insight này cho khách hàng. Bước đầu tiên là xây dựng personas, tức là tạo ra đại diện cho phân khúc khách hàng dựa trên các yếu tố như độ tuổi, kinh nghiệm đầu tư, mục tiêu tài chính và mức độ chấp nhận rủi ro của họ.\n\n**57:57** Sau khi xác định được personas, nhóm sẽ tiến hành phân tích sâu hơn về hành vi bằng cách xây dựng một journey map để hiểu rõ hành vi của người dùng. Điều này bao gồm các điểm chính như nghiên cứu cách họ tương tác với các tính năng, tần suất sử dụng, và các yếu tố ảnh hưởng đến quyết định đầu tư của họ. Tiếp theo, nhóm tập trung vào việc xác định nhu cầu ưu tiên của từng đối tượng khách hàng.\n\n**58:49** Ví dụ, nhà đầu tư mới cần nhiều hướng dẫn và công cụ học tập hơn, trong khi các nhà giao dịch chuyên nghiệp có thể ưu tiên các công cụ phân tích để nâng cao khả năng thực hiện giao dịch thành công. Cuối cùng, dựa trên kết quả phân tích dữ liệu và triết lý của Kafi – xây dựng ước mơ tài chính – nhóm quyết định tập trung vào hai đối tượng chính: new trader và professional trader (hay còn gọi là newbie trader và day trader).\n\n**59:31** Từ đó, nhóm rút ra kết luận quan trọng là cần định hình lại cách tiếp cận giao dịch chứng khoán. Các kết luận bao gồm việc giúp nhà đầu tư mới vượt qua các rào cản kiến thức, đáp ứng nhu cầu về tốc độ và chính xác cho các nhà giao dịch chuyên nghiệp, và giải quyết các vấn đề liên quan đến bảo mật và quản lý rủi ro. Cuộc nghiên cứu này cũng chỉ ra rằng các nhà giao dịch có xu hướng sử dụng ứng dụng di động như một công cụ hỗ trợ, để theo dõi biến động thị trường, cập nhật tin tức nhanh chóng, và kiểm tra số dư tài sản.\n\n**01:00:15** Sau khi hoàn thành quá trình nghiên cứu, nhóm và Kafi đã thống nhất được một số giải pháp chính. Ba vấn đề chính mà nhóm xác định được là sự phức tạp đối với nhà đầu tư mới, quy trình onboarding khó khăn, và nhu cầu đa dạng của các nhóm đối tượng khác nhau.\n\n**01:01:10** Để giải quyết từng vấn đề này, nhóm phát triển ba giải pháp chính. Các giải pháp này được thiết kế dựa trên những hiểu biết sâu sắc từ nghiên cứu người dùng và phân tích thị trường. Giải pháp đầu tiên là giúp đỡ các nhà đầu tư mới, vì đầu tư là một lĩnh vực phức tạp, đặc biệt là đối với người mới bắt đầu. Cafi được thiết kế trở thành một người hướng dẫn đáng tin cậy, sử dụng công cụ hỗ trợ Contextual Help (trợ giúp ngữ cảnh).\n\n**01:01:49** Ví dụ, trong một biểu đồ giá phức tạp, sẽ có một biểu tượng nhỏ xuất hiện ở góc màn hình. Khi người dùng chạm vào biểu tượng này, một trợ giúp tương tác sẽ xuất hiện, giải thích các khái niệm như khối lượng giao dịch là gì, giá đóng cửa là gì. Nó cũng cung cấp các mẹo để đọc biểu đồ, chẳng hạn như biểu đồ nến.\n\n**01:02:36** Phép tìm hiểu sâu về các kỹ thuật và các chỉ số kỹ thuật. Tất cả đều sẽ hiển thị trong một màn hình. Cuối cùng là việc cải thiện giao diện người dùng bằng cách áp dụng nguyên tắc \"Less is More\" bằng cách tạo ra một giao diện tối giản, hiện đại và khoa học. Mỗi yếu tố trên màn hình đều có một mục đích cụ thể để giúp người dùng thực hiện giao dịch nhanh chóng và hiệu quả, làm cho các nhà giao dịch mới không cảm thấy choáng ngợp trước khối lượng thông tin lớn.\n\n**01:03:21** Với giải pháp thứ hai, nhóm tập trung vào việc cải thiện từng bước trong quy trình onboarding, giúp người dùng dễ dàng hơn. Trước đây, nhóm nhận thấy ứng dụng Cafi gặp khó khăn với tỷ lệ người dùng bỏ cuộc trong quá trình đăng ký. Nguyên nhân chính là do quy trình đăng ký và xác minh danh tính điện tử (eKYC) phức tạp, khiến người dùng nản lòng vì phải cung cấp quá nhiều thông tin. Để khắc phục vấn đề này, nhóm đã tối ưu hóa quy trình onboarding bằng cách chia nhỏ quá trình đăng ký thành các bước ngắn gọn, chỉ yêu cầu đủ thông tin ở mỗi bước.\n\n**01:04:06** Ngoài ra, nhóm còn cho phép người dùng khám phá ứng dụng trước khi hoàn tất đăng ký để tạo cảm giác thoải mái, không bị áp lực phải cung cấp quá nhiều thông tin ngay lập tức. Khi người dùng đã tạo tài khoản xong, nhóm cũng hướng dẫn từng bước về xác minh, theo dõi danh mục và đặt lệnh một cách trực quan, tích hợp thanh tiến độ để giúp người dùng dễ dàng theo dõi quá trình. Cách tiếp cận này không chỉ đơn giản hóa quy trình mà còn tạo ra trải nghiệm phù hợp với nhu cầu cá nhân của từng đối tượng khách hàng.\n\n**01:04:48** Giải pháp thứ ba là thiết kế công cụ tùy theo từng đối tượng người dùng. Các nhà đầu tư có nhu cầu sử dụng công cụ hỗ trợ khác nhau tùy theo mức độ kinh nghiệm. Khi nền tảng web có thể linh hoạt trong việc bố trí các tính năng, thì thiết kế giao diện trên điện thoại lại bị hạn chế hơn. Vấn đề đặt ra là làm sao để cung cấp đủ công cụ cho các nhà đầu tư chuyên nghiệp mà không làm khó khăn cho người dùng mới. Giải pháp của nhóm là áp dụng hệ thống phân loại người dùng. Sau khi hoàn tất đăng ký, người dùng sẽ được chia thành các nhóm như mới bắt đầu, trung cấp và chuyên nghiệp. Mỗi nhóm sẽ nhận được trải nghiệm phù hợp với mức độ hiểu biết và mục tiêu đầu tư của họ.\n\n**01:05:24** Ví dụ, người mới có thể tiếp cận các bài học cơ bản, trong khi nhà đầu tư chuyên nghiệp sẽ được cung cấp các công cụ phân tích chuyên sâu. Cách tiếp cận này không chỉ cải thiện trải nghiệm người dùng mà còn thúc đẩy sự phát triển của nền tảng Kafi bằng cách cung cấp nội dung và công cụ phù hợp với từng giai đoạn phát triển của người dùng. Kafi sẽ trở thành một môi trường học tập và đầu tư năng động, phục vụ cho cả người mới và những nhà đầu tư dày dặn kinh nghiệm.\n\n**01:06:00** Kết quả sau case study của Kafi cho thấy rằng, có rất nhiều cách để giải quyết những vấn đề mà các ứng dụng chứng khoán đang đối mặt. Tuy nhiên, quan trọng nhất vẫn là hiểu rõ nhu cầu của khách hàng. Nếu một công ty đang phục vụ nhiều nhóm đối tượng người dùng khác nhau, thì việc thu thập và phân tích nhu cầu đa dạng của họ là rất quan trọng. Sau đó, cần sắp xếp thứ tự ưu tiên để đáp ứng nhu cầu phù hợp với từng đối tượng.\n\n**01:06:43** Ở đây có một số phương pháp hiệu quả để khám phá và hiểu nhu cầu khách hàng, bao gồm khảo sát bằng câu hỏi đóng mở để thu thập thông tin, xây dựng personas để tạo các đại diện người dùng, xác định mục tiêu, hành vi và khó khăn của họ. Phân tích đối thủ cạnh tranh cũng là một phương pháp, sử dụng các công cụ phân tích để đánh giá sản phẩm của đối thủ, từ đó nhìn ra điểm mạnh và yếu của họ.\n\n**01:07:26** Ngoài ra, AI có thể được kết hợp vào quá trình nghiên cứu người dùng, giúp xử lý một khối lượng thông tin lớn từ các đối thủ cạnh tranh hoặc từ dữ liệu thu thập được trong quá trình khảo sát và phỏng vấn người dùng. AI có thể phân tích tất cả các dữ liệu đó và tạo ra những personas cho từng nhóm người dùng. Từ đó, chúng ta có thể tìm ra các giải pháp phù hợp với nhu cầu của từng tập khách hàng.\n\n**01:08:08** Em xin hết. Mọi người có câu hỏi gì không? Thật ra mấy cái này cũng không rút gọn được vì áp dụng hết luôn. Không có rút gọn được. Đúng rồi, cực lắm. Ai không có giọng rung rung sợ sợ vậy đâu. Personal của em là gì, của một designer là gì?\n\n**01:09:52** Personal hả? Thì đó, giống như em nói, từ khi có AI thì việc nghiên cứu user trở nên nhẹ nhàng hơn. Không còn phải đi khảo sát, đi hỏi, đi phỏng vấn quá nhiều user. Có nhiều người bên ngoài mỗi ngày phải gọi điện phỏng vấn mười mấy người. Chị có xài cafe để làm research không? Em có xài cafe để làm research là sao? Mình phải bớt lại chị, phỏng vấn personas của bên mình, thì em chat với cả ChatGPT.\n\n**01:11:08** Ừ, personas thật ra khi hỏi AI về personas nó sẽ cho anh một nùi luôn. Rất nhiều thứ. Vấn đề chính là AI không giúp lên kế hoạch ưu tiên các vấn đề, mà chỉ giúp mình tìm ra những personas ban đầu thôi. Từ đó mình phải dựa vào kinh nghiệm và những cuộc phỏng vấn người dùng thực tế, rồi mới phân tích và nhóm lại các personas cho đúng. Nếu không thì AI sẽ đưa ra quá nhiều personas.\n\n**01:11:56** Kafi chỉ là tham khảo mấy cái của đối thủ cạnh tranh thôi. Ok, anh không có câu hỏi gì nữa. Không biết có thu được giọng anh chưa. Nếu có phần nào thiếu thì gửi slide để xem sau.\n\n**01:13:25** Theo kịch bản là Tom sẽ có một cái bài cho anh em tên là *mixture of agents*, tức là cụm mấy cái agents nó ngồi lại với nhau xong rồi nó chạy multi-agent để ra kết quả, mà tạm thời bài đó có vẻ dễ, mọi người sẽ chưa đến lúc để nghe bài đó đâu. Anh đang nghĩ vậy nên skip bài đó nhé. Giờ có một thông báo quan trọng hơn về chuyện đi chơi và bài test.\n\n**01:14:09** Bài test sẽ có nội dung như sau: mấy anh em xem chuẩn bị trước là vừa. Thứ nhất là anh em sẽ viết hai bài luận. Tự viết, nào viết dở là sẽ bị chém ha. Hai bài luận, một bài luận đầu tiên là về văn hóa. Anh sẽ pick ra một trong bốn cụm văn hóa mà team mình đang theo đuổi, chắc xoay quanh hybrid working xong rồi các kiểu thôi nha. Mấy anh em sẽ viết một bài về cái đó. Câu hỏi thì anh sẽ đưa sau, nhưng giờ phổ biến trước, chắc cuối tuần sẽ release một cái về văn hóa, để mọi người đặt tay vào làm.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/AhehaT_PK84?si=jh0lgTRFw1oWMfgk&amp;start=4462\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**01:14:52** Lý do để làm bài này là vì giai đoạn hiện tại, anh nghĩ mọi người cần cố gắng, phải tự set motivation cho mình để thích nghi với giai đoạn mới. Giai đoạn mới là giai đoạn của thị trường. Giai đoạn của công ty mình thì bình thường, không có gì hết, nhưng thị trường nó thay đổi, nên để phù hợp thì mọi người cần có lý do để refresh lại động lực của mình trong ngành này. Được ha. Sẽ có một bài luận cho mấy anh em về văn hóa.\n\n**01:15:36** Bài thứ hai, câu hỏi sẽ xoay quanh chuyện này. Anh chưa chốt câu hỏi chính xác là gì, nhưng nó sẽ nằm trong chuyện mà ứng dụng của lĩnh vực mà mấy anh em đang làm, nó đang được ứng dụng tới đâu rồi. Có thể gom lại thành một bài giống như *state of the app* của lĩnh vực mấy anh em đang làm, ở bên ngoài người ta đang triển khai như thế nào, thì đó là bài thứ hai.\n\n**01:16:18** Sample cho bài đó có thể nhìn như sau: không biết đây có không, nhưng sample thôi. Bên dev thì chắc dễ, nhưng bên kiểu làm sale, làm design, làm tester, làm PM, tất cả các roles liên quan. Mà Tom đang tính là nó sẽ cut hết mấy cái đó thành agents hết. Thật ra là mình sẽ biết nó sẽ cover được đâu đó 70-80% công việc, nhưng vẫn cần người đứng đằng sau để lái agents đó, thành ra là cũng sẽ tùy ý.\n\n**01:17:04** Ví dụ như bài này phải không? Để coi lại nha. Đúng rồi, thử coi, phải không? Có một số bài anh đang coi cách sử dụng AI như thế này. Có một số bài như vậy. Bên vật dev nó cũng cover một số, cũng không có nhiều lắm, nhưng đại ý là vậy nhé. Bài số hai sẽ là với mỗi role của mấy anh em trong công ty, mấy anh em đang cầm một cái role nhất định, thì cái role của mình, hiện tại là làm sao, chuyện sử dụng AI người ta đang xài như thế nào, đó là bài số hai nhé. Được ha.\n\n**01:17:42** Bài số ba sẽ liên quan tới chuyện thực hành. Đề thì chưa biết, tại vì nếu đưa chủ đề linh tinh quá thì mấy anh em lên ngồi chat với GPT nó cũng không có tác dụng gì lắm. Nên sẽ liên quan đến chuyện chạy thực tế, làm nghề, build software thôi, nên chuyện thực tế áp dụng cho mình sao để hiệu quả thì chắc anh sẽ nghĩ ra một cái đề. Có thể là một đề để submit, rồi mọi người dùng AI để assessment. Anh không có cổ súy hoàn toàn cho chuyện AI cover mọi thứ nhá. Tại vì thấy cách mọi người sử dụng rồi. Ví dụ như anh dùng mấy cái tool kia để ra cái script, thì nó cũng rất chung chung, không có thực tiễn và không có bài học rút ra.\n\n**01:18:16**Comment nhanh vậy thôi để mọi người thấy rằng chuyện sử dụng máy móc, làm rập khuôn thì nó rất là gà. Gà, mà biết dùng chữ gì cho đúng nữa? Nhưng nhìn nó chán, chán đời lắm. Rồi ha, bài số ba là ứng dụng nhé. Là chuyện của mình sau khi tìm hiểu rồi, thì bài thứ ba sẽ là ứng dụng.\n\n**01:18:58** Tiếp, hiện tại mọi người sẽ có lịch đi chơi, nếu mà đúng thì khoảng đầu tháng 12 mình sẽ có khoảng hai tháng để chuẩn bị. Mình sẽ cần chốt trước đó một tháng là ít nhất, nên mọi người có một tháng để làm thôi. Được ha. Nên những thứ mọi người cần submit là đây. Đây là gần như điều kiện cần cho chuyện mấy bạn đi chơi, và nó cũng là điều kiện đủ cho performance review cuối năm vào tháng 12 và tháng 1.\n\n**01:19:39** Hiện tại, anh đang expect những hoạt động của team mình sẽ được assess với AI ở mức độ mà mình kiểm soát được, đảm bảo cái đầu ra vẫn là cái mà mình mong muốn như trước giờ, chứ không phải là \"tại vì em dùng cái này, nên giờ kết quả nó ra như vậy, là tại anh bảo em dùng\". Được ha? Như đương dao tự đâm chân mình rồi đổ lỗi cho người khác, thì không được. Ok, đó là điều kiện cần để đi chơi, và điều kiện đủ để làm bài review.\n\n**01:20:14** Điều này quan trọng, vì lần này, bài review vào tháng 12, nếu bạn nào đi một vòng mà không làm được, thì khả năng cao là junior với fresher sẽ bay màu hết. Hôm qua có xem một cái bài rất buồn cười. Nó không được tuyển vào đâu hết, nên nó làm một cái game multiplayer, firm crash, sử dụng Go và TP. Nó đăng lên và sử dụng toán để làm animation. Comment rất là vui.\n\n**01:21:04** Review đợt tháng 12 sẽ là cái đó nhé. Đó là thông báo cuối cùng để anh em nắm. Message sẽ được release vào cuối tuần để mọi người chuẩn bị deadline để nộp, và chấm điểm cho Huy vào trước tuần thứ tư của tháng 11. Chắc tuần thứ tư của tháng 10 là mấy bạn còn ba tuần đó, đúng không? Đúng rồi, ha. Đây là thông báo. Mấy anh em không tham gia con thì cũng không quan trọng lắm.\n\n**01:21:55** Tiếp nữa, đó là cái list mà Tom đang làm một số phần ở đây. Anh chưa check hết, nhưng anh bắt đầu check từ từ xem là assess những gì. List pilot sao chậm quá nè. List khác, list khác, khác list bữa trước nói. Review nhanh qua cho mấy anh em thấy một chút. List này ha, Tôm đang làm. Anh thấy có một số bạn tham gia nè. Đây là tín hiệu rất tốt, cho thấy mọi người đã bắt đầu aware được sự thay đổi concept trong chuyện làm software.\n\n**01:22:42** Giờ nó xuất hiện thêm server, rồi cách làm data manipulation khác nhau, data collection khác nhau. Mọi thứ đều khác hết, nên là sẽ khác. Những phần reward đã gửi rồi xong. Còn phần Tom đang làm, để review. Đợi anh review, anh review của mấy bạn. Rồi Tom sẽ review tiếp những phần khác. Một số cái như Hiếu Vũ nữa. Hiếu Vũ có đây không? Nhưng mà chưa thấy update gì hết. Bắt đầu xin việc kiểu này là toang rồi.\n\n**01:23:15** Các bạn ơi, phải chủ động đi tìm đề tài để làm rồi ha. Đây là một cái list. Còn cái list khác đợi Tom finish, thì mình sẽ đi qua một cái list khác. Cái chủ đề *multi-agent*, khi nào mấy chủ đề kia thông qua hết? *Knowledge sharing*, grouping, *specific projection.*\n\n**01:24:07** Mấy cái *MapReduce*, team đang làm nè, collect data, build gom data lại rồi chạy cho nó. Thành đang làm con này nè, bữa trước đang kiến trúc, đang hơi quay. Tiếp theo là những chủ đề khác liên quan đến hệ thống cũ. Trước chỉ có server thôi, mà giờ có thêm agent, nên phải đưa dữ liệu qua cho tụi nó. Cấu trúc kiến trúc sẽ khác đi một tí. Khi nhận một cái đề bài, cấu trúc agent ra sao vẫn là chủ đề chưa bao giờ thảo luận kỹ với nhau.\n\n**01:25:12** Một số bạn đang setup dify, thấy có liên quan, nhưng mà nhiều câu hỏi về kiến trúc, về cấu trúc một hệ thống không chỉ có server mà có nhiều agent đứng dọc trong đó. Giống như bài Hoàng làm hồi nãy. Đó là một sample dễ, nhưng bài toán cụ thể thì cấu trúc server sẽ như thế nào? Đó là chủ đề thực tế thôi, phải làm. Nhắc lại vậy thôi, hiện tại nếu không quan tâm thì phần Tom đang viết chẳng có ý nghĩa gì lắm. Chúng ta đang bị tụt lại rất xa trong kiến thức này.\n\n**01:25:39** Anh nghĩ cụm kiến thức này sẽ thành foundation cho software engineer. Không phải là kiến thức blockchain, không cần ai cũng phải biết. Nhưng phần này phải biết. Quan trọng là phải biết cách chia bài toán ra sao, để có logic chart trong đầu. Nếu không chia được thì đang gà. Nhẹ nhàng vậy ha.\n\n**01:26:17** Đó là toàn bộ message. Muốn tranh thủ cho anh em biết định hướng và expectation đang di chuyển theo hướng đó nha. Cuối tuần này sẽ có đề bài để viết hai bài luận, một bài report và một bài case study nhé. Nếu không còn gì thêm thì chắc là gg.\n\n**01:26:53** Tạm biệt anh em, hẹn gặp lại. Hy vọng hôm nay mấy chủ đề recap lại vẫn có giá trị. Sau khi có kiến thức đầy đủ hơn thì sẽ tiếp tục chủ đề hệ thống mới. Còn hiện tại, tất cả hệ thống mọi người đang build vẫn còn trong cái group cũ. Nghĩa là cũ với bên ngoài, chưa đến đó. Nhưng đi trước biết trước thì tốt hơn ha. Rồi ok, vậy ha. Mọi người xem thử còn câu hỏi gì không?\n\n**01:27:44** Chắc không có gì thêm, kết thúc nhé. Đúng rồi, cái này phải chat với team mình. Hôm qua thằng Đạt nó một cái clip lên này. Mình cảm thấy mình đi sau xã hội rất nhiều luôn. Đạt đâu nhỉ? Nó là clip của mấy anh Việt Nam ngồi automate với cái gì đó. Tiêu rồi. Biết kênh nào không?\n\n**01:28:42** Rồi, chắc vậy. Kênh đó random nhỉ? Hiện tại mọi người còn upset về việc học sâu như cũ. Học kiến trúc này kiến trúc nọ. Nhưng automate ở mức độ này thì phải ứng dụng nhiều hơn. Tất cả các app doanh nghiệp hay app bình thường sẽ nằm trong scope như vậy. Nếu build up dễ thì nó cover hết các trường hợp và làm rất nhanh. Nếu build up khó thì mấy anh em còn chưa biết mấy cái dễ nữa thì khó. \n\n**01:29:22** Hy vọng mỗi buổi thứ sáu mình học thêm được một cái gì mới. Hẹn gặp mọi người ở OGIF tuần sau.\n\n---\n\n**English Transcript**\n\n**00:00** Today we have a few topics on Go commentary, and there will be a product design commentary from Nam. After that, there will be some sections related to evaluating chatbots and technical details on how to build a chatbot by Hoang and Tom. They will probably share a bit about microservices architecture. If we have time, there will be a case study on a crypto finance project by Anna.\n\n**08:47** Nam Bui is up, but I haven’t seen his work completed yet... Okay, share your screen when you're ready.\n\n**10:31** Can everyone see the screen? Great, let's continue from last week's product design presentation. This week, I will discuss two topics, starting with the Sparkle icon. The Sparkle icon is probably quite familiar to everyone. If you’ve seen this icon before, press 1 for me. This icon is used across multiple apps, and today I’ll introduce a few of those apps.\n\n**11:30** First is the Plane Finder app, which uses this icon to show new blog posts. The second app is Ulta, an e-commerce app specializing in clothing and cosmetics. It uses the Sparkle icon for the Discover feature. You’re probably more familiar with the third app, Google Meet, which uses this icon for removing the background and adding a new one.\n\n**12:14** So we have three apps using the Sparkle icon, and there are more apps utilizing it. The Sparkle icon isn’t just for one specific feature; it’s becoming quite common. As AI technology emerged, it started incorporating this icon heavily. For example, Figma uses the icon for the AI generator. Other apps, like Miro (for drawing diagrams or wireframes), also use it.\n\n**12:59** Another example is Dovetail, which uses the icon to generate meeting summaries. Most AI apps are now adopting this icon. Finally, the Nylas app has integrated the Sparkle icon as its primary interface symbol. This has made users associate the Sparkle icon with AI features, making it a symbol for AI.\n\n**13:45** Before showing AI interfaces, I shared some examples of how this icon is used in other apps for various features, demonstrating that the Sparkle icon isn’t limited to just one function but can support multiple ones. To use the icon effectively, I think we should display a tooltip when hovering over it to explain the feature, or show the feature name underneath the icon. Generally, using the Sparkle icon or other generic icons requires tooltips or feature names to avoid user confusion.\n\n**14:31** Now, I’ll move on to the second topic, which discusses onboarding new users for AI. I’ll compare different apps and share best practices for onboarding new users who are just logging in or exploring a new AI tool.\n\n**15:26** Here we have a famous app from China called SparekDesk. When users first enter the app, they are presented with a list of questions and tutorials to help them explore the app. On the other hand, ChatGPT doesn’t need such a list, as users can immediately start by typing a question to test its capabilities.\n\n**16:10** Instead of providing a list of guiding questions, users often begin with ChatGPT by asking something like “Can you...?” to test what it can do. This makes onboarding with ChatGPT more effective than going through lengthy documentation.\n\n**17:09** Another example is the App Store, where users can see categories like Productivity to display app features. On the left side, it shows Productivity, while on the right side, it displays search results and the app’s key features. This makes it easier for users to understand the app before downloading it.\n\n**18:02** I think each character creates a different set of questions, which can confuse users as they have to decide which one to choose. Meanwhile, this software offers concise tooltips for users without lengthy onboarding steps. The key takeaway here is that we should eliminate unnecessary steps for users instead of overwhelming them with too many.\n\n**18:58** For example, the app on the left gives users very specific, detailed questions, while the one on the right offers general questions without relating to any specific situation. In my opinion, general questions are more effective because overly specific questions often don’t match users’ actual needs. Thus, I think detailed questions are redundant in the onboarding process. In contrast, ChatGPT’s general questions have a higher chance of aligning with users’ expectations.\n\n**19:44** From these four examples, I conclude: First, we should limit giving users too many detailed questions and instead let them ask directly what they want. Second, we should clearly define the scope of features right from the start, to set user expectations. Otherwise, they might get frustrated and delete the app if it doesn’t meet their needs. Third, we need to remove unnecessary onboarding steps to optimize user time. Lastly, we should present general questions rather than overly specific ones.\n\n**20:33** That’s it for me. If you have any questions, feel free to leave comments. But I think the comparison here raises a point: Do these apps target the same task? Because in some cases, specific questions might still be useful depending on the situation. It’s not always ideal to present random questions, as ChatGPT is more of a general-purpose chat tool, whereas other chat interfaces are more specific to certain tasks.\n\n**21:26** But what I was talking about here is also a generic chat tool like ChatGPT, not for any specific task. Yes, that’s why I compared two generic chat tools side by side.\n\n**22:09** Yes, exactly as you said. A specific app might need more specific questions, but in this case, I’m only comparing two general-purpose chat tools.\n\n**23:07** Got it. Any more questions? Feel free to ask. Now let's move to the next topic. This time we have two articles about AI: one about the misunderstanding of the Sparkle icon and the other about best practices for onboarding new AI users. Does anyone have questions about the Sparkle icon?\n\n**23:58** Actually, now most AI apps have mic-like icons and other symbols that make it easy to recognize AI features. Agreed. As for onboarding, I feel like it’s a bit tricky. The goal of onboarding is to give users a starting point to explore the app, not something for long-term use. This type of onboarding is specifically for new users only.\n\n**25:10** I’ve sent a link for further reading. This article summarizes new AI-supported interfaces. Recently, there have been many cool new chat apps with great features and UI. This morning, I noticed ChatGPT added a Canvas feature, with a pop-up to scroll through artifacts from CR. If you’re interested, feel free to check it out. Okay, thanks. Alright, let’s continue. Ok, I’m done. Bye, everyone.\n\n**26:42** This week, I’ve got two articles to share, nothing too complicated. The first one is about Prep, which is a tool for compile-time evaluation. It enables compile-time evaluation, allowing the process to happen during compile-time instead of runtime.\n\n**29:11** So, does everyone know what compile-time evaluation is? Normally, the values we assign to variables or functions are evaluated at runtime, but this tool helps convert those calculations to compile-time. This boosts performance, especially for computationally heavy tasks. For example, calculating large Fibonacci numbers at compile-time is much faster than doing it at runtime.\n\n**29:42** It’s simple to use. You just place the code that needs compile-time evaluation inside the `prep` function. As you can see here (pointing to the screen), Fibonacci calculations for small numbers are straightforward, but as the numbers grow, it gets slower. By using `prep`, larger numbers are calculated much faster. When building the code, you need to use a command like this to execute the `prep` tool during compile-time.\n\n**30:25** However, there are some limitations. First, it only supports values that can be determined at compile-time, and those values must be in the same scope as the `prep` function. Additionally, you cannot use it for IO operations because they don’t make sense at compile-time.\n\n**31:15** Zero is a runtime library. It claims to be database compatible. It’s also simple to use. You just import it and start using it, like in this example here, which shows compatibility with a basic relational database. It claims to be free. Ok, any questions? If not, let’s move on.\n\n**32:18** Right, this article I checked was posted about four days ago, correct? I saw that Go thing was also from about four days ago. Yes, that’s right, during that week. And I also have something else from the other day. The article on lm power Go—did we go over that yet? I’m not sure, but I think we did. Let me search for it. Anyway, there are some articles here that I think the team will be interested in. This one here, for example, got a lot of upvotes. The guy used Go to develop a web app, and it produced around 22 notes on how to use Go for web development.\n\n**33:07** I’m not sure if you’ve checked it, but the community has upvoted this a lot. Yes, I think I did. It’s like these notes came from various release versions. It highlights useful technical notes, which is why it’s getting attention. Ok, it’s like they pointed out old versions from Google, right?\n\n**33:49** Yes, exactly. Then they check out the wins and cool features of those older Go versions. Ok, is this summary new? Yes, it’s a new one. Instead of relying on Awesome Go, this guy made his own list. Underneath, there’s a link to his paid course. Ok, seems legit. We’ll track this article again. I picked up an older article yesterday, reposted it, and saw the community is slowly picking up on it. If we’re smart about it, we’ll track more.\n\n**34:32** Yes, and I read the article Hiếu pointed out too. He mentioned a Go repo where people can find microservice examples, and it looks pretty good. I’ll search for the link and send it to everyone.\n\n**36:32** Today I’ll introduce a project I worked on about two months ago. It’s a system AI project. When the task becomes too large with too many subtasks, you need to break it into individual modules with a router in the middle. This router receives user requests and forwards them to the relevant submodules. Today’s article will explain how I evaluated this system.\n\n**37:10** One method we used was a simulated user to interact with the modules. Then, an evaluator would assess the conversation based on criteria we defined. For example, I simulated a scenario with an airline customer wanting a refund for their ticket. The entire conversation happens between AI agents, and you can see from the chat that it starts with greetings and introductions, followed by the refund request. The AI then calls different modules to handle each part of the process. After the final response, the evaluator checks whether the process met the refund criteria.\n\n**37:56** In this case, I used a binary metric—0 for no refund, 1 for successful refund. Then, the evaluator reasons through the conversation and provides the result. I used Langchain’s ecosystem to test this. Everything worked smoothly with OpenAI. The evaluator looks at whether the necessary steps were taken to meet the goal.\n\n**38:41** Here’s an example of a successful simulation. The ticket office module processed the request and returned the result to the user. This way, we can assess and optimize the workflow if needed. It’s a method for evaluating chatbot agents.\n\n**39:33** Any questions? Basically, you simulate a user-agent conversation, and the evaluator assesses the final result. For instance, in a test case, you input what you want the simulated user to say. Then, it interacts with the chatbot, and the evaluator reviews the result to see if it meets the expected outcome.\n\n**40:35** For example, we’re using three agents here: one simulated user, one chatbot, and one evaluator. Langchain supports building a graph to organize the conversations. For instance, the user interacts with the chatbot, and at the end, the evaluator checks the conversation. The evaluator can define things like checking the number of tools used, ensuring no tool was called twice, etc.\n\n**42:07** It’s like an automation test case, right? Exactly. You define the test cases and assign tags to each agent. Some tests are set to pass, others to fail, depending on the situation. Last time Đạt talked about defining the expected output, but the workflow is generated automatically. This way, when a tool is used, it checks whether the tool is used correctly and how many times the tool was called.\n\n**43:25** Everything can be defined in the final evaluator to check. Suppose we want to hard-code a test case, we can do that. Meaning we can define a conversation, like booking a ticket, and check if all the steps for success are there or if any steps lead to failure. Everything can be predefined.\n\n**44:05** When we hard-code a full flow like that, we can track each step. But with this approach, everything can run automatically and check as part of the process. You can define metrics to evaluate the conversation, such as correctness or accuracy, to determine if the agent is functioning properly. This is a way to comprehensively test the agent.\n\n**45:31** There’s another part I combined with this one. You can see how the agent handles everything, going through different stages of the conversation. This example was taken from two previous collaboration samples, but it's specific to our case. The whole process is evaluated through three small architectures combined, with a router in the middle. The router routes requests to smaller modules based on the user’s request and returns results.\n\n**46:40** That’s one way to handle it, and you can see how it operates. The entire process can be evaluated step by step. If you need to build a test in a real app, this approach can still be applied.\n\n**47:50** Okay, next, Hoang is handing it back to Tom. Looks like Tom’s topics are almost done, right Tom? I just need to run a script to update some image links. There seem to be a lot of images. Okay, continue sharing about the case study.\n\n**49:39** Please check the Figma link to get a clearer view because the screen sometimes gets distorted. Before sharing, do we need to sensor anything? Is there any NDA involved? Or is this just a normal case study? There’s no issue here; this is the first project where the design team applied AI, mainly to support UX research.\n\n**50:36** Kafi is a company from before, which used to have a different name. It was obscure in the market for a while, but after 2022, there was a personnel restructuring, so they renamed it Kafi. They began re-structuring, and after 2024, Kafi reported impressive profits. They used these profits to start developing and upgrading two applications: Kafi Trade and Kafi Wealth, with the goal of expanding their business strategy and market. They came to Dwarves Foundation to invest in user research and technology.\n\n**51:30** The main challenge for Kafi’s current app is that the user experience doesn’t meet the needs of a diverse group of users. Imagine an investment app that doesn’t align with user needs when they first approach it. This challenge led Kafi to research user experience to meet the varying needs of their customers. So, the team posed the question, “What do we do next?” The main goal was to create an app that met expectations and provided real value to investors.\n\n**52:19** This process wasn’t easy because the team wasn’t just improving an app—they wanted to create a philosophy, building a tool that could change how people approach investing. I’ve broken down the user research process into three phases: empathize (understanding user needs), planning, and design. First is empathize. In this phase, the team began to really understand what customers wanted and expected.\n\n**53:07** The three main questions the team wanted to answer at the start of the project were: What are the current pain points and difficulties? What do users really want? And what do they need? The team then conducted in-depth research to dissect these issues. This included usability testing, where the team directly used the app to gain deep insights and capture details that other methods might miss, such as the emotions and thoughts of users when interacting with the app.\n\n**53:54** Additionally, the team investigated forums and communities like Reddit and Facebook to understand user behavior and hidden factors in the stock market that Kafi hadn’t yet grasped. During the research, the team also used AI to study the market and analyze competitors, using SWOT analysis to understand the current products on the market, including their strengths and weaknesses.\n\n**55:29** After completing all primary research and data collection, the team moved to the concept development phase, where they analyzed the collected information to gain deep insights. Next was the project planning phase. After gathering all primary data from competitors, AI, and surveys, the team prioritized forming strategies for the real user experience.\n\n**56:18** The team first needed to understand what users wanted and needed. Then they classified the collected information and sorted it by priority. The findings were presented to the Kafi team to help them form strategies based on real data and agree on the identified issues. The next phase was secondary research, a more in-depth study of product strategy.\n\n**57:08** There are three main phases: building personas, prioritizing user journeys, and addressing pain points. From this, the team better understood the product roadmap and identified features for the second version of the product. They then presented these insights to the client. The first step was building personas, representing customer segments based on factors such as age, investment experience, financial goals, and risk tolerance.\n\n**57:57** After identifying the personas, the team analyzed user behavior more deeply by mapping out a user journey to understand their actions. This included key points like how they interact with features, the frequency of use, and factors influencing their investment decisions. Next, the team focused on identifying the prioritized needs of each customer segment.\n\n**58:49** For example, new investors need more guidance and learning tools, while professional traders might prioritize analytical tools to enhance their trading success. Finally, based on data analysis and Kafi’s philosophy of building financial dreams, the team decided to focus on two main user groups: new traders and professional traders, also known as newbie traders and day traders.\n\n**59:31** The team drew an important conclusion: we need to reshape how users approach stock trading. These conclusions include helping new investors overcome knowledge barriers, addressing the need for speed and accuracy for professional traders, and solving security and risk management issues. The research also showed that traders tend to use mobile apps as a support tool to track market fluctuations, quickly update news, and check asset balances.\n\n**01:00:15** After completing the research process, the team and Kafi agreed on several key solutions. The three main issues identified were the complexity for new investors, the difficult onboarding process, and the diverse needs of different user groups.\n\n**01:01:10** To address these issues, the team developed three key solutions. These solutions were designed based on deep insights from user research and market analysis. The first solution was to help new investors, as investing is a complex field, especially for beginners. Kafi was designed to become a reliable guide, using a tool called Contextual Help.\n\n**01:01:49** For example, in a complex price chart, a small icon will appear in the corner of the screen. When the user taps on it, interactive help will pop up to explain concepts like what trading volume or closing price means. It also provides tips on reading charts, such as candlestick charts.\n\n**01:02:36** This allows users to dive deeper into techniques and technical indicators, all within a single screen. Finally, to improve the user interface, the team applied the principle of \"Less is More\" by creating a modern, minimalist, and functional interface. Every element on the screen has a specific purpose, helping users trade quickly and efficiently, ensuring new traders don’t feel overwhelmed by the large amount of information.\n\n**01:03:21** The second solution focused on simplifying the onboarding process, making it easier for users. Previously, the team found that Kafi’s app had a high dropout rate during registration, mainly because the electronic identity verification (eKYC) process was too complex, requiring users to provide too much information. To fix this, the team optimized the onboarding process by breaking it down into smaller steps, only requiring essential information at each step.\n\n**01:04:06** Additionally, users were allowed to explore the app before completing registration, helping them feel more comfortable without the pressure of providing too much information upfront. After users created an account, they were guided through steps like verification, tracking portfolios, and placing orders with an integrated progress bar to help them follow the process. This approach not only simplified the process but also created a personalized experience for each customer segment.\n\n**01:04:48** The third solution was designing tools tailored to each user group. Investors have different tool needs depending on their experience level. While the web platform allows flexible feature placement, the mobile interface is more limited. The challenge was providing enough tools for professional traders without making it difficult for new users. The team’s solution was to apply a user segmentation system. After completing registration, users were categorized into groups like beginners, intermediate, and professionals. Each group received an experience tailored to their level of knowledge and investment goals.\n\n**01:05:24** For example, beginners could access basic learning modules, while professional traders would be provided with in-depth analytical tools. This approach not only improved the user experience but also promoted the growth of the Kafi platform by providing relevant content and tools at different stages. Kafi could create a dynamic learning and investment environment, serving both newcomers and experienced investors.\n\n**01:06:00** The results after Kafi’s case study showed that there are many ways to address the issues that stock trading apps face. However, the most important thing is understanding the customers’ needs. If a company serves multiple user segments, it’s crucial to gather and analyze their diverse needs. After that, priorities need to be set to meet the needs of each group.\n\n**01:06:43** Some effective methods for discovering and understanding user needs include surveys with closed and open-ended questions to collect information, building personas to represent users, identifying their goals, behaviors, and pain points, and competitor analysis using tools to assess their products and identify strengths and weaknesses.\n\n**01:07:26** Additionally, AI can be integrated into the user research process, helping process large amounts of data from competitors or from survey and interview data. AI can analyze all that data and create personas for each user group. From there, we can find solutions that match the needs of each customer segment.\n\n**01:08:08** That’s all from me. Any questions? Honestly, these things can't really be shortened, as we applied everything. There’s no way to summarize it further. Exactly, it’s a lot. Nobody’s voice is shaking with nerves here.\n\n**01:09:52** What’s your personal take, as a designer, on AI? Well, as I said, since AI came along, user research has become lighter. No more need to go out and survey or interview too many users. Many people out there still have to call and interview a dozen users every day. Have you used ChatGPT for research? How do you use it for personas?\n\n**01:11:08** When I ask AI about personas, it gives me a lot of results. The main issue is that AI doesn’t help plan the prioritization of issues—it only helps find initial personas. From there, you have to rely on experience and real user interviews, then analyze and group personas correctly. If not, AI will give you too many personas.\n\n**01:11:56** Kafi mostly references competitor benchmarks anyway. Okay, I don’t have any more questions. Not sure if we recorded my voice. If there’s anything missing, just send the slides.\n\n**01:13:25** According to the agenda, Tom has a session called *mixture of agents*, where a group of agents work together, running a multi-agent system to get results. For now, though, that session might be too easy. I don’t think we’re ready for it, so we’ll skip it for now. There’s something more important to discuss about the trip and the test.\n\n**01:14:09** The test content will be as follows. You should start preparing now. First, you’ll write two essays. Write them yourself—if it’s bad, you’ll get criticized! The first essay will be about culture. I’ll pick one of the four core cultural pillars our team is following, likely centered around hybrid working, among other things. You’ll write an essay about that. I’ll share the question later, but I’m letting you know now. We’ll release it by the weekend for you to get started on it.\n\n**01:14:52** The reason for this is that, at this stage, I think everyone needs to set their own motivation to adapt to this new phase. The new phase is shaped by the market. The company phase is still normal, nothing special, but the market is changing. To align with that, everyone needs to refresh their motivation in this industry. That’s the first essay.\n\n**01:15:36** The second essay question will revolve around this: I haven’t decided on the exact wording yet, but it will be about the state of the app in your field. How is AI being applied in the field you work in? You’ll summarize this into an essay—kind of like a state-of-the-app report about how AI is being implemented in the industry outside. That’s the second essay.\n\n**01:16:18** Here’s a sample for that essay. I don’t know if I have it here—just a sample, though. For devs, it’s easier, but for those in sales, design, testing, or PM roles—it applies to all of you. Tom is thinking about cutting out those roles and replacing them with agents entirely. To be honest, we can expect AI to cover about 70–80% of the work, but we’ll still need people to drive those agents. So it’s a mixed approach.\n\n**01:17:04** For example, this article—is this the one? Let me check again. Right, take a look—does it look familiar? Some articles talk about how to use AI in a certain way. There are a few like this. The dev community covers some of this, but not a lot. Anyway, the second essay is about your role in the company. Given your role, how is AI being applied to your work today? That’s the second essay, okay?\n\n**01:17:42**  The third one will be about practical application. I haven’t decided on the prompt yet because if I give you random topics, you’ll just sit and chat with GPT, and it won’t be very useful. So it’ll relate to hands-on tasks—building software and making sure AI is used effectively in your actual work. I’ll think of a submission prompt for that, maybe asking everyone to use AI for assessment. I’m not fully endorsing AI to cover everything because I’ve seen how everyone is using it. For instance, when I use certain tools to generate scripts, it’s very generic and lacks practical insights.\n\n**01:18:16** Just a quick comment on that: the way you’re using AI as a machine, in a formulaic way, shows inexperience. I’m not sure what word to use here, but it’s pretty dull. Very underwhelming. Okay, essay three will be on application—after you’ve researched and understood things, it’ll be about how you practically apply AI.\n\n**01:18:58** Moving on—if the trip goes as planned, we’ll likely go in early December. That gives us about two months to prepare, and we’ll need to finalize everything at least a month in advance. So you’ll have about a month to work on this. Alright? These submissions will be required. This is a necessary condition for the trip, and it’ll also be a condition for the performance review in December and January.\n\n**01:19:39** Currently, I’m expecting that our team’s activities will be assessed using AI to a level where we can control the outcomes and ensure they align with what we want, just like before. It shouldn’t be a case of, “because I used this tool, now the result is like this—because you told me to use it.” Got it? It’s like stabbing yourself with a knife and then blaming someone else—this won’t work. Okay, this is a necessary condition for the trip, and also the sufficient condition for the review.\n\n**01:20:14** This is important because this December’s review, if someone makes it all the way through and doesn’t perform well, then it’s highly likely that the juniors and freshers will be cut. Yesterday, I saw a really funny post. This guy didn’t get hired anywhere, so he made a multiplayer game called *firm crash*, using Go and TP. He posted it and used math to create animations. The comments were pretty amusing.\n\n**01:21:04** So, the December review will focus on that. That’s the final announcement to make sure everyone is aware. The message will be released by the weekend so that everyone can prepare for the deadline to submit, and Huy will grade it before the fourth week of November. Probably, by the fourth week of October, you’ll have about three weeks left, right? Exactly. This is the announcement. If some of you aren’t participating, it doesn’t really matter that much.\n\n**01:21:55** Next, there’s the list that Tom has been working on. I haven’t checked everything yet, but I’m starting to assess things one by one. Why is the pilot list so slow? This is a different list from the one I mentioned before. I’ll quickly go through it to show you all. This list here—Tom is working on it. I see some of you are participating, which is a good sign. It shows that people are starting to become aware of the change in the concept of how we develop software.\n\n**01:22:42** Now, we’ve got the addition of servers, new methods for data manipulation, and different approaches to data collection. Everything is changing, so things will be different. The rewards have already been sent out and are done. As for what Tom is working on, I’ll review it. I’ll review the work that others have done, and Tom will review some other parts. One of the examples is Hieu Vu. Hieu Vu, are you here? I haven’t seen any updates from you. If you’re starting to look for jobs like this, it’s not going to go well.\n\n**01:23:15** You guys need to be proactive in finding topics to work on. Here’s one of the lists. As for the other list, we’ll go through it once Tom finishes it. There’s the *multi-agent* topic—when the other topics are done. *Knowledge sharing*, grouping, *specific projection.*\n\n**01:24:07** The *MapReduce* topic—the team is working on it, collecting data, building it up, and running it. Thanh is working on this one. Last time we were working on the architecture; it’s still a bit rough. Next up are other topics related to the old system. Before, we only had servers, but now we have agents, so we need to send data to them. The architecture will change a bit. When given a problem, how we structure the agents is still a topic we haven’t fully discussed with each other.\n\n**01:25:12** Some of you are setting up Dify and can see it’s related, but there are many questions about architecture and how to structure a system with not just servers but multiple agents distributed throughout. It’s similar to the example Hoang gave earlier—that was just an easy sample. But when it comes to a real problem, how will the server architecture look? This is a real, practical topic that we need to handle. Just reminding you all again: if you’re not paying attention, what Tom is writing might not make much sense to you. We’re falling far behind in this area of knowledge.\n\n**01:25:39** I think this cluster of knowledge will become foundational for software engineers. It’s not blockchain knowledge—I’m not saying everyone needs to know that. But this part, you need to know. What’s important is knowing how to break down a problem and create a logical flowchart in your mind. If you can’t break it down, then you’re still inexperienced. Just a gentle reminder.\n\n**01:26:17** That’s the full message. I just wanted to make sure everyone knows where the direction and expectations are heading. This weekend, there will be an essay prompt: you’ll need to write two essays, one report, and one case study. If there’s nothing else, I think that’s it.\n\n**01:26:53** Goodbye everyone, see you later. Hopefully, today’s recapped topics are still valuable to you. Once you have more knowledge, we’ll move on to discussing the new system. For now, everything you’re building is still within the old framework—meaning it’s old compared to the outside world. But knowing ahead of time is always better. Okay then, let’s wrap up. Does anyone have any questions?\n\n**01:27:44** I guess not. Let’s finish here. Yes, I need to chat with our team. Yesterday, Dat posted a video. I feel like we’re lagging behind society so much. Where’s Dat? He posted a video of some Vietnamese guys automating something. This is crazy. Do you know which channel it’s from?\n\n**01:28:42** Alright, I think so. Is it a random channel? Right now, everyone is still upset about learning architecture the old way. They’re stuck on learning this architecture and that architecture. But at this level of automation, we need to apply it more. Every enterprise app or regular app will fall under this scope. If it’s easy to build up, then it’ll cover everything quickly. If it’s hard to build up, and you don’t even know how to handle the easy stuff yet, then it’s going to be even harder. See you all at OGIF next week.\n\n**01:29:22** I hope that every Friday we learn something new. See you all at OGIF next week.\n","title":"OGIF Office Hours #26 - Product Design Commentary, Go Weekly, Trading App Case Study, Chatbot Evaluations, and Announcement for Essay Assignments","short_title":"#26 Design insights, Go tools, Trading app, Chatbots, Essays","description":"In this Office Hours, Nam Bui shared product design insights on the Sparkle icon in AI and onboarding, Phat covered Go tools Prep and War Zero, and Hoang discussed chatbot evaluations. Anh presented a case study on AI-driven user research for Kafi. Management announced AI essay assignments tied to the year-end trip and performance reviews.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Fri Oct 04 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/26-20241004.md","slugArray":["updates","ogif","26-20241004"]},{"content":"\n### Topic highlights\n1. Nam's presentation on \"UX Guide to Prompt with AI\"\n   - Overview of current AI-human interaction trends\n   - Introduction to the \"Race\" (Role, Action, Context, Expectation) concept in AI prompting\n   - Discussion of new methods to improve AI UX:\n     - Context Through Rephrasing\n     - Implicit Referencing\n     - Continue Conversation\n     - Racing and AI Scoring\n     - System Prompting\n   - Focus on designing AI tools for better user experience beyond speed and accuracy\n\n2. Minh's presentation on computing the union of two finite automata\n   - Applications of finite state machines in programming\n   - Use of automata in input validation (e.g., regex for email, phone number checks)\n   - Application in event-driven systems and event buttons\n   - Demonstration using Go source code\n\n3. Phat's presentation on Go Weekly commentary\n   - Overview of recent developments in the Go programming language\n   - Discussion of notable changes and updates\n   - Insights into the Go community and ecosystem\n\n4. Lap's presentation on Frontend Report for September\n   - Overview of recent trends and developments in frontend technologies\n   - Discussion of notable frameworks, libraries, and tools\n   - Insights into the frontend community and ecosystem\n\n---\n\n**Vietnamese Transcript**\n\n**08:02** Có thông tin gì cần phổ biến không? Không thì chắc để phát lên trước, nay thấy nhiều bài quá, để ưu tiên cho mấy bạn mới. Ok, nay có tới năm bài.\n\n**09:13**  Xin mời anh em.  Anh em nào có topic thì lên sớm nhờ. Dạ, pha start trước rồi, chưa đến phần Thành, mời Nam.  Dạ, bài của em là \"User Experience AI.\" Cái bài này chị team làm đi, rồi Thành bạn đã chuẩn bị chưa? Hôm nay, Nam sẽ chia sẻ về đề tài có tên là \"UX Guide to  Prompt with AI.\"\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hq_u9GQdNMg?si=FdFGv418n1MC5Apq&amp;start=608\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**10:20** \nThì em nói overview trước về tình hình hiện tại. Giao tiếp giữa con người và AI là chủ đề rất phổ biến hiện nay, và sự xuất hiện của LLM (Large Language Models) là công cụ hữu ích mà team mình đang muốn tìm hiểu. Bài hôm nay em sẽ dành cho ai quan tâm đến User Experience (UX) của AI, cụ thể hơn là cách các tool hiện đang thiết kế cho sự tương tác giữa người dùng và AI tốt hơn. Hiện nay có khá nhiều tool và platform ra đời, nhưng họ thường tập trung vào việc cải thiện tốc độ prompt và độ chính xác, thay vì chú trọng đến trải nghiệm người dùng.\n\n**11:08** Cái khái niệm \"Race\" (Role, Action, Context, Expectation) rất phổ biến trong việc prompt AI. Người dùng cần prompt theo cấu trúc này để AI có thể tạo ra output chính xác nhất. Tuy nhiên, không phải trường hợp nào cũng áp dụng được \"Race.\" Có nhiều công ty đã phát triển những phương pháp mới để cải thiện UX của AI, giúp tương tác giữa người dùng và AI mượt mà hơn.\n\n**12:04** Phương pháp đầu tiên là \"Context Through Rephrasing.\" Phương pháp này giúp AI truy vấn lại ngữ cảnh của câu hỏi trước, để trả lời câu hỏi tiếp theo một cách liên mạch, không cần từ đầu phải có cấu trúc prom chuẩn chỉnh. Ví dụ: Câu hỏi đầu tiên là “Who is the wife of Superman?” Tiếp theo, câu hỏi “When did they get married?” AI sẽ hiểu ngữ cảnh và liên kết đúng. Nhưng nếu không có ngữ cảnh phù hợp, như câu “What day did Titanic sink?”, AI sẽ không thể đưa ra kết quả đúng.\n\n**12:50** Tiếp theo là \"Implicit Referencing,\" ví dụ khi hỏi về số tầng của một building, AI sẽ tự động assume đó là một tòa nhà nổi tiếng như \"Willis Tower in Chicago.\" Nếu hỏi “What day?” mà không có ngữ cảnh liên quan, AI không thể trả lời chính xác. Các câu hỏi cần có sự liên kết chặt chẽ với nhau để AI có thể trả lời tốt hơn, và điều này cũng áp dụng cho \"Context Through Rephrasing.\"\n\n**14:19** Một khái niệm tương tự là \"Continue Conversation,\" như trong Google Assistant. Các câu hỏi được nối tiếp một cách tự nhiên, và mỗi câu hỏi mới sẽ liên quan đến những câu hỏi trước đó để tạo ra một chuỗi hội thoại liên tục.\n\n**15:03** Phương pháp tiếp theo là \"Racing and AI Scoring.\" Google Assistant cũng áp dụng phương pháp này. Nó cung cấp nhiều tùy chọn dựa trên các ngữ cảnh khác nhau, giúp người dùng có kết quả tốt hơn. AI cũng có thể tự động học từ những lựa chọn của người dùng để cải thiện khả năng tương tác. Ví dụ, khi AI không rõ ngữ cảnh, nó sẽ đưa ra các tùy chọn cho người dùng chọn.\n\n**16:03** Cuối cùng là \"System Prompting.\" Lý thuyết này định hướng cho AI hoạt động theo ngữ cảnh và mục tiêu người dùng đặt ra. Nó giúp AI tạo ra output chính xác mà không cần tuân theo một chuẩn prompt cố định. Ví dụ, cùng một câu hỏi “Plan for releasing a software product,” Chat GPT có thể đưa ra các khái niệm chung chung, trong khi GPT mini sẽ đưa ra các câu hỏi chi tiết hơn để giúp người dùng prompt tiếp và đạt kết quả chính xác hơn.\n\n**17:45** Bài hôm nay sẽ tập trung vào việc thiết kế tool AI sao cho user experience tốt hơn, không chỉ dựa vào tốc độ hay độ chính xác, mà còn chú trọng đến sự tương tác và trải nghiệm tổng thể của người dùng.\n\n**18:50** Tóm tắt lại bài này cho các bạn, đặc biệt là các bạn designer, bài của Nam có hai khía cạnh chính. Thứ nhất, nó giải thích cấu trúc của \"Race\" và cách áp dụng nó. Thứ hai, nó đưa ra một framework thiết kế tool AI tập trung vào việc prompt sao cho tương tác giữa AI và người dùng tốt hơn. Cấu trúc \"Race\" này gồm Role, Action, Context, và Expectation, và nó giúp cải thiện UX của AI.\n\n**19:20** Giải thích cái cấu trúc sơ qua của chuyện là cái Race nó như thế nào, có những thể loại Race như thế nào là những phần nãy giờ Nam nói. Cái thứ hai đó là cái layer về chuyện xây dựng (build) một ứng dụng tập trung vào chuyện prompting, thì cấu trúc đó gắn vào ra làm sao. Khi viết một cái Race, bạn sẽ phải nói rõ Role, Action, Context, và Expectation.\n\n**20:03** Race được mô tả rất rõ ràng: Role là gì, Action là gì, mọi thứ được mô tả theo cái Expect là gì, Task là gì. Tóm lại, chữ R thì cơ bản nhất là các designer sẽ nhìn và hiểu cấu trúc của một câu Race. Nó sẽ có cấu trúc nhất định, dựa trên đó mà đưa ra kết quả tiêu chuẩn. Input là như vậy, và output sẽ nhận được kết quả tương ứng.\n\n**20:47** Phần thứ hai, phần cuối của bài này, sẽ nói về chuyện khi mình đã hiểu cấu trúc của một cái prompt rồi, và hiểu luôn cách để prompt sao cho chuẩn xác. Khi thiết kế, cần phải chú ý những gì? Phần này sẽ là phần mở vì bài này giống như là bài 101 cho các bạn designer để nhìn qua và hiểu cơ bản.\n\n**21:30** Nam đã nói khá nhiều về cái chữ R, nên đôi lúc có thể mọi người sẽ hiểu lầm là bài này đang giải thích chi tiết lại cái đó. Nhưng thực ra bài này là giới thiệu về prompting cho UX designer. Ok, câu hỏi sẽ là, có ai có thắc mắc gì không? Bài này khá cơ bản, team mình xài nhiều rồi, demo cũng nhiều rồi. Có một phần cần lưu ý, bài này đặc biệt hơn ở chỗ giới thiệu về system prompting, mà các bài khác không có.\n\n**22:31** Bài này giới thiệu cái system prompting mà các bài hướng dẫn khác thường không nhắc tới. Các bài viết cho người dùng cuối (end user) thường không đề cập đến điều này nhiều. Bài này nhắc tới system prompting vì nó viết dưới góc nhìn của designer – một người trong đội build. System prompting sẽ khác so với prompting thông thường, vì nó điều khiển cách AI hoạt động theo mục tiêu cụ thể của hệ thống.\n\n**23:06** Cấu trúc của system prompting khác so với các loại R thông thường mà mọi người thường thấy khi đọc research. Thường thì các bạn chỉ thấy nói về 200 kiểu R khác nhau, nhưng không có góc độ là viết cho người build app. Bài này dành cho designer, không phải là end user, mà là người đứng giữa, để kết nối các phần lại với nhau.\n\n**23:48** Bài này khác với những bài viết dành cho engineer vì nó không chỉ giới thiệu về tooling để xây dựng prompts, mà còn nói về việc kết hợp các kiểu R lại với nhau. Đây là bài ở mức độ trung gian, phù hợp cho các bạn làm designer, có vai trò đứng giữa, không trực tiếp build nhưng cũng không phải người dùng cuối. Nó giúp kết nối hai phần này với nhau.\n\n**24:33** Ok, cảm ơn Nam. Tuần sau chắc sẽ scope lại bài theo content cho mọi người dễ hiểu hơn. Còn đi sâu vào chi tiết thì sẽ hơi khó để mọi người nắm bắt hết nội dung. Cảm ơn em nhé. Mời bạn tiếp theo. Để xem thử, không xem màn hình được, à vào lại rồi.\n\n**25:41** Bài của em hôm nay là về một vấn đề nhỏ trong kỹ thuật lập trình, đó là cách compute một tổ hợp (Union) của hai cái finite automata hay còn gọi là finite state machine. Em sẽ demo nó trên một cái source code Go. Chủ đề này hôm nay sẽ có một số mục chính. Trước tiên sẽ giải thích các ứng dụng của automata để mọi người dễ hình dung trước, rồi sẽ đi vào chi tiết.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hq_u9GQdNMg?si=nEFRO7pOhdBxjouy&amp;start=1617\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**26:41** Ứng dụng mà của finite state machine mà mọi người thường thấy nhất là nó sẽ dùng trong việc có một cái button và một cái input, thì mình sẽ muốn kiểm tra xem input này đưa vào cái button đó nó sẽ match hay là nó fail. Nó đơn giản chỉ là như vậy thôi. Cái dễ thấy nhất thường sẽ là dùng regex để kiểm tra xem một đoạn text có phải là một email hoặc là số điện thoại, hoặc là số nhà hay không. Mình sẽ có một cái button giống như vậy, và mình sẽ đưa một đoạn text vào cho nó kiểm tra xem nó có match với điều kiện đó không.\n\nNgoài regex, dễ thấy nhất, thì ở trong những cái hệ thống event-driven nó sẽ có cái gọi là event button. Mọi người sẽ define một cái button dưới dạng một cái state machine, sau đó, mỗi event sẽ là một state, nó sẽ đi qua event button này và sẽ được filter qua xem nó có match với cái event đó hay không. Nếu match thì nó sẽ đi qua và tới cái state tiếp theo để nó làm tiếp, còn nếu không thì nó sẽ fail và không đi qua được.\n\n**27:27** Đây là một ví dụ của nó: Ví dụ, mình có một cái event bus, tất cả các event sẽ đi qua cái event bus này và sẽ được filter qua các rule. Nếu một event thỏa mãn điều kiện của rule thì nó sẽ đi qua để tiếp tục xử lý. Điều này thường thấy nhất trong các hệ thống cloud hiện tại, họ dùng rất nhiều cái hệ thống này để quản lý các event và filter chúng qua những cái rule như vậy. Mọi người có thể thấy trong những cái hệ thống lớn như của Amazon chẳng hạn, event của họ sẽ đi qua một chuỗi các rule như thế.\n\n**28:05** Ví dụ là mình có một cái button, và tất cả những cái item nào có cái field image, trong cái field image đó có một cái object là width với giá trị là 800, thì nó sẽ được pass qua hết. Và ở dưới thì nó cũng sẽ thêm một vài cái rule nữa, chẳng hạn như những cái field khác nhau mà mình thêm vào cho cái button đó. Đó là một ví dụ về việc finite state machine và event button hoạt động như thế nào. Khi một event được đưa vào hệ thống, nó sẽ đi qua các rule, và nếu thỏa mãn các điều kiện thì nó sẽ được pass qua để tiếp tục các bước xử lý tiếp theo.\n\n**28:56** Đây là một ví dụ cụ thể về hệ thống event của Amazon, nơi mà các event của họ sẽ đi qua một chuỗi các rule để được filter và xử lý. Hầu hết các hệ thống cloud hiện nay đều sử dụng những mẫu button tương tự để quản lý và xử lý các event một cách có tổ chức và hiệu quả.\n\n**29:37** Trong thực tế, bây giờ mình sẽ đi ngược lại một chút về finite automata (f automata) dưới góc độ toán học, nó là cái gì. Thực chất, nó đơn giản là một cái machine trong đó có một tập hợp những states. Để đi từ một state này tới một state tiếp theo, nó cần phải đi qua một transition. Ví dụ, để từ start state tới một end state, nó sẽ luôn cần phải có một điểm bắt đầu gọi là start state và một điểm kết thúc gọi là end state. Vì vậy, nó được gọi là finite state machine bởi vì nó luôn có điểm bắt đầu và điểm kết thúc.\n\n**30:21** Ở giữa, sẽ có một tập hợp các transitions và states để di chuyển từ điểm bắt đầu tới điểm kết thúc. Một input symbol là cái để đưa vào một state để nó di chuyển tới một state khác, và trong thực tế, input symbol thường sẽ là một ký tự. Tí nữa mình sẽ bàn chi tiết về vấn đề này. Accepting state là trạng thái mà khi input của nó được chấp nhận, thì nó sẽ được di chuyển tới một state khác thông qua một transition. Nếu như không chấp nhận thì nó sẽ không di chuyển tới đâu cả, coi như transition đó không dẫn tới một state nào.\n\n**31:04** Có hai loại finite automata, đó là deterministic finite automata (DFA) và nondeterministic finite automata (NFA). Điểm khác biệt duy nhất ở đây là với DFA, mỗi state sẽ có một input symbol duy nhất dẫn tới một transition tới một state khác. Còn với NFA, nó có thể có nhiều transitions cho cùng một state, thậm chí có thể không có transition nào hết. Điều này chỉ khác nhau về cách thể hiện con đường từ điểm bắt đầu tới điểm kết thúc, chứ thật ra một cái finite state machine đều có thể được biểu diễn dưới dạng DFA hoặc NFA, chỉ khác nhau cách biểu diễn thôi.\n\n**31:51** Về phần Union của hai cái finite automata, thì nó sẽ là tổ hợp của tất cả các states và transitions của hai cái finite automata cộng lại. Đặc điểm của nó là nếu ví dụ cái event A pass qua được cái finite automaton FA1 và event B pass qua cái finite automaton FA2, thì tổ hợp của hai cái này, Union của hai cái này, nó phải đảm bảo là cả event A và event B đều pass qua được.\n\n**32:45** Tại sao chúng ta cần phải tính toán Union của hai cái finite automata? Trong thực tế, ví dụ như khi dùng một cái event button, ta sẽ không dùng một cái button mà sẽ dùng nhiều button kết hợp lại với nhau. Ví dụ ở trong hình, chúng ta có thể define rất nhiều button, và trong event của mình có thể chứa nhiều đoạn thông tin match với những button này. Khi muốn kết hợp những button đó lại với nhau, chúng ta sẽ cần tính toán tổ hợp của tất cả chúng lại.\n\n**33:24** Nhưng mình sẽ không tính tất cả một lần, mà sẽ tính từng cái một, từng cặp một, ví dụ như cặp A và cặp B trước, sau đó lấy tổ hợp của A và B, rồi lại tính với cặp C. Chỉ cần tính toán hai button một lúc thôi, đây là mức cơ bản nhất để tính ra được tổ hợp của tất cả các button này.\n\nĐể tính toán Union của hai cái finite automata, theo lý thuyết thì chúng ta sẽ phải tính hết tất cả các states và transitions của hai automata đó. Ví dụ mình có hai cái button A và B, trong mỗi button sẽ có rất nhiều states, ví dụ như từ A1 đến Ax và từ B1 đến Bx. Khi tính toán theo kiểu lý thuyết, mình sẽ phải tính toán tất cả các trường hợp kết hợp giữa hai button này, ví dụ A1-B1, A2-B2, A1-B2, A2-B1, có rất nhiều trường hợp.\n\n**34:07** Trong thực tế mình chỉ quan tâm đến việc khi đưa event vào button thì mình muốn biết nó có match hay không thôi. Mình chỉ cần quan tâm xem event đó sau khi đưa vào button, nó có thể đi đến state cuối hay không. Việc tính toán tất cả các states trong Union sẽ rất lãng phí và không cần thiết. Do đó, cách tiếp cận thực tế là mình sẽ có hai finite automata với các states từ A1 tới Ax và từ B1 tới Bx. Khi tính tổ hợp của chúng, mình sẽ kiểm tra xem state đó có dẫn tới một transition nào trong A hoặc B hay không. Nếu không, mình sẽ bỏ qua.\n\n**35:40** Ví dụ như nếu state chỉ dẫn tới A1 và không có transition nào dẫn tới B, thì mình sẽ chỉ tính toán cho nhánh của A, bỏ qua nhánh của B. Ngược lại, cũng tương tự với B. Trường hợp cuối cùng là nếu A1 di chuyển tới Ax và B1 cũng di chuyển tới Bx, thì chúng ta sẽ tạo ra một state mới là Ax-Bx. Lúc này, mình sẽ bắt đầu đệ quy lại và tiếp tục tính toán từ bước đầu tiên này. Ví dụ, mình có A1-B1, và sau đó có A2-B2, thì mình sẽ lặp lại bốn bước này để tính toán tiếp.\n\n**36:15** Khi đó, số lượng states mà mình có thể bỏ qua và không cần tính hoặc không cần lưu trữ sẽ giảm đi rất nhiều so với phương pháp lý thuyết ở trên.\n\nVề input symbol, như trong ví dụ về event button hoặc regex, trong thực tế, các button và input mà chúng ta truyền vào chương trình đều sẽ ở dạng ký tự. Ký tự ở đây thường sẽ là những cái.\n\n**37:04** Ký tự dưới dạng UTF-8, tức là những ký tự đơn giản ví dụ như từ a tới z hoặc từ 0 đến 9. Nó sẽ nằm gọn trong UTF-8, bao gồm 244 ký tự. Mặc dù UTF-8 xài 8 bits (2^8 - 1 = 256), nhưng những bits từ 245 đến 255 thì dư ra, nên mình không xài, chỉ có 244 bits đầu tiên thôi. Rồi, đây là phần detail implementation trong code. Đây là cái workflow cơ bản mà mình sẽ thực hiện. Không biết có zoom được không? Zoom hình hồi nãy thử xem, không thấy chữ gì hết. Từ từ, để xem lại.\n\n**38:21** Rồi, cái FA là gì? Finite automata hả? Đúng rồi, automata. Cái hàm này sẽ merge hai cái automata lại với nhau. Đầu tiên nó sẽ tạo ra một cái key để mình đánh dấu lại, để không phải đi lại những cái state mà mình đã xử lý rồi. Sau đó, nó sẽ check thử cái key này, nếu không trùng, thì nó bắt đầu làm việc. Nó sẽ tạo một cái combined state rỗng, bao gồm tất cả các transitions của hai cái finite automata đó. Rồi nó sẽ tiếp tục merge từng cái finite automata lại với nhau, từng cái một. Kéo lên, mình đọc chưa kịp cái đó.\n\n**39:33** Trong quá trình implementation, sẽ có một số điểm cần chỉnh sửa trong cấu trúc dữ liệu để lưu lại những states đó. Đề tài này của em là em đang chạy cho cái example nào vậy? Hình này đang chạy sample nào? Đây chắc để em show code thì dễ nhìn hơn, phải nhìn vào đề bài mới biết đang code cho bài nào. Rồi, sau cái ví dụ này, sẽ có nhiều câu hỏi cho mình. Nhưng bài này chỉ cần Phúc và Tuấn hiểu là được, mọi người hiểu code rõ không?\n\nVí dụ hồi nãy về bài toán event button, ở đây mình sẽ define một cái button chẳng hạn. Cái button em define ra dưới dạng T, và đây là cái event. Khi mình chạy đoạn code này, nó chỉ là một phần logic thôi, ngoài ra còn nhiều đoạn code khác nữa. Nhưng khi chạy cái đó, kết quả mình mong đợi là nó sẽ kiểm tra xem event này có match với button này không. Nó sẽ trả về kết quả là đúng hay không đúng, event có match với button không.\n\n**41:13** Đúng rồi, đó là bài toán mà vấn đề này đang giải quyết. Đây là đoạn code đơn giản, em sẽ chạy ra kết quả, chỉ kiểm tra xem nó có match với button này hay không thôi. Ví dụ ở đây, button này có transition với từ \"user_register,\" chẳng hạn. Nếu em sửa lại điều gì đó khác, thì nó sẽ không match. Còn nếu event thỏa mãn điều kiện thì nó sẽ match, kiểu như vậy.\n\n**42:09** Em sẽ đi thẳng tới phần logic chính. Nó sẽ là cái hàm để merge hai cái finite state machine lại với nhau. Mỗi cái finite automata này đại diện cho một cái button. Cứ tưởng tượng mình có nhiều cái button. Ở đây mới chỉ có một cái button thôi, ví dụ em tách cái này thành hai button. Hàm của mình có nhiệm vụ merge hai cái button đó lại để tạo ra một cái button tổng.\n\n**43:31** Như đã nói, để tránh tính toán quá nhiều, trước tiên mình sẽ giải thích các tham số truyền vào hàm. Hai cái FAState là hai cái structure đại diện cho hai cái button hồi nãy của mình. Mỗi cái structure này bao gồm một small table để đại diện cho một dãy những input symbols và những transitions tương ứng. Epsilon là state mà tự đưa lại chính vị trí của nó, mình sẽ bỏ qua nó tạm thời. Ở đây mình chỉ quan tâm tới hai cái states này thôi. Đơn vị nhỏ nhất ở đây mà mình muốn làm input là file, bởi vì một ký tự sẽ được thể hiện dưới dạng UTF-8 và bao gồm 244 bits. Bây giờ mình sẽ loop qua từng bit trong từng ký tự này để so sánh.\n\n**44:20** Ví dụ như trong ví dụ này, mình đưa một cái event vào, sau khi mình compute xong hai cái button này, nó sẽ bắt đầu từ từng ký tự. Ví dụ nó sẽ đi từ ký tự dấu ngoặc, rồi sẽ kiểm tra xem có transition nào tới cái \"user\" không. Nếu không có, nó sẽ skip phần ID, vì nó không match. Bạn này đang đi vào chi tiết cách so sánh từng ký tự.\n\n**45:02** Skip đoạn này đi. Chỉ cần xem lợi ích và ý tưởng của việc cài đặt thôi, còn so sánh chi tiết thì không cần thiết ở đây. Lợi ích của phương pháp này đơn giản là nó giúp thuật toán không phải tính toán lại nhiều lần. Thuật toán khá đơn giản, chỉ là compare, như mình đã phân tích. Nếu một ký tự không có dẫn tới một transition nào, mình sẽ bỏ qua. Hoặc nếu nó chỉ dẫn tới một nhánh, mà nhánh đó không có transition nào, thì mình cũng bỏ qua luôn.\n\n**46:34** Ví dụ nếu state A1 của mình đi đến state B, mà state B không tồn tại, thì mình sẽ bỏ qua nhánh đó. Ngược lại, nếu state này đã tồn tại trong map rồi, mình cũng sẽ bỏ qua. Chỉ khi nào thỏa hết các điều kiện thì mình mới bắt đầu tính toán và loop qua từng state trong finite automata. Sau khi loop qua từng bước với mỗi state tương ứng trong B, mình sẽ ra được cái state tổng và gán nó vào, sau đó return ra kết quả.\n\n**47:17** Mọi người có hiểu không? Hỏi Minh xem. Minh đi coi cái này, anh kêu Minh quăng cái link lên. Bữa anh em nghe có hiểu không? Quan trọng là coi lại cái diagram đầu tiên, vì mình sợ mọi người không hiểu. Diagram này lâu lắm rồi, hơn cả tháng rồi đúng không? Đúng rồi, diagram này, mọi người có hiểu không?\n\n**49:11** Hệ thống như event bus của Amazon cần phải merge có khi lên đến hàng triệu cái button, nên sẽ có một số chi tiết trong phần implementation để làm những việc này nhanh hơn. Rồi qua một hình khác nữa đi, hình kế tiếp, hình mà nó rẽ hai nhánh, dùng hình đó để nói dễ hơn. Hình rẽ hai nhánh, đúng rồi. Cái hình rẽ hai nhánh, cái nào mà nên? Ừ chắc dùng giữ hình này đi, mấy anh kia có hiểu không?\n\n**50:11** Nói luôn cho rõ, lỡ nói bài này, mọi người nắm thì nó sẽ ok hơn. Hoàng có hiểu không? Em có hiểu cái này làm gì không? À, Phúc hỏi là có dùng bit operator không? Này thì chưa, chưa đến mức đó, chỉ là chi tiết so sánh rồi, không liên quan tới phần đó đâu. Tuấn, Minh ơi, Vincent đâu rồi, mọi người có hiểu bài này không? Không hiểu hả? Bài này nó ẩn tới ba lớp trong đó của phần Minh nói nha. Để mình clear vài thứ cho anh em đỡ lẫn lộn.\n\n**51:03** Đầu tiên là finite automata, tức là cái machine trạng thái, giống như cái state transition diagram mà mấy anh em hay vẽ. Nhớ không? Nó có những trạng thái (states) và các nút (nodes) đại diện cho trạng thái đó. Cái thứ hai là các điều kiện (input symbols) để di chuyển từ trạng thái này qua trạng thái khác, gọi là transition. Đọc cho dễ hiểu, dễ nhớ nhé. Nó giống như cái state transition diagram, đó là cái đầu tiên.\n\n**51:47** Cái thứ hai, cái mà Minh vừa show ra, là hai loại finite automata này. Tại sao lại show ra hai loại này? Vì có những trạng thái rất đơn giản, nó chỉ đi một chiều và không quay ngược lại được. Ví dụ, giờ ăn trưa chẳng hạn. Khi mình đi ra Hà Đô để ăn trưa, mình có thể đi ăn phở, đi bộ ra quán phở, ăn xong rồi đi về. Đó là hoàn thành một cái finite state trạng thái hũ hạn. Nó không có quay đầu lại được, đó là finite automata.\n\n**53:10** Một ví dụ khác, có một trạng thái finite automata mới là đi ăn trưa, nhưng lần này đi xuống siêu thị mua cơm, trả tiền rồi đi về. Vẫn là một cái finite automata, nhưng nó có các states khác với cái trước.\n\n**53:57** Câu chuyện là làm sao tính toán tổ hợp (union) của hai cái finite automata này. Giả sử có hai trạng thái tổ hợp, một là đi ăn phở, hai là đi mua cơm siêu thị. Ta cần build một cái union cho hai trạng thái đó, giống như Minh đã nói về việc merge hai cái state machines lại. Ở đây, chúng ta sẽ có hai lựa chọn: một là đi ăn phở, hai là đi siêu thị mua cơm. Ý tưởng là làm sao tổ hợp tất cả các lựa chọn có thể có giữa hai hệ thống states khác nhau.   \n\n**54:30** Mình tính tổ hợp của nó thì mình gộp lại thôi. Trong cái trường hợp hồi nãy, ví dụ đó, mình sẽ có bao nhiêu options? Một người đi ăn phở, người kia đi siêu thị, đúng không? Ví dụ cũng là tính tổ hợp, nhưng đây là tổ hợp khác nha. Bài toán là có hai cái hệ thống finite automata (FA), và mình yêu cầu là tính union của chúng lại. Sau đó, mình kiểm tra như thế nào? Sẽ có hai phần: phần thứ nhất là đi theo luồng ban đầu – đi ăn phở, và phần thứ hai là đi theo luồng siêu thị. Một trường hợp khác là khi chập hai hệ điều kiện lại với nhau, nó sẽ sinh ra một hệ phụ nữa. Khi đó, mình lại phải tiếp tục tính toán và compute thêm.\n\n**55:17** Rồi, idea cơ bản của việc làm union của nhiều finite automata là vậy. Nó giống như phần mà Minh đã show lúc nãy, Minh có show cái source code. Rồi, coi lại cái hàm lúc nãy đi. Được rồi, ở đây, hàm của Minh có cái hàm để merge tất cả các states lại. Tức là, như đây, mình giả lập là có hai cái hệ states thôi đúng không, của hai cái finite automata khác nhau. Sau đó mình gộp lại thành một hệ chung, rồi ra được cái bảng lớn. Trên cái bảng lớn đó, mình mới tiếp tục tính toán với từng điều kiện.\n\n**56:04** Giờ mình đã build xong cái bảng lớn, một cái array lớn là danh sách tổng các điều kiện nằm ngay đó. Bây giờ mình sẽ bắt đầu tính toán. Khi có một điều kiện mới đưa vào, nó sẽ bắt đầu bằng cách kiểm tra tất cả các điều kiện của hệ đầu tiên. Nếu không được, thì nó kiểm tra các điều kiện của hệ thứ hai. Nếu vẫn không match, thì nó sẽ kiểm tra tiếp điều kiện của hệ tổ hợp giữa hai hệ trước đó. Logic tính toán cơ bản là như vậy.\n\n**57:02** Cái khó của bài này, nếu anh em cảm thấy hơi lẫn lộn, là do quá trình mô hình hóa từ toán học sang lập trình. Cho xem lại cái hàm và cái hình lúc nãy. Hình này là để giải thích tại sao trong bài regular expressions, người ta lại mention điều đó. Khi mình check trong cái dấu ngoặc vuông trong regular expressions, mình phải đi qua bao nhiêu điều kiện trong đó. Vì có nhiều options như vậy, mỗi option lại được mô hình hóa thành toán để dễ xử lý. Mỗi điều kiện là một cái finite automata, và chúng ta tính union của các điều kiện này.\n\n**58:38** Mô hình hóa toán logic thành lập trình là quá trình tính toán với nhiều hệ khác nhau. Mình phải tính toán xem điều kiện union của các hệ 1, 2, 3, 4... Nếu không có điều kiện nào, thì mình phải tính tiếp hệ giao của từng cặp điều kiện. Bài toán này là như vậy. Nếu anh em muốn tìm hiểu thêm, đây là một bài quan trọng vì nó giúp cho hiểu cách mà mình làm trong các hệ thống logic lớn.\n\n**59:21** Chắc bữa trước đưa cho Minh coi rồi. Tại vì điều này quan trọng, bởi nó liên quan tới việc làm hàm cộng trong logic. So sánh phổ biến nhất là login authentication, như bài log in, nó sẽ dính tới bài này. Trong quá trình log in, sẽ có nhiều điều kiện, ví dụ như nó pass bằng 2FA, hoặc email, hoặc SMS, hoặc password. Mỗi thứ này có thể mô hình hóa thành một cái finite automata riêng, và khi mình compute, mình gom tất cả lại.\n\n**01:00:00** Ví dụ như có yêu cầu là người dùng phải có vừa face scan vừa có QR code trên app để đăng nhập. Đó là một điều kiện tổ hợp (giao), chứ không đơn giản là một điều kiện if như bình thường. Trong mô hình toán học, ta sẽ dễ dàng xử lý hơn vì nó sẽ có tính chất đệ quy để tính toán các tổ hợp logic phức tạp. Cái quan trọng nhất là làm sao để tính được tổ hợp này mà không phải tính lại nhiều lần. Output sẽ là success hoặc failure. Nhưng đối với các bạn junior, khi thêm một case mới mà không có tư duy mô hình hóa, họ sẽ làm rất nhiều if statements lộn xộn, gây khó khăn khi bảo trì code.\n\n**01:01:29** Khi thêm một feature mới mà không có tư duy về mô hình hóa, code sẽ trở nên rối rắm và không hiệu quả. Họ sẽ phải sửa lại nhiều lần, gây ra nhiều lỗi và mất nhiều thời gian hơn để kiểm thử và sửa lỗi. Đó là lý do tại sao bài toán này quan trọng, vì nó ảnh hưởng tới việc thiết kế hệ thống, đặc biệt là các hệ thống như login authentication, nơi mà việc tổ hợp nhiều điều kiện là rất phổ biến.\n\n**01:02:23** Còn câu hỏi nào không? Không có hả? Minh, em có hiểu hết không? Ok, chắc hết giờ rồi. Thành ơi, còn bài nào nữa không? Chắc còn hai bài nữa, tranh thủ làm nốt thôi. Để em xem nào. Mọi người thấy màn hình không? Ok, tuần này em chỉ biết được hai bài, còn một bài nữa nhưng nó dài quá, chắc hẹn tuần sau. Bài đó cần chi tiết hơn về cách sử dụng.\n\n**01:03:36** Bài tiếp theo là về Go và cách embed file. Go embed là gì? Nó cho phép mình embed một cái file trực tiếp vào trong binary. Điều này giúp mình giảm thiểu việc handle các external files. Cách sử dụng là khi mình embed một file vào binary, quá trình handle sẽ trở nên đơn giản hơn. Nhưng có một hạn chế, đó là nếu file quá lớn, thì binary của mình sẽ phình to ra. Nên cần phải cẩn thận khi sử dụng.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hq_u9GQdNMg?si=Jiktpv6YYMbiOzp8&amp;start=3793\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**01:04:15** Cách sử dụng như thế này: mình chỉ việc import rồi sử dụng như bình thường. Ví dụ, mình có một cái file message, mình embed file đó vào, rồi có thể truy cập file đó trực tiếp trong binary. Đối với nhiều file, mình có thể thêm ký tự sau như thế này. Sau đó, mình dùng biến đã embed để read file hoặc access như một file bình thường. Hoặc mình có thể embed nguyên một thư mục Directory luôn.\n\n**01:04:57** Thường thì chúng ta muốn embed cái static file như file ảnh, HTML, hoặc cái gì đó kiểu vậy. Về cái limitation mình nói trước đó, cái thứ hai là về reflect một cái package. Bài này thì nội dung cũng không mới. Thật ra cũng không mới nếu như mà em xài Go và có đọc trước bài của bác R rồi. Em sẽ nói qua luôn. Context của ông tác giả này cũng giống như mình thôi. Ví dụ như ổng đang xài một cái tool, một cái codebase nào đó, xong ổng gặp vấn đề về reflect và viết lại bài này. Thì nhìn chung, reflect có ba phần cần chú ý.\n\n**01:05:49** Ba phần quan trọng là: từ interface value cho đến reflection object, và ngược lại. Phần cuối cùng là khi muốn modify thì những cái value đó phải settable – nghĩa là phải được export, tức là phải viết trên capitalized value. Interface value là gì? Reflection object là gì? Interface value là mỗi hàm mà mình xài trong package reflect, nó luôn được hiểu là một interface{} rộng, cho nên nó là giá trị interface. Còn cái giá trị này là reflection object, và ngược lại.\n\n**01:06:36** Về chiều đi: ValueOf sẽ trả về một reflection object. Còn chiều ngược lại: từ đây, mình có thể dùng method là .Interface() để trả ngược lại giá trị ban đầu. Bên Go thì hiện tại nó đã mặc định sẵn rồi. Nếu muốn cập nhật (update) cái gì đó, mình cần tìm cái settable. Reflect có method này để mình có thể dùng và cập nhật được.\n\n**01:07:12** Còn một ý nữa là bên bài viết đó cũng đã nói rồi – nên tránh dùng reflect trừ trường hợp bất khả kháng. Vì nếu mình dùng các hàm như FieldByName, nếu input không được kiểm soát tốt, nó có thể dẫn đến panic hoặc crash ngay lập tức. Nên chỉ dùng khi thực sự cần thiết thôi, trong những trường hợp bí bách.\n\n**01:07:53** Còn một bài khác nữa mà em nói là dài, nói về map. Bài này so sánh giữa việc xài map bình thường với khi cần hỗ trợ concurrency, thì mình cần dùng locking strategy. Có thể xài mutex hay cái gì đó, hoặc lock khác. Bên package sync có hỗ trợ một cái sync.Map. Bài đó sẽ so sánh giữa hai cách tiếp cận này. Thực sự thì không có cái nào hơn cái nào, mà tuỳ vào use case mà xài.\n\n**01:08:35** Rồi chắc tới phần sau. Phát dạ, đơn giản thôi. Minh Trần đang hỏi về logic của ba automata, rồi yêu cầu thêm hai automata nữa. Thì Minh Trần đang hiểu sai thứ tự rồi. Thứ tự sẽ là theo logic khác. Tại sao anh Huy lại nói về các automata của hệ thống Việt Nam? Là bởi vì trước đây họ tiếp cận từ góc độ máy công nghiệp, những hệ máy tự động hoá. Không thể build tụi nó để chúng tương tác với nhau, chạy với nhau tự động, vì chi phí thử và sai rất cao.\n\n**01:09:31** Vì thế, để đảm bảo hiệu quả, họ phải tính toán về mặt logic trước, xem có bao phủ hết các trường hợp không. Ví dụ, khi có ba hệ thống, thêm hai hệ thống nữa là thành năm hệ thống. Trước tiên, phải xem thiết kế logic có chồng chéo gì không. Sau đó, mình mới list out các cây logic ra và tính toán. Đó là bước đầu tiên, sau đó mới tiến hành cài đặt.\n\n**01:10:09** Còn phần lập trình thực hiện sau đó tuỳ vào cách bạn muốn làm: có thể là union các hệ thống hoặc làm hàm cộng. Quan trọng là trước khi làm gì, mình phải đảm bảo phần logic đã cover được hết các trường hợp. Logic ở đây không chỉ là chuyển từ A sang B, mà là hệ logic tổng quát, bao gồm việc tính toán trên cây logic.\n\n**01:10:50** Union trong bài này nói về logic toán học một chút thôi. Còn khi implementation, nếu anh em đã làm thì chắc cũng dễ dàng làm được hàm cộng. Chỉ cần hiểu là trong union logic, chúng ta gom các điều kiện lại và tính toán. Sau khi gom các điều kiện đó, câu hỏi sẽ là trong hàm cộng, nó thực hiện như thế nào. Thường thì mọi người sẽ cố gắng explicitly từng bước một.\n\n**01:11:53** Ok, chắc ổn rồi. Thành còn gì nữa không? Ok, được rồi, để bên DevOps xử lý tiếp. Vào thử lại xem có vấn đề gì không. Mọi người tranh thủ làm bài test sớm nhé. Đợt này có deal về tài chính và AI, nên hãy chú ý.\n\n**01:13:04** Rồi, em sẽ nói qua luôn. Trong tháng 9 này thì không có nhiều tin nổi bật. Em sẽ nói nhanh thôi. Đầu tiên là về React, với những keywords như server actions, server functions, và React compiler. Có một bài viết trên freeCodeCamp về kiến trúc của React 19, nói rõ về cách tối ưu hoá hiệu suất. Nếu mọi người có thời gian thì nên đọc bài này.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hq_u9GQdNMg?si=2kaVp-rYPWxf3Rup&amp;start=4446\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**01:15:12** Về Next.js, không có gì mới. Chỉ có một cái lùm xùm hồi đầu tháng khi OpenAI chuyển từ Next.js sang Remix. Tóm lại, OpenAI muốn trang của họ nhẹ hơn vì Next.js hơi nặng đối với kiểu trang SPA của chatbox. Vì vậy, họ quyết định quay về dùng Remix. Điều này liên quan đến một xu hướng mà em cảm thấy đang xuất hiện trong cộng đồng engineer: các framework như Next.js dần không được ưa chuộng như trước nữa.\n\n**01:15:51**\nCòn về Next.js, không có gì nhiều, chỉ vậy thôi. Ngoài ra, có một cái OpenNext, nó đang hướng tới hỗ trợ việc host Next.js trên tất cả các runtime. Hiện tại, Next.js chỉ chính thức hỗ trợ hosting trên các môi trường cụ thể, còn nếu muốn host ở những môi trường khác thì rất khó khăn.\n\n**01:16:28** Thằng OpenNext này thì mục tiêu của tụi nó là muốn hướng tới một cách mà mọi người có thể host Next.js trên tất cả các môi trường, kiểu không còn bị Versel độc quyền nữa. Vậy nên, có thằng này làm để giải quyết vấn đề đó. Qua cái mục này thì em thấy có hai cái thú vị đang được feature ở đây. Có một thanh niên đang implement một hệ thống real-time đơn giản dùng TypeScript và React. Nói chung, nó khá đơn giản, nhưng mà khi đọc thì thấy nó vui vui, kiểu như là JavaScript làm được mọi thứ vậy.\n\n**01:17:14** Next là một bài về chủ đề này. Nó hơi giống như commentary, nhưng mà em để bên này vì thấy nó cũng khá liên quan. Bài này bàn về trạng thái của ES5 trên web. ES5 giống như đợt trước em có nói, kiểu như CSS3 vậy, mấy cái công nghệ này tồn tại quá lâu rồi. Bài này khảo sát xem các thư viện, trang web trên internet liệu còn bao nhiêu trang web đang còn dùng ES5 hay đã move qua ES6 hết rồi. Tóm lại, kết luận là 89% của top 10.000 trang web hiện tại đã shift sang ES6 rồi.\n\n**01:17:55** Cho nên, kết luận ở đây là ES5 vẫn xài, nhưng mà khi làm một cái gì đó mới, nhất là khi làm thư viện mới, thì nói chung là không nên hướng tới ES5 nữa, vì nó cũng sắp lỗi thời rồi, nó đã quá lâu rồi. State of ES5 vẫn khá là liên quan.\n\n**01:18:44** Về phía trending, không có gì nhiều, nhưng có một bài này em thấy khá vui. Người ta đang có một cái open letter để kêu gọi thằng Oracle bỏ cái trademark của JavaScript. Em mới biết là JavaScript thuộc về trademark của Oracle. Khi nhắc tới Oracle, mọi người chỉ biết về Java thôi, gần như không có sản phẩm nào liên quan tới JavaScript, nhưng mà trademark của JavaScript lại thuộc về Oracle. Nên cái open letter này là kiểu mấy ông lớn trong giới developer yêu cầu Oracle thả cái trademark của JavaScript ra đi, đừng giữ nữa, vì Oracle không có đóng góp gì cho cộng đồng JavaScript.\n\n**01:19:22** Có rất nhiều người nổi tiếng đã ký vào bức thư này, những người creator của Node.js và JavaScript, kiểu rất nhiều người họ đã ký. Em cũng mới biết tới, nhưng mà thấy cũng hay hay.\n\n**01:20:16** Rồi tiếp theo, quay lại mấy cái framework và library mới, nhưng chắc phần này em sẽ skip vì không có gì đặc biệt. Có một cái bài commentary mà anh Thành gửi cho em, nó liên quan về cái sentiment của cộng đồng về React và JavaScript, đặc biệt là Next.js. Bài này khá dài, nhưng tóm lại ý chính của họ là các framework như Next.js càng ngày càng nặng.\n\n**01:20:55** Họ chỉ trích xu hướng hiện tại của cộng đồng engineer React là các front-end developers đang chạy theo các framework và library lạm dụng quá nhiều JavaScript. Điều này có lợi cho trải nghiệm của developer (DX), nhưng lại làm giảm trải nghiệm của người dùng (UX) vì phải ship quá nhiều JavaScript về phía client. Tóm lại là code thì sướng, nhưng sản phẩm cuối cùng thì người dùng lại không thích. Đặc biệt là họ chỉ đích danh thằng Next.js, nói rằng cần đẩy ngược các phần nặng về lại server để cải thiện trải nghiệm người dùng.\n\n**01:21:28** Cái sentiment này khá rõ ràng, họ đang kêu gọi mọi người chuyển ngược về server-side nhiều hơn. Em thấy bên front-end cứ đi vòng quanh vậy thôi, từ server chuyển xuống client, rồi từ client nặng quá lại kêu chuyển về server.\n\n**01:22:19** Nói chung là đó là mấy bài em thấy thú vị trong đợt tháng 9 vừa rồi. Drama thì cũng có chút thú vị, lôi kéo sự chú ý. Bên Go thì ổn định quá nên không có drama, thành ra không ai nói gì nhiều. Còn bên JavaScript thì cứ có drama suốt, từ server-side script, JavaScript modules, kiểu như drama quanh đi quẩn lại. Cộng đồng này lúc nào cũng vậy, không có biên chuẩn rõ ràng thì lúc nào cũng cãi nhau về chuyện đó.\n\nCảm ơn mọi người. Về phần reminder, các anh em tranh thủ làm bài test sớm nhé, để có thời gian xử lý kịp. Còn một số phần team lab cần xem lại, đặc biệt là báo cáo kết quả sau khi chuyển hết phần này, xem còn gì cần report không. Thành, chắc tụi mình sẽ wrap up ở đây và tập trung vào các case đã nói trước rồi, nhé.\n\n**01:23:30** Rồi, cảm ơn mọi người! Về phần reminder, các anh em tranh thủ làm bài test sớm nhé, để có thời gian xử lý kịp. Còn một số phần team lab cần xem lại, đặc biệt là báo cáo kết quả sau khi chuyển hết phần này, xem còn gì cần report không. Thành, chắc tụi mình sẽ wrap up ở đây và tập trung vào các case đã nói trước rồi, nhé.\n\n**01:24:04** Lập, xem lại giúp nhé. Cát có share một bài bên ngoài, bài đó mới post lên, dễ hiểu, mọi người thử xem nhé. Xu hướng hiện tại của mình sẽ kết thúc chu kỳ của mấy cái software không cần suy nghĩ nhiều, mà tập trung vào phần tooling nhiều hơn. Giờ mấy cái kỹ thuật cơ bản về toán và logic đang quay lại. Sắp tới, team lab sẽ report các chủ đề theo hướng logic nhiều hơn, để anh em nghe quen dần.\n\n**01:24:50** Tom hồi giữa tuần có dựng lại một cái library mới tên là WebUI sau khi cái library cũ bị shut down. Mọi người thử xem. Thằng này khá là legit, khi mình hỏi về chủ đề compile union của hai cái finite automata, nó trả lời toàn bộ theo công thức toán hết, nhìn rất dễ hiểu. Nó giải thích rõ ràng từng bước làm thế nào để tính union của hai hệ thống finite automata.\n\n**01:26:15** Đây, hai hệ rời, hệ chập lại điều kiện để tính toán điều kiện của hai cái dưới đây. Nó nói về chuyện state transitions, anh đang thử nghiệm một vài khái niệm về toán trên đây, và thấy khá là legit. Nếu được, khuyến khích anh em xài con này nhiều hơn. Con này, Tôm đã ngồi mod lại cái system của nó rồi. Ban đầu có thể sẽ nhìn hơi khó chịu một chút, vì mình đã quen nói chuyện bằng ngôn ngữ bình thường khi giải đề toán rất bình thường. Giờ mình phải step back lại một chút, để thấy rằng mấy kiến thức về khối A (toán học) giờ nó có giá trị. Full logic luôn. Rồi, advance như thế nào, practical implications là như thế nào, kỹ thuật làm như thế nào, đều có hết.\n\n**01:26:57** Thành thử ra, với những gì đang diễn ra, với các inquiry và commentary, anh ngồi dò, chắc chắn là thị trường sẽ chuyển qua hướng tài chính. Từ năm ngoái đến giờ, sau đợt blockchain và crypto, team mình hiện tại, đội của Huy Nguyễn vẫn đang tiếp tục, và đội đó vẫn rất ổn. Một số kỹ thuật mới hơn bên blockchain, như Monas hay gì đó, thì mình chưa xem, nhưng chắc cũng tương tự thôi, không có kỹ thuật nào khác biệt quá.\n\n**01:28:29** Về mảng tài chính, mình đang tích cực gần với các cycles về tài chính. Domain đó đang build up theo hướng này, và có vẻ như đây là một cửa rất sáng. Hướng này team mình cũng đang dần làm gần hết rồi, giờ chỉ còn lại là số lượng case study nhiều hay ít nữa thôi. Anh nghĩ vậy là hợp lý. Chất lượng đội ngũ cũng đang được cải thiện dần. Như bài lúc nãy đưa cho Minh, không nhớ là đã đưa cho Minh Lư chưa, nhưng Minh có xem được thì chắc cũng đã hiểu được tầm 6/10. Nhưng anh tin rằng nó vẫn hơn rất nhiều so với nhiều người khác. Mặc dù có sợ, nhưng không report lại được. Minh đã mở hai phần của finite state ra và giải thích rất legit.\n\n**01:29:12** Định hướng của team là theo hướng đó. Nếu khéo, thì chắc là hết tháng này, mình có thể đẩy thêm được nội dung về toán logic nhiều hơn một chút, cố gắng so sánh giữa những khái niệm cũ và những khái niệm mới mà mình đang biết, tương đương với nhau thôi. Biên lại, chỉnh lại cho phù hợp. Ok, không yêu cầu tất cả mọi người phải đi theo hướng đó, nhưng theo quan sát cơ bản, anh thấy thị trường đang dịch chuyển theo hướng đó. Để giữ giá trị khác biệt, mình chơi game theo cách khác chút. Đó là message để anh em aware.\n\n**01:29:58** Nếu không có gì khác thì còn một bài của anh Thành, chắc để sau. Còn lại, mọi thứ, thằng vừa rồi nếu mọi người chưa có access, thì xin chỗ Tom nhé. Hẹn gặp lại anh em tuần sau. Thứ Tư tuần sau sẽ không có buổi họp giữa tuần, mọi người ngồi và làm tiếp theo hướng mình vừa nói nhé. Content làm sao để anh em hiểu.\n\n**01:30:57** Ok, chắc là vậy nhé. Bye bye anh em, hẹn gặp lại anh em vào Thứ Sáu tuần sau. Thứ Tư tuần sau sẽ không có buổi nào ở giữa nữa. Mọi người dành thời gian xem thêm nội dung liên quan tới những gì cần để hoàn thành bài test nhé. Cảm ơn tất cả anh em. Bye bye, hẹn gặp lại.\n\n---\n\n**English transcript**\n\n**08:02** Is there any information that needs to be shared? If not, let's have Phát go first, I see a lot of topics today, so let's prioritize the new members. Ok, there are five topics today.\n\n**09:13** Please come forward. Whoever has a topic, please go early. Yes, Phát will start first, and then Thành’s part will follow. Nam, are you ready? Today, Nam will share a topic called \"UX Guide to Prompt with AI.\"\n\n**10:20** I’ll give an overview of the current situation first. Interaction between humans and AI is a popular topic today, and the emergence of Large Language Models (LLM) is a useful tool that our team is looking into. Today’s topic is for anyone interested in the User Experience (UX) of AI, specifically how tools are currently designed to improve the interaction between users and AI. Many tools and platforms are being developed today, but they mostly focus on improving prompt speed and accuracy instead of focusing on the user experience.\n\n**11:08** The concept of \"RACE\" (Role, Action, Context, Expectation) is quite common in prompting AI. Users need to prompt in this structure for AI to generate the most accurate output. However, not every case applies to \"RACE.\" Many companies have developed new methods to improve AI UX, helping make the interaction between users and AI smoother.\n\n**12:04** The first method is \"Context Through Rephrasing.\" This method helps AI query the context of the previous question to answer the next question coherently, without needing a perfectly structured prompt from the start. For example, if the first question is \"Who is the wife of Superman?\" and then you ask, \"When did they get married?\" AI will understand the context and connect the dots. But if there is no relevant context, such as asking, \"What day did the Titanic sink?\" AI won’t be able to provide the right answer.\n\n**12:50** Next is \"Implicit Referencing,\" for example, when asking about the number of floors in a building, AI might assume it's a famous building like the \"Willis Tower in Chicago.\" If you ask, \"What day?\" without proper context, AI cannot give an accurate answer. Questions must be tightly connected for AI to answer better, and this also applies to \"Context Through Rephrasing.\"\n\n**14:19** A similar concept is \"Continue Conversation,\" like in Google Assistant. Questions are naturally linked, and each new question relates to the previous ones to create a continuous conversation.\n\n**15:03** The next method is \"Racing and AI Scoring.\" Google Assistant also applies this method. It provides multiple options based on different contexts, helping users get better results. AI can also learn from user choices to improve interaction. For example, when AI is unclear about the context, it will give users options to choose from.\n\n**16:03** Lastly, there is \"System Prompting.\" This theory directs AI to operate based on the context and user-defined goals. It helps AI generate accurate output without following a fixed prompt standard. For example, when asking, \"Plan for releasing a software product\". ChatGPT may provide general concepts, while GPT mini will ask more detailed questions to help users continue prompting for more precise results.\n\n**17:45** Today’s discussion focuses on designing AI tools to improve user experience, not just in terms of speed or accuracy but also in terms of user interaction and overall experience.\n\n**18:50** To summarize this for everyone, especially designers, Nam's topic has two main aspects. First, it explains the structure of \"RACE\" and how to apply it. Second, it presents a framework for designing AI tools, focusing on how to prompt effectively to improve the interaction between AI and users. The RACE structure includes Role, Action, Context, and Expectation, and it helps enhance AI UX.\n\n**19:20** To explain briefly, R stands for Role, and there are different types of R’s that Nam mentioned earlier. For designers to understand the R structure, it's important to look at how to build an app focused on prompting and how this structure ties in. It involves introducing the R technique, a common technique Nam mentioned earlier, called RACE. When writing a RACE, you need to clearly state the Role, Action, Context, and Expectation.\n\n**20:03** RACE is described very clearly: what is Role, what is Action, everything is explained, including what Expectation is and what Task is. In summary, the most basic thing for designers is to understand the structure of a RACE prompt. It follows a specific structure, which produces standard results. The input follows that structure, and the output will provide corresponding results.\n\n**20:47** The second and final part of this presentation will discuss what to pay attention to when designing once you understand the structure of a prompt and how to prompt accurately. This part is open-ended because this is like a 101 guide for designers to look at and understand the basics.\n\n**21:30** Nam has talked quite a bit about the letter R, so some people might misunderstand that this topic is just explaining that concept in detail. But in fact, this presentation is introducing prompting to UX designers. Ok, any questions? This topic is quite basic; our team has used it a lot, and we’ve demoed it many times. There’s one point to note: this topic is special because it introduces system prompting, which other guides don’t cover.\n\n**22:31** This presentation introduces system prompting, which is usually not mentioned in other guides. Guides for end-users (end users) rarely mention this. This topic covers system prompting because it’s written from a designer’s perspective – someone who is part of the team building it. System prompting differs from regular prompting because it controls how AI operates based on the system's specific goals.\n\n**23:06** The structure of system prompting differs from the usual R's that people often see when reading research. Typically, you see discussions about 200 different types of R’s, but there is no perspective from someone building the app. This topic is for designers, not for end-users, but for those in-between to connect the different parts.\n\n**23:48** This is different from articles for engineers because it not only introduces the tools to build prompts but also discusses how to combine different R types. This is an intermediate-level topic, suitable for designers who play the intermediary role, not directly building but also not the end-users. It helps bridge these two parts together.\n\n**24:33** Ok, thanks, Nam. Next week, we will scope this topic again to make the content easier to understand for everyone. Going into detail might be a bit difficult for everyone to grasp. Thank you, Nam. Now, on to the next speaker. Let’s see if we can view the screen. Ah, it’s back.\n\n**25:41** My topic today is a small problem in programming techniques, which is how to compute the union of two finite automata, also known as finite state machines. I will demo it using Go source code. Today’s topic will have a few key points. First, I’ll explain the applications of automata for everyone to get an idea, then we’ll go into the details.\n\n**26:41** The most common application of finite state machines is that when you have a button and an input, you want to check whether the input matches or fails. It’s as simple as that. The most common example is using regex to check whether a piece of text is an email, a phone number, or a street number. We have a button like that, and we feed in a piece of text to check if it matches the condition.\n\nAside from regex, another common case is in event-driven systems, where we have event buttons. You define a button in the form of a state machine, and each event is a state. The event will go through the event button and get filtered to see if it matches that event. If it matches, it moves on to the next state for further processing; otherwise, it fails and doesn’t go through.\n\n**27:27** Here’s an example: Suppose we have an event bus, and all the events pass through this event bus and get filtered through the rules. If an event satisfies the rule, it proceeds for further processing. This is most commonly seen in modern cloud systems, where they use a lot of these systems to manage events and filter them through rules like this. You can see this in large systems like Amazon, where their events pass through a series of rules.\n\n**28:05** For example, suppose we have a button, and all items with a field \"image\" that contains an object with a width of 800 will pass through. And we can also add a few more rules for different fields that we add to that button. This is an example of how finite state machines and event buttons work. When an event enters the system, it passes through rules, and if the conditions are met, it will pass through to the next processing steps.\n\n**28:56** This is a specific example of Amazon’s event system, where their events pass through a series of rules to be filtered and processed. Most cloud systems today use similar button patterns to manage and process events in an organized and efficient way.\n\n**29:37** In practice, let's go back a bit to finite automata (f automata) in mathematical terms, what it is. In essence, it's simply a machine with a set of states. To move from one state to the next, it needs to go through a transition. For example, to go from the start state to the end state, there will always need to be a start point called the start state and an endpoint called the end state. That’s why it’s called a finite state machine because it always has a start and an end.\n\n**30:21** In between, there will be a set of transitions and states to move from the start point to the end point. An input symbol is what you feed into a state to move it to another state, and in practice, the input symbol is often a character. We’ll talk more about this in detail later. The accepting state is the state where if the input is accepted, it moves to another state through a transition. If it’s not accepted, it doesn’t go anywhere, as if the transition doesn’t lead to any state.\n\n**31:04** There are two types of finite automata, deterministic finite automata (DFA) and nondeterministic finite automata (NFA). The only difference is that with DFA, each state has a single input symbol leading to a transition to another state. With NFA, there can be multiple transitions for the same state, and there may even be no transitions at all. This difference is just about how the path from the start to the end is represented, but both finite state machines can be expressed as either DFA or NFA. It’s just a matter of representation.\n\n**31:51** Regarding the union of two finite automata, it’s the combination of all the states and transitions of the two finite automata. Its feature is that if event A passes through finite automaton FA1 and event B passes through finite automaton FA2, the union of these two must ensure that both event A and event B pass through.\n\n**32:45** Why do we need to compute the union of two finite automata? In practice, for example, when using an event button, we don’t use just one button, we use multiple buttons combined. For example, in the diagram, we can define many buttons, and in our event, we may have multiple pieces of information that match these buttons. When we want to combine these buttons, we need to compute the union of all of them.\n\n**33:24** But we don’t compute them all at once; we compute them one at a time, for example, first with pairs A and B, then take the union of A and B and compute it with pair C. We just need to compute two buttons at a time—this is the most basic level of calculating the union of all these buttons.\n\n**34:07** To compute the union of two finite automata, theoretically, we would have to calculate all the states and transitions of both automata. For example, if we have two buttons, A and B, and each button has many states, such as from A1 to Ax and from B1 to Bx. Theoretically, we would have to calculate all combinations of these two buttons, like A1-B1, A2-B2, A1-B2, A2-B1—there are many combinations.\n\n34:07 In practice, we only care about whether, when feeding an event into the button, we want to know if it matches or not. We only care if, after feeding the event into the button, it can reach the final state or not. Calculating all the states in the union would be wasteful and unnecessary. Therefore, the practical approach is to have two finite automata with states from A1 to Ax and from B1 to Bx. When calculating their union, we check if the state leads to any transition in A or B. If not, we skip it.\n\n**35:40** For example, if the state only leads to A1 and there’s no transition leading to B, then we only calculate the branch for A and skip B. Similarly, we do the same for B. The last case is if A1 moves to Ax and B1 also moves to Bx, then we create a new state, Ax-Bx. At this point, we recursively start again and continue calculating from this first step. For example, we have A1-B1, and then we have A2-B2, so we repeat these four steps to continue calculating.\n\n**36:15** This way, the number of states we can skip and not calculate or store is significantly reduced compared to the theoretical method mentioned earlier.\n\nRegarding input symbols, like in the event button or regex examples, in practice, the buttons and inputs we feed into the program are always in the form of characters. Characters here are often those.\n\n**37:04** Characters in UTF-8, which are simple characters like from a to z or from 0 to 9. They fit into UTF-8, which includes 244 characters. Although UTF-8 uses 8 bits (2^8 - 1 = 256), the bits from 245 to 255 are left over, so we don’t use them, just the first 244 bits. Now, here’s the implementation detail in the code. This is the basic workflow we’ll follow. Not sure if it can be zoomed in? Try zooming in on the diagram from earlier, the text isn't visible. Wait a moment, let’s check again.\n\n**38:21** Alright, what is FA? Finite automata? Yes, automata. This function will merge two automata together. First, it creates a key to mark the states that have already been processed so that we don’t have to revisit them. Then, it checks this key, and if it’s not a duplicate, it starts working. It creates an empty combined state that includes all the transitions of the two finite automata. Then it continues merging each finite automaton, one by one. Scroll up, I couldn’t read that part in time.\n\n**39:33** During implementation, there will be some points where we need to modify the data structure to store those states. Which example is your topic based on? Which sample is this diagram running? Let me show the code; it’ll be easier to see. You have to look at the problem to know which code we're dealing with. After this example, we’ll have more questions. But this topic only needs Phúc and Tuấn to understand, does everyone understand the code clearly?\n\n**40:13** The earlier example about the event button, here we define a button, for example. The button I defined is in the form of T, and here’s the event. When we run this code, it’s just part of the logic; there are more parts of the code. But when running that, the expected result is that it will check if this event matches this button. It will return whether the event matches the button or not.\n\n**41:13** That’s right, that’s the problem this code is solving. This is simple code; it will run and return results, just checking if it matches this button or not. For example, here, this button has a transition with \"user_register,\" for instance. If I change something else, it won’t match. But if the event meets the condition, it will match, something like that.\n\n**42:09** I’ll go straight to the main logic. It’s the function to merge two finite state machines together. Each of these finite automata represents a button. Imagine we have multiple buttons. Here we only have one button, but imagine I split this into two buttons. My function is responsible for merging those two buttons into one total button.\n\n**43:31** As mentioned earlier, to avoid too much calculation, I’ll first explain the parameters passed into the function. The two FAState are two structures representing the two buttons we had earlier. Each structure includes a small table to represent a series of input symbols and their corresponding transitions. Epsilon is the state that returns to its own position, we’ll skip that for now. Here, we only care about these two states. The smallest unit we want to use as input is the file because a character is represented in UTF-8 and includes 244 bits. Now, we’ll loop through each bit in these characters to compare.\n\n**44:20** For example, in this case, when I input an event, after computing these two buttons, it starts from each character. For example, it starts with a bracket and checks if there’s any transition to \"user.\" If there isn’t, it skips the ID part because it doesn’t match. This part goes into the details of comparing each character.\n\n**45:02** Skip this part. Just look at the benefits and the idea behind the implementation; there’s no need to compare in detail here. The benefit of this method is simple: it helps the algorithm avoid recalculating too many times. The algorithm is quite simple, it’s just comparing, as we analyzed earlier. If a character doesn’t lead to a transition, we skip it. Or if it only leads to one branch, and that branch doesn’t have any transitions, we skip it as well.\n\n**46:34** For example, if state A1 moves to state B, but state B doesn’t exist, we skip that branch. Conversely, if that state already exists in the map, we skip it. Only when all conditions are met do we start calculating and loop through each state in the finite automata. After looping through each step with the corresponding state in B, we get the final state and assign it, then return the result.\n\n**47:17** Does everyone understand? Ask Minh. Minh, check this out. I told Minh to send the link. Did you all understand this? The important thing is to review the first diagram because I’m afraid people don’t understand it. This diagram was a long time ago, more than a month ago, right? Yes, this diagram, does everyone understand?\n\n**49:11** Systems like Amazon’s event bus need to merge sometimes up to millions of buttons, so there will be some details in the implementation to speed up these tasks. Switch to another diagram, the next one, the one that branches into two; use that to explain better. The branching diagram, which one should we use? Let’s stick with this diagram, do the others understand?\n\n**50:11** Let’s explain it clearly so that everyone gets it. Hoàng, do you understand? Do you get what this is doing? Ah, Phúc asked if it uses a bit operator. Not yet, it hasn’t reached that level, it’s just detailed comparisons, unrelated to that part. Tuấn, Minh, where’s Vincent? Does everyone understand this topic? No? This topic is nested in three layers from what Minh discussed earlier. Let’s clear a few things to make it less confusing for everyone.\n\n**51:03** First, finite automata, or state machines, are like state transition diagrams that you often draw. Remember? They have states and nodes representing those states. Second, there are conditions (input symbols) that allow you to move from one state to another, called transitions. Read it carefully to understand and remember it better. It’s like a state transition diagram; that’s the first point.\n\n**51:47** The second point is the two types of finite automata that Minh just showed. Why show these two types? Because some states are simple, they only move in one direction and can’t reverse. For example, lunchtime. When you walk out to Hà Đô to eat pho, you can walk to the pho restaurant, eat, and return. That completes a finite state; it doesn’t reverse, that’s a finite automaton.\n\n**53:10** Another example is a new finite automaton where you go to the supermarket to buy lunch, pay, and return. It’s still a finite automaton, but it has different states than the previous one.\n\n**53:57** The issue is how to calculate the union of these two finite automata. Let’s say there are two states: one where you eat pho, and the other where you go to the supermarket to buy lunch. We need to build a union of these two states, like how Minh talked about merging two state machines. Here, we have two choices: one is to eat pho, and the other is to go to the supermarket. The idea is to compute all possible combinations of these two state systems.\n\n**54:30** We calculate their union by simply combining them. In the earlier example, how many options do we have? One person goes to eat pho, and the other goes to the supermarket, right? This example is also calculating the union, but it’s a different kind of union. The problem is that there are two finite automata (FA), and we need to compute their union. Then we check how to combine them. There are two parts: one part follows the original flow—eating pho, and the other part follows the supermarket flow. Another case is when you combine two sets of conditions, which will generate a new set. At that point, we have to continue calculating and computing more.\n\n**55:17** The basic idea of creating a union of multiple finite automata is like that. It’s similar to what Minh showed earlier—Minh showed the source code. Now, let’s go back to that function. Alright, here, Minh’s function has a method to merge all the states. This means we simulate having two state systems only, right? From two different finite automata. Then we merge them into a unified system, which gives us a big table. From that big table, we continue to calculate based on each condition.\n\n**56:04** Now, we’ve built the big table—a large array that contains the complete list of conditions. Now, we’ll start calculating. When a new condition is input, it begins by checking all the conditions of the first system. If it doesn’t match, it checks all the conditions of the second system. If it still doesn’t match, it checks the conditions of the union of the two systems. The basic calculation logic is just like that.\n\n**57:02** The difficulty of this problem, if you feel a bit confused, lies in the process of modeling from mathematics into programming. Do you get it, Tư? Lucky, did you grasp it? Ok, follow the problem. Show the function and the diagram from earlier. This diagram explains why regular expressions mention this. When you check in square brackets in regular expressions, you need to go through all the conditions inside. Because there are so many options, each option is modeled mathematically to make it easier to handle. Each condition is a finite automaton, and we compute the union of these conditions.\n\n**58:38** Modeling mathematical logic into programming is the process of calculating with different systems. We need to calculate the union condition of systems 1, 2, 3, 4... If none of the conditions are met, we have to calculate the intersection of each pair of conditions. This problem is like that. If you want to learn more, this is an important topic because it helps you understand how we operate in large logic systems.\n\n**59:21** I think I gave this to Minh earlier. This is important because it relates to creating logic addition functions. A common comparison is login authentication, like in the login process, which relates to this problem. During the login process, there are many conditions, for example, passing 2FA, email, SMS, or password. Each of these can be modeled into its own finite automaton, and when we compute them, we combine them all.\n\n**0 1:00:00** For example, there might be a requirement for the user to have both face scan and QR code to log in. That’s a combined condition (intersection), not just a simple if statement. In mathematical modeling, we can handle this easily because it has recursive properties to compute complex logic combinations. The most important thing is how to calculate this combination without recalculating many times. The output will either be success or failure. But for junior developers, when adding a new case without the modeling mindset, they’ll end up creating many messy if statements, making it hard to maintain the code.\n\n**01:01:29** When adding a new feature without a modeling mindset, the code becomes messy and inefficient. They’ll have to rewrite it many times, causing many bugs and wasting time fixing and testing. That’s why this problem is important, as it impacts system design, especially in systems like login authentication, where combining multiple conditions is common.\n\n**01:02:23** Any more questions? No? Minh, do you understand it all? Ok, looks like we’re out of time. Thành, are there any more topics? There are two more, but let’s try to wrap them up quickly. Let me check. Can everyone see the screen? Ok, this week, I only have two topics, there’s another one, but it’s too long, we’ll do it next week. That one requires more detail in terms of usage.\n\n**01:03:36** The next topic is about Go and how to embed files. What is Go embed? It allows us to embed a file directly into the binary. This helps reduce the need to handle external files. The way it works is that when we embed a file into the binary, the handling process becomes simpler. But there’s a limitation: if the file is too large, the binary will expand. So, be careful when using this.\n\n**01:04:15** The usage is like this: we just import it and use it as usual. For example, we have a message file, we embed that file into the binary, and then we can access that file directly. For multiple files, we can add additional characters like this. Then, we use the embedded variable to read or access it like a normal file. Or we can even embed an entire directory.\n\n**01:04:57** Usually, we want to embed static files like images, HTML, or something like that. As for the limitation I mentioned earlier, the second topic is about reflecting a package. This topic is not new. It’s not really new if you’ve used Go and read the article by Dr. R. I’ll go over it quickly. The context is that the author encountered a problem with reflection while using a tool or codebase and wrote this article. In general, reflection has three key points to note.\n\n**01:05:49** The three important points are: from interface value to reflection object, and vice versa. The final point is when you want to modify the values, they need to be settable, meaning they need to be exported, or written with a capitalized value. What is an interface value? What is a reflection object? The interface value is, in every function we use in the reflect package, it’s always understood as a wide interface{}, so it’s an interface value. And this value is a reflection object, and vice versa.\n\n**01:06:36** As for the direction: ValueOf returns a reflection object. In the opposite direction, from here, we can use the method .Interface() to return the original value. In Go, this is now default. If you want to update something, you need to find something settable. Reflect has this method for you to use and update.\n\n**01:07:12** Another point mentioned in that article is to avoid using reflect unless absolutely necessary. If you use functions like FieldByName, if the input is not well-controlled, it can lead to panic or crashes immediately. So, only use it when absolutely necessary, in cases where there’s no other option.\n\n**01:07:53** There’s another article that I mentioned that’s quite long, about map. It compares using regular maps with the need to support concurrency, where you’ll need a locking strategy. You can use mutex or something else, or some other lock. The sync package provides a sync.Map. The article compares these two approaches. There’s no better option; it depends on the use case.\n\n**01:08:35** Now, let’s move on to the next part. Phát, simple stuff. Minh Trần is asking about the logic of three automata and then adding two more automata. But Minh Trần is misunderstanding the order. The order will follow different logic. Why did Huy mention automata systems in Vietnam? Because previously, they approached it from the perspective of industrial machines, automated systems. They couldn’t build them to interact with each other or run automatically because the cost of trial and error was too high.\n\n**01:09:31** So, to ensure effectiveness, they had to calculate the logic first to see if it covered all cases. For example, when there are three systems, and you add two more, making five systems. First, you have to see if the logic design overlaps. Then, we list out the logic trees and calculate. That’s the first step, then we proceed with implementation.\n\n**01:10:09** As for implementation, it depends on how you want to do it: you can union the systems or create an addition function. The important thing is that before you do anything, you must ensure the logic covers all the cases. Logic here is not just about going from A to B; it’s a general logic system, including calculations on logic trees.\n\n**01:10:50** Union in this article talks about mathematical logic a bit. When it comes to implementation, if you’ve done it before, you’ll find it easy to create an addition function. Just understand that in union logic, we combine conditions and calculate. After combining those conditions, the question is how the addition function performs. Usually, people try to explicitly go step by step.\n\n**01:11:53** Ok, seems good now. Thành, is there anything else? Ok, got it, DevOps team will handle the rest. Try it again and see if there’s any issue. Everyone, please do your tests early. We’ve got a financial and AI deal this time, so pay attention.\n\n**01:13:04** Now, I’ll move on. In September, there weren’t many notable updates. I’ll go over it quickly. First, about React, with keywords like server actions, server functions, and React compiler. There’s an article on freeCodeCamp about React 19’s architecture, detailing how to optimize performance. If you have time, you should read that article.\n\n**01:15:12** Regarding Next.js, nothing much new. There was some noise at the beginning of the month when OpenAI switched from Next.js to Remix. In short, OpenAI wanted their page to be lighter because Next.js was a bit heavy for a chatbox SPA (Single Page Application). So, they decided to switch back to Remix. This relates to a trend I’m noticing in the engineer community: frameworks like Next.js are becoming less favored.\n\n**01:16:28** The goal of OpenNext is to make it so that people can host Next.js on any environment, no longer being restricted by Vercel’s exclusivity. So, this project is here to solve that problem. Moving on, I see two interesting things being featured. There’s someone implementing a simple real-time system using TypeScript and React. It’s pretty simple, but reading it makes you smile, like JavaScript can do everything.\n\n**01:17:14** Next is a piece about this topic, which is kind of like commentary, but I’m putting it here because it’s still relevant. This article discusses the state of ES5 on the web. ES5 is like what I mentioned before, like CSS3, technologies that have been around for too long. This article surveys how many websites on the internet are still using ES5 or if they’ve moved on to ES6. In short, the conclusion is that 89% of the top 10,000 websites have already shifted to ES6.\n\n**01:17:55** So, the takeaway here is that ES5 is still in use, but when building something new, especially when building a new library, generally, you shouldn’t aim for ES5 anymore because it’s almost outdated; it’s been around for too long. The state of ES5 is still somewhat relevant.\n\n**01:18:44** Regarding trending topics, there’s not much, but there is an amusing one. There’s an open letter asking Oracle to give up the JavaScript trademark. I just found out that JavaScript belongs to Oracle's trademark. When people think of Oracle, they only know Java, and almost no product relates to JavaScript. But the trademark for JavaScript is owned by Oracle. So this open letter is basically developers asking Oracle to release the JavaScript trademark, not hold onto it anymore, because Oracle hasn’t contributed anything to the JavaScript community.\n\n**01:19:22** Many big names have signed the letter, including the creators of Node.js and JavaScript, many well-known people have signed it. I just found out, but it seems interesting.\n\n**01:20:16** Moving on to new frameworks and libraries, but I’ll probably skip this part because there’s nothing special. There’s a commentary from Thành, relating to the sentiment in the React and JavaScript community, especially around Next.js. The article is quite long, but to sum it up, the main point is that frameworks like Next.js are getting heavier.\n\n**01:20:55** They criticize the current trend in the React engineer community: front-end developers are chasing after frameworks and libraries that overuse JavaScript. This benefits the developer experience (DX), but it reduces the user experience (UX) because too much JavaScript is being shipped to the client. In short, writing code is fun, but the final product doesn’t make the user happy. They specifically mention Next.js, saying that the heavy parts need to be pushed back to the server to improve the user experience.\n\n**01:21:28** This sentiment is quite clear; they’re calling for a shift back to more server-side solutions. I feel like the front-end community keeps going in circles: moving from the server to the client, and now the client is too heavy, so they’re calling to move back to the server.\n\n**01:22:19** In general, those are the interesting topics I found in September. Drama is always interesting; it grabs attention. In Go, everything is stable, so there’s no drama, which is why no one talks much. But in JavaScript, there’s always drama, from server-side scripts to JavaScript modules, the drama just keeps coming back around. The community is always like this; without clear standards, people are always arguing.\n\n**01:23:30** Thanks, everyone. Regarding the reminder, please do your tests early so there’s time to handle everything. The team lab still has some work to review, especially the reports after everything is transferred over. Thành, I think we’ll wrap up here and focus on the cases we mentioned earlier.\n\n**01:24:04** Lập, please review. Cát shared an article outside, it’s new, easy to understand, everyone take a look. The current trend seems to be ending the cycle of software that doesn’t require much thought, focusing more on tooling. Now, basic techniques in math and logic are making a return. In the future, the lab team will report more on topics in logic, so everyone gets used to it.\n\n**01:24:50** Tom rebuilt a new library called WebUI after the old one was shut down. Everyone take a look. This one is quite legit. When you ask it about the union of two finite automata, it responds with everything in mathematical formulas, very easy to understand. It explains clearly how to compute the union of two finite automata systems.\n\n**01:26:15** Here, the two systems combine conditions to calculate. It talks about state transitions, I’m testing a few mathematical concepts on it, and it seems quite legit. If possible, I encourage everyone to use this more. Tom has already modified its system. Initially, it might seem a bit uncomfortable because we’ve been used to using normal language to talk about these problems for so long. Now, we have to step back a little, and see that knowledge in math is valuable now. Full logic. Then, how to advance, practical implications, how to implement it—everything is there.\n\n**01:26:57** Given what’s happening with the inquiries and commentary, I’ve been checking, and I’m certain the market is shifting toward finance. Since last year, after the blockchain and crypto wave, our team, Huy Nguyễn’s team, is still moving forward, and that team is still doing well. Some newer techniques in blockchain, like Monas or something, we haven’t looked at yet, but it’s probably similar, no major technical differences.\n\n**01:28:29** In finance, we’re actively working with the financial cycles. That domain is building up this way, and it seems like a bright opportunity. Our team is also almost done with this, now it’s just a matter of how many case studies there are. I think this direction is reasonable. The team’s quality is gradually improving. Like the material I gave to Minh earlier, I can’t remember if I gave it to Minh Lư yet, but if Minh has seen it, he should understand about 6/10. But I believe it’s still much better than many others. Even though there might be fear, he didn’t report back. Minh opened two parts of the finite state machine and explained them very well.\n\n**01:29:12** The team’s direction is to follow this path. If done skillfully, by the end of this month, we could push more content about math and logic. We’ll try to compare old concepts with new ones we already know. Let’s refine and adjust. Ok, it’s not required that everyone follow this path, but based on basic observation, I see the market is shifting in that direction. To keep our value distinct, we have to play a different game. Consider this as a message for everyone to be aware.\n\n**01:29:58** If there’s nothing else, there’s one more article from Thành, but we’ll leave it for later. As for the rest, if anyone doesn’t have access to the thing from earlier, ask Tom. See you next week. Next Wednesday, there won’t be a mid-week meeting, everyone sit and continue along the direction we just discussed. Let’s work on the content so that everyone can understand.\n\n**01:30:57** Ok, I think that’s it. Bye-bye, everyone, see you next Friday. Next Wednesday, there won’t be a mid-week meeting. Everyone take time to review the content related to what needs to be done for the test. Thanks, everyone. Bye-bye, see you.\n","title":"OGIF Office Hours #27 - Go Weekly, Frontend Report Sep, UX Guide to Prompt with AI, Computing the Union of Two Finite Automata","short_title":"#27 Go weekly, Frontend, AI UX, Finite Automata","description":"In OGIF office hour 27, covering presentations on UX Guide to Prompt with AI, computing the union of finite automata, and other topics including Go Weekly and Frontend Report for September.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Mon Oct 14 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/27-20241011.md","slugArray":["updates","ogif","27-20241011"]},{"content":"\n**Topic Highlights**\n\n- **Go Weekly #16**: Phat discussed concurrent data structures in Go, focusing on `sync.Map`. He explored its structure, use cases, and performance trade-offs in high-read, low-write scenarios. He also touched on garbage collection issues reported by the Go team.\n- **Generative AI UX Design Patterns**: Nam presented on UX design patterns for AI integration, covering System Scope Relationship, Spatial Relationship, and Functional Relationship. He explained how AI can be incorporated at various levels in digital products and discussed different ways to present AI features in user interfaces.\n- **Yelp Usecase AI**: Dat presented real-world AI use cases from Yelp, explaining how AI is used for recommendation systems, text editing, and image summarization. He explored AI applications in generating datasets, spam detection, and auto-generating short video reviews for restaurants.\n- **LLM Pattern**: Hoang introduced design patterns for integrating LLMs (Large Language Models) into applications. Key patterns included in-context learning, data preprocessing, and multi-agent collaboration, highlighting their practical use in AI-powered systems.\n- **Dify Git Analyze**: Cat demonstrated a Git repository analysis tool built using Dify. The tool scrapes content from repositories and supports diagram generation for code structure analysis, with a focus on optimizing the knowledge retrieval process in large datasets\n\n---\n\n**Vietnamese Transcript**\n\n**0:28** Chủ đề hôm nay vẫn có Go Weekly, và Nam đang thử nghiệm phần commentary về thiết kế hàng tuần. Chúng ta sẽ theo dõi trong vài tuần tới xem nội dung như thế nào.\n\n**11:19** Nam sẽ trình bày tiếp cho anh em, và sau đó sẽ có một vài bài của Hoàng, Cát, Đạt. Chúng ta đang nghiên cứu về các trường hợp sử dụng mà các công ty khác đang áp dụng, hoặc các công cụ mà dev đang sử dụng, và có thể sẽ mở một bài chia sẻ trong tuần này hoặc tuần sau. Bài hôm nay sẽ xoay quanh việc tạo một nút thiết kế UX. Trước đây, có rất nhiều câu hỏi về phạm vi mà AI đang áp dụng và vai trò của nó sẽ như thế nào – liệu nó chỉ đóng góp như một thành phần nhỏ riêng lẻ hay là cả một ứng dụng trong các sản phẩm số. Hôm nay, em sẽ giải đáp thắc mắc đó, tức là AI đang đóng vai trò như thế nào và cách thức hoạt động của nó ra sao.\n\n**12:11** Đầu tiên, em sẽ nói về \"System Scope Relationship.\" Hình ảnh này sẽ mô tả AI được tích hợp vào các hệ thống ở nhiều cấp độ khác nhau, từ một thành phần nhỏ lẻ đến một hệ sinh thái toàn diện hơn. AI có thể chỉ là một phần nhỏ trong một thành phần hoặc có thể phát triển thành các tính năng lớn hơn, giúp tự động hóa nhiều chức năng. Điều này sẽ giúp người dùng trải nghiệm ứng dụng dễ dàng hơn. AI có thể đóng vai trò trong bất kỳ phần nào của sản phẩm số – từ thành phần, luồng xử lý, tính năng cho đến toàn bộ ứng dụng, hoặc thậm chí là một nền tảng hoặc hệ sinh thái.\n\n**12:53** Ví dụ, trong một ứng dụng, AI có thể đóng vai trò một tính năng nhỏ, giúp người dùng thao tác nhanh hơn thay vì phải làm thủ công. Hoặc AI có thể là toàn bộ một ứng dụng như ChatGPT, nơi toàn bộ ứng dụng được xây dựng trên nền tảng AI, phục vụ cho một mục đích nhất định. Hoặc AI có thể là một nền tảng như Rewind AI, với nhiều tính năng hỗ trợ AI cho nhiều công việc khác nhau trong cùng một ứng dụng. Đây là phạm vi của AI trong các sản phẩm hiện nay.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/s7doIOUDGgA?si=nx8a1rNN4wSuuPBo&amp;start=688\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**13:39** Tiếp theo, về \"Spatial Relationship,\" phần này giúp chúng ta hiểu về cách tính năng AI được bố trí và sắp xếp trong giao diện người dùng (UI). Có nhiều cách để tích hợp AI vào thiết kế, và quan trọng là làm sao để bố trí chúng sao cho hợp lý, tối ưu trải nghiệm người dùng mà không gây rối mắt hay phức tạp giao diện. Spatial Relationship ảnh hưởng trực tiếp đến trải nghiệm người dùng. Ví dụ, AI có thể hoạt động độc lập hoặc song song với các tính năng khác, nhưng vẫn giữ không gian riêng của mình. Khi hiểu được các mối quan hệ này, chúng ta có thể chọn cách sử dụng và sắp xếp tính năng AI một cách tối ưu, không gây phân tâm cho người dùng.\n\n**15:11** Có sáu cách để trình bày tính năng AI, bao gồm:\n\n1. **Separate**: AI hoạt động độc lập.\n2. **Alongside**: AI được đặt bên cạnh các tính năng khác.\n3. **Layer**: AI hoạt động dưới dạng lớp phủ.\n4. **Integrated Parent**: AI đóng vai trò chính trong điều hướng hoặc quản lý nội dung chính.\n5. **Integrated Child**: AI đóng vai trò nhỏ hơn, bổ trợ cho tính năng chính.\n6. **Point**: AI chỉ xuất hiện như một biểu tượng nhỏ, giúp người dùng hiểu thêm về cách nó hoạt động.\n\n**16:41** Tiếp theo là \"Functional Relationship,\" phần này mô tả các mối quan hệ chức năng giữa AI và các tính năng khác trong hệ thống. AI có thể tồn tại độc lập nhưng vẫn adapt (thích nghi) với các nội dung và tính năng của hệ thống ở mức cao hơn. AI có thể tích hợp với các tính năng hiện có để cải thiện hiệu suất, thay vì người dùng phải thao tác thủ công. Khi hiểu rõ cách hoạt động chức năng của AI, chúng ta sẽ xác định rõ vai trò của nó trong ứng dụng và thiết kế để các hành động chức năng của nó không bị xung đột, cũng như không làm gián đoạn luồng sử dụng của người dùng.\n\n**17:28** Có sáu cách để mô tả mối quan hệ chức năng của AI:\n\n1. **Separate**: AI hoạt động riêng biệt.\n2. **Aware Of**: AI tách biệt nhưng có khả năng nhận biết các thay đổi trong tính năng chính.\n3. **Acting Up**: AI tương tác qua lại giữa các tính năng.\n4. **Feature Incorporate**: AI được tích hợp như một phần của một tính năng hiện có.\n5. **Usage**: AI được sử dụng theo cách mà nó tương tác với các phần khác trong ứng dụng.\n6. **Usage Conventionally**: AI tương tác hai chiều với các tính năng khác một cách trực tiếp.\n\n**18:14** Nó sẽ không ảnh hưởng trực tiếp đến tính năng chính, nhưng nó sẽ có tác động qua lại với AI và từ đó giúp cải thiện tính năng chính. Đây là một ví dụ cụ thể hơn về cách sử dụng của nó, chẳng hạn như trong code này có thể generate một panel bên phải.\n\nTiếp theo là **Acting Up**, nghĩa là hai bên sẽ có tác động qua lại, có thể trao đổi dữ liệu qua lại với nhau. Ví dụ, tính năng A có thể hiểu được dữ liệu từ tính năng B và ngược lại. Các dữ liệu này sẽ được trao đổi qua lại liên tục để cải thiện sự tương tác.\n\nTiếp theo là **Feature Incorporate**, nghĩa là AI được tích hợp trực tiếp vào các tính năng hiện có của ứng dụng. Cuối cùng là **Usage Conventionally**, nghĩa là AI sẽ tương tác theo cách thông thường với các tính năng khác, giống như cách các ứng dụng truyền thống hoạt động.\n\nVí dụ như khi bạn dùng một ứng dụng và có nhiều tính năng khác nhau, AI sẽ đóng vai trò trong các phần như feature, nhưng không phải lúc nào cũng là phần chính, mà sẽ đóng vai trò bổ trợ.\n\n**19:06** Ví dụ khác là ứng dụng Quora hay các ứng dụng khác, AI sẽ có nhiều tính năng nhỏ được tích hợp vào, như kiểu gợi ý trả lời câu hỏi, giúp người dùng thực hiện các tác vụ dễ dàng hơn. Vậy là nãy giờ em đã đi qua ba phần chính:\n\n1. **System Scope**: Giới thiệu cách AI tích hợp vào sản phẩm.\n2. **Spatial Relationship**: Giới thiệu cách sắp xếp AI trong giao diện người dùng.\n3. **Functional Relationship**: Giới thiệu các mối quan hệ chức năng giữa AI và các tính năng khác.\n\nNhững phần này giúp tối ưu hóa sản phẩm, cải thiện trải nghiệm người dùng và nâng cao hiệu quả cho ứng dụng AI.\n\n**19:57** Điều này rất quan trọng bởi vì nếu mình hiểu rõ cách áp dụng AI, tính năng mình làm sẽ mang lại nhiều giá trị hơn cho người dùng. Ví dụ mà em quên chưa nhắc đến là phần \"separate.\" Em đã đưa ra một số ví dụ, nhưng để quay lại một chút về \"separate\" – tính năng AI hoạt động độc lập. Mình có thể xem xét trường hợp Microsoft có một cái slider để generate hình ảnh song song với tính năng khác. Hoặc với một ứng dụng như Shopee, AI sẽ đóng vai trò hỗ trợ bên cạnh tính năng chính của ứng dụng.\n\n**20:53** Đó là những ví dụ minh họa cho việc sắp xếp và bố trí AI trong giao diện và sản phẩm. Anh Thành có thấy phần này như thế nào? Em thấy nó giống với các patterns thông thường trong thiết kế.\n\n**22:01** Anh Thành: Đúng rồi, những cái này là các mẫu patterns mình hay dùng trong việc thiết kế ứng dụng AI, hoặc khi tích hợp AI vào một ứng dụng hoặc sản phẩm riêng biệt. Về cơ bản, nó là những cấu trúc quen thuộc để mình hiểu rõ hơn về cách áp dụng AI. Em có thể phân loại, chia nhỏ chúng ra thành những tính năng nhỏ hơn. Phần này rất rõ ràng.\n\n**23:31** Cảm ơn Nam. Ok, tiếp theo là bài của Hoàng và Đạt nhé.\n\nHôm nay, em sẽ giới thiệu một bài gọi là \"AI Button trong các ứng dụng LLM.\" Trước khi vào bài, em sẽ nói qua về nội dung và agenda. Đầu tiên là chúng ta sẽ tìm hiểu về các design patterns liên quan đến AI Button. Những cái pattern này được áp dụng trong nhiều ứng dụng khác nhau. Em sẽ lấy ra những cái phổ biến và dễ hiểu nhất để giới thiệu cho mọi người.\n\n**24:35** Bài này sẽ xoay quanh việc sử dụng ứng dụng AI trong các sản phẩm số. Ứng dụng này tận dụng sức mạnh của các mô hình AI để giải quyết các bài toán cụ thể hoặc hỗ trợ người dùng trong các tác vụ. Khi sử dụng LLM, nhiều người có thể gặp vấn đề là mô hình không đưa ra đúng kết quả như mong đợi. Điều này là do bản chất của các mô hình này chỉ dựa trên khả năng phản hồi dựa trên chuỗi dữ liệu. Có nhiều cách để giải quyết vấn đề này. Một trong những cách tốn kém nhất là phải điều chỉnh lại toàn bộ mô hình từ đầu. Điều này có thể mất nhiều thời gian và nguồn lực.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/s7doIOUDGgA?si=Jrnm_7QXsbImTctp&amp;start=1435\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**25:15** Mình có một cách gọi là **in-context learning**, có nghĩa là AI có thể học trực tiếp ngay trong ngữ cảnh hiện tại khi bạn đang sử dụng nó. Đây là một kỹ thuật như là few-shot learning hoặc zero-shot learning, giúp AI tự học mà không cần phải được huấn luyện lại từ đầu. Ví dụ, bạn chỉ cần cho AI một vài ví dụ nhỏ trong ngữ cảnh và nó sẽ tự điều chỉnh cách hoạt động của mình dựa trên những gì được cung cấp. Thay vì phải retrain toàn bộ mô hình, cách này giúp tiết kiệm thời gian và tài nguyên rất nhiều, và nó vẫn đảm bảo AI có thể học từ ngữ cảnh cụ thể mà bạn cung cấp.\n\n**25:52** Với trường hợp này, **in-context learning** được sử dụng rất nhiều trong **prompt engineering**. Mọi người sẽ cung cấp các ví dụ có sẵn trực tiếp vào prompt và mô hình sẽ học từ những ví dụ đó để tạo ra các kết quả tiếp theo. Đó là ý tưởng chính của in-context learning. Về cơ bản, thiết kế sẽ hoạt động như thế này: bạn có một truy vấn, sau đó bạn xây dựng prompt với các ví dụ cần thiết và dữ liệu few-shot learning, rồi bạn đưa nó qua mô hình, mô hình sẽ trả về kết quả dựa trên các ví dụ đó. Tuy nhiên, nó không chỉ dừng lại ở các ví dụ, mà còn bao gồm rất nhiều yếu tố khác.\n\n**26:37** Nhìn rộng hơn, in-context learning liên quan đến việc cung cấp ngữ cảnh vào prompt bằng cách truyền vào các thông tin mà mô hình không có sẵn. Vì đây là một mô hình được huấn luyện trước, kiến thức của nó bị giới hạn, vì vậy bạn truyền thêm thông tin vào ngữ cảnh và prompt để mô hình học trong quá trình tạo ra kết quả. Ví dụ, trong chẩn đoán hình ảnh y khoa, mô hình có thể không có đủ kiến thức chuyên môn. Vì vậy, bạn cung cấp kiến thức đó vào ngữ cảnh và prompt để mô hình học trong quá trình tạo ra kết quả. Đó là cốt lõi của in-context learning.\n\nTiếp theo là nút thiết kế thứ hai quan trọng, được gọi là **data preprocessing/ editing**.\n\n**27:54** Phần này miêu tả quy trình chuẩn bị dữ liệu cho mô hình ngôn ngữ (LM). Như mọi người biết, LM hoạt động dựa trên các cơ sở dữ liệu vector, sử dụng so sánh vector để tìm các điểm dữ liệu tương tự. Quy trình này thường liên quan đến việc xử lý dữ liệu đa phương tiện và các loại thông tin khác nhau. Để đảm bảo đầu ra là tối ưu, việc áp dụng các bước xử lý trước dữ liệu là rất quan trọng. Ví dụ, bạn có thể xử lý trước văn bản bằng cách lọc ra các chi tiết không cần thiết để làm ngắn lại, hoặc với hình ảnh và âm thanh, bạn có thể loại bỏ nhiễu hoặc nén dữ liệu để giảm kích thước trước khi đưa qua mô hình ngôn ngữ.\n\n**29:19** Việc xử lý trước hoặc chỉnh sửa dữ liệu giúp mô hình hoạt động hiệu quả hơn. Có nhiều cách để xử lý trước, tuỳ thuộc vào loại dữ liệu hoặc ngữ cảnh. Bạn sẽ thực hiện điều này dựa trên các yêu cầu cụ thể. Nút thiết kế tiếp theo mà tôi muốn đề cập đến là một thiết kế thường được sử dụng, mặc dù có nhiều tên gọi khác nhau. Tôi gọi nó là **example agent**. Đây là một thiết kế thường thấy khi bạn muốn truy vấn của mình đi qua nhiều ngữ cảnh khác nhau. Ví dụ, nếu bạn có một ứng dụng đánh giá bài viết, bạn có thể cho bài viết đó đi qua một đường ống nơi mỗi agent đánh giá bài viết từ một góc độ khác nhau.\n\n**30:11** Một agent có thể đánh giá bài viết từ góc nhìn của một nhà văn, một agent khác có thể từ một góc nhìn khác. Sau khi đi qua tất cả các agent này, sẽ có một lớp tổng hợp cuối cùng để kết hợp hoặc xử lý các kết quả đó, và cuối cùng cung cấp cho người dùng một kết quả tổng hợp. Thiết kế này thường thấy trong các hệ thống đánh giá, nơi bạn đánh giá kết quả từ các mô hình khác nhau và chọn ra kết quả tốt nhất dựa trên các điều kiện đã được thiết lập trước.\n\n**30:55** Nút thiết kế tiếp theo, gọi là **agentic button**. Vậy agentic có nghĩa là gì? Trong ngữ cảnh của các mô hình ngôn ngữ (LMs), **agentic LMs** ám chỉ việc nâng cấp khả năng của mô hình. Vì mô hình chỉ biết những gì nằm trong dữ liệu huấn luyện của nó, chúng ta sẽ nâng cấp nó để tăng cường sức mạnh của nó và giảm thiểu sự can thiệp của con người. Thiết kế này giúp hệ thống tự động hoá nhiều hơn, cho phép nó hoạt động với ít sự can thiệp của con người hơn.\n\n**32:24** Thiết kế này có một số thành phần chính giúp bạn đạt được mức độ tự động hóa này. Có bốn thành phần chính: **reflection**, **planning**, **execution**, và **multi-collaboration**. Mỗi thành phần này đều giúp hệ thống của bạn trở nên tự động hóa hơn. Đầu tiên, chúng ta hãy nói về **reflection**. Reflection liên quan đến việc đánh giá kết quả ban đầu của mô hình dựa trên một tiêu chí hoặc một chỉ số cụ thể để xác định xem kết quả đó đã được tối ưu hóa chưa. Nếu chưa, hệ thống sẽ điều chỉnh và lặp lại quá trình này, tiếp tục tạo ra kết quả cho đến khi đạt được kết quả tối ưu.\n\n**33:06** Reflection giúp giảm thiểu sự can thiệp của con người vì thay vì tạo ra một kết quả ban đầu không đáp ứng mong đợi của bạn, hệ thống sẽ tinh chỉnh dựa trên các tiêu chí đã được thiết lập trước, cuối cùng đưa ra một kết quả chính xác hơn mà không cần điều chỉnh thủ công.\n\nReflection button này có nghĩa là nó sẽ đánh giá cái output ban đầu của một con AI, rồi nó sẽ đánh giá dựa theo một tiêu chuẩn nào đó hoặc là một cái chỉ số nào đó để xem là cái kết quả này đã tối ưu chưa. Nếu chưa tối ưu nó sẽ thêm thắt một chút và nó sẽ chạy vòng lại con AI đó để nó tạo ra kết quả khác cho tới khi nào đạt được kết quả tối ưu nó sẽ trả cho mình cái kết quả cuối cùng. cái này nó sẽ giúp giảm thiểu việc con người phải can thiệp vào quá trình làm việc, bởi vì nếu mà output đầu tiên không đúng ý mình, mình không cần phải tự chỉnh lại nữa mà nó sẽ tự tối ưu.\n\n**33:42** Button thứ hai là tool. Tool có thể là external, nó có thể là external API hoặc là những cái function mà mọi người code. Những cái tool này được sử dụng để cho model có thể lấy được những knowledge từ thế giới bên ngoài, những real-time knowledge, những external resource mà nó không được train sẵn. Như OpenAI hay là Claude đều có hỗ trợ. Khi đó, con model có thể tự biết khi nào cần gọi tool dựa vào cái description mà mọi người viết trên cái tool đó. Model sẽ tự biết cách lấy và extract thông tin từ tool, rồi trả về cho con LM để nó generate ra output.\n\n**34:30** Kế tiếp là planning. Planning button có nghĩa là mọi người cho con LM có khả năng lập kế hoạch, để tránh việc phải prompt đi prompt lại nhiều lần. Ví dụ, nếu có một task phức tạp, mình sẽ có một cái prompt lớn cho nó plan ra tất cả các step mà nó cần làm theo kiểu step by step. Cách này sẽ cho nó làm những việc nhỏ trước, rồi cuối cùng kết hợp lại thành một cái task lớn. Cái kiểu planning design này có nhiều biến thể, và đây là biến thể đơn giản nhất: lập kế hoạch xong rồi làm từng bước một.\n\n**35:10 C**uối cùng là multi-collaboration. Cái này em đã present cách đây một tháng rồi. Nói chung, nó giống như kiểu là AI giỏi việc nào làm việc đó. Mình có một cái context đúng không? mình chia nó ra, rồi đưa qua từng người. Người nào giỏi việc đó nó sẽ giải quyết việc đó, xong rồi pass qua con agent tiếp theo. Cứ thế, cuối cùng nó sẽ complete được cái requirement. Cái design này sử dụng tính chất divide and conquer khá nhiều. Chia việc lớn thành việc nhỏ, rồi đưa việc nhỏ cho người giỏi chuyên môn. Đây là một cái design button mà em thấy khá nhiều nơi bên ngoài sử dụng.\n\n**36:24** Đó là những design button mà em thấy nhiều nơi sử dụng và hiểu nhất. Em đã trình bày xong. Mọi người có câu hỏi gì không?\n\n**37:10** Hoàng, em nói lại cái phần planning, để confirm lại cái comment của anh Bảo. Nó giống như là kiểu đọc cái prompt đúng không? Nó sẽ hiểu cái prompt của anh trước, xong rồi nó sẽ chia cái prompt ra thành những cái nhỏ hơn, xong rồi nó sẽ có những con worker, có thể là những IDE worker hoặc là những cái prompt nhỏ để nó hoàn thành task đó. Đúng không?\n\n**37:40** Đúng rồi, anh có thể hiểu như vậy. Mình có thể chia prompt ra, ví dụ như là một task phức tạp, nó sẽ chia ra nhiều cái plan nhỏ. Những cái plan nhỏ này sẽ làm step by step. Ví dụ nó làm plan 1 trước, rồi làm plan 2, rồi làm plan 3. Sau khi hoàn thành tất cả các plan, nó sẽ tổng hợp lại ở một cái chỗ nào đó, hoặc là một cái component cuối cùng để nó ra được câu trả lời cuối cùng.\n\n**38:06** Ý là nó giống như cái con Zero mà hôm trước anh Tom present ấy. Con worker sẽ có thể làm một số task như đọc file, xóa file, sửa file, hay là talk với Internet, gửi email các thể loại. basically, agent các thứ như vậy.\n\n**38:52** Đúng rồi, bản chất của nó là thay vì làm một cục rất lớn để giải quyết hết cái task đó, mình phải đi prompt đi prompt lại nhiều lần để nó cho ra kết quả. Mình có một cái prompt trước, để chia nhỏ thành các task nhỏ, rồi sau đó có một cái pipeline để nó đi qua từng con worker, làm những việc nhỏ nhỏ cho mình.\n\n**39:23** Ok, kéo lên slide 14 đi Hoàng, slide 14. Anh cũng thấy là kiểu con này giống giống con Mule Automation mà Tom setup đúng không? Con Mule button mà Tom setup ấy. Em đã code xong rồi nhưng nhìn cái design này với cả cái button giống hệ nhau này.\n\n**39:46** Ừ, cái này là thằng Tpm nó chạy loop rồi, nhìn ra giống giống một tí. Nó giống planning mà anh Tom vừa nói, là nó break task ra từng phần, rồi xử lý từng phần một. Nó có iteration trong đó, giống như là nó có một list các step mà em đã mô tả ở trên. Back lại cái của em, chính là chỗ mà agent đang thấy. Cái của anh thấy nó giống planning hơn, là nó chia plan ra trước, rồi làm step by step từng plan một, đi qua mỗi vòng làm từng cái một. Còn cái này nó giống như là làm song song với nhau, nó parallel với nhau, để ra output xong rồi đánh giá lại output đó, rồi đưa ra kết quả cuối cùng. Chắc anh nhầm cái work rồi, đã correct lại.\n\n**42:28** Đúng rồi, thử đi. Nó là kiểu như vậy đó, nó chia ra thành nhiều việc khác nhau. Nó giống như là classify, nó chạy qua từng cái. Cái này giống multi-collaboration hơn, vì nó giống như question classifier, chỉ chạy một trong mấy cái này thôi. Mỗi agent làm việc đúng chuyên môn của nó, rồi combine lại.\n\n**43:33** Nhưng mà anh thấy mấy phần như reason với input analysis có đúng không? Của Tom, phần expert ấy. Riêng vụ pick domain ấy, nó có classifier ở đó, nhưng mà mấy phần reason với input analyzer là những agent khác nhau. Bên group đó là expert thôi, mình consider nó như là một group expert đúng không? Và nó combine với năm cái agent mình phía dưới.\n\n**45:33** Nếu mà làm tất cả mọi thứ trong cùng một cái prompt, em chắc chắn nó sẽ không ra được kết quả mình mong muốn đâu. Vì context quá nhiều và không có example cụ thể. Đầu tiên là accuracy chắc chắn sẽ giảm vì quá nhiều dữ liệu cùng lúc. Cái chính là phải chia ra nhiều layer, từng bước một. Thực tế mình cần output từ con LM, chứ không thể hardcode từ trước được. Mình chỉ muốn một cái prompt đơn giản nhất, để nó làm ra các câu trả lời nhỏ, rồi từ đó có một câu trả lời lớn.\n\n**46:59** Đúng rồi, khi làm nhỏ ra, mình sẽ biết vấn đề nằm ở đâu để debug. Như anh đã nói, specify kỹ, chia ra từng layer, nếu thấy sai ở đâu mình sửa ở đó. Còn nếu quăng một cục, mình sẽ không biết nó sai chỗ nào, rồi phải sửa rất nhiều lần.\n\n**48:43** Đúng rồi anh. Ví dụ như tạo một cái event trong calendar vào ngày mai, nếu không có sự kiện trong giờ đó tạo event, còn nếu có rồi thông báo. Nếu mình quăng một cục request đảm bảo nó sẽ rối ngay, vì nó phải thực hiện theo step by step. Nếu chia thành từng layer, test từng bước sẽ ổn hơn.\n\n**49:23** Nó sẽ em chắc là 99% là nó sẽ mù luôn á. Nếu mà còn nếu mình chia cái thành layer cơ, thành nhiều lớp layer á, làm test bài test nó sẽ ok hơn. Rồi, hô nào nên nữ, nên văn phòng là có Tôm ở đấy người chửi nhau. Anh không có hỏi nào chắc là cảm ơn Hoàng trước. À, đến Đạt nhé. Đạt nhờ. À, em không thị xem màn hình. Ok rồi, mọi người thấy màn hình của em chưa? Ừ, thấy rồi.\n\n**50:38** Hôm nay em nói về Yelp use cases. Từ từ Đạt, để anh giới thiệu context một chút. đợt này team mấy bạn sẽ focus vô đâu đó và đi search thử mấy cái phần use case ấy. Use case ở đây có nhiều dạng. Cái dạng mà Đạt đang sharing nó sẽ là mình xem thử các bên startup hay enterprise nó đang apply vào để giải quyết vấn đề gì. Là có thể là những cái green field, tức là những cái hoàn toàn mới. Hoặc là những cái mà nó optimize cho cái phần current workflow của chúng đó, kiểu vậy. Nó sẽ viết những use case và report lại hàng tháng, những cái phần update. Ngoài ra có một cái phần dạng use case khác nữa đó là những cái phần tuning mà để boost phần development của bên phía bên phía là tech các thứ. nó sẽ có những cái technique hay là có những cái phần editor mới, hay là mấy cái tool mới các thứ. đ cũng sẽ report cái phần đấy đâu đó trong tech. Đang testing thử trong khoảng hai tuần một đấy. đây là một cái bài đầu tiên chắc con Yelp này, nó đang dạng là con start-up phải không, chắc là. tiếp tục giới thiệu cho anh em một tí về cách mà bọn này đang apply AI là như thế nào?\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/s7doIOUDGgA?si=l1ZUsZApjB78hPcD&amp;start=3018\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**52:01** Yelp là cái đơn vị nó đưa ra cái software, nó cung cấp cái software cho các store, các bên mà doanh nghiệp muốn làm các đơn vị nhỏ lẻ như kiểu là giao hàng nhanh, hay là nhà hàng, rồi các bánh dụng cụ cơ bản, kiểu như vậy. Yelp này nó bán cái software cho mọi người làm việc đó. em sẽ chia sẻ chút về thằng này, nó sử dụng AI vào trong cái tooling của nó như thế nào.\n\n**53:00** trước đó chúng nó có một cái machine learning system rồi, bây giờ nó app thêm AI vào để giúp cho cái việc recommendation nó đúng hơn. bọn Yelp này nó có trên hệ thống của chúng nó, nó có nhiều cái thể loại đánh giá như kiểu đánh giá nhà hàng nó không bị tốt chẳng hạn. dựa trên những cái review đó, chúng nó có làm cái trò là text editing để so sánh được những cái kết quả mà spam hay không á. nó sẽ sử dụng AI vào trong cái việc gì. Thứ nhất là chúng nó sẽ tạo, chúng nó sử dụng AI để làm cái việc làm dataset, để train được cái model đánh giá là nó đang spam hay nó đang review tốt hay xấu như thế nào á. nó sẽ sử dụng AI để tạo ra cái dataset dựa trên LinkedIn. ở trong đây, em đọc có thấy bảo là chúng có sử dụng số tính như Zero-shot và Few-shot để làm dataset. chúng nó chỉ sử dụng một số cái model ở trên Hugging Face, rồi xong chúng nó làm classify để đánh giá được là review tốt hay xấu. đây là một cái use case cho cái việc AI dùng để làm text editing.\n\n**54:18** À, sang cái use case thứ hai của chúng nó, là chúng nó có sử dụng Clip Model. Clip Model bản chất của nó là xử lý hình ảnh. Xử lý hình ảnh có nghĩa là sao? Có nghĩa là dựa trên review, dựa trên review... đợi em chút để em kiếm nè. À, Clip á, nó sẽ xử lý hai thứ. Một là cái caption của cái ảnh, và cái ảnh nó như thế nào. qua Clip này á, nó sẽ hiểu được cái context của cái ảnh là cái gì. chúng nó sử dụng Clip vào trong những cái công việc như là những cái người ta đi vào trong một quán ăn hay một cái quán nhậu á, chúng nó sẽ review, chụp ảnh để capture lại những cái thứ này. Và ví dụ như hình ảnh của một cái món sản phẩm đi, trước khi apply Clip nó không đánh giá được, nó không đánh giá được là nó có bánh quế không, nó chỉ đánh giá được mỗi gà rán thôi chẳng hạn. Sau khi apply Clip vào á, nó sẽ biết được là có gà rán và có bánh quế. bản chất, nó sử dụng cái Clip này là một phần của AI, là nó xử lý ảnh, xử lý ảnh và caption của ảnh, và hình ảnh thành vector để nó so sánh với nhau. đây là hai use case của nó. những cái use case này được áp dụng cho cái gì?\n\n**55:38** Hai cái use case trên nó sẽ áp dụng trong cái tình huống là khi mà mình có nhiều review á, mình có thể summarize nó lại thành một cái highlight review ở trên đây. dựa trên những cái thứ mà nó chuyển thành vector được á, nó có thể annotation được cái việc là những cái hình ảnh đang nói cái gì, nó support cho mình được cái gì ở trong đây. Đợi một chút, nó sẽ highlight cho mình luôn. nó sẽ biết được cho mình cái context của cái ảnh là gì, nó có thể annotation được cái việc này. đó là cái use case của cái việc mà AI dùng để làm image summarization.\n\n**56:15** Đầu năm nay nó có release thêm cái là Yelp Assistant. Dựa trên những cái nền tảng cũ của chúng nó, chúng nó có thể tạo ra chatbot rồi, xong nó có thể review lại cái highlight như thế này, mình cứ hỏi nó xong nó recommendation cho mình cái gì thôi. Đơn giản là như vậy. Ngoài ra em có thấy một cái use case cũng khá đặc biệt, có nghĩa là trong cái giai đoạn từ 2020 á, nó nổ ra cái câu chuyện là làm clip ngắn review các thứ á. chúng nó có một cái nguồn dataset nhất định cho cái việc đó. em thấy chúng nó bảo chúng nó sắp release một cái như anh Tom có đề cập, cái bọn đó có thể chuyển văn bản thành giọng nói á. dựa trên cái nguồn dataset review này á, có lẽ chúng nó support review thêm cái việc mà làm video clip ngắn để mô tả cái nhà hàng.\n\n**57:45** Dựa trên những cái review, những cái video mà người ta tới người ta review á, mình có thể tạo ra được một cái đoạn script, xong cho nó chạy qua AI, nó tự động làm ra một cái video về một cái nhà hàng như mình. đây là use case của bọn này, đơn giản nó có thế thôi. Ok, quay lại cái câu hỏi đầu tiên, cái này nó sẽ dạng là dùng AI để label data, đúng không?\n\n**58:35** Ok, vậy là check xem là cái comment là negative hay positive, đúng không? Kể kiểu đấy là một ví dụ. Cái thứ hai nữa là nó sử dụng cái clip model, đúng không? Chắc là sẽ dạng giống như Vision, nhưng mà live hơn, cũng để dán nhãn, đúng không? Để dán nhãn giống như cái của bên phía Plot, dán nhãn cho ảnh. hai cái use case đó, nó sẽ được ứng dụng trong cái việc gì?\n\n**59:18** Em nghĩ có một cái ý khá hay mà nó chưa nói tới, là câu chuyện là nó có nguồn dataset sẵn. Như là ai tới review, ai tới đánh giá các thứ, dựa trên những cái clip ngắn như thế này, nó có thể tạo ra được một cái video intro về cái nhà hàng đó. Nó sử dụng AI. Em nghĩ là nó sử dụng AI để viết kịch bản, rồi sau đó đưa kịch bản đó cho một con AI voice để nói. Nhưng mà hình ảnh nó lấy ở đâu? Như kiểu là video nó sẽ lấy từ đâu ra?\n\n**59:57** Từ trong cái review, ai tới review họ sẽ có một cái video để review. Ok, tự động tạo advertisement, đúng không? Dạ vâng, cho TikTok hay những nền tảng như TikTok các thứ, kiểu summarize từ review của user. Nghe cũng có vẻ sáng tạo đấy. Ừ, chắc anh em confirm mấy cái của anh bảo làm rồi đúng không?\n\n**01:00:07** Đang vậy, cái này ok là cái caption. Ok, đúng hầu như là đúng anh. Bạn nói đúng, là chúng nó sẽ, em nghĩ em nghĩ cái use case này bọn này ban đầu á, cái mục đích ban đầu của bọn này là làm recommendation. trước đó, trước khi có AI chúng nó đã có một cái hybrid recommendation model trước. Căn bản là nó sẽ... Em nghĩ là khi mà có cái này á, nó dẹp gần hết cái model cũ này luôn. Em nghĩ có một cái khá hay là cái business messaging mà chúng nó không có đề cập nhiều. Có nghĩa là em nghĩ là nó sẽ dựa trên là có review top 50 review chẳng hạn. Xong top 50 cái interaction, kiểu như rating như thế nào. Thứ nhất là review tốt, n rating tốt, cái business messaging của nó sẽ tốt. Mà Yelp không đề cập vấn đề này, mình không trách nó được.\n\n**01:00:51** Ok, anh em có câu hỏi cho Đạt không? Bài đầu tiên đấy. Đạt bảo đang thêm mấy cái, mình phải enterprise nữa, nhưng mà thầy thấy đang Viettel với cả FPT, với cả VNG các thứ, đang chưa biết thấy chúng nó thế nào. Đạt kêu mấy cái tool, cái tool gì coding của bên phía FPT hả, đang kêu cùi.\n\n**01:01:41** Hì, một bản for, một bản for của của continue à? Nó thế, nó thế không tốt. Nó hơi cùi, thô. Hai, chị hết rồi à? Chắc vậy. Đạt nhé. Hôm nay mấy bài về Yelp và Tech Linh chắc tuần sau, tuần sau, tuần sau nữa, nếu kịp.\n\n**01:02:01** Tí demo luôn đi, Đạt luôn. Để Đạt demo một tí cái gì nhỉ? Cá đang là một con bot, để có thể question với cả question một cái short code dưới dạng kiểu developer mà hiểu rõ hơn về code, hay là test kiểu như là một vai trò auditor đi kiểm tra chất lượng của code. Đạt đang demo dev cái workflow hay con bot dựa trên diff đó cho anh em xem thử nào. Mình bật hình rồi Đạt ơi.\n\n**01:03:01** đây là một cái project để em xin vào club ai nha. Trình em gọi là hơi 'newb' nên project này mà có lem quá mọi người thông cảm. Workflow cơ bản là em sẽ lấy query, rồi trích xuất ra được cái URL của repo. Ở đây em có dùng lại cái scrapper của anh Tom, nhưng mà nó chưa đúng ý em, nên em có tạo một con scrapper ở local nó sẽ lấy được tất cả content của repo luôn. Nhưng mà cái đó nó quá lâu với quá lớn. Ờ, default hiện tại em chưa thấy làm cách nào mà bỏ vào con context được, trừ khi dùng cái knowledge retrieval, mà dùng knowledge retrieval em không có gọi là trực tiếp được mà phải bỏ vào trước. Mình không có chọn, không có chọn repo được.\n\n**01:05:45** Cái scraper này của anh Tom nó không có lấy content của file, cho nên em chưa vẽ diagram được. Vẽ diagram có thể em dùng, tí nữa em test thử. Cái này là em lấy được content của những file nè, ở root, ở những file doc. Những file đó không chắc câu hỏi của Huy vừa đưa ra chắc là cũng không trả lời được. Để em thử, em có sẵn cái full của em vô đây rồi, offline nhỉ. Bên phía in sẵn content rồi, chứ không online. Cái này em generate bằng luôn, cũng không có.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/s7doIOUDGgA?si=DGxSbJrTJjDCyUp5&amp;start=3798\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**01:07:07** Cái này nó sẽ scrap full content, nó sẽ đầy đủ hơn. Để em thử đặt câu hỏi của bên Huy hay của Hoàng các em thử nào. Mình thử BC chat lên rồi đặt câu hỏi xem. Anh có không? À không. Maybe là cái context này quá lớn, cái phần knowledge retrieval này em chưa tìm được cách mà cho nó vào context tốt được.\n\n**01:09:19** Retrieve tối ưu lắm. Cái file text này cũng mấy chục ngàn dòng, mấy chục ngàn dòng á. Mở lên xem thử nà, đ đang dùng mini hả, đổi sang máy đ xịn hơn xem có ok hơn không. Đồ mini hơi cùi. 2 triệu từ như thế, từ làm sao mà nó còn xong được ta? Em nghĩ là phải có một cái server, cái dedicated server luôn nó mới ok. Anh đang tò mò tại sao nó chạy được ấy, bởi vì 29U word à, như vừa thấy à. Nhân với cả 4 này là số to. Kích cỡ đấy, Follow up xem thử. Ok, tức là em vẫn là từ cái context thôi đúng không, là mình cũng chỉ dạng là query kiểu query vb đúng không, chứ không phải mình nhập hết tất cả cái đấy vào context.\n\n**01:10:57** Ok, đúng rồi anh. em chưa nắm được là cái retrieval của thằng dify nó sẽ chạy như thế nào. Không biết nó chạy có đúng không, nó retrieve có đúng không. Em chưa tracing được nó mà em có cái tool tracing ở phía trước nữa, có thể test lại thử xem như thế nào. Nhưng mà ý là nếu mà kiểu retrieval như này chắc là kết quả nó sẽ không đúng được đâu anh. Anh cũng đang chưa biết là nó sẽ run bao nhiêu data ấy. Kiểu nó chỉ prefer 2-300 thôi, kiểu data không thể nào đủ mà để làm mấy cái task kiểu này. Cái này ít nhất cũng phải vài trăm tương đối data ấy. Dạ cái này còn work in progress.\n\n**01:11:35** Đùa đấy, cứ lên công ty là có AI Club rồi. À, là của full version hay là fix được cái vụ này demo với bọn anh ở trên office nhé, mà try em để lại cho anh. OK, để em xem nó vẫn không build ra chắc mọi người coi đỡ. Cái chắc build bị gì đó, mọi người thấy màn hình không ạ?\n\n**01:13:08** Dạ tuần này như em nói tuần trước em sẽ up cái bài sync.Map này. Em thấy nó hay với chi tiết để mọi người mà xài Go có cái nhìn tổng quan hơn về map nói chung. Và cái thằng sync map này đi qua trước là phần context. khi mọi người viết map đúng không, mà mình nếu mà mình viết concurrent map hay operation đó, mình làm concurrent á, về bản 1.16 trước nó sẽ không báo đâu, nhưng mà nó vẫn không safe nha. Còn bản từ 1.16 trở đi á nó sẽ error như thế này đó. Cho nên là để mà solve được problem này bình thường mọi người có thể viết map kèm với tại package sync, viết manual đó được.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/s7doIOUDGgA?si=0nH3Rjv-OZ5FAoAP&amp;start=4394\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**01:13:56** Bên cạnh đó nó có một cái option khác đó là thằng sync.Map này. chút nữa đến cuối mình sẽ sẽ nói tại sao nó lại được đề ra xài và cái usecase của nó như thế nào. thằng này nó được đề ra để mà mình không cần quan tâm lắm về cái việc mà mình phải xài mutex để lock lại cho việc synchronize. Tức là mình chỉ có việc xài thôi. Xài nó trông đơn giản như thế này nha, nó friendly như là mình viết map kiểm tra value vậy. Ví dụ như mình load một cái key lên có value ok nó sẽ giống như là việc map value bình thường thôi. Trong như này, nếu có là ok true, còn nếu không có false của y chang.\n\n**01:14:38** Còn có một số cái function mà mình có thể xài rất handy. Đây là bảng 12.23 sẽ có clear, clear hết. Ví dụ như load là để lấy value, store là để update hoặc store cái key. Update vậy. Delete các thứ. ngoài cái việc mà mình viết concurrent đó đi đó, bên cạnh đó khi mà mình range, tức là mình loop một cái map nó cũng bị race condition nữa. thằng sync map này nó có cái hàm range này, mình xài mình sẽ không quan tâm nó là ấy, nó sẽ không bị nhưng mà như hàm range bình thường thôi. nó sẽ không cho mình cái cái snapshot mà gọi là consistent nhất, là khi mà mình vừa mới vô cái snapshot nó không được update là.\n\n**01:15:28** Mà mình range, tức là mình loop một cái map, nó cũng bị race condition nữa. thằng `sync.Map` này nó có cái hàm `Range`, mình xài, mình sẽ không quan tâm nó là cái gì, nó sẽ không bị như bình thường đâu. Nhưng mà như hàm `Range` bình thường thôi, nó sẽ không cho mình cái snapshot mà gọi là consistent nhất, là khi mà mình vừa mới vào cái snapshot nó không được update. trong lúc đó mình sẽ phải thay đổi cách viết, nhưng ít nhất là nó sẽ không bị phải error như thế này.\n\n**01:16:06** Đến cái phần bên dưới nó work như thế nào á. mọi người, nếu mà mọi người viết khi mà xem `CH` và `definition` cái `map` nó được cấu trúc như thế này: nó sẽ bao gồm hai cái `map`. Đó, nghe đến đây là mọi người sẽ thấy hơi kinh, nghe hơi thốn `RAM` với `memory`. Nó có một cái `Read Only map` và một cái `Dirty map`. nghe như thế mọi người có thể đoán được là nó sẽ làm việc theo kiểu là những cái value mà nếu mà được `write` nó sẽ được viết vào cái thằng `Dirty map` này hết. Cứ viết `update` vào đây, `update` vào đây, con này nó sẽ giống như là.\n\n**01:16:46** Cái `Read Only map` này nó sẽ là những cái khi mà mình đọc vào á, mình sẽ luôn đọc ở đây. Còn `write` sẽ luôn `write` mới vào thằng `Dirty map`. Còn cái flow bên dưới nó làm việc như thế nào chút xíu nữa mình sẽ nhìn cái chart flow mình sẽ thấy. À, cả hai cái `map` này có một điểm chung: nó đều có một cái con trỏ `entry` nha mọi người, để ý để dễ hiểu cái flow. Ví dụ, ở đây mình thêm một cái `entry` mới, đúng không? nó sẽ thêm vào `Dirty map` và nó đều trỏ đến `entry` này. Cái này nó sẽ giống như là một cái `flag` để đánh dấu rằng là cái `map` này đã được thay đổi rồi. Tức là cái thằng `Read Only map` này nó không phải là mới nhất nữa. Khi này bên dưới nó sẽ nhìn và hiểu rằng là thằng `Dirty map` mới là cái nên đọc vào.\n\n**01:17:27** Hình này thể hiện rằng là ví dụ như mình `update` một cái value nào đó, do bên dưới nó là con trỏ đúng không, mình chỉ việc `update` cái con trỏ đó thôi, không cần phải `update` từng cái value như là mình làm với `map` truyền thống. để làm được điều này á, bên dưới nó để ra một cơ chế là ba cái trạng thái (`state`) cho cái con trỏ `entry` này. `State` thứ nhất là `normal state`, đúng không? `Normal state` tức là những cái value cũ của `map`, nó đang có đủ và có thể xài được, không có bị gì hết. Còn trạng thái `amended` là khi mà `entry` đã bị sửa lại. Còn `delete state` là khi một `entry` nào đó đã được `delete` khỏi `map`, nhưng nó chưa được remove hoàn toàn nha. Tức là nó sẽ được...\n\n**01:18:59** ...assign cái con trỏ `entry` vào `new entry`, chứ chưa remove ra. Còn cái `expired state` là xóa hoàn toàn, giống như là `hard delete` là mất khỏi `map` luôn. Để hình dung rõ hơn, mọi người có thể nhìn cái flow như thế này nha: ví dụ ban đầu cái `map` của mình đang có một cái `key1` và `value1` đúng không? bên `Dirty map` chưa có gì cả, tức là chưa được thêm bớt gì. Sau đó, mình thêm một cái `key2` nào đó, đúng không? nó sẽ được thêm vào `Dirty map`, và khúc này là thằng `map` đã `amended` rồi, nó đã có một cái `flag` `amended` ở đây.\n\n**01:19:40** Sau đó, khi mình xóa (`delete`) một cái `key`, `map` này sẽ bị gán `new entry`, đúng không? Bên này cũng sẽ được tương tự gán `new entry`, giống như cái hình trước. Tức là mình chỉ cần cập nhật con trỏ thôi, không cần phải cập nhật value. Rồi, sau khi `delete` xong, đúng không, để `promote` được cái `Dirty map` này, mình phải cập nhật lại qua bên `Read Only map`, để `Dirty map` trở về `new state`, giống như đưa về trạng thái ban đầu.\n\n**01:20:18** Tương tự, thêm một `key3` nữa, khi thêm cái `key3` này á, cái `state` này nè, sau khi nó đã trở về `new state` rồi đúng không, mình thêm `key3` vào á, nó xác định rằng thằng này đã được `delete` rồi, nó sẽ là `delete` hoàn toàn. Điều này có nghĩa là lần sau, khi nó so sánh với `Dirty map`, nó biết rằng bên này cái `value1` đã bị xóa rồi, không còn nữa. cái `Read Only map` lúc này chỉ còn lại `key2` và `key3`.\n\n**01:20:51** Cho nên chính vì lý do này, `sync.Map` không có hàm `len` cho mọi người xài. Tại vì nếu như mọi người dùng hàm `len` ở đây, sẽ không biết được `value` của nó, tại vì lúc đó nó sẽ đếm cả những cái `value` đã `expired` hay `deleted`. Mọi người có thể thấy, chính vì cái cấu trúc của `sync.Map` được build như thế này, use case của nó được recommended là nên dùng cho những use case mà đọc (`read`) nhiều hơn ghi (`write`). Tức là nếu mà `write` hoặc `delete` nhiều, mọi người tưởng tượng chỗ này nó xài con trỏ liên tục, và có một cái issue bên Go team đã report là thằng này không bao giờ được garbage collected.\n\n**01:21:36** Sau đó Go team họ confirm rằng cái `sync.Map` này được sinh ra chủ yếu để support mấy cái bên trong Go Library thôi. Nếu mọi người thấy nó `handy` vì có những function dễ xài có thể xài, nhưng nếu use case của mọi người mà cần lưu trữ (`store`), hoặc là `update`, `delete` nhiều không nên xài, vì nó sẽ làm chậm hệ thống.\n\n**01:22:24** Dạ chắc chỉ vậy thôi ạ. Em có code lại cái bài bên này là cái bác này hay share mấy bài cũng khá chi tiết, mọi người có thể follow theo dõi. Ủa, cái này là topic gì Phát? Cho anh coi lại cái bài kịch bản đúp đầu r. À, cái sync map à? Ừ, sync map á. Ủa, nó có khác gì với lại cái anh vừa pass vô không vậy? Khác ở cái gì? Hình như là khác á anh. Ý là cái này em nhớ không nhầm là kiểu như cộng đồng tùy. Anh ví dụ use case họ muốn viết một cái gì đó mà họ thấy. Đó, anh nhìn thấy, họ ghi cái trong cái bên đấy, link mà nhìn thấy cách nó chạy mà lý do tụi nó làm thêm cái gì ấy nhỉ?\n\n**01:23:30** Anh nhìn thấy nè, họ thêm một cái lớp nữa để họ xài. Ví dụ như là họ sẽ có những cái use case đúng không? Ví dụ như họ muốn implement generic trên `sync.Map` đó. Cái này cũng có ảnh hưởng do cái vụ link nãy em nói, do thằng này nó không được garbage collected nè. Đó, kiểu vậy. ví dụ như bên này Go team ở dưới, họ đã confirm chốt xong cái này là cái `sync.Map` này họ kêu là cái này là `intended`, intentional choice rồi, cho nên họ sẽ không sửa. Họ sẽ không đổi đúng không? Bây giờ cộng đồng làm gì mình chỉ biết là họ tự xài thôi. Ý là họ thích cái việc `sync.Map` này được để ra dễ xài, có mấy cái function ngon lành, họ ráng thêm một tầng nữa, rồi chế những cái mà họ cảm thấy là ok, mình có thể xài được. Kiểu vậy.\n\n**01:24:07** Ủa mà sao cái clip này cũng lâu mà bữa nay lại chọn à? Ờ, thế kiểu insight thôi, insight cho mọi người xài. Ý là cái use case này cũng có thể được apply cho bên mình. Ví dụ như bên enterprise đúng không? ví dụ mình xài `map`, mà mình xài concurrency đúng không? mọi người sẽ tự viết một cái `struct`, xong rồi mọi người sẽ nhét một cái `mutex` vào, rồi tùy người sẽ ngồi bắt đầu viết lại. Đủ các kiểu. Trong khi đó thằng `sync.Map` rất handy, như nãy em show anh, là mấy cái function này là nó luôn follow cái chuẩn, là anh muốn `load` anh phải gọi hàm này. Kiểu vậy, nó chuẩn hơn.\n\n**01:24:50 M**ọi người sẽ tự viết một cái `struct` như thế, xong rồi mọi người sẽ nhét một cái mutex vào, tùy người sẽ ngồi bắt đầu viết rồi đú các kiểu. Trong khi đó `sync.Map` rất là handy. `Sync.Map` này như em show anh nãy đó, những cái function của nó, nó luôn follow cái chuẩn này hết. Anh muốn load anh phải gọi hàm này, kiểu vậy nó sẽ chuẩn hơn. Nhưng mà như cái bài này là mình phải để ý những cái trade-off của nó, xài cho đúng quy. Ok, hiểu rồi, tức là quy chuẩn cái cách mà sử dụng `map` hả? Với lại workflow hả?\n\n**01:25:26 C**ảm ơn Phát. Rồi để tranh thủ, mấy cái Thành ơi, nhất là xin anh em thêm 10 phút nữa nhé. Nó sẽ hơi tốn thời gian thêm xíu. Nhất là anh nhận được tổng cộng 11 cái submission cho cái bài test của mình. Có ít bài hình ở trên, mấy anh em nhìn ở trên tí. Deadline của mình là đến ngày 20, tức là tuần sau nhé. Bữa trước anh thông báo như là 27 ha, phải không? 26, 27 gì đó là deadline, mấy anh em coi tranh thủ còn một tuần nhìn bài đó rồi làm ha. Cái bài đó nó sẽ quan trọng, có một số cái mà chi tiết của từng bài đó anh chưa có nhìn kỹ. Chỉ có bài của Tôm bữa trước, Tôm nó quăng nhanh lên trên lobby quá, thành ra là có nhìn sơ qua xíu. Nhưng mà còn của mấy anh em chưa nhìn rồi. Nhưng mà cái ý chính là mọi người xem thử nha, cái chất lượng bài của mình á, tập trung ở chuyện là đợt này khi mà market nó thay đổi nhiều vậy, cái demand của thị trường cho cái nghề làm software nó có sự thay đổi lớn á.\n\n**01:26:15** Tất nhiên những cái nhu cầu nó vẫn sẽ còn ở đó thôi, nhưng mà cái số lượng đó nó giảm xuống. Thành ra đó anh gọi là cái sự thay đổi về cái nhu cầu thị trường gần như với góc nhìn của anh trải qua nó là giống như 2014, nhưng mà on-over-again, vậy là sự thay đổi công nghệ mới ra, mọi thứ mới ra, thị trường mới rồi những cái tiềm năng mới nó sẽ xuất hiện trên đó. cái bài test nó sẽ quan trọng với việc là giúp cho mình, nhất là test về văn hóa, nhìn lại trong cái lúc mà tụi anh muốn check lại cái team á, muốn là hai cái đội: đội làm research study với cả đội làm consulting nó có một cái sự phân hóa rõ ràng.\n\n**01:27:36** Nó có một cái sự phân hóa rõ ràng. Như trong cái bài viết anh post lên notion cách đây khoảng hai tuần hả, sẽ có sự phân hóa rõ ràng. Tương lai nó sẽ có thêm một số những cái policy mới cho chính sách về lợi ích khác nhau giữa hai đội nữa. Nhưng mà hiện nay là, như mình thấy đó, mọi người thấy OGIF dần dần nó được chuyển qua gần như thành cái buổi là report lại tất cả những cái study. Cái phần mà anh em đang coi mới và report lại trên này. Có thể những bài đó do được add, có thể những bài đó là do mọi người bắt đầu anh nhìn thấy, có một vài thành viên trong team mình thật sự là thấy cái kiến thức mới đó, xong rồi pick up những kiến thức mới đó để mà coi.\n\nTừ từ thấy rõ ràng là tụi anh muốn cái sự phân hóa đó nó diễn ra càng ngày càng rõ hơn. Và cũng có chính sách rõ ràng cho cái chuyện đó. Tức là ai mà thích coi mấy cái phần topic nhiều hơn, xong rồi ra ứng dụng ở tới mức là MVP, hay là ứng dụng vô những cái dự án nếu có, hoặc là đi deep dive thêm về kiến thức á, sẽ có một cái benefit khác. Những anh em nào mà không nhất thiết để phải ngồi coi những cái phần liên quan tới phần study như vậy, cứ ngồi làm dự án bình thường thôi. Nhưng mà nó sẽ có một số vấn đề khác đi kèm mà anh cũng có list ra trong cái link notion cách đây hai tuần. mọi người xem nhìn lại cái link đó một tí, để biết là vì cái định hướng như vậy nên là cái bài test này nó mang ý nghĩa là xem thử coi là cái mức độ của mọi người trong chuyện bắt kịp kiến thức mới, hoặc là cái độ tương thích với lại văn hóa trong cái giai đoạn mà tất cả mọi thứ nó thay đổi như vậy tới mức nào ha.\n\n**01:29:20** Để hiểu vì cái mục tiêu là như vậy, nên là cái lúc mà chấm cái bài á, anh sẽ là người duy nhất chấm cái bài đó. Team mấy anh chị khác không có chấm đâu. Tất cả mọi người sẽ phải làm mà, nên là anh nghĩ rằng anh set cái standard cho chuyện đó. Nên là mấy bạn chịu khó làm bài đó tự làm là một chuyện. Thứ hai nữa là bài nào mà chất lượng thấp thật ra cũng không có vấn đề gì hết, chấm điểm thấp một xíu thôi, nhưng mà vừa làm hết vẫn sẽ được đủ điểm để mà coi như là pass cái đó. Chỉ là sau đó cái kết quả trước mắt thể hiện được á, là anh sẽ phân cụm thành hai cụm khác nhau.\n\nĐội Foundation hay là đội Lab á, vẫn là đội core của mình từ năm nay, ha. Đó là cái thông báo chính. Nên là trên 11 cái bài này, nếu bạn nào làm xong rồi mà cảm thấy là mình có thể làm tốt hơn được cho cái chuyện mà anh vừa mới nói đó, đội mình thật ra là cái team Foundation và cái team Lab á vẫn sẽ được ưu tiên nhiều hơn trong những vấn đề khác nhau. Được ha. Nên là nếu mà anh em cái bài đó mà đang kiểu làm qua loa á, tập trung ngồi làm kỹ lại tí. Check hai thứ ha: văn hóa trên đó là một, thứ hai nữa là kiến thức.\n\n**01:29:56** Sau đó cái kết quả trước mắt thể thấy được á, là anh sẽ ân cụm thành hai cụm khác nhau, cái đội Foundation hay là đội Lab á vẫn là sẽ đội core của mình từ từ từ 8-9 năm nay ha. đó là vậy, đó là cái thông báo chính. Nên là trên 11 cái bài này, nếu bạn nào làm xong rồi mà cảm thấy là mình có thể làm tốt hơn được cho cái chuyện là anh vừa mới stay ra, là đội mình thiệt ra là cái team Foundation, cái team Lab á vẫn sẽ được ưu tiên nhiều hơn trong những vấn đề khác nhau. Được ha. Nên là nếu mà anh em cái bài đó mà đang kiểu làm qua loa á, tập trung ngồi làm kỹ lại tí, check hai thứ ha: văn hóa trên đó là một, thứ hai nữa là kiến thức cho cái cụm thông tin cái cụm gần nhất mà nó đang có vẻ hot nhất là LLM thôi.\n\nNhưng thực ra team mình vẫn cover rất là nhiều mảng khác nhau, vẫn đang có xem về design, mấy bạn cũng đang xem đúng không. Vẫn có đội đang xem đúng không. Go vẫn đang xem. Blockchain có vẻ nó qua trend tí rồi, thị trường nó đang sideways thôi, nhưng mà về demand của consulting nó vẫn yêu cầu những cái đó rất là nhiều.\n\n**01:31:46** Mấy cái mini app cho telegram, họ mua về rồi clone nhanh lên, thấy góc nhìn của mấy bạn làm business logic (BL) và tech (TCH) bây giờ nó khác một xíu rồi, không còn như ngày đầu nữa. Nhưng mà với consulting mình vẫn có thể sử dụng thôi, bình thường. Hoặc là mình có thể nhìn theo một góc nhìn khác, theo dạng là nó như một cái asset class mới xuất hiện. Với vai trò là developer, mình phải nhìn nó theo góc nhìn làm sao để nó ảnh hưởng đến cái workflow của mình như thế nào, quản lý tài sản ra sao.\n\n**01:32:29** Đó là vấn đề về bài test nhé. Mấy anh em chú ý cái đó. Thứ hai, nãy có nhắc tới cái định hướng về team và số lượng nhân sự. Trong đó có nhắc lại cái link notion hôm trước anh có gửi nhé. Đội Foundation, đội chính khi start lại lần nữa như vậy. Lúc trước team tụi anh bắt đầu chỉ có ba người thôi, sau đó dần dần tăng lên bốn người, rồi lên năm người. Có thêm Quan, có thêm Hiếu, có thêm mấy bạn khác. Nhưng mà ban đầu start với ba người, giờ đội hình xịn hơn rồi. Bây giờ 40 người toàn là thứ dữ, chắc chắn sẽ đi nhanh hơn. Câu chuyện chung là vậy, đánh giá chung cũng là như thế, nên mấy anh em nắm tình hình nha.\n\n**01:33:12** Cái thứ ba nữa có liên quan là Huy Nguyễn, nếu mà xong rồi, chắc tuần sau xem lại thống kê con số về ICY giùm anh nha. Hôm trước em cũng báo là số lượng bắt đầu chạy hơi nhiều, nên mình phải xem lại, cân lại con số cho nó hợp lý. Riêng phần này nhờ Huy và Thành chủ động làm giùm, xử lý giùm anh, xem lại cân số cho nó hợp lý. Thành có một công việc phụ là phần benefit cho thành viên team Lab, xem thử đề xuất như thế nào. Nó có thể được coi là một cái payon, nhưng mình sẽ không trả qua kênh bình thường, mà sẽ có cái cơ chế khác.\n\n**01:33:52** Nhưng mà mấy thành viên team Lab sẽ có cái đó, mọi người quen với cái đó rồi. Cuối cùng là, riêng phần về LLM hiện tại, trong cái list câu hỏi có một câu hỏi quan trọng là làm sao để sử dụng, tìm hiểu bên ngoài sử dụng LLM như thế nào và adapt ra sao. Nhấn mạnh lại câu đó, vì nó là một câu mang ý nghĩa trong việc làm knowledge discovery. Câu hỏi này liên quan đến việc test là không chỉ đơn thuần là dùng, mà là tất cả các công cụ mà mấy anh em thấy được trong team hiện tại. Khi có người sử dụng hiệu quả, có người sử dụng kém hiệu quả hơn, RT (retrieval technology) nó thành một spectrum rất rõ ràng, những người thấp là thấp, những người cao rất cao.\n\n**01:34:38** Tụi anh muốn nâng cái standard đó lên. Spectrum đó tụi anh muốn rút ngắn lại, càng cô động lại càng tốt. Bây giờ nó đang rất dài. Câu này ngoài việc dùng tool để làm discovery, nó còn mang ý nghĩa xem ngành nghề của mình sẽ như thế nào trong việc ứng dụng đó để nâng cao competency của mình, làm việc có năng suất hơn. Đó là toàn bộ vấn đề, và mọi người xác nhận lại xem cái mình làm có đúng chưa, nó có tầng ý nghĩa sâu xa hơn vậy.\n\n**01:35:20** Cuối cùng để kết thúc buổi này, Thành ơi, mấy buổi OGIF sau, những phần mà Tom đã làm liên quan đến việc xây dựng structure của một cái LLM app, có thể lấy cái đó ra phân tích thử nhé. Phân tích lấy cái đó để làm sâu hơn luôn nhé.\n\n**01:35:56**Toàn bộ mọi người hy vọng là tất cả anh em đều pass hết để đi chơi cho nó vui vẻ. Tuần sau sẽ có một cái bài khác. Tuần sau request là bên chỗ của Minh L. Minh ơi, chắc là lên làm một cái demo nha, tiếp tục về cái finite state machine, FSM á. Vì trong định hướng những công nghệ nền tảng như blockchain, AI, nhưng phần chính vẫn sẽ là các anh em làm engineer sẽ có một ngách khác để đi, đó là hiểu rõ các hệ thống lớn vận hành thế nào. Tương lai, nếu mình không phải là người sinh ra để làm data manipulation AI sẽ làm giùm mình, mình không cần tự thiết kế hay làm mấy việc của junior nữa.\n\n**01:37:35** Cách duy nhất để lên senior là hiểu rõ vấn đề và làm kiến trúc thôi. Phần finite state machine đóng vai trò tương đối quan trọng, liên quan đến chuyện scale mà trước giờ tụi mình đã nói nhiều. Trước đó Minh có đọc và hiểu đúng góc nhìn mà anh đang muốn hướng tới. Nên là xem thử làm bài phân biệt các loại general server của nó nhé. Server state machine và event-based server. Rồi làm một cái sample để biểu diễn và implement nó luôn bằng Erlang nha. Erlang có sẵn hết các framework rồi.\n\n**01:39:01** Bài này chắc là khi nào Minh Lưu. ready, nếu tuần sau không kịp có thể là hai tuần. Đề nghị mấy bạn backend và mấy bạn sen team mình gom lại, có gì confirm trước nhé. Vì bài này rất quan trọng trong chuyện phân tích thiết kế phần mềm. Bài này rất quan trọng. Trước giờ mọi người chỉ nói tới modeling và làm C4 thôi, nhưng Erlang là ngôn ngữ đi sát cái này nhất rồi, thường mọi người sẽ không biết hết. Chúng ta không nhất thiết phải học Erlang nhưng có thể nhìn cách thiết kế và build của họ để làm phần đó rất chuẩn, giống như là họ có framework sẵn, mình chỉ cần gắn vào để sử dụng thôi.\n\n**01:39:37 T**ranh thủ, ngày 20 tháng 10 là chủ nhật, Mỹ với Ngọc và Giang có post rồi. Hôm đó là các chị em đi chơi, còn không ở Sài Gòn đại diện team sẽ chúc mọi người phát tài. Chúc mọi người phát tài chắc hợp lý nhất trong trường hợp này. Một chút chúc khác có vẻ không liên quan lắm. Rồi vậy nha, anh em tham gia được đăng ký với Mỹ để book bàn và đi cho hợp lý.\n\n**01:41:19 N**hờ Thành những buổi sau cấu trúc lại thành mấy cái talk nhé. Rồi làm goal đó, team mình có thêm Builder-club nữa, đội đó chắc để xem mấy anh em lúc trước làm Super Bit ổn định lại hoặc làm console ổn định lại anh sẽ cấu trúc lại sau nhé. Đợt này chắc là nghỉ ngơi đầy đủ rồi. Rồi ok, anh em có câu hỏi gì cho bài test không kết thúc ở đây nhé. Rồi tạm biệt mấy anh em, hẹn gặp lại tuần sau. Cảm ơn Thành, cảm ơn tất cả mọi người.\n\n---\n\n**English Transcript**\n\n**0:28** The topic still includes Go Weekly, and Nam is currently testing the weekly design commentary. Let's see how it goes over the next few weeks.\n\n**11:19** Nam will continue to present to the team, and there are a few topics from Hoang, Cat, and Dat. We’re currently researching various use cases that other companies are applying and some of the tools being used by developers. There will likely be a presentation this week or next about these findings. The focus will be on generating a UX design button. In the past, there have been questions about where AI is applied and how it plays a role, whether it serves as a small, standalone component or as part of a broader application for digital products. Today, I will address how AI contributes and how it functions.\n\n**12:11** First, I will talk about system scope relationships. This diagram illustrates how AI is integrated into systems at different levels, from a small component to a comprehensive ecosystem. AI can be a small part of a component or evolve into a larger function, automating features to improve user experience (UX). Here, AI plays a crucial role in digital products, and when integrated, it can fit into various parts—from components to flows, to features, or even as an entire application. It can be part of a platform or ecosystem.\n\n**12:53** For example, as a feature within an app, AI can help users interact with the app more easily, saving time by automating tasks that would otherwise be done manually. As a standalone application, there are many examples like ChatGPT, which serves a specific purpose, or as a platform like Rewind AI, which offers multiple features supporting AI in different tasks within the same app. These are examples of the scope of AI's current operations.\n\n**13:39** Next, regarding the spatial relationship, this helps us understand how AI features are placed and organized within the user interface (UI). There are several ways to integrate AI into design, and it's important to know how to position them in the app so that they optimize user experience without causing confusion or making the interface too complex. Spatial relationships directly affect user experience. For example, AI can operate independently or alongside other features while still maintaining its own space. When you understand these relationships, you can choose how to place and use AI features in a way that enhances usability without overwhelming the user.\n\n**15:11** There are six different methods for presenting AI: it can be entirely separate, alongside other features, layered, integrated with the parent feature, or in small points such as icons. These methods include:\n\n- Separate: AI operates as a separate feature.\n- Alongside: AI is placed next to other features.\n- Layer: AI overlays with another feature.\n- Integrated Parent: AI serves a major role in navigating and managing core content.\n- Integrated Child: AI operates as a secondary, smaller feature.\n- Point: AI is a small icon or widget that helps the user understand its function.\n\n**16:41** Moving on to the functional relationship, this describes the functional interactions between AI and other features in the system. AI can exist separately but still adapt to the overall content and functionality of the app at a higher level. AI can integrate with existing features to improve performance, replacing manual tasks. Understanding how AI works functionally allows us to define its role clearly in the app and design in a way that ensures the functional actions don’t conflict with one another and don't disrupt the user flow.\n\n**17:28** There are six methods to describe this functional relationship, which are similar to the spatial relationships I mentioned earlier:\n\n1. Separate: AI operates independently.\n2. Aware Of: AI exists separately but is aware of how it affects the main feature.\n3. Acting Up: AI interacts back and forth with other features, adapting data between them.\n4. Feature Incorporate: AI is incorporated as a part of an existing feature.\n5. Usage: AI adapts based on how it's used within the app.\n6. Usage Conventionally: AI communicates directly with other features in a two-way interaction.\n\nI will provide an example of this functional relationship in the code I am about to show, where AI generates a panel on the right side of the screen.\n\n**19:06** For example, the acting-up relationship means AI can be aware of and react to changes made by other features, like data syncing between two systems. In contrast, feature incorporation would mean AI is integrated as part of the overall functionality of a specific feature.\n\n**19:57** That covers the main aspects I’ve discussed so far, with three key elements for integrating AI into product design: optimizing product features, improving user functionality, and enhancing the overall effectiveness of the AI-powered system. It’s important to understand how to apply AI properly to provide clear value to the user. If we understand how to apply AI effectively, it becomes easier to design a system that brings value to the user by integrating AI in a meaningful way.\n\n**20:53** I realized I missed an example earlier, so let me go back and explain. I’ll share a few examples that I think will clarify the functional relationships we discussed. For instance, in Microsoft, there’s a tool that generates images—this operates alongside other features in a parallel fashion. There’s also a feature that sits beside the main functions of the app but doesn’t serve as a core part of the experience.\n\n**22:01** Yes, that's a good example. The functional actions and spatial relationships you presented seem to be similar to common patterns. These are just standard patterns for AI design—how to integrate an AI feature into an app or design an AI-driven app, depending on how it’s categorized.\n\n**22:31** Yes, these are patterns we often use when designing AI applications or integrating AI into a separate application or product. Essentially, they are familiar structures to help us better understand how to apply AI. You can categorize and break them down into smaller features. This part is very clear.\n\n**23:31** Thank you, Nam. Ok, next will be Hoàng and Đạt’s presentation.\n\nToday, I will introduce a topic called \"AI Button in LLM Applications.\" Before diving in, let me briefly cover the content and agenda. First, we will explore design patterns related to the AI Button. These patterns are applied in various applications. I’ll pick out the most common and understandable ones to introduce to everyone.\n\n**24:35** This presentation will revolve around using AI in digital products. These applications leverage the power of AI models to solve specific problems or assist users in tasks. When using LLMs, many may encounter the issue where the model does not provide the expected result. This happens because the model operates based on its ability to respond using the data it has been trained on. There are multiple ways to address this issue. One of the most expensive ways is to retrain the entire model from scratch, which can take a lot of time and resources.\n\n**25:15** We have a technique called **in-context learning**, which means AI can learn directly within the current context while you are using it. This technique includes few-shot learning or zero-shot learning, allowing the AI to learn without needing to be retrained from scratch. For example, you only need to provide the AI with a few small examples in the context, and it will adjust its behavior based on what is provided. Instead of retraining the entire model, this method saves a lot of time and resources while still ensuring the AI can learn from the specific context you give it.\n\n**25:52** In this case, **in-context learning** is widely used in **prompt engineering**. People provide available examples directly into the prompt, and the model learns from those examples to generate subsequent results. That's the main idea of in-context learning. Essentially, the design works like this: you have a query, then you build a prompt with the necessary examples and few-shot learning data, and you pass it through the model, which returns a result based on those examples. However, it doesn’t stop at just examples; many other factors are involved as well.\n\n**26:37** Broadly speaking, in-context learning involves feeding the context into the prompt by providing information that the model doesn’t inherently have. Since this is a pre-trained model, its knowledge is limited, so you provide additional information in the context and prompt for the model to learn during the result generation process. For instance, in medical image diagnosis, the model may not have enough specialized knowledge. Therefore, you provide that expertise into the context and prompt so the model can learn during the result generation process. That’s the core of in-context learning.\n\nNext, we have another important design button, which is **data preprocessing/editing**.\n\n**27:54** This section describes the process of preparing data for the language model (LM). As you know, LMs operate based on vector databases, using vector comparisons to find similar data points. This process often involves handling multimedia data and various types of information. To ensure optimal output, applying data preprocessing steps is crucial. For example, you can preprocess text by filtering out unnecessary details to shorten it, or with images and audio, you can remove noise or compress the data to reduce size before passing it through the language model.\n\n**29:19** Data preprocessing or editing helps the model operate more efficiently. There are many ways to preprocess, depending on the type of data or context. You perform this based on specific requirements. The next design button I want to mention is a commonly used one, though it goes by different names. I call it the **example agent**. This design is commonly seen when you want your query to pass through multiple contexts. For example, if you have a content review application, you can let that content pass through a pipeline where each agent evaluates the content from a different perspective.\n\n**30:11** One agent might evaluate the content from a writer's perspective, and another agent might do so from a different angle. After going through all these agents, there will be a final synthesis layer to combine or process those results, ultimately providing the user with a comprehensive output. This design is often seen in evaluation systems where results from different models are evaluated, and the best outcome is chosen based on predefined conditions.\n\n**30:55** The next design button is called **agentic button**. So, what does agentic mean? In the context of language models (LMs), **agentic LMs** refer to enhancing the model's capabilities. Since the model only knows what’s in its training data, we upgrade it to increase its power and minimize human intervention. This design helps the system become more automated, allowing it to operate with less human interference.\n\n**32:24** This design has several key components that help you achieve this level of automation. There are four main components: **reflection**, **planning**, **execution**, and **multi-collaboration**. Each of these components helps make your system more automated. First, let’s talk about **reflection**. Reflection involves evaluating the initial results of the model based on a specific criterion or metric to determine if the result has been optimized. If it hasn’t, the system adjusts and repeats the process, continuing to generate results until it reaches an optimal outcome.\n\n**33:06** Reflection helps reduce human intervention because, instead of producing an initial result that doesn’t meet your expectations, the system refines itself based on pre-established criteria, eventually delivering a more accurate result without manual adjustment.\n\nThe Reflection button means that it will evaluate the initial output of an AI, then assess it according to a certain standard or metric to see if the result has been optimized. If not, it will adjust slightly and run the AI again to generate another result until the optimal result is achieved. This helps reduce the need for human intervention, as if the first output is not what you expected, you don’t need to manually adjust it—the system will optimize itself.\n\n**33:42** The second button is the tool. Tools can be external, such as external APIs or functions that people code. These tools are used to allow the model to access knowledge from the outside world, real-time knowledge, or external resources that it hasn’t been pre-trained on. For example, OpenAI or Claude both support this. The model can know when to call the tool based on the description you write for the tool. The model will know how to retrieve and extract information from the tool and then return it to the LM to generate an output.\n\n**34:30** Next is planning. The planning button means that you give the LM the ability to plan, preventing the need to prompt multiple times. For example, if you have a complex task, you provide a large prompt for the LM to plan out all the steps it needs to take in a step-by-step manner. This allows it to perform smaller tasks first, which are eventually combined into a larger task. This planning design has many variations, and this is the simplest version: planning and then executing step by step.\n\n**35:10** Finally, multi-collaboration. I presented this about a month ago. Essentially, it's like having the AI excel at a particular task. You have a context, right? You divide it and pass it through to different agents. Each agent is good at its specific task, and after they complete their tasks, it passes on to the next agent. In this way, it can complete the requirement. This design heavily utilizes the divide-and-conquer principle—breaking a large task into smaller tasks and assigning each to a specialized agent. This is a design button I’ve seen being used in many places.\n\n**36:24** Those are the design buttons that I’ve seen used in many places and understand the most. I’ve finished my presentation. Does anyone have any questions?\n\n**37:10** Hoàng, can you repeat the part about planning to confirm Bảo’s comment? It’s like it reads the prompt, right? It understands your prompt first, then breaks it down into smaller tasks, and then there are workers—perhaps IDE workers or smaller prompts—to complete the task. Is that correct?\n\n**37:40** Yes, you can think of it that way. You can split the prompt, for example, in a complex task, into several smaller plans. These smaller plans will be done step by step. For instance, it executes plan 1 first, then plan 2, then plan 3. Once all the plans are completed, they are compiled somewhere or in a final component to produce the final answer.\n\n**38:06** It’s like the Zero you presented last time, right? The worker can do tasks like reading files, deleting files, modifying files, or interacting with the Internet, sending emails, and so on. So basically, agents work in this way.\n\n**38:52** Exactly. Instead of handling a massive task all at once, which requires repeated prompting, you start with a prompt that breaks the task into smaller tasks, and then a pipeline runs through each worker, handling small tasks for you.\n\n**39:23** Ok, pull up slide 14, Hoàng. Slide 14. I also see this is kind of like the Mule Automation setup that Tom created, right? The Mule button that Tom set up. I’ve finished the code, but this design and the button look exactly the same.\n\n**39:46** Yes, this is a looping process with Tom, which looks somewhat similar. It’s like planning, as Tom mentioned, where it breaks down the task into parts and handles each part. It has iterations within it, like a list of steps you described earlier. Referring back to yours, the agents can see that. What I’m seeing looks more like planning: it splits the plan upfront and then works step by step on each plan, moving through each round one by one. This one, though, works more in parallel, where they run simultaneously, produce the output, evaluate it, and then return the final result. I think I got the workflow mixed up; it’s now corrected.\n\n**42:28** Exactly, give it a try. It works like that, breaking down into different tasks. It’s more like a classification, running through each one. This is closer to multi-collaboration because it’s like a question classifier, where only one agent runs for each task. Each agent works on its specific expertise, then combines everything.\n\n**43:33** But do you think the parts like reasoning and input analysis are correct? Tom’s expert part. Specifically, for picking domains, there’s a classifier, but reasoning and input analyzers are separate agents. In that group, they’re experts, right? We consider them a group of experts, and they combine with the five agents underneath.\n\n**45:33** If we try to do everything within a single prompt, I’m certain it won’t give us the desired result. The context is too large and lacks specific examples. The main issue is that accuracy will definitely decrease because there’s too much data at once. The key is to split it into multiple layers, step by step. In reality, we need the output from the LM; we can’t hardcode it all in advance. We just want the simplest prompt so it can generate small answers that ultimately lead to a large answer.\n\n**46:59** Exactly, by breaking it down, we can identify where the problem lies and debug it. Like you mentioned, specify clearly and break it down into layers. If something goes wrong, we can fix that part. If you throw everything in at once, you won’t know where the error is, and you’ll have to fix it repeatedly.\n\n**48:43** Exactly. For example, creating an event in the calendar for tomorrow—if there’s no event at that time, it creates the event, but if there is already one, it sends a notification. If we throw in a large request at once, it will get confusing because it has to execute step by step. Breaking it into layers and testing each step will make it work better.\n\n**49:23** I'm almost certain that 99% of the time, it will get lost if it’s done in one go. However, if we split it into layers, into multiple layers, and do the tests, it will work much better. Ok, let's go. If anyone's at the office, Tom’s probably there to argue with. If no one has any more questions, thanks to Hoàng first. Now, Đạt, you’re up. Đạt, are you sharing your screen? Ok, can everyone see my screen? Yes, we can.\n\n**50:38** Today, I’m going to talk about Yelp use cases. Wait a second, Đạt, let me introduce some context first. So this time, the team will focus somewhere and search for some use cases. There are different types of use cases. The type Đạt is sharing is where we look at how startups or enterprises are applying AI to solve specific problems. It could be something completely new, like a greenfield, or it could be optimizing the current workflow of their system. They will write use cases and report updates monthly. In addition, there’s another type of use case, which involves tuning to boost the development on the tech side. They will also report that part somewhere in tech. We’re testing this for about two weeks. This is the first report, and it’s about Yelp. Yelp is a startup, right? Now, Đạt, introduce how they are applying AI.\n\n**52:01** Yelp is a company that provides software to stores and businesses that want to offer services like fast delivery, restaurants, or basic utilities. Yelp sells the software for those tasks. I’ll share a bit about how they use AI in their tools.\n\n**53:00** Before this, they had a machine learning system, but now they’ve added AI to improve the accuracy of their recommendations. Yelp has many types of reviews on its system, like restaurant reviews, which may not always be good. Based on those reviews, they do some text editing to compare whether the results are spam or legitimate. AI is used here in several ways. First, they use AI to create datasets to train a model to assess whether a review is spam or a good/bad review. They use AI to generate datasets based on LinkedIn. From what I’ve read, they use techniques like Zero-shot and Few-shot learning to create these datasets. They use some models from Hugging Face and then classify the reviews as good or bad. This is one use case where AI is applied in text editing.\n\n**54:18** Now onto the second use case—they use the Clip Model. The Clip Model primarily processes images. What does that mean? It means that based on reviews... wait a minute, let me find the reference... Ah, Clip processes two things: one is the caption of the image, and the other is the image itself. Through Clip, it can understand the context of the image. Yelp uses Clip for tasks such as when someone goes into a restaurant or pub and posts reviews or captures images of the place. For example, before applying Clip, it couldn’t identify if there were waffles in a dish; it could only identify fried chicken. After applying Clip, it can now recognize both fried chicken and waffles. Essentially, it uses Clip as part of AI to process images, captions, and convert images into vectors to compare them. So, these are the two use cases for Yelp.\n\n**55:38** These two use cases are applied in situations where you have many reviews, and you can summarize them into a highlight review. Based on the information converted into vectors, it can annotate what the images are conveying, and what they are supporting. Just give it a moment, it will highlight it for you. It understands the context of the image and can annotate it accordingly. This is the use case for how AI is used in image summarization.\n\n**56:15** Earlier this year, Yelp released the Yelp Assistant. Based on their existing platform, they were able to create a chatbot that reviews highlights like this. You simply ask, and it recommends something for you. It's as simple as that. Additionally, I noticed a use case from 2020 when the trend of short review clips started becoming popular. Yelp had a dataset specifically for that purpose. They mentioned that they are about to release something, as Tom referred to, that can convert text to speech. Based on the review dataset, they might support creating short video clips to describe a restaurant.\n\n**57:45** Based on reviews or videos posted by people, Yelp could generate a script and run it through AI to automatically create a video about a restaurant. That’s the use case. It’s simple as that. Ok, going back to the first question, this use case is essentially using AI to label data, right?\n\n**58:35** Ok, so it checks whether the comment is negative or positive, right? That’s one example. The second one is using the Clip Model, correct? It’s similar to Vision but more live, also for labeling, right? Like with Plot, labeling for images. So, these two use cases are applied for what?\n\n**59:18** I think there's an interesting point that hasn't been mentioned yet, which is the story about having a ready-made dataset. For instance, when someone leaves a review or gives a rating, based on these short clips, Yelp could generate an intro video for the restaurant. It uses AI for that. I think they use AI to write the script and then pass that script to an AI voice to narrate. But where do they get the images from? How do they get the video content?\n\n**59:57** From the review, when someone comes to review, they will have a video to review. Ok, so it's automatically generating an advertisement, right? Yes, for TikTok or similar platforms, summarizing user reviews. Sounds pretty creative. Yeah, I guess you guys have confirmed what Bảo mentioned, right?\n\n**01:00:07** Yeah, this one is about the caption, and it's mostly correct. You're right, I think the initial purpose of this use case was for recommendation. Before they had AI, they already had a hybrid recommendation model in place. Basically... I think with this new AI, they will likely replace the old model. One interesting point that wasn't mentioned much is business messaging. I think it’s based on, say, the top 50 reviews or top 50 interactions—how are the ratings, and if the reviews are good and the ratings are good, then the business messaging will also be good. But Yelp didn’t bring up this topic, and we can’t blame them for that.\n\n**01:00:51** Does anyone have any questions for Đạt? This is his first presentation. Đạt mentioned he’s working on adding more, probably for enterprise too. But I’ve seen Viettel, FPT, and VNG, and I’m still not sure how they are doing things. Đạt said some of FPT's coding tools are kind of lame.\n\n**01:01:41** Haha, is it just a continuation of a previous version? Yeah, it’s not great. It’s a bit rough and underdeveloped. Are we done with that? I guess so. Ok, Đạt. Today we’ve covered Yelp and Tech Linh, so maybe next week or the week after that, if time permits.\n\n**01:02:01** Let's do a demo real quick, Đạt. Could you demo something for us? What about a bot that can handle questions or understand short code from a developer’s perspective? Or something like an auditor checking the code quality? Could you demo the workflow or the bot you’re working on with that diff you mentioned? Please turn on the screen, Đạt.\n\n**01:03:01** So this is a project I’m working on for joining the AI Club. I’m pretty new at this, so if the project looks rough, please bear with me. The basic workflow is that I take a query and extract the URL of a repository. Here, I reused Tom’s scraper, but it didn’t fully meet my needs, so I created my own local scraper to fetch all the content from the repo. However, that takes too long and generates too much data. As of now, I haven't found a way to add it to the context unless I use knowledge retrieval. But to use knowledge retrieval, I have to prepare it in advance; I can’t select the repo directly.\n\n**01:05:45** Tom’s scraper doesn’t capture the content of the files, so I haven’t been able to draw a diagram yet. I might use it for the diagram later, I’ll test it out. This scraper only fetches the content from the root directory and some doc files. Those files might not answer Huy’s question accurately. Let me try it; I have my full setup ready offline. The content is already prepared, not online. This was generated directly, so it doesn’t have it either.\n\n**01:07:07** This scraper fetches the full content, so it’s more complete. Let me try asking questions like Huy’s or Hoàng’s. Let’s try BC chat and ask a question there. Do you have it? Ah no. Maybe the context is too large, and I haven’t figured out how to integrate it properly into the knowledge retrieval part.\n\n**01:09:19** The retrieval process is very optimized. This text file has tens of thousands of lines, tens of thousands! Let’s open it and see. Are you using a mini machine? Try switching to a more powerful machine to see if it runs better. The mini machine is a bit weak. Two million words... how is it even handling that? I think you’d need a dedicated server to run it efficiently. I’m curious how it's even running; we’re talking about 29U words, as we saw. Multiply that by 4, and the number is huge. The size... Let's follow up and see. Ok, so you’re working directly from the context, right? You’re querying like a typical query vb, rather than feeding all the data into the context.\n\n**01:10:57** Right, exactly. I’m not sure how the retrieval in this diffy system works. I don’t know if it’s retrieving the correct data or if it’s retrieving at all. I haven’t been able to trace it, but I have a tracing tool that I can test later to see how it works. But the idea is that if the retrieval works like this, it probably won’t give accurate results. You’re unsure about how much data it's running, right? It seems to only prefer 2-300 items, and that’s not enough data for these kinds of tasks. This requires at least several hundred data points. So yeah, this is still a work in progress.\n\n**01:11:35** Just joking—there’s always the AI Club at the company! Oh, so is this the full version, or is it the fixed one? If it’s fixed, demo it for us in the office, and try to leave it for me. OK, let me see. It still hasn’t built, so people are just watching for now. The build seems to have some issues—can everyone see the screen?\n\n**01:13:08** So, this week, as I mentioned last week, I will upload the sync.Map article. I think it's really useful, with details that give people using Go a general overview of maps. Regarding sync.Map, let's first go over the context. When writing maps, especially concurrent maps or concurrent operations, before version 1.16, it wouldn’t show any errors, but it wasn’t safe either. From version 1.16 onward, it throws an error like this. So to solve this issue, people usually write maps with a sync package, like using manual sync.RWMutex.\n\n**01:13:56** Besides that, there’s another option called sync.Map. Later, I’ll explain why this option exists and what its use case is. This sync.Map was created so that you don’t have to worry much about using mutexes to lock data for synchronization. You just use it. It’s as simple as this, and it’s friendly—just like using a map to check values. For example, when you load a key with a value, if it's available, it returns true; otherwise, it returns false, just like a regular map.\n\n**01:14:38** Additionally, it has several handy functions. For example, version 12.23 has `clear` to clear everything, `load` to get a value, `store` to update or store a key, and so on. Besides writing concurrently, when you range (loop) over a map, race conditions can also occur. However, with sync.Map’s range function, it handles that, so you don’t have to worry about it. It doesn’t behave like a typical range function. However, it doesn’t give you a fully consistent snapshot. When you first enter, the snapshot may not be updated. So, during this, you have to change your writing method, but at least it won’t error like this.\n\n**01:16:06** Now, let’s go over how it works. When you write and define the map, it’s structured with two maps. At this point, you might be thinking, “Wow, this sounds like it’s heavy on RAM and memory!” There’s a Read-Only map and a Dirty map. From this, you can infer that values, when written, will be updated in the Dirty map. It just keeps updating there, while the Read-Only map. \n\n**01:16:46** The Read-Only map will always be used when you're reading. Meanwhile, the writes will always be made to the Dirty map. As for the underlying flow, we’ll look at the chart in a moment to better understand it. Both of these maps have a common point: they both use a pointer called an entry. Pay attention to this part to make the flow easier to follow. For example, when you add a new entry, it will be added to the Dirty map, and both will point to this entry. This works as a flag that indicates the map has been changed. So, at this point, the Read-Only map is no longer the most up-to-date version. The system will know that the Dirty map is the one to read from.\n\n**01:17:27** This diagram shows that, for example, when you update a value, since it’s using a pointer underneath, you only need to update the pointer itself, not each value as you would in a traditional map. To achieve this, the system implements a mechanism that defines three states for the entry pointer. The first state is the **normal state**, meaning that the old values in the map are still intact and can be used, without any issues. The second state is **amended**, meaning that the entry has been modified. And the third state is the **delete state**, where an entry has been deleted from the map, but it hasn’t been completely removed. It’s still held in a transitional state, and the entry pointer is moved to a new position, but it hasn’t been fully removed yet.\n\n**01:18:59** The pointer `entry` is assigned to the `new entry`, but it hasn’t been removed yet. The `expired state` refers to complete deletion, like a hard delete, meaning the entry is completely removed from the map. To help visualize this, you can refer to this flow: for example, at the beginning, the map has a `key1` and `value1`, and at this point, the `Dirty map` has nothing, meaning nothing has been added or changed yet. Then, if you add a `key2`, it will be added to the `Dirty map`, and at this point, the map is marked as `amended` because a `flag` indicating `amended` is set here.\n\n**01:19:40** Afterward, when you delete a `key`, the map will be assigned a `new entry`, right? The same thing happens on the other side, as it is also assigned a `new entry`, similar to the previous diagram. In essence, you’re only updating the pointer without having to update the values themselves. Then, after completing the deletion, to promote the `Dirty map`, you must update it through the `Read Only map` so that the `Dirty map` returns to a `new state`, like resetting it to the original state.\n\n**01:20:18** Similarly, when adding a new `key3`, after the state has returned to the `new state`, and you add `key3`, the system identifies that the previous entry has been deleted entirely. This means that next time when it compares with the `Dirty map`, it knows that the `value1` has been deleted and no longer exists. At this point, the `Read Only map` will only contain `key2` and `key3`.\n\n**01:20:51** Due to this, `sync.Map` does not have a `len` function for users to utilize. This is because, if you used the `len` function here, it would not account for the actual values, as it would count even those that have been expired or deleted. As you can see, because `sync.Map` is structured this way, its use case is recommended for scenarios that require more reading (`read`) than writing (`write`). If you perform a lot of `write` or `delete` operations, just imagine the pointer being used continuously, and there’s even an issue reported by the Go team that this map is never garbage collected.\n\n**01:21:36** Later, the Go team confirmed that this `sync.Map` was designed primarily to support some of the internal Go Library processes. If you find it handy because of its user-friendly functions, you can use it, but for use cases that involve storing (`store`), updating, or deleting often, it’s not recommended, as it may slow down the system.\n\n**01:22:24** That’s about it. I’ve written some code based on this topic, and there’s a blogger who shares detailed posts on this subject, so you might want to follow them. Oh, what’s the topic, Phát? Show me the post again. Ah, `sync.Map`, right? `Sync.Map`. Does it differ from what you just passed in? What’s different? I think it does. The point is that I remember, depending on the community, people might have different use cases. For instance, if someone wants to implement something specific, they can adapt it as needed.\n\n**01:23:30** You can see that some people add an extra layer on top for their own use cases. For example, some want to implement generics on `sync.Map`. This is partly because of the linking issue I mentioned earlier, where the map isn’t garbage collected. That’s the problem. The Go team has already confirmed that this behavior is intentional, and they won’t fix it. They’re not going to change it, right? So now, what the community does is figure out how to work around it. They like how easy `sync.Map` is to use, with those nice functions, so they just add another layer to customize it further, making it usable for their specific needs.\n\n**01:24:07** Why are we discussing this old clip now? Oh, it’s just an insight for people to use. This use case can be applied to enterprise environments too. For example, in enterprise projects, if we use `map` and need concurrency, typically, people would write a custom `struct`, add a `mutex`, and then write everything themselves. But `sync.Map` is handy, as I showed earlier, with functions that follow certain standards. If you want to `load`, you have to call a specific function, and everything is structured that way, making it more reliable.\n\n**01:24:50** People usually write a custom `struct`, then add a `mutex`, and start writing all the necessary logic themselves. Meanwhile, `sync.Map` is really handy. As I showed you earlier, it has several functions that adhere to a specific standard. If you want to `load`, you must call a specific function. This structure ensures consistency. However, you still need to be aware of the trade-offs when using `sync.Map`, making sure to apply it correctly in the right context. Right, so you have to understand the proper workflow and `map` usage.\n\n**01:25:26** Phát: Yes, about `Map`. Ok, thanks, Phát. Now, let’s quickly get through a few things. Thành, I need about 10 more minutes from the team. It’ll take a bit more time because I’ve received a total of 11 submissions for the test. Not many have attached images, so some of you can review them. Our deadline is set for the 20th, which is next week. I think earlier, I mentioned the 27th, or was it 26th or 27th? Anyway, that's the deadline. So, please review everything this week and get the submissions ready. This test is important because the market is shifting significantly, and there’s a big change in the demand for software roles.\n\n**01:26:15** Of course, the demand is still there, but the volume has decreased. That's why I refer to it as a shift in the market demand, similar to what happened around 2014, where it’s like things are changing all over again. New technology is coming out, new opportunities, new markets, and emerging potentials. So, this test will be essential in helping us assess, especially when it comes to team culture. We’re taking this opportunity to evaluate the team, particularly to see how the research study team and the consulting team are becoming more distinct.\n\n**01:27:36** There’s a clear distinction between the two teams now. Like I mentioned in the post on Notion about two weeks ago, this distinction is becoming more pronounced. In the future, there will be more specific policies related to different benefits between these two teams. But for now, as you can see, OGIF is gradually becoming a session where we report on all the studies that the team has been reviewing and reporting back on. Some of those reports might be added later, and you can see that some team members have been picking up new knowledge and sharing it.\n\n**01:27:36** Gradually, it's becoming clearer that we want this differentiation to become more distinct over time. And there will be clear policies around this. So, those who enjoy diving deep into topics and taking them to the level of MVP, or applying them in actual projects, or going deeper into knowledge, they will get different benefits. Those who don't necessarily want to focus on study-related topics can continue working on projects as usual, but there will be other issues involved, which I've listed in the Notion link from two weeks ago. Everyone should review that link to understand the direction we're going in. This test is designed to assess how well you can keep up with new knowledge and how aligned you are with the culture during this time of significant changes.\n\n**01:29:20** Because of these goals, I’ll be the only one grading this test. None of the other team members will be grading. Everyone has to do it, and I’ve set the standard for this. So, the important thing is that everyone does the test themselves. Even if the quality isn’t the best, it’s fine. I’ll just give it a lower score, but as long as it’s completed, you’ll pass. The immediate outcome I see from this is that I’ll group the results into two clusters.\n\nThe Foundation team and the Lab team, they’re still the core teams we’ve had for the past eight or nine years. This is the main announcement. If you’ve finished your test and feel like you can improve based on what I’ve just said, the Foundation team and the Lab team will still be prioritized in various aspects. So, if you feel like you did the test carelessly, please take some time to do it thoroughly. Focus on two things: the culture aspect and the knowledge.\n\n**01:29:56** The immediate result you’ll see is that I’ll group the results into two clusters. The Foundation team and the Lab team will remain the core of our team from now until the next eight or nine years. That’s the main announcement. Out of these 11 submissions, if anyone feels they can improve after hearing what I’ve said, please focus on making it better, especially since the Foundation and Lab teams will be prioritized more in different areas. So, if you feel like you’ve done it hastily, take the time to refine it. Check two things: the culture aspect and the latest, hottest topic cluster, which right now is LLM.\n\nBut in reality, our team still covers many different areas. We still have people focusing on design, and others still working on Go, right? Blockchain might have moved a bit out of the spotlight, and the market is going sideways, but consulting still demands a lot of expertise in those areas.\n\n**01:31:46** Regarding mini apps for Telegram, they quickly clone them, and now the business logic (BL) and tech (TCH) approaches have shifted a bit from the early days. But for consulting, we can still use them as usual, or we can view them from a different angle, where they become a new asset class. As developers, we should look at how these affect our workflow and how we manage assets.\n\n**01:32:29** That’s the matter concerning the test. Pay attention to that. Second, as mentioned earlier, regarding team direction and numbers, I mentioned the Notion link I sent earlier. The Foundation team, which started over again, initially had just three people, and then gradually it grew to four, then five. We added Quan, Hiếu, and others. Initially, it was just three of us, but now the team is much stronger. With 40 people, all highly skilled, we’ll certainly move faster. That’s the general overview, so everyone should be aware of the current situation.\n\n**01:33:12** Third, Huy Nguyễn, once you’re done, next week please take a look at the ICY numbers. Earlier, you mentioned the numbers were starting to grow, so we’ll need to review and balance those out. For this task, Huy and Thành, please take charge and ensure it’s handled properly. Thành also has an additional task, which is to review benefits for the Lab team members and propose something. It could be considered as a payon, but it won’t go through the normal channels, as there will be a different mechanism for this.\n\n**01:33:52** But the Lab team members will have that, and everyone’s familiar with it. Lastly, regarding the LLM, in the current question list, there’s an important question about how to use LLM externally and how to adapt it. Emphasize that question, as it’s about knowledge discovery. The test question is not only about using it but about all the tools our team currently uses. When some people use them effectively and others less so, it creates a very clear spectrum—those who are weaker remain weaker, and those who are stronger stand out much more.\n\n**01:34:38** We want to raise the standard. We want to shorten that spectrum, to make it as compact as possible. Right now, the gap is too wide. Beyond using tools for discovery, this question also asks us to look at how our field of work can apply these tools to elevate our competencies and make us more productive. That’s the whole issue, so everyone should confirm whether what they’ve done is correct or not. It has a deeper meaning than it seems.\n\n**01:35:20** Lastly, to wrap up today’s session, Thành, for the next OGIF meetings, apart from diving deeper into use cases, there are things Tom has done related to building the structure of an LLM app. We could take that and analyze it. Let’s break it down and dive deeper into it.\n\n**01:35:56** Hopefully, everyone passes the test so we can all have a good time. Next week, there will be another test. Next week, Minh L., can you do a demo? Continue with the finite state machine, FSM. As part of our focus on foundational technologies like blockchain and AI, the key point is that engineers will have a different path forward. The goal is to understand how large systems operate. In the future, if you’re not the one handling data manipulation—AI will do that for us, we won’t need to design things ourselves or do junior-level tasks anymore.\n\n**01:37:35** The only way to become senior is to understand the issues and work on architecture. The finite state machine plays an important role, especially in scaling, something we’ve talked about a lot. Minh has read through it and understood the direction we’re aiming for. So, we need to do a comparison between the types of general servers it covers. State machine-based servers versus event-based servers. Then create a sample to show how it’s modeled, implemented using Erlang. Erlang already has the frameworks for it.\n\n**01:39:01** This topic will proceed when Minh Lưu is ready. If it’s not next week, it could be in two weeks. I suggest that the backend team and the senior team gather together, and if there’s anything, confirm it beforehand. This topic is critical for software analysis and design. It’s a very important session. Up until now, we’ve only talked about modeling and doing C4 diagrams, but Erlang is the language that goes deepest into this area. Most people don’t know it entirely. We don’t necessarily need to learn Erlang, but we can look at how they design and build systems to handle this area properly, as they already have frameworks available. We just need to plug them in and use them.\n\n**01:39:37** Speaking of which, October 20th is a Sunday, and Mỹ, Ngọc, and Giang have already posted about it. The ladies are going out on that day, and for those not in Saigon, the team representatives will wish everyone prosperity. It seems like wishing prosperity is the most appropriate thing to say in this situation. Any other wishes might not fit as well. Alright, so if anyone wants to join, register with Mỹ to book a table and plan accordingly.\n\n**01:41:19** Thành, in the upcoming meetings, structure things into talks. Then set the goal for that. Our team now has a Builder Club as well. I’ll look into how the team members who used to work on Super Bit and console are stabilizing things, and I’ll restructure afterward. This time, it seems like we’ve had a good rest. Alright, does anyone have any questions about the test? If not, we’ll wrap up here. Alright, goodbye everyone, see you next week. Thanks, Thành, and thanks to everyone.\n\n---\n","title":"OGIF Office Hours #28 - Golang sync.Map, Generative AI UX design patterns, Yelp's AI use cases, Design patterns in LLM application, and Dify github analyzer","short_title":"#28 Go sync.Map, AI UX, Yelp AI, LLM Patterns, Git Analysis","description":"OGIF Office Hours #28 covered Go Weekly #16 by Phat on sync.Map concurrency, Nam's Product Commentary #4 on Generative AI UX design patterns, Dat Nguyen's presentation on Yelp's AI use cases including recommendation systems, Hoang's discussion on LLM application design patterns, and Cat's demonstration of a Dify-based Git repository analysis tool.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Mon Oct 21 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/28-20241018.md","slugArray":["updates","ogif","28-20241018"]},{"content":"\n71 minutes\nRecorded Apr 19, 2024\n\n## Summary\n\n1. **Generative AI Discussion**: There is a significant focus on Generative AI, its applications, and its implications for the team's projects. The discussion includes technical aspects of AI and machine learning, including deep learning and neural networks.\n\n2. **Community and Learning**: Han discusses community involvement and learning initiatives, for a corporate or organizational context. This includes mentions of learning about finance and technology trends.\n\n3. **Project Development and Collaboration**: Various projects and collaborations are mentioned, including work with external parties like Discord and a focus on community and top-level discussions about recent work and updates.\n\n4. **Future Plans and Strategies**: There is talk about future strategies and plans, including tokenomics, the use of NFTs (Non-Fungible Tokens), and building a supportive community through innovative means like blockchain technology.\n\n5. **Interactive Components**: A live discussion on topics like liquidity, market dynamics, and specific case studies related to technological applications in finance.\n\n6. **Technical Deep Dives**: Detailed explanations are provided on topics like liquidity in markets, the role of different market players, and the use of technology to enhance market operations.\n\n## Transcript\n\n> The transcript formatting and language accuracy is a WIP, so it might look a little weird. This will be improved in later iterations.\n\n![](assets/3-ogif-office-hours-0419_0419-1_compressed.mp4)\n\n```\n00:00:00: 1-baddeed_0: bình lao mình làm phải rồi chắc là đổ thiếu thiếu nguyên thiếu biên à\n00:00:12: 1-baddeed_0: chắc đổ mẹ đẹp thiếu thứ hai thứ hai thứ hai thứ hai mình chờ mình chờ à à à à à à à à à\n00:00:34: 1-baddeed_0: tổng\n00:00:42: 1-baddeed_0: hôm nay mình sẽ có bốn chủ đề nhé hôm nay có ba chủ đề đã có một chủ đề chính là quan trọng nhất\n00:00:56: 1-baddeed_0: hai chủ đề là cái study của anh với cô tin làm đây có chủ đề là anh không chứ của anh chậm anh\n00:01:04: 1-baddeed_0: có toàn của nhật của những bức toàn những tài khoản nhớ rồi cho tôi toàn đây đã có Nguyên Nguyên đã cho\n00:01:12: 1-baddeed_0: thuyềnкой con bên sana bên thôi rồi chúng mình không\n00:01:14: 1-baddeed_0: phải bắt мест\n00:01:24: 1-baddeed_0: bí thư\n00:01:34: 1-baddeed_0: ok\n00:01:36: 1-baddeed_0: thương\n00:01:38: 1-baddeed_0: cầu\n00:01:38: 1-baddeed_0: bนะคะ\n00:01:38: 1-baddeed_0: 2017\n00:01:39: 1-baddeed_0: 2017\n00:01:40: 1-baddeed_0: 2016\n00:01:40: 1-baddeed_0: 2017\n00:01:40: 1-baddeed_0: ytr\n00:01:40: 1-baddeed_0: ytr\n00:01:41: 1-baddeed_0: ytr\n00:01:41: 1-baddeed_0: ytr\n00:01:41: 1-baddeed_0: ytr\n00:01:42: 1-baddeed_0: Chúng mình vô tiết mục chính nha.\n00:01:44: 1-baddeed_0: Bây giờ là 5h10.\n00:01:46: 1-baddeed_0: Chào mừng anh em đến buổi khuyên cuối tuần.\n00:01:49: 1-baddeed_0: Hy vọng giờ này mọi người đã đi một hết.\n00:01:50: 1-baddeed_0: Đóng laptop, chuẩn bị nghỉ.\n00:01:54: 1-baddeed_0: Nghỉ cuối tuần là vừa.\n00:01:56: 1-baddeed_0: Hôm nay mình sẽ có 3 topic chính.\n00:01:59: 1-baddeed_0: Trong đó 1 topic sẽ diễn ra thường xuyên.\n00:02:01: 1-baddeed_0: Đang đang trong quá trình tụi anh đang học về tiền và dòng điền.\n00:02:07: 1-baddeed_0: Chủ đề cũng thường xuyên xuất hiện.\n00:02:10: 1-baddeed_0: Một chủ đề hôm nay sẽ bút cho An.\n00:02:12: 1-baddeed_0: An làm về Trilative AI, Discord, các việc năm trước ở đây.\n00:02:16: 1-baddeed_0: Và một xíu thông tin về community, top nói chung.\n00:02:21: 1-baddeed_0: Những công tác mới nhất.\n00:02:23: 1-baddeed_0: Cuối cùng mình sẽ kết quốc tuần.\n00:02:26: 1-baddeed_0: Ngay chỗ này.\n00:02:27: 1-baddeed_0: Rồi, thì chắc là...\n00:02:29: 1-baddeed_0: Để bắt đầu trước thì chắc là mời An đi vô đúng trọng tâm.\n00:02:33: 1-baddeed_0: An lên present một tí.\n00:02:35: 1-baddeed_0: Câu chuyện của ngày hôm nay là...\n00:02:38: 1-baddeed_0: Hồi thứ 6 tuần trước, thứ 7 tuần trước.\n00:02:41: 1-baddeed_0: An có đọc đúng.\n00:02:42: 1-baddeed_0: Đọc được một cái bài.\n00:02:43: 1-baddeed_0: Mà anh cảm giác là khá relevant với những chuyện team mình đang làm.\n00:02:47: 1-baddeed_0: Vì vậy...\n00:02:49: 1-baddeed_0: Vì vậy mà mới...\n00:02:52: 1-baddeed_0: Quyết định là nhờ An coi thử có thể tóm tắt hoặc là coi ứng dụng.\n00:02:56: 1-baddeed_0: Hay là lại được với cái chủ đề này không.\n00:02:57: 1-baddeed_0: Chủ đề này nó cũng có hẹn.\n00:02:59: 1-baddeed_0: Chủ đề nó cũng không quá mới.\n00:03:02: 1-baddeed_0: Không quá cũ.\n00:03:02: 1-baddeed_0: Nhưng mà vì một đội của team như Discord.\n00:03:05: 1-baddeed_0: Thì nó làm trò gì đó với Trilative AI.\n00:03:09: 1-baddeed_0: Thì...\n00:03:10: 1-baddeed_0: Nên nhờ An dành khoảng 5 phút.\n00:03:12: 1-baddeed_0: Chỉ sẽ đánh giá góc nhìn của An trong phần này trong bữa nào.\n00:03:14: 1-baddeed_0: Ha?\n00:03:15: 1-baddeed_0: Rồi xin mời An lên sáu.\n00:03:27: 1-baddeed_0: Rồi đúng rồi.\n00:03:28: 1-baddeed_0: Thứ 2 đi rồi.\n00:03:30: 1-baddeed_0: An ơi nghe không em?\n00:03:40: 1-baddeed_0: An chật đâu nhở?\n00:03:42: 1-baddeed_0: Anh làm gì mà làm chật dùm các?\n00:03:50: 1-baddeed_0: Ủa gì em?\n00:03:57: 1-baddeed_0: Sao em ổ? Em ổ là trái dấu án em ơi.\n00:03:59: 1-baddeed_0: Nó...\n00:04:00: 1-baddeed_0: Nó scale em ơi.\n00:04:04: 1-baddeed_0: Thôi...\n00:04:10: 1-baddeed_0: Lên đấy.\n00:04:11: 1-baddeed_0: Nước đây Mystia...\n00:04:20: 1-baddeed_0: Do cái này khách hàng cho nên nói sẵn ai đi.\n00:04:26: 1-baddeed_0: Cái này, he he,\n00:04:26: 1-baddeed_0: aker,\n00:04:27: 1-baddeed_0: thử đi được합니다.\n00:04:29: 1-baddeed_0: Anh thử đi.\n00:04:30: 2-cor3_co_0: Ok, chủ đề hôm nay là Generative AI, sao là mọi người cũng nghe thường xuyên về nó rồi.\n00:04:30: 1-baddeed_0: Còn mấy người đ共 ấy không?\n00:04:30: 1-baddeed_0: Bởi gọi chị...\n00:04:31: 1-baddeed_0: Có hai cái gì á\n00:04:32: 1-baddeed_0: haven't we done yet?\n00:04:34: 1-baddeed_0: Chỗ này nó xinform thぁm입니다.\n00:04:35: 1-baddeed_0: Vậy cả người chơi nhau69 thầy mẹ,\n00:04:38: 1-baddeed_0: anh kêu an đi.\n00:04:39: 1-baddeed_0: Ừ, kênh này ban âm đi Whether or not...\n00:04:47: 2-cor3_co_0: Vừa có đọc một bài của tôi\n00:04:49: 2-cor3_co_0: Discord\n00:04:50: 2-cor3_co_0: Nó là cái trò gì đó\n00:04:52: 2-cor3_co_0: Nhưng mà chủ yếu là cái process của nó\n00:04:55: 2-cor3_co_0: Từ lúc mà\n00:04:56: 2-cor3_co_0: Có ID tới lúc mà\n00:04:58: 2-cor3_co_0: Rồi sản phẩm\n00:05:00: 2-cor3_co_0: Cho user của nó\n00:05:02: 2-cor3_co_0: Thì nó sẽ coi những bước nào thôi\n00:05:04: 2-cor3_co_0: Cũng không phải là ứng dụng gì\n00:05:06: 2-cor3_co_0: Phùng khiếp của thằng\n00:05:07: 2-cor3_co_0: Giờ\n00:05:08: 2-cor3_co_0: Thì nó là kiểu\n00:05:11: 2-cor3_co_0: Mọi người thấy slide không vậy\n00:05:16: 2-cor3_co_0: Ok ok\n00:05:22: 2-cor3_co_0: Ừ\n00:05:26: 2-cor3_co_0: Thấy chưa thấy chưa thấy chưa\n00:05:37: 2-cor3_co_0: Ok\n00:05:40: 2-cor3_co_0: Thấy slide chưa\n00:05:43: 2-cor3_co_0: rồi\n00:05:47: 2-cor3_co_0: thật ra cái bài article của tụi nó\n00:05:50: 2-cor3_co_0: cũng chả có gì nhiều đâu\n00:05:51: 2-cor3_co_0: nên là chắc là sẽ chen vô\n00:05:54: 2-cor3_co_0: tí để mọi người biết\n00:05:55: 2-cor3_co_0: cái Centrally Trip AI\n00:05:57: 2-cor3_co_0: tụi nó hay nói là cái gì thôi\n00:05:59: 2-cor3_co_0: có cái base trước rồi\n00:06:00: 2-cor3_co_0: mới biết là ok tụi nó xài nó để làm cái gì\n00:06:04: 2-cor3_co_0: thì\n00:06:05: 2-cor3_co_0: cái agenda hôm nay là\n00:06:09: 2-cor3_co_0: Centrally Trip AI 101 thôi\n00:06:11: 2-cor3_co_0: đó là cái kiểu một cái tám tác nhỏ của cái process mà tụi nó sử dụng Generative AI\n00:06:17: 2-cor3_co_0: để làm cái quá trình mà tụi nó apply cái Generative AI vô cho mấy cái user,\n00:06:26: 2-cor3_co_0: mấy task của user hoặc là mấy cái use case của tụi nó.\n00:06:31: 2-cor3_co_0: Thì Generative AI 101 là,\n00:06:33: 2-cor3_co_0: Gần đây thì nghe nó thôi\n00:06:36: 2-cor3_co_0: Nhưng mà cái thằng đó\n00:06:37: 2-cor3_co_0: Nó là một phần\n00:06:40: 2-cor3_co_0: Trong cái\n00:06:41: 2-cor3_co_0: Nguyên cái bức tranh của tụi AI\n00:06:44: 2-cor3_co_0: Thì AI là\n00:06:45: 2-cor3_co_0: Một cái\n00:06:46: 2-cor3_co_0: Kiểu\n00:06:49: 2-cor3_co_0: Một cái nhánh của thằng\n00:06:52: 2-cor3_co_0: Computer Science\n00:06:54: 2-cor3_co_0: Thì nó để\n00:06:55: 2-cor3_co_0: Giả lập lại những cái hành vi và suy nghĩ\n00:06:57: 2-cor3_co_0: Giống như con người\n00:06:58: 2-cor3_co_0: Thì\n00:07:01: 2-cor3_co_0: phát triển\n00:07:03: 2-cor3_co_0: hơn tí\n00:07:06: 2-cor3_co_0: thì nó có trong\n00:07:07: 2-cor3_co_0: thằng AI sẽ có một cái gọi là machine learning\n00:07:10: 2-cor3_co_0: machine learning là thằng\n00:07:11: 2-cor3_co_0: tiếp theo của\n00:07:13: 2-cor3_co_0: trong một cái\n00:07:15: 2-cor3_co_0: sub-set nhỏ trong cái thằng\n00:07:17: 2-cor3_co_0: AI\n00:07:18: 2-cor3_co_0: thì machine learning là\n00:07:20: 2-cor3_co_0: nó sẽ là nó build những cái model\n00:07:23: 2-cor3_co_0: để nó\n00:07:24: 2-cor3_co_0: để cho máy có thể học được\n00:07:31: 2-cor3_co_0: và nó có thể đưa ra những cái\n00:07:33: 2-cor3_co_0: prediction\n00:07:34: 2-cor3_co_0: về\n00:07:37: 2-cor3_co_0: kiểu như là\n00:07:40: 2-cor3_co_0: một cái programming bình thường\n00:07:42: 2-cor3_co_0: thì mình sẽ đưa ra những cái\n00:07:44: 2-cor3_co_0: những cái rule\n00:07:47: 2-cor3_co_0: những cái quy chuẩn cho thằng máy\n00:07:49: 2-cor3_co_0: nó làm theo y chang vậy thôi\n00:07:50: 2-cor3_co_0: và ra quýt bá y chang\n00:07:52: 2-cor3_co_0: input vậy, output vậy\n00:07:54: 2-cor3_co_0: nó sẽ không biết được\n00:07:56: 2-cor3_co_0: nó không có kiểu là\n00:07:57: 2-cor3_co_0: kiểu unstructure\n00:08:00: 2-cor3_co_0: Bây giờ data, mình sẽ có tập input, đi qua một cái process thì nó ra một cặp output cố định,\n00:08:10: 2-cor3_co_0: thì đó là một programming bình thường của mình.\n00:08:12: 2-cor3_co_0: Còn machine learning, đi qua model thì nó ra một cái output mà nó không xác định trước.\n00:08:20: 2-cor3_co_0: nó có thể là cái kéo bút nó khá là rộng\n00:08:24: 2-cor3_co_0: và\n00:08:24: 2-cor3_co_0: nó phải phụ thuộc vào cái\n00:08:27: 2-cor3_co_0: mô độ mà mình training\n00:08:29: 2-cor3_co_0: tập data mình training\n00:08:31: 2-cor3_co_0: thì đó là cái machine learning\n00:08:33: 2-cor3_co_0: thì trong\n00:08:37: 2-cor3_co_0: machine learning sẽ có rất nhiều cái\n00:08:39: 2-cor3_co_0: loại machine learning\n00:08:41: 2-cor3_co_0: như là\n00:08:42: 2-cor3_co_0: supervised, unsupervised\n00:08:45: 2-cor3_co_0: semi-supervised gì đó\n00:08:47: 2-cor3_co_0: rồi deep learning, natural network\n00:08:49: 2-cor3_co_0: thì đó là\n00:08:51: 2-cor3_co_0: mấy cái loại\n00:08:53: 2-cor3_co_0: trong những cái nhánh nhỏ\n00:08:56: 2-cor3_co_0: trong cái thằng machine learning\n00:08:57: 2-cor3_co_0: thì sau đó\n00:08:59: 2-cor3_co_0: cái thằng phát triển\n00:09:01: 2-cor3_co_0: mà được nhiều người biết tới nhất\n00:09:03: 2-cor3_co_0: đó là cái Neural Network\n00:09:04: 2-cor3_co_0: Neural Network là tụi nó sẽ giả lập lại\n00:09:07: 2-cor3_co_0: cái\n00:09:07: 2-cor3_co_0: là một cái loại machine learning\n00:09:10: 2-cor3_co_0: mà tụi nó giả lập lại cái cách hoạt động\n00:09:13: 2-cor3_co_0: của cái neutron của\n00:09:14: 2-cor3_co_0: con người\n00:09:15: 2-cor3_co_0: thì nó sẽ có nhiều layer trong đó\n00:09:19: 2-cor3_co_0: Thì trong một cái Neural Network thì nó sẽ có một cái subset nhỏ hơn nữa.\n00:09:26: 2-cor3_co_0: Thì subset đó nó gọi là Deep Learning.\n00:09:29: 2-cor3_co_0: Deep Learning nó là những cái model Neural Network nhưng mà nó sẽ có nhiều hơn 3 layer trở lên.\n00:09:36: 2-cor3_co_0: Thì là nó sẽ có rất nhiều layer để nó, mỗi layer, mỗi hidden layer nó sẽ filter data để nó ra được một cái output.\n00:09:44: 2-cor3_co_0: Thì tưởng tượng là deep learning\n00:09:47: 2-cor3_co_0: Thì nó sẽ có\n00:09:48: 2-cor3_co_0: Nhiều hơn 3 cái layer\n00:09:51: 2-cor3_co_0: Thì nó sẽ là deep learning\n00:09:51: 2-cor3_co_0: Sau deep learning\n00:09:55: 2-cor3_co_0: Deep learning cách đây chắc\n00:09:56: 2-cor3_co_0: 10, 20, 18, 19 gì đó\n00:09:58: 2-cor3_co_0: Nó khá là nổi\n00:09:59: 2-cor3_co_0: Nhưng mà kiểu phức tạp quá\n00:10:02: 2-cor3_co_0: Cho ai làm tới\n00:10:03: 2-cor3_co_0: Thì nó mới đi tới\n00:10:05: 2-cor3_co_0: Bước sau là cái thằng\n00:10:07: 2-cor3_co_0: Generative AI\n00:10:09: 2-cor3_co_0: Là cái mà năm ngoái với năm nay\n00:10:12: 2-cor3_co_0: Mọi người nghĩ rất là nhiều về nó\n00:10:13: 2-cor3_co_0: thì Generative AI thì nó sẽ gần hơn\n00:10:16: 2-cor3_co_0: với cái việc là\n00:10:18: 2-cor3_co_0: tạo ra những cái\n00:10:20: 2-cor3_co_0: nó là\n00:10:22: 2-cor3_co_0: nó là\n00:10:23: 2-cor3_co_0: nó là\n00:10:25: 2-cor3_co_0: combine lại rất là nhiều thứ để ra được\n00:10:28: 2-cor3_co_0: những cái gọi là\n00:10:29: 2-cor3_co_0: generate ra những cái\n00:10:32: 2-cor3_co_0: text, những cái video\n00:10:34: 2-cor3_co_0: dựa vào những cái\n00:10:37: 2-cor3_co_0: input của mình\n00:10:39: 2-cor3_co_0: thì nó là\n00:10:40: 2-cor3_co_0: Generative AI\n00:10:41: 2-cor3_co_0: còn\n00:10:43: 2-cor3_co_0: nhỏ hơn channel A\n00:10:45: 2-cor3_co_0: đó là MLM\n00:10:47: 2-cor3_co_0: thì MLM nó là tập trung\n00:10:50: 2-cor3_co_0: nhiều hơn về bên cái phần\n00:10:51: 2-cor3_co_0: NLP\n00:10:52: 2-cor3_co_0: NLP là cái\n00:10:54: 2-cor3_co_0: Natural Language Processing\n00:10:59: 2-cor3_co_0: thì nó là\n00:11:00: 2-cor3_co_0: dạng\n00:11:01: 2-cor3_co_0: mấy con chat CPT đó\n00:11:02: 2-cor3_co_0: nó chính là MLM\n00:11:04: 2-cor3_co_0: thì nó chỉ chuyên tập trung cho cái việc\n00:11:07: 2-cor3_co_0: là generate ra những cái\n00:11:09: 2-cor3_co_0: Thì mình like\n00:11:10: 2-cor3_co_0: Đang với tôi\n00:11:11: 2-cor3_co_0: Ờ\n00:11:12: 2-cor3_co_0: Chỉ là bức tranh tổng thể\n00:11:15: 2-cor3_co_0: Thì\n00:11:15: 2-cor3_co_0: Để mọi người nắm được là\n00:11:17: 2-cor3_co_0: Khi mà người ta nói\n00:11:18: 2-cor3_co_0: Tới những cái này\n00:11:19: 2-cor3_co_0: Thì\n00:11:20: 2-cor3_co_0: Nó đang ở\n00:11:21: 2-cor3_co_0: Cái bước nào rồi\n00:11:22: 2-cor3_co_0: Thì mình đang ở\n00:11:23: 2-cor3_co_0: State\n00:11:23: 2-cor3_co_0: Của cái\n00:11:24: 2-cor3_co_0: Generate AI rồi\n00:11:25: 2-cor3_co_0: Là cái mà\n00:11:26: 2-cor3_co_0: Tụi nó\n00:11:27: 2-cor3_co_0: Có thể\n00:11:28: 2-cor3_co_0: Tạo ra\n00:11:29: 2-cor3_co_0: Những cái\n00:11:30: 2-cor3_co_0: Ờ\n00:11:31: 2-cor3_co_0: Text\n00:11:33: 2-cor3_co_0: Video\n00:11:33: 2-cor3_co_0: Ờ\n00:11:35: 2-cor3_co_0: Rồi\n00:11:38: 2-cor3_co_0: thì cái là bức tranh tâm thể\n00:11:41: 2-cor3_co_0: về Generative AI\n00:11:43: 2-cor3_co_0: thì cái bài báo hôm trước\n00:11:48: 2-cor3_co_0: thì nó sẽ\n00:11:49: 2-cor3_co_0: của thằng Discord nó sẽ\n00:11:51: 2-cor3_co_0: tập trung về cái thằng mà\n00:11:53: 2-cor3_co_0: về cái process mà tụi nó sử dụng\n00:11:56: 2-cor3_co_0: cái Generative AI này\n00:11:57: 2-cor3_co_0: cho cái idea của nó\n00:11:59: 2-cor3_co_0: thì cái process nó cũng giống như là\n00:12:02: 2-cor3_co_0: cái quy trình phát triển phần mềm của mình\n00:12:04: 2-cor3_co_0: đó giờ hết\n00:12:04: 2-cor3_co_0: nó cũng đi từ idea tới MVP này đó\n00:12:07: 2-cor3_co_0: thì trong quá trình đi từ IDA đến MVP\n00:12:10: 2-cor3_co_0: cho một cái\n00:12:11: 2-cor3_co_0: cái ứng dụng\n00:12:14: 2-cor3_co_0: của Genki.ai thì nó sẽ trải qua\n00:12:16: 2-cor3_co_0: những bước nào để mình biết là\n00:12:18: 2-cor3_co_0: sau này mình có dư sky như vậy\n00:12:20: 2-cor3_co_0: mình muốn xài thì mình nên làm\n00:12:22: 2-cor3_co_0: theo những bước đó cho nó kiểu\n00:12:24: 2-cor3_co_0: nó có quy trình\n00:12:26: 2-cor3_co_0: rồi nó ra được cái kết quả\n00:12:28: 2-cor3_co_0: nó ok tí\n00:12:29: 2-cor3_co_0: thì cái đó là cái quy trình của nó\n00:12:31: 2-cor3_co_0: để nó chia sẻ\n00:12:32: 2-cor3_co_0: thì đầu tiên nó vẫn là\n00:12:35: 2-cor3_co_0: cái quy trình cơ bản của nó vẫn là\n00:12:37: 2-cor3_co_0: có idea, rồi bắt đầu sẽ define những cái requirement\n00:12:43: 2-cor3_co_0: sau khi có những requirement của cái idea đó sẽ là prototype\n00:12:48: 2-cor3_co_0: thì nó dùng cái prototype này để đi, nó quăng qua những cái model trên thị trường hiện tại\n00:12:55: 2-cor3_co_0: nó validate rồi nó quay về, nó validate liên tục tiên tục\n00:13:01: 2-cor3_co_0: để nó biết được một cái mô đồ chuẩn nhất,\n00:13:08: 2-cor3_co_0: có output nó kiểu sát với lại cái expectation của nó nhất.\n00:13:13: 2-cor3_co_0: Sau đó tụi nó sẽ deploy lên cái môi trường để cho tự do sơ sải.\n00:13:19: 2-cor3_co_0: Thì cái quá trình idea này chắc cũng là cũng đơn giản thôi, mình bỏ qua nha.\n00:13:25: 2-cor3_co_0: Cái define, trong cái quy trình mà mình define cái requirement á,\n00:13:29: 2-cor3_co_0: thì tụi nó có nhắc đến một vài cái factor\n00:13:31: 2-cor3_co_0: mà khi mà mình define\n00:13:33: 2-cor3_co_0: rồi requirement mình nên để ý\n00:13:35: 2-cor3_co_0: thì giống như là\n00:13:36: 2-cor3_co_0: sẽ có vài factor như là cái latency\n00:13:39: 2-cor3_co_0: về cái độ trễ\n00:13:41: 2-cor3_co_0: khi mà mình sử dụng\n00:13:43: 2-cor3_co_0: RAM model gì đó\n00:13:44: 2-cor3_co_0: thì khi mà mình đưa một input\n00:13:47: 2-cor3_co_0: đưa một input vô thì bao lâu\n00:13:49: 2-cor3_co_0: sẽ output cho user\n00:13:50: 2-cor3_co_0: cái task complexity\n00:13:53: 2-cor3_co_0: là cái task của mình\n00:13:55: 2-cor3_co_0: nó có phức tạp hay không\n00:13:56: 2-cor3_co_0: cái vấn đề mình cần giải quyết nó phức tạp tới mức nào\n00:13:59: 2-cor3_co_0: để mình viết được là cái model nào\n00:14:02: 2-cor3_co_0: sẽ phù hợp với mình\n00:14:03: 2-cor3_co_0: cái prompt length\n00:14:05: 2-cor3_co_0: thì đó là cái context mình input cho\n00:14:08: 2-cor3_co_0: cái thằng model đó\n00:14:10: 2-cor3_co_0: sẽ giống như mình\n00:14:11: 2-cor3_co_0: một cái task của mình\n00:14:13: 2-cor3_co_0: để mà thằng model đó\n00:14:16: 2-cor3_co_0: nó hiểu được cái task\n00:14:18: 2-cor3_co_0: và nó đưa ra các boost đó\n00:14:20: 2-cor3_co_0: thì\n00:14:20: 2-cor3_co_0: mình sẽ input một cái context\n00:14:24: 2-cor3_co_0: thì mình cũng nên consider\n00:14:26: 2-cor3_co_0: là ok cái model\n00:14:28: 2-cor3_co_0: có thể nhận được content\n00:14:29: 2-cor3_co_0: lên là bao nhiêu\n00:14:30: 2-cor3_co_0: để mình biết được là\n00:14:33: 2-cor3_co_0: nó có phù hợp\n00:14:36: 2-cor3_co_0: với cái task của mình hay không\n00:14:37: 2-cor3_co_0: cái nữa là\n00:14:40: 2-cor3_co_0: cái quality của cái output\n00:14:41: 2-cor3_co_0: của thằng kiểu model đó\n00:14:43: 2-cor3_co_0: nó có đảm bảo được\n00:14:45: 2-cor3_co_0: là nó giải quyết được vấn đề của mình hay không\n00:14:47: 2-cor3_co_0: safety\n00:14:50: 2-cor3_co_0: là mấy cái factor\n00:14:51: 2-cor3_co_0: về mấy cái kiểu\n00:14:53: 2-cor3_co_0: về\n00:14:54: 2-cor3_co_0: content\n00:14:56: 2-cor3_co_0: cái\n00:14:57: 2-cor3_co_0: cái output của thằng\n00:15:00: 2-cor3_co_0: em model của\n00:15:02: 2-cor3_co_0: cái RM đó\n00:15:03: 2-cor3_co_0: nó có\n00:15:06: 2-cor3_co_0: kiểu như là\n00:15:09: 2-cor3_co_0: mấy cái proxy của mình\n00:15:10: 2-cor3_co_0: nó có đáp ứng được hay không\n00:15:12: 2-cor3_co_0: kiểu như trong user\n00:15:14: 2-cor3_co_0: user data thì nó có được\n00:15:16: 2-cor3_co_0: liên quan lý ra hay không\n00:15:18: 2-cor3_co_0: rồi mấy cái content\n00:15:20: 2-cor3_co_0: mấy cái\n00:15:21: 2-cor3_co_0: 18 cộng là 3 gì đó\n00:15:24: 2-cor3_co_0: nó có kiểu\n00:15:26: 2-cor3_co_0: project với nó hay không\n00:15:27: 2-cor3_co_0: rồi\n00:15:28: 2-cor3_co_0: we play with support\n00:15:29: 2-cor3_co_0: thì\n00:15:30: 2-cor3_co_0: support bao nhiêu\n00:15:31: 2-cor3_co_0: language\n00:15:31: 2-cor3_co_0: thì nó là\n00:15:32: 2-cor3_co_0: estimative query\n00:15:34: 2-cor3_co_0: per second\n00:15:35: 2-cor3_co_0: thì\n00:15:36: 2-cor3_co_0: nó cũng tìm ra\n00:15:37: 2-cor3_co_0: performance của\n00:15:38: 2-cor3_co_0: cái\n00:15:38: 2-cor3_co_0: NUP đó\n00:15:39: 2-cor3_co_0: you know\n00:15:42: 2-cor3_co_0: vài\n00:15:43: 2-cor3_co_0: vài\n00:15:43: 2-cor3_co_0: let's try\n00:15:44: 2-cor3_co_0: khi mình\n00:15:45: 2-cor3_co_0: define\n00:15:46: 2-cor3_co_0: cái requirement\n00:15:47: 2-cor3_co_0: thì\n00:15:48: 2-cor3_co_0: trong\n00:15:49: 2-cor3_co_0: tùy\n00:15:50: 2-cor3_co_0: few case thôi\n00:15:51: 2-cor3_co_0: thì nếu mà mình có\n00:15:52: 2-cor3_co_0: few case khác\n00:15:53: 2-cor3_co_0: mình cần\n00:15:53: 2-cor3_co_0: cái factor khác\n00:15:55: 2-cor3_co_0: mình có\n00:15:55: 2-cor3_co_0: để mình consider khi mà mình bắt đầu mình lên cái prototype để mình chọn cái model nào phù hợp cho cái product của mình\n00:16:05: 2-cor3_co_0: Sau quá trình define cái requirement rồi thì mình có prototype\n00:16:13: 2-cor3_co_0: mình scope out lại là mình nên chọn những cái model nào có sẵn trên thị trường để mình test nó\n00:16:21: 2-cor3_co_0: Khi mình test, sau khi mình mix model, mình sẽ làm sao để value được model có phù hợp với product và view case của mình\n00:16:39: 2-cor3_co_0: thì cái quá trình đó người ta gọi là quá trình\n00:16:43: 2-cor3_co_0: evaluating cái prompt của mình\n00:16:45: 2-cor3_co_0: thì\n00:16:46: 2-cor3_co_0: nếu mà mình biết mô đồ\n00:16:48: 2-cor3_co_0: trên thị trường sẽ có kiểu\n00:16:49: 2-cor3_co_0: hiện tại có kiểu quá nhiều mô đồ\n00:16:52: 2-cor3_co_0: vài chục vài trăm mô đồ vậy đó\n00:16:54: 2-cor3_co_0: thì mình cũng không biết là thằng nào nó phù hợp với mình\n00:16:56: 2-cor3_co_0: rồi mình sẽ có\n00:16:58: 2-cor3_co_0: cái prompt để mình\n00:17:00: 2-cor3_co_0: giải quyết\n00:17:01: 2-cor3_co_0: để mình đưa cho nó\n00:17:04: 2-cor3_co_0: để nó generate cho mình\n00:17:06: 2-cor3_co_0: cái output\n00:17:07: 2-cor3_co_0: thì mình cũng không biết là cái ROM nào\n00:17:09: 2-cor3_co_0: nó sẽ cho ra kết quả\n00:17:11: 2-cor3_co_0: ok nhất với mình\n00:17:12: 2-cor3_co_0: thì mình sẽ có quá trình\n00:17:14: 2-cor3_co_0: evalu cái ROM của mình\n00:17:17: 2-cor3_co_0: và biết cái mô đồ\n00:17:18: 2-cor3_co_0: thì\n00:17:20: 2-cor3_co_0: đây là cái set cơ bản\n00:17:23: 2-cor3_co_0: mà tụi nó đưa ra thôi\n00:17:25: 2-cor3_co_0: quá trình evalu này nó có nhiều thứ\n00:17:27: 2-cor3_co_0: trong đây, kiểu như là\n00:17:29: 2-cor3_co_0: mình đưa vào\n00:17:32: 2-cor3_co_0: cái input là cho một cái mô đồ\n00:17:33: 2-cor3_co_0: mô đồ nào đó\n00:17:34: 2-cor3_co_0: viết story\n00:17:37: 2-cor3_co_0: about\n00:17:38: 2-cor3_co_0: quân bớt gì gì đó\n00:17:40: 2-cor3_co_0: thì đưa ra cho\n00:17:41: 2-cor3_co_0: một cái thằng model\n00:17:42: 2-cor3_co_0: nó gọi là cái\n00:17:44: 2-cor3_co_0: inferencing model\n00:17:45: 2-cor3_co_0: gì đó\n00:17:46: 2-cor3_co_0: rồi thằng này\n00:17:47: 2-cor3_co_0: nó sẽ đưa ra\n00:17:48: 2-cor3_co_0: cái output là\n00:17:48: 2-cor3_co_0: ok\n00:17:49: 2-cor3_co_0: nó là cái gì đó\n00:17:50: 2-cor3_co_0: once a month\n00:17:51: 2-cor3_co_0: a time\n00:17:51: 2-cor3_co_0: gì đó\n00:17:52: 2-cor3_co_0: thì mình có lúc đầu\n00:17:53: 2-cor3_co_0: mình lấy thằng này\n00:17:54: 2-cor3_co_0: mình đưa cho một thằng khác\n00:17:56: 2-cor3_co_0: cái thằng này\n00:17:57: 2-cor3_co_0: nó sẽ gọi là\n00:17:57: 2-cor3_co_0: cái secret model\n00:17:58: 2-cor3_co_0: cái crisis model này\n00:18:00: 2-cor3_co_0: critic model này\n00:18:01: 2-cor3_co_0: nó\n00:18:01: 2-cor3_co_0: sẽ làm nhiệm vụ là\n00:18:03: 2-cor3_co_0: nó đánh giá\n00:18:04: 2-cor3_co_0: nó phê bình cái output của thằng kia\n00:18:06: 2-cor3_co_0: thì sau khi mà có được\n00:18:09: 2-cor3_co_0: cái lách giá về mình đó\n00:18:10: 2-cor3_co_0: thì mình sẽ có lòng hãy ngược lại cho cái thằng kia\n00:18:13: 2-cor3_co_0: để tự động optimize\n00:18:15: 2-cor3_co_0: cái kết quả\n00:18:16: 2-cor3_co_0: và cái prompt của mình gì đó\n00:18:18: 2-cor3_co_0: thì cái quá trình này nó sẽ bị lật lại\n00:18:21: 2-cor3_co_0: cho đến khi nào mà\n00:18:22: 2-cor3_co_0: mình có được cái prompt\n00:18:24: 2-cor3_co_0: và cái output\n00:18:25: 2-cor3_co_0: tốt nhất và gần sát\n00:18:28: 2-cor3_co_0: với lại cái dự kê của mình nhất\n00:18:30: 2-cor3_co_0: thì cái big big này\n00:18:32: 2-cor3_co_0: thì cái tôi Discord nó đang nói là\n00:18:34: 2-cor3_co_0: nó sẽ biết cái best in class\n00:18:36: 2-cor3_co_0: model để nó làm cái thằng\n00:18:38: 2-cor3_co_0: Crystic này\n00:18:39: 2-cor3_co_0: thì nó sẽ sử dụng cái GPT-4\n00:18:43: 2-cor3_co_0: để nó\n00:18:44: 2-cor3_co_0: evaluate cái\n00:18:46: 2-cor3_co_0: output của tụi\n00:18:47: 2-cor3_co_0: những cái model inferencing\n00:18:49: 2-cor3_co_0: thì\n00:18:52: 2-cor3_co_0: thì đó là cái quá trình\n00:18:54: 2-cor3_co_0: mà tụi nó đánh giá\n00:18:55: 2-cor3_co_0: lặp đi lặp lại để mà tụi nó tìm ra được\n00:18:58: 2-cor3_co_0: cái from và cái model\n00:19:00: 2-cor3_co_0: phù hợp nhất cho cái UK và cái product\n00:19:02: 2-cor3_co_0: thì sau cái quá trình này\n00:19:07: 2-cor3_co_0: đã tìm được một cái\n00:19:08: 2-cor3_co_0: UK product rồi\n00:19:10: 2-cor3_co_0: tìm được model phù hợp\n00:19:12: 2-cor3_co_0: thì sẽ bắt đầu\n00:19:14: 2-cor3_co_0: quăng lên deploy\n00:19:16: 2-cor3_co_0: deploy thì nó sẽ quay lại\n00:19:18: 2-cor3_co_0: vấn đề trái đất của mình\n00:19:20: 2-cor3_co_0: tự deploy\n00:19:23: 2-cor3_co_0: xài model quả sẵn\n00:19:24: 2-cor3_co_0: và self-hub cái model\n00:19:25: 2-cor3_co_0: thì nó cũng là cái việc\n00:19:28: 2-cor3_co_0: mà mình trade off giữa cái việc là\n00:19:30: 2-cor3_co_0: mình sẵn sàng trả tiền cho tụi nó\n00:19:32: 2-cor3_co_0: để xài cái API của tụi này\n00:19:34: 2-cor3_co_0: có sẵn, không cần phải maintain\n00:19:36: 2-cor3_co_0: không cần be user\n00:19:37: 2-cor3_co_0: chỉ cần\n00:19:40: 2-cor3_co_0: sử dụng API xong rồi lấy output\n00:19:42: 2-cor3_co_0: xong rồi mình đi verify\n00:19:44: 2-cor3_co_0: mình đi write cái output này\n00:19:47: 2-cor3_co_0: coi là nó có phù hợp\n00:19:48: 2-cor3_co_0: với lại cái tiêu chuẩn của mình không\n00:19:50: 2-cor3_co_0: rồi mình mới\n00:19:52: 2-cor3_co_0: format cái output đưa về cho user\n00:19:54: 2-cor3_co_0: thì cái này là\n00:19:56: 2-cor3_co_0: quá trình mà 1 cái 2 level\n00:19:58: 2-cor3_co_0: của cái việc\n00:19:59: 2-cor3_co_0: sử dụng cái\n00:20:01: 2-cor3_co_0: mình sẽ làm cái lm có sẵn để giải quyết vấn đề\n00:20:06: 2-cor3_co_0: Vấn đề là nó sẽ đơn giản như là mình không cần maintain cái lm này\n00:20:11: 2-cor3_co_0: nhưng mà mình sẽ kiểu tốn tiền, càng ngày càng tốn tiền cho nó\n00:20:15: 2-cor3_co_0: Thành ra mấy ngày này nó tính theo kiểu tiền của tôi này\n00:20:21: 2-cor3_co_0: Giả sử thằng quỷ GPD4 này, sải nhiều user chắc trả tiền mất nghị luôn\n00:20:28: 2-cor3_co_0: Còn cái khác là cái self-LM thì nó trade-off việc là mình sẽ phải tự maintain cái LM của mình\n00:20:36: 2-cor3_co_0: Tự build server, rồi tự rom ra, rồi load balance, rồi import gì đó, v.v.\n00:20:44: 2-cor3_co_0: Nguyên cái đóng này, rồi ngồi mình tự optimize, tự build server, rồi consider nó\n00:20:51: 2-cor3_co_0: thì nó sẽ dựa vào những cái, đa số nó sẽ dựa vào những cái model kiểu outsource\n00:20:58: 2-cor3_co_0: để làm á\n00:21:01: 2-cor3_co_0: thì chắc là mình sẽ tự build nó như này\n00:21:03: 2-cor3_co_0: như này là mình build những cái model mình có sẵn trên thị trường\n00:21:06: 2-cor3_co_0: để đa tiếp lội sẵn trên thị trường để mình làm\n00:21:10: 2-cor3_co_0: ý này là cái vấn đề trade-off\n00:21:15: 2-cor3_co_0: sử dụng cho mất cứ software nào\n00:21:18: 2-cor3_co_0: chẳng có gì\n00:21:21: 2-cor3_co_0: Trong quá trình này thì cái mà có vẻ mới mẻ và mọi người thấy consider để mà tốt bằng tích của đồ là cái quá trình Evaluate Caperarm\n00:21:42: 2-cor3_co_0: Hôm bữa mình mới tìm hiểu văn này thì tụi nó cũng khá nhiều thứ trong đây\n00:21:48: 2-cor3_co_0: Những cái về cái Actors Evaluate Model nó có\n00:21:53: 2-cor3_co_0: Nó có những cái rule, những cái matrix mà mình cần phải\n00:21:57: 2-cor3_co_0: Khi mình cần phải biết khi mình evaluate một cái prompt á\n00:22:03: 2-cor3_co_0: Thì cái quá trình mà evaluating cái prompt này nó\n00:22:07: 2-cor3_co_0: Mình nghĩ là đóng vai trò khá quan trọng trong cái process mà\n00:22:11: 2-cor3_co_0: Mình tìm cái model phù hợp và cái prompt phù hợp cho cái sản phẩm của mình\n00:22:17: 2-cor3_co_0: Thì cái quá trình này nó sẽ tốn nhiều effort trong cái nguyên cái project làm cái blog của mình.\n00:22:35: 2-cor3_co_0: Rồi, đó là toàn bộ cái article của thằng...\n00:22:47: 2-cor3_co_0: đang hiểu kiểu là nó sẽ tìm ý là cái chân biết ai đó là nó gồm rất là nhiều thứ lên\n00:23:16: 2-cor3_co_0: thì nó đang cần\n00:23:19: 2-cor3_co_0: biết một cái model nào đó\n00:23:22: 2-cor3_co_0: như là MMA\n00:23:23: 2-cor3_co_0: hoặc là cái GPT\n00:23:26: 2-cor3_co_0: hoặc là một cái model\n00:23:27: 2-cor3_co_0: tào lao ở trên thị trường\n00:23:29: 2-cor3_co_0: để nó giải quyết một cái\n00:23:31: 2-cor3_co_0: problem nào đó của tụi nó\n00:23:34: 2-cor3_co_0: giải sử như là tụi nó muốn\n00:23:37: 2-cor3_co_0: làm một cái\n00:23:40: 2-cor3_co_0: software để nó\n00:23:43: 2-cor3_co_0: classify những cái object\n00:23:45: 2-cor3_co_0: hoặc là software để mà nó\n00:23:48: 2-cor3_co_0: detect những cái hình ảnh\n00:23:50: 2-cor3_co_0: những con mèo\n00:23:52: 2-cor3_co_0: con chó gì đó\n00:23:53: 2-cor3_co_0: hoặc là\n00:23:55: 2-cor3_co_0: mấy cái mô đồ để\n00:23:58: 2-cor3_co_0: record hoặc là để\n00:23:59: 2-cor3_co_0: summarize một cái bài báo\n00:24:02: 2-cor3_co_0: chẳng hạn, thì tụi nó cần phải chọn\n00:24:04: 2-cor3_co_0: một mô đồ đó phù hợp nhất cho sản phẩm\n00:24:06: 2-cor3_co_0: thì nó sẽ bắt đầu\n00:24:08: 2-cor3_co_0: đặt ra những cái quy trình này\n00:24:09: 2-cor3_co_0: để cái output cuối cùng\n00:24:12: 2-cor3_co_0: của nó, nó sẽ là\n00:24:13: 2-cor3_co_0: Tụi nó sẽ nên xài mô đồ nào\n00:24:15: 2-cor3_co_0: Và cái problem của nó sẽ như thế nào\n00:24:18: 2-cor3_co_0: Để ra được kết quả\n00:24:20: 2-cor3_co_0: Mong muốn\n00:24:21: 2-cor3_co_0: Và giải quyết được vấn đề của nó\n00:24:23: 2-cor3_co_0: Cảm ơn\n00:24:23: 2-cor3_co_0: Cảm ơn\n00:24:30: 3-thanh_pham_0: không chắc đọc nó vậy thì là bên kia đi còn nó sẽ kiểu experiment với những cái\n00:24:36: 2-cor3_co_0: Cảm ơn\n00:24:48: 3-thanh_pham_0: feature như cái áp bé nên qua tính em thì nó đi file ra một ngọn quy trình\n00:24:53: 3-thanh_pham_0: Để đâu đó mà thứ nhất là để xây dựng này sau đó để xem cái output của cái app đấy nó có ok không\n00:25:02: 3-thanh_pham_0: Thì nó giống như trước giờ mình làm thôi nhưng mà may be là kiểu chưa có bước đánh giá cái chấm điểm\n00:25:10: 3-thanh_pham_0: scoring cái cái cái output của cái cái app hay cái model thôi chính xác là của cái model mà của cái\n00:25:13: 2-cor3_co_0: đúng ý là trước giờ em thấy mình làm nha có đây là mình sẽ đi tìm cái mô đồ và mình sẽ mua đồ đó\n00:25:23: 3-thanh_pham_0: Cảm ơn các bạn đã theo dõi và hẹn gặp lại.\n00:25:27: 2-cor3_co_0: rồi mình nghĩ ra cái dư kê thì mình xài của đồ đó nhưng mà cái quy định nể quy trình là tựa\n00:25:33: 2-cor3_co_0: nó để đi file cái đi nó rồi nó đi pha cái dư kê xin lỗi tôi muốn làm cái gì cho sản phẩm rồi và\n00:25:38: 2-cor3_co_0: đi tìm cái mô đồ và cái prompt phù hợp\n00:25:41: 2-cor3_co_0: thì mới xin ra\n00:25:43: 2-cor3_co_0: quá trình này\n00:25:43: 2-cor3_co_0: còn xưa giờ em thấy mình kiểu\n00:25:46: 2-cor3_co_0: đi tìm cái mô đồ chơi thôi mà\n00:25:53: 3-thanh_pham_0: Hẹn gặp lại các bạn trong những video tiếp theo.\n00:26:08: 2-cor3_co_0: Ờ, đúng rồi, kiểu vậy. Tụi nó có thể làm bất cứ gì, tụi nó có thể chọn một cái model có sẵn trên thị trường cũng được nếu mà nó phù hợp.\n00:26:20: 2-cor3_co_0: Còn nếu mà tất cả mọi thứ mà tìm không phù hợp thì cái quy trình này có thể là tụi nó sẽ tự build một cái model luôn, chứ không phải là tụi nó lúc nào cũng xài những cái model quá sẵn trên thị trường.\n00:26:23: 3-thanh_pham_0: là cái điểm chấm điểm là hiện tại nó sẽ có như kiểu một cái một cái mít và đem điểm cho cho\n00:26:46: 3-thanh_pham_0: của mấy cái LEM app, output của model\n00:26:49: 3-thanh_pham_0: thì not sure phải standard hay không\n00:26:53: 3-thanh_pham_0: nhưng mà chúng ta open sort nhiều cái\n00:26:56: 3-thanh_pham_0: dạng Benx, kiểu tạng như thế\n00:26:58: 3-thanh_pham_0: thì cũng hôm trước chưa đọc kỹ là xem\n00:27:01: 3-thanh_pham_0: bọn Discord thì nó đang kiểu refer theo\n00:27:03: 3-thanh_pham_0: một cái quy chuẩn nào\n00:27:05: 3-thanh_pham_0: nhưng mà chắc nó sẽ kiểu như kiểu\n00:27:08: 3-thanh_pham_0: AP testing thôi\n00:27:09: 3-thanh_pham_0: nó pick một cái model, nó test xem là\n00:27:12: 3-thanh_pham_0: cái output nó có match với cả cái recommend hay không\n00:27:14: 3-thanh_pham_0: không có thì chọn 2 hướng\n00:27:17: 3-thanh_pham_0: thứ nhất là chọn model khác\n00:27:18: 3-thanh_pham_0: nó Qualify hơn\n00:27:19: 3-thanh_pham_0: hai là nó sẽ đi kiểu file tuning\n00:27:21: 3-thanh_pham_0: hoặc là implement mấy cái\n00:27:23: 3-thanh_pham_0: technique như kiểu Rack Rack các thứ\n00:27:25: 3-thanh_pham_0: để đảm bảo output\n00:27:26: 3-thanh_pham_0: thì cuối cùng ở đây là kiểm thử xem là\n00:27:29: 3-thanh_pham_0: chạy kiểu iteration thôi\n00:27:32: 3-thanh_pham_0: lúc xem output nó có ok không\n00:27:34: 3-thanh_pham_0: chưa ok thì ta tìm cách ta\n00:27:36: 3-thanh_pham_0: làm cho nó ok hơn\n00:27:38: 2-cor3_co_0: Chịu kìa vậy tại vì bữa trong cái\n00:27:44: 3-thanh_pham_0: Nếu có thích thì nhớ like, share và đăng ký kênh để ủng hộ kênh của mình nhé.\n00:28:02: 2-cor3_co_0: Cái link nữa nó có một cái gọi là\n00:28:05: 2-cor3_co_0: cái này nè\n00:28:09: 2-cor3_co_0: assist evaluation\n00:28:11: 2-cor3_co_0: thì nó là kiểu\n00:28:14: 2-cor3_co_0: quăng một đống from\n00:28:16: 2-cor3_co_0: qua một đống cái model\n00:28:18: 2-cor3_co_0: xong ra một đống cái output\n00:28:20: 2-cor3_co_0: thì sẽ có một thằng\n00:28:22: 2-cor3_co_0: đứng giữa\n00:28:23: 2-cor3_co_0: để validate cái đống output này\n00:28:26: 2-cor3_co_0: cho đọc điểm số nào đó\n00:28:28: 2-cor3_co_0: rồi mình sẽ biết được là\n00:28:30: 2-cor3_co_0: mình nên pick những cái\n00:28:31: 2-cor3_co_0: from nào từ model nào\n00:28:33: 2-cor3_co_0: nó đi ngược, có value rồi đúng không?\n00:28:35: 2-cor3_co_0: có cái đánh giá của thằng model\n00:28:38: 2-cor3_co_0: giả sử thằng chìm\n00:28:40: 2-cor3_co_0: thì 4 nó đánh giá xong rồi\n00:28:42: 2-cor3_co_0: thì mình sẽ đi ngược lại là ok\n00:28:43: 2-cor3_co_0: thằng nào điểm cao nhất, pick nó\n00:28:45: 2-cor3_co_0: rồi pick cái prompt nào cao nhất thì pick ra\n00:28:47: 2-cor3_co_0: để làm cái giải quyết vấn đề của mình thôi\n00:28:57: 2-cor3_co_0: đúng rồi, đúng rồi, đúng rồi\n00:29:03: 2-cor3_co_0: ừ ừ\n00:29:11: 1-baddeed_0: rồi có một cái quy trình mà tụi nó đang sử dụng để đảm bảo các em đạt được mục tiêu cho nó yêu cầu\n00:29:21: 1-baddeed_0: anh em có hỏi cho em không sẵn không có hỏi\n00:29:22: 2-cor3_co_0: cken\n00:29:29: 1-baddeed_0: bài của em 40 phút giảm mạng 3 phút\n00:29:35: 1-baddeed_0: 10 phút\n00:29:41: 1-baddeed_0: ok Nếu không có câu hỏi câu hỏi không em nhanh mình qua\n00:29:50: 1-baddeed_0: cái\n00:29:51: 1-baddeed_0: ok không có hỏi Cảm ơn em Cảm ơn em Cảm ơn tâm rồi rồi Mời các bạn xuống sân khấu các\n```\n\n![](assets/3-ogif-office-hours-0419_0419-2_compressed.mp4)\n```\n00:30:02: 1-baddeed_0: ok giờ mình sẽ qua đây còn lại chủ đề còn lại là\n00:30:12: 1-baddeed_0: tên của tìm góp như thế nào tuần sau\n00:30:20: 1-baddeed_0: tuần sau có mấy cái mũi intro biết không?\n00:30:21: 1-baddeed_0: tuần sau có mấy cái mũi intro biết không?\n00:30:21: 1-baddeed_0: Tìm bạn Bảo tàu Xài tưởng mình hiện nay đang bắt đầu triển khai chuyện frankly hết tất cả hoạt động làm\n00:30:29: 1-baddeed_0: Có nhiềuimpact, tuần sau có một em xem nhạc sản xuất font,\n00:30:50: 1-baddeed_0: Các con đeo data ra\n00:30:52: 1-baddeed_0: Thì build được mỗi con ẩm hợp\n00:30:56: 1-baddeed_0: Chỗ này\n00:30:58: 1-baddeed_0: Rồi đây\n00:31:00: 1-baddeed_0: Đây là data\n00:31:02: 1-baddeed_0: Từ trên ra\n00:31:04: 1-baddeed_0: Từ trên ra ra lên bên\n00:31:06: 1-baddeed_0: Rồi\n00:31:08: 1-baddeed_0: Phần này chắc là đã vừa nào\n00:31:10: 1-baddeed_0: Huy Vĩnh đã làm xong hết rồi format tất cả mọi thứ\n00:31:12: 1-baddeed_0: Số máy đã đẹp hết để\n00:31:14: 1-baddeed_0: Trình bày mỗi chủ đề sau\n00:31:16: 1-baddeed_0: Tạm tại cái stage của cái team mình đang phát triển\n00:31:18: 1-baddeed_0: Đẹp thế này nhá\n00:31:20: 1-baddeed_0: Đã được một cái\n00:31:22: 1-baddeed_0: Tập kênh như thế nào mọi thứ ra làm sao\n00:31:24: 1-baddeed_0: Hãy trình việc lại trình tiếp\n00:31:26: 1-baddeed_0: Trình nào như thế nào\n00:31:28: 1-baddeed_0: Đang dạy là một cái\n00:31:30: 1-baddeed_0: Tuần sau mọi người sẽ được giới thiệu tiếp\n00:31:32: 1-baddeed_0: Cái token của team\n00:31:36: 1-baddeed_0: Cái phần\n00:31:38: 1-baddeed_0: Chủ yếu giờ bên MCN nhà mày team sẽ được gắn một cái role đó\n00:31:40: 1-baddeed_0: Ví dụ như role Rampage này\n00:31:42: 1-baddeed_0: Thì cái tuần sau người sẽ được gắn một cái NFT\n00:31:44: 1-baddeed_0: Mình sẽ bắt đầu chuyển qua giai đoạn là\n00:31:48: 1-baddeed_0: Sử dụng\n00:31:50: 1-baddeed_0: Data\n00:31:52: 1-baddeed_0: Để định danh\n00:31:54: 1-baddeed_0: Ví dụ như anh em tham gia team\n00:31:56: 1-baddeed_0: Đợt vừa rồi sẽ được phát cho một cái role\n00:31:58: 1-baddeed_0: Nguyễn Nguyễn sẽ bắt đầu bảo mọi người là\n00:32:00: 1-baddeed_0: Để em\n00:32:02: 1-baddeed_0: Đi connect kích thước, connect wallet đi\n00:32:04: 1-baddeed_0: Xem người đó như thế nào\n00:32:06: 1-baddeed_0: Thì sẽ có wallet rồi\n00:32:08: 1-baddeed_0: Những bạn nào thuộc team sẽ được phát cho một cái NFT\n00:32:10: 1-baddeed_0: Với NFT đó bắt đầu sẽ\n00:32:12: 1-baddeed_0: Sẽ được hết thể thống role của team\n00:32:14: 1-baddeed_0: Tất cả mọi thứ sẽ dựa trên thế hết\n00:32:16: 1-baddeed_0: Và\n00:32:18: 1-baddeed_0: Anh em sẽ được entry vào một cái website\n00:32:20: 1-baddeed_0: Để\n00:32:22: 1-baddeed_0: Website đó rồi\n00:32:24: 1-baddeed_0: Đây là website mà team mình\n00:32:26: 1-baddeed_0: Đã thiết kế\n00:32:28: 1-baddeed_0: Đang làm\n00:32:30: 1-baddeed_0: Không biết xong kịp không\n00:32:32: 1-baddeed_0: Giới thiệu trước\n00:32:34: 1-baddeed_0: Sẵn dụng buổi này để work through cho\n00:32:36: 1-baddeed_0: Mấy em\n00:32:38: 1-baddeed_0: Nếu mấy bạn nào chưa nghe\n00:32:40: 1-baddeed_0: Thì tranh thủ nghe, mấy bạn nào nghe rồi thì nghe lại lần nữa\n00:32:42: 1-baddeed_0: Đây là website do\n00:32:44: 1-baddeed_0: Anh thiết kế\n00:32:46: 1-baddeed_0: Team My Nguyễn\n00:32:48: 1-baddeed_0: Hiển\n00:32:50: 1-baddeed_0: Minh Cloud\n00:32:52: 1-baddeed_0: Và Vincent\n00:32:54: 1-baddeed_0: Không biết có thiếu ai không\n00:32:56: 1-baddeed_0: Mọi người sẽ được đưa vào cái trang web\n00:32:58: 1-baddeed_0: Sau khi nhận được IC\n00:33:00: 1-baddeed_0: Mọi thứ mọi người sẽ được lên đây\n00:33:02: 1-baddeed_0: Những phần quà\n00:33:04: 1-baddeed_0: IC của mọi người nhận được\n00:33:06: 1-baddeed_0: Trác liên quan đến ví dụ như\n00:33:08: 1-baddeed_0: The rider\n00:33:10: 1-baddeed_0: The top of the year\n00:33:12: 1-baddeed_0: The top performer\n00:33:14: 1-baddeed_0: Những kiểu, nhận được IC đúng không\n00:33:16: 1-baddeed_0: Khi cài token đó lên\n00:33:18: 1-baddeed_0: Cái trang này của mình, biết giờ chạy được chưa không?\n00:33:20: 1-baddeed_0: Mấy em sẽ\n00:33:22: 1-baddeed_0: Tựa lên đây\n00:33:24: 1-baddeed_0: Tất cả mấy em holder trước giờ\n00:33:26: 1-baddeed_0: Đang tạm share holder của team sẽ cầm đếp đếp\n00:33:28: 1-baddeed_0: Còn sẽ có kênh để đem cái stack\n00:33:30: 1-baddeed_0: Token vào\n00:33:32: 1-baddeed_0: Và nó sẽ ra cái view\n00:33:34: 1-baddeed_0: Cái phần pool nó được trích ra\n00:33:36: 1-baddeed_0: Từ phần employee của mình\n00:33:38: 1-baddeed_0: Employee\n00:33:40: 1-baddeed_0: Cái ESOP\n00:33:42: 1-baddeed_0: Employee share option pool của mình\n00:33:44: 1-baddeed_0: Khoảng 10-20%\n00:33:46: 1-baddeed_0: Thì nó sẽ được trả dần cho những bạn\n00:33:48: 1-baddeed_0: Đón góp lại stack token trên đây\n00:33:50: 1-baddeed_0: Along the way\n00:33:52: 1-baddeed_0: Khi mà stack 2 ở token này vô\n00:33:54: 1-baddeed_0: Thì mình sẽ nhận được đếp g\n00:33:56: 1-baddeed_0: Cầm đếp g tương đương là cầm share của team\n00:33:58: 1-baddeed_0: Thì nó sẽ thể hiện một tính chất là\n00:34:00: 1-baddeed_0: Không chỉ team member\n00:34:02: 1-baddeed_0: Không chỉ là những bạn mà\n00:34:04: 1-baddeed_0: Trước giờ làm operation\n00:34:06: 1-baddeed_0: Làm vận hành, làm leadership\n00:34:08: 1-baddeed_0: Tất cả mấy em còn lại\n00:34:10: 1-baddeed_0: Có cái vốn liếu nhất định\n00:34:12: 1-baddeed_0: IC của mình\n00:34:14: 1-baddeed_0: Cũng có thể là đem ở đây\n00:34:16: 1-baddeed_0: Rồi nó yield ra ở kia\n00:34:18: 1-baddeed_0: Cặp một phần kia coi như là thể hiện phần đấu gấp của mình như đấy\n00:34:20: 1-baddeed_0: Tiếp theo là\n00:34:22: 1-baddeed_0: NFT này\n00:34:24: 1-baddeed_0: Khi mà sở hữu được NFT được thưởng\n00:34:26: 1-baddeed_0: Do bạn đã được giành hiệu nào đó\n00:34:28: 1-baddeed_0: Trong quá trình mình hoạt động\n00:34:30: 1-baddeed_0: Hàng tuần hàng tháng\n00:34:32: 1-baddeed_0: Mấy anh em có được giải này hay kia\n00:34:34: 1-baddeed_0: Thì mọi người sẽ được phát cho một cái set NFT\n00:34:38: 1-baddeed_0: Mấy anh em sẽ vô đây\n00:34:40: 1-baddeed_0: Bấm nút stack\n00:34:42: 1-baddeed_0: Thì cái NFT này nó giống như\n00:34:44: 1-baddeed_0: Cái bùa, cái charm\n00:34:46: 1-baddeed_0: Mà lúc mình chơi game hồi nhỏ đó\n00:34:48: 1-baddeed_0: Cái charm nó sẽ giúp nó cộng lất lên\n00:34:50: 1-baddeed_0: Tăng cái tỉ lệ boost\n00:34:54: 1-baddeed_0: Nó boost yield từ 2 cái pool này ra\n00:34:56: 1-baddeed_0: Được ha\n00:34:58: 1-baddeed_0: Đây là một chiều diễn stack game kia\n00:35:00: 1-baddeed_0: Anh có biết cái gì này chốt chưa\n00:35:02: 1-baddeed_0: Rồi\n00:35:04: 1-baddeed_0: Stack cái NFT, cầm NFT quăng vô\n00:35:08: 1-baddeed_0: Sẽ có cái pool\n00:35:10: 1-baddeed_0: Cầm NFT quăng vô\n00:35:12: 1-baddeed_0: Bấm stack\n00:35:14: 1-baddeed_0: Rồi\n00:35:16: 1-baddeed_0: Nó sẽ tăng cái lất của mình lên\n00:35:18: 1-baddeed_0: Được ha\n00:35:20: 1-baddeed_0: Đây là một cái\n00:35:22: 1-baddeed_0: Phần tranh thủ để giới thiệu cho mọi người biết\n00:35:24: 1-baddeed_0: Mình có những cái phần như vầy\n00:35:26: 1-baddeed_0: Sẽ release soon\n00:35:28: 1-baddeed_0: Tới khi nào có buổi đó\n00:35:30: 1-baddeed_0: Thì sẽ có những cái hướng dẫn chi tiết\n00:35:32: 1-baddeed_0: Ai đang cầm IC thì vô stack IC\n00:35:34: 1-baddeed_0: Ai đang có thể redeem cái NFT\n00:35:36: 1-baddeed_0: Do đạt được trách hiệu như trước đó\n00:35:38: 1-baddeed_0: Thì vô redeem\n00:35:40: 1-baddeed_0: Mấy anh em đang cầm gem của team\n00:35:42: 1-baddeed_0: Thì vô để stack luôn\n00:35:44: 1-baddeed_0: Rồi\n00:35:46: 1-baddeed_0: Thì đây là một cái nội dung\n00:35:48: 1-baddeed_0: Trong cái stack NFT\n00:35:50: 1-baddeed_0: Có phần của team mình\n00:35:52: 1-baddeed_0: Chuyện đầu tiên\n00:35:54: 1-baddeed_0: Chuyện thứ hai\n00:35:56: 1-baddeed_0: Song song với đó\n00:35:58: 1-baddeed_0: Đó là\n00:36:00: 1-baddeed_0: Anna vừa thiết kế một trang siêu đẹp\n00:36:02: 1-baddeed_0: Hà\n00:36:04: 1-baddeed_0: Tưởng như đây là trang hôm\n00:36:06: 1-baddeed_0: Khi vào trang này thì mình có gì\n00:36:08: 1-baddeed_0: Mình sẽ còn\n00:36:12: 1-baddeed_0: Giới thiệu về team mình\n00:36:16: 1-baddeed_0: Đây là một phần sản phẩm của bên Tôn Ôn\n00:36:18: 1-baddeed_0: Mình đang lấy\n00:36:20: 1-baddeed_0: Mình làm ví dụ trước để sử dụng\n00:36:22: 1-baddeed_0: Thì trên này có lúc stack nè\n00:36:24: 1-baddeed_0: Sau này thì có lúc stack vào trang này\n00:36:26: 1-baddeed_0: Đây là link của trang mình của team mình\n00:36:28: 1-baddeed_0: List ra tất cả các bounty, các quest\n00:36:30: 1-baddeed_0: List ra mấy cái event này nọ\n00:36:32: 1-baddeed_0: Mà team mình đang làm\n00:36:34: 1-baddeed_0: Đang có data được aggregate lại đưa lên hết\n00:36:36: 1-baddeed_0: Sau đó dẫn vào lúc stack\n00:36:38: 1-baddeed_0: Đây là profile trang hồi nãy\n00:36:40: 1-baddeed_0: Nó thành\n00:36:42: 1-baddeed_0: Một cái\n00:36:44: 1-baddeed_0: Cái luồng cơ bản\n00:36:46: 1-baddeed_0: Hi vọng là với cái guồng này\n00:36:48: 1-baddeed_0: Nó có thể...mình đang tin là...\n00:36:50: 1-baddeed_0: Nếu mà thực hiện tốt\n00:36:52: 1-baddeed_0: Hàng tháng\n00:36:54: 1-baddeed_0: Từ trước tới nay\n00:36:56: 1-baddeed_0: Team mình trung bình sẽ chi khoảng đâu\n00:36:58: 1-baddeed_0: Khoảng 5000 USDT\n00:37:00: 1-baddeed_0: Cho hoạt động của\n00:37:02: 1-baddeed_0: Luận hành economic yield trên IC\n00:37:04: 1-baddeed_0: Nói chung\n00:37:06: 1-baddeed_0: Trong đó từ 2000-2500 là yield lấy thưởng\n00:37:08: 1-baddeed_0: Cho mấy hoạt động về submit\n00:37:10: 1-baddeed_0: Mấy article nè\n00:37:12: 1-baddeed_0: Làm bounty nè\n00:37:14: 1-baddeed_0: Hoặc là học hành gì mới\n00:37:16: 1-baddeed_0: Làm presentation các kiểu\n00:37:18: 1-baddeed_0: Cái chi tiết, cái framework của nó\n00:37:20: 1-baddeed_0: Sẽ được report lại sớm\n00:37:22: 1-baddeed_0: Trước đây thì nó chia làm nhiều bộ phận với nhau\n00:37:24: 1-baddeed_0: Ai...mỗi team sẽ có cái quota nhất định\n00:37:26: 1-baddeed_0: Mấy anh em làm việc với team nào\n00:37:28: 1-baddeed_0: Để được thưởng hết á\n00:37:30: 1-baddeed_0: Ai mà làm nhiều cái learning\n00:37:32: 1-baddeed_0: Ai làm nhiều cái bounty\n00:37:34: 1-baddeed_0: Sẽ có những phần lưỡi khác nhau\n00:37:36: 1-baddeed_0: Ai làm event các kiểu\n00:37:38: 1-baddeed_0: Hoặc là submit bài các kiểu\n00:37:40: 1-baddeed_0: Thì nó được thưởng các phần khác nhau\n00:37:42: 1-baddeed_0: Nói chung là nó sẽ giao động từ 2000-2500\n00:37:44: 1-baddeed_0: Một phần...\n00:37:46: 1-baddeed_0: 2000-2500 còn lại\n00:37:48: 1-baddeed_0: Thì nó sẽ đưa vào cái ứng dụng của...\n00:37:50: 1-baddeed_0: Ứng lương\n00:37:52: 1-baddeed_0: Mà là tạm thời thì nay là thấy\n00:37:54: 1-baddeed_0: Mấy anh em xài cũng hơi căng\n00:37:56: 1-baddeed_0: Nói chung là...\n00:37:58: 1-baddeed_0: Mấy anh này xài tiền kiểu gì mà\n00:38:00: 1-baddeed_0: Tháng nào cũng đi ứng lương hết\n00:38:02: 1-baddeed_0: Giống như là cứ đè tiền công ty ra\n00:38:04: 1-baddeed_0: Để ứng trước, tính tích\n00:38:06: 1-baddeed_0: Làm hay không thì chỉ ra để tính sau đó\n00:38:08: 1-baddeed_0: Thì nhìn cũng hơi căng\n00:38:10: 1-baddeed_0: Nói chung là...\n00:38:12: 1-baddeed_0: Nói chung là...\n00:38:14: 1-baddeed_0: Hi vọng là với cái...\n00:38:16: 1-baddeed_0: Kiểu này\n00:38:18: 1-baddeed_0: Mình đang bắt đầu mình shift dần\n00:38:20: 1-baddeed_0: Để tạo ra một cái công ty\n00:38:22: 1-baddeed_0: Chuyển dần sẽ thành một cái team\n00:38:24: 1-baddeed_0: Bến tố cập bậc thôi một xíu\n00:38:26: 1-baddeed_0: Mình sẽ chuyển\n00:38:28: 1-baddeed_0: Điều này sẽ là\n00:38:30: 1-baddeed_0: Sẽ build được một cái nền kinh tế\n00:38:32: 1-baddeed_0: Nho nhỏ\n00:38:34: 1-baddeed_0: Nền kinh tế địa phương ha\n00:38:36: 1-baddeed_0: Ờm...\n00:38:38: 1-baddeed_0: Nền kinh tế nhỏ nhỏ dựa trên cái này\n00:38:40: 1-baddeed_0: Thì đó là một cái...\n00:38:42: 1-baddeed_0: Nó là một cái thứ mới\n00:38:44: 1-baddeed_0: Một cái lý thuyết mới mà team đang thử nghiệm\n00:38:46: 1-baddeed_0: Vì những cái nền kinh tế web 3\n00:38:48: 1-baddeed_0: Nó show ra được là...\n00:38:50: 1-baddeed_0: Dùng...\n00:38:52: 1-baddeed_0: Khi mà có cơ chế incentivization cụ thể\n00:38:54: 1-baddeed_0: Rõ ràng, minh bạch\n00:38:56: 1-baddeed_0: User có thể...\n00:38:58: 1-baddeed_0: Lấy được tiền liền\n00:39:00: 1-baddeed_0: Nói user lấy tiền thì hơi kì\n00:39:02: 1-baddeed_0: Cái contributor có thể earn được ngay lập tức\n00:39:04: 1-baddeed_0: Thay vì đợi khoảng rất là lâu\n00:39:06: 1-baddeed_0: Cái mô hình kiểu cũ làm consulting á\n00:39:08: 1-baddeed_0: Nó ổn định nhưng mà nó đợi\n00:39:10: 1-baddeed_0: Cái...\n00:39:12: 1-baddeed_0: Chu kỳ ra khoảng 1 tháng\n00:39:14: 1-baddeed_0: Thì nó cũng hơi lâu đúng không?\n00:39:16: 1-baddeed_0: Với cái này nó bắt đầu nó chuyển dần dần qua\n00:39:18: 1-baddeed_0: Với cái này nó bắt đầu nó chuyển dần dần qua\n00:39:20: 1-baddeed_0: Cái này nó bắt đầu nó chuyển dần dần qua\n00:39:22: 1-baddeed_0: Mình sẽ có thể thử nghiệm nó\n00:39:24: 1-baddeed_0: Được ha?\n00:39:26: 1-baddeed_0: Đó là cái hiện trạng của team\n00:39:28: 1-baddeed_0: Để mấy anh em nắm và...\n00:39:30: 1-baddeed_0: Mình sẽ biến thành một cái protocol\n00:39:32: 1-baddeed_0: Mình sẽ biến thành một cái protocol\n00:39:34: 1-baddeed_0: Để khi chạy một cái network dạng giống như vậy\n00:39:36: 1-baddeed_0: Có thể mang ra sử dụng\n00:39:38: 1-baddeed_0: Ideally nếu\n00:39:40: 1-baddeed_0: Cái cơ chế này\n00:39:42: 1-baddeed_0: Mà mình có thể universalize nó\n00:39:44: 1-baddeed_0: Cho những cái cộng đồng khác\n00:39:46: 1-baddeed_0: Mang năng chất tương tự\n00:39:48: 1-baddeed_0: Thì làm cái phần...\n00:39:50: 1-baddeed_0: Mà thế giới web 3 nó chưa có touch vào\n00:39:52: 1-baddeed_0: Hoặc là rất là nhiều người đang muốn làm nó\n00:39:54: 1-baddeed_0: Nhưng mỗi người một hướng khác nhau\n00:39:56: 1-baddeed_0: Có thể...maybe là thành một cái product\n00:39:58: 1-baddeed_0: Cũng không chừng\n00:40:00: 1-baddeed_0: Hoặc không thành thì...thôi\n00:40:02: 1-baddeed_0: Mấy anh em được cơ hội để trải nghiệm\n00:40:04: 1-baddeed_0: Được ha?\n00:40:06: 1-baddeed_0: Rồi thì...\n00:40:08: 1-baddeed_0: Đây là nội dung cho cái chủ đề mà\n00:40:10: 1-baddeed_0: Đang muốn tranh thủ buổi này chia sẻ\n00:40:12: 1-baddeed_0: Kèm với đó...\n00:40:14: 1-baddeed_0: Thẳng thông báo luôn\n00:40:16: 1-baddeed_0: Đến cuối tháng này\n00:40:18: 1-baddeed_0: Đã ra mình có cái build up offline\n00:40:20: 1-baddeed_0: Mình sẽ thử cái chuyện đó\n00:40:22: 1-baddeed_0: Xem như thế nào...\n00:40:24: 1-baddeed_0: Nhưng mà dính ngày lễ...\n00:40:26: 1-baddeed_0: Tính tới tính lui hỏi thử hai nhóm\n00:40:28: 1-baddeed_0: Bữa trước mình vote á\n00:40:30: 1-baddeed_0: Trước lễ hay sau lễ đó\n00:40:32: 1-baddeed_0: Cũng hơi căng\n00:40:34: 1-baddeed_0: Chắc là lý do chính nhất là tại anh Nam\n00:40:36: 1-baddeed_0: Nó làm đám hỏi\n00:40:38: 1-baddeed_0: Mấy anh em bỏ đi hết sở Sài Gòn rồi\n00:40:40: 1-baddeed_0: Cũng khó để sắp xếp thời gian\n00:40:42: 1-baddeed_0: Vì vậy mà thông báo là tới...\n00:40:44: 1-baddeed_0: Vì vậy mà thông báo là...\n00:40:50: 1-baddeed_0: Tạm thời tháng 4 này sẽ không build up offline\n00:40:52: 1-baddeed_0: Lý do là như vậy\n00:40:54: 1-baddeed_0: Mình sẽ cố gắng mình sẽ dời qua tháng 5\n00:40:56: 1-baddeed_0: Hopefully\n00:40:58: 1-baddeed_0: Mà mỗi tháng 5 mà có cái nào nó...\n00:41:00: 1-baddeed_0: Nó cưới hay làm gì nữa thì...\n00:41:02: 1-baddeed_0: Cũng phải do anh\n00:41:04: 1-baddeed_0: Anh cũng cố gắng hết sức\n00:41:06: 1-baddeed_0: Tới đó cứ thế nào...\n00:41:08: 1-baddeed_0: Mấy anh em cứ chơi thôi\n00:41:10: 1-baddeed_0: Ha ha ha ha\n00:41:12: 1-baddeed_0: Mình sẵn thông báo đó\n00:41:14: 1-baddeed_0: Rồi bây giờ là đến một cái...\n00:41:16: 1-baddeed_0: Tiết mục cuối cùng\n00:41:18: 1-baddeed_0: Chủ đề cuối cùng\n00:41:20: 1-baddeed_0: Rồi mình phát IC thì mình nghỉ nha\n00:41:22: 1-baddeed_0: Mình còn 10 phút chinh thủ\n00:41:24: 1-baddeed_0: Ha ha ha ha\n00:41:26: 1-baddeed_0: Ha ha ha ha\n00:41:28: 1-baddeed_0: Ha ha ha ha\n00:41:30: 1-baddeed_0: Ha ha ha ha\n00:41:32: 1-baddeed_0: Để kêu anh em\n00:41:34: 1-baddeed_0: Kêu anh em cái này trước\n00:41:36: 1-baddeed_0: Có anh em comment với anh em không\n00:41:38: 1-baddeed_0: Có đóng góp ý kiến không\n00:41:40: 1-baddeed_0: Để mấy anh em nút build\n00:41:42: 1-baddeed_0: Build chơi vừa ý\n00:41:44: 1-baddeed_0: Vừa ý mọi người\n00:41:46: 1-baddeed_0: ...\n00:41:48: 1-baddeed_0: ...\n00:41:50: 1-baddeed_0: ...\n00:41:52: 1-baddeed_0: Từ từ...\n00:41:54: 1-baddeed_0: Có có có\n00:41:56: 1-baddeed_0: Có anh em nào có comment về chỗ này không\n00:41:58: 1-baddeed_0: Thấy giao diện này có ok không\n00:42:00: 1-baddeed_0: Giao diện này\n00:42:02: 1-baddeed_0: Nhìn...\n00:42:04: 1-baddeed_0: Nhìn có...\n00:42:06: 1-baddeed_0: Cute quá không\n00:42:08: 1-baddeed_0: So cute\n00:42:10: 1-baddeed_0: So cute\n00:42:12: 1-baddeed_0: Cute\n00:42:14: 1-baddeed_0: Đừng chích bớt lại\n00:42:16: 1-baddeed_0: Ha ha ha ha\n00:42:18: 1-baddeed_0: Ha ha ha\n00:42:20: 1-baddeed_0: Ha ha\n00:42:22: 1-baddeed_0: Ha ha\n00:42:24: 1-baddeed_0: Cái chết địch\n00:42:26: 1-baddeed_0: Tao xem hình nãy giờ mà anh em nói vậy\n00:42:28: 1-baddeed_0: Cái chết địch\n00:42:30: 1-baddeed_0: Cái chết địch\n00:42:32: 1-baddeed_0: Cái chết địch\n00:43:12: 1-baddeed_0: rồi ha, ok\n00:43:27: 1-baddeed_0: chân thủ qua chủ đề sau thì mình kết thúc nha\n00:43:29: 1-baddeed_0: mấy anh em\n00:43:30: 1-baddeed_0: nghỉ cuối tuần, kết thúc một tuần\n```\n\n![](assets/3-ogif-office-hours-0419_0419-3_compressed.mp4)\n```\n00:43:33: 1-baddeed_0: rồi, chủ đề của Liquidity\n00:43:35: 1-baddeed_0: hôm trước\n00:43:37: 1-baddeed_0: mình đã nói về chuyện là\n00:43:39: 1-baddeed_0: các thành phần trong một cái nền kinh tế\n00:43:41: 1-baddeed_0: trong đó là Liquidity nó sẽ có bao gồm\n00:43:43: 1-baddeed_0: buyer, seller\n00:43:45: 1-baddeed_0: market making\n00:43:46: 1-baddeed_0: broker, mấy kiểu\n00:43:48: 1-baddeed_0: nói về cái đó\n00:43:51: 1-baddeed_0: thật ra bài đó\n00:43:53: 1-baddeed_0: chỉ giới thiệu sơn, anh không có muốn\n00:43:55: 1-baddeed_0: nói về đó quá nhiều\n00:43:56: 1-baddeed_0: ở đây team đang có một cái list\n00:43:58: 1-baddeed_0: như thế này, khuyên cho mấy anh em\n00:44:01: 1-baddeed_0: mấy người đang\n00:44:02: 1-baddeed_0: đang làm trên này\n00:44:04: 1-baddeed_0: anh đang ở trước trên này\n00:44:06: 1-baddeed_0: rồi, trước là con son Liquidity nè\n00:44:09: 1-baddeed_0: Liquidity nói rồi\n00:44:11: 1-baddeed_0: đó là khả năng mà mình cân bật một tài sản gì đó\n00:44:13: 1-baddeed_0: nhanh chóng thành tiền mặt cash\n00:44:17: 1-baddeed_0: cái nào nó càng\n00:44:20: 1-baddeed_0: nó càng nhỏ má dần như chất lỏng vậy\n00:44:22: 1-baddeed_0: Liquidity, như thành Liquidity\n00:44:25: 1-baddeed_0: thì\n00:44:26: 1-baddeed_0: nó là dễ thanh khoản\n00:44:28: 1-baddeed_0: cái nào mà càng khó nó được mà\n00:44:29: 1-baddeed_0: cắt nhỏ ra để dễ dàng bán\n00:44:31: 1-baddeed_0: gọi là dễ dàng\n00:44:33: 1-baddeed_0: nói gì đó là\n00:44:34: 1-baddeed_0: tính thanh khoản nó thấp hơn\n00:44:37: 1-baddeed_0: bên tập nhất nói rồi\n00:44:39: 1-baddeed_0: chủ đề này có chủ đề stakeholder chứ cũng giới thiệu rồi\n00:44:41: 1-baddeed_0: cái component ở trong cái thị trường\n00:44:43: 1-baddeed_0: nói về chuyện là\n00:44:44: 1-baddeed_0: thị trường có buyer, có seller, có product\n00:44:47: 1-baddeed_0: có market\n00:44:49: 1-baddeed_0: có market maker\n00:44:53: 1-baddeed_0: có mấy thằng làm broker, có platform, mọi thứ\n00:44:56: 1-baddeed_0: thì cái yếu tố đó nó sẽ hình thành lên cái thị trường\n00:44:59: 1-baddeed_0: và trong đó cái tài sản nào ở giữa\n00:45:02: 1-baddeed_0: độ lớn của thị trường tổng thì nó gọi là cái market size\n00:45:05: 1-baddeed_0: nếu mà cắt nhỏ ra những góc độ là Liquidity á\n00:45:08: 1-baddeed_0: tiền mặt, cổng phí á, thì nó sẽ thành...\n00:45:10: 1-baddeed_0: 這是енно próh\n00:45:13: 1-baddeed_0: control\n00:45:29: 1-baddeed_0: cái nóng gỗ\n00:45:30: 1-baddeed_0: xong rồi nó mới lên cái phần\n00:45:32: 1-baddeed_0: giữ…\n00:45:33: 1-baddeed_0: lục definitely\n00:45:36: 1-baddeed_0: chút đứa đi\n00:45:38: 1-baddeed_0: giữ cũngねぇ\n00:45:38: 1-baddeed_0: Whoa!\n00:45:39: 1-baddeed_0: nhìn ra nước đó weil đó ơi!\n00:45:40: 1-baddeed_0: tốt đúng không? Và nếu mà thị trường đó nó dễ gom lại để mà có cái liquidity pool ở giữa\n00:45:50: 1-baddeed_0: dễ dàng quăng tiền vô để mình liquid tài sản của mình. Thì cái đó gọi là liquidity market ha.\n00:45:58: 1-baddeed_0: Tiếp lại chi tiết hơn thì là buổi sau mình sẽ intro cụ thể từng cái. Có một chủ đề hồi trước\n00:46:05: 1-baddeed_0: là tôi đã nói là tôi đã tự tư đầu cơ tuần vừa rồi nè. Sắp tới chắc tuần sau hoặc là tuần sau nữa không biết\n00:46:11: 1-baddeed_0: thì sẽ có liên quan tới đầu tư. Nó có cái khán niệm là DCA, M&A chơi nhiều thì không biết.\n00:46:18: 1-baddeed_0: Hi vọng là ảnh sẽ come up với một cái gì đó dễ hiểu cho những bạn mà chưa từng tham gia\n00:46:24: 1-baddeed_0: chủ đề mở động cho cái này. Bây giờ chủ đề liquidity nó nói chung là yếu tố mà anh quan tâm nhất.\n00:46:34: 1-baddeed_0: Rồi đó là thứ mà sản phẩm mình quan tâm nhất.\n00:46:35: 1-baddeed_0: Đó là cái đầu tiên mình muốn làm trong hình tài chính. Cũng có thể mở rộng ra nói một số cái\n00:46:41: 1-baddeed_0: client của mình đang làm gì với thị trường như thế nào.\n00:46:44: 1-baddeed_0: Và cái liquidity market nó được nhìn nhận như thế nào dưới góc dịch của đội tài chính.\n00:46:49: 1-baddeed_0: Thì thay mở rộng thớn đó. Đó là cái thứ mà anh đang thích nhất, đang quan tâm đó nhất.\n00:46:55: 1-baddeed_0: Vì một client của mình là đội nghệ nhân đang được rename thành Hatch Foundation.\n00:47:01: 1-baddeed_0: Chúng mình chắc là cái chiến lược đi Hatching.\n00:47:04: 1-baddeed_0: Vì một client của mình là đội nghệ nhân đang được rename thành Hatch Foundation.\n00:47:05: 1-baddeed_0: In general để rút tiền, rút cái liquidity trong cái liquidity pool nói chung ra khỏi thị trường, ra khỏi market.\n00:47:15: 1-baddeed_0: Dan có một chiến lược mà nó sẽ dành khoảng mấy năm nay.\n00:47:19: 1-baddeed_0: Có thể anh nói được cái đó. Để buổi sau nói.\n00:47:22: 1-baddeed_0: Bây giờ trước khi nói, đó là cái mở rộng của chủ đề là chuyện này.\n00:47:25: 1-baddeed_0: Trước khi nói sau bơm thì mình sẽ nói về cái liquidity market mà anh đang quan tâm là gì.\n00:47:30: 1-baddeed_0: Được hả?\n00:47:33: 1-baddeed_0: Đây, có một thứ mà anh rất là thích.\n00:47:34: 1-baddeed_0: Đó là cái bài nét .com.\n00:47:52: 1-baddeed_0: Đây, đây là biểu tượng dễ nhất của liquidity market của cái asset tên là BTC.\n00:48:02: 1-baddeed_0: BTC trái mọi người sẽ thấy. Đó là để nhìn nhận nó là cái liquidity market á.\n00:48:08: 1-baddeed_0: Thì đầu tiên phải đảm bảo là cái loại tài sản đó nó có thể dễ dàng được nó liên quyết đấy.\n00:48:16: 1-baddeed_0: Biến thành là liên quyết.\n00:48:18: 1-baddeed_0: Có người mua và có người bán.\n00:48:20: 1-baddeed_0: Thì cái đây là một cái hình dạng của, đây là một cái hình dạng của liquidity market.\n00:48:27: 1-baddeed_0: Ở mức độ dễ nhìn thấy nhất.\n00:48:30: 1-baddeed_0: Mình sẽ luôn luôn thấy có một cái này. Mọi người thấy không?\n00:48:33: 1-baddeed_0: Cái market trade này.\n00:48:34: 1-baddeed_0: Thì luôn luôn có những cái dòng, dòng đỏ tượng trưng cho người bán.\n00:48:38: 1-baddeed_0: Dòng đỏ tượng trưng cho người bán đúng rồi.\n00:48:41: 1-baddeed_0: Động thanh là người mua.\n00:48:43: 1-baddeed_0: Nó cứ mua liên tục như vậy.\n00:48:44: 1-baddeed_0: Tưởng tượng mình có cái tài sản như vậy.\n00:48:47: 1-baddeed_0: Mình quăng cái đây.\n00:48:49: 1-baddeed_0: Mình muốn liquid nó.\n00:48:52: 1-baddeed_0: Cứ quăng lên là sẽ có người mua.\n00:48:54: 1-baddeed_0: Mình muốn đang có liquid.\n00:48:57: 1-baddeed_0: Mình muốn kịch vợ một tài sản.\n00:48:59: 1-baddeed_0: Thì cứ lên đây có người mua.\n00:49:01: 1-baddeed_0: Thì nó cực, thị trường này liquid cực cao.\n00:49:04: 1-baddeed_0: Tính liquid nó cực cao.\n00:49:06: 1-baddeed_0: Và đây là hình dạng đầu tiên nó nói cho mấy em thấy.\n00:49:08: 1-baddeed_0: Đó là một cái nơi mà nó có thể hiện là tài sản.\n00:49:12: 1-baddeed_0: Tên tài sản là một.\n00:49:14: 1-baddeed_0: Cái thứ hai là có người bán và có người mua.\n00:49:17: 1-baddeed_0: Thì đây là dấu hiệu đầu tiên của cái market.\n00:49:20: 1-baddeed_0: Và nếu mà nó dễ dàng nó thành, thành khoản.\n00:49:23: 1-baddeed_0: Thì nó gọi là liquidity market.\n00:49:25: 1-baddeed_0: Đó là cái đầu tiên.\n00:49:26: 1-baddeed_0: Nghe hiểu?\n00:49:29: 1-baddeed_0: Ok.\n00:49:30: 1-baddeed_0: Cái thứ hai.\n00:49:32: 1-baddeed_0: Đây là cái thứ mà nó ít người nói hơn.\n00:49:34: 1-baddeed_0: Đó là Shopee.\n00:49:37: 1-baddeed_0: Shopee này nếu mà nhìn khéo thì nó cũng là một cái liquidity market.\n00:49:41: 1-baddeed_0: Mà nó là mặt hàng gì?\n00:49:44: 1-baddeed_0: Mặt hàng gì?\n00:49:50: 1-baddeed_0: Cách đây khoảng một năm,\n00:49:53: 1-baddeed_0: ước mà Thành Phạm có làm một cái bài,\n00:49:55: 1-baddeed_0: cái bài là\n00:49:57: 1-baddeed_0: Radio Talk.\n00:49:58: 1-baddeed_0: Radio Talk với lại một cái team làm về data á.\n00:50:01: 1-baddeed_0: Nó có đi nó, nó đi nó chắc giá.\n00:50:04: 1-baddeed_0: Của những mặt hàng.\n00:50:05: 1-baddeed_0: Ví dụ mặt hàng về iPhone nhỉ.\n00:50:15: 1-baddeed_0: Đây thì mình thấy.\n00:50:16: 1-baddeed_0: Cái thứ mà mình nhìn thấy ở trên đây á.\n00:50:18: 1-baddeed_0: Thật ra nó là một cái dạng khác.\n00:50:21: 1-baddeed_0: Đây là những cái lệnh.\n00:50:23: 1-baddeed_0: Đây là những cái lệnh ban.\n00:50:25: 1-baddeed_0: Cái trang này nó không kiểm thị những cái lệnh mua.\n00:50:27: 1-baddeed_0: Nhưng nó hiện tại những cái lệnh bán.\n00:50:30: 1-baddeed_0: Và để mình đáp xét những cái lệnh bán đó.\n00:50:32: 1-baddeed_0: Ví dụ như con này.\n00:50:34: 1-baddeed_0: Có cái spec như vầy.\n00:50:36: 1-baddeed_0: Thì đây là một cái lệnh bán của nó.\n00:50:37: 1-baddeed_0: Đây là một cái lệnh bán. Đây là hai lệnh bán. Đây là ba lệnh bán.\n00:50:40: 1-baddeed_0: Thì khi mình shop lại, nhận list á.\n00:50:42: 1-baddeed_0: Thì nếu mà nhìn nhanh, nó sẽ tương đương.\n00:50:45: 1-baddeed_0: Với cái này đúng không?\n00:50:46: 1-baddeed_0: Đây là những cái lệnh bán.\n00:50:48: 1-baddeed_0: Với cái mặt hàng lúc này tính là iPhone chơi cho V&D.\n00:50:51: 1-baddeed_0: Đây là một cái hình dạng khác của liquidity market.\n00:50:54: 1-baddeed_0: Một cách khéo hơn đó là.\n00:50:57: 1-baddeed_0: Cái người seller người ta tham gia vào thị trường á.\n00:50:59: 1-baddeed_0: Với vai trò exchange tham gia vào trường Bitcoin.\n00:51:02: 1-baddeed_0: Hoặc là thị trường tóc nói chung.\n00:51:04: 1-baddeed_0: Thì đã là seller có list lên.\n00:51:06: 1-baddeed_0: Thì cái này nó sẽ tương đương là một cái lệnh bán.\n00:51:09: 1-baddeed_0: Mình là người dù như lệnh mua đi.\n00:51:11: 1-baddeed_0: Hôm nay dù như mặt hàng này có dịch vụ cao.\n00:51:13: 1-baddeed_0: Có giảm giá. Thì lại cái price của nó nó drop xuống.\n00:51:16: 1-baddeed_0: Thì bằng chân mình mua mình là có lệnh.\n00:51:18: 1-baddeed_0: Lệnh đó là lệnh mua.\n00:51:20: 1-baddeed_0: Thì nói chung là cứ ở những nơi nào nó xuất hiện.\n00:51:23: 1-baddeed_0: Dưới góc độ làm rolling của mình á.\n00:51:25: 1-baddeed_0: Những nơi nào nó xuất hiện.\n00:51:26: 1-baddeed_0: Mình có thể tìm ra một cái hình thái như vậy.\n00:51:28: 1-baddeed_0: Thì anh em sẽ hiểu.\n00:51:29: 1-baddeed_0: Nó chỉ là các cái display khác.\n00:51:31: 1-baddeed_0: Và cái thị trường này hoàn toàn có thể được mua liên hoàn là giống vậy.\n00:51:35: 1-baddeed_0: Thì tương đương một cái thứ đứng giữa.\n00:51:39: 1-baddeed_0: Giữa cái hạt hóa kiểu như vậy.\n00:51:43: 1-baddeed_0: Với lại cả cái pocket.\n00:51:45: 1-baddeed_0: Anh em sẽ dùng cái con NFT.\n00:51:49: 1-baddeed_0: Nhìn NFT sẽ dễ hiểu hơn nữa.\n00:51:52: 1-baddeed_0: Tương đương nha.\n00:51:53: 1-baddeed_0: Ví dụ như đây.\n00:51:54: 1-baddeed_0: Đây là một cái app.\n00:51:56: 1-baddeed_0: Một loại asset.\n00:51:57: 1-baddeed_0: Một loại asset khác.\n00:51:59: 1-baddeed_0: Được đặt tên là NFT MATLAB.\n00:52:01: 1-baddeed_0: Thì tất cả những cái mình thấy hồi nãy.\n00:52:03: 1-baddeed_0: Như bên iPhone 15 đó.\n00:52:04: 1-baddeed_0: Ở đây cũng sẽ là một cái lệnh bán.\n00:52:07: 1-baddeed_0: Đây là cái lệnh sell.\n00:52:09: 1-baddeed_0: Và khi có người vô người ta mua.\n00:52:13: 1-baddeed_0: Thì nó sẽ thành một cái dòng như vầy.\n00:52:16: 1-baddeed_0: Thì đây cũng là một cái hình thái của Liquidity Market.\n00:52:21: 1-baddeed_0: Thì chuyện nhận ra Liquidity Market nó có hình dạng như thế nào.\n00:52:25: 1-baddeed_0: Nó sẽ quyết định cho chuyện là mình áp dụng cái chiến lược.\n00:52:29: 1-baddeed_0: Lạp sản phẩm trên đó.\n00:52:34: 1-baddeed_0: Mình sẽ hiểu là hành vi của những cái nhóm user.\n00:52:37: 1-baddeed_0: Thật ra nó sẽ cuối cùng.\n00:52:39: 1-baddeed_0: Nó sẽ quy về một số đầu mối nhất định thôi.\n00:52:41: 1-baddeed_0: Nó không có khác lắm.\n00:52:42: 1-baddeed_0: Và có quy luật cho chuyện đó.\n00:52:44: 1-baddeed_0: Đây là những cái lệnh bán.\n00:52:46: 1-baddeed_0: Và đây là những cái asset có người bán có người mua.\n00:52:48: 1-baddeed_0: Nó đang diễn ra như vậy hết.\n00:52:50: 1-baddeed_0: Thấy không?\n00:52:52: 1-baddeed_0: Rồi.\n00:52:53: 1-baddeed_0: Và khi nhìn lại.\n00:52:54: 1-baddeed_0: Bên này nó có chạc.\n00:52:56: 1-baddeed_0: Tại vì nó quá nhỏ.\n00:52:57: 1-baddeed_0: Có thể chắc được cái chạc.\n00:52:59: 1-baddeed_0: Bên này nó hơi khó để mình chắc cái chạc.\n00:53:01: 1-baddeed_0: Tại vì.\n00:53:02: 1-baddeed_0: Shopping nó không có cái xu thế nó làm gì đó.\n00:53:05: 1-baddeed_0: Nhưng mà nhìn.\n00:53:06: 1-baddeed_0: Các nhìn của Liquidity Market.\n00:53:07: 1-baddeed_0: Nhìn xong.\n00:53:08: 1-baddeed_0: Thì ta có shopping đó.\n00:53:10: 1-baddeed_0: Bạn này là như nhau không khác gì hết.\n00:53:12: 1-baddeed_0: Chỉ là cách hiển thị sản phẩm nó khác nhau thôi.\n00:53:15: 1-baddeed_0: Maybe vì tính chất của nó.\n00:53:16: 1-baddeed_0: Maybe là vì thị trường này.\n00:53:18: 1-baddeed_0: Mọi người không quen với những thế liệu tài chính.\n00:53:20: 1-baddeed_0: Nhưng mà với mức độ là mình là người đi làm sản phẩm tài chính.\n00:53:22: 1-baddeed_0: Thì nó sẽ.\n00:53:23: 1-baddeed_0: Nhìn thấy được cái sự giao hòa đó.\n00:53:25: 1-baddeed_0: Nó sẽ có một số cái lợi thế để quyết định.\n00:53:27: 1-baddeed_0: Thì đây.\n00:53:29: 1-baddeed_0: Thằng TenSort này.\n00:53:31: 1-baddeed_0: Là một cái nơi mà nó nhìn thấy cái idea đó.\n00:53:33: 1-baddeed_0: Nó biến.\n00:53:34: 1-baddeed_0: Một trong những cái làm.\n00:53:35: 1-baddeed_0: Biến cái.\n00:53:36: 1-baddeed_0: Cái chuyện mà giao dịch bên này á.\n00:53:38: 1-baddeed_0: Như như thấy nè.\n00:53:42: 1-baddeed_0: Đó. Một hình thái của nó.\n00:53:44: 1-baddeed_0: Những người này đang muốn bán.\n00:53:46: 1-baddeed_0: Những người này đang muốn mua.\n00:53:47: 1-baddeed_0: Đây là giao dịch cũ.\n00:53:49: 1-baddeed_0: Đây là.\n00:53:50: 1-baddeed_0: Cái giá được thay đổi theo thời gian.\n00:53:53: 1-baddeed_0: Đó.\n00:53:54: 1-baddeed_0: Đó nha.\n00:53:55: 1-baddeed_0: Với bên em hay trade thì đây là cái góc nhìn dễ nhìn nhất.\n00:53:58: 1-baddeed_0: Nhưng mà với team mình thì sao?\n00:54:01: 1-baddeed_0: Thì mọi người sẽ quen nhìn kiểu này hơn.\n00:54:03: 1-baddeed_0: Có một cái thị trường lớn.\n00:54:04: 1-baddeed_0: Rất là lớn.\n00:54:05: 1-baddeed_0: Khi được.\n00:54:06: 1-baddeed_0: Mấy cái đội làm.\n00:54:08: 1-baddeed_0: Sản phẩm nó nhìn tới á.\n00:54:10: 1-baddeed_0: Nó sẽ không nhìn đến góc độ.\n00:54:12: 1-baddeed_0: Full equity market.\n00:54:14: 1-baddeed_0: Nó sẽ là trang web listing.\n00:54:16: 1-baddeed_0: Trang web thế này thế kia.\n00:54:17: 1-baddeed_0: Nó không khai thác đến góc độ tài chính.\n00:54:19: 1-baddeed_0: Thành ra nó không áp dụng những cái.\n00:54:21: 1-baddeed_0: Kỹ thuật mà dân tài chính.\n00:54:23: 1-baddeed_0: Sải được.\n00:54:24: 1-baddeed_0: Trong những cái này.\n00:54:25: 1-baddeed_0: Tự hành.\n00:54:26: 1-baddeed_0: Rồi.\n00:54:27: 1-baddeed_0: Thì.\n00:54:28: 1-baddeed_0: Ngày hôm nay.\n00:54:29: 1-baddeed_0: Cái thứ muốn chia sẻ với mọi người là.\n00:54:31: 1-baddeed_0: Nếu mà bắt đầu.\n00:54:33: 1-baddeed_0: Có ứng thú với chuyện làm tài chính.\n00:54:35: 1-baddeed_0: Đặc biệt là với team banking.\n00:54:37: 1-baddeed_0: Mấy buổi sau được.\n00:54:38: 1-baddeed_0: Thì anh giới thiệu một số cái.\n00:54:39: 1-baddeed_0: Cái cách.\n00:54:40: 1-baddeed_0: Mà anh nhìn thấy được.\n00:54:42: 1-baddeed_0: Những cái đội.\n00:54:43: 1-baddeed_0: Nó là em em.\n00:54:44: 1-baddeed_0: Những cái đội.\n00:54:45: 1-baddeed_0: Những cái đội stakeholder.\n00:54:46: 1-baddeed_0: Trong cái thị trường này.\n00:54:47: 1-baddeed_0: Tụi nó làm sao để nó.\n00:54:49: 1-baddeed_0: Nó.\n00:54:50: 1-baddeed_0: Nó.\n00:54:51: 1-baddeed_0: Nó exploit được thị trường này.\n00:54:52: 1-baddeed_0: Nó.\n00:54:54: 1-baddeed_0: Mắt cách này cách kia.\n00:54:56: 1-baddeed_0: Nghe đi  Know này.\n00:54:57: 1-baddeed_0: Từ nay hãy giới thiệu về.\n00:55:00: 1-baddeed_0: Thế чего mình hát.\n00:55:07: 1-baddeed_0: Bằng.\n00:55:08: 1-baddeed_0: Ok.\n00:55:09: 1-baddeed_0: Lol nghề tụi này giới thiệu nghe nè.\n00:55:14: 1-baddeed_0: Nücken,\n00:55:20: 1-baddeed_0: sầu vô hơn vì.\n00:55:21: 1-baddeed_0: L должны sao.\n00:55:22: 1-baddeed_0: Làm sao.\n00:55:23: 1-baddeed_0: Trước cùng Chí nó có post một cái bài làm cái order book hay là cái AMM gì đó không nhớ nữa\n00:55:32: 1-baddeed_0: Bằng rớt gì đó, nhìn cũng giống giống\n00:55:36: 1-baddeed_0: Rồi ok\n00:55:44: 1-baddeed_0: Nếu có câu hỏi thì nội dung như đó nhé\n00:55:47: 1-baddeed_0: Về phần ability\n00:55:48: 1-baddeed_0: Là như đó\n00:55:52: 1-baddeed_0: Câu hỏi cho mọi người là\n00:55:55: 1-baddeed_0: Tìm một cái ví dụ tương tự như shopping\n00:56:00: 1-baddeed_0: Một cái industry cụ thể\n00:56:04: 1-baddeed_0: Mà đã được những cái đội bị nó khai thác\n00:56:10: 1-baddeed_0: Là thị trường truyền thống nhưng mà đã được những đội nó khai thác\n00:56:14: 1-baddeed_0: Để nó tài chính hóa ngành đó\n00:56:21: 1-baddeed_0: Tìm một cái ví dụ\n00:56:22: 1-baddeed_0: Và tớp ví dụ thì\n00:56:25: 1-baddeed_0: Nói là Paisie\n00:56:27: 1-baddeed_0: Ghi cái brand ra nếu mà được thì cho giải thích hoặc là cho screenshot của phần đấy nhé\n00:56:33: 1-baddeed_0: Vậy dễ hơn\n00:56:52: 1-baddeed_0: Nhiều là lưu da\n00:57:05: 1-baddeed_0: Các anh xem\n00:57:08: 1-baddeed_0: Xem cái am un\n00:57:11: 1-baddeed_0: unpreb\n00:57:14: 1-baddeed_0: lum\n00:57:16: 1-baddeed_0: B出來\n00:57:20: 1-baddeed_0: cho ví dụ nhé\n00:57:36: 1-baddeed_0: Tôi mình sẽ đến đây\n```\n","title":"OGIF Office Hours #3 - Generative AI, Tokenomics, and Finance Talks","short_title":"#3 Generative AI, Tokenomics, and Finance Talks","description":"Our third office hours community discussion, where we'll cover diverse topics ranging from the current state of the dwarf community and their experiences with devbox, insights on and continuation of liquidity markets, advancements in generative AI technology, to fun events like a lucky draw for icy. The goal is to foster learning by sharing weekly topics suggested through tags, encouraging collaborative growth among our members.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["monotykamary"],"date":"Sat Apr 27 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/3-20240419.md","slugArray":["updates","ogif","3-20240419"]},{"content":"\n86 minutes\nRecorded Apr 26, 2024\n\n### Summary\n\n[00:03](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3) Discussion on upcoming topics and team activities\n\n[14:53](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=893) Topics discussed: virtualization, personal finance, and trading\n\n[20:23](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=1223) Ordering process of different t-shirt sizes and stickers discussed.\n\n[23:10](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=1390) Discussion on community selections and upcoming activities\n\n[29:09](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=1749) Introduction to the concept of VM in the 1960s\n\n[31:48](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=1908) Virtual machines solve resource-sharing conflicts and offer hardware utilization\n\n[36:56](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=2216) Containers are lighter and offer namespace isolation\n\n[39:44](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=2384) Discussion on namespaces and containers\n\n[45:18](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=2718) Docker is user-friendly and convenient for setting up environments.\n\n[47:51](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=2871) Explanation of reference type and dependencies in development\n\n[53:45](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3225) Dollar cost averaging (DCA) is a strategy for investing.\n\n[56:25](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3385) Investing without a strategy leads to fluctuations\n\n[1:01:32](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3692) Understanding buy and sell orders in trading.\n\n[1:04:08](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3848) Different investment methods and their advantages and disadvantages\n\n[1:09:40](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=4180) Investment risks and considerations\n\n[1:12:35](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=4355) Discussion on the topic of financial market and teamwork\n\n[1:17:11](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=4631) Discussion on design methods and demo for Vinson implementation\n\n[1:19:49](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=4789) Overview of upcoming design process with C4 reviews\n\n[1:26:04](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=5164) Conclusion of the discussion\n\n### Transcript\n\n> The transcript formatting and language accuracy is a WIP, so it might look a little weird. This will be improved in later iterations.\n\n[00:03](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3) Discussion on upcoming topics and team activities\n\n- The conversation revolves around inviting friends, discussing topics related to history and dca, and updating team activities.\n- They talk about missing friends and the need for potential participants in the discussion.\n\n[14:53](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=893) Topics discussed: virtualization, personal finance, and trading\n\n- Virtualization is an evolutionary process and part of historical background\n- There was an article on personal finance and dollar cost averaging\n- Introduction to trading and technical updates on container uploading\n\n[20:23](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=1223) Ordering process of different t-shirt sizes and stickers discussed.\n\n- Various t-shirt sizes from S to XXL are being ordered for team members.\n- Each person will receive three free stickers along with the t-shirt order.\n\n[23:10](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=1390) Discussion on community selections and upcoming activities\n\n- Community members to select stack profiles for free stickers.\n- Plans for giveaways and upcoming holiday season activities.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/C6UpT7t8nd8?si=TtiburoUXjAEusEH&amp;start=1229\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[29:09](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=1749) Introduction to the concept of VM in the 1960s\n\n- VM concept introduced to address the problem of underutilized hardware\n- Original VM created for running multiple operating systems and users on the same computer hardware\n\n[31:48](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=1908) Virtual machines solve resource-sharing conflicts and offer hardware utilization\n\n- VMs enable multiple users to share hardware resources but suffer from disadvantages such as being heavy and difficult to share\n- Users found VMs difficult to use and share, leading to the concept of application containers\n\n[36:56](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=2216) Containers are lighter and offer namespace isolation\n\n- Containers reuse the kernel and virtual machines setup\n- Containers provide quicker, lighter environment setup and namespace isolation\n\n[39:44](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=2384) Discussion on namespaces and containers\n\n- Namespaces limit resources a container can see, while also directing resources internally.\n- Containers have initial disadvantages but require knowledge of general system concepts for use.\n\n[45:18](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=2718) Docker is user-friendly and convenient for setting up environments.\n\n- Docker runs fast on native units but not as efficient on other systems.\n- It is still popular due to ease of use and resource management benefits.\n\n[47:51](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=2871) Explanation of reference type and dependencies in development\n\n- Reference type bars are connected and don't need to repackage dependencies when there is a change in version.\n- Understanding Linux container architecture is crucial for using Unit C and encountering difficulties in applying it.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/C6UpT7t8nd8?si=9aF1i6ILqFZMRrH4&amp;start=2722\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[53:45](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3225) Dollar cost averaging (DCA) is a strategy for investing.\n\n- DCA involves investing a set amount regularly regardless of price fluctuations.\n- Benefits of DCA include risk minimization, independence from asset price and purchase time, ease of investment management, suitability for long-term investment, and discipline building.\n\n[56:25](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3385) Investing without a strategy leads to fluctuations\n\n- DCA breaks down the investment into smaller amounts over time to reduce the impact of market fluctuations.\n- Choosing a suitable investment, determining the investment amount, acceptable loss level, and investment period are key steps in applying the DCA strategy.\n\n[1:01:32](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3692) Understanding buy and sell orders in trading.\n\n- Explanation of how buy order leads to sell order and their similarities.\n- Detailed explanation of Dollar-Cost Averaging (DCA) and its application in practice.\n\n[1:04:08](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3848) Different investment methods and their advantages and disadvantages\n\n- Investing in Bitcoin during a price drop can lead to high profits, as seen in the case of El Salvador's president in 2021.\n- Dollar-cost averaging (DCA) involves long-term investment and is suitable for those with little capital, but it can make investors sensitive and prone to selling at a loss during market fluctuations.\n\n[1:09:40](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=4180) Investment risks and considerations\n\n- Research sketchy projects before investing\n- Beware of compound risks with Token coin and BTC pair\n\n[1:12:35](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=4355) Discussion on the topic of financial market and teamwork\n\n- Encouragement to research and bring new topics to the table in the financial market\n- Call to action for teamwork and collaboration to tackle specific topics and areas of expertise\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/C6UpT7t8nd8?si=DdT8feRq_TGJCM7Y&amp;start=3856\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:17:11](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=4631) Discussion on design methods and demo for Vinson implementation\n\n- Topics related to specific design introduction and methods were discussed\n- Plans to demo a part of Vinson implementation next week\n\n[1:19:49](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=4789) Overview of upcoming design process with C4 reviews\n\n- Introduction to design lessons by Vinson and the importance of C4 review process\n- Details on the schedule for upcoming technical posts and topic submissions\n\n[1:26:04](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=5164) Conclusion of the discussion\n\n- The speaker decides to end the video\n- Saying goodbye to the viewers and expressing the hope to meet them later\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/C6UpT7t8nd8?si=606Vk_MwgMuuPlnj&amp;start=5165\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n---\n\n**Vietnamese version**\n\nShort Summary for [OGIF Office Hours #4](https://www.youtube.com/watch?v=C6UpT7t8nd8) \n\nOGIF #4 - Thảo luận về các chủ đề liên quan đến DCA, Devbox\n\n[00:03](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3) Thảo luận về các chủ đề và lịch sử sắp tới\n\n[14:53](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=893) Thảo luận về các bài viết và chủ đề sắp tới trong phiên\n\n[20:23](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=1223) Quy trình đặt hàng áo phông và nhãn dán\n\n[23:10](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=1390) Thành viên cộng đồng có thể chọn từ các biểu tượng và nhận nhãn dán miễn phí\n\n[29:09](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=1749) Giới thiệu khái niệm máy V\n\n[31:48](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=1908) Máy ảo giải quyết xung đột và tối đa hóa việc sử dụng phần cứng\n\n[36:56](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=2216) Vùng chứa tái sử dụng tài nguyên để thiết lập hiệu quả.\n\n[39:44](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=2384) Thảo luận về sự khác biệt giữa không gian tên và quy trình chứa\n\n[45:18](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=2718) Mối quan tâm và cách sử dụng bảo mật Docker trên các hệ điều hành khác nhau\n\n[47:51](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=2871) Hiểu loại tham chiếu và sự phụ thuộc trong quá trình phát triển.\n\n[53:45](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3225) Trung bình chi phí bằng đô la (DCA) là một chiến lược đầu tư tiền một cách nhất quán theo thời gian bất kể biến động giá cả.\n\n[56:25](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3385) Phương pháp DC giúp giảm lỗ so với đầu tư không có chiến lược\n\n[1:01:32](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3692) Tìm hiểu lệnh mua và lệnh bán\n\n[1:04:08](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3848) Lợi nhuận và rủi ro trong chiến lược đầu tư\n\n[1:09:40](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=4180) Rủi ro và chiến lược đầu tư\n\n[1:12:35](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=4355) Thảo luận về hợp tác nhóm và lựa chọn chủ đề\n\n[1:17:11](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=4631) Thảo luận về chủ đề thiết kế sắp tới\n\n[1:19:49](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=4789) Thảo luận về tiêu chuẩn thiết kế C4 và các chủ đề sắp tới\n\n[1:26:04](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=5164) Kết thúc video và chào tạm biệt\n\n---\n\n**Detailed Summary for [OGIF Office Hours #4](https://www.youtube.com/watch?v=C6UpT7t8nd8)**\n\nTitle:  OGIF #4 - DCA, Devbox\n\n[00:03](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3) Thảo luận về các chủ đề và sự kiện sắp tới\n\n- Kế hoạch cập nhật tình hình đội và tiếp tục hoạt động sau kỳ nghỉ\n\n[14:53](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=893) Thảo luận về các bài viết và chủ đề sắp tới \n\n- Bài viết đầu tiên nói về ảo hóa và bối cảnh lịch sử của nó.\n- Bài viết thứ hai nói về tài chính cá nhân và đầu tư, tiếp nối bài viết trước của Huy Tiêu và giới thiệu về Trung bình chi phí bằng đô la.\n\n[20:23](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=1223) Quy trình đặt hàng áo phông và nhãn dán\n\n- Các kích thước có sẵn nằm trong khoảng từ S đến XXL, với sự phân bổ kích thước cụ thể được người nói đề cập.\n- Mỗi người sẽ nhận được ba nhãn dán miễn phí khi đặt hàng.\n\n[23:10](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=1390) Thành viên cộng đồng có thể chọn từ các biểu tượng và nhận nhãn dán miễn phí\n\n- Các thành viên cộng đồng được khuyến khích chọn các pip logo từ các tùy chọn có sẵn\n- Mỗi người sẽ nhận được ba nhãn dán miễn phí khi lựa chọn\n\n[29:09](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=1749) Giới thiệu khái niệm máy V\n\n- Giới thiệu máy V vào những năm 1960 để giải quyết vấn đề máy tính lớn một người dùng\n- Mục đích ban đầu của máy V là chạy nhiều hệ điều hành và người dùng trên cùng một phần cứng\n\n[31:48](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=1908) Máy ảo giải quyết xung đột và tối đa hóa việc sử dụng phần cứng\n\n- Máy ảo cho phép nhiều người dùng tương tác trên một máy tính mà không bị xung đột bằng cách điều khiển hai máy tính cùng nhau trong một thiết bị phần cứng\n- Tuy nhiên, dạng máy ảo ban đầu có nhược điểm như nặng, khó chia sẻ do phải thiết lập nhiều tài nguyên.\n\n[36:56](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=2216) Vùng chứa tái sử dụng tài nguyên để thiết lập hiệu quả.\n\n- Các thùng chứa tái sử dụng kernel và VM, thiết lập các kênh riêng cho HĐH.\n- Các thùng chứa nhẹ hơn, sử dụng ít tài nguyên hơn và cho phép tạo các môi trường riêng biệt trên cùng một phần cứng.\n\n[39:44](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=2384) Thảo luận về sự khác biệt giữa không gian tên và quy trình chứa\n\n- Không gian tên trong một vùng chỉ tương tác với máy chủ của máy chủ\n- Các vùng chứa có những hạn chế về tài nguyên mà chúng có thể truy cập so với không gian tên\n\n[45:18](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=2718) Mối quan tâm và cách sử dụng bảo mật Docker trên các hệ điều hành khác nhau\n\n- Docker chạy với quyền root dẫn đến báo cáo bảo mật không đầy đủ. Tuy nhiên, nó cung cấp hiệu suất nhanh trên các đơn vị gốc nhưng phải đối mặt với các vấn đề trên các hệ thống ngoài vùng chứa.\n- Bất chấp những lo ngại về bảo mật, Docker vẫn phổ biến vì tính chất thân thiện với người dùng và sự tiện lợi trong việc thiết lập môi trường.\n\n[47:51](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=2871) Hiểu loại tham chiếu và sự phụ thuộc trong quá trình phát triển.\n\n- Các thanh loại tham chiếu được kết nối và không chồng chéo. Sự phụ thuộc được đề cập nếu cần thiết.\n- Bộ chứa Linux yêu cầu kiến thức về kiến trúc và các phần phụ thuộc. Nó cung cấp một môi trường thân thiện hơn để phát triển.\n\n[53:45](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3225) Trung bình chi phí bằng đô la (DCA) là một chiến lược đầu tư tiền một cách nhất quán theo thời gian bất kể biến động giá cả.\n\n- DCA cho phép tính toán chi phí trung bình theo thời gian và có khả năng thu được lợi nhuận hấp dẫn.\n- Lợi ích của DCA bao gồm giảm thiểu rủi ro từ biến động của thị trường, không phụ thuộc vào giá tài sản/thời điểm mua, dễ dàng quản lý các khoản đầu tư dài hạn và xây dựng kỷ luật đầu tư.\n\n[56:25](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3385) Phương pháp DC giúp giảm lỗ so với đầu tư không có chiến lược\n\n- Đầu tư 3.000 USD trong tháng đầu tiên thay vì chia đều hàng tháng\n- Lựa chọn khoản đầu tư phù hợp, xác định mức lỗ tối đa, thời gian đầu tư và chiến lược vào/ra\n\n[1:01:32](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3692) Tìm hiểu lệnh mua và lệnh bán\n\n- Lệnh mua dẫn đến lệnh bán có cùng giá trị\n- Thảo luận về Trung bình chi phí bằng đô la (DCA) và ứng dụng của nó trong các tình huống thị trường khác nhau\n\n[1:04:08](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=3848) Lợi nhuận và rủi ro trong chiến lược đầu tư\n\n- Chiến lược đầu tư Bitcoin của El Salvador và lợi nhuận tiềm năng\n- Ưu điểm và nhược điểm của phương pháp đầu tư Trung bình chi phí bằng đô la (DCA)\n\n[1:09:40](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=4180) Rủi ro và chiến lược đầu tư\n\n- Hãy nghiên cứu kỹ lưỡng trước khi đầu tư vào những dự án sơ sài hoặc sai lệch.\n- Hãy xem xét rủi ro khi kết hợp Token coin và BTC, điều này có thể dẫn đến thua lỗ gộp trong thời kỳ thị trường suy thoái.\n\n[1:12:35](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=4355) Thảo luận về hợp tác nhóm và lựa chọn chủ đề\n\n- Khuyến khích làm việc nhóm và lựa chọn chủ đề cho các cuộc thảo luận và nghiên cứu trong tương lai\n- Đề cập đến việc phân chia chủ đề giữa các thành viên trong nhóm dựa trên kinh nghiệm và chuẩn bị chủ đề cho buổi học tiếp theo\n\n[1:17:11](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=4631) Thảo luận về chủ đề thiết kế sắp tới\n\n- Chủ đề tuần tới sẽ tập trung vào việc giới thiệu và thiết kế một thiết kế cụ thể bằng một phương pháp cụ thể.\n- Bài thuyết trình sẽ ngắn gọn, trình bày cách né tránh cỡ 3 và thảo luận về kiến trúc.\n\n[1:19:49](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=4789) Thảo luận về tiêu chuẩn thiết kế C4 và các chủ đề sắp tới\n\n- Tiêu chuẩn thiết kế C4 và sự cần thiết chỉ vẽ cái cơ bản\n- Các chủ đề và bài viết sắp tới, bao gồm các cuộc thảo luận về kỹ thuật và quy trình giao dịch\n\n[1:26:04](https://www.youtube.com/watch?v=C6UpT7t8nd8&t=5164) Kết thúc video và chào tạm biệt. \n","title":"OGIF Office Hours #4 - DCA, Devbox","short_title":"#4 DCA, Devbox","description":"Our fourth office hours community discussion, from DCA to Devbox topic. The goal is to foster learning by sharing weekly topics suggested through tags, encouraging collaborative growth among our members.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Wed Jun 05 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/4-20240426.md","slugArray":["updates","ogif","4-20240426"]},{"content":"\n### Topics and Highlights\n\n- **Swap ICY-BTC:** Huy shared updates on the ICY-BTC swap mechanism, explaining the current state and adjustments needed to ensure accurate ICY valuation during swaps.\n- **GitHub BotL:** Thanh introduced a GitHub bot to automate PR reviews, aiming to improve processing speed and consistency in code management.\n- **Memo UI:** The team presented improvements to the Memo user interface, focusing on better data access and user experience.\n- **Agentic: MCP-DB:** Huy discussed the MCP-DB system, highlighting how it handles data storage and retrieval to support agents in automated workflows.\n- **Pocket Turning, Recapable:** Vincent shared progress on the Pocket Turning and Recapable, outlining the completion of core gameplay and next steps.\n- **Funding Rate Arbitrage:**  Antran presented a strategy for funding rate arbitrage across multiple exchanges, addressing technical challenges and execution strategies.\n\n### Vietnamese Transcript\n\n**[05:30]** Hôm nay chắc mình bắt đầu sớm nha. Buổi hôm nay chắc kết hợp với lại anh trong buổi meeting một xíu. Một phần là sẽ làm showcase, cái thứ hai là anh tổng kết một số việc mà bữa trước có trao đổi với mấy anh em á. Cái số hai, cái số ba là mình sẽ bắt đầu cho mấy anh em đăng ký công việc. Hiện tại để mà dễ trước, chắc là mình sẽ để cho Huy Nguyễn đi show mấy cái phần bên Huy trước, liên quan tới ICY một tí, xong rồi show một số cái về tech mà team mình đang làm nè. Để mình có một cái snapshot về chuyện là team tech thì hiện nay như thế nào nhé. Rồi sắp tới thì team mình cần gì, với lại mấy anh em xem contribute được gì vào đó ha. \n\n**[06:35]** Huy, Thành đâu? Nhường sân khấu này nè. Rồi ok, nội dung đầu tiên, chắc là bên ICY Swap trước đi. Mình announce đó, hồi tuần trước, tuần này deploy lên rồi thì giờ những cái khác biệt như thế nào, chắc nhờ Huy đi lại hết mấy series đó.\n\n**[07:29]** Alo, rồi rồi, đã xem màn hình rồi. Thì bây giờ mọi người có thể vào trang ICY Swap để mà swap được rồi. Đây, mình chỉ số liệu nha. Nhưng mà ở trên đây thì nó đang ready hết tất cả mọi thứ rồi. Việc làm duy nhất bây giờ là đang ngồi soát lại mấy cái số ICY á. Tại vì lúc trước vận hành á, thì mình vận hành theo kiểu là mình neo cái giá ICY, nên mình cũng không quan tâm cái lượng lưu thông (circulated) lắm. Nên có mấy trường hợp là mình để vô mấy cái ví của team, hoặc là chuyển qua mấy cái Mochi Balance của em hoặc là của anh Bảo. Thì mấy cái đó đang cần rà soát lại để mà nó ra cái số lưu thông đúng. Tại vì giờ mình sẽ ngồi, cái giá của mình nó sẽ dynamic theo cái pool nên cần ngồi check lại cái đó thì cũng gần xong hết rồi.\n\n**[09:09]** Giờ còn mỗi cái account của anh Bảo là cần kiểm tra lại thôi. Nhớ có đợt là chuyển cho anh Bảo, giờ đang ngồi xem lại cái phần đó rồi cộng trừ lại rồi cắt cái phần đó ra khỏi cái circulated thì số này nó sẽ ra đúng. Còn lại hiện tại muốn swap ủng hộ thì cũng có thể swap được ở trên trang này. Lịch là đang vậy. Em show thử cái list Holder của mình hiện tại cho mấy anh em xem chắc cần biết nhiều hơn xíu. Trước giờ mọi người tham gia không quan tâm nhiều lắm nhưng mà chắc lần này thì mình cần để ý hơn.\n\n**[09:51]** ICY của mình mình deploy ở trên Base, đúng không? Nên khi anh em vào trong cái list Holder, mọi người sẽ thấy được một cái list khoảng tất cả những cái ví nào đang được giữ ICY của team mình, thì là CCK Holder ha. Là một. Rồi thì cái link để mà vô đây chắc Huy share nha. Chứ mọi người lên mà search thì chắc không biết được đâu.\n\nĐầu tiên là anh em cần nắm cái này. Quay qua đoạn này rồi. Anh nghĩ mấy anh em cần quan tâm phần này nhiều hơn xíu. Nó trở thành cái norm của thế giới tech luôn rồi, không cần làm gì mới nữa. Nên anh em nắm được thì sẽ ok hơn.\n\n**[10:33]** ICY của mình hiện đã được list. Trong danh sách này có các ví minter, ví dùng để lập ngân sách cho các hoạt động, và một số ví đang nắm giữ lượng ICY lớn. Các hoạt động liên quan đến staking ICY sẽ được triển khai dần dần trong thời gian tới. Đây là thông tin đầu tiên anh em cần nắm rõ.\n\n**[11:15]** Huy, demo thử luồng swap đi. Có ai có địa chỉ Bitcoin với một ít ICY không? Vincent có ở đây không? Ok, giờ thử swap từ ICY sang Bitcoin. Giá hiện tại được tính theo cơ chế động dựa trên lượng ICY đang lưu hành và pool. Chức năng swap rất đơn giản, chỉ cần điền số lượng, bấm swap là xong.\n\n**[12:27]** Khoan đã, đừng nhập địa chỉ ảo. Ok, vậy là ổn rồi. Khung đầu tiên là ICY như bình thường. Ở dưới thì đang hiển thị đơn vị là satoshi, tức là đơn vị nhỏ nhất của Bitcoin. Khi nhập số lượng vào, nó sẽ tự động chuyển đổi. Tuy nhiên, tỷ giá hiện tại đang bị lệch một chút, khoảng 1.2 thay vì 1.5. Đây chắc là lỗi tính toán nhỏ, chỉnh lại là được.\n\n**[13:28]** Cần có số ICY tối thiểu để swap. Thử nhập 30 ICY xem sao. Refresh lại thử xem có được không.\n\n**[14:43]** Hình như không đủ tiền trong ví rồi. Bạn có ETH trên Base không? Chuyển qua Base và kiểm tra lại xem.\n\n**[15:51]** Không phải lỗi đó đâu. Vấn đề là account chưa được đăng ký nên không thể thực hiện giao dịch. Sẽ fix phần đó sau. Mục tiêu ở đây là giúp mọi người hiểu rõ hơn về cơ chế swap và cách định giá token. Nếu nắm rõ thì sau này sẽ dễ dàng hơn trong việc quản lý tokenomics.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pj13pwqkVdQ?si=0LryX12wLbTu3i1m&amp;start=806\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**[16:47]** Huy, giải thích nhanh lại cơ chế tính giá đi. Lần trước Quan demo chưa nói kỹ phần đó. Giá của ICY được xác định theo cơ chế minting, nghĩa là giá sẽ không thay đổi mạnh nếu có ai đó swap số lượng lớn. Nó không hoạt động theo kiểu cơ chế tạo lập thị trường tự động (AMM) mà giá sẽ được kiểm soát theo cơ chế minting. Cơ chế này giúp giá duy trì ổn định ngay cả khi có giao dịch lớn.\n\n**[17:43]** Hoàn toàn là nó phụ thuộc vào Bitcoin. Nên nếu giá Bitcoin tăng thì lượng ICY mà anh em đang cầm sẽ tăng về giá trị USD. Còn về cơ chế minting, nhờ Huy giải thích thêm một chút. Nói chung là cơ chế chung của mình trước giờ là mình sẽ cố định giá trị của ICY theo USDC. Anh em không cần quan tâm nhiều, cứ hiểu đơn giản là một ICY tương đương với 1.5 USD.\n\n**[18:37]**Phần đảm bảo này là để giúp team vận hành có thể đảm bảo là tới ngày thì sẽ đổi USDC vào trong contract để mọi người swap. Tỷ giá swap trong contract cũ là cố định ở mức 1.5 ICY, nhưng đó là model cũ. Model mới của mình thì linh hoạt hơn. Nếu anh em đã dùng Uniswap hay các AMM (Automatic Market Maker) khác thì nó cũng tương tự một chút. Ở đây, cơ chế hoạt động là bên dưới có một pool thanh khoản (liquidity pool), trong đó chứa cả ETH và USDC. Tùy vào tình hình của pool lúc đó, tỷ giá sẽ được điều chỉnh dựa trên lượng ETH và USDC trong pool.\n\n**[19:18]** Cơ chế của mình cũng tương tự như vậy. Giá ICY sẽ được quyết định bởi lượng Bitcoin trong pool và lượng ICY đang được lưu hành. Công thức đơn giản thôi: mình có lượng ICY (X), có lượng BTC (Y) trong pool, thì X/Y sẽ ra được giá trị của một ICY tính theo BTC. Công thức này là công thức toán học cơ bản, không có gì phức tạp.\n\n**[19:55]** Do cơ chế hoạt động của mình, sẽ có hai thời điểm làm thay đổi thanh khoản:\n\n1. **Thời điểm đầu tiên** là vào mỗi tháng, team vận hành sẽ đổ thêm BTC vào pool để làm chi phí cho các hoạt động của team. Lúc này giá ICY sẽ tăng lên một chút vì lượng BTC trong pool tăng lên.\n2. **Thời điểm thứ hai** là khi team đẩy thêm ICY vào pool (minting thêm). Khi mint thêm ICY, giá ICY trên thị trường sẽ giảm xuống do lượng ICY trong pool tăng lên.\n\n**[20:35]** Hai trường hợp trên sẽ ảnh hưởng trực tiếp đến giá ICY. Còn nếu giá Bitcoin thay đổi thì giá trị USD của ICY có thể thay đổi, nhưng giá ICY tính theo BTC thì không thay đổi. Market impact từ Bitcoin là yếu tố bên ngoài, không ảnh hưởng trực tiếp đến việc minting hoặc giá trị ICY trong pool.\n\n**[21:12]** Anh em có câu hỏi gì thêm thì đặt câu hỏi, tí nữa sẽ trả lời sau. À, có câu hỏi về việc swap ngược từ BTC về ICY đúng không? Hiện tại thì chưa có chức năng đó. Hiện tại chỉ hỗ trợ swap từ ICY sang BTC thôi, không có chức năng swap ngược lại. Tức là mua vào thì được, nhưng bán ra thì chưa hỗ trợ.\n\n**[21:40]** Cảm ơn Huy. Có gì cần lưu ý thêm không? Cần lưu ý là hiện tại vẫn đang trong giai đoạn thử nghiệm nên có thể có một số trường hợp ngoại lệ. Ví dụ như một số tình huống có thể phát sinh khi swap hoặc thanh khoản chưa đủ. Về cơ bản thì luồng hiện tại vẫn đang hoạt động ổn định.\n\n**[22:00]** Như là số lượng ICY tối thiểu để swap. Vì bản chất là team mình đang cover cái phần phí mà để mà làm gas trên ETH, trên Base và cả trên BTC luôn thì nên đang kiểu đang giới hạn cái số ICY nó swap nhiều tí để mà hạn chế với cái việc mà mọi người swap tầm 1-2 ICY để test á thì nó tốn cái chi phí gas nên đang để tầm trên 20 ICY mới cho mọi người swap trên web.\n\nCái thứ hai là ở cái do cái việc mà mình mint thêm ICY thì nó sẽ làm thay đổi giá thị trường, thì nên em đang disable luôn cái phần mà cơ chế cái ứng lương trước của mình.\n\n**[22:37]** Tức là đồng loạt ứng lương thì nó sẽ ảnh hưởng giá đúng không? Vậy cái lesson learn trong cái này đó là sau đợt này làm thì có vài điểm mà anh đang thấy là bắt đầu team mình đang tập trung vô build những cái tool nó hỗ trợ mình hoạt động. Cũng là một số cái thử nghiệm mới, cũng là một số cái mà hỗ trợ hoạt động thiệt sự. Nhưng mà sau khi xong mấy cái bài này thì nó sẽ ra được một số mấy cái article liên quan thì mấy anh em nếu mà trước đó không có tham gia những cái dự án đó có thể tìm lại những cái bài đó để mà coi được cái game, cái knowledge game từ cái đợt đó là cái gì của mấy anh em làm dự án đó ha. \n\n**[23:24]** Rồi thì trong cái vụ ICY Swap đợt này chắc là được hai ba bài phải không? Dạ, như được ba bài. Còn kiểu viết nhiều thêm thì vẫn có nhiều cái để viết. Ừ, thôi đó cứ thong thả từ từ đi.\n\n**[24:02]** Sau phần của Huy, anh cảm ơn Huy rồi chuyển sang nội dung thứ hai liên quan đến những gì team mình đang làm. Anh Bảo ai nói trước cũng được, nhưng chắc là để Thành nói trước. Thành bảo là em nói trước cũng được, em sẽ gom lại hết để anh cho mọi người biết team đang ở giai đoạn nào. Nhưng anh bảo là để Thành nói trước đi, tại vì đang có người bấm chuông. Rồi anh mời Thành bắt đầu.\n\n**[25:00]** Mọi người, Memo của mình là một trong những cái đợt lớn đợt này, có upgrade format lại cho nhìn nó ok hơn tí. Mình luôn muốn mình tạo những cái map content, những cái thứ mà mình đọc được cái mình up lên đây. Nhưng mà hiện tại cái mô hình đó thật ra nó cũng không có còn quá hiệu quả với chuyện là mấy cái model ra đời nó nén dữ liệu lại, rồi mình query trực tiếp từ đó ra thì nó sẽ hiệu quả hơn.\n\nThì cái point của chuyện là đưa những cái kiến thức mà nó bình thường lên trên Memo thì nó cũng không phù hợp lắm ha. Nên đợt này lúc mà làm lại thì có một cái ý chính để mà muốn nói với anh em đó là Memo hiện tại sẽ được dùng chỉ cho mục đích duy nhất thôi — đó là cái knowledge gain mà từ dự án.\n\nCái đó là gần như là những cái mới mà nó xuất phát từ chính cái hoạt động của cái team mình. Gần như trên đây sau này nó sẽ gồm là liên quan tới lĩnh vực gì đó, mình đã làm gì đó trong đó. Nó có nhiều hơn, maybe là sau một giai đoạn thì khi tụi nó train lại cái model thì những cái dữ liệu của mình á thì nó sẽ trở thành một phần của kiến thức chung cho cả cộng đồng.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pj13pwqkVdQ?si=MhsFuFFQ5NFKTlYS&amp;start=1556\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**[25:39]** Và cái phần này anh nghĩ là nó sẽ giúp ích rất nhiều cho cái chuyện mà mọi người làm kiểu training lại cho AI model sau này, hoặc là mấy cái chuyện mà mình muốn nó có cái việc mà suggestion kiểu tự động ấy.\n\n**[26:24]** Nội dung sẽ trở thành một phần trong mô hình đó hoặc nếu có mấy công cụ tìm kiếm trên internet, thì có thể bài của mình chỉ là một phần nhỏ trong nguồn tài liệu được tham khảo vào thôi, giống như là một phần nhỏ trong citation. Điều này cũng không có vấn đề gì lớn. Nhưng nhìn chung, toàn bộ những nội dung này sẽ gần như trở thành spirit của team.\n\nTrong lần nâng cấp lớn này, có một điểm chính mà Tuấn đã hoàn thành chưa nhỉ? Tuấn ơi, phần liên quan đến việc đồng bộ toàn bộ dữ liệu của team, nhất là về phần nội dung, hiện đang được định hướng như vậy để các thành viên nắm rõ hơn.\n\n**[27:00]** Tức là sau đợt này, các thành viên đang tham gia vào các dự án sẽ có xu hướng ngồi lại với nhau để xem xét kỹ hơn từ những dự án đó, và xác định rõ phần **knowledge gain** (kiến thức thu được) từ chính các dự án đó là gì. Sau đó, team sẽ đưa lên Memo làm nguồn tài liệu nội bộ cho team.\n\nPhần thứ hai là ở cuối mỗi bài sẽ có một phần liên quan đến **group of reading**. Hiện tại phần này vẫn chưa hoàn chỉnh, nhưng ý tưởng là sau khi hoàn thiện, sẽ có thêm phần thông tin tổng hợp về bài viết để người đọc có thể tra cứu và học thêm từ bài viết đó.\n\n**[27:47]** Ngoài ra, tất cả dữ liệu của team được viết ra sẽ được gán định danh ví dụ như **GitHub**, **Discord**, hoặc những kênh nội bộ khác. Dữ liệu này sẽ được upload lên dạng **blockchain storage** trên nền tảng **Arweave (AV)** – một nền tảng lưu trữ phi tập trung. Điều này giúp cho nội dung của team có một định danh rõ ràng và minh bạch.\n\nThêm vào đó, người đọc sẽ có thể xem lại bài viết, đánh giá hoặc để lại phản hồi trực tiếp trên bài viết. Đây là một phần của ý tưởng nâng cấp mới cho trang **Memo** của team.\n\n**[28:39]** Trước đây, team đã có ý định sử dụng Obsidian để quản lý nội dung, nhưng có vẻ như một số thành viên gặp khó khăn trong việc làm quen với công cụ đó. Vì vậy, hiện tại để làm cho mọi thứ đơn giản hơn, team sẽ chuyển sang cơ chế trực tiếp hơn. Cụ thể là thay vì phải làm qua Obsidian, các thành viên có thể submit nội dung trực tiếp vào repository của thư viện chung của team.\n\nCác thành viên chỉ cần đưa nội dung vào và submit trực tiếp qua nền tảng này, không cần phải tuân theo workflow bắt buộc của Obsidian nữa. Nếu ai vẫn muốn dùng Obsidian thì không sao, nhưng nếu không dùng thì cũng không ảnh hưởng gì cả. Đây là thay đổi cơ bản nhất trong hệ thống Memo của team.\n\n**[29:24]** Hiện tại team đang làm một số dự án chính, bao gồm:\n\n1. Bitcoin Swap – đã nhắc tới ở phần trước.\n2. Memo – vừa mới trình bày xong.\n3. Hai dự án nhỏ khác:\n- **agentic** – nhóm của Quang và Huy đang phát triển.\n- **github bot** – nhóm của Thành đang thực hiện, hiện đang test thử.\n\nGiờ chắc nhường lại cho Thành để chia sẻ thêm về những nội dung này.\n\n**[30:32]** Dự án này đã được khởi động hơn một tuần và đã chính thức chạy code được hơn một tuần. Mục đích chính của nó là tạo ra một hệ thống nhắc nhở (reminder). Trước đây, team thường gặp tình huống khi tạo pull request (PR), mọi người hay để đó và chờ chạy xong rồi quên luôn việc cần review. Tool này sẽ phục vụ cho việc theo dõi và cập nhật thông tin về các hoạt động hàng ngày trên github hoặc hàng tuần trên các kênh giao tiếp nội bộ của team.\n\n**[31:18]** Hệ thống này được thiết kế dưới dạng một tích hợp đơn giản. Luồng hoạt động cơ bản bao gồm một số use case như: thông báo cho người được assign để review, tương tác với GitHub API, và post thông tin vào các kênh nội bộ như Discord hoặc Slack. Hiện tại, team đang test thử trên Discord. Ngoài ra, team cũng đang thử nghiệm với agentic và một framework mới gọi là **Mastra AI**.\n\nFramework này khác với các tool Python thông thường. Một số thành viên trong team không quen làm việc với Python, nên team muốn thử nghiệm xem liệu sử dụng framework mới này có hiệu quả hơn các giải pháp hiện tại hay không. Framework này hỗ trợ các tính năng như setup môi trường, define các trạng thái để quản lý dữ liệu, và cho phép cấu hình lại tùy theo nhu cầu của team.\n\n**[32:19]** Cấu trúc của hệ thống này có hai phần chính:\n\n1. **Agentic App** – Đây là ứng dụng chính để xử lý các hoạt động của hệ thống.\n2. **Discord App** – Hỗ trợ việc gửi thông báo vào Discord.\n\nNgoài ra, hệ thống còn có một vài component phụ, như workflow để xử lý công việc theo lịch trình, kiểm tra và thông báo cho developer nếu có bất kỳ pull request nào đang chờ được review. Nếu pull request vượt quá một khoảng thời gian nhất định, hệ thống sẽ gửi thông báo để nhắc người thực hiện review.\n\n**[33:12]** Agentic App sẽ expose một vài API cho phép chat và theo dõi trạng thái của các pull request. Khi có một pull request được tạo ra, hệ thống sẽ tự động xác định các điều kiện như trạng thái của pull request (work in progress hay chưa), thời gian tạo pull request, và sẽ gửi thông báo cho người review sau khoảng 30 phút kể từ lúc tạo. Ví dụ: nếu có một pull request cần được review nhưng không có ai assigned hoặc đã quá thời gian xử lý, hệ thống sẽ tự động ping lại người phụ trách.\n\n**[35:02]** Thay vì phải theo dõi thủ công, hệ thống sẽ gắn con agent vào để tự động theo dõi và thông báo thông qua endpoint của hệ thống. Trong phần logic, hệ thống sẽ định nghĩa các điều kiện cụ thể, chẳng hạn như chỉ gửi thông báo nếu pull request được tạo trong vòng 30 phút hoặc đang trong trạng thái work in progress. Nếu pull request được cập nhật hoặc chuyển trạng thái, hệ thống sẽ tự động theo dõi và gửi thông báo cho developer để đảm bảo không bị sót.\n\n**[35:39]** Hệ thống sẽ hoạt động dựa trên code filter thông thường. Ngoài ra, nó sẽ có một số workflow khác như việc gửi thông báo vào cuối ngày để tổng hợp tình trạng của các pull request trên Discord. Hệ thống sẽ tự động gửi thông báo về số lượng pull request đang mở, tình trạng của chúng và trạng thái review hiện tại. Đây là chức năng chính của tool này — đóng vai trò như một công cụ reminder.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pj13pwqkVdQ?si=Zduog0abeAWXIIM4&amp;start=2107\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**[36:24]** Hệ thống cũng có thể tích hợp với các công cụ chat khác. Đơn giản là có thể tạo thêm một command và gửi request tới endpoint của hệ thống. Các request này sẽ được định nghĩa dựa trên schema cụ thể, ví dụ như input là **review ID** hoặc các thông tin khác liên quan đến trạng thái của pull request. Hệ thống sẽ lấy dữ liệu này và hiển thị trên giao diện mà người dùng thường xuyên sử dụng.\n\n**[37:04]** Phần xử lý backend của hệ thống được thực hiện thông qua tool Lippia, một công cụ định dạng dữ liệu JSON thành dạng bảng Markdown table hoặc dạng data binding. Hiện tại team đang test thử hai luồng xử lý này trước khi mở rộng thêm các tính năng khác. Khi hệ thống hoạt động ổn định, các workflow này sẽ được mở cho tất cả các thành viên trong team thử nghiệm và phát triển thêm.\n\n**[38:08]** Hệ thống được thiết kế để mở rộng một cách linh hoạt. Các thành viên trong team có thể tự phát triển và đóng góp các workflow khác nhau. Hệ thống này cho phép xây dựng các tool dưới dạng một đơn vị độc lập (**packaging unit**), sau đó kết hợp các đơn vị này lại để tạo ra các workflow phức tạp hơn. Khi muốn phát hành một workflow mới, các thành viên chỉ cần định nghĩa lại đơn vị cơ bản và tích hợp nó vào hệ thống.\n\nViệc mở rộng các workflow sẽ giúp hệ thống phát triển theo chiều ngang (mở rộng số lượng tính năng), thay vì theo chiều dọc (phát triển tính năng hiện tại). Khi số lượng các workflow tăng lên, hệ thống sẽ càng trở nên linh hoạt và mạnh mẽ hơn.\n\n**[38:54]** Về cơ bản, workflow được coi là lớp ứng dụng (application layer) tương tự như các API data trước đây. Hệ thống này sẽ hoạt động ở cấp độ tool, nhưng người dùng cuối sẽ tương tác với nó qua giao diện của workflow. Hiện tại, vẫn chưa có đơn vị nào triển khai thành công mô hình này ở quy mô lớn. Tuy nhiên, GitHub hiện đã mở rộng API cho các developer tạo các extension và tích hợp chúng trực tiếp vào GitHub.\n\n**[39:40]** Dify đang xây dựng một nền tảng để hỗ trợ các developer phát triển và triển khai các tool và workflow này một cách dễ dàng hơn. Mục tiêu là tạo ra một marketplace để các tool và workflow có thể được phân phối và sử dụng bởi nhiều người dùng khác nhau. Hệ thống này tương tự như một nền tảng mở, cho phép các developer bên thứ ba triển khai các tool và workflow của riêng họ.\n\nTrên nền tảng của Dify đã có khoảng 50 tool khác nhau. Một số tool đã từng được phát hành dưới dạng thử nghiệm, nhưng do chưa có định hướng rõ ràng và thiếu sự hỗ trợ từ cộng đồng, nên chúng chưa đạt được thành công như mong đợi.\n\n**[40:17]** Một số nền tảng trước đây đã thử xây dựng mô hình tương tự nhưng chưa đạt được thành công. Lý do là vì các tool này chỉ được xây dựng dưới dạng form, thiếu khả năng tương tác với dữ liệu bên ngoài và chưa có khả năng kết hợp các workflow phức tạp. Tuy nhiên, Dify đang tập trung vào việc giải quyết các vấn đề này để tạo ra một hệ sinh thái hoàn chỉnh cho các workflow và tool.\n\n**[40:59]** Các công cụ này cũng cho phép người dùng đẩy dữ liệu từ các nguồn bên ngoài vào hệ thống. Người dùng có thể gửi dữ liệu từ các ứng dụng bên ngoài qua các Open Form hoặc API. Dify sẽ tự động xử lý và định dạng dữ liệu để sử dụng trong các workflow của hệ thống.\n\n**[41:56]** Team đang tập trung vào hai hướng phát triển chính:\n\n1. Tiếp tục mở rộng và phát triển các workflow hiện có.\n2. Cải tiến và tối ưu hóa các công cụ hiện tại để hỗ trợ việc triển khai và sử dụng dễ dàng hơn.\n\nHệ thống được xây dựng dựa trên các tiêu chuẩn chung về thiết kế tool và workflow. Công cụ Smithery hiện tại đang đóng vai trò như một Agent để quản lý các workflow. Smithery cũng có thể được sử dụng như một Package Manager để cài đặt và quản lý các tool trong hệ thống.\n\n**[42:53]** Workflow sẽ hoạt động theo cơ chế, nếu một workflow nào đó trở nên phổ biến, mọi người có thể lấy nó về và sử dụng dưới dạng tool. Bản chất của các công cụ này là được thiết kế để phục vụ các domain cụ thể. Ví dụ như một công cụ để tạo file, tìm kiếm hoặc lấy file code chẳng hạn. Nó hoạt động giống như một SDK, tức là một bộ thư viện mà bạn chỉ cần import vào để sử dụng.\n\n**[43:37]** Khi đã tích hợp vào SDK, bạn có thể sử dụng các method sẵn có để thao tác với dữ liệu. Điều này cho phép tích hợp dễ dàng vào các công cụ AI. Hiện tại, chỉ có Cross là hỗ trợ trực tiếp cho các thao tác này. Tuy nhiên, trong tương lai, nó sẽ được chuẩn hóa để các công cụ khác cũng có thể dễ dàng tích hợp. Trường hợp của Manus là một ví dụ. Manus sử dụng rất nhiều tool khác nhau, tuy nhiên khi so sánh với hệ thống agent trong Smithery, về cơ bản chúng là hai lớp hoàn toàn khác nhau.\n\n**[44:15]** Trong hệ thống của Manus, các công cụ được kết hợp lại để tạo ra các workflow tổng quát hơn. Các công cụ này hoạt động ở các lớp khác nhau, trong khi các agent trong Smithery được thiết kế để hoạt động độc lập. Câu hỏi đặt ra là làm thế nào để phân biệt rõ ràng sự khác nhau giữa hệ thống của Manus và hệ thống agent trong Smithery. Có một bài tóm tắt về điều này đã được đăng trong kênh AI Club — nội dung chính nói về khả năng suy nghĩ (thinking) và khả năng sử dụng máy tính (computer use).\n\n**[45:09]** Cơ chế của hệ thống Manus là một hệ thống service-oriented. Để kết hợp nhiều tool với nhau trong cùng một workflow, cần phải định nghĩa rõ các bước thực hiện. Ví dụ như bước 1 cần sử dụng tool nào, bước 2 cần sử dụng tool nào, v.v. Điều này đòi hỏi các bước phải được cấu hình cụ thể. Tuy nhiên, hệ thống mới có khả năng suy luận để tự động xác định xem cần sử dụng những công cụ nào để hoàn thành tác vụ. Đây chính là điểm khác biệt giữa hệ thống mới và các hệ thống cũ.\n\n**[45:59]** Cụ thể, hệ thống mới có thể nhận biết được một tác vụ cần sử dụng bao nhiêu công cụ, thực hiện qua các bước nào, và có thể điều chỉnh thứ tự thực hiện một cách thông minh. Đây là một cơ chế đặc biệt và khác biệt so với các hệ thống cũ. Nói cách khác, nó hoạt động như một Supervisor — có khả năng suy luận và đưa ra quyết định về thứ tự và phương pháp thực hiện các bước trong workflow.\n\n**[46:35]** Hệ thống Supervisor hoạt động ở lớp cao hơn so với các agent trong  Smithery. Các agent trong  Smithery chỉ đơn giản là các công cụ thực thi một tác vụ cụ thể, trong khi Supervisor có khả năng quản lý và điều phối toàn bộ quá trình thực hiện tác vụ. Việc tích hợp Supervisor cho phép hệ thống hoạt động một cách linh hoạt hơn, đồng thời dễ dàng mở rộng và bổ sung thêm các công cụ mới.\n\n**[47:33]** Mục tiêu của team là hiểu rõ cách hoạt động của hệ thống và nắm được cơ chế điều hành của các workflow. Nếu có thể xác định được cách thức triển khai và quản lý các workflow, thì sẽ có thể chọn lọc và sử dụng các công cụ hiệu quả hơn. Đây là điều mà team đang hướng tới — xây dựng một hệ thống có khả năng mở rộng và tối ưu hóa quy trình làm việc.\n\n**[48:24]** Tiếp theo, team sẽ tập trung vào việc xây dựng hệ thống **MCP**. Đây là một hệ thống mới được thiết kế để quản lý dữ liệu và workflow. Team đã tiến hành demo hệ thống này cách đây khoảng hai tuần. Bản chất của hệ thống MCP là xây dựng một agent hoạt động trên nền tảng có sẵn. Người dùng có thể nhanh chóng triển khai và kiểm tra hệ thống thông qua MCP.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pj13pwqkVdQ?si=KGQZ4rVPmrc9nMq9&amp;start=2935\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**[49:10]** MCP sẽ là một hệ thống hoàn chỉnh, bao gồm một cơ sở dữ liệu (**database**) và một máy chủ (**server**). Điều này cho phép hệ thống hoạt động một cách độc lập và có khả năng xử lý dữ liệu lớn. Khác với các hệ thống cũ, MCP sẽ cho phép người dùng điều chỉnh cấu hình và quản lý dữ liệu dễ dàng hơn.\n\n**[49:58]** Bản chất của MCP là một agent, được định nghĩa theo một cấu trúc input và output cụ thể. Điều này cho phép các hệ thống khác nhau có thể kết nối và tương tác với MCP thông qua các giao thức tiêu chuẩn. Nói cách khác, MCP có thể được tích hợp vào bất kỳ hệ thống nào thông qua các giao thức được định nghĩa sẵn.\n\n**[50:35]** MCP cũng cho phép người dùng quản lý dữ liệu thông qua Knowledge Database, bản chất nó là timescale database, dump hết mọi data về hoạt động của team vào trong đó. Đây là một cơ sở dữ liệu dạng time-series, cho phép ghi nhận các sự kiện theo thời gian thực, ai làm backend sẽ quen dạng event sourcing, event log. Ví dụ: ghi nhận thông tin về các thành viên của team, trạng thái hoạt động của hệ thống, hoặc các sự kiện quan trọng khác.\n\n**[51:13]** Knowledge Database sẽ lưu trữ toàn bộ dữ liệu hoạt động của team, bao gồm các thông tin như ai đã thực hiện tác vụ gì, trạng thái của hệ thống vào từng thời điểm cụ thể, và các thông tin khác liên quan đến hoạt động nội bộ của team. Điều này cho phép team theo dõi và phân tích hiệu suất làm việc, từ đó đưa ra các quyết định điều chỉnh hợp lý.\n\n**[51:51]** Concept của hệ thống sẽ có một thành phần gọi là Landing Zone. Landing Zone có nghĩa là mọi dữ liệu mà mình đang có — khoảng mười mấy đến hàng chục bộ dữ liệu (database) — sẽ được tập kết vào đây. Trước đây, khoảng ba đến năm năm trước, nếu muốn xây dựng một hệ thống lưu trữ dữ liệu mình sẽ tạo một con bot để thu thập mọi hoạt động của team và đưa vào trong cơ sở dữ liệu của mình.\n\nVới mô hình Meta mới, tất cả các dữ liệu lớn (Big Data) sẽ được dump vào một kho lưu trữ tạm thời dưới dạng file .dat trên S3 hoặc GCS (Google Cloud Storage). Con MCP này sẽ có khả năng đọc trực tiếp từ Landing Zone. Nếu hệ thống thấy rằng dữ liệu trong Landing Zone có giá trị và cần thiết, nó có thể tự động chuyển đổi dữ liệu đó sang dạng Time Series Database (TSDB) để sử dụng lâu dài. Đây chính là end game (kết quả cuối cùng) của hệ thống này.\n\nCòn lại, vấn đề sẽ là xây dựng các Use Case (trường hợp sử dụng) dựa trên các dữ liệu đã được tổ chức trong hệ thống — theo hướng mà team mong muốn. Đây là định hướng phát triển quan trọng của hệ thống MCP trong thời gian tới.\n\n**[52:25]** Vậy là hiện tại team sẽ có một hệ thống cơ sở dữ liệu cũ — đó là cơ sở dữ liệu dạng table kiểu cũ, nằm ở phần bên dưới của hệ thống (có thể thấy trên diagram với các khối màu xanh dương). Giờ đây, team đang bổ sung thêm hai thành phần mới:\n\n- Thành phần **Landing Zone** — nằm trong khối màu vàng phía trên của hệ thống.\n- Thành phần **Time Series Database (TSDB)** — được kết nối trực tiếp với các thành phần trong hệ thống cũ để phân tích và khai thác dữ liệu.\n\nTeam đang lưu trữ các dữ liệu thô trong Landing Zone. Về bản chất, việc tập kết dữ liệu trong Landing Zone giống như việc gom quân — tập trung tất cả dữ liệu về một chỗ, sau đó mới quyết định cách phân tích và xử lý. Đây là cơ chế giúp hệ thống vận hành linh hoạt hơn và dễ dàng mở rộng khi có thêm dữ liệu mới.\n\n**[53:11]** Điểm đặc biệt của hệ thống này là khả năng tự động chuyển đổi dữ liệu từ Landing Zone sang Time Series Database. Cơ chế này xuất phát từ nhu cầu ngày càng tăng về phân tích dữ liệu cục bộ (local analytics). Đây là xu hướng đang nổi lên trong bối cảnh sự phát triển của AI (Trí tuệ nhân tạo).\n\nSự trỗi dậy của AI đã làm gia tăng nhu cầu về các hệ thống phân tích dữ liệu theo thời gian thực. Khi các dữ liệu thô được tập kết vào Landing Zone, hệ thống sẽ tự động nhận diện dữ liệu có giá trị và chuyển chúng sang TSDB để phân tích chi tiết hơn. Đây là một bước tiến quan trọng trong việc xây dựng hệ thống phân tích dữ liệu hiệu quả và có khả năng thích ứng với những thay đổi của thị trường.\n\n**[53:45]** Hiện tại team đã có thể chạy analytic trực tiếp cho phần dữ liệu được lưu trữ trên local. Hệ thống này cho phép chạy analytic ngay trên dữ liệu Data Lake mà không cần phải chuyển dữ liệu đi xa. Đối với phần dữ liệu trong Landing Zone — tức là phần file packet mà Huy đang show trên màn hình — đây là phần mà team cần tập trung nghiên cứu thêm. Vấn đề này có liên quan đến text processing, nên mấy anh em cần phải pick up (nắm bắt) chủ đề này. Cái này cũng không khó lắm, chắc học trong vòng nửa ngày là có thể nắm được cơ bản.\n\nPhần Prompt để tìm kiếm và khai thác dữ liệu cũng khá nhanh và đơn giản, không phức tạp. Đây là phần rất đáng để thử nghiệm vì nó liên quan đến cơ chế knowledge discovery (khám phá tri thức) trong hệ thống. Đây là một trong những phần nâng cấp mới mà Huy vừa nhắc tới.\n\n**[54:22]**  Điểm nổi bật nhất của hệ thống trong đợt nâng cấp này chính là **Knowledge Hub**. Đây là nơi mà team sẽ tập trung toàn bộ dữ liệu để phục vụ cho việc phân tích và khai thác tri thức. Knowledge Hub sẽ trở thành một dạng **data pool** chung của toàn team. Bất kỳ ai cũng có thể thêm dữ liệu vào đây, và hệ thống sẽ xử lý, chuyển đổi dữ liệu theo format tiêu chuẩn.\n\nĐiều quan trọng là khi hệ thống đã được thiết lập xong, mọi người trong team sẽ có chung một **protocol** để sử dụng. Các module hoặc component khác nhau sẽ có thể **share (chia sẻ)** chung một cấu trúc dữ liệu và truy cập trực tiếp vào Knowledge Hub. Đây sẽ là nền tảng chung để đồng bộ dữ liệu và xử lý dữ liệu trong nội bộ team.\n\n**[54:58]** Về phần cơ sở dữ liệu (DB), hệ thống sẽ có hai lớp:\n\n- **DB cũ:** Dùng để hỗ trợ các nghiệp vụ hiện có và xử lý các dữ liệu có cấu trúc sẵn.\n- **DB mới:** Được thiết kế để kết nối trực tiếp với **Knowledge Hub** và hỗ trợ phân tích dữ liệu theo thời gian thực.\n\nĐiểm đặc biệt là phần **MCP** sẽ đóng vai trò như một **protocol** để các module khác nhau có thể giao tiếp với nhau. Điều này có nghĩa là bất kỳ dữ liệu nào cần được truy cập hoặc xử lý, chỉ cần đưa vào đúng đường dẫn của hệ thống thì nó sẽ tự động được xử lý theo cấu trúc tiêu chuẩn. Đây là cách để hệ thống đồng nhất dữ liệu và tránh xung đột khi có nhiều nguồn dữ liệu cùng được xử lý.\n\n**[55:43]** Từ giờ, team sẽ cần làm quen với các cơ chế xử lý dữ liệu mới. Mọi người nên dành thời gian để tìm hiểu thêm về các thành phần trong hệ thống mới. Khi các thành phần này hoạt động ổn định, các dự án mới của team sẽ tận dụng các công cụ này để triển khai nhanh hơn và hiệu quả hơn. Đây sẽ là bộ công cụ chính để phục vụ cho các dự án trong tương lai.\n\nHệ thống này có tiềm năng trở thành **requirement** bắt buộc trong các dự án tiếp theo. Nếu bạn muốn bắt kịp với hệ thống mới, hãy bắt đầu từ việc tìm hiểu các nguyên lý cơ bản về MCB và các protocol liên quan.\n\n**[56:40]** Trước đây, khi team triển khai hệ thống trên S3 hoặc GCS (Google Cloud Storage), việc xử lý dữ liệu khá mất thời gian. Tuy nhiên, với cơ chế mới, dữ liệu từ Landing Zone sẽ được xử lý nhanh hơn và dễ dàng hơn.\n\nHệ thống đã được thử nghiệm trên nhiều nền tảng khác nhau, bao gồm **S3** và **GCS**. Tuy nhiên, vì hạ tầng hiện tại của team đang chạy trên **GCS**, nên các dữ liệu từ Landing Zone sẽ được xử lý trên GCS trước. Mặc dù vậy, về mặt kỹ thuật, hệ thống này có thể mở rộng sang các nền tảng khác mà không gặp trở ngại lớn.\n\n**[57:45]** Cơ chế hoạt động của Landing Zone khá đơn giản:\n\n- Các dữ liệu từ nhiều nguồn khác nhau sẽ được tập trung vào Landing Zone.\n- Các dữ liệu này sẽ được lưu dưới dạng **file Parquet** theo từng ngày.\n- Hệ thống có khả năng đọc lại các file này thông qua cơ chế **Time Series Database** (TSDB).\n\nHiện tại, một số file **Parquet** mẫu đã được tạo và đang trong quá trình kiểm tra. Nếu cần, team có thể chạy thử demo trên các dữ liệu mẫu này để kiểm tra tính nhất quán của hệ thống.\n\n**[58:24]** Những hoạt động của team giống như kiểu **AI sub** hoặc **Memo** thì nó cũng được đẩy hết lên đây. Nhiệm vụ của **Landing Zone** là lưu trữ mọi dữ liệu mà team muốn, ai muốn lưu trữ gì thì cứ đẩy hết vào đây rồi sau đó hệ thống sẽ quyết định xử lý dữ liệu đó như thế nào. Hệ thống cũng đã cung cấp một số công cụ để mọi người có thể đẩy dữ liệu lên, ví dụ như là các **API proxy** để forward các sự kiện. Mọi người muốn push thông tin lên Landing Zone thì chỉ cần gọi API là được.\n\nMemo hiện tại đang sử dụng cơ chế này để lấy dữ liệu từ các **nền tảng xã hội** và đồng bộ vào hệ thống. Cơ chế này cũng đã được thử nghiệm thành công. Còn đối với những loại dữ liệu có tính đặc thù như là **Discord messages** hoặc **data từ Basecamp**, team cần phải xây dựng các **crawler** hoặc các **connector** để thu thập dữ liệu. Hiện tại, team đã có một số template sẵn cho những loại dữ liệu này.\n\n**[58:59]** Về hướng phát triển tiếp theo, team sẽ tập trung vào việc khai thác dữ liệu từ Landing Zone. Nếu bạn muốn tham gia vào dự án này, lời khuyên là hãy bắt đầu từ một **vertical cụ thể**. Ví dụ:\n\n- Xác định một **use case** rõ ràng.\n- Tìm hiểu xem **dữ liệu nào** cần cho use case đó.\n- Định nghĩa lại cơ chế khai thác dữ liệu theo hướng **từ trên xuống dưới**.\n\nThay vì kiểu thấy dữ liệu nào hay thì lưu lại, team nên nghĩ theo hướng là **xác định use case trước** rồi mới quyết định lưu trữ dữ liệu. Điều này giúp hệ thống hoạt động một cách có tổ chức và dễ dàng quản lý hơn.\n\nVí dụ cụ thể là nếu có một use case về **Project Nghệ Nhân** thì team sẽ cần tạo một **Git Agent** để thu thập dữ liệu từ Git, sau đó đẩy dữ liệu đó vào **Knowledge Hub** thông qua MCP. Từ đó, hệ thống sẽ định nghĩa các công cụ khai thác dữ liệu cho use case này.\n\n**[1:00:16]** Ngoài ra, team đang phát triển một MCP Server nhỏ. MCP Server này thực chất là một server cơ bản, sử dụng các thành phần kỹ thuật thông thường của hệ thống internet hiện tại. Nó định nghĩa các input và output rõ ràng, cho phép kết nối với nhiều loại giao diện khác nhau.\n\nVí dụ:\n\n- Nếu có một MCP để xử lý dữ liệu từ Slack, team sẽ định nghĩa các API cho từng loại dữ liệu.\n- Nếu cần có các công cụ để đọc dữ liệu từ Google Sheets hoặc phân tích dữ liệu về tình trạng check-in trong tuần, team có thể tạo các MCP tool để xử lý những dữ liệu đó.\n\nMCP sẽ là một thành phần trung gian để đồng bộ và xử lý dữ liệu từ nhiều nguồn khác nhau. Mọi người có thể truy cập các công cụ này từ Editor, Command Line, hoặc bất kỳ giao diện nào khác.\n\n**[1:01:07]** Bản chất của MCP là nó sẽ đóng vai trò như một **API Gateway** để kết nối các công cụ. Nếu bạn cần theo dõi việc check-in hàng tuần của mọi người trong team, bạn có thể tạo một MCP để thu thập dữ liệu từ **Knowledge Hub** và Google Sheets, sau đó so sánh dữ liệu để xem ai đã check-in và ai chưa check-in.\n\nHệ thống hiện tại đang dừng ở mức độ triển khai MCP Server cơ bản. Giao diện hiện tại sử dụng **Command Line** để gọi MCP, nhưng về cơ bản team có thể mở rộng để kết nối với các công cụ khác nhau.\n\n**[1:01:43]** Hệ thống đang tập trung vào việc triển khai cơ chế xác thực (authentication) và phân quyền (authorization).\n\n- Authentication – Xác thực người dùng để truy cập vào hệ thống.\n- Authorization – Phân quyền cho các hoạt động xử lý dữ liệu.\n\nHệ thống đang được sử dụng nội bộ trong team, chưa công khai ra bên ngoài. Nếu bạn muốn sử dụng MCP, bạn sẽ cần nhập vào **private key** để xác thực quyền truy cập.\n\n**[1:02:23]** Về mặt kỹ thuật, MCP có thể mở rộng ra các thành phần khác nhau trong hệ thống. Mọi người có thể tích hợp MCP vào các ứng dụng hiện tại hoặc các công cụ hiện có mà không cần phải viết lại quá nhiều code.\n\nTeam vẫn đang thử nghiệm tính năng này và tập trung vào việc hoàn thiện các phần về bảo mật và quản lý quyền truy cập. Khi hệ thống đã ổn định, mọi người có thể tích hợp MCBP vào các quy trình xử lý dữ liệu hiện có.\n\n**[1:03:00]** Chỉ là đang dừng lại ở đây thôi, chưa xử lý được các bài toán phức tạp về authorization. Sau khi hoàn thành các bước hiện tại thì mới đến việc xử lý các bài toán phức tạp hơn liên quan đến authorization và quyền sử dụng hệ thống. Mọi người có thể tập trung vào các vấn đề cơ bản trước đã.\n\nRồi, cảm ơn Huy nhé. Đây là một trong những phần phát triển kỹ thuật quan trọng của team. Nếu theo dõi các hoạt động trên tech và AI Club, mọi người sẽ nhận ra team đang tiến tới các bước tiếp theo trong quá trình phát triển. Về mặt kỹ thuật, mọi người nên chú ý vào các từ khóa quan trọng mà Huy vừa đề cập. Nếu chưa hiểu rõ thì có thể xem lại bản ghi để nắm được đầy đủ thông tin.\n\n**[1:03:45]** Team core vẫn đang tiếp tục phát triển hệ thống. Yêu cầu tất cả các thành viên tham gia vào dự án để có thể **transfer knowledge** hiệu quả hơn. Dự án này là môi trường để mọi người học hỏi và thực hành.\n\nĐây là cơ hội để các thành viên mới trong team tiếp cận và nắm bắt các khía cạnh kỹ thuật quan trọng. Nếu cảm thấy chưa sẵn sàng thì có thể tham khảo các phần hướng dẫn và tài liệu nội bộ để bắt kịp. Việc training sẽ được thực hiện trong quá trình làm việc chứ không có các buổi training riêng. Đây là môi trường thực hành trực tiếp để vừa làm vừa học.\n\n**[1:04:29]** Bên cạnh việc phát triển hệ thống, team cũng đang thực hiện knowledge transfer từ các dự án đã hoàn thành. Dự kiến cuối tháng sẽ có một buổi tổng hợp lại các bài học rút ra từ các dự án này. Nếu ai chưa thực sự hiểu rõ thì có thể tham khảo hoặc hỏi các thành viên đã làm qua để nắm thêm thông tin.\n\nNếu cảm thấy chưa sẵn sàng hoặc cần thêm thông tin thì có thể hỏi trực tiếp các thành viên trong team. Mọi người có thể ping các thành viên có kinh nghiệm hơn để nhận được sự hỗ trợ.\n\n**[1:05:07]** Team có hai nhóm khác nhau đang hoạt động song song:\n\n- **Team của Tuấn** đang phát triển một số game và ứng dụng nhỏ.\n- **Team build** đang làm việc trên các ứng dụng thử nghiệm để kiểm tra tính khả thi của hệ thống.\n\nCác hoạt động này tương tự với các nhóm **Build Club** và **AI Club** trong team Foundation. Một số sản phẩm đã bắt đầu có **output** tốt. Tuấn và team đang phát triển một trò chơi dựa trên **Turing Machine**.\n\n**[1:06:38]** Trò chơi **Turing Machine** mà team Tuấn phát triển được chuyển thể từ phiên bản board game thành phiên bản trên thiết bị di động. Mục tiêu của trò chơi là đoán một chuỗi gồm **ba số**. Để đoán đúng chuỗi số này, người chơi sẽ nhận được các **clue** (gợi ý).\n\nVí dụ:\n\n- Nếu gợi ý nói rằng “một trong ba số phải lớn hơn 1” → Người chơi có thể nhập số vào và hệ thống sẽ xác định xem đáp án có đúng hay không.\n- Nếu hai số sai nhưng một số đúng thì hệ thống sẽ phản hồi ngay để người chơi có thể tiếp tục điều chỉnh.\n\nLuật chơi khá phức tạp nên có thể gây khó khăn cho người chơi mới. Tuấn và team đang tiếp tục điều chỉnh để trò chơi trở nên dễ tiếp cận hơn mà không mất đi tính thử thách.\n\n**[1:07:23]** Tên trò chơi là [**Pocket Turing**](https://pocket-turing.vercel.app/) bởi vì phiên bản board game gốc của nó liên quan đến các thẻ đục lỗ – giống như cơ chế hoạt động của Turing Machine trong lập trình máy tính. Tuy nhiên, mình đã điều chỉnh và phát triển thêm các yếu tố mới để phù hợp hơn với phiên bản di động.\n\nMÌnh có kế hoạch tinh chỉnh và mở rộng trò chơi trong các phiên bản tiếp theo. Ngoài ra, cũng đang kiểm tra xem có thể triển khai thêm các tính năng thu phí hoặc các tùy chọn nâng cao để tăng khả năng monetize.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pj13pwqkVdQ?si=bP3ZjI3af1fVijle&amp;start=3997\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**[1:08:16]** Mình đang thử nghiệm phiên bản beta của trò chơi. Trò chơi đã hoàn thiện về mặt gameplay và người chơi có thể trải nghiệm trọn vẹn các tính năng. Bước tiếp theo là thử nghiệm với nhóm người dùng rộng hơn để thu thập phản hồi và cải thiện sản phẩm.\n\n**[1:09:15]** Mục tiêu tiếp theo là đưa trò chơi vào App Store và Google Play để tiếp cận nhiều người dùng hơn. Trước mắt, team muốn đảm bảo trò chơi hoạt động ổn định và không phát sinh lỗi nghiêm trọng.\n\nTuấn kỳ vọng trò chơi sẽ thu hút được ít nhất **100 người dùng** trả phí trong giai đoạn thử nghiệm đầu tiên. Nếu nhận được phản hồi tích cực  sẽ mở rộng thêm các tính năng mới và cải thiện trải nghiệm người chơi. Mong nhận được phản hồi từ các thành viên khác để có thể điều chỉnh và hoàn thiện sản phẩm tốt hơn. Tuấn đã chia sẻ link tải trò chơi cho các thành viên trong team để mọi người có thể trải nghiệm và đóng góp ý kiến.\n\n**[1:10:13]** Nếu anh em hứng thú với việc build sản phẩm thì giai đoạn này là thời điểm phù hợp để bắt đầu. Trước đây team đã thử nghiệm nhiều lần nhưng lần này là cơ hội tốt để làm bài bản hơn. Việc phát triển các sản phẩm nội bộ không chỉ giúp cải thiện năng lực kỹ thuật mà còn mở ra cơ hội thương mại hóa trong tương lai.\n\nNgoài game của Tuấn, team đang phát triển thêm các công cụ khác. Nếu có ý tưởng hay, anh em có thể đóng góp để cùng xây dựng và thử nghiệm. Cách bán hoặc thương mại hóa sản phẩm thì tính sau, quan trọng là hoàn thiện các tính năng cốt lõi trước.\n\n**[1:10:58]** Tiếp theo là phần của An. An từng làm một tool gọi là **Rec** để tổng hợp thông tin theo dạng giống với hệ thống của **Apple**. Phiên bản 1 của Rec yêu cầu người dùng tự sắp xếp thông tin, còn phiên bản 2 hiện tại đã được tích hợp AI để hỗ trợ sắp xếp tự động.\n\nTuy nhiên, AI vẫn có một số hạn chế trong việc nhận diện nội dung đầy đủ. Đôi khi AI không thể xác định được toàn bộ ngữ cảnh nên kết quả trả về chưa thực sự hoàn hảo. Tuy nhiên, các nội dung quan trọng vẫn được sắp xếp và hiển thị đầy đủ.\n\n**[1:11:56]** Tool này đang trong giai đoạn hoàn thiện, nhưng các chức năng cốt lõi đã ổn định. Hiện tại, team đang tập trung vào việc cải thiện phần giao diện và tối ưu trải nghiệm người dùng. An dự kiến sẽ tiếp tục phát triển thêm các tính năng bổ sung để hỗ trợ người dùng tốt hơn.\n\n**[1:12:51]** Các dự án của team hiện đang ở giai đoạn thử nghiệm và cải tiến. Nếu ai có thắc mắc hoặc góp ý, có thể trực tiếp trao đổi với An hoặc các thành viên khác trong team. Hiện tại, các dự án đã showcase gần hết. Các phần chi tiết hơn sẽ được đề cập vào buổi sau.\n\n**[1:13:57]** Bên đội mình, anh luôn nói về chuyện kiến thức liên quan tới liquidity và game in general, thì anh em thật sự muốn team mình đẩy theo hướng đó một chút. Vì nó có lợi cho gần như là cái life skill luôn, đúng không? Nên anh muốn team mình đi theo hướng đấy trong đợt này. Mấy anh em, đặc biệt là những người hứng thú với trading, tức là lấy data về để tìm kiếm cái Alpha trên đó, Intel trên đó, để ra được những cái market-making dựa trên điều kiện nào đó.\n\n**[1:14:43]** Nó là một cái, hoặc có thể đi xa hơn để làm một luồng rất tuyệt vời. Hình như hiện tại chỉ là ước mơ của anh thôi. An đã làm được một version, anh thấy khá ok. Đây là cơ hội để cho anh em biết trong team đang có những tiến triển như vậy. Đang chạy ha, mời An. Nói chung là game kiếm tiền thôi. Coi tụi nó kiếm tiền sao thì mình làm vậy. Mấy cái thường thường thì có biết một cái gì để thử, nó cũng là dạng **Delta neutral**, đúng không? Thì mình cũng research những thứ đó. Rồi đi build và research xong để có kiến thức ship.\n\n**[1:15:30]** Chơi cái cột này hết thôi, không nhìn tới đâu nữa. Mọi người thấy màn hình terminal chưa? Có thấy chưa? Có thấy rồi, ok, chạy để chạy thử. Chắc phải zoom lên, zoom lên một hai level, hơi nhỏ, rồi ok rồi. Đây là arbitrage để ăn funding free, thì có nhiều thể loại arbitrage. Cái này chỉ là một trong những loại đó thôi, ăn trên chênh lệch phantom giữa các sàn. Đang tập trung vào ba sàn: Binance, OKX — thằng OKX này sàn của nó không có nhiều dữ liệu lắm — nên em có cái diagram cho cái đó không, An?\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pj13pwqkVdQ?si=IevTgfLbxwcu6MOh&amp;start=4506\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n**[1:16:26]** Nghĩ mọi người sẽ hơi khó hình dung. Nhìn cái này chắc không hiểu nó là gì. Có diagram không? Ok, không có vẽ à? Có cái này, to, nhưng là lý thuyết, không cụ thể ra được high level. Không thấy, chắc phải ngồi vẽ lại sơ sơ. Thấy chưa? Chắc nhìn hình của anh đi, hình của anh, biết ngay là cái này luôn. PRL à? Ủa, nó đang chạy lộn, quên, nó đang vào mấy cái socket của…\n\n**[1:17:47]** Tụi nó để lấy real-time data về. Đang lấy dữ liệu từ bao nhiêu account? Ba cái: Binance, Bybit, với cái gì nữa? Ok rồi, init để lấy giá về, đúng không? Lấy giá, lấy funding, lấy phí chưa? Lấy mấy cái data như phí thì đang code theo calculation, chưa xài để lấy về. OKX chắc không có. Mấy cái trade này thì thường chỉ nằm ở hai cái chính: Binance, Bybit. Ừ, setup ok rồi, nó sẽ có mảng thể hiện cái vị nào đang có chênh lệch funding, thì có profit. Em tính được nếu mình vào thì nó sẽ bao nhiêu. PH là số lần thu funding để hòa vốn phí, monitoring cái cao nhất giữa hai sàn. Bước một là lấy chênh lệch funding giữa hai bên, đúng không? Không, em nói là lấy trên ba exchange, so với góc của nó vẫn là exchange net, đúng không? Ừ, exchange net tính sau thôi. \n\n**[1:19:49]** Funding thì giả sử tụi nó thường, trên lập giá thì không có nhiều, kiểu một thằng dương, hai thằng đều dương, hoặc hai thằng đều âm, thì chênh lệch ít hơn. Thật ra mình đặt counter trên cái chênh khác, chỉ là offset giá di chuyển, để không lỗ bởi giá. Trên exchange net, không có chênh lệch đó, mình làm funding lúc nào cũng bằng 0. Vì không có phí swap, thay vì counter trên sàn khác bằng cái đó, mình counter lúc funding bằng 0. Hiện tại chấp nhận ít lợi hơn, nhưng version đầu tiên vậy.\n\n**[1:20:33]** Lấy giá, lấy **funding**, rồi coi có deploy capital thôi, đúng không? Chạy thử chưa? Chưa đổ tiền vô. Ừ, cái này kiểu game scale, cần nhiều tiền mới ăn, vài trăm ngàn thì vô không thấy gì. Hiểu, ok. Về kỹ thuật thì em làm gì? Từ lúc price crash, em làm những gì?\n\n**[1:21:25]** Đầu tiên em research chart trước, coi nó thế nào, có chênh lệch gì không. Xong rồi ship, code hết bằng Cloud 3.7. Phải lấy data sàn trước qua socket, từ API dock của sàn, quăng lên WebSocket client. Sàn nào cũng có dock, lấy về ship lên, tự view được.\n\n**[1:22:15]** Web cho ba sàn xong, có form đầy đủ. Sau đó build chart, giải thích cho nó, build từ từ. Check data, sai thì tự build sample để đảm bảo data đúng. Vì format giữa các sàn khác nhau.\n\n**[1:23:01]** Khác hết, nên cần test data valid mới compare được. Tiếp theo build con để vào lệnh, khi phát hiện thì có thằng đứng ra vào lệnh, watch bot xem lỗ không, làm từ từ, hợp lý. Quá trình hết bao lâu? Một tuần.\n\n**[1:23:58]** Bước tiếp theo của tool này là gì? Em sẽ check data trước, xem sàn nào dễ kiếm tiền, có lời. Quản lý rủi ro, lấy phí structure của sàn. Vì phí ảnh hưởng lớn, phải tính chính xác, đảm bảo lời mới vào lệnh. Có back system không? Có history để backtest không? Có, nhưng không chính xác.\n\n**[1:25:38]** Đây là showcase kỹ thuật, hướng này team tự lập, ok. Anh em showcase game trading, có bước đẩy tiếp, đang trên đường làm cái muốn làm, rất good. Công nghệ, techno house, xài thế nào thôi. Quan trọng nhất là…\n\n**[1:26:19]** Hoạt động team hiện tại vậy nhé. Productivity gần đây bắt đầu sync. Tom comment trước, productivity team giờ bao nhiêu? 2/10 hay 4/10? So với 6-7/10 cần, anh thấy setup tốt rồi.\n\n**[1:27:01]** Bước tiếp theo về mặt catch up cái công nghệ tool link để hỗ trợ mình vận hành đội theo mô hình này, nó đang được improve từ từ lên. Bên thị trường, thị trường **funding** nói chung và những sản phẩm bắt đầu cũng rục rịch quay trở lại. Người ta thấy công nghệ ổn định hơn. Bên **crypto** thì do macro ảnh hưởng nhiều, nhưng cứ có trend nào về tech là sẽ vô cắn thôi, là vậy ha. Anh đang thấy sắp tới tín hiệu để nó resume lại thì đâu đó khoảng 50/50. Trước đó anh nhìn thì cái market rất tệ, kiểu mọi thứ chưa sẵn sàng. Dù có học nhiều, làm nhiều thì cũng không ra kết quả liền.\n\n**[1:27:40]** Nhưng đợt này anh nghĩ mấy anh em sẽ phải có sự yêu cầu về chuyện tham gia mấy cái này ha. Tuần sau chắc nhờ Huy, Tom với Thành thống kê lại, xem ngoại trừ dự án anh em đang làm thì hoạt động tham gia những dự án side project như vậy, anh em nào đang làm gì ha. Đó là thần sau nội dung, thì cũng trao đổi gần hết rồi. Tuần sau còn một số cái core flow tiếp, nhưng chắc cũng không ảnh hưởng quá nhiều tới mọi thứ.\n\n**[1:28:22]** Hôm nay là ngày 14, hy vọng đến cuối tháng này, buổi họp team tiếp theo sẽ show được nhiều progress hơn. Tất cả những thứ mình đang làm rất quan trọng ha. Toàn bộ này đều đang được đưa lên Memo, tụi anh đang sử dụng Memo đó không chỉ để share trên đó không ăn thua. \n\n**[1:29:01]** Shill khắp nơi mấy công ty khác mình biết, bắt đầu mở rộng network ra để xem tìm kiếm user cần thiết. Chuyện là mình biết những thứ này rồi thì làm sao mình mound được khả năng mình profit từ kiến thức của mình, ý là vậy. Ok ha, đó là cái skin mà team đang chạy theo. Tóm lại, thị trường nhận định đang như vậy. Tuần sau mấy anh em sẽ phải đăng ký làm cái registration vô cho những cái phần, với lại Huy, Tom và Thành là những bên mạng bắt buộc.\n\n**[1:29:45]** Còn bên mấy cái hobby club, như kiểu Build hay gì đó, thì anh không yêu cầu cao vào bên đó, ra cái kỹ thuật để apply, nó cũng không quan trọng lắm. Quan trọng là output nhiều hơn. Hai nhóm khác nhau: một nhóm là những phần mà core project mình sẽ làm, tập trung vào làm sao tăng activity, tăng cái **knowledge base** của mọi người; còn cụm kia tập trung vào cái **skill set**, chuyện develop product sao launch, làm sao làm onboarding tốt hơn, user các kiểu. Là một cái nhóm skill set khác. \n\n**[1:30:27]** Đặc biệt là Huy, Huy đang co cho cái việc quay trở lại office để bắt đầu làm shadowing cho chuyện **knowledge transfer**, thì nếu được thì cứ tiếp tục để nó diễn ra. Rồi xem số liệu như thế nào thì report lại cho anh ha. Hopefully khi nào có con số đây thì mấy anh em xem thảo luận tiếp, làm sao setup cái vụ shadowing đó trên mấy cái dự án mà mình, mấy cái site mà mình tham gia, để có cái case share với nhau ha. \n\n**1:31:05** Toàn bộ là vậy. Nếu bây giờ không có gì khác thì chắc mình kết thúc ở đây. Đây có bao nhiêu bạn nhờ? 28 bạn hả? Không, đang bao nhiêu bạn trong con này nhờ? Chuẩn bị spam ICY, có vấn đề để transfer ICY chưa? Để cái này mai mốt lấy acc anh, hoài căng quá. Có vấn đề trên ICY nhờ. Mọi người ra random nha, giật cô hồn nha. Amount 28 thì mình sẽ drop 14 token ICY, entry là 14 rồi. Xin mời, duration là 5 giây. Ok, let’s go. Một ICY hồi nãy là tương đương khoảng 100 Satoshi rồi đó.\n\n**[1:32:09]** Tuần sau lịch vậy nha, mọi người xem phối hợp với nhau để làm việc cho hiệu quả rồi. Bye bye.\n\n---\n\n### English Transcript\n\n**[05:30]** Hello, can you hear me? Oh, okay, it’s fine now. Today, I think we’ll start a bit early. Today’s session will probably combine with the brother in the meeting for a little bit. One part will be to do a showcase, the second part is that the brother will summarize some things that were discussed with the guys previously. The second and third parts are that we’ll start letting the guys register for tasks. For now, to make it easier, I’ll probably let Huy Nguyễn go first to show the parts related to Huy, which involve ICY a little, and then show some tech stuff that our team is currently working on. This will give me a snapshot of how the tech team is doing right now. Then, moving forward, what our team needs and what the guys can contribute to it. Alright, let’s get started.\n\n**[06:35]** Huy, where’s Thành? Let’s give them the stage now. Okay, for the first content, let’s start with ICY Swap. We announced it, last week or this week it was deployed, so now how are the differences, I’ll probably ask Huy to go over that whole series again.\n\n**[07:29]** Hello, alright, I’ve seen the screen already. So now everyone can go to the ICY Swap page to swap. Here, I’ll show the data. But up here, everything is fully ready now. The only thing left to do is that we’re currently reviewing the ICY numbers. Because previously, when we were operating, we operated by pegging the ICY price, so we didn’t really care much about the circulating supply. So there were some cases where we put it into the team’s wallets or transferred it to Mochi Balances for me or for brother Bảo. Those things need to be reviewed again to get the correct circulating supply number. Because now we’ll sit down, and the price will be dynamic based on the pool, so we need to check that again, and it’s almost done.\n\n**[09:09]** Now, the only thing left is brother Bảo’s account that needs to be checked again. I remember there was a time we transferred to brother Bảo, so now we’re reviewing that part, doing the addition and subtraction, and cutting that part out of the circulating supply, then this number will come out correct. For now, if anyone wants to swap to support, they can swap on this page. That’s the current schedule. I’ll show the list of our current Holders so the guys can see, probably need to know a bit more. Up until now, people participated without paying much attention, but this time we need to be more mindful.\n\n**[09:51]** Our ICY is deployed on Base, right? So when the guys go into the Holder list, everyone will see a list of all the wallets currently holding our team’s ICY, which are the CCK Holders. That’s one thing. And then the link to access this, Huy will share it, I guess. Because if people go search for it, they probably won’t find it.\n\nFirst, the guys need to understand this. Moving on to this part now. I think the guys need to pay more attention to this part. It’s become the norm in the tech world already, no need to do anything new anymore. So if the guys grasp this, it’ll be better.\n\n**[10:33]** Our ICY is now listed. In this list, there are minter wallets, wallets used to budget for activities, and some wallets holding large amounts of ICY. Activities related to staking ICY will be rolled out gradually in the coming time. This is the first piece of information the guys need to understand clearly.\n\n**[11:15]** Huy, demo the swap process for us. Does anyone have a Bitcoin address with some ICY? Is Vincent here? Okay, now let’s try swapping from ICY to Bitcoin. The current price is calculated dynamically based on the circulating ICY amount and the pool. The swap function is very simple, just enter the amount, press swap, and it’s done.\n\n**[12:27]** Wait, don’t enter a fake address. Okay, it’s good now. The first frame is ICY as usual. Below it, it’s displaying the unit in satoshi, which is the smallest unit of Bitcoin. When you enter the amount, it will automatically convert. However, the current exchange rate is slightly off, around 1.2 instead of 1.5. This is probably a small calculation error, we can fix it.\n\n**[13:28]** You need a minimum amount of ICY to swap. Try entering 30 ICY and see how it goes. Refresh it and check if it works.\n\n**[14:43]** It seems like there’s not enough money in the wallet. Do you have ETH on Base? Transfer it to Base and check again.\n\n**[15:51]** It’s not that error. The issue is that the account hasn’t been registered, so it can’t perform the transaction. We’ll fix that part later. The goal here is to help everyone understand the swap mechanism and how token pricing works better. If you understand it well, it’ll be easier to manage tokenomics later on.\n\n**[16:47]** Huy, quickly explain the pricing mechanism again. Last time Quan demoed it but didn’t go into detail about that part. The price of ICY is determined by the minting mechanism, meaning the price won’t fluctuate heavily if someone swaps a large amount. It doesn’t operate like an automated market maker (AMM) mechanism; the price will be controlled through the minting mechanism. This mechanism helps keep the price stable even with large transactions.\n\n**[17:43]** It completely depends on Bitcoin. So if Bitcoin’s price goes up, the amount of ICY you guys are holding will increase in USD value. As for the minting mechanism, Huy, explain a bit more. Generally, our overall mechanism so far is that we fix ICY’s value to USDC. You guys don’t need to worry too much, just understand simply that one ICY is equivalent to 1.5 USD.\n\n**[18:37]** This assurance part is to help the operating team ensure that by the deadline, USDC will be added into the contract for everyone to swap. The swap rate in the old contract was fixed at 1.5 ICY, but that was the old model. Our new model is more flexible. If you guys have used Uniswap or other AMMs (Automated Market Makers), it’s somewhat similar. Here, the mechanism works with a liquidity pool underneath, which contains both ETH and USDC. Depending on the pool’s situation at that time, the exchange rate will be adjusted based on the amount of ETH and USDC in the pool.\n\n**[19:18]** Our mechanism works similarly. The price of ICY will be determined by the amount of Bitcoin in the pool and the amount of ICY currently in circulation. The formula is simple: we have the amount of ICY (X), we have the amount of BTC (Y) in the pool, then X/Y will give us the value of one ICY in terms of BTC. This formula is basic mathematics, nothing complicated.\n\n**[19:55]** Due to our operating mechanism, there will be two moments that change liquidity:\n\n1. **The first moment** is every month when the operating team adds more BTC into the pool to cover the costs of the team’s activities. At this point, the price of ICY will increase slightly because the amount of BTC in the pool increases.\n2. **The second moment** is when the team adds more ICY into the pool (minting more). When more ICY is minted, the market price of ICY will decrease because the amount of ICY in the pool increases.\n\n**[20:35]** The two cases above will directly affect the price of ICY. However, if the price of Bitcoin changes, the USD value of ICY might change, but the price of ICY in terms of BTC will not change. The market impact from Bitcoin is an external factor and does not directly affect the minting or the value of ICY in the pool.\n\n**[21:12]** If you guys have any more questions, feel free to ask, and we’ll answer them later. Oh, there’s a question about swapping back from BTC to ICY, right? Currently, that function isn’t available. Right now, we only support swapping from ICY to BTC, not the reverse swap. Meaning you can buy in, but selling out isn’t supported yet.\n\n**[21:40]** Thank you, Huy. Anything else to note? One thing to note is that we’re still in the testing phase, so there might be some exceptional cases. For example, some situations might arise during swaps or when liquidity isn’t sufficient. Fundamentally, though, the current flow is still operating stably.\n\n**[22:00]** Like the minimum ICY amount required to swap. Because essentially, our team is covering the gas fees for transactions on ETH, on Base, and even on BTC, we’re kind of limiting it so that the ICY amount swapped needs to be a bit higher. This is to avoid situations where people swap just 1-2 ICY to test, which would cost gas fees, so we’ve set it at around above 20 ICY to allow swapping on the web.\n\nThe second thing is that since minting more ICY will change the market price, I’ve disabled the part about our previous salary advance mechanism.\n\n**[22:37]** Meaning if everyone advances salaries at the same time, it would affect the price, right? So the lesson learned from this is that after this round, there are a few points I’m noticing. Our team is starting to focus on building tools to support our operations. These are also some new experiments and some things that genuinely support our activities. But after finishing these tasks, we’ll produce some articles related to them. So if any of you didn’t participate in those projects earlier, you can look back at those articles to understand the game, the knowledge gained from that round, and what the guys working on those projects achieved.\n\n**[23:24]** So with this ICY Swap round, we’ll probably get two or three articles, right? Yes, like three articles. And if we want to write more, there’s still plenty to write about. Yeah, alright, take it slow and steady.\n\n**[24:02]** After Huy’s part, I thank Huy and move on to the second topic related to what our team is currently doing. Brother Bảo, whoever wants to go first is fine, but I’ll probably let Thành speak first. Thành said it’s okay for him to go first, he’ll gather everything to let everyone know what stage the team is at. But I said let Thành go first because someone’s ringing the bell. Alright, I invite Thành to start.\n\n**[25:00]** Everyone, our Memo is one of the big things this round, and we’ve upgraded its format to make it look a bit better. We always want to create content maps, things that we can read and upload here. But currently, that model isn’t really that effective anymore because new models compress data, and querying directly from there would be more efficient.\n\nSo the point is that putting ordinary knowledge onto Memo isn’t very suitable anymore. For this round, when reworking it, there’s one main idea I want to tell you all: Memo will now be used for one sole purpose — the knowledge gained from projects.\n\nThat’s almost like the new things that come directly from our team’s activities. In the future, it’ll mostly consist of what field it’s related to and what we’ve done in that field. There’s more to it — maybe after a period when they retrain the model, our data will become part of the shared knowledge for the whole community.\n\n**[25:39]** And I think this part will be very helpful for things like retraining AI models later or for cases where we want it to provide automatic suggestions.\n\n**[26:24]** The content will become part of that model, or if there are internet search tools, our articles might just be a small part of the referenced materials, like a small piece in a citation. That’s not a big issue. But overall, all this content will pretty much become the spirit of the team.\n\nIn this major upgrade, there’s one key point that Tuấn has completed, right? Tuấn, the part about syncing all the team’s data, especially the content, is currently being directed this way so the members can understand it better.\n\n**[27:00]** Meaning after this round, the members participating in projects will tend to sit down together to review those projects more closely and determine exactly what the **knowledge gain** from those projects is. After that, the team will upload it to Memo as internal reference material for the team.\n\nThe second part is that at the end of each article, there will be a section related to a **group of reading**. This part isn’t fully complete yet, but the idea is that once it’s finished, there will be an additional section summarizing information about the article so readers can look up and learn more from it.\n\n**[27:47]** In addition, all the data written by the team will be tagged with identifiers such as **GitHub**, **Discord**, or other internal channels. This data will be uploaded to a **blockchain storage** form on the **Arweave (AV)** platform — a decentralized storage platform. This ensures that the team’s content has a clear and transparent identifier.\n\nOn top of that, readers will be able to review the articles, rate them, or leave feedback directly on the articles. This is part of the new upgrade idea for the team’s **Memo** page.\n\n**[28:39]** Previously, the team intended to use Obsidian to manage content, but it seems some members had difficulty getting familiar with that tool. Therefore, to make things simpler now, the team will switch to a more direct mechanism. Specifically, instead of having to go through Obsidian, members can submit content directly to the repository of the team’s shared library.\n\nMembers just need to input the content and submit it directly through this platform, without having to follow Obsidian’s mandatory workflow anymore. If someone still wants to use Obsidian, that’s fine, but if they don’t, it won’t affect anything. This is the most fundamental change in the team’s Memo system.\n\n**[29:24]** Currently, the team is working on several main projects, including:\n\n1. Bitcoin Swap — already mentioned in the previous section.\n2. Memo — just presented.\n3. Two smaller projects:\n    - **Agentic** — being developed by Quang and Huy’s group.\n    - **GitHub Bot** — being worked on by Thành’s group, currently in testing.\n\nNow, I’ll probably hand it over to Thành to share more about these contents.\n\n**[30:32]** This project was started over a week ago and has officially been running code for more than a week. Its main purpose is to create a reminder system. Previously, the team often encountered situations where, after creating a pull request (PR), people would leave it there, wait for it to finish running, and then forget about the need to review it. This tool will serve to track and update information about daily activities on GitHub or weekly activities on the team’s internal communication channels.\n\n**[31:18]** This system is designed as a simple integration. The basic workflow includes several use cases, such as notifying the person assigned to review, interacting with the GitHub API, and posting information to internal channels like Discord or Slack. Currently, the team is testing it on Discord. Additionally, the team is experimenting with Agentic and a new framework called **Mastra AI**.\n\nThis framework is different from typical Python tools. Some team members aren’t familiar with working in Python, so the team wants to test whether using this new framework is more effective than current solutions. The framework supports features like setting up the environment, defining states to manage data, and allowing reconfiguration based on the team’s needs.\n\n**[32:19]** The system’s structure has two main parts:\n\n1. **Agentic App** — This is the main application for handling the system’s activities.\n2. **Discord App** — This supports sending notifications to Discord.\n\nAdditionally, the system has a few auxiliary components, such as workflows to handle scheduled tasks, check, and notify developers if there are any pull requests waiting for review. If a pull request exceeds a certain amount of time, the system will send a notification to remind the person responsible for reviewing it.\n\n**[33:12]** The Agentic App will expose a few APIs that allow chatting and tracking the status of pull requests. When a pull request is created, the system will automatically identify conditions like the pull request’s status (work in progress or not), the time it was created, and will notify the reviewer after about 30 minutes from the creation time. For example, if a pull request needs review but no one is assigned or it has exceeded the processing time, the system will automatically ping the responsible person again.\n\n**[35:02]** Instead of having to track manually, the system will attach an agent to automatically monitor and notify through the system’s endpoint. In the logic part, the system will define specific conditions, such as only sending notifications if the pull request was created within 30 minutes or is in a work-in-progress state. If the pull request is updated or changes status, the system will automatically track and notify the developer to ensure nothing is missed.\n\n**[35:39]** The system will operate based on standard code filters. Additionally, it will have some other workflows, like sending notifications at the end of the day to summarize the status of pull requests on Discord. The system will automatically send notifications about the number of open pull requests, their statuses, and the current review status. This is the main function of this tool — acting as a reminder tool.\n\n**[36:24]** The system can also integrate with other chat tools. It’s simple — you can create an additional command and send a request to the system’s endpoint. These requests will be defined based on a specific schema, such as the input being a **review ID** or other information related to the pull request’s status. The system will take this data and display it on the interface that users frequently use.\n\n**[37:04]** The backend processing of the system is handled through the Lippia tool, which formats JSON data into Markdown tables or data-binding formats. Currently, the team is testing these two processing flows before expanding to additional features. Once the system is stable, these workflows will be opened up for all team members to test and further develop.\n\n**[38:08]** The system is designed to scale flexibly. Team members can independently develop and contribute different workflows. This system allows the creation of tools as standalone **packaging units**, which can then be combined to create more complex workflows. When wanting to release a new workflow, members just need to redefine the basic unit and integrate it into the system.\n\nExpanding workflows will help the system grow horizontally (increasing the number of features) rather than vertically (developing existing features). As the number of workflows increases, the system will become more flexible and powerful.\n\n**[38:54]** Fundamentally, workflows are considered the application layer, similar to previous data APIs. This system will operate at the tool level, but end users will interact with it through the workflow interface. Currently, no entity has successfully implemented this model on a large scale. However, GitHub has now expanded its API for developers to create extensions and integrate them directly into GitHub.\n\n**[39:40]** Dify is building a platform to support developers in developing and deploying these tools and workflows more easily. The goal is to create a marketplace where tools and workflows can be distributed and used by various users. This system is similar to an open platform, allowing third-party developers to deploy their own tools and workflows.\n\nOn Dify’s platform, there are already about 50 different tools. Some tools were previously released as experiments, but due to a lack of clear direction and community support, they didn’t achieve the expected success.\n\n**[40:17]** Some platforms in the past tried building similar models but didn’t succeed. The reason is that those tools were only built as forms, lacking the ability to interact with external data and unable to combine complex workflows. However, Dify is focusing on solving these issues to create a complete ecosystem for workflows and tools.\n\n**[40:59]** These tools also allow users to push data from external sources into the system. Users can send data from external applications via Open Forms or APIs. Dify will automatically process and format the data for use in the system’s workflows.\n\n**[41:56]** The team is focusing on two main development directions:\n\n1. Continuing to expand and develop existing workflows.\n2. Improving and optimizing current tools to support easier deployment and use.\n\nThe system is built based on common standards for tool and workflow design. The Smithery tool is currently acting as an Agent to manage workflows. Smithery can also be used as a Package Manager to install and manage tools within the system.\n\n**[42:53]** Workflows will operate on the mechanism that if a workflow becomes popular, people can take it and use it as a tool. The nature of these tools is that they are designed to serve specific domains. For example, a tool for creating files, searching, or retrieving code files. It works like an SDK, meaning a library that you just need to import to use.\n\n**[43:37]** Once integrated into the SDK, you can use the available methods to manipulate data. This allows easy integration into AI tools. Currently, only Cross directly supports these operations. However, in the future, it will be standardized so other tools can also integrate easily. The case of Manus is an example. Manus uses many different tools, but when compared to the agent system in Smithery, they are fundamentally two completely different layers.\n\n**[44:15]** In Manus’s system, tools are combined to create more general workflows. These tools operate at different layers, while agents in Smithery are designed to work independently. The question is how to clearly distinguish the difference between Manus’s system and the agent system in Smithery. There’s a summary article about this posted in the AI Club channel — the main content discusses the ability to think (thinking) and the ability to use computers (computer use).\n\n**[45:09]** The mechanism of the Manus system is a service-oriented system. To combine multiple tools into a single workflow, the execution steps need to be clearly defined. For example, step 1 uses which tool, step 2 uses which tool, and so on. This requires the steps to be specifically configured. However, the new system has the ability to reason and automatically determine which tools are needed to complete a task. This is the key difference between the new system and older systems.\n\n**[45:59]** Specifically, the new system can recognize how many tools a task requires, which steps to go through, and can intelligently adjust the execution order. This is a special mechanism and a difference compared to older systems. In other words, it operates like a Supervisor — capable of reasoning and making decisions about the order and method of executing steps in a workflow.\n\n**[46:35]** The Supervisor system operates at a higher layer than the agents in Smithery. Agents in Smithery are simply tools that execute a specific task, while the Supervisor has the ability to manage and coordinate the entire task execution process. Integrating the Supervisor allows the system to operate more flexibly while making it easy to expand and add new tools.\n\n**[47:33]** The team’s goal is to understand how the system works and grasp the mechanics of managing workflows. If we can determine how to deploy and manage workflows, we’ll be able to select and use tools more effectively. This is what the team is aiming for — building a system capable of scaling and optimizing workflows.\n\n**[48:24]** Next, the team will focus on building the **MCP** system. This is a new system designed to manage data and workflows. The team conducted a demo of this system about two weeks ago. The essence of the MCP system is to build an agent that operates on an existing platform. Users can quickly deploy and test the system through MCP.\n\n**[49:10]** MCP will be a complete system, including a **database** and a **server**. This allows the system to operate independently and handle large amounts of data. Unlike older systems, MCP will allow users to adjust configurations and manage data more easily.\n\n**[49:58]** The essence of MCP is an agent, defined with a specific input and output structure. This allows different systems to connect and interact with MCP through standard protocols. In other words, MCP can be integrated into any system via predefined protocols.\n\n**[50:35]** MCP also allows users to manage data through the Knowledge Database, which is essentially a timescale database where all the team’s activity data is dumped. This is a time-series database that enables recording events in real-time, something backend developers will recognize as event sourcing or event logs. For example, it records information about team members, the system’s operational status, or other significant events.\n\n**[51:13]** The Knowledge Database will store all the team’s activity data, including details like who performed which task, the system’s status at specific times, and other information related to the team’s internal operations. This allows the team to track and analyze work performance, thereby making reasonable adjustment decisions.\n\n**[51:51]** The system’s concept includes a component called the Landing Zone. The Landing Zone means that all the data we currently have — about a dozen to tens of datasets (databases) — will be centralized here. Three to five years ago, if we wanted to build a data storage system, we’d create a bot to collect all the team’s activities and input them into our database.\n\nWith the new Meta model, all large data (Big Data) will be dumped into a temporary storage in the form of .dat files on S3 or GCS (Google Cloud Storage). The MCP will have the ability to read directly from the Landing Zone. If the system determines that the data in the Landing Zone is valuable and necessary, it can automatically convert that data into a Time Series Database (TSDB) for long-term use. This is the end game (final outcome) of this system.\n\nThe remaining issue will be building Use Cases based on the organized data in the system — in the direction the team desires. This is a key development direction for the MCP system in the near future.\n\n**[52:25]** So currently, the team will have an old database system — a traditional table-based database located at the bottom of the system (visible in the diagram with blue blocks). Now, the team is adding two new components:\n\n- The **Landing Zone** component — located in the yellow block at the top of the system.\n- The **Time Series Database (TSDB)** component — directly connected to the old system’s components for data analysis and exploitation.\n\nThe team is storing raw data in the Landing Zone. Essentially, centralizing data in the Landing Zone is like rallying troops — gathering all the data in one place before deciding how to analyze and process it. This mechanism makes the system more flexible and easily scalable when new data is added.\n\n**[53:11]** The special feature of this system is its ability to automatically convert data from the Landing Zone to the Time Series Database. This mechanism stems from the growing need for local data analytics. This is an emerging trend in the context of AI (Artificial Intelligence) development.\n\nThe rise of AI has increased the demand for real-time data analysis systems. When raw data is centralized in the Landing Zone, the system will automatically identify valuable data and transfer it to the TSDB for more detailed analysis. This is a significant step forward in building an efficient and adaptable data analysis system to market changes.\n\n**[53:45]** Currently, the team can already run analytics directly on the data stored locally. This system allows running analytics right on the Data Lake without needing to transfer data elsewhere. For the data in the Landing Zone — the file packets that Huy is showing on the screen — this is the part the team needs to focus on researching further. This issue relates to text processing, so the guys need to pick up this topic. It’s not too difficult; it’ll probably take about half a day to grasp the basics.\n\nThe Prompt for searching and exploiting data is also quite fast and simple, not complicated. This is a part very worth experimenting with because it relates to the knowledge discovery mechanism in the system. This is one of the new upgrades Huy just mentioned.\n\n**[54:22]** The most standout feature of the system in this upgrade is the **Knowledge Hub**. This is where the team will centralize all data to serve analysis and knowledge exploitation. The Knowledge Hub will become a common **data pool** for the entire team. Anyone can add data here, and the system will process and convert the data into a standard format.\n\nThe important thing is that once the system is fully set up, everyone in the team will have a common **protocol** to use. Different modules or components will be able to **share** a common data structure and access the Knowledge Hub directly. This will be the common foundation for syncing and processing data within the team.\n\n**[54:58]** Regarding the database (DB), the system will have two layers:\n\n- **Old DB:** Used to support existing operations and process pre-structured data.\n- **New DB:** Designed to connect directly with the **Knowledge Hub** and support real-time data analysis.\n\nThe special thing is that the **MCP** will act as a **protocol** for different modules to communicate with each other. This means that any data needing access or processing just needs to be fed into the system’s correct pathway, and it will be automatically processed according to the standard structure. This is how the system unifies data and avoids conflicts when multiple data sources are processed simultaneously.\n\n**[55:43]** From now on, the team will need to get familiar with the new data processing mechanisms. Everyone should take the time to learn more about the components in the new system. Once these components are stable, the team’s new projects will leverage these tools to deploy faster and more efficiently. This will be the main toolkit to serve future projects.\n\nThis system has the potential to become a **requirement** for upcoming projects. If you want to keep up with the new system, start by learning the basic principles of MCP and related protocols.\n\n**[56:40]** Previously, when the team deployed systems on S3 or GCS (Google Cloud Storage), data processing took quite a bit of time. However, with the new mechanism, data from the Landing Zone will be processed faster and more easily.\n\nThe system has been tested on various platforms, including **S3** and **GCS**. However, since the team’s current infrastructure runs on **GCS**, the data from the Landing Zone will be processed on GCS first. That said, technically, the system can expand to other platforms without major obstacles.\n\n**[57:45]** The Landing Zone’s operating mechanism is quite simple:\n\n- Data from various sources will be centralized in the Landing Zone.\n- This data will be stored as **Parquet files** by day.\n- The system can read these files back through the **Time Series Database (TSDB)** mechanism.\n\nCurrently, some sample **Parquet** files have been created and are being tested. If needed, the team can run a demo on these sample data sets to check the system’s consistency.\n\n**[58:24]** The team’s activities, like **AI sub** or **Memo**, are also fully pushed up here. The task of the **Landing Zone** is to store all the data the team wants — anyone who wants to store something can push it all here, and then the system will decide how to process that data. The system has also provided some tools for people to push data up, such as **API proxies** to forward events. If anyone wants to push information to the Landing Zone, they just need to call the API.\n\nMemo is currently using this mechanism to pull data from **social platforms** and sync it into the system. This mechanism has been successfully tested. For more specific data types like **Discord messages** or **data from Basecamp**, the team needs to build **crawlers** or **connectors** to collect the data. Currently, the team already has some ready-made templates for these data types.\n\n**[58:59]** For the next development direction, the team will focus on exploiting data from the Landing Zone. If you want to join this project, the advice is to start with a specific **vertical**. For example:\n\n- Identify a clear **use case**.\n- Find out **which data** is needed for that use case.\n- Redefine the data exploitation mechanism in a **top-down** approach.\n\nInstead of storing whatever data seems interesting, the team should think in terms of **defining the use case first** and then deciding what data to store. This helps the system operate in an organized and easily manageable way.\n\nA specific example is if there’s a use case about **Project Nghệ Nhân**, the team would need to create a **Git Agent** to collect data from Git, then push that data into the **Knowledge Hub** via MCP. From there, the system would define data exploitation tools for this use case.\n\n**[1:00:16]** Additionally, the team is developing a small MCP Server. This MCP Server is essentially a basic server, using standard technical components of the current internet system. It defines clear inputs and outputs, allowing connection to various interfaces.\n\nFor example:\n\n- If there’s an MCP to process data from Slack, the team will define APIs for each data type.\n- If tools are needed to read data from Google Sheets or analyze weekly check-in status data, the team can create MCP tools to handle that data.\n\nMCP will act as an intermediary component to sync and process data from various sources. Everyone can access these tools from the Editor, Command Line, or any other interface.\n\n**[1:01:07]** The essence of MCP is that it will serve as an **API Gateway** to connect tools. If you need to track everyone’s weekly check-ins in the team, you can create an MCP to collect data from the **Knowledge Hub** and Google Sheets, then compare the data to see who has checked in and who hasn’t.\n\nThe current system is at the stage of deploying a basic MCP Server. The current interface uses the **Command Line** to call MCP, but fundamentally, the team can expand it to connect with various other tools.\n\n**[1:01:43]** The system is focusing on implementing authentication and authorization mechanisms.\n\n- **Authentication** – Verifying users to access the system.\n- **Authorization** – Assigning permissions for data processing activities.\n\nThe system is currently being used internally within the team and has not been made public externally. If you want to use MCP, you’ll need to input a **private key** to authenticate your access rights.\n\n**[1:02:23]** Technically, MCP can expand to different components within the system. Everyone can integrate MCP into existing applications or tools without needing to rewrite too much code.\n\nThe team is still testing this feature and focusing on completing the security and access management parts. Once the system is stable, everyone can integrate MCP into their existing data processing workflows.\n\n**[1:03:00]** It’s just paused here for now; we haven’t tackled the complex authorization problems yet. After completing the current steps, we’ll move on to addressing more complex issues related to authorization and system usage rights. For now, everyone can focus on the basic issues first.\n\nAlright, thank you, Huy. This is one of the important technical development parts for the team. If you follow the activities on the tech and AI Club, you’ll notice the team is moving toward the next steps in the development process. Technically, everyone should pay attention to the key terms Huy just mentioned. If you’re not clear on them, you can review the transcript to get the full information.\n\n**[1:03:45]** The core team is still continuing to develop the system. We request all members to participate in the project so we can **transfer knowledge** more effectively. This project is an environment for everyone to learn and practice.\n\nThis is an opportunity for new team members to get acquainted with and grasp important technical aspects. If you feel unprepared, you can refer to the internal guides and documents to catch up. Training will happen during the work process rather than in separate sessions. This is a hands-on environment where you learn while doing.\n\n**[1:04:29]** Alongside system development, the team is also conducting knowledge transfer from completed projects. We expect to have a session at the end of the month to summarize the lessons learned from these projects. If anyone doesn’t fully understand yet, they can refer to or ask members who’ve worked on them for more information.\n\nIf you feel unprepared or need more details, you can directly ask team members. Everyone can ping more experienced members to get support.\n\n**[1:05:07]** The team has two different groups working in parallel:\n\n- **Tuấn’s team** is developing some games and small applications.\n- **The build team** is working on experimental applications to test the system’s feasibility.\n\nThese activities are similar to the **Build Club** and **AI Club** groups within the Foundation team. Some products have started showing good **output**. Tuấn and his team are developing a game based on the **Turing Machine**.\n\n**[1:06:38]** The **Turing Machine** game that Tuấn’s team is developing is adapted from the board game version into a mobile version. The game’s goal is to guess a sequence of **three numbers**. To guess the correct sequence, players receive **clues**.\n\nFor example:\n\n- If the clue says “one of the three numbers must be greater than 1” → Players can input numbers, and the system will determine if the answer is correct.\n- If two numbers are wrong but one is correct, the system will respond immediately so players can continue adjusting.\n\nThe rules are quite complex, which might be challenging for new players. Tuấn and the team are continuing to tweak it to make the game more accessible without losing its challenge.\n\n**[1:07:23]** The game is called [**Pocket Turing**](https://pocket-turing.vercel.app/) because the original board game version involves punched cards — similar to how the Turing Machine works in computer programming. However, I’ve adjusted and added new elements to make it more suitable for the mobile version.\n\nI plan to refine and expand the game in future versions. Additionally, I’m checking if we can implement premium features or advanced options to increase monetization potential.\n\n**[1:08:16]** I’m testing the beta version of the game. The gameplay is complete, and players can fully experience the features. The next step is to test it with a broader user group to gather feedback and improve the product.\n\n**[1:09:15]** The next goal is to bring the game to the App Store and Google Play to reach more users. For now, the team wants to ensure the game runs stably without serious bugs.\n\nTuấn hopes the game will attract at least **100 paying users** in the initial testing phase. If we get positive feedback, we’ll expand with new features and improve the player experience. I’d love to hear feedback from other team members to adjust and perfect the product further. Tuấn has shared the game download link with team members so everyone can try it and provide input.\n\n**[1:10:13]** If you guys are excited about building products, this is a good time to start. The team has experimented many times before, but this is a chance to do it more systematically. Developing internal products not only improves technical skills but also opens up future commercialization opportunities.\n\nBesides Tuấn’s game, the team is working on other tools. If you have any good ideas, feel free to contribute so we can build and test together. How to sell or monetize the products can be figured out later; the priority is completing the core features first.\n\n**[1:10:58]** Next is An’s part. An once made a tool called **Rec** to aggregate information in a format similar to **Apple**’s system. Version 1 of Rec required users to manually organize information, while the current Version 2 has integrated AI to support automatic organization.\n\nHowever, the AI still has some limitations in fully recognizing content. Sometimes it can’t grasp the entire context, so the results aren’t completely perfect. Still, the important content is organized and displayed fully.\n\n**[1:11:56]** This tool is in the refinement stage, but the core functions are stable. Currently, the team is focusing on improving the interface and optimizing the user experience. An plans to continue developing additional features to better support users.\n\n**[1:12:51]** The team’s projects are currently in the testing and improvement phase. If anyone has questions or suggestions, they can directly discuss with An or other team members. For now, we’ve showcased almost all the projects. More detailed parts will be covered in the next session.\n\n**[1:13:57]** On our team’s side, I always talk about the knowledge related to **liquidity** and **game in general**, right? We really want the team to push a little in that direction because it’s beneficial for almost like a **life skill**, you know? So I want our team to head in that direction this time. Especially those of you who are really interested in **trading**, meaning getting data to find the **Alpha** on it, the **Intel** on it, to come up with some **market-making** strategies based on certain conditions or something like that.\n\n**[1:14:43]** It’s one thing, or it could even go further to create a really awesome flow. It feels like it’s just my dream for now. An has already made a version that I think is pretty okay. Just taking this chance to let you guys know that the team has this kind of progress going on. It’s running, right? Let’s invite An. Okay, okay, generally it’s just a money-making game. See how they make money, and we’ll do the same. The usual stuff has a bit of something to test, a bit of it is also in the form of **Delta neutral**, right? So we also research those things there. Then go build and research to have the knowledge to ship it.\n\n**[1:15:30]** Play this column until it’s all used up, that’s it, no looking over there. Do you all see the terminal screen? Do you see it? Yes, okay, let’s run it. Let’s run it. I think we need to zoom in, zoom in one or two levels, it’s still a bit small, okay now. Yeah, this is the arbitrage to eat the **funding free frost**, right? There are many, many types of arbitrage like that. This is just one of those types, which is eating off the difference, the **phantom bin**, between the exchanges. We’re focusing on three exchanges: **Binance**, **OKX** — that devil OKX, their exchange doesn’t have too much stuff — so, do you have a diagram for that, An?\n\n**[1:16:26]** I think it’ll be a bit hard for everyone to visualize. Looking at this, they won’t understand what it is. Is there one? Okay, no diagram? Oh, there’s this, big one, just theory, nothing concrete comes up at a high level? I guess we’ll have to sketch it roughly again. Do you see it yet? Maybe look at my diagram, yeah, my diagram, so you know it’s this right away. The PRL? Wait, it’s messed up, running wrong, forgot, it’s going into the sockets of…\n\n**[1:17:47]** Those guys to pull **real-time data** back, and it’s currently pulling data from how many accounts? Three accounts — **Binance**, **Bybit**, and what? Okay, initialized to get the price back, right? Getting the price, getting the **funding** back, getting the price yet? Getting some data like fees and fee-related data, it’s kind of coded according to that calculation, but it hasn’t been used to fetch yet. OKX probably doesn’t have it. Those trades, okay, don’t have it, so usually it’s just on the two main ones, which are **Binance** and **Bybit**. Yeah, setup is okay, and then it’ll have an array to show which pair has the difference, the difference in **funding**, then it’ll have profit, and I calculate that if we enter, how much it would be. PH is the number, the number of times we collect the **funding** to break even with the fees. It’s monitoring, monitoring the highest between the two exchanges, that’s it. Step one is getting the difference, the difference in **funding** between the two sides, right? Between the two sides that I’m talking about, no. Because I said this is getting from three exchanges, so compared to its angle, it’s still on the exchange net, right? Yeah, exchange net is something calculated later because…\n\n**[1:19:49] Funding**, let’s say normally, on the price setup, they usually don’t have much, like one is positive, two are positive, or two are negative, so the difference is smaller. Actually, we place a counter on the other difference, it’s just the offset, the price movement offset, so it doesn’t lose due to the price. On the exchange net, there won’t be that difference, we make the **funding** always equal to zero, right? Because there’s no swap fee there, and instead of countering on another exchange with that thing, we counter at the moment when the **funding** is also zero. Currently, we accept that it won’t be as profitable, but that’s how the first version is.\n\n**[1:20:33] b**So we get the price, get the top, get the **funding**, then see if it’s just about deploying capital, right? Have you tried running it yet? Not yet, haven’t poured money in. Yeah, this is like a scale game, you need a lot of money to profit, but with just a few hundred or a few thousand, it goes in, and it doesn’t look like much. Got it, got it, okay, understood. But on the technical side, technically, for me to do this, what did I apply from start to finish? From when it crashed, what did I do? Yeah…\n\n**[1:21:25]** First, I researched that chart beforehand, checked how it was, whether it had this or that, all those things. Yeah, got those dots sorted. We’ll ship it for that, yeah, that guy will code everything with code, okay? Using this **Cloud 3.7**, right? First, you have to get the exchange’s data before calculating anything. The main exchanges will pull from sockets, and the setup is, first, on the API docks of the exchanges, right? This one, yeah, then pull their docks back, throw it to this guy, it ships up to the **WebSocket client**. Every exchange has docks, all of them, pull them back, ship them up, and it’ll auto-view.\n\n**[1:22:15]** The web for all three exchanges is done, with forms and everything. After that, we start building it up, yeah, this part, this chart. The first step is probably explaining it to it and stuff, kind of it builds slowly up. Then check the data and all, if it’s wrong, it auto-builds itself. I built it, and it auto, every time there’s something new, it’ll auto-build a sample to check the data before finding it again for us. Cool, to ensure the data is correct or not. Because the thing between the exchanges, the format is different, the data format is…\n\n**[1:23:01]** Different, everything is different, right? So to compare it all into one final form for it to compare, it needs a section to test pulling the data back, ensuring the data is valid, then it starts comparing. That’s the step. Next, it’ll be building things like, next is, yeah, building the guy to place orders. When it detects these, there’ll be a guy standing by to place orders, watching our bot to see if it’s losing or whatever, slowly, reasonably. The whole process took how long? About a week, yeah, cool, huh? So now the next step…\n\n**[1:23:58]** The next step of this tool I’m working on, what’s the next step? I’ll check the data first, check the data to see which one makes money easily, which one is profitable, which one you put money into and it’s all profitable. There’ll be data to check those profits, then manage more of our stuff, like risks and all that, then, yeah, pull all the data back about the fee structure of the exchanges. Because if you use those trusts or whatever, the exchange fees affect the thing a lot, so you need the exact fees, then calculate…\n\n**[1:24:51]** How to ensure it’s profitable in the end before placing orders, right? Next will probably be those steps. Okay, that’s the step, the step of when to place orders, that’s the final thing, right? The rest needs to filter the data first. Is there a back system built? Because I think this data, does it have history or not? Does it? Or is it just at that moment? It does, if you can get the history, it’s backtest history, but I think it’s not accurate, huh? Yeah, not accurate, not there. I don’t think so. The other stuff might have it, but this arbitrage is a bit hard to get accurate.\n\n**[1:25:38]** This is a technical showcase. I think with this direction in the team, independently, our team, regarding this direction, it’s okay. You guys showcasing the trading game have started having steps that the team is pushing forward to do. I think fundamentally, fundamentally, you guys are all on a path, on the way to getting to what you want to do, which is very good. The thing is, with technology, with that tech know-how, how we bring it out and use it, right?\n\n**[1:26:19]** The team’s activities in general are like this, okay? Regarding productivity, it feels like recently everyone has started syncing with each other to a certain degree. But with Tom, Tom is probably out, but Tom had a comment from before when you guys were sitting and chatting. We were thinking, what’s the team’s productivity level right now? How much would Tom rate it? 2/10 or 4/10, huh? If compared to the level we need, you guys at like 6-7/10, the general average, I think we’re in a very good setup right now.\n\n**[1:27:01]** The next step regarding the quality, the technology tool link to support us in operating the team according to this model, it’s being improved slowly but surely. On the market side, the **funding** market in general and the products are starting to stir and come back. People see the technology becoming more stable. In **crypto**, it’s heavily influenced by macro factors, but whenever there’s a tech trend, they’ll jump in and bite, that’s how it is, right? I’m seeing signals for it to resume soon, about 50/50 right now. Before this, I looked at the market, and it was really bad, like everything wasn’t ready yet. Even if you studied a lot and worked a lot, results wouldn’t come immediately.\n\n**[1:27:40]** But this time, I think you guys will need to have some requirements about participating in these things, okay? Next week, I’ll probably ask Huy,Tom and Thành to compile some stats, to see besides the projects you’re working on, what’s the participation in side projects like that, who’s doing what, alright? That’s the follow-up after the content, we’ve discussed almost everything. Next week, there are still some core flow parts left, but they probably won’t affect things too much.\n\n**[1:28:22]** Today is the 14th, I hope by the end of this month, the next team meeting will show more progress. Everything we’re doing is very important, right? Another important thing is we have Sister Minh here, Nicki. Probably past the out time already. All of this is being uploaded to **Memo**, and we’re using that **Memo** not just to share on it — that’s not enough — but the channels we’re working on are being sent out…\n\n**[1:29:01]** To everywhere, to other companies we know, starting to expand the network to look for necessary users. The thing is, we know these things already, so how do we mound our ability to profit from our knowledge? That’s the idea, okay? That’s the skin the team is following. In summary, the market assessment is like this. Next week, you guys will need to register for those parts, and Huy, Tom, and Thành are the mandatory segments.\n\n**[1:29:45]** As for the hobby clubs, like Build or something, I don’t have high demands there, producing technical stuff to apply, it’s not that important. The output matters more. Two different groups: one group is the core project parts we’ll work on, focusing on how to increase activity, increase everyone’s **knowledge base**; the other group focuses on the **skill set**, how to develop products for launch, how to do onboarding better, users and all that. It’s a different skill set group. You guys next week jump in and start thinking, especially…\n\n**[1:30:27]** Especially Huy, Huy is co-handling the return to the office to start shadowing for **knowledge transfer**. If it works, just keep it going, then see how the numbers look and report back to me, okay? Hopefully, when we have the numbers, you guys discuss further, figure out how to set up that shadowing on the projects, the sites we’re involved in, to have cases to share with each other, right? Like Sister An, finishing this in a week is super solid, doing everything herself, using new workflows and all, it’s great…\n\n**[1:31:05]** Alright, you guys, that’s the whole thing. If there’s nothing else now, we’ll probably end here. How many people are here? 28 people, huh? No, how many in this call right now? Preparing to spam ICY, is there an issue with transferring ICY yet? Everyone go random, grab it like ghosts, okay? Amount is 28, so we’ll drop 14 ICY tokens, entry is 14 already. Go ahead, duration is 5 seconds. Okay, let’s go. One ICY earlier was about 100 Satoshi already.\n\n**[1:32:09]** Now starting, don’t know when the boss updates the multiplier price, just estimate it for now. Today’s early, next time seeing Bitcoin, it looks cool. Happy Weekend, bye bye everyone.","title":"OGIF Office Hours #41 - ICY-BTC Swap, GitHub Bot, MCP-DB, Pocket Turing, Recapable, and Arbitrage Strategy","short_title":"#41 ICY-BTC, GitHub Bot, MCP-DB, Pocket Turing","description":"In OGIF 41, the team covered key updates on the ICY-BTC swap, GitHub bot automation, MCP-DB system for agent workflows, and progress on the Pocket Turning and Recapable projects and we also shared insights into funding rate arbitrage strategies.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Thu Mar 20 2025 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/41-20250314.md","slugArray":["updates","ogif","41-20250314"]},{"content":"\n80 minutes\nRecorded May 03, 2024\n\n### Summary\nTitle: Singapore Market Report, Creating Nested Sidebar in Memo, C4 Modeling - Dwarves Foundation Office Hours.\n\n[00:03](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3) Introducing team members and preparing for the meeting.\n\n[09:12](https://www.youtube.com/watch?v=PIAHm1gRqww&t=552) Discussion on upcoming topics and overview of team activities\n\n[13:24](https://www.youtube.com/watch?v=PIAHm1gRqww&t=804) Discussing upcoming events and activities\n\n[15:24](https://www.youtube.com/watch?v=PIAHm1gRqww&t=924) Minh Le presents Singapore market research in a 5-minute segment\n\n[18:51](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1131) Companies cutting down costs by reducing workforce and marketing expenses\n\n[20:11](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1211) Discussing different product testing in various market segments\n\n[22:53](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1373) Startups must limit expenditures and focus on profitable areas\n\n[24:18](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1458) Discussing different aspects and applications of C4 modelling\n\n[27:29](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1649) Discussing the benefits of creating a nested sidebar for team collaboration\n\n[29:10](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1750) Demonstration of upcoming features and interface\n\n[32:48](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1968) Process of transferring IC to another system\n\n[34:25](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2065) Introducing the stacking model for protocol protection.\n\n[37:58](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2278) C4 modelling helps in problem statement and system structure representation\n\n[39:11](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2351) C4 model helps in communicating system structures effectively.\n\n[42:13](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2533) Implementing specific component functionalities\n\n[43:39](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2619) C4 model for decision making and testing\n\n[46:49](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2809) Using the CFO model as a framework for communication and diagramming\n\n[48:18](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2898) Understanding C4 modeling and Memo's nested sidebar\n\n[52:05](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3125) Using recursion and HTML output.js to nest items\n\n[53:56](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3236) Handling menu items and rendering HTML\n\n[58:41](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3521) Discussing C4 modelling and Memo's nested sidebar\n\n[1:01:00](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3660) Transitioning from pure JavaScript to using Outbox\n\n[1:04:11](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3851) Implementing features in C4 modeling\n\n[1:06:03](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3963) Next week's agenda planning\n\n[1:11:41](https://www.youtube.com/watch?v=PIAHm1gRqww&t=4301) Discussion about C4 modeling and Memo's nested sidebar\n\n[1:13:41](https://www.youtube.com/watch?v=PIAHm1gRqww&t=4421) Introducing the nested sidebar feature in Memo\n\n[1:19:05](https://www.youtube.com/watch?v=PIAHm1gRqww&t=4745) Submission process for assigned topics\n\n---\n\n### Transcript\n\n> The transcript formatting and language accuracy is a WIP, so it might look a little weird. This will be improved in later iterations.\n\nDetailed Summary for [Office Hours - C4 modelling and How we made Memo's nested sidebar](https://www.youtube.com/watch?v=PIAHm1gRqww) \n\nTitle: Singapore Market Report, Creating Nested Sidebar in Memo, C4 Modeling - Dwarves Foundation Office Hours.\n\n[00:03](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3) Introducing team members and preparing for the meeting.\n\n- Discussion about the missing team members and ensuring everyone is present.\n- Verification of team members' attendance and preparation for the upcoming event.\n\n[09:12](https://www.youtube.com/watch?v=PIAHm1gRqww&t=552) Discussion on upcoming topics and overview of team activities\n\n- Team activities and highlights from the past week will be summarized\n- Introduction to the trading process and insights shared by An regarding building trading strategies\n\n[13:24](https://www.youtube.com/watch?v=PIAHm1gRqww&t=804) Discussing upcoming events and activities\n\n- e27 is starting a new event series focused on the tech industry in the region.\n- Planning to network and reconnect with colleagues and friends during the events.\n\n[15:24](https://www.youtube.com/watch?v=PIAHm1gRqww&t=924) Ngọc presents market research in a 5-minute segment\n\n- Nikki and Minh Le compiled an overview of the ecosystem and market research\n- Discussion about sharing screen and chart data for startup funding\n\n[18:51](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1131) Companies cutting down costs by reducing workforce and marketing expenses\n\n- IT sector heavily impacted, companies looking to cut down on workforce costs\n- Marketing teams shifting focus to technology development to reduce marketing expenses\n\n[20:11](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1211) Discussing different product testing in various market segments\n\n- Lazada group's e-commerce testing and technical issues with label display\n- Logistics and fintech testing and investment distribution for 2023\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/PIAHm1gRqww?si=REj46sApLqAKddRO&amp;start=1134\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[22:53](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1373) Startups must limit expenditures and focus on profitable areas\n\n- Hesitancy in expanding into new markets due to concerns about data privacy\n- Corporate structure leading to slow adoption of new technologies and high implementation costs\n\n[24:18](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1458) Discussing different aspects and applications of C4 modelling\n\n- Various professionals focusing on specific niche areas within the market\n- Highlighting the need for more comprehensive data aggregation\n\n[27:29](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1649) Discussing the benefits of creating a nested sidebar for team collaboration\n\n- Exploring how it helps in market research and accessing company and VC information easily\n- Highlighting the advantage of collaborating with ecosystem builders for consulting roles\n\n[29:10](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1750) Demonstration of upcoming features and interface\n\n- Introduction to a new page layout designed for user convenience\n- Details on upcoming features related to stacking and data retrieval\n\n[32:48](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1968) Process of transferring IC to another system\n\n- Mentions the steps involved in transferring IC tokens to another system.\n- Explains the process of token selection, address input, confirmation, and receiving rewards.\n\n[34:25](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2065) Introducing the stacking model for protocol protection.\n\n- Implementing the stacking model as a mechanism for quicker employee share options.\n- Encouraging team contribution through the use of Tokens for faster rewards.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/PIAHm1gRqww?si=4pviJM5xLZuvNGWi&amp;start=2266\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[37:58](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2278) C4 modelling helps in problem statement and system structure representation\n\n- Modeling involves problem statement to create solution and representation of system structure.\n- Challenges in communication and understanding arise in creating system architecture using C4 modeling.\n\n[39:11](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2351) C4 model helps in communicating system structures effectively.\n\n- Using abstractions to represent system structures in a simple and understandable way for different domains.\n- Collaborating with all parties to agree on common terminology and diagrams for defining domains and solutions.\n\n[42:13](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2533) Implementing specific component functionalities\n\n- Explaining the specific implementation of each component using functions or methods like the App Factor authenticate\n- Utilizing UML components or box and line diagrams to express abstractions clearly for better understanding\n\n[43:39](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2619) C4 model for decision making and testing\n\n- C4 model used for source of choice for design documents and decision making\n- C4 diagram utilized for testing and QA to ensure alignment and accuracy\n\n[46:49](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2809) Using the CFO model as a framework for communication and diagramming\n\n- Utilizing the CFO model to communicate and convey solutions effectively\n- Expanding on the diagramming process for specific cases such as event model and different architectures\n\n[48:18](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2898) Understanding C4 modeling and Memo's nested sidebar\n\n- Discussion on the level of container and its context in components\n- Implementing a technical topic and the need for diagrams\n\n[52:05](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3125) Using recursion and HTML output.js to nest items\n\n- Employ recursion for unlimited nested items\n- Utilize outp js library for HTML output functionality\n\n[53:56](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3236) Handling menu items and rendering HTML\n\n- Explaining the process of handling each case and returning the HTML\n- Addressing questions about the tool and the testing process\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/PIAHm1gRqww?si=LKFYvKl_kOEraIpY&amp;start=2883\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[58:41](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3521) Discussing C4 modelling and Memo's nested sidebar\n\n- Explaining the structure and purpose of C4 modelling and Memo's nested sidebar\n- Detailing the process of creating and iterating PlayBook playground and data folders\n\n[1:01:00](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3660) Transitioning from pure JavaScript to using Outbox\n\n- Exploring two previous methods attempted before the current approach.\n- Discussion on the benefits of using Outbox for smoother functionality.\n\n[1:04:11](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3851) Implementing features in C4 modeling\n\n- Discussing different implementation choices and variations\n- Choosing different features for different projects and case studies\n\n[1:06:03](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3963) Next week's agenda planning\n\n- Deciding on the topic for the next week's session\n- Discussion on using a common template for easy start\n\n[1:11:41](https://www.youtube.com/watch?v=PIAHm1gRqww&t=4301) Discussion about C4 modeling and Memo's nested sidebar\n\n- Conversation about the design and implementation of a game with the necessary buttons.\n- Planning for the upcoming week's agenda and the need for quick voting.\n\n[1:13:41](https://www.youtube.com/watch?v=PIAHm1gRqww&t=4421) Introducing the nested sidebar feature in Memo\n\n- Discussing the implementation process of the C4 modeling technique\n- Exploring the functionalities and benefits of Memo's nested sidebar feature\n\n[1:19:05](https://www.youtube.com/watch?v=PIAHm1gRqww&t=4745) Submission process for assigned topics\n\n- Submit assigned topics for review by organizing structure\n- Collaborate on foundational topics and design elements before final submission\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/PIAHm1gRqww?si=_fvPep-YtVUkOngO&amp;start=3679\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n---\n\n**Vietnamese version**\n\nShort Summary for [Office Hours - Singapore market report, C4 modelling and How we made Memo's nested sidebar](https://www.youtube.com/watch?v=PIAHm1gRqww)\n\nOGIF 5 - Báo cáo thị trường Singapore, tạo nested side bar cho memo, mô hình C4.\n\n[00:03](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3) Giới thiệu các thành viên trong nhóm và chuẩn bị cho cuộc họp.\n\n[09:12](https://www.youtube.com/watch?v=PIAHm1gRqww&t=552) Thảo luận về các chủ đề sắp tới và tổng quan về hoạt động của nhóm\n\n[13:24](https://www.youtube.com/watch?v=PIAHm1gRqww&t=804) Thảo luận về các sự kiện và hoạt động sắp tới\n\n[15:24](https://www.youtube.com/watch?v=PIAHm1gRqww&t=924) Minh trình bày nghiên cứu thị trường trong phân đoạn 5 phút\n\n[18:51](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1131) Các công ty cắt giảm chi phí bằng cách giảm lực lượng lao động và chi phí tiếp thị\n\n[20:11](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1211) Thảo luận về việc thử nghiệm các sản phẩm khác nhau ở các phân khúc thị trường khác nhau\n\n[22:53](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1373) Startup phải hạn chế chi tiêu và tập trung vào lĩnh vực sinh lời\n\n[24:18](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1458) Thảo luận về các khía cạnh và ứng dụng khác nhau của mô hình C4\n\n[27:29](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1649) Thảo luận về lợi ích của việc tạo thanh bên lồng nhau để cộng tác nhóm\n\n[29:10](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1750) Trình diễn các tính năng và giao diện sắp tới\n\n[32:48](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1968) Quá trình chuyển IC sang hệ thống khác\n\n[34:25](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2065) Giới thiệu mô hình xếp chồng để bảo vệ giao thức.\n\n[37:58](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2278) Mô hình C4 giúp phát biểu vấn đề và biểu diễn cấu trúc hệ thống\n\n[39:11](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2351) Mô hình C4 giúp truyền đạt cấu trúc hệ thống một cách hiệu quả.\n\n[42:13](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2533) Triển khai các chức năng thành phần cụ thể\n\n[43:39](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2619) Mô hình C4 để ra quyết định và thử nghiệm\n\n[46:49](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2809) Sử dụng mô hình CFO làm khuôn khổ cho việc giao tiếp và lập sơ đồ\n\n[48:18](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2898) Tìm hiểu mô hình C4 và thanh bên lồng nhau của Bản ghi nhớ\n\n[52:05](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3125) Sử dụng đệ quy và HTML input.js để lồng các mục\n\n[53:56](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3236) Xử lý các mục menu và hiển thị HTML\n\n[58:41](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3521) Thảo luận về mô hình C4 và thanh bên lồng nhau của Bản ghi nhớ\n\n[1:01:00](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3660) Chuyển từ JavaScript thuần túy sang sử dụng Hộp thư đi\n\n[1:04:11](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3851) Triển khai các tính năng trong mô hình C4\n\n[1:06:03](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3963) Lập kế hoạch chương trình tuần tới\n\n[1:11:41](https://www.youtube.com/watch?v=PIAHm1gRqww&t=4301) Thảo luận về mô hình C4 và thanh bên lồng nhau của Bản ghi nhớ\n\n[1:13:41](https://www.youtube.com/watch?v=PIAHm1gRqww&t=4421) Giới thiệu tính năng thanh bên lồng nhau trong Bản ghi nhớ\n\n[1:19:05](https://www.youtube.com/watch?v=PIAHm1gRqww&t=4745) Quy trình submit bài cho các chủ đề được giao\n\n---\n\n**Detailed Summary for [Office Hours 5 - Singapore Market Report, C4 modelling and How we made Memo's nested sidebar](https://www.youtube.com/watch?v=PIAHm1gRqww)**\n\n[00:03](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3) Giới thiệu các thành viên trong nhóm và chuẩn bị cho cuộc họp.\n\n- Thảo luận về các thành viên trong nhóm mất tích và đảm bảo mọi người đều có mặt.\n- Xác minh sự tham dự của các thành viên trong nhóm và chuẩn bị cho sự kiện sắp tới.\n\n[09:12](https://www.youtube.com/watch?v=PIAHm1gRqww&t=552) Thảo luận về các chủ đề sắp tới và tổng quan về hoạt động của nhóm\n\n- Các hoạt động của nhóm và những điểm nổi bật trong tuần qua sẽ được tóm tắt\n- Giới thiệu về quy trình giao dịch và những hiểu biết sâu sắc được An chia sẻ về việc xây dựng chiến lược giao dịch\n\n[13:24](https://www.youtube.com/watch?v=PIAHm1gRqww&t=804) Thảo luận về các sự kiện và hoạt động sắp tới\n\n- e27 đang bắt đầu chuỗi sự kiện mới tập trung vào ngành công nghệ trong khu vực.\n- Lập kế hoạch kết nối và kết nối lại với đồng nghiệp và bạn bè trong các sự kiện.\n\n[15:24](https://www.youtube.com/watch?v=PIAHm1gRqww&t=924) Ngọc trình bày nghiên cứu thị trường trong phân đoạn 5 phút\n\n- Nikki và Minh Lê tổng hợp tổng quan về hệ sinh thái và nghiên cứu thị trường\n- Thảo luận về việc chia sẻ dữ liệu màn hình và biểu đồ để tài trợ cho khởi nghiệp\n\n[18:51](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1131) Các công ty cắt giảm chi phí bằng cách giảm lực lượng lao động và chi phí tiếp thị\n\n- Ngành CNTT bị ảnh hưởng nặng nề, các công ty tìm cách cắt giảm chi phí nhân lực\n- Đội ngũ tiếp thị chuyển trọng tâm sang phát triển công nghệ để giảm chi phí tiếp thị\n\n[20:11](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1211) Thảo luận về việc thử nghiệm các sản phẩm khác nhau ở các phân khúc thị trường khác nhau\n\n- Thử nghiệm thương mại điện tử của tập đoàn Lazada và các vấn đề kỹ thuật về hiển thị nhãn\n- Thử nghiệm và phân phối đầu tư về hậu cần và fintech cho năm 2023\n\n[22:53](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1373) Startup phải hạn chế chi tiêu và tập trung vào lĩnh vực sinh lời\n\n- Do dự trong việc mở rộng sang các thị trường mới do lo ngại về quyền riêng tư dữ liệu\n- Cơ cấu doanh nghiệp dẫn đến việc áp dụng công nghệ mới chậm và chi phí triển khai cao\n\n[24:18](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1458) Thảo luận về các khía cạnh và ứng dụng khác nhau của mô hình C4\n\n- Nhiều chuyên gia khác nhau tập trung vào các lĩnh vực thích hợp cụ thể trên thị trường\n- Nhấn mạnh sự cần thiết phải tổng hợp dữ liệu toàn diện hơn\n\n[27:29](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1649) Thảo luận về lợi ích của việc tạo thanh bên lồng nhau để cộng tác nhóm\n\n- Khám phá cách nó giúp ích trong nghiên cứu thị trường và truy cập thông tin của công ty và VC một cách dễ dàng\n- Làm nổi bật lợi thế của việc cộng tác với các nhà xây dựng hệ sinh thái cho vai trò tư vấn\n\n[29:10](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1750) Trình diễn các tính năng và giao diện sắp tới\n\n- Giới thiệu về bố cục trang mới được thiết kế để thuận tiện cho người dùng\n- Thông tin chi tiết về các tính năng sắp tới liên quan đến xếp chồng và truy xuất dữ liệu\n\n[32:48](https://www.youtube.com/watch?v=PIAHm1gRqww&t=1968) Quá trình chuyển IC sang hệ thống khác\n\n- Đề cập đến các bước liên quan đến việc chuyển mã thông báo IC sang hệ thống khác.\n- Giải thích quy trình lựa chọn mã thông báo, nhập địa chỉ, xác nhận và nhận phần thưởng.\n\n[34:25](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2065) Giới thiệu mô hình xếp chồng để bảo vệ giao thức.\n\n- Triển khai mô hình xếp chồng như một cơ chế để các lựa chọn chia sẻ của nhân viên nhanh hơn.\n- Khuyến khích sự đóng góp của nhóm thông qua việc sử dụng Token để nhận phần thưởng nhanh hơn.\n\n[37:58](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2278) Mô hình C4 giúp phát biểu vấn đề và biểu diễn cấu trúc hệ thống\n\n- Mô hình hóa liên quan đến việc phát biểu vấn đề để tạo ra giải pháp và biểu diễn cấu trúc hệ thống.\n- Những thách thức trong giao tiếp và hiểu biết nảy sinh trong việc tạo ra kiến trúc hệ thống bằng mô hình C4.\n\n[39:11](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2351) Mô hình C4 giúp truyền đạt cấu trúc hệ thống một cách hiệu quả.\n\n- Sử dụng sự trừu tượng để biểu diễn cấu trúc hệ thống một cách đơn giản và dễ hiểu cho các miền khác nhau.\n- Phối hợp với các bên để thống nhất các thuật ngữ và sơ đồ chung để xác định lĩnh vực và giải pháp.\n\n[42:13](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2533) Triển khai các chức năng thành phần cụ thể\n\n- Giải thích cách triển khai cụ thể của từng thành phần bằng cách sử dụng các hàm hoặc phương thức như xác thực App Factor\n- Sử dụng các thành phần UML hoặc sơ đồ hộp và đường để thể hiện sự trừu tượng một cách rõ ràng để hiểu rõ hơn\n\n[43:39](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2619) Mô hình C4 để ra quyết định và thử nghiệm\n\n- Mô hình C4 dùng làm nguồn lựa chọn cho tài liệu thiết kế và ra quyết định\n- Sơ đồ C4 được sử dụng để thử nghiệm và đảm bảo chất lượng để đảm bảo sự liên kết và độ chính xác\n\n[46:49](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2809) Sử dụng mô hình CFO làm khuôn khổ cho việc giao tiếp và lập sơ đồ\n\n- Sử dụng mô hình CFO để truyền đạt và truyền tải giải pháp hiệu quả\n- Mở rộng quy trình lập sơ đồ cho các trường hợp cụ thể như mô hình sự kiện và các kiến trúc khác nhau\n\n[48:18](https://www.youtube.com/watch?v=PIAHm1gRqww&t=2898) Tìm hiểu mô hình C4 và thanh bên lồng nhau của Bản ghi nhớ\n\n- Thảo luận về mức độ của vùng chứa và bối cảnh của nó trong các thành phần\n- Thực hiện một chủ đề kỹ thuật và sự cần thiết của sơ đồ\n\n[52:05](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3125) Sử dụng đệ quy và HTML input.js để lồng các mục\n\n- Sử dụng đệ quy cho các mục lồng nhau không giới hạn\n- Sử dụng thư viện outp js cho chức năng xuất HTML\n\n[53:56](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3236) Xử lý các mục menu và hiển thị HTML\n\n- Giải thích quy trình xử lý từng trường hợp và trả về HTML\n- Giải quyết các câu hỏi về công cụ và quy trình thử nghiệm\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/PIAHm1gRqww?si=AfoC7F4inqjIna9c&amp;start=3017\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[58:41](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3521) Thảo luận về mô hình C4 và thanh bên lồng nhau của Bản ghi nhớ\n\n- Giải thích cấu trúc và mục đích của mô hình C4 và thanh bên lồng nhau của Bản ghi nhớ\n- Chi tiết quá trình tạo và lặp lại các thư mục dữ liệu và sân chơi PlayBook\n\n[1:01:00](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3660) Chuyển từ JavaScript thuần túy sang sử dụng Hộp thư đi\n\n- Khám phá hai phương pháp trước đó đã được thử trước phương pháp hiện tại.\n- Thảo luận về lợi ích của việc sử dụng Hộp thư đi để có chức năng mượt mà hơn.\n\n[1:04:11](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3851) Triển khai các tính năng trong mô hình C4\n\n- Thảo luận về các lựa chọn và biến thể triển khai khác nhau\n- Chọn các tính năng khác nhau cho các dự án và nghiên cứu điển hình khác nhau\n\n[1:06:03](https://www.youtube.com/watch?v=PIAHm1gRqww&t=3963) Lập kế hoạch chương trình tuần tới\n\n- Quyết định chủ đề cho buổi học tuần tới\n- Thảo luận về việc sử dụng một mẫu chung để dễ dàng bắt đầu\n\n[1:11:41](https://www.youtube.com/watch?v=PIAHm1gRqww&t=4301) Thảo luận về mô hình C4 và thanh bên lồng nhau của Bản ghi nhớ\n\n- Cuộc trò chuyện về việc thiết kế và triển khai trò chơi bằng các nút cần thiết.\n- Lập kế hoạch cho chương trình nghị sự của tuần tới và nhu cầu bỏ phiếu nhanh chóng.\n\n[1:13:41](https://www.youtube.com/watch?v=PIAHm1gRqww&t=4421) Giới thiệu tính năng thanh bên lồng nhau trong Bản ghi nhớ\n\n- Thảo luận quá trình thực hiện kỹ thuật mô hình hóa C4\n- Khám phá các chức năng và lợi ích của tính năng thanh bên lồng nhau của Bản ghi nhớ\n\n[1:19:05](https://www.youtube.com/watch?v=PIAHm1gRqww&t=4745) Quy trình nộp bài cho các chủ đề được giao\n\n- Gửi chủ đề được giao để xem xét theo cơ cấu tổ chức\n- Cộng tác về các chủ đề cơ bản và các yếu tố thiết kế trước khi gửi bản cuối cùng\n","title":"OGIF Office Hours #5 - Singapore market report, C4 modelling, How we created Memo's nested sidebar","short_title":"#5 Singapore Market Report, C4 Modelling, Memo's Nested Sidebar","description":"Our fifth office hours community discussion covers the Singapore market report, C4 modeling, and how we created Memo's nested sidebar. We aim to promote learning and growth within our community by sharing weekly topics, selected through tags, and encouraging collaboration among members.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Thu Jun 06 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/5-20240503.md","slugArray":["updates","ogif","5-20240503"]},{"content":"\n147 minutes\nRecorded May 10, 2024\n\n### Summary\nTranscript for [Office Hours - Looking at the Factory pattern, Erlang state machines, and the Trading Process](https://www.youtube.com/watch?v=9RBYMYIxmXk) \n\nTitle: Exploring Factory Pattern, Erlang State Machines, and Trading Processes with Dwarves Foundation\n\n[00:03](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3) Factory pattern and its details\n\n[10:55](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=655) The Factory pattern simplifies the product creation process for customers.\n\n[18:26](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=1106) Factory method allows for separate initialization and logic of each product.\n\n[21:29](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=1289) Advantages and disadvantages of the Factory pattern discussed.\n\n[28:12](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=1692) Understanding the difference between Factory and builder pattern in object initialization\n\n[31:58](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=1918) Understanding the Factory pattern and its variations\n\n[38:55](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=2335) Discussion on combining Factory pattern with builder prototype\n\n[41:32](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=2492) Minh is taking on additional responsibilities and moving up within the team structure.\n\n[47:15](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=2835) Exploring optimization opportunities in the trading process\n\n[50:14](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3014) Optimizing trading processes for profit maximization\n\n[56:02](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3362) Automating stock position resizing and management using a bot\n\n[59:10](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3550) Utilizing platforms like Fly for efficient application deployment\n\n[1:05:15](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3915) Introduction to the Erlang state machine\n\n[1:08:48](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=4128) Understanding the state transitions in the trading process\n\n[1:13:22](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=4402) Exploring the Factory pattern and Erlang state machines\n\n[1:15:48](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=4548) Implementing state machines in the system\n\n[1:21:09](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=4869) Implementing the Factory Pattern in Erlang state machines\n\n[1:23:58](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5038) Managing server errors and data retrieval in Erlang state machines\n\n[1:28:54](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5334) Discussion on implementing a regular state machine and utilizing Erlang state machines.\n\n[1:31:28](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5488) Erlang state machine design and macro feature benefits\n\n[1:35:57](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5757) Exploring the benefits of implementing Erlang state machines in the process flow.\n\n[1:38:43](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5923) Discussing the Factory pattern, Erlang state machines, and the Trading Process.\n\n[1:46:14](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=6374) Overview of g is prot and the anh side\n\n---\n\n### Transcript\n\n> The transcript formatting and language accuracy is a WIP, so it might look a little weird. This will be improved in later iterations.\n\nDetailed Summary for [Office Hours - Looking at the Factory pattern, Erlang state machines, and the Trading Process](https://www.youtube.com/watch?v=9RBYMYIxmXk) \n\n\n[00:03](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3) Factory pattern and its details\n\n- Explaining the problem the Factory pattern solves and its solution\n- Discussing the concept structure, practical application, advantages, and disadvantages\n\n[10:55](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=655) The Factory pattern simplifies the product creation process for customers.\n\n- The pattern involves a customer expressing their drink preferences to a bartender, who customizes or suggests a drink based on the preferences.\n- The Factory method is a type of design pattern that simplifies the initialization of objects by providing a common interface.\n\n[18:26](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=1106) Factory method allows for separate initialization and logic of each product.\n\n- The factory method is used when the application doesn't know in advance what type of object it will work with.\n- It is beneficial for situations where runtime conditions determine object type initialization.\n\n[21:29](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=1289) Advantages and disadvantages of the Factory pattern discussed.\n\n- Advantages include easy code readability and separation of logic. Disadvantages involve increased complexity and code size.\n\n[28:12](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=1692) Understanding the difference between Factory and builder pattern in object initialization\n\n- Factory pattern simplifies object initialization using inherited functions, while builder pattern involves defining and implementing steps for object creation.\n- Builder pattern allows for creating objects with different steps, ensuring flexibility and customization in object construction.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/9RBYMYIxmXk?si=qv9Sf0WDxmL83YPJ&amp;start=1426\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[31:58](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=1918) Understanding the Factory pattern and its variations\n\n- The Factory pattern involves using an interface to create objects\n- There is also the abstract Factory pattern for creating related sets of products\n\n[38:55](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=2335) Discussion on combining Factory pattern with builder prototype\n\n- The team discussed the implementation of Factory pattern with builder prototype\n- Considered ease of prototyping with Singleton pattern in Singapore\n\n[41:32](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=2492) Minh is taking on additional responsibilities and moving up within the team structure.\n\n- Minh started as Junior PM, gaining more insight into team operations.\n- Minh is progressing towards a role as a second assistant, related to management and project management.\n\n[47:15](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=2835) Exploring optimization opportunities in the trading process\n\n- Discussing the recurring tasks in the trade process such as deposits and checks\n- Implementing optimizations through automation and custom indicators\n\n[50:14](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3014) Optimizing trading processes for profit maximization\n\n- Utilizing specific triggers on Binance for efficient trading analysis and decision-making\n- Notifying and capitalizing on favorable exchange rates during specific timeframes\n\n[56:02](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3362) Automating stock position resizing and management using a bot\n\n- Creating a bot called 'distribute Anf' to resize stock positions\n- Utilizing Roxim to handle requests and automate stock management\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/9RBYMYIxmXk?si=bPXYdqAIhH6JwQ3S&amp;start=2616\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[59:10](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3550) Utilizing platforms like Fly for efficient application deployment\n\n- It automates processes to save time and focus on key tasks like stock management.\n- Fly platform offers simple deployment solutions for applications like Telegram or Discord.\n\n[1:05:15](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3915) Introduction to the Erlang state machine\n\n- The Erlang state machine consists of three states: closed, open, and half-open, resembling a circuit breaker.\n- It is used to handle requests and prevent server downtime with its different states.\n\n[1:08:48](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=4128) Understanding the state transitions in the trading process\n\n- Explaining how server status affects communication with other parties.\n- Detailing the circuit breaker's role in managing connections and events.\n\n[1:13:22](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=4402) Exploring the Factory pattern and Erlang state machines\n\n- The Factory pattern focuses on data structures in each function\n- Erlang state machines manage processes like user registration with multiple states\n\n[1:15:48](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=4548) Implementing state machines in the system\n\n- The process involves three stages and three actions\n- The demo part discusses different versions and implementation details\n\n[1:21:09](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=4869) Implementing the Factory Pattern in Erlang state machines\n\n- Discussing the process of re-attaching libraries and handling input functions.\n- Exploring the simplification of logic through the use of Grapper in implementation.\n\n[1:23:58](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5038) Managing server errors and data retrieval in Erlang state machines\n\n- Dividing processing logic into smaller parts for easy scalability and code maintenance\n- Utilizing state transitions and error management functions in Erlang for efficient process handling\n\n[1:28:54](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5334) Discussion on implementing a regular state machine and utilizing Erlang state machines.\n\n- Explanation on using Erlang state machines and the support from the Standard Library side.\n- Discussion on the underlying nature of how it runs and the complexity of implementation.\n\n[1:31:28](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5488) Erlang state machine design and macro feature benefits\n\n- Erlang state machine design includes using macros that generate code during the process of using it, making it convenient and efficient.\n- Working with the Lan side and the macro feature provides cost-effective processes, supporting different languages and minimizing resource usage.\n\n[1:35:57](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5757) Exploring the benefits of implementing Erlang state machines in the process flow.\n\n- Understanding the importance of data and functions in Erlang state management.\n- Exploring the structure of OTP in managing states and processes.\n\n[1:38:43](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5923) Discussing the Factory pattern, Erlang state machines, and the Trading Process.\n\n- Ways of managing code logic with OTP, FSM, and GenServer in Erlang.\n- Exploring the transition from a gen server to a state machine for enhanced error handling.\n\n[1:46:14](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=6374) Overview of g is prot and the anh side\n\n- Discussion on Erlang state machines and their role in the trading process\n- Exploration of the Factory pattern and its significance in system design.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/9RBYMYIxmXk?si=5tMCQjJHHhfw5ssp&amp;start=4438\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n---\n\n**Vietnamese version**\n\nShort Summary for [Office Hours 6 - Looking at the Factory pattern, Erlang state machines, and the Trading Process](https://www.youtube.com/watch?v=9RBYMYIxmXk) \n\n[00:03](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3) Mẫu nhà máy và các chi tiết của nó\n\n[10:55](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=655) Mẫu Factory đơn giản hóa quá trình tạo sản phẩm cho khách hàng.\n\n[18:26](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=1106) Phương thức xuất xưởng cho phép khởi tạo và logic riêng biệt của từng sản phẩm.\n\n[21:29](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=1289) Những ưu điểm và nhược điểm của mẫu Factory đã được thảo luận.\n\n[28:12](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=1692) Hiểu sự khác biệt giữa mẫu Factory và mẫu trình xây dựng trong quá trình khởi tạo đối tượng\n\n[31:58](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=1918) Tìm hiểu mẫu Nhà máy và các biến thể của nó\n\n[38:55](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=2335) Thảo luận về việc kết hợp mẫu Factory với nguyên mẫu của trình xây dựng\n\n[41:32](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=2492) Minh đang đảm nhận thêm trách nhiệm và thăng tiến trong cơ cấu nhóm.\n\n[47:15](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=2835) Khám phá các cơ hội tối ưu hóa trong quá trình giao dịch\n\n[50:14](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3014) Tối ưu hóa quy trình giao dịch để tối đa hóa lợi nhuận\n\n[56:02](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3362) Tự động thay đổi kích thước và quản lý vị trí cổ phiếu bằng bot\n\n[59:10](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3550) Sử dụng các nền tảng như Fly để triển khai ứng dụng hiệu quả\n\n[1:05:15](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3915) Giới thiệu về máy trạng thái Erlang\n\n[1:08:48](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=4128) Hiểu sự chuyển đổi trạng thái trong quá trình giao dịch\n\n[1:13:22](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=4402) Khám phá mẫu Factory và máy trạng thái Erlang\n\n[1:15:48](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=4548) Triển khai các máy trạng thái trong hệ thống\n\n[1:21:09](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=4869) Triển khai Factory Pattern trong máy trạng thái Erlang\n\n[1:23:58](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5038) Quản lý lỗi máy chủ và truy xuất dữ liệu trong máy trạng thái Erlang\n\n[1:28:54](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5334) Thảo luận về việc triển khai máy trạng thái thông thường và sử dụng máy trạng thái Erlang.\n\n[1:31:28](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5488) Thiết kế máy trạng thái Erlang và các lợi ích của tính năng macro\n\n[1:35:57](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5757) Khám phá lợi ích của việc triển khai máy trạng thái Erlang trong quy trình.\n\n[1:38:43](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5923) Thảo luận về mô hình Nhà máy, máy trạng thái Erlang và Quy trình giao dịch.\n\n[1:46:14](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=6374) Tổng quan chung về Erlang\n\n---\n\n**Detailed Summary for [Office Hours 6 - Looking at the Factory pattern, Erlang state machines, and the Trading Process](https://www.youtube.com/watch?v=9RBYMYIxmXk)**\n\n[00:03](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3) Mẫu nhà máy và các chi tiết của nó\n\n- Giải thích vấn đề mà mẫu Factory giải quyết và giải pháp của nó\n- Thảo luận về cấu trúc khái niệm, ứng dụng thực tế, ưu nhược điểm\n\n[10:55](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=655) Mẫu Factory đơn giản hóa quá trình tạo sản phẩm cho khách hàng.\n\n- Mô hình này liên quan đến việc khách hàng bày tỏ sở thích về đồ uống của họ với người pha chế, người này sẽ tùy chỉnh hoặc gợi ý đồ uống dựa trên sở thích.\n- Phương thức Factory là một kiểu mẫu thiết kế giúp đơn giản hóa việc khởi tạo các đối tượng bằng cách cung cấp một giao diện chung.\n\n[18:26](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=1106) Phương thức xuất xưởng cho phép khởi tạo và logic riêng biệt của từng sản phẩm.\n\n- Phương thức xuất xưởng được sử dụng khi ứng dụng không biết trước nó sẽ hoạt động với loại đối tượng nào.\n- Nó có lợi cho các tình huống trong đó điều kiện thời gian chạy xác định việc khởi tạo loại đối tượng.\n\n[21:29](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=1289) Những ưu điểm và nhược điểm của mẫu Factory đã được thảo luận.\n\n- Ưu điểm bao gồm khả năng đọc mã dễ dàng và tách logic. Nhược điểm liên quan đến việc tăng độ phức tạp và kích thước mã.\n\n[28:12](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=1692) Hiểu sự khác biệt giữa mẫu Factory và mẫu trình xây dựng trong quá trình khởi tạo đối tượng\n\n- Mẫu Factory đơn giản hóa việc khởi tạo đối tượng bằng cách sử dụng các hàm kế thừa, trong khi mẫu trình xây dựng liên quan đến việc xác định và triển khai các bước để tạo đối tượng.\n- Builder Pattern cho phép tạo đối tượng với các bước khác nhau, đảm bảo tính linh hoạt và tùy biến trong quá trình xây dựng đối tượng.\n\n[31:58](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=1918) Tìm hiểu mẫu Nhà máy và các biến thể của nó\n\n- Mẫu Factory liên quan đến việc sử dụng giao diện để tạo đối tượng\n- Ngoài ra còn có mẫu Factory trừu tượng để tạo các bộ sản phẩm liên quan\n\n[38:55](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=2335) Thảo luận về việc kết hợp mẫu Factory với nguyên mẫu của trình xây dựng\n\n- Nhóm đã thảo luận về việc triển khai mẫu Factory với nguyên mẫu của trình xây dựng\n- Được coi là dễ tạo mẫu với mẫu Singleton ở Singapore\n\n[41:32](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=2492) Minh đang đảm nhận thêm trách nhiệm và thăng tiến trong cơ cấu nhóm.\n\n- Minh bắt đầu với vị trí Thủ tướng cấp dưới, hiểu rõ hơn về hoạt động của nhóm.\n- Minh đang tiến tới vai trò trợ lý thứ hai, liên quan đến quản lý và quản lý dự án.\n\n[47:15](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=2835) Khám phá các cơ hội tối ưu hóa trong quá trình giao dịch\n\n- Thảo luận về các nhiệm vụ định kỳ trong quá trình giao dịch như tiền gửi và séc\n- Thực hiện tối ưu hóa thông qua tự động hóa và các chỉ số tùy chỉnh\n\n[50:14](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3014) Tối ưu hóa quy trình giao dịch để tối đa hóa lợi nhuận\n\n- Sử dụng các trình kích hoạt cụ thể trên Binance để phân tích giao dịch và ra quyết định hiệu quả\n- Thông báo và tận dụng tỷ giá hối đoái thuận lợi trong các khung thời gian cụ thể\n\n[56:02](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3362) Tự động thay đổi kích thước và quản lý vị trí cổ phiếu bằng bot\n\n- Tạo bot có tên 'phân phối Anf' để thay đổi kích thước vị trí cổ phiếu\n- Sử dụng Roxim để xử lý các yêu cầu và tự động hóa quản lý kho\n\n[59:10](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3550) Sử dụng các nền tảng như Fly để triển khai ứng dụng hiệu quả\n\n- Nó tự động hóa các quy trình để tiết kiệm thời gian và tập trung vào các nhiệm vụ chính như quản lý kho.\n- Nền tảng Fly cung cấp các giải pháp triển khai đơn giản cho các ứng dụng như Telegram hoặc Discord.\n\n[1:05:15](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=3915) Giới thiệu về máy trạng thái Erlang\n\n- Máy trạng thái Erlang bao gồm ba trạng thái: đóng, mở và nửa mở, giống như một bộ ngắt mạch.\n- Nó được sử dụng để xử lý các yêu cầu và ngăn chặn thời gian ngừng hoạt động của máy chủ với các trạng thái khác nhau.\n\n[1:08:48](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=4128) Hiểu sự chuyển đổi trạng thái trong quá trình giao dịch\n\n- Giải thích trạng thái máy chủ ảnh hưởng như thế nào đến việc giao tiếp với các bên khác.\n- Trình bày chi tiết vai trò của bộ ngắt mạch trong việc quản lý các kết nối và sự kiện.\n\n[1:13:22](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=4402) Khám phá mẫu Factory và máy trạng thái Erlang\n\n- Mẫu Factory tập trung vào cấu trúc dữ liệu trong từng chức năng\n- Máy trạng thái Erlang quản lý các quy trình như đăng ký người dùng với nhiều trạng thái\n\n[1:15:48](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=4548) Triển khai các máy trạng thái trong hệ thống\n\n- Quá trình này bao gồm ba giai đoạn và ba hành động\n- Phần demo thảo luận về các phiên bản khác nhau và chi tiết triển khai\n\n[1:21:09](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=4869) Triển khai Factory Pattern trong máy trạng thái Erlang\n\n- Thảo luận về quá trình gắn lại thư viện và xử lý các hàm đầu vào.\n- Khám phá việc đơn giản hóa logic thông qua việc sử dụng Grapper trong quá trình triển khai.\n\n[1:23:58](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5038) Quản lý lỗi máy chủ và truy xuất dữ liệu trong máy trạng thái Erlang\n\n- Chia logic xử lý thành các phần nhỏ hơn để dễ dàng mở rộng và bảo trì mã\n- Sử dụng các chức năng chuyển đổi trạng thái và quản lý lỗi trong Erlang để xử lý quy trình hiệu quả\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/9RBYMYIxmXk?si=RUPNA7_7p3CYFoYA&amp;start=4935\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:28:54](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5334) Thảo luận về việc triển khai máy trạng thái thông thường và sử dụng máy trạng thái Erlang.\n\n- Giải thích về cách sử dụng máy trạng thái Erlang và sự hỗ trợ từ phía Thư viện chuẩn.\n- Thảo luận về bản chất cơ bản của cách thức hoạt động và mức độ phức tạp của việc triển khai.\n\n[1:31:28](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5488) Thiết kế máy trạng thái Erlang và các lợi ích của tính năng macro\n\n- Thiết kế máy trạng thái Erlang bao gồm việc sử dụng macro tạo mã trong quá trình sử dụng, giúp nó thuận tiện và hiệu quả.\n- Làm việc với phía Lan và tính năng macro cung cấp các quy trình tiết kiệm chi phí, hỗ trợ các ngôn ngữ khác nhau và giảm thiểu việc sử dụng tài nguyên.\n\n[1:35:57](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5757) Khám phá lợi ích của việc triển khai máy trạng thái Erlang trong quy trình.\n\n- Hiểu được tầm quan trọng của dữ liệu và chức năng trong quản lý trạng thái Erlang.\n- Khám phá cấu trúc của OTP trong việc quản lý trạng thái và quy trình.\n\n[1:38:43](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=5923) Thảo luận về mô hình Nhà máy, máy trạng thái Erlang và Quy trình giao dịch.\n\n- Cách quản lý code logic với OTP, FSM, GenServer trong Erlang.\n- Khám phá quá trình chuyển đổi từ máy chủ gen sang máy trạng thái để xử lý lỗi nâng cao.\n\n[1:46:14](https://www.youtube.com/watch?v=9RBYMYIxmXk&t=6374) Tổng quan về Erlang\n\n- Thảo luận về máy trạng thái Erlang và vai trò của chúng trong quá trình giao dịch\n- Khám phá mẫu Factory và ý nghĩa của nó trong thiết kế hệ thống\n","title":"OGIF Office Hours #6 - Looking at the Factory pattern, Erlang state machines, and the Trading Process","short_title":"#6 Factory Pattern, Erlang State Machines, and Trading Process","description":"In our sixth community discussion, we'll delve into the Factory pattern, Erlang state machines, and the Trading Process. By sharing weekly topics chosen through tags, we foster a collaborative learning environment for our community to grow.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Fri Jun 07 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/6-20240510.md","slugArray":["updates","ogif","6-20240510"]},{"content":"\n88 minutes\n\nRecorded May 17, 2024\n\n**Summary for [Office Hours - Echelon EXPO, Programming patterns, and Moonlighting](https://www.youtube.com/watch?v=VST3aAbw7pY)**\n\n[00:03](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3) Discussion on programming patterns\n\n[06:54](https://www.youtube.com/watch?v=VST3aAbw7pY&t=414) Explaining the Factory button and its problem\n\n[12:59](https://www.youtube.com/watch?v=VST3aAbw7pY&t=779) Programming patterns like dot dot and singleton are discussed\n\n[17:12](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1032) Race conditions in singleton pattern can cause data inconsistency.\n\n[23:31](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1411) Introduction to prototype creational button pattern\n\n[26:43](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1603) Implementing counter interface for managing inventories\n\n[31:29](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1889) Different design patterns have specific characteristics for creating new objects.\n\n[33:58](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2038) Using builder buttons for creating variations of objects\n\n[39:56](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2396) Discussion on programming patterns\n\n[43:42](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2622) Discussion on the usage and shortcomings of the builder pattern in JavaScript\n\n[50:00](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3000) Investors focus more on market experience than the product itself.\n\n[53:14](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3194) Challenges and concerns in enterprise AI implementation\n\n[58:51](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3531) Entering new markets and new projects.\n\n[1:00:59](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3659) Echelon EXPO and consulting opportunities\n\n[1:05:47](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3947) Observations and opportunities in the market\n\n[1:08:33](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4113) Importance of genuine storytelling in professional interactions\n\n[1:13:43](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4423) Echelon EXPO studio specializing in web products in Hong Kong\n\n[1:16:37](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4597) Topics on AI, architecture, and software design discussed in the next few sessions.\n\n[1:21:33](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4893) Team offering rewards for learning new topics\n\n[1:23:59](https://www.youtube.com/watch?v=VST3aAbw7pY&t=5039) Discussing strategies for knowledge sharing and testing performance\n\n---\n\n**Detailed Summary**\n\n[00:03](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3) Discussion on programming patterns\n\n- Topics covered include creational patterns like Singleton, Prototype, and Builder\n- Emphasis on sharing knowledge and discussing patterns related to programming\n\n[06:54](https://www.youtube.com/watch?v=VST3aAbw7pY&t=414) Explaining the Factory button and its problem\n\n- Factory button allows creation of objects with varying complexity but faces issues with initializing small fields\n- Build button solves the problem by allowing adjustments to each field during initialization\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/VST3aAbw7pY?si=Bt1L6VPeuBtO46gg&amp;start=371\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[12:59](https://www.youtube.com/watch?v=VST3aAbw7pY&t=779) Programming patterns like dot dot and singleton are discussed\n\n- Examples of programming patterns like RR library and Spotify web library are provided\n- Detailed explanation of singleton pattern and its practical applications\n\n[17:12](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1032) Race conditions in singleton pattern can cause data inconsistency.\n\n- Singleton pattern can lead to multiple instances being created due to race conditions during initialization.\n- Singleton pattern has limited practical applications and can violate the single responsibility principle.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/VST3aAbw7pY?si=MiUwsM31di1fwTJR&amp;start=2076\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[23:31](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1411) Introduction to prototype creational button pattern\n\n- Creation of access object with database details and initialization at run time.\n- Utilizing proxy pattern to replicate access object for reusability and database access.\n\n[26:43](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1603) Implementing counter interface for managing inventories\n\n- Creating a counter interface named counter for managing goods in store inventory\n- Each product type in the store requires a separate counter for inventory management\n\n[31:29](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1889) Different design patterns have specific characteristics for creating new objects.\n\n- Builders help choose special features when creating new objects, such as cars, trains, or buses.\n- Abstract Factory includes special cases like creating an electric car using a separate factory to override default functions.\n\n[33:58](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2038) Using builder buttons for creating variations of objects\n\n- Builder pattern allows dedicated builders for each vehicle specification\n- Creational pattern brings prototypes for cloning objects and limiting data accesses\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/VST3aAbw7pY?si=hbYlHC8NsspkiBpn&amp;start=1840\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[39:56](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2396) Discussion on programming patterns\n\n- Exploring abstract Factory and Factory method functions\n- Conversation about object creation and type considerations\n\n[43:42](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2622) Discussion on the usage and shortcomings of the builder pattern in JavaScript\n\n- Abstract Factory is less used compared to other patterns like the builder in JavaScript.\n- Builder pattern in JavaScript has limited benefits and many shortcomings, leading to it being rarely used.\n\n[50:00](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3000) Investors focus more on market experience than the product itself.\n\n- Investors prioritize market and industry experience over just the product.\n- Teams in Credit and Bank organizations build models to detect fraud and fishing.\n\n[53:14](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3194) Challenges and concerns in enterprise AI implementation\n\n- Large enterprise companies cautious about AI integration\n- Security, privacy, cost-benefit, and ethical concerns in AI implementation\n\n[58:51](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3531) Entering new markets and new projects.\n\n- Exploring new markets and projects with innovative technology.\n- Challenges of entering untapped markets and new technologies.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/VST3aAbw7pY?si=8LSBHNQta9gRQx4T&amp;start=3505\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:00:59](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3659) Echelon EXPO and consulting opportunities\n\n- Discussion of market limitations and consulting potential\n- Feedback and mindset of SPB team in the industry\n\n[1:05:47](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3947) Observations and opportunities in the market\n\n- Discussion on declining levels in the market over 3-4 years\n- Exploring new opportunities and learning from consulting teams\n\n[1:08:33](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4113) Importance of genuine storytelling in professional interactions\n\n- Sharing authentic and engaging stories can help in building connections and gaining interest from others.\n- Being genuine in communication can lead to more meaningful interactions and potential opportunities.\n\n[1:13:43](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4423) Echelon EXPO studio specializing in web products in Hong Kong\n\n- Development and design work divided between Anh, Huy Nguyen, Vincent, and Hien\n- Plans for upcoming meetups and sharing sessions led by Huy Nguyen for all participants\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/VST3aAbw7pY?si=XK6QEoTEJdtGZPCq&amp;start=4432\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:16:37](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4597) Topics on AI, architecture, and software design discussed in the next few sessions.\n\n- Discussion on specific areas like commenting challenge and product design.\n- Analysis of open source products and assigning tasks for designing specific products.\n\n[1:21:33](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4893) Team offering rewards for learning new topics\n\n- Submitting suggested topics in advance is encouraged\n- Rewards of 600 to 1000 ICY for successful topic research\n\n[1:23:59](https://www.youtube.com/watch?v=VST3aAbw7pY&t=5039) Discussing strategies for knowledge sharing and testing performance\n\n- These knowledge bases provide access for sharing information and updating Memo series.\n- Gim and coder equivalency discussed, importance of testing performance for money K s.\n\n---\n\n**Tóm tắt nội dung [Office Hours - Echelon EXPO, Programming patterns, and Moonlighting](https://www.youtube.com/watch?v=VST3aAbw7pY)**\n\n[00:03](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3) Thảo luận về các mẫu lập trình như các mẫu sáng tạo\n\n[05:51](https://www.youtube.com/watch?v=VST3aAbw7pY&t=351) Thảo luận về các mẫu thiết kế sáng tạo\n\n[10:00](https://www.youtube.com/watch?v=VST3aAbw7pY&t=600) Giới thiệu về Mẫu thiết kế Builder\n\n[11:58](https://www.youtube.com/watch?v=VST3aAbw7pY&t=718) Hiểu các giá trị trường trong một hàm xem riêng\n\n[16:59](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1019) Mẫu Singleton trong lập trình\n\n[19:13](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1153) Ưu điểm và nhược điểm của mẫu Singleton\n\n[23:15](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1395) Triển khai cơ chế khóa để khởi tạo và khởi tạo ngay lập tức\n\n[25:45](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1545) Khám phá mẫu nguyên mẫu để nhân bản đối tượng.\n\n[29:01](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1741) Triển khai giao diện Counter để tạo các phiên bản thuộc tính.\n\n[30:46](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1846) Thảo luận về các mẫu thiết kế sáng tạo và tái cấu trúc\n\n[33:58](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2038) Triển khai các mẫu lập trình cho các biến thể của đối tượng\n\n[35:38](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2138) Thảo luận về các mẫu thiết kế lập trình\n\n[40:10](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2410) Thảo luận về các mẫu thiết kế phương pháp Factory và Factory trừu tượng.\n\n[42:55](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2575) Thảo luận về các mẫu lập trình và cách sử dụng lỗi thời\n\n[47:07](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2827) Tóm tắt hội nghị Echelon EXPO tại Singapore\n\n[48:59](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2939) Đầu tư và phục hồi thị trường ở Đông Nam Á\n\n[53:06](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3186) Thảo luận về những thách thức và mối quan tâm trong việc áp dụng AI cho doanh nghiệp\n\n[55:15](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3315) Những lo ngại về mặt đạo đức về việc sử dụng AI cho mục đích xấu\n\n[58:59](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3539) Những thách thức trong việc áp dụng công nghệ\n\n[1:00:33](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3633) Thảo luận về các thị trường mới nổi và cơ hội tư vấn\n\n[1:03:40](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3820) Những thách thức với việc truy cập và vận hành dữ liệu tại SP Digital\n\n[1:05:15](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3915) Cần kỹ năng lập trình cấp cao\n\n[1:08:50](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4130) Tận dụng bản chất hướng nội của bạn để xây dựng kết nối\n\n[1:10:32](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4232) Chuyển sang các mô hình và hệ thống lập trình mới.\n\n[1:14:19](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4459) Thông báo về sự kiện offline meetup sắp tới\n\n[1:16:20](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4580) Thảo luận về định hướng tương lai của nhóm dựa trên các phiên gần đây\n\n[1:19:36](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4776) Thảo luận về các mô hình lập trình và làm việc ngoài giờ\n\n[1:21:19](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4879) Thảo luận về các hoạt động sắp tới của team\n\n---\n\n**Tóm tắt chi tiết nội dung**\n\n[00:03](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3) Thảo luận về các mẫu lập trình như các mẫu sáng tạo\n\n- Khám phá mô hình sáng tạo cùng Hoàng Anh và Vinon\n- Các chủ đề sắp tới bao gồm chuyến đi Singapore và kết hợp hiệu quả\n\n[05:51](https://www.youtube.com/watch?v=VST3aAbw7pY&t=351) Thảo luận về các mẫu thiết kế sáng tạo\n\n- Giải thích mẫu Factory và khả năng khởi tạo các đối tượng phức tạp một cách dễ dàng nhưng có những hạn chế trong việc thay đổi các trường trong quá trình khởi tạo.\n- Tiếp tục thảo luận về mẫu Builder và vai trò của nó trong việc giải quyết các vấn đề liên quan đến khởi tạo đối tượng.\n\n[10:00](https://www.youtube.com/watch?v=VST3aAbw7pY&t=600) Giới thiệu về Mẫu thiết kế Builder\n\n- Giải thích cách tạo các đối tượng tùy chỉnh như Ring với các thuộc tính mong muốn\n- Mô tả quá trình sử dụng mẫu trình xây dựng để tăng thêm tính linh hoạt và tạo đối tượng một cách dễ dàng\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/VST3aAbw7pY?si=iMLaATltaeLt--n7&amp;start=690\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[11:58](https://www.youtube.com/watch?v=VST3aAbw7pY&t=718) Hiểu các giá trị trường trong một hàm xem riêng\n\n- Thêm các tiện ích như trình ghi nhật ký hoặc trình xác thực trong đối tượng\n- Ví dụ về các mẫu phổ biến như sử dụng trình tạo để xử lý đầu vào\n\n[16:59](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1019) Mẫu Singleton trong lập trình\n\n- Đảm bảo chỉ có một phiên bản của một lớp được tạo có thể truy cập được trên toàn cầu.\n- Xử lý tình trạng chủng tộc để ngăn chặn nhiều trường hợp ngoài ý muốn.\n\n[19:13](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1153) Ưu điểm và nhược điểm của mẫu Singleton\n\n- Giúp quản lý tài nguyên được chia sẻ duy nhất nhưng vi phạm nguyên tắc trách nhiệm duy nhất.\n- Mã máy khách trở nên phụ thuộc trực tiếp vào loại lớp Singleton, khiến việc gỡ lỗi và kiểm tra trở nên khó khăn.\n\n[23:15](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1395) Triển khai cơ chế khóa để khởi tạo và khởi tạo ngay lập tức\n\n- Quá trình này bao gồm việc kiểm tra xem phiên bản tức thời đã được khởi tạo chưa, khóa nó rồi kiểm tra lại để đảm bảo phiên bản tức thời duy nhất\n- Việc kiểm tra thất bại đảm bảo chỉ có một lần khởi tạo đối tượng\n\n[25:45](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1545) Khám phá mẫu nguyên mẫu để nhân bản đối tượng.\n\n- Mẫu nguyên mẫu cho phép sao chép một đối tượng trong thời gian chạy bằng cách sử dụng hàm Clone mà không cần lo lắng về việc khởi tạo hoặc triển khai đối tượng.\n- Bằng cách triển khai chức năng Sao chép, nhà phát triển có thể dễ dàng tạo một bản sao của đối tượng với tất cả dữ liệu được khởi tạo trong thời gian chạy để sử dụng tiếp, chẳng hạn như truy cập cơ sở dữ liệu.\n\n[29:01](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1741) Triển khai giao diện Counter để tạo các phiên bản thuộc tính.\n\n- Tạo phiên bản mới bằng chức năng Clone.\n- Xử lý các tình huống khác nhau như lỗi và sửa giá trị bộ đếm.\n\n[30:46](https://www.youtube.com/watch?v=VST3aAbw7pY&t=1846) Thảo luận về các mẫu thiết kế sáng tạo và tái cấu trúc\n\n- Các mẫu sáng tạo giúp tránh quá tải việc tái cấu trúc bằng cách cung cấp các triển khai sẵn có với các hành vi phổ biến.\n- Các ví dụ bao gồm phương pháp Factory để sử dụng hành vi mà không cần khởi tạo đối tượng trực tiếp, Nhà máy trừu tượng để sử dụng lại các hành vi phổ biến giữa các đối tượng và Trình tạo để chọn các đặc điểm đối tượng cụ thể trong quá trình khởi tạo.\n\n[33:58](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2038) Triển khai các mẫu lập trình cho các biến thể của đối tượng\n\n- Thảo luận về việc sử dụng mẫu Tóm tắt Factory để tạo các biến thể đối tượng bằng cách mở rộng các nhà máy mặc định\n- Khám phá cách sử dụng mẫu Builder để xây dựng các đối tượng có thông số kỹ thuật cụ thể\n\n[35:38](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2138) Thảo luận về các mẫu thiết kế lập trình\n\n- Khám phá khái niệm nhân bản các đối tượng để tái sử dụng\n- Chi tiết cách sử dụng phương thức Factory và Tóm tắt Factory trong API phụ trợ\n\n[40:10](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2410) Thảo luận về các mẫu thiết kế phương pháp Factory và Factory trừu tượng.\n\n- Khám phá việc sử dụng các hàm để tạo các phương thức Factory.\n- Những cân nhắc về việc xử lý các cấu trúc đối tượng phức tạp và ý nghĩa về hiệu suất.\n\n[42:55](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2575) Thảo luận về các mẫu lập trình và cách sử dụng lỗi thời\n\n- Mẫu Tóm tắt Factory ít được sử dụng hơn so với các mẫu khác như mẫu Builder.\n- Mẫu trình tạo trong JavaScript thường được sử dụng nhưng có thể bị hiểu nhầm do tính chất của nó.\n\n[47:07](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2827) Tóm tắt hội nghị Echelon EXPO tại Singapore\n\n- Echelon X là sự kiện kết nối các công ty khởi nghiệp, nhà đầu tư và cộng đồng với hơn 10.000 người tham dự tại Singapore.\n- Chính phủ Singapore cũng tham gia sự kiện này.\n\n[48:59](https://www.youtube.com/watch?v=VST3aAbw7pY&t=2939) Đầu tư và phục hồi thị trường ở Đông Nam Á\n\n- Nhà đầu tư thuyết trình về việc tài trợ cho các dự án ở Đông Nam Á\n- Quan tâm đến các thị trường như Philippines và Indonesia, với các sự kiện sắp tới\n\n[53:06](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3186) Thảo luận về những thách thức và mối quan tâm trong việc áp dụng AI cho doanh nghiệp\n\n- Doanh nghiệp thận trọng ứng dụng AI, dựa vào công cụ cá nhân hơn là giải pháp hoàn chỉnh\n- Tranh luận về việc nên xây dựng năng lực AI nội bộ hay tận dụng các mô hình chính phủ hiện có\n\n[55:15](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3315) Những lo ngại về mặt đạo đức về việc sử dụng AI cho mục đích xấu\n\n- Việc sử dụng AI để tạo nội dung giả mạo sẽ đặt ra các vấn đề về đạo đức và nguy cơ lạm dụng công nghệ.\n- Các kỹ sư đang cân nhắc việc rời Singapore do chi phí sinh hoạt cao và khó khăn trong việc xin thường trú.\n\n[58:59](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3539) Những thách thức trong việc áp dụng công nghệ\n\n- Chậm áp dụng công nghệ mới do chiếm lĩnh thị trường\n- Thiếu động lực để các công ty lớn hơn đổi mới\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/VST3aAbw7pY?si=XgGNnWfscfRwQCXJ&amp;start=3418\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:00:33](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3633) Thảo luận về các thị trường mới nổi và cơ hội tư vấn\n\n- Ví dụ về một công ty khởi nghiệp ở Indonesia đang phát triển camera cho tài xế xe tải, cho thấy tiềm năng ở những thị trường chưa được khai thác\n- Tầm quan trọng của việc nắm bắt các cơ hội phát triển nghề nghiệp và tư vấn nhóm tại các thị trường như vậy\n\n[1:03:40](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3820) Những thách thức với việc truy cập và vận hành dữ liệu tại SB Digital\n\n- Sự cố truy cập dữ liệu trong nhóm SB Digital và các nhóm khác\n- Tầm quan trọng của việc hiểu cấu trúc dữ liệu và cấp độ truy cập để vận hành trơn tru\n\n[1:05:15](https://www.youtube.com/watch?v=VST3aAbw7pY&t=3915) Cần kỹ năng lập trình cấp cao\n\n- Ứng viên cần có kỹ năng lập trình nâng cao để nổi bật\n- Tầm quan trọng của việc học hỏi liên tục và thích ứng với xu hướng thị trường\n\n[1:08:50](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4130) Tận dụng bản chất hướng nội của bạn để xây dựng kết nối\n\n- Sử dụng bản chất hướng nội của bạn để trở nên dễ gần và dễ tiếp cận\n- Các nhà xây dựng liên doanh có thể dễ dàng kết nối các nguồn lực cần thiết\n\n[1:10:32](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4232) Chuyển sang các mô hình và hệ thống lập trình mới.\n\n- Khả năng quan sát và khả năng thích ứng là rất quan trọng để điều hướng các cơ hội mới.\n- Việc tương tác với các chuyên gia trong ngành như Huy Nguyễn sẽ mang lại những hiểu biết có giá trị.\n\n[1:14:19](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4459) Thông báo về sự kiện offline sắp tới\n\n- Sự kiện offline vào tuần tới thay vì sự kiện trực tuyến\n- Huy Nguyễn chủ trì sự kiện, nhấn mạnh sự tham gia tích cực và chia sẻ\n\n[1:16:20](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4580) Thảo luận về định hướng tương lai của nhóm dựa trên các phiên gần đây\n\n- Khám phá các khía cạnh kỹ thuật như tốc độ chạy và bắt đầu các chủ đề kỹ thuật khác.\n- Lập kế hoạch đi sâu vào phân tích kiến trúc, thiết kế và thiết kế sản phẩm.\n\n[1:19:36](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4776) Thảo luận về các mô hình lập trình và làm việc ngoài giờ\n\n- Nó liên quan đến việc thảo luận về tư duy và tư vấn các câu hỏi liên quan\n- Bao gồm các chủ đề như cách sử dụng mô hình, thiết lập quyền truy cập dữ liệu và các cuộc thảo luận thông thường\n\n[1:21:19](https://www.youtube.com/watch?v=VST3aAbw7pY&t=4879) Thảo luận về các hoạt động và ưu đãi sắp tới của nhóm\n\n- Nhóm sẽ tiếp tục các hoạt động theo hướng thiết kế Phần mềm, khuyến khích v/v nghiên cứu\n- Ưu tiên cho các chủ đề nghiên cứu có tiềm năng\n","title":"OGIF Office Hours #7 - Echelon EXPO, Programming patterns, and Moonlighting","short_title":"#7 Echelon EXPO, Programming patterns, and Moonlighting","description":"In our seventh community discussion, we'll discuss about Echelon EXPO; builder, singleton, prototype patterns. By sharing weekly topics chosen through tags, we foster a collaborative learning environment for our community to grow.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Tue Jun 25 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/7-20240517.md","slugArray":["updates","ogif","7-20240517"]},{"content":"\n84 minutes\n\nRecorded June 07, 2024\n\n**Short Summary for [Office Hours - What's next for June and Behavior Design Patterns](https://www.youtube.com/watch?v=POJ2hNaKJx4)**\n\n[00:03](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3) Updates in team phase\n\n[10:44](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=644) Discussion about new shirts and picture\n\n[17:01](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1021) Updates on recent activities and future plans\n\n[19:36](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1176) Proposing to cut down activities related to retainer work\n\n[24:47](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1487) Discussing sustainable work commitment and project management\n\n[27:48](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1668) Team's direction and decision making\n\n[32:50](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1970) Discussing the Observer Design Pattern\n\n[38:07](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=2287) One-to-many relationship between subject and server, and observer pattern in action\n\n[44:47](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=2687) Benefits of the observer pattern\n\n[48:42](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=2922) Discussion on handling new information and maintaining connection\n\n[55:13](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3313) Explaining file packing and sending process\n\n[57:28](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3448) Explaining the command pattern in software design\n\n[1:02:12](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3732) Implementing comment pattern for transaction management\n\n[1:04:45](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3885) Discussing the use of Command Design Pattern in handling requests and responses\n\n[1:10:35](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4235) Understanding the consequence of user actions\n\n[1:13:42](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4422) Understanding object-oriented design and programming\n\n[1:19:11](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4751) Discussion on game making and design patterns\n\n[1:22:05](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4925) Need processes for crowd to follow\n\n---\n\n**Detailed Summary**\n\n[00:03](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3) Updates in team phase\n\n- Discussion on team updates and potential changes\n- Acknowledgment and gratitude to Huy Nguyen for organizing a meeting\n\n[10:44](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=644) Discussion about new shirts and picture\n\n- Conversation about the new shirt design and distribution among the team.\n- Debating on the wedding picture and assessing its price.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/POJ2hNaKJx4?si=K4vPKnODteVEF1eJ&amp;start=404\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[17:01](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1021) Updates on recent activities and future plans\n\n- Discussions on blockchain and language model implementation\n- Encouraging more active participation and rewarding knowledge generation\n\n[19:36](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1176) Proposing to cut down activities related to retainer work\n\n- Activities such as sharing knowledge, designing and writing memo will be prioritized\n- Clearer differentiation in levels of roles including bit level, baby V level, and rock level\n\n[24:47](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1487) Discussing sustainable work commitment and project management\n\n- Balancing client satisfaction and sustainable work commitment\n- Addressing the challenges of project management and the need for clear processes\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/POJ2hNaKJx4?si=1hXjP0tIghPowU0J&amp;start=1422\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[27:48](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1668) Team's direction and decision making\n\n- New team members testing the status of the team\n- Importance of background checks and cultural features in the team\n\n[32:50](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1970) Discussing the Observer Design Pattern\n\n- Covering the concept, usage, and examples of the Observer Design Pattern.\n- Mentioning the advantages and disadvantages while implementing the pattern.\n\n[38:07](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=2287) One-to-many relationship between subject and server, and observer pattern in action\n\n- Subject manages the list of dependent servers and notifies them of state changes\n- Examples of observer pattern using DOM events and event emitters\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/POJ2hNaKJx4?si=-PEFlPSGYZpBU_jp&amp;start=2240\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[44:47](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=2687) Benefits of the observer pattern\n\n- Automatically updating with a state change and reducing manual updates.\n- Easy expansion and maintenance, objects do not need to know details about each other.\n\n[48:42](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=2922) Discussion on handling new information and maintaining connection\n\n- Exploring ways to automatically update on new information without teasing\n- Addressing challenges in applying articles on the CCY channel and ensuring proper handling of data\n\n[55:13](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3313) Explaining file packing and sending process\n\n- Discusses how to pack a file into an object with specific parameters for actions and operations.\n- Details dividing the process into two main parts: invo and receiver, and the importance of this division in interface design.\n\n[57:28](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3448) Explaining the command pattern in software design\n\n- Detailing the process of packing events into objects and handling them using the pattern\n- Discussing the role of interfaces, concrete commands, and invokers in the pattern\n\n[1:02:12](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3732) Implementing comment pattern for transaction management\n\n- Utilizing a comment pattern in a project to manage transactions effectively and efficiently\n- Components like C transaction and proxy service utilized for handling transaction logic and third-party payment services respectively\n\n[1:04:45](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3885) Discussing the use of Command Design Pattern in handling requests and responses\n\n- This method involves sending a message as a response to a command.\n- Exploring how the Command Pattern is used in real-life projects for more efficient handling of content.\n\n[1:10:35](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4235) Understanding the consequence of user actions\n\n- Exploring the impact of user actions on the system and data\n- Grouping data together based on common attributes for better organization\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/POJ2hNaKJx4?si=XViXMAN_H2CqW_Ez&amp;start=4066\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:13:42](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4422) Understanding object-oriented design and programming\n\n- Objectifying actions and states is essential in object-oriented programming\n- Objectification has many models and requires understanding the concept deeply\n\n[1:19:11](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4751) Discussion on game making and design patterns\n\n- Conversation about the use of templates in game development and staying to answer questions\n- Explanation of the process of linking and designing code for game development\n\n[1:22:05](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4925) Need processes for crowd to follow\n\n- Processes help bridge the gap between symbolic belief and reality\n- Processes are essential for scaling the team\n\n---\n\n**Tóm tắt nội dung [Office Hours - What's next for June and Behavior Design Patterns](https://www.youtube.com/watch?v=POJ2hNaKJx4)** \n\n[00:03](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3) Thảo luận về các cập nhật và sự kiện\n\n[09:39](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=579) Thảo luận về tác động của làm việc từ xa đối với các cuộc họp mặt và sự kiện nhóm\n\n[14:38](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=878) Sử dụng bài viết gửi lên Memo để tính điểm kinh nghiệm\n\n[16:24](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=984) Thảo luận về các chủ đề kỹ thuật nâng cao như sức mạnh AI và blockchain.\n\n[19:48](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1188) Hãy xem xét cắt giảm các hoạt động liên quan đến công việc của người lưu giữ.\n\n[21:14](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1274) Xem xét và lọc các hoạt động trong quá khứ để mang lại lợi ích\n\n[25:01](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1501) Quản lý khối lượng công việc để mang lại sự hài lòng cho khách hàng\n\n[26:36](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1596) Thảo luận về không gian bền vững và giờ làm việc hiệu quả\n\n[30:32](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1832) Kiểm tra và phản hồi về Mẫu thiết kế hành vi\n\n[32:15](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1935) Thảo luận về lợi ích và phân phối của Disb\n\n[38:47](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=2327) Các mẫu thiết kế hành vi bao gồm mẫu người quan sát, người phát sự kiện và người nghe sự kiện.\n\n[41:08](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=2468) Mẫu thiết kế hành vi\n\n[45:47](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=2747) Các mẫu thiết kế hành vi có thể dễ dàng mở rộng và duy trì\n\n[48:40](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=2920) Thảo luận về tầm quan trọng của việc duy trì kết nối trong quá trình giải quyết vấn đề\n\n[53:02](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3182) Giới thiệu mẫu nhận xét trong mẫu thiết kế hành vi\n\n[55:33](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3333) Behavior Design Patterns là gì\n\n[58:40](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3520) Triển khai các mẫu thiết kế hành vi trong xử lý đơn hàng\n\n[1:00:31](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3631) Các mẫu thiết kế hành vi trong ứng dụng máy thu\n\n[1:03:59](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3839) Hiểu quy trình xử lý yêu cầu thanh toán hoặc chuyển khoản của người dùng\n\n[1:05:54](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3954) Các mẫu thiết kế hành vi nhấn mạnh vào việc triển khai plug and play\n\n[1:10:05](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4205) Hiểu các mẫu thiết kế hành vi trong mã hóa\n\n[1:12:08](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4328) Nhóm các mục liên quan thành các đối tượng riêng biệt để tổ chức tốt hơn.\n\n[1:15:41](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4541) Sự khác biệt giữa lập trình hướng đối tượng và lập trình chức năng\n\n[1:17:19](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4639) Bàn luận về phương pháp\n\n[1:21:42](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4902) Tầm quan trọng của khả năng lặp lại và khả năng tiếp cận trong các mẫu thiết kế hành vi.\n\n[1:23:42](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=0) Cập nhật tháng 6 và các mẫu thiết kế hành vi mới\n\n---\n\n**Tóm tắt chi tiết nội dung**\n\n[00:03](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3) Thảo luận về các cập nhật và sự kiện\n\n- Cảm ơn Huy Nguyễn đã tổ chức sự kiện\n- Phản hồi và nhận xét về sự kiện và đánh giá tổng thể trên thang điểm 10.\n\n[09:39](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=579) Thảo luận về tác động của làm việc remote đối với các cuộc họp mặt và sự kiện nhóm\n\n- Những thách thức của việc kết hợp các sự kiện xã hội và học tập trong môi trường từ xa\n- Tìm kiếm phản hồi về các sự kiện cộng đồng trước đây và đánh giá sự thành công của sự kiện\n\n[14:38](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=878) Sử dụng bài viết gửi lên Memo để tính điểm kinh nghiệm\n\n- Các bài viết gửi lên Memo dùng để tính điểm kinh nghiệm cho team\n- Việc tổ chức các chủ đề liên quan đến phạm vi kỹ thuật\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/POJ2hNaKJx4?si=UiwFtzZU66-l-pY5&amp;start=821\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[16:24](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=984) Thảo luận về các chủ đề kỹ thuật nâng cao như sức mạnh AI và blockchain.\n\n- Sức mạnh AI và hệ thống tương tác đang được tổng hợp và nghiên cứu.\n- Khám phá blockchain và các ứng dụng thực tế của nó.\n\n[19:48](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1188) Hãy xem xét cắt giảm các hoạt động liên quan đến công việc của người lưu giữ.\n\n- Có thể giảm lượng thời gian dành cho các hoạt động công việc của người lưu giữ, chẳng hạn như chia sẻ kiến thức và viết bản ghi nhớ.\n- Bắt đầu có sự phân hóa rõ ràng hơn về vai trò, đặc biệt là trong việc xác định các cấp độ trách nhiệm và kỹ năng khác nhau cho sự phát triển trong tương lai.\n\n[21:14](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1274) Xem xét và lọc các hoạt động trong quá khứ để mang lại lợi ích\n\n- Huy Nguyễn đang xem xét lại các hoạt động cũ để sắp xếp lại ICY distribution và role.\n- Các vai trò cũ sẽ giữ role ở đây, hãy kiểm tra xem liệu họ có nhận được thêm lợi ích nào không\n\n[25:01](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1501) Quản lý khối lượng công việc để mang lại sự hài lòng cho khách hàng\n\n- Khối lượng công việc bền vững cho chuyên gia tư vấn là khoảng 30-32 giờ mỗi tuần\n- Tầm quan trọng của việc lập kế hoạch và yêu cầu rõ ràng để tránh lãng phí thời gian không cần thiết\n\n[26:36](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1596) Thảo luận về không gian bền vững và giờ làm việc hiệu quả\n\n- Nhấn mạnh 30 giờ làm việc hiệu quả mỗi tuần để làm việc hiệu quả\n- Khuyến khích các thành viên trong nhóm bình luận bằng các câu hỏi và suy nghĩ về định hướng hiện tại của nhóm\n\n[30:32](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1832) Kiểm tra và phản hồi về Mẫu thiết kế hành vi\n\n- Tham gia thử nghiệm sâu các mẫu hành vi để có thông tin chi tiết và cải tiến.\n- Mời tham gia để nhận phản hồi và lợi ích trong việc phát triển kỹ năng.\n\n[32:15](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=1935) Thảo luận về lợi ích và phân phối của Disb\n\n- Khám phá các mẫu B và Lệnh cung cấp\n- Điều chỉnh độ phân giải và FPS để tải nhẹ hơn\n\n[38:47](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=2327) Các mẫu thiết kế hành vi bao gồm mẫu người quan sát, người phát sự kiện và người nghe sự kiện.\n\n- Mẫu người quan sát liên quan đến một chủ thể và người quan sát để theo dõi các thay đổi trạng thái.\n- Trình phát sự kiện cho phép các đối tượng phát ra sự kiện để các đối tượng khác lắng nghe và phản hồi.\n\n[41:08](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=2468) Mẫu thiết kế hành vi\n\n- Thư viện quản lý trạng thái với các khái niệm tương tự như mẫu quan sát\n- Được sử dụng trong các khung giao diện người dùng như React để xử lý và cập nhật sự kiện\n\n[45:47](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=2747) Các mẫu thiết kế hành vi có thể dễ dàng mở rộng và duy trì\n\n- Thêm hoặc xóa người quan sát mà không thay đổi đối tượng\n- Ví dụ thực tế về việc YouTube gửi thông báo tự động tới người dùng\n\n[48:40](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=2920) Thảo luận về tầm quan trọng của việc duy trì kết nối trong quá trình giải quyết vấn đề\n\n- Tránh lãng phí tài nguyên không cần thiết bằng cách cập nhật tự động thay vì kiểm tra thủ công\n- Minh họa tác động của việc bỏ qua các bản cập nhật về hiệu suất hệ thống bằng ví dụ về triển khai CK dành cho người tiêu dùng\n\n[53:02](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3182) Giới thiệu mẫu nhận xét trong mẫu thiết kế hành vi\n\n- Mẫu nhận xét chuyển yêu cầu thành đối tượng có tham số\n- Các đối tượng có thể được kết hợp với hàng đợi hoặc các yêu cầu khác cho các hoạt động cụ thể\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/POJ2hNaKJx4?si=GbAIbmQ0vyzRhqMB&amp;start=3076\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[55:33](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3333) Behavior Design Patterns là gì\n\n- Cách chia phân phân biệt ra thành hai phần chính\n- Ví dụ về sự kiện on click và logic của onclick\n\n[58:40](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3520) Triển khai các mẫu thiết kế hành vi trong xử lý đơn hàng\n\n- Một số lệnh nhất định được triển khai dưới dạng phương pháp đóng gói các đơn hàng, chẳng hạn như đối với bip stack hoặc cơm chiên hải sản.\n- Invoker, chẳng hạn như người phục vụ, nhận đơn đặt hàng và chuyển nó cho Người nhận, chẳng hạn như đầu bếp, người thực hiện mệnh lệnh cụ thể để chuẩn bị món ăn được chỉ định.\n\n[1:00:31](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3631) Các mẫu thiết kế hành vi trong ứng dụng máy thu\n\n- Khám phá mẫu lệnh cho các giao dịch trong hệ thống thanh toán\n- Hiểu giao diện người dùng lạc quan để có trải nghiệm người dùng tốt hơn\n\n[1:03:59](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3839) Hiểu quy trình xử lý yêu cầu thanh toán hoặc chuyển khoản của người dùng\n\n- Yêu cầu của người dùng kích hoạt yêu cầu lệnh có dữ liệu tới Rapid MQ để tạo sự kiện\n- Dịch vụ proxy sử dụng yêu cầu lệnh, xử lý nó và gửi phản hồi lại\n\n[1:05:54](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=3954) Các mẫu thiết kế hành vi nhấn mạnh vào việc triển khai plug and play\n\n- Mẫu thiết kế nhấn mạnh vào việc tạo giao diện để cho phép tích hợp dễ dàng và chức năng plug-and-play.\n- Mục tiêu là mô hình hóa hành vi để cho phép dễ dàng đính kèm các thành phần mới mà không cần phải viết lại các chức năng hiện có.\n\n[1:10:05](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4205) Hiểu các mẫu thiết kế hành vi trong mã hóa\n\n- Giải thích khái niệm Invoker trong việc xử lý các hành động và sự phụ thuộc\n- Đưa ra một ví dụ về việc sử dụng dữ liệu lịch sử để hoàn nguyên và thực hiện thay đổi\n\n[1:12:08](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4328) Nhóm các mục liên quan thành các đối tượng riêng biệt để tổ chức tốt hơn.\n\n- Thay vì coi mọi thứ như một thực thể duy nhất, hãy nhóm các mục liên quan thành các đối tượng riêng biệt, chẳng hạn như giao dịch và lịch sử.\n- Bằng cách tập trung vào việc khách quan hóa các mục liên quan, nó cho phép tổ chức và quản lý tốt hơn trong mã.\n\n[1:15:41](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4541) Sự khác biệt giữa lập trình hướng đối tượng và lập trình chức năng\n\n- Lập trình hướng đối tượng tập trung vào tính linh hoạt và thiết lập quy tắc, trong khi lập trình chức năng thiếu quy tắc và nhấn mạnh tính linh hoạt.\n- Các mẫu thiết kế hướng đối tượng giúp mô hình hóa các hành vi và hành động liên quan một cách hiệu quả.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/POJ2hNaKJx4?si=toYjjVQ1vOqPKfOx&amp;start=4535\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n[1:17:19](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4639) Bàn luận về phương pháp\n\n- Phân tích cách tiếp cận trình bày ref gr và ý nghĩa của nó\n- Khám phá ứng dụng của phương pháp này trong phát triển trò chơi, đặc biệt là trong cấu trúc cây kỹ năng\n\n[1:21:42](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=4902) Tầm quan trọng của khả năng lặp lại và khả năng tiếp cận trong các mẫu thiết kế hành vi.\n\n- Các mẫu thiết kế hành vi phải có tính lặp lại và áp dụng được cho toàn bộ dân chúng chứ không chỉ một số ít được chọn lọc.\n- Thiết lập các quy trình rõ ràng là điều cần thiết để mở rộng quy mô nhóm và đảm bảo khả năng tiếp cận cho tất cả mọi người.\n\n[1:23:42](https://www.youtube.com/watch?v=POJ2hNaKJx4&t=0) Cập nhật tháng 6 và các mẫu thiết kế hành vi mới\n\n- Các bản cập nhật cho tháng 6 sẽ bao gồm các tính năng và cải tiến mới\n- Các mẫu thiết kế hành vi đã được phát triển để nâng cao trải nghiệm người dùng\n","title":"OGIF Office Hours #9 -  What's next for June and Behavior Design Patterns","short_title":"#9 What's next for June and Behavior Design Patterns","description":"Join us for our ninth community discussion, where we will be addressing June's key updates and providing an overview of effective behavior design patterns. The discussion will be guided by weekly topics selected through community input, fostering a collaborative learning environment for all participants.","tags":["office-hours","ogif","discord"],"pinned":false,"draft":false,"hiring":false,"authors":["innno_"],"date":"Thu Jun 27 2024 00:00:00 GMT+0000 (Coordinated Universal Time)","filePath":"updates/ogif/9-20240607.md","slugArray":["updates","ogif","9-20240607"]}],"isListPage":true},"__N_SSG":true}